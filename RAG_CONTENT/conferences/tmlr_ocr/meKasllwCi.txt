Under review as submission to TMLR
On-Demand Unlabeled Personalized Federated Learning
Anonymous authors
Paper under double-blind review
Abstract
InFederated Learning (FL), multiple clients collaborate to learn a shared model through
a central server while keeping data decentralized. Personalized Federated Learning (PFL)
further extends FL by learning a personalized model per client. In both FL and PFL,
all clients participate in the training process and their labeled data are used for training.
However, in reality, novel clients may wish to join a prediction service after it has been
deployed , obtaining predictions for their own unlabeled data.
Here, we introduce a new learning setup, On-Demand Unlabeled PFL (OD-PFL), where a
system trained on a set of clients, needs to be later applied to novel unlabeled clients at
inference time. We propose a novel approach to this problem, ODPFL-HN, which learns
to produce a new model for the late-to-the-party client. Speciï¬cally, we train an encoder
network that learns a representation for a client given its unlabeled data. That client
representation is fed to a hypernetwork that generates a personalized model for that client.
Evaluated on ï¬ve benchmark datasets, we ï¬nd that ODPFL-HN generalizes better than the
current FL and PFL methods, especially when the novel client has a large shift from training
clients. We also analyzed the generalization error for novel clients, and showed analytically
and experimentally how novel clients can apply diï¬€erential privacy to protect their data.
1 Introduction
Federated Learning (FL) is the task of learning a model over multiple disjoint local datasets, while keeping
data decentralized (25). Personalized Federated Learning (PFL) (38) extends FL to the case where the data
distribution varies across clients. PFL has numerous applications from a smartphone application that wishes
to improve text prediction without uploading user-sensitive data, to a consortium of hospitals that wish to
train a joint model while preserving the privacy of their patients. Current PFL methods assume that all
clients participate in training and that their data is labeled , so once a model is trained, a novel client cannot
be added.
In many cases, however, a federated model has been trained and deployed, but then novel clients wish to
join. Often, such novel clients do not have labeled data, and their data distribution may shift from that of
training clients. This is the case, for example, when a speech recognition federated model has been deployed
and needs to be applied to new users or when a virus diagnostic has been developed for some regions or
countries, and then needs to be applied to new populations while the virus spreads. This learning setup
poses a hard challenge to existing approaches. Non-personalized FL techniques may not generalize well to
novel clients due to domain shift. PFL techniques learn personalized models but are not designed to be
applied to a client that was not available during training.
When a novel client joins with its labeleddata, there are various strategies to adapt the pre-trained model
to the novel client. For instance, a FL model can be ï¬ne-tuned using those labels. For PFL, it is less clear
which personalized model should be ï¬ne-tuned. (29) used a hypernetwork (HN) that generates a personalized
model for each client, given a descriptor of client labels. To generalize to a novel client with labeled data,
they ï¬ne-tuning the descriptor using the labeled data through the hypernetwork. While all these approaches
are useful, they cannot handle novel clients that have no labeled data.
Here, we deï¬ne a novel problem: performing federated learning on novel clients with unlabeled data that
are only available at inference time. We call this setup OD-PFL forOn-Demand Unlabeled Personalized
1Under review as submission to TMLR
Figure 1: The On-demand PFL problem. A set ofkclientsc1,...,ckare available for training a PFL
model, each with their own distribution Pi(x,y). After training is completed, a new client appears, with its
own distribution Pnewover unlabeled data. The goal is to create a model fnewthat minimizes the loss over
the new client data l(y,fnew(x)).
Federated Learning . We propose a novel approach to this problem, called ODPFL-HN. During training,
our architecture learns a space of personalized models, one for each client, together with an encoder that
maps each client to a point in that client space. All personalized models are learned jointly through an HN,
allowing us to combine personalized data eï¬€ectively. At inference time, a novel client can locally compute
its own descriptor using the client encoder. Then, it sends the descriptor to the server as input to the HN
and obtains its personalized model.
A key question remains for this approach to succeed: How to compute a descriptor of a novel unlabeled
client? A key idea is to deï¬ne a client encoder that maps a dataset into a descriptor, and train it jointly with
the HN. We explore the properties that this encoder should have. First, its architecture should implement
a function that is invariant to permutations over its inputs (35). Furthermore, if objects in the data adhere
to their own symmetries, such as images, graphs, or point clouds, the encoder architecture should also be
invariant to these symmetries (24). To the best of our knowledge, this is the ï¬rst paper that discusses
learning such invariant descriptors of datasets or clients.
FL is motivated by privacy, but was shown to be vulnerable (21). In the OD-PFL setup, novel clients do
not expose data or gradients, so they can better control their privacy. We show theoretically how diï¬€erential
privacy (DP) can be applied eï¬€ectively to a new client and then experimentally measured how DP aï¬€ects
the accuracy of the personalized model.
This paper makes the following contributions: (1) A new learning setup, OD-PFL, learning a personalized
model to novel unlabeled clients at inference time . (2) A new approach, learn a space of models
using an encoder that maps an unlabeled client to that space, and an architecture ODPFL-HN based on
hypernetworks. (3) A generalization bound based on multitask learning and domain adaptation, and analysis
ofdiï¬€erentialprivacyforanovelclient. (4)Evaluationonï¬vebenchmarkdatasets, showingthatODPFL-HN
performs better than or equal to the baselines.
2 Related work
Federated learning (FL) . In FL, clients collaboratively solve a learning task, while preserving data privacy
and maintaining communication eï¬ƒciency. By collaborating through FL, clients leverage the shared pool of
knowledge from other clients in the federation, and can better handle data scarcity, low data quality, and
unseen classes. The literature on FL is vast and cannot be covered here. We refer the reader to recent surveys
(1;36). Wenotethat(20)addressesclientswithunlabeleddatabutdoesnotaddressnovel(test-time)clients,
which is the main focus of this paper.
Personalized Federated Learning (PFL) . FL methods learn a single global model across clients, and
this limits their ability to deal with heterogeneous clients. In contrast, PFL methods are designed to handle
heterogeneity of data between clients by learning multiple models. (30) separates PFL methods into data-
2Under review as submission to TMLR
based and model-based approaches. Data-based PFL approaches aim to smooth the statistical heterogeneity
of data among diï¬€erent clients, by normalizing the data (7) or by selecting a subset of clients with minimal
class imbalance (32). Model-based PFL approaches adapt to the diversity of data distributions across clients.
As an example, a server may learn a global model and share it with all the clients. Then, each client learns
its own local model on top of the global model. We refer the reader to recent surveys (16; 30).
Novel labeled clients . Several recent studies proposed to create personalized models for a novel labeled
client. (29) used an HN to produce personalized models for training clients. Given a novel client, they
tuned the embedding layer of the HN using client labels. In (22), each client interpolates a global model
and a local kNN model is produced using the labels of the novel clients. (23) modeled each client as a
mixture of distributions using an EM-like algorithm. A new labeled client uses its labels to calculate its own
personalized mixture. All these methods depend on having access to labels of the novel client hance do not
apply to the OD-PFL setup. In Sec. 6.2, we test 3 diï¬€erent ways to apply existing PFL models to our setup
and show that ODPFL-HN outperforms all these variants.
Adapting a model to a new distribution during inference can be viewed as a variant of domain adaptation
(DA) (31; 14; 19). Our on-demand setup can be viewed as an adaptation of DA to FL. We emphasize that
DA is fundamentally diï¬€erent from FL, since in FL the data is distributed across diï¬€erent clients. As a
result, DA approaches cannot be applied directly to the FL setup. To the best of our knowledge, this is the
ï¬rst paper to address test-time adaptation in a FL setup.
Diï¬€erential privacy (DP) . The goal of DP is to share information about a dataset but to avoid sharing
information about individual samples in the dataset. Although privacy is a key motivation of PFL, private
information is exposed in the process: an adversarial client can infer the presence of exact data points in
the data of other clients, and under certain conditions even generate the data of other clients. See a survey
for more details (26). A natural solution is to use DP to protect client privacy (10). However, DP adds
noise to the training process and may harm the model performance. Here, we focus on the privacy of a
novel client at test time, so the trained models remain untouched, and each novel client can choose its own
privacy-accuracy trade-oï¬€ at inference time.
3 The Learning Setup
We now formally deï¬ne the learning setup of OD-PFL. We follow the notation in (2). Let Xbe an input
space andYan output space. Pis a probability distribution over the data XÃ—Y. Letlbe a loss function
l:YÃ—Yâ†’R.His a set of hypotheses with h:Xâ†’Y. The error of a hypothesis hover a distribution P
is deï¬ned by errP(h) =/integraltext
XÃ—Yl(h(x),y)dP(x,y).
In OD-PFL, we train a federation of Nclientsc1,...,cN, and other, novel, clients are added at inference
time. For simplicity of notation, we consider a single novel client cnew. Let{Pi}N
i=1be the data distributions
of training clients, and Pnewthe data distribution of the novel client cnew. Each training client has access
tomiIID samples from its distribution Pi, denoted as Si={(xi
j,yi
j)}mi
j=1.
The goal of OD-PFL is to use data from training clients {Si}N
i=1to learn a mechanism that can assign a
hypothesis hnewâˆˆHwhen given unlabeled data from a novel client Snew={xnew
j}m
j=1. This hypothesis
should minimize the expected error of the novel client. For any distribution of its data Pnew, that error is
deï¬ned byerrPnew(hnew) =/integraltext
XÃ—Yl(hnew(x),y)dPnew(x,y).
4 Our approach
We introduce OD-PFL to address the challenge of producing an â€œon-demand" personalized model for new
unlabeled clients after a federated model has been deployed. This task is diï¬ƒcult because the data distri-
bution of a novel client may diï¬€er from that of training clients and is unknown at training time. Also, the
training clients are no longer available at inference time. To the best of our knowledge, these constraints
were not considered in the FL setup before, and existing methods are not designed to handle this new setup.
Generalizing to a novel client is hard for FL methods, because they do not specialize. It is hard for PFL
methods, because no single model learned during training would not necessary ï¬t a novel client. Even if it
3Under review as submission to TMLR
Unlabeled Data of client ğ‘–ğ‘¥!"!#$%!g!Client encoder(permutation invariant)Hypernetworkğ‘“"Descriptor of client ğ‘–ğ‘’"#Local networkof client ğ‘–ğ‘¥ğ‘¦%h(â‹…	;ğ°#)ğ°!
Figure 2: The high-level architecture structure of ODPFL-HN. Given a client ciwithmiunlabeled
samplesx1,...,xmi, the client encoder gÎ³produces an embedding Ë†ei. Then, the hypernetwork fÎ¸predicts
weightswifor the local model hiof clienti.
did, there is no clear way to select that model, because the novel client has no labels to use as a selection
criteria. Here, we propose a meta-learning mechanism to produce a model that ï¬ts the new distribution of
unlabeled data.
A natural candidate for such a meta-mechanism would be hypernetworks (HNs). HNs are neural networks
that output the weights of another network and can therefore be used to produce â€œon-demand" models. Since
the weights of the generated model are a (diï¬€erentiable) function of the HN parameters, training the HN
is achieved simply by propagating gradients from the generated (client) model. To generate a model for a
client, the HN should be fed with a descriptor that summarizes the client dataset. Here we propose to learn
aclient encoder that takes as input the unlabeled data of a client and produces a dense descriptor. Figure 2
illustrates our approach. Each client feeds its input samples to a client encoder that produces an embedding
vector. Then an HN takes the embedding and produces a personalized model. During training, the client
uses its labels to tune the personalized model and back-propagates the gradients to the HN and the client
encoder. We now describe our approach in detail.
Client encoding. The goal of client encoding is to map an entire data set into a dense descriptor. Formally,
it maps unlabeled samples Si={xi
j}mi
j=1of clientito a descriptor eiembedded in a representation space
E. In essence, the encoder is expected to map similar datasets to nearby descriptors in a way that balances
personalization â€“ of unique clients, with generalization â€“ across similar clients.
For this mapping to be eï¬€ective, it should obey several properties. First, the embedding should be inductive
and generalizing, in the sense that the embedding function would later be applied to a novel client at test
time and should generalize to that client. Second, since data samples form an unordered set, we wish that
the encoder obeys the set symmetries of the data and is invariant to permutations over samples. Third, the
encoder should capture the full data set. We now discuss our design decisions when building the encoder.
First, with respect to generalization. One may be tempted to explicitly regularize the representation such
that similar datasets are mapped to close vectors in the embedding space. However, note that the descriptors
are consumed by the downstream HN. Therefore, training the two networks jointly, while regularizing their
parameters, should yield a representation that generalizes across clients. This is because the encoder tunes
the representation to ï¬t the downstream HN.
Second, with respect to permutation invariance, we tested three architectures. (1) DeepSet (DS) (35). In
DS, each data point is fed to the same ("siamese") model and produces a feature vector. Then, an invariant
pooling operator (usually mean) is applied to all outputs, and then processed by a second model, yielding
the ï¬nal descriptor. (2) DS is invariant to permutations over input samples, but it does not take into
account symmetries of each element itself, such as translation invariance in images. We use Deep Sets for
symmetric elements (DSS) (24) to handle symmetries at both the set level and the element level. (3) DS and
DSS uniformly aggregate information from all individual elements in the set. Sometimes, it is beneï¬cial to
4Under review as submission to TMLR
Algorithm 1 Training On-demand PFL-HN
Server executes:
initializeÎ¸,Î³
foreach round t= 1,2,...do
iâ†select a random client out of Nclients
eiâ†ClientEncoding (gÎ³)
wiâ†fÎ¸(ei) âŠ¿server computes a personal model
âˆ†wiâ†ClientUpdate (wi)
apply chain rule to obtain âˆ†Î¸andâˆ†eifrom âˆ†wi
Î¸â†Î¸âˆ’Î·âˆ†Î¸
âˆ†Î³â†ClientBackprop (âˆ†ei)
Î³â†Î³âˆ’Î·âˆ†Î³
function ClientEncoding (gÎ³) //Run on client i
eiâ†gÎ³({xk}mi
k=1) âŠ¿clienticomputes its embedding
returneito server
function ClientUpdate (wi) //Run on client i
Bâ†split{xk}mi
k=1into batches
wnew
iâ†wi
foreach local epoch efrom 1toEdo
foreach batch bâˆˆBdo
updatewnew
iusingl(h(Â·;wnew
i);b) âŠ¿training
âˆ†wiâ†wnew
iâˆ’wi
return âˆ†wito server
function ClientBackprop (âˆ†ei) //Run on client i
apply chain rule to obtain âˆ†Î³from âˆ†ei
return âˆ†Î³to server
considerseveralelementstogetherwhencomputingthedescriptor. Tocapturesample-to-sampleinteractions,
we used a set transformer (ST) (18). ST uses attention to aggregate representations of all elements into a
single descriptor. The weight of each element is determined by the context of other elements in the dataset.
We treated the architecture as a hyperparameter and selected it using the validation set.
Finally, with respect to describing the full dataset. The simplest approach is to use large batches that contain
the entire dataset as input to the client encoder. We also tested an alternative approach that can be applied
to large datasets that do not ï¬t in a single batch in memory. In these cases, we split the data into smaller
batches, encoded each batch, and used the average over batch descriptors as the ï¬nal descriptor. Note that
this resembles a DeepSet architecture and that when batches are sampled uniformly at random, would obey
in expectation invariance to input permutation.
Hypernetworks. Our goal is to create a personalized model for a new client at inference time. Assuming
that the client encoder summarized all relevant information to create such a personalized model. A natural
solution is to learn a mapping from such descriptors to personalized models, and apply it to the descriptor
of a novel client. This is exactly what HNs are designed for.
An HNfÎ¸parameterized by Î¸embodies a mapping from a client-embedding space to a hypotheses space
fÎ¸:Eâ†’H. A clientwithanembeddingvector eiismappedbythe HNtoapersonalizedmodel hi=h(Â·;wi),
withwi=fÎ¸(ei).
5Under review as submission to TMLR
Training. The client encoder and the HN are trained jointly. They produce a client descriptor and a
personalized model for every client by optimizing the following loss
L(Î¸,Î³) =n/summationdisplay
i=1mi/summationdisplay
j=1l/parenleftbigg
fÎ¸/parenleftBig
gÎ³({xi
j}mi
j=1)/parenrightBig/parenleftBig
xi
j/parenrightBig
,yi
j/parenrightbigg
(1)
using training clients (labeled) c1,...,cN, wherelis a cross-entropy loss.
Workï¬‚ow. Algorithm 1 shows the workï¬‚ow of ODPFL-HN. During training, in each communication step,
we repeat these 4 steps: (1) The server selects a random client and sends to it the current encoder gÎ³. (2)
The client locally predicts its embedding eiand sends it back to the server. (3) Using its embedding, the
server uses an HN fÎ¸to generate a customized network hi=h(Â·;wi)and communicates it to the client.
(4) The client then locally trains that network on its data and communicates back to the server the delta
between the weights before and after training. Using the chain rule, the server can train the hypernetwork
and the encoder.
At inference time, (1) the server sends the encoder to the novel client. (2) The client uses the encoder
to calculate an embedding enewand sends it to the server. (3) The server uses the HN to predict the
personalized model of the client hnew=h(Â·;wnew)from the embedding and sends the result to the client.
The client then applies its personalized model locally without revealing its data.
5 Generalization bound
The data of the new client and the clients of the federation may be sampled from diï¬€erent distributions.
In the general case, there is no guarantee that learning a model for labeled clients would lead to a good
model for a novel client. We now show that under reasonable assumptions, previous bounds developed for
multitask learning (MTL) and for domain adaptation (DA), can be applied to the OD-PFL setup, to bound
the generalization error of the novel client.
Intuitively, theboundhastwoterms; onecapturesthedomainshift, andtheothercapturesthegeneralization
error.
Theorem1. LetHbe a hypothesis space, Pnewbe a data distribution of a novel client, and Qbe a distribution
over the distributions of the clients, that is, Piis drawn from Q.Ë†errz(H)is the empirical loss over the
training-client data and is deï¬ned in detail in the Appendix ??.
The generalization error of a novel client is bounded by errPnew(H)â‰¤ Ë†errz(H) +/epsilon1+
1
2/integraltext
PinfhâˆˆHË†dHâˆ†H(P,Pnew)dQ(P). Here,/epsilon1is an approximation error of a client in the federation from
Theorem 2 in (2) and Ë†dHâˆ†His a distance measure between the probability distributions deï¬ned in (3).
Proof.See Appendix ??for a detailed proof.
6 Experiments
6.1 Experiment setup and evaluation protocol
We evaluated ODPFL-HN using ï¬ve benchmarks using an experimental protocol designed for the OD-PFL
setup where novel clients are presented to the server during inference.
Client split: To quantify the performance of novel clients, we ï¬rst randomly partition the clients to Ntrain
train clients and Nnovelnovel clients. We use Nnovel =N/10. Unless stated otherwise, we report average
accuracy for the novel clients. To conduct a fair comparison, training is limited to 500 steps for all evaluated
methods. In each step, the server communicates with a 0.1fraction of training clients following the protocol
of each method.
6Under review as submission to TMLR
Table 1:Accuracy on novel unlabeled clients, CIFAR10 & CIFAR100: Values are averages across
clients and standard error of the means.
CIFAR-10 CIFAR-100
split pathological Î±= 0.1Î±= 1Î±= 10 pathological Î±= 0.1Î±= 1Î±= 10
FedAvg 50.3Â±2.9 58.7Â±3.6 48.4Â±2.9 66.2Â±0.5 16.2Â±1.3 17.9Â±1.0 13.5Â±1.7 30.2Â±0.4
FedProx 54.2Â±2.0 53.9Â±2.2 54.2Â±1.0 52.8Â±0.6 5.5Â±1.2 15.9Â±0.7 20.6Â±0.6 12.4Â±0.6
FedMA 42.9Â±1.8 49.3Â±3.4 54.5Â±0.9 53.8Â±0.6 11.2Â±0.7 12.6Â±1.0 6.5Â±0.4 7.3Â±0.3
PFL-sampled 24.8Â±1.0 61.0Â±3.7 49.4Â±3.068.5Â±0.7 3.9Â±0.4 13.5Â±0.5 3.4Â±1.4 32.4Â±0.1
PFL-nearest 24.4Â±6.2 63.1Â±3.5 49.4Â±0.968.5Â±0.7 6.5Â±2.7 14.3Â±0.6 3.4Â±0.4 32.1Â±0.2
PFL-ensemble 47.6Â±3.2 62.2Â±3.7 49.4Â±3.068.5Â±0.7 7.8Â±1.8 20.4Â±1.2 3.4Â±1.4 32.7Â±0.2
ODPFL-HN (ours) 59.5Â±3.5 66.0Â±3.0 62.9Â±1.068.1Â±0.5 19.5Â±2.1 26.4Â±0.1 32.9Â±0.9 33.6Â±0.1
Sample split and HP tuning: We split the samples of each training client into a training set and a
validation set. Validation samples were used for hyperparameter tuning. See Appendix ??for more details.
6.2 Baselines
We evaluate using FL methods, which train a single global model, and PFL methods, which train one model
per client. We compare the following FL methods: (1) FedAVG (25), where the parameters of local models
are averaged with weights proportional to the sizes of the client datasets. (2) FedProx (27) adds a proximal
term to the client cost functions, thereby limiting the impact of local updates by keeping them close to the
global model. (3) FedMA (33) constructs the shared global model in a layer-wise manner by matching and
averaging hidden elements with similar feature extraction signatures. For inference with FL methods, all
novel clients are evaluated using the single global model.
Applying PFL methods to OD-PFL is not straightforward because PFL methods are not designed to
generalize to a novel unlabeled client. They produce a model per training client, but it is not clear how
to use these models for inference over a novel client. We tested three diï¬€erent ways to use PFL for inference
with a novel client: (4) PFL-sampled: Draw a trained client model uniformly at random. We evaluate this
baseline by computing the mean accuracy of all personalized models on each novel client. (5) PFL-nearest:
We used the training client model closest to the novel client. We measure the distance using A-distance (4),
which can be calculated in a FL setup. (6) PFL-Ensemble: (4) and (5) use a model from one of the
training clients as the new client model. Here, we try a stronger baseline that uses all personalized models
for a single novel client, by averaging the logits of all models for each prediction. In practice, this method is
expensive in communication and computation costs. All experiments used pFedHN (29) to produce models
for training clients.
6.3 Results for CIFAR
We evaluate ODPFL-HN using CIFAR10 and CIFAR100 (15) using two protocols that were previously
suggested in the literature.
(1) Pathological split: As proposed by (25), we sort the training samples by their labels and partition
them intoNÂ·Kshards. Then each client is randomly assigned Kof the shards. This results in Nclients
with the same number of training samples and a diï¬€erent distribution over labels. In our experiments, we
useN= 100clients,K= 2for CIFAR10 and K= 5for CIFAR100.
(2) Dirichlet allocation: We follow the procedure by (12) to control the magnitude of the distribution shift
between clients. For each client i, samples are drawn independently with class labels following a categorical
distribution over classes with a parameter qiâˆ¼Dir(Î±). Here,Diris the symmetric Dirichlet distribution.We
conduct three experiments for each of the two datasets with Î±âˆˆ0.1,1,10. Smaller values of alpha imply
larger distribution shifts between clients.
7Under review as submission to TMLR
Table 2:Accuracy on novel unlabeled clients for iNaturalist, Landmarks and Yahoo Answers.
Values are averages and SEMs across novel clients.
iNaturalist Landmarks Yahoo Answers
split Geo-300 Geo-1k User-160k User-1K
FedAvg 36.1Â±1.6 36.9Â±1.1 34.8Â±1.3 27 .6Â±0.1
FedProx 17.4Â±0.8 26.5Â±1.7 13.8Â±1.0 13 .9Â±0.1
FedMA 13.4Â±0.7 17.5Â±0.8 3.80Â±0.4 25 .0Â±0.1
PFL sampled 25.6Â±1.4 27.2Â±0.9 37.4Â±1.3 33 .2Â±0.1
PFL nearest 24.2Â±3.7 26.9Â±4.6 33.1Â±3.6 13 .2Â±0.1
PFL ensemble 31.5Â±1.6 36.6Â±1.2 39.1Â±1.4 33.2Â±0.1
ODPFL-HN 37.5Â±1.7 41.6Â±1.2 41.1Â±1.4 35.8Â±0.2
Implementation details: There are three diï¬€erent models in ODPFL-HN: A target model, an HN, and a
client encoder. Target model: We use a LeNet (17) with two convolutions and two fully connected layers.
To assure a fair comparison, we use the same target model across all evaluated methods and baselines.
Client encoder: For the DS encoder, we use the same architecture as the target model, with an additional
fully connected layer followed by pooling operations over batch dimension. These layers are added after each
convolution layer and before the fully connected layers. For the DSS and the ST encoder we use the public
implementation provided by the authors. Hypernetwork: The HN is a fully connected network, with 3
hidden layers and linear head for each target weight tensor.
Results: Table 1 compares ODPFL-HN to baselines on CIFAR-10 and CIFAR-100. ODPFL-HN performs
better than all baselines in all the evaluated scenarios, except for CIFAR-10 with the Î±= 10split.
6.4 Results for iNaturalist
iNaturalist is a dataset for Natural Species Classiï¬cation based on the iNaturalist 2017 Challenge (11).
The dataset has 1,203 classes. Following (13), we evaluate ODPFL-HN using two geographical splits of
iNaturalist: iNaturalist-Geo-1k with 368 clients, and iNaturalist-Geo-300 with 1,208 clients.
Implementation details: We use a MobileNetV2 (28) pre-trained on ImageNet to extract features for
each image. The extracted feature vectors, of length 1280, are the input for both the target model and the
client encoder. Target model: The target model is a fully connected network with two Dense layers and a
Dropout layer. Client encoder: The client encoder has three fully connected layers with pooling operations
after the ï¬rst layer. HN implementation is the same as in Sec. 6.3.
Results: Table 2 shows ODPFL-HN outperforms current FL methods and adapted PFL methods.
6.5 Results for Landmarks
Landmarksisbasedonthe2019Landmark-RecognitionChallenge(34). Following(13), wedividethedataset
into clients by authorship. The resulting Landmarks-User-160k split contains 1,262 clients with 2,028 classes.
Implementation is as in Sec. 6.4.
Results: Table 2 shows that ODPFL-HN outperforms current FL methods in all evaluations. ODPFL-
HN outperforms the adapted PFL methods with the exception of PFL-ensemble where it ties. However,
PFL-ensemble suï¬€ers from relatively large communication and computation costs compared to the proposed
ODPFL-HN.
6.6 Results for Yahoo Answers
Yahoo Answers is a question classiï¬cation dataset (37), with 1.4 million training samples from 10 classes.
We divide the data into 1000 clients using the Dirichlet allocation procedure with Î±= 10.
8Under review as submission to TMLR
(a) (b)
Figure 3: Distribution shift. (a) Accuracy of novel clients vs. distribution shift between the novel client
and training clients. Shown results for CIFAR-100 across multiple splits to Ntrain = 90train clients and
Nnovel = 10novel clients using symmetric Dirichlet distributions with varying parameter Î±(see Sec. 6.7).
Accuracies of novel clients are reported against the KL-divergence (over label distribution) from the nearest
train client for each method. (b)Test mean accuracy ( Â±S.E.M. over 10 clients) for CIFAR-10 novel clients
corrupted with blur using various size of Gaussian ï¬lters and rotation at various angles.
Implementation details: We used BERT (6) to extract a 768-dimension feature vector for each sample.
For more details, see Section 6.4.
Results: Table 2 shows that ODPFL-HN outperforms current FL methods and adapted PFL methods.
6.7 How distribution shift aï¬€ects generalization
We expect ODPFL-HN generalization to depend on the similarity between the novel client and the training
clients. Novel clients that diï¬€er from training clients may perform poorly compared to clients that are similar
to training clients.
To quantify this eï¬€ect, we generated clients at varying similarity levels by creating new splits of CIFAR-100
using Dirichlet allocation while varying Î±âˆˆ{0.1,0.25,0.5,1,10}. To measure the similarity between a novel
client and all training clients, we computed the empirical label distributions of each client and computed
their KL-divergence from the novel client. Figure 3a presents the accuracy of a novel client as a function
of itsDKLto the nearest train client. As expected, the accuracy decreases as DKLgrows, for all evaluated
methods. ODPFL-HN demonstrates the most moderate decrease, achieving the highest accuracy in large
distribution shifts.
6.8 Robustness to covariate shift
Common benchmarks for PFL assume that diï¬€erent clients have a diï¬€erent distribution of labels. Here, we
conduct an additional experiment to measure the eï¬€ect of covariate shifts between clients. We evaluated
the robustness of ODPFL-HN to a wide range of blur and rotation corruptions, using the CIFAR10 dataset.
We applied the corruptions to the data of the novel client, while the data of training clients was kept
uncorrupted. Figure 3b compares the accuracy for novel clients with varying levels of blur and rotation
corruption. ODPFL-HN consistently out-performs all baselines.
We test ODPFL-HN robustness to covariate shift, by training an FL model on CIFAR10 (pathological split)
and used STL10 as the data of the novel client. ODPFL-HN achieves 43.1%Â±4.1%, much better than
all other baselines: FedProx 35.3%Â±2.7%, FedMA 32.9%Â±2.5%, FedAvg 34.7%Â±4.1%, PFL-sampled
17.6%Â±0.6%, PFL-ensemble 28.1%Â±1.9%and PFL-nearest 31.9%Â±3.8%.
9Under review as submission to TMLR
Figure 4: How much data is needed to achieve diï¬€erential privacy? Test accuracy ( Â±SEM) for CIFAR-10
novel client as a function of datasets size. The blue curve depicts models with privacy level of /epsilon1= 0.3. With
more data, smaller perturbation is needed to achieve a desired level of privacy, as a result, the accuracy rises
when more data is used.
7 Diï¬€erential Privacy
A key aspect of FL is data privacy, since it does not require clients to share their data directly with the hub.
Unfortunately, some private information may be exposed (see a recent survey by 26). In this section, we
analyze the privacy of a novel client and characterize how it can protect its privacy by applying diï¬€erential
privacy (DP) (9). We further study the trade-oï¬€ between the privacy and accuracy of personalized models.
We ï¬rst deï¬ne key concepts and our notation. We use (/epsilon1,Î´)-DP as deï¬ned by (8). Two datasets D,D/primeare
adjacent if they diï¬€er in a single instance.
Deï¬nition 7.1. A randomization mechanism M:Dâ†’Rsatisï¬es a (/epsilon1,Î´)-diï¬€erential privacy if for any two
adjacent inputs d,d/primeâˆˆDand for any subset of outputs SâŠ†Rit holds that Pr[M(d)âˆˆS]â‰¤e/epsilon1Pr[M(d/prime)âˆˆ
S] +Î´.
Here,/epsilon1quantiï¬es privacy loss, where smaller values mean better privacy protection, and Î´bounds the
probability of privacy breach. The sensitivity of a function fis deï¬ned by âˆ†f= maxD,D/prime||f(D)âˆ’f(D/prime)||,
for two datasets DandD/primethat diï¬€er by only one element.
It was shown in (8) that given a model f, data privacy can be preserved by perturbing the output of the
model and calibrating the standard deviation of the perturbation according to the sensitivity of the function
fand the desired level of privacy /epsilon1. Intuitively, if the protected model is not very sensitive to changes in a
single training element, one can achieve DP with smaller perturbations.
Our focus here is to apply DP to a novel client that joins a pre-trained ODPFL-HN model. Fortunately,
since the novel client does not participate in training, the only information that a novel client shares with
the server is the client descriptor. This descriptor is computed locally by the client, so applying DP to the
encoder can protect its data privacy.
Several mechanisms were proposed to achieve DP by adding noise. (8) describes a Gaussian mechanism
that adds noise drawn from a Gaussian distribution with Ïƒ2=2âˆ†f2log(1.25/Î´)
/epsilon12. Our analysis focuses on the
Gaussian mechanism, but the same method can be used with other noise mechanisms.
Let a novel client apply (/epsilon1,Î´)-DP to the encoder using the Gaussian mechanism. The server sends the
encodergto the client. The client then sends to the server g({xi
j}mi
j=1) +Î¾as its embedding, where Î¾is
an IID vector from Gaussian distribution with Ïƒ2=2(âˆ†g)2log(1.25/Î´)
/epsilon12. To do that, the client must know the
sensitivity of the encoder. The following lemma shows that for a DS encoder, we can bound the sensitivity
of the encoder, hence bound the noise magnitude necessary to achieve privacy. See proof in Appendix ??.
10Under review as submission to TMLR
Lemma 2. Letgbe a deep-set encoder, written as: g(D) =Ïˆ(1
|D|/summationtext
xâˆˆDÏ†(x)). IfÏˆis a linear function
with Lipschitz constant LÏˆ, andÏ†is bounded by BÏˆ, then the sensitivity of the encoder is bounded by
âˆ†gâ‰¤2
|D|LÏˆBÏ†.
The lemma shows that the encoder sensitivity decreases linearly with the size of the novel client dataset |D|.
For a given (/epsilon1,Î´), a lower sensitivity allows us to use less noise to achieve the desired privacy. This in turn
means that the client can achieve better performance.
We now empirically evaluate the eï¬€ect of adding Gaussian additive noise to the embedding of a novel client.
To meet the conditions in lemma 2, we normalized the output of Ï†to be on a unit sphere, so BÏ†= 1. In
addition, we average the output of Ï†, soLÏˆ= 1. We usedÎ´= 0.01and compared diï¬€erent values of /epsilon1and
dataset sizes.
Figure 4 shows that with suï¬ƒcient data, a novel client can protect its privacy without compromising its
performance. For example, given a desired privacy of /epsilon1= 0.3, if the client feeds the DP-encoder with 3000
samples, the HN creates a personalized model from a perturbed embedding that is as accurate as a non-DP
model.
8 Conclusion
This paper describes a new real-world FL setup, where a model trained in a FL workï¬‚ow is transferred to
novel clients whose data are not labeled and were not available during training. We describe ODPFL-HN, a
novel approach to OD-PFL, based on an encoder that learns a space of clients and an HN that maps clients
to corresponding models in an â€œon-demand" way. We evaluated ODPFL-HN on ï¬ve benchmark datasets,
showing that it generalizes better than current FL and modiï¬ed PFL methods. We also analyze and bound
the generalization error for a novel client and analyze applying DP for the novel client. We hope that this
paper will encourage the research community to consider generalization to novel clients when designing FL
methods.
References
[1] AbdulRahman, S., Tout, H., Ould-Slimane, H., Mourad, A., Talhi, C., Guizani, M.: A survey on
federated learning: The journey from centralized to distributed on-site learning and beyond. IEEE
Internet of Things Journal 8(7), 5476â€“5497 (2020)
[2] Baxter, J.: A model of inductive bias learning. Journal of artiï¬cial intelligence research 12, 149â€“198
(2000)
[3] Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., Vaughan, J.W.: A theory of learning
from diï¬€erent domains. Machine learning 79(1-2), 151â€“175 (2010)
[4] Ben-David, S., Blitzer, J., Crammer, K., Pereira, F., et al.: Analysis of representations for domain
adaptation. Advances in neural information processing systems 19, 137 (2007)
[5] Blumer, A., Ehrenfeucht, A., Haussler, D., Warmuth, M.K.: Learnability and the vapnik-chervonenkis
dimension. Journal of the ACM (JACM) 36(4), 929â€“965 (1989)
[6] Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT:Pre-trainingofdeepbidirectionaltransformers
for language understanding. In: Proceedings of the 2019 Conference of the North American Chapter
of the Association for Computational Linguistics: Human Language Technologies, Volume 1. pp. 4171â€“
4186. Association for Computational Linguistics, Minneapolis, Minnesota (Jun 2019)
[7] Duan, M., Liu, D., Chen, X., Liu, R., Tan, Y., Liang, L.: Self-balancing federated learning with global
imbalanced data in mobile systems. IEEE Transactions on Parallel and Distributed Systems 32(1),
59â€“71 (2021)
11Under review as submission to TMLR
[8] Dwork, C., Kenthapadi, K., McSherry, F., Mironov, I., Naor, M.: Our data, ourselves: Privacy via
distributed noise generation. In: Annual International Conference on the Theory and Applications of
Cryptographic Techniques. pp. 486â€“503. Springer (2006)
[9] Dwork, C., McSherry, F., Nissim, K., Smith, A.: Calibrating noise to sensitivity in private data analysis.
In: Theory of cryptography conference. pp. 265â€“284. Springer (2006)
[10] El Ouadrhiri, A., Abdelhadi, A.: Diï¬€erential privacy for deep and federated learning: A survey. IEEE
Access10, 22359â€“22380 (2022)
[11] Horn, G.V., Aodha, O.M., Song, Y., Cui, Y., Sun, C., Shepard, A., Adam, H., Perona, P., Belongie, S.J.:
The inaturalist species classiï¬cation and detection dataset. 2018 IEEE/CVF Conference on Computer
Vision and Pattern Recognition pp. 8769â€“8778 (2018)
[12] Hsu, T.M.H., Qi, H., Brown, M.: Measuring the eï¬€ects of non-identical data distribution for federated
visual classiï¬cation. arXiv preprint arXiv:1909.06335 (2019)
[13] Hsu, T.M.H., Qi, H., Brown, M.: Federated visual classiï¬cation with real-world data distribution.
In: Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020,
Proceedings, Part X 16. pp. 76â€“92. Springer (2020)
[14] Kim, Y., Cho, D., Han, K., Panda, P., Hong, S.: Domain adaptation without source data. IEEE
Transactions on Artiï¬cial Intelligence (2021)
[15] Krizhevsky, A., Hinton, G., et al.: Learning multiple layers of features from tiny images. Technical
Report TR-2009, University of Toronto, Toronto. (2009)
[16] Kulkarni, V., Kulkarni, M., Pant, A.: Survey of personalization techniques for federated learning. In:
2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4). pp.
794â€“797. IEEE (2020)
[17] LeCun, Y., Bottou, L., Bengio, Y., Haï¬€ner, P.: Gradient-based learning applied to document recogni-
tion. Proceedings of the IEEE 86(11), 2278â€“2324 (1998)
[18] Lee, J., Lee, Y., Kim, J., Kosiorek, A., Choi, S., Teh, Y.W.: Set transformer: A framework for attention-
based permutation-invariant neural networks. In: International Conference on Machine Learning. pp.
3744â€“3753. PMLR (2019)
[19] Liang, J., Hu, D., Feng, J.: Do we really need to access the source data? source hypothesis transfer for
unsupervised domain adaptation. In: International Conference on Machine Learning. pp. 6028â€“6039.
PMLR (2020)
[20] Lu, N., Wang, Z., Li, X., Niu, G., Dou, Q., Sugiyama, M.: Federated learning from only unlabeled data
with class-conditional-sharing clients. arXiv preprint arXiv:2204.03304 (2022)
[21] Mammen, P.M.: Federated learning: opportunities and challenges. arXiv preprint arXiv:2101.05428
(2021)
[22] Marfoq, O., Neglia, G., Bellet, A., Kameni, L., Vidal, R.: Federated multi-task learning under a mixture
of distributions. Advances in Neural Information Processing Systems 34, 15434â€“15447 (2021)
[23] Marfoq, O., Neglia, G., Vidal, R., Kameni, L.: Personalized federated learning through local memoriza-
tion. In: Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., Sabato, S. (eds.) Proceedings
of the 39th International Conference on Machine Learning. Proceedings of Machine Learning Research,
vol. 162, pp. 15070â€“15092. PMLR (17â€“23 Jul 2022)
[24] Maron,H.,Litany,O.,Chechik,G.,Fetaya,E.: Onlearningsetsofsymmetricelements.In: International
Conference on Machine Learning. pp. 6734â€“6744. PMLR (2020)
12Under review as submission to TMLR
[25] McMahan, B., Moore, E., Ramage, D., Hampson, S., y Arcas, B.A.: Communication-eï¬ƒcient learning of
deep networks from decentralized data. In: Artiï¬cial Intelligence and Statistics. pp. 1273â€“1282. PMLR
(2017)
[26] Mothukuri, V., Parizi, R.M., Pouriyeh, S., Huang, Y., Dehghantanha, A., Srivastava, G.: A survey on
security and privacy of federated learning. Future Generation Computer Systems 115, 619â€“640 (2021)
[27] Sahu, A.K., Li, T., Sanjabi, M., Zaheer, M., Talwalkar, A., Smith, V.: On the convergence of federated
optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127 3, 3 (2018)
[28] Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C.: Mobilenetv2: Inverted residuals and
linear bottlenecks. In: Proceedings of the IEEE conference on computer vision and pattern recognition.
pp. 4510â€“4520 (2018)
[29] Shamsian, A., Navon, A., Fetaya, E., Chechik, G.: Personalized federated learning using hypernetworks.
In: International Conference on Machine Learning. pp. 9489â€“9502. PMLR (2021)
[30] Tan, A.Z., Yu, H., Cui, L., Yang, Q.: Towards personalized federated learning. IEEE Transactions on
Neural Networks and Learning Systems (2022)
[31] Wang, D., Shelhamer, E., Liu, S., Olshausen, B., Darrell, T.: Tent: Fully test-time adaptation by
entropy minimization. arXiv preprint arXiv:2006.10726 (2020)
[32] Wang, H., Kaplan, Z., Niu, D., Li, B.: Optimizing federated learning on non-iid data with reinforcement
learning. In: IEEE INFOCOM 2020-IEEE Conference on Computer Communications. pp. 1698â€“1707.
IEEE (2020)
[33] Wang, H., Yurochkin, M., Sun, Y., Papailiopoulos, D., Khazaeni, Y.: Federated learning with matched
averaging. In: International Conference on Learning Representations (ICLR) (2020)
[34] Weyand, T., Araujo, A., Cao, B., Sim, J.: Google landmarks dataset v2 - a large-scale benchmark
for instance-level recognition and retrieval. In: conference on computer vision and pattern recognition
(2020)
[35] Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola, A.J.: Deep sets.
Advances in neural information processing systems 30(2017)
[36] Zhang, C., Xie, Y., Bai, H., Yu, B., Li, W., Gao, Y.: A survey on federated learning. Knowledge-Based
Systems216, 106775 (2021)
[37] Zhang, X., Zhao, J., LeCun, Y.: Character-level convolutional networks for text classiï¬cation. Advances
in neural information processing systems 28, 649â€“657 (2015)
[38] Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V.: Federated learning with non-iid data. arXiv
preprint arXiv:1806.00582 (2018)
13