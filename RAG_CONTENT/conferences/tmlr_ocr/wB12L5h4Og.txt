Under review as submission to TMLR
Robust Semi-Supervised Metric Learning
Meets with High Dimensionality
Anonymous authors
Paper under double-blind review
Abstract
Classical semi-supervised metric learning usually formulates the objectives via maximiz-
ing/minimizing the ratio formed with must-links and cannot-links. However, the presence
of noise and adversarial attacks can result in incorrect pairings, which will diminish the relia-
bility of learned projection directions. To develop a robust distance metric learning method,
we propose a new objective for distance metric learning using the /lscript2,q-norm ( 0< q < 2)
distances which will alleviate the inï¬‚uence of outliers or adversarial attacks. We develop
an algorithm that will decrease the objective monotonically with updates. Additionally,
we address computational burdens (e.g., O(d3)complexity, where dis the size of features)
by introducing a 2D metric learning algorithm and extending it to arbitrary dimensions
with kernel methods, backed by theoretical guarantees. Extensive empirical evaluations
consistently demonstrate the superiority of our methods across various experimental setups.
1 Introduction
Most clustering/classiï¬cation algorithms rely on deï¬ning a distance metric to assess the similarity between
instances (Kulis et al., 2013; Kaya & Bilge, 2019; Bellet et al., 2013; Yang & Jin, 2006). Applying an
appropriate distance metric that can capture important features from instances is critical to improving per-
formance, as illustrated in Figure 2. While some general metrics are available, they often treat all features
equally, which is inadequate as certain features hold more signiï¬cance than others. Therefore, how to learn
a distance metric that eï¬ƒciently captures the idiosyncrasies of data with good quality has emerged as a
prevalent research focus (Cakir et al., 2019; LÃ³pez-SÃ¡nchez et al., 2019; Karlinsky et al., 2019). Traditional
techniques require explicit class labels and labeled data for classiï¬cation transformations (Goldberger et al.,
2004). However, obtaining precise labels in real-world scenarios is costly and time-consuming, prompting
the development of semi-supervised methods that learn distance metrics with limited supervisory informa-
tion (Hoi et al., 2006). These methods typically assume either a small portion of labeled data or pairwise
constraints between examples. Clearly, the latter type is weaker. Therefore extensive research has been done
to learn distance metrics with pairwise relevance information: must-links and cannot-links (Xiang et al.,
2008). For more comprehensive survey of various metric learning algorithms, we refer our readers to the
classical monograph (Kulis et al., 2013) and references therein.
The goal of this paper is to develop a robust distance metric incorporating pairwise relevance relationships.
Existing metric learning methods, often based on squared Frobenius norm distances, are susceptible to
outliers, features, and adversarial attacks. To address this issue, we propose a robust distance metric
learning objective using the /lscript2,q-norm, oï¬€ering robustness against outliers/attacks for any 0< q < 2.
In addition, existing methods typically vectorize images before optimizing the projection matrix Wvia
eigenvalue decomposition, which becomes computationally demanding for large dimensions, such as 100Ã—100
grayscale images ( d= 10000 ). Additionally, vectorization distorts image structure, leading to reduced
recognition accuracy. Inspired by above, we propose a 2D metric learning algorithm that avoids image
vectorization, utilizing covariance matrices with dimensions rÃ—r, wherer= min{m,n}for eachmÃ—ninput
image. This approach oï¬€ers signiï¬cant computational savings compared to existing methods, as shown in
Figure 1. Besides, inspired by Kernel Principal Component Analysis (SchÃ¶lkopf et al., 1997) and Kernel
Support Vector Machine (Amari & Wu, 1999), we introduce a kernel-based metric learning algorithm to
1Under review as submission to TMLR
â€¦Vectorized input imagesCovariance matrix
pmâ€¦12np x mnp x mp x mn input imagesTraditionalmethod
method2DCovariance matrixppEigenvalueDecompositionO(ğ’‘ğŸ‘ğ’ğŸ‘)
EigenvalueDecompositionO(ğ’‘ğŸ‘)ppppâ€¦+
Figure 1: Upper ï¬‚ow denotes metric learning via traditional methods by vectorizing images, lower ï¬‚ow is
the 2D metric learning method proposed in this paper, the covariance matrix size is signiï¬cantly reduced.
addressnon-linearityinhigher-dimensionalspacesusingkerneltrick. Thismethodensuresthattheprojection
matrix Wsatisï¬es orthonormality constraints, even when obtained implicitly or in inï¬nite dimensions. Our
algorithms do not require explicit class labels; instead, they utilize pairwise relevance relationships in a
semi-supervised manner, and they are designed for minimal computational costs and rapid convergence.
In Section 2, we will formulate the objective for metric learning and discuss its connection with Fisherâ€™s
LDA before introducing a general framework for solving maximizing trace ratio problem. In Section 3, we
discuss a more robust formulation against noise and adversarial samples which widely exist in real world.
Section 4 depicts 2D metric learning which can be naturally extended to higher dimension and Section 5
generalizes into kernel version for metric learning. Section 6 entails convergence analysis, which concludes
our method enjoys superlinear convergence rate and experiments in Section 7 demonstrate the superiority
of our proposed methods over existing counterparts. Our main contributions are summarized as below:
â€¢Propose a robust metric learning formulation and solve it with an eï¬ƒcient algorithm.
â€¢Design novel 2D metric learning along with its robust version which works fast on high dimensional
data, and propose an eï¬ƒcient algorithm which has superlinear convergence rate.
â€¢Discuss and solve kernel version metric learning which goes beyond the linearity assumption.
2 Related Work
2.1 Mahalanobis Distance
HeishappyShe is happyHe is very happyShe is very happyHeisangryShe is angryHe is very angryShe is very angry
Figure 2: An illustration to demonstrate the impor-
tance of metric learning. If we do K-means directly
based on the word-count matrix generated from each
sentence, then it may yield poor results. A good met-
ric learning should be able to learn diï¬€erent weights
for various features. For example, if â€˜happyâ€™ and â€˜an-
gryâ€™ are assigned with signiï¬cantly diï¬€erent weights,
thenK-means can work well on the learned metrics.Assume that we have a set of ndata pointsX=
{xiâˆˆRp}n
i=1and two sets of pairwise constraints
over the data points Xare given under certain ap-
plicationcontext(Xingetal.,2003;Liuetal.,2019)1
/braceleftBigg
S={(xi,xj)|xiandxjare in the same class };
D={(xi,xj)|xiandxjfrom diï¬€erent classes },
(1)
1We note that our model can be easily extended to triplet relationship R={(xi,xj,xl)|xiis more similar to xjthan to xl}
where xiâˆ’xlandxiâˆ’xjcan be conveyed in the numerator and denominator in Eq. (3) respectively.
2Under review as submission to TMLR
where we denote Sas must-links and Das cannot-links. Note that it is not necessary for all the data points
inXto be involved in SorD.
Given any two data points xiandxj, the Mahalanobis distance between them is deï¬ned as:
/bardblxiâˆ’xj/bardblM=/radicalBig
(xiâˆ’xj)TM(xiâˆ’xj), (2)
where MâˆˆRpÃ—pis the Mahalanobis distance metric (Shen et al., 2010; De Maesschalck et al., 2000), a
symmetric matrix of size pÃ—p. In general, Mis a valid metric if and only if Mis a positive semi-deï¬nite
matrix by satisfying the non-negativity and the triangle inequality conditions, i.e.,M/followsequal0. The goal of
robust metric learning is to learn an optimal square matrix Mfrom a collection of data points Xin the
presence of outliers or adversarial attacks, coupled with a set of similar pairwise constraints Sand a set of
dissimilar pairwise constraints D, such that the distances between the data point pairs in Sare as small as
possible, whilst those in Dare as large as possible.
2.2 Metric Learning
Because Mis positive semi-deï¬nite, we can reasonably write M=WWT, where WâˆˆRpÃ—rwith
râ‰¤p. Thus the Mahalanobis distance under the metric Mcan be computed as /bardblxiâˆ’xj/bardblM=/radicalBig
(xiâˆ’xj)TWWT(xiâˆ’xj) =/vextenddouble/vextenddoubleWT(xiâˆ’xj)/vextenddouble/vextenddouble
2, which deï¬nes a transformation y=WTxunder pro-
jection matrix W. Our intuition is data points from diï¬€erent classes after projection are far away while from
same class should be close, therefore we can formulate the objective as:
max
WTW=I/summationtext
(xi,xj)âˆˆD/vextenddouble/vextenddoubleWT(xiâˆ’xj)/vextenddouble/vextenddouble2
2
/summationtext
(xi,xj)âˆˆS/bardblWT(xiâˆ’xj)/bardbl2
2=d/summationtext
i=1/vextenddouble/vextenddoubleWTbi/vextenddouble/vextenddouble2
2
s/summationtext
i=1/bardblWTai/bardbl2
2=/vextenddouble/vextenddoubleWTB/vextenddouble/vextenddouble2
F
/bardblWTA/bardbl2
F=tr/parenleftbig
WTSbW/parenrightbig
tr(WTSwW), (3)
where A= [a1,a2,...,as]âˆˆRpÃ—ssuch that each column of A: (xiâˆ’xj)satisï¬es (xi,xj)âˆˆ
S, and similarly B= [b1,b2,...,bd]âˆˆRpÃ—dsuch that each column of B: (xiâˆ’xj)satisï¬es
(xi,xj)âˆˆ D.Sw=/summationtext
(xi,xj)âˆˆS(xiâˆ’xj) (xiâˆ’xj)Tis the covariance matrix of must-links and Sb=
/summationtext
(xi,xj)âˆˆD(xiâˆ’xj) (xiâˆ’xj)Tdenotes covariance of cannot-links. For the sake of brevity, we denote |S|=s
and|D|=d. In the above objective, the numerator term measures the scatteredness of diï¬€erent classes, while
the denominator term denotes the compactness of the same class. Orthogonality constraint is to prevent
degenerate solution(Xiang et al., 2008).
2.3 Connection with Fisherâ€™s Linear Discriminant Analysis
It is easy to notice that the above equation has the same objective as Fisherâ€™s Linear Discriminant Analysis
wheretheonlydiï¬€erenceistheexistenceoforthonormalityconstrainton Winourformulation. Byobserving
the independence of each column of W, we can reformulate Eq. (3) as :
max
wi/summationdisplay
i=1wT
iSbwi, s.t.wT
iSwwi= 1,âˆ€iâˆˆ[r]. (4)
By making use of Lagrangian Multipliers, we obtain Sbwi=Î»iSwwiandmax
wi/summationtext
i=1wT
iSbwi= max/summationtext
i=1Î»i.
If we assume Swis invertible and the projection is along diï¬€erent directions, then to obtain optimal W,
it is equivalent to solve Sâˆ’1
wSbwi=Î»iwiand ï¬nd the top reigenvalues of Sâˆ’1
wSband the corresponding
eigenvectors. However, the main drawback of Fisherâ€™s LDA is as Sâˆ’1
wSbis not necessarily symmetric, each
column of optimal Wis generally non-orthogonal to each other, which means the new coordinate system
formed by W, has non-orthogonal axes. The reason to prefer orthogonal coordinates instead of general
curvilinear coordinates is simplicity: many complications arise when coordinates are not orthogonal. Our
experiments in Figure 4 demonstrate that the orthonormal constraint is nontrivial as it can not only obtain
better objective, but also the classiï¬cation accuracy is higher as it can avoid ill-conditioned coordinate base.
We refer our readers to Daubechies (1993); Ninness et al. (1999) and references therein.
3Under review as submission to TMLR
w1w2xw1w2w3WTx
(a) Projection as WTx.
w1w2w3w1w2w3 (b) Non-orthogoanl Axes.
w1w2w3w1w2w3 (c) Orthogonal Axes.
Figure 3: When/bardblwi/bardbl2= 1,WTxis the projection in new axes system formed by columns of W. Speciï¬cally,
wT
ixdetermines the position in i-th axis. In Fisherâ€™s LDA formulation, each wiis not orthogonal to others.
In contrast, the orthonormality constraint ensures the new coordinate follows Cartesian system.
Algorithm 1 The algorithm to solve the problem (5).
Initialization: vâˆˆC
repeat
CalculateÎ»=f(v)
g(v)
Updatevby solving the following problem:
v= arg max
vâˆˆCf(v)âˆ’Î»g(v) (6)
untilconvergence
2.4 An Optimization Framework
The objective formulation above is inherently nonconvex due to the nonconvex nature of orthogonality
constraint imposed on W. In response to this challenge, we propose to address the problem eï¬€ectively with
an iterative algorithm. We ï¬rst introduce a framework for maximization problem (Wang et al., 2014):
max
vâˆˆCf(v)
g(v),whereg(v)>0 (âˆ€vâˆˆC). (5)
The optimization procedure is described in Algorithm 1. The set Cin our metric learning problem is Stiefel
manifoldSt(p,r)deï¬ned as{W:WâˆˆRpÃ—r,WTW=Ir}. Several theorems are now in order.
Theorem 2.1. By updating as Algorithm 1, the objective in (5) is monotonically non-decreasing.
Proof.By deï¬nition v+= arg max vâˆˆCf(v)âˆ’Î»g(v), we have: f(v+)âˆ’Î»g(v+)â‰¥f(v)âˆ’Î»g(v) = 0. Since
g(v)â‰¥0, thereforef(v+)âˆ’Î»g(v+)â‰¥0 =â‡’Î»+=f(v+)
g(v+)â‰¥f(v)
g(v)=Î».
Theorem 2.2. If the updated vin Algorithm 1 is a stationary point of problem (6), the converged solution
in Algorithm 1 is a stationary point of problem (5).
Proof.Suppose the converged solution in Algorithm 1 is vâˆ—. Ifvâˆ—is a stationary point of problem (6),
f/prime(vâˆ—)âˆ’f(vâˆ—)
g(vâˆ—)g/prime(vâˆ—) = 0â‡’f/prime(vâˆ—)g(vâˆ—) =f(vâˆ—)g/prime(vâˆ—). (7)
On the other hand, if vâˆ—is a critical point of problem (5), then
(f(v)
g(v))/prime|v=vâˆ—= 0â‡’f/prime(vâˆ—)g(vâˆ—)âˆ’f(vâˆ—)g/prime(vâˆ—)
g2(vâˆ—)= 0. (8)
Apparently, Eq. (7) is equivalent to (8) given the fact that g(v)>0, which completes the proof.
4Under review as submission to TMLR
1 1.5 2 2.5 3 3.5 4
iteration125130135140145150155160ObjectiveOur algorithm, with orthonormal constraint
LDA, no orthonormal constraint
(a) Objective comparison in Eq. 3.
k = 1 k = 3 k = 5 k = 70.60.70.80.91Accuracy, ORLOrthonormal
Not orthonormal (b) Accuracy on ORL dataset.
k = 1k = 3k = 5k = 7k = 90.60.70.80.91Accuracy, headpose
Orthonormal
Not orthonormal (c) Accuracy on Headpose dataset.
Figure 4: Experiments show that the orthonormality constraint can not only obtain better objective
(Fig. 4(a)), but also improve classiï¬cation results on real-world datasets (Fig. 4(b)â€“Fig. 4(c)).
3 Robust Metric Learning
3.1 Problem Formulation
Eq. (3) quantiï¬es the ratio between squared /lscript2-norm distances of pairs within must-links and cannot-links.
Like other least square minimization models in machine learning and statistics, it is sensitive to outliers.
Recent progress (Baccini et al., 1996; Gao, 2008; Ke & Kanade, 2004; Ding et al., 2006; Kwak, 2008; Wright
etal.,2009)hasshownthatthe /lscript1-normor/lscript2,1-normdistancecanpromoterobustnessagainstoutliersamples
or features, which have been widely applied to replace the squared /lscript2-norm distance in many traditional
machine learning methods, such as /lscript2,q-norm PCA (Wang et al., 2018). Inspired by the methods described
above, we propose a general robust metric learning formulation based on Eq. (3) as:
max
WTW=I/summationtext
(xi,xj)âˆˆS/vextenddouble/vextenddoubleWT(xiâˆ’xj)/vextenddouble/vextenddoubleq
2/summationtext
(xi,xj)âˆˆD/bardblWT(xiâˆ’xj)/bardblq
2=/summationtexts
i=1/vextenddouble/vextenddoubleWTai/vextenddouble/vextenddoubleq
2/summationtextd
i=1/bardblWTbi/bardblq
2=/bardblATW/bardbl2,q
/bardblBTW/bardbl2,q, (9)
where 0<q< 22and/bardblZ/bardbl2,q=/summationtext
i/bardblZ(i,:)/bardblq
2.
The above objective is obviously more challenging than Eq. 3 given the fact q/negationslash= 2. As we will discuss later,
we will propose a more generalized algorithm in which vanilla metric learning where q= 2is a special case.
3.2 Algorithm to Solve Eq. (6)
In this subsection, we are to develop an algorithm to obtain the optimal solution of Win the following
problem:
max
WTW=I/bardblATW/bardbl2,qâˆ’Î»/bardblBTW/bardbl2,q, (10)
which is equivalent to:
min
WTW=IÎ»/bardblBTW/bardbl2,qâˆ’/bardblATW/bardbl2,q. (11)
We start with a lemma that will be the foundation for analysis:
Lemma 3.1.âˆ‡W/bardblATW/bardbl2,1=ADATW, where Dis a diagonal matrix with D(i,i) =1
/bardblaT
iW/bardbl.
Proof of Lemma 3.1.
âˆ‡W/bardblATW/bardbl2,1=/summationdisplay
iâˆ‡W/bardblaT
iW/bardbl=/summationdisplay
iai1
/bardblaT
iW/bardblaT
iW=/summationdisplay
iaiD(i,i)aT
iW= (/summationdisplay
iaiD(i,i)aT
i)W=ADATW,
(12)
2Note our algorithm also works for qâ‰¥2or evenqâ‰¤0, but that makes less sense as our goal is to make the model robust
to outliers, therefore q> 2will make it more sensitive to noise.
5Under review as submission to TMLR
where the ï¬rst equation comes from the deï¬nition of the /lscript2,q-norm for matrices, the second equation comes
from the fact that âˆ‡x/bardblx/bardbl=x
/bardblx/bardbl.
Based upon the lemma, we turn to study the /lscript2,q-norm case:
Lemma 3.2.âˆ‡W/bardblATW/bardbl2,q=ADATW, where Dis a diagonal matrix with D(i,i) =q/bardblaT
iW/bardblqâˆ’2.
Proof of Lemma 3.2.
âˆ‡W/bardblATW/bardbl2,q=/summationdisplay
iâˆ‡W/bardblaT
iW/bardblq=/summationdisplay
iq/bardblaT
iW/bardblqâˆ’1âˆ‡W/bardblaT
iW/bardbl
=/summationdisplay
iq/bardblaT
iW/bardblqâˆ’1ai1
/bardblaT
iW/bardblaT
iW=/summationdisplay
iaiD(i,i)aT
iW
=(/summationdisplay
iaiD(i,i)aT
i)W=ADATW,(13)
where the ï¬rst equation comes from the deï¬nition of matrix /lscript2,q-norm, the second equation comes from the
fact thatâˆ‡xyq=qyqâˆ’1âˆ‡xyand the second line is directly from Lemma 3.1. One can see if q= 2, then the
gradient becomes 2AATWwhich is in accordance with the vanilla squared Frobenius norm case. Therefore,
our formulation is a more general case of traditional metric learning.
Denotef(W) =Î»/bardblBTW/bardbl2,qâˆ’/bardblATW/bardbl2,q, thenâˆ‡f(W) =Î»BDBBTWâˆ’ADAATW.
3.3 Algorithm to Solve Eq. (11) with Retraction
0 510 15 20 25 30 35 40 45 50
iteration1.241.251.261.271.281.291.31.311.321.33ObjectiveRobust metric learning with retraction
Figure 5: Objective update on syn-
thetic data demonstrates our retrac-
tion algorithm can make the objective
monotonically decreasing, which vali-
dates our theoretical analysis.Given the ï¬rst order (gradient) information of the objective, it is not
surprising to use projected gradient descent method where as long as
we can ï¬nd an appropriate stepsize, we can guarantee the objective
will be monotonically decreasing. Meanwhile, the orthonormality
constraint is nonconvex, which inspires us to propose a backtracking
line search style algorithm. For sake of further analysis, we start
with the following deï¬nition:
Deï¬nition 3.3. A retraction on a diï¬€erentiable manifold Cis a
smooth mapping Retrfrom the agent space of C:TC, ontoCsatisfy-
ing the following two conditions, Retr XCdenotes the restriction of
RetrontoTXC: 1.Retr X(0) = X,âˆ€XâˆˆC; 2. For any XâˆˆC
andÎ´âˆˆTXC, it holds that limÎ´â†’0/bardblRetrX(Î´)âˆ’(X+Î´)/bardblF
/bardblÎ´/bardblF= 0.
For the Stiefel manifold St(p,r), common retractions include the
polar decomposition Retrpolar
X(Î´) = (X+Î´)(I+Î´TÎ´)âˆ’1/2, the QR
decomposition RetrQR
X(Î´) =qf(X+Î´), whereqf(X)is the Q factor of the QR factorization of X. For a
matrix WâˆˆRpÃ—rwithrâ‰¤p, the total cost of computing the orthogonal projection is 8pr2+O(r3)ï¬‚ops,
while if W=X+Î´andÎ´âˆˆTXCthen the polar decomposition takes only 3pr2+O(r3)ï¬‚ops and the
QR decomposition takes only 2pr2+O(r3). So if we can get a Î´âˆˆTXCeï¬ƒciently, we can utilize cheaper
retraction operation rather than the expensive projection via singular value decomposition.
Based on the proximal gradient method described in Algorithm 2, in order to leverage retractions to handle
the Stiefel manifold constraint, we need to ï¬nd a descent direction in the tangent space TWkC, which is
formulated as:
Vk=argmin
V/angbracketleftgradf(Wk),V/angbracketright+1
2t/bardblV/bardbl2
F,s.t.VâˆˆTWkC, (14)
where grad fdenotes the Riemannian gradient of f. And using the fact that for VâˆˆTWkCwe have
/angbracketleftgradf(Wk),V/angbracketright=/angbracketleftâˆ‡f(Wk),V/angbracketright, we can simply solve the descent direction Vwithout computing the
6Under review as submission to TMLR
Algorithm 2 Robust metric learning algorithm to solve Eq. (11) with retractions.
Input:/epsilon1,0<Î³ < 1.
Initialization: t.
repeat
Obtain Vkby Eq. (18)
SetÎ±= 1
Whilef(Retr Wk(Î±Vk))>f(Wk)âˆ’Î±/bardblVk/bardbl2
F
2t
Î±=Î³Î±
End While
Wk+1=Retr Wk(Î±Vk)
untilsatisfying stopping criterion /bardblVk/bardblFâ‰¤/epsilon1
L
Riemannian gradient grad f:
Vk=argminl (V) =argmin
V/angbracketleftâˆ‡f(Wk),V/angbracketright+1
2t/bardblV/bardbl2
F,s.t.VâˆˆTWkC. (15)
With the deï¬nition of the tangent space to C=St(p,r)beingTWC={V|VTW+WTV= 0}, we can
obtain Vby checking the Karushâ€“Kuhnâ€“Tucker (KKT) conditions for the following Lagrangian function
with a Lagrange multiplier Î“:
minL(V,Î“) =/angbracketleftâˆ‡f(Wk),V/angbracketright+1
2t/bardblV/bardbl2
Fâˆ’/angbracketleftVTW+WTV,Î“/angbracketright. (16)
The KKT conditions are
0âˆˆâˆ‚VL(V,Î“),VTW+WTV= 0, (17)
and we can obtain the following closed-form solution for Vkassociated with Wk:
Vk=t((Wkâˆ‡f(W)TWk+WkWT
kâˆ‡f(Wk))
2/bardblWk/bardbl2
Fâˆ’âˆ‡f(Wk)). (18)
We summarize the procedure by using retractions with a line search in Algorithm 2.
Here we also show the convergence properties of Algorithm 2, we present the following facts about retrac-
tions (Boumal et al., 2019) that will be leveraged in the later analysis:
Lemma 3.4. LetCbe a compact embedded submanifold of the Euclidean space, for all XâˆˆCandÎ´âˆˆTXC,
there exist constants C1>0andC2>0such that the following two inequalities hold:
/bardblRetr X(Î´)âˆ’X/bardblFâ‰¤C1/bardblÎ´/bardblF,/bardblRetr X(Î´)âˆ’(X+Î´)/bardblFâ‰¤C2/bardblÎ´/bardbl2
F. (19)
First, we want to show that we can get a descent direction VinTWkCby solving Eq. (18).
Lemma 3.5. Withl(V)being the objective in Eq. (15), for any Î±âˆˆ[0,1], we have
l(Î±Vk)âˆ’l(0)â‰¤Î±2âˆ’2Î±
2t/bardblVk/bardbl2
F. (20)
Proof.lis1
t-strongly convex, then
l(V1)â‰¥l(V2) +/angbracketleftâˆ‡l(V2),V1âˆ’V2/angbracketright+1
2/bardblV1âˆ’V2/bardbl2
F, (21)
and when V1,V2âˆˆTWkC, we have/angbracketleftâˆ‡l(V2),V1âˆ’V2/angbracketright=/angbracketleftProjTWkCâˆ‡l(V2),V1âˆ’V2/angbracketright, and 0âˆˆ
ProjTWkCâˆ‡l(V2)based on the optimality condition. Then, let V1= 0,V2=Vkin Eq. (21), we have
l(0)â‰¥l(Vk) +1
2t/bardblVk/bardbl2
F=/angbracketleftâˆ‡f(Wk),Vk/angbracketright+1
t/bardblVk/bardbl2
F, (22)
therefore, we have l(Î±Vk)âˆ’l(0) =/angbracketleftâˆ‡f(Wk),Î±Vk/angbracketright+1
2t/bardblÎ±Vk/bardbl2
Fâ‰¤Î±2âˆ’2Î±
2t/bardblVk/bardbl2
F.
7Under review as submission to TMLR
We now show that the objective sequence {f(Wk)}is monotonically decreasing in Algorithm 2:
Lemma 3.6. For anyt >0, there exists a constant Â¯Î± > 0such that for any 0< Î±â‰¤min{1,Â¯Î±}, the
inequality in the line search procedure, i.e. f(Retr Wk(Î±Vk))> f(Wk)âˆ’Î±/bardblVk/bardbl2
F
2t, is satisï¬ed, and the
objective sequence {f(Wk)}generated by Algorithm 2 satisï¬es
f(Wk+1)âˆ’f(Wk)â‰¤âˆ’Î±/bardblVk/bardbl2
F
2t. (23)
Proof.With Lemma 3.4, let W+
k=Wk+Î±Vk, then for any Î±>0we have
f(Retr Wk(Î±Vk))âˆ’f(Wk)â‰¤/angbracketleftâˆ‡f(Wk),Retr Wk(Î±Vk)âˆ’Wk/angbracketright+L
2/bardblRetr Wk(Î±Vk)âˆ’Wk/bardbl2
F
â‰¤C2/bardblâˆ‡f(Wk)/bardblF/bardblÎ±Vk/bardbl2
F+Î±/angbracketleftâˆ‡f(Wk),Vk/angbracketright+LC2
1
2/bardblÎ±Vk/bardbl2
F.(24)
Sinceâˆ‡fis continuous onC, we can safely say /bardblâˆ‡f(W)/bardblFis upper bounded by a constant number G> 0,
thus letc0=C2G+LC2
1
2, we can get
f(Retr Wk(Î±Vk))âˆ’f(Wk)â‰¤Î±/angbracketleftâˆ‡f(Wk),Vk/angbracketright+c0Î±2/bardblVk/bardbl2
F
=c0Î±2/bardblVk/bardbl2
F+l(Î±Vk)âˆ’1
2t/bardblÎ±Vk/bardbl2
Fâˆ’l(0)
â‰¤c0Î±2/bardblVk/bardbl2
Fâˆ’1
2t/bardblÎ±Vk/bardbl2
F+Î±2
2t/bardblVk/bardbl2
Fâˆ’Î±
t/bardblVk/bardbl2
F
= (c0âˆ’1
Î±t)/bardblÎ±Vk/bardbl2
F,(25)
wherel(V)is deï¬ned in Eq. (15) and the second inequality comes from Lemma 3.5. By setting Â¯Î±=1
2tc0, we
guarantee that for 0<Î±â‰¤min{1,Â¯Î±},f(Retr Wk(Î±Vk))âˆ’f(Wk)â‰¤âˆ’Î±
2t/bardblVk/bardbl2
F.
Deï¬nition 3.7. Wkis an/epsilon1-stationary point of g(W)if/bardblVk/bardblFâ‰¤/epsilon1
L.
Theorem 3.8. Algorithm 2 will return an /epsilon1-stationary point in O(1
/epsilon12)iterations.
Proof.Suppose Algorithm 2 doesnâ€™t terminate until the Kthiteration, which means
/bardblVk/bardblF>/epsilon1
L,âˆ€k= 0,1,...,Kâˆ’1, (26)
and letÎ±kdenote the actual Î±in thekthiteration, and we have Î±kâ‰¥Î³Â¯Î±from Lemma 3.6, we have
f(W0)âˆ’fâˆ—â‰¥f(W0)âˆ’f(WK)â‰¥Kâˆ’1/summationdisplay
k=0Î±k
2t/bardblVk/bardbl2
F=t
2Kâˆ’1/summationdisplay
k=0Î±k/bardblVk
t/bardbl2
F>t/epsilon12
2Kâˆ’1/summationdisplay
k=0Î±kâ‰¥Kt/epsilon12
2Î³Â¯Î±,(27)
which implies that the number of iterations needed to obtain an /epsilon1-stationary point in Algorithm 2 is O(1
/epsilon12).
4 2D Metric Learning
For a 2D dataset X={xiâˆˆRpÃ—m}n
i=1(e.g., grayscale images) and given relevance relationships between
certain pairs, we group paired data into SorD. Unlike conventional metric learning, our 2D metric learning
algorithm operates directly on 2D matrices instead of 1D vectors, eliminating the need to transform image
data (Zhang & Zhou, 2005; Li & Yuan, 2005). This allows us to construct image covariance matrices directly
from the original matrices, resulting in signiï¬cantly reduced covariance matrix sizes, as shown in Fig. 1.
8Under review as submission to TMLR
4.1 Problem Formulation
Given any two 2D data points xiandxj, its Mahalanobis distance between them can be naturally given by:
/bardblxiâˆ’xj/bardbl2
M=tr/braceleftBig
(xiâˆ’xj)TM(xiâˆ’xj)/bracerightBig
=/bardblWT(xiâˆ’xj)/bardbl2
F, (28)
where M=WWTâˆˆRpÃ—p.
Similar to the practices in traditional metric learning methods, suppose we are given a set of paired data
instances inD, along with some paired samples from Sdeï¬ned in Eq. (1), without loss of generality, we
denote{D1,D2,...,Dd}where Dk=xk
iâˆ’xk
jâˆˆRpÃ—mis the diï¬€erence between paired samples taken from
setD. Similarly, we can denote {S1,S2,...,Ss}where Sk=xk
iâˆ’xk
jfrom setS. By following the idea
of Fisherâ€™s LDA (Fisher, 1936), the projection matrix Wwill make the distance within the same class as
small as possible while setting the distance between diï¬€erent classes as large as possible, therefore we can
formulate the 2D metric learning objective as:
max
WTW=I/summationtext
(xi,xj)âˆˆD/vextenddouble/vextenddoubleWT(xiâˆ’xj)/vextenddouble/vextenddouble2
F
/summationtext
(xi,xj)âˆˆS/bardblWT(xiâˆ’xj)/bardbl2
F=d/summationtext
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddouble2
F
s/summationtext
i=1/bardblWTSi/bardbl2
F, (29)
It is obvious that the denominator in Eq. (29) is nonnegative, therefore we could use the general framework
in Algorithm 1 to optimize Win Eq. (29) withCcorresponding to the orthonormal constraint on W.
Following Algorithm 1, now we turn to optimize max
WTW=If(W)âˆ’Î»g(W). By Eq. (29) we have:
f(W) =d/summationdisplay
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddouble2
F=d/summationdisplay
i=1tr/parenleftbig
WTDiDT
iW/parenrightbig
=tr/parenleftbig
WTSbW/parenrightbig
, (30)
where Sb=D1DT
1+D2DT
2+Â·Â·Â·+DdDT
ddenotes the covariance matrix of data pairs from diï¬€erent
clusters. Similarly, we can get g(W) =/summationtexts
i=1/vextenddouble/vextenddoubleWTSi/vextenddouble/vextenddouble2
F=/summationtexts
i=1tr/parenleftbig
WTSiST
iW/parenrightbig
=tr/parenleftbig
WTSwW/parenrightbig
,with
Sw=S1ST
1+S2ST
2+Â·Â·Â·+SsST
sdenotes the covariance matrix from the same clusters.
The optimization problem now is in the following form:
max
Wtr/parenleftbig
WTSbW/parenrightbig
âˆ’Î»tr/parenleftbig
WTSwW/parenrightbig
=tr/braceleftbig
WT(Sbâˆ’Î»Sw)W/bracerightbig
, (31)
with constraint WTW=IrÃ—r. Though the constraint is nonconvex, still there is a closed solution for W
by noticing the fact that Sbâˆ’Î»Swis symmetric, which can be obtained by doing eigenvalue decomposition
toSbâˆ’Î»SwâˆˆRpÃ—pand pick the reigenvectors corresponding to the largest reigenvalues. The constraint
WTW=IrÃ—ris automatically satisï¬ed due to the property of symmetric matrix eigenvalue decomposition.
Algorithm 3 2D metric learning algorithm.
Input:{D1,...,Dd},{S1,...,Ss},Sw,Sbandr.
Initialization: W
repeat
CalculateÎ»=tr(WTSbW)
tr(WTSwW);
[U,V] =eig(Sbâˆ’Î»Sw,/primedescent/prime);
W+=UVT;
untilconvergence
9Under review as submission to TMLR
Algorithm 4 Robust 2D metric learning algorithm.
Input:{D1,...,Dd},{S1,...,Ss}andr.
Initialization: W
repeat
CalculateÎ»=tr(WTSbW)
tr(WTSwW)
repeat
Calculate Sb,Swaccording to Eq. (34);
[U,V] =eig(Sbâˆ’Î»Sw,â€˜descent/prime);
W+=UVT;
untilconvergence
untilconvergence
Regarding the analysis of complexity, for the sake of simplicity, we assume the image dimension to be nÃ—n.
Traditional metric learning methods vectorize an image to a vector of size n2, so the covariance matrix size
isn2Ã—n2. Generally speaking, the complexity of eigenvalue decomposition is O(p3)given matrix size pÃ—p.
Therefore, the time complexity of 2D metric learning proposed by this paper is O(n3)while traditional is
O(n6), which is a huge improvement, especially when nis considerably large. Assume there are Kloops to
updateÎ»in Algorithm 1, then the whole complexity is O(Kâˆ—n3)since the most signiï¬cant consumption in
the algorithm comes from eigenvalue decomposition.
4.2 Robust 2D Metric Learning
The same robust strategy in Section 3 can be applied to 2D metric learning as well:
max
WTW=I/summationtext
(xi,xj)âˆˆD/vextenddouble/vextenddoubleWT(xiâˆ’xj)/vextenddouble/vextenddoubleq
F
/summationtext
(xi,xj)âˆˆS/bardblWT(xiâˆ’xj)/bardblq
F=d/summationtext
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddoubleq
F
s/summationtext
i=1/bardblWTSi/bardblq
F, (32)
where 0<q< 2. Following earlier analysis, we turn to optimize:
max
WTW=Id/summationdisplay
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddoubleq
Fâˆ’Î»s/summationdisplay
i=1/vextenddouble/vextenddoubleWTSi/vextenddouble/vextenddoubleq
F. (33)
The robust 2D metric learning problem can be addressed using a very similar approach to vanilla 2D. By
denotingf(W) =d/summationtext
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddoubleq
Fâˆ’Î»s/summationtext
i=1/vextenddouble/vextenddoubleWTSi/vextenddouble/vextenddoubleq
F, thenâˆ‡f(W) =q(Sbâˆ’Î»Sw)W, where we deï¬ne:
Sw=S1ST
1
/bardblWTS1/bardbl2âˆ’q
F+Â·Â·Â·+SsST
s
/bardblWTSs/bardbl2âˆ’q
F,Sb=D1DT
1
/bardblWTD1/bardbl2âˆ’q
F+Â·Â·Â·+DdDT
d
/bardblWTDd/bardbl2âˆ’q
F. (34)
Algorithm 4 is slightly diï¬€erent from Algorithm 3 in terms an inner loop to ensure WandSw,Sbconverge.
5 Kernel Version Metric Learning
While the preceding sections oï¬€er methodologies for 1D and 2D data, itâ€™s important to acknowledge that in
real-world scenarios, a substantial volume of data exists in high-dimensional spaces. Rather than transform-
ing the tensor data into 2D or 1D formats, we present a versatile approach to address such data by leveraging
the Kernel trick, which has demonstrated substantial promising performance, particularly when the data in
the original space ( Rd) may not be well separable but can be eï¬€ectively separated by projecting it into a
higher-dimensional space. ( Rn) via Î¦(xi)where Î¦ :Rdâ†’Rn(Liu et al., 2008; Leslie et al., 2001; Patle &
Chouhan, 2013; Ye et al., 2009; Cai et al., 2011). Assume we are given {D1,D2,...,Dd},{S1,S2,...,Ss},
10Under review as submission to TMLR
where Di,SiâˆˆRp. Diï¬€erent from existing methods, the kernel method bypasses the explicit computation
of eigenvalues, while it provides the eï¬ƒcient calculation of eigenvalues through the kernel trick instead. To
the best of our knowledge, kernel metric learning in the form of min-max ratio optimization has not been
previously explored in the literature.
5.1 Problem Formulation
Same as before, we formulate the kernel version objective as:
max
WTW=I/summationtext
(xi,xj)âˆˆD/vextenddouble/vextenddoubleWTÎ¦ (xiâˆ’xj)/vextenddouble/vextenddouble2
2
/summationtext
(xi,xj)âˆˆS/bardblWTÎ¦ (xiâˆ’xj)/bardbl2
2=d/summationtext
i=1/vextenddouble/vextenddoubleWTÎ¦(Di)/vextenddouble/vextenddouble2
2
s/summationtext
i=1/bardblWTÎ¦(Si)/bardbl2
2=/vextenddouble/vextenddoubleWTÎ¦(D)/vextenddouble/vextenddouble2
F
/bardblWTÎ¦(S)/bardbl2
F. (35)
Similar to the steps in the 2D version, we can ï¬rst initialize Î»followed by optimizing:
max
WTW=Itr/parenleftbig
WTÎ¦(D)Î¦T(D)W/parenrightbig
âˆ’Î»tr/parenleftbig
WTÎ¦(S)Î¦T(S)W/parenrightbig
=tr/braceleftbig
WT(Î¦(D)Î¦T(D)âˆ’Î»Î¦(S)Î¦T(S))W/bracerightbig
.
(36)
By observing that Î¦(D)Î¦T(D)âˆ’Î»Î¦(S)Î¦T(S)is symmetric, we can transfer it into ï¬nding the reigenvectors
corresponds to the top rlargest eigenvalue of Î¦(D)Î¦T(D)âˆ’Î»Î¦(S)Î¦T(S). If we denote an eigenvector as v,
and its corresponding eigenvalue as Î¸, we have:
(Î¦(D)Î¦T(D)âˆ’Î»Î¦(S)Î¦T(S))v=Î¸v
â‡”(d/summationdisplay
i=1Î¦(Di)Î¦T(Di)âˆ’Î»s/summationdisplay
i=1Î¦(Si)Î¦T(Si))v=Î¸v
â‡”d/summationdisplay
i=1Î¦(Di)/angbracketleftÎ¦T(Di),v/angbracketright/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
scalarâˆ’Î»s/summationdisplay
i=1Î¦(Si)/angbracketleftÎ¦T(Si),v/angbracketright/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
scalar=Î¸v,(37)
we see that vis a linear combination of Î¦(Di)andÎ¦(Si), therefore we have:
v= [Î¦(D),Î¦(S)]/bracketleftbiggÎ±d
Î±s/bracketrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Î±, (38)
whereÎ±âˆˆRd+s. Now plug Eq. (38) in Eq. (37) we have:
(Î¦(D)Î¦T(D)âˆ’Î»Î¦(S)Î¦T(S))[Î¦(D),Î¦(S)]Î±=Î¸[Î¦(D),Î¦(S)]Î±, (39)
which is equivalent to:
[Î¦(D)KDDâˆ’Î»Î¦(S)KSD,Î¦(D)KDSâˆ’Î»Î¦(S)KSS]Î±=Î¸[Î¦(D),Î¦(S)]Î±. (40)
By multiplying [Î¦(D),Î¦(S)]Tto both sides of the above equation:
/bracketleftbiggKDDKDDâˆ’Î»KDSKSDKDDKDSâˆ’Î»KDSKSS
KSDKDDâˆ’Î»KSSKSDKSDKDSâˆ’Î»KSSKSS/bracketrightbigg
Î±=Î¸/bracketleftbiggKDDKDS
KSDKSS/bracketrightbigg
Î±, (41)
therefore,Î¸andÎ±are the eigenvalue and eigenvector of
/bracketleftbigg
KDDKDS
KSDKSS/bracketrightbiggâˆ’1/bracketleftbiggKDDKDDâˆ’Î»KDSKSDKDDKDSâˆ’Î»KDSKSS
KSDKDDâˆ’Î»KSSKSD KSDKDSâˆ’Î»KSSKSS/bracketrightbigg
, (42)
where KDD= Î¦(D)TÎ¦(D),KDS= Î¦(D)TÎ¦(S),KSD= Î¦(S)TÎ¦(D),KSS= Î¦(S)TÎ¦(S)3.
3Clearly,/bracketleftBigKDD KDS
KSD KSS/bracketrightBig
is a Kernel matrix, therefore it is SPD. To avoid the singular case, in practice, we can take its
inversion as/braceleftBig/bracketleftBigKDD KDS
KSD KSS/bracketrightBig
+/epsilon1I/bracerightBigâˆ’1
, where/epsilon1is a very small positive scalar.
11Under review as submission to TMLR
Algorithm 5 Kernel metric learning algorithm.
Input:{D1,...,Dd},{S1,...,Ss},rand calculate KDD,KDS,KSDandKSSaccordingly.
Initialization: Î»
repeat
Obtain eigenvalue Î¸and eigenvector Î±via Eq. (41);
CalculateÎ»as Eq. (43);
untilconvergence
It is worth noting that we do the eigenvalue decomposition based on the above matrix with dimension
(s+d)Ã—(s+d)instead of high dimension n, and itâ€™s computationally eï¬ƒcient to get eigenvectors G=
[Î±1,...,Î±r]corresponding to the largest rlargest eigenvalues Î¸. After we obtain GâˆˆR(s+d)Ã—rcomposed of
the ï¬rstreigenvectors, according to Eq. (38), we obtain the projection matrix Was[Î¦(D),Î¦(S)]G. And
therefore:
Î»=/vextenddouble/vextenddoubleWTÎ¦(D)/vextenddouble/vextenddouble2
F
/bardblWTÎ¦(S)/bardbl2
F=tr/parenleftbig
GT[Î¦(D),Î¦(S)]TÎ¦(D)Î¦T(D)[Î¦(D),Î¦(S)]G/parenrightbig
tr(GT[Î¦(D),Î¦(S)]TÎ¦(S)Î¦T(S)[Î¦(D),Î¦(S)]G)=tr/braceleftbigg
GT/bracketleftbigg
KDDKDDKDDKDS
KSDKDDKSDKDS/bracketrightbigg
G/bracerightbigg
tr/braceleftbigg
GT/bracketleftbigg
KDSKSDKDSKSS
KSSKSDKSSKSS/bracketrightbigg
G/bracerightbigg.
(43)
5.2 Image Recognition Via Kernel Version
In image clustering or classiï¬cation, the cluster/class assignment is based on Euclidean distance in the lower
dimension by projection matrix W. Also, for some kernels, say Gaussian kernel, Wcan not be explicitly
obtained as it is an inï¬nite dimension mapping. Therefore, we seek image recognition implicitly via the
Kernel trick. Assume we have anchor data samples A={aj}(j= 1,...,h )and query data ai, the squared
Euclidean distance in transformed space is /bardblWTÎ¦(Qj)/bardbl2
F, where Qj=ajâˆ’ai(j= 1,...,h ). Therefore:
/bardblWTÎ¦(Qj)/bardbl2
F=tr/parenleftbig
GT[Î¦(D),Î¦(S)]TÎ¦(Qj)Î¦T(Qj)[Î¦(D),Î¦(S)]G/parenrightbig
=tr/braceleftbigg
GT/bracketleftbigg
KDQjKQjDKDQjKQjS
KSQjKQjDKSQjKQjS/bracketrightbigg
G/bracerightbigg
.
(44)
The kernel version metric learning algorithm is summarized in Algorithm 5. We end this section by pointing
out that diï¬€erent kernel options may result in various performances, such as Linear, polynomial, and RBF
kernel,hyper-parameterneedstuningwhennecessary,but K(x,y) =/angbracketleftÎ¦(x),Î¦(y)/angbracketrightiscomputationallyeï¬ƒcient
via the Kernel trick. In the kernel version metric learning algorithm, the main consumption goes to inversion
and eigenvalue decomposition both on (s+d)Ã—(s+d), therefore the whole complexity is O(Kâˆ—(s+d)3).
6 Convergence Analysis
We give the convergence rate of Algorithm 3 and Algorithm 5 in the following theorem:
Theorem 6.1. The convergence rate of Algorithm 3 and Algorithm 5 is superlinear.
Proof.We start the analysis with the deï¬nition of superlinear convergence rate: limkâ†’âˆ/bardblFk+1âˆ’Fâˆ—/bardbl
/bardblFkâˆ’Fâˆ—/bardbl= 0,
where we deï¬ne
Fâˆ—= max
WTW=Itr/parenleftbig
WTSbW/parenrightbig
tr(WTSwW):= max
WTW=If(W)
g(W)= max
WTW=IF(W), (45)
and we have
Wâˆ—âˆˆargmaxf(W)âˆ’F(Wâˆ—)g(W). (46)
AsWâˆˆRpÃ—r, we conclude the leading eigenvalues of Sbâˆ’Fâˆ—Swdenoted as Î»1,...,Î»rsatisfy/summationtextr
i=1Î»i= 0.
Many previous works have focused on the convergence rate of the constrained maximum trace ratio problem,
including global linear or local quadratic, we refer the readers to Ngo et al. (2012); Zhang et al. (2010; 2013)
12Under review as submission to TMLR
and the references therein. Our analysis will utilize the global linear convergence result established by Zhang
et al. (2010), based on which we will show it is indeed superlinear:
F(Wâˆ—)âˆ’F(Wk+1)â‰¤(1âˆ’1
Îº(Sw))(F(Wâˆ—)âˆ’F(Wk)), (47)
whereÎº(Sw) =/summationtextr
i=1Î»i(Sw)//summationtextr
i=1Î»pâˆ’i+1(Sw)>1almost surely .
For any symmetric matrix CâˆˆRpÃ—pandV= (v1,v2,...,vp)be its eigenvectors in decreasing order w.r.t.
eigenvalues, then we have
r/summationdisplay
i=1Î»iâˆ’tr/parenleftbig
WTCW/parenrightbig
=r/summationdisplay
i=1Î»iâˆ’p/summationdisplay
i=1Î»i/bardblWTvi/bardbl2
2=r/summationdisplay
i=1Î»i(1âˆ’/bardblWTvi/bardbl2
2)âˆ’p/summationdisplay
i=r+1Î»i/bardblWTvi/bardbl2
2,(48)
with the fact that
/bardblWTvi/bardbl2
2=vT
iWWTviâ‰¤/bardblWWT/bardbl2=/bardblWTW/bardbl2= 1, (49)
we have
r/summationdisplay
i=1Î»iâˆ’tr/parenleftbig
WTCW/parenrightbig
â‰¥r/summationdisplay
i=1Î»i(1âˆ’/bardblWTvi/bardbl2
2)âˆ’Î»r+1p/summationdisplay
i=r+1/bardblWTvi/bardbl2
2
â‰¥Î»r(râˆ’r/summationdisplay
i=1/bardblWTvi/bardbl2
2)âˆ’Î»r+1(râˆ’r/summationdisplay
i=1/bardblWTvi/bardbl2
2)
=(Î»râˆ’Î»r+1)(râˆ’r/summationdisplay
i=1/bardblWTvi/bardbl2
2).(50)
Denote Â¯V= (v1,v2,...,vr)âˆˆRpÃ—r, for any square rotation matrix RâˆˆRrÃ—rsuch that RTR=RRT=I,
withÏƒi(Â·)denoting the singular values, we have
min
Wâˆ—/bardblWâˆ’Wâˆ—/bardbl2
Fâ‰¤min
R/bardblWâˆ’Â¯VR/bardbl2
F= min
R/bardblW/bardbl2
F+/bardblÂ¯VR/bardbl2
Fâˆ’2tr/parenleftbig
WTÂ¯VR/parenrightbig
= min
R2(râˆ’tr/parenleftbig
RTÂ¯VTW/parenrightbig
) = 2(râˆ’r/summationdisplay
i=1Ïƒi(Â¯VTW))
â‰¤2(râˆ’r/summationdisplay
i=1Ïƒ2
i(Â¯VTW)) = 2(râˆ’/bardblÂ¯VTW/bardbl2
F) = 2(râˆ’r/summationdisplay
i=1/bardblWTvi/bardbl2
2).(51)
Combine Eq. (50) and Eq. (51), we get
r/summationdisplay
i=1Î»iâˆ’tr/parenleftbig
WTCW/parenrightbig
â‰¥Î»râˆ’Î»r+1
2min
Wâˆ—/bardblWâˆ’Wâˆ—/bardbl2
F. (52)
DenoteP(W) =f(W)âˆ’F(Wâˆ—)g(W) =g(W)(F(W)âˆ’Fâˆ—) =tr/parenleftbig
WT(Sbâˆ’Fâˆ—Sw)W/parenrightbig
, now set C=
Sbâˆ’Fâˆ—Sw, recall that the leading eigenvalues of Sbâˆ’Fâˆ—Swsatisfy/summationtextr
i=1Î»i= 0, and invoke Eq. (52), we
get
Î»râˆ’Î»r+1
2min
Wâˆ—/bardblWâˆ’Wâˆ—/bardbl2
Fâ‰¤âˆ’tr/parenleftbig
WTCW/parenrightbig
=g(W)(Fâˆ—âˆ’F(W)). (53)
With the deï¬nition of g(W)in Eq. (45), we have
g(W) =tr/parenleftbig
WTSwW/parenrightbig
â‰¤r/summationdisplay
i=1Î»i(Sw), (54)
13Under review as submission to TMLR
therefore, by plugging W=Wk, we can obtain
min
Wâˆ—/bardblWâˆ’Wâˆ—/bardbl2
Fâ‰¤2/summationtextr
i=1Î»i(Sw)
Î»râˆ’Î»r+1(Fâˆ—âˆ’F(Wk))â‰¤2/summationtextr
i=1Î»i(Sw)
Î»râˆ’Î»r+1(Fâˆ—âˆ’F(W0))(1âˆ’1
Îº(Sw))k.(55)
On the other side,
|g(Wâˆ—)âˆ’g(Wk)|=|/angbracketleftWâˆ—âˆ’Wk,âˆ‡g(Î¸Wk+ (1âˆ’Î¸)Wâˆ—)/angbracketright|=|/angbracketleftWâˆ—âˆ’Wk,2Sw(Î¸Wk+ (1âˆ’Î¸)Wâˆ—)/angbracketright|
â‰¤2/bardblWâˆ—âˆ’Wk/bardblF/bardblSw/bardbl2(Î¸/bardblWk/bardblF+ (1âˆ’Î¸)/bardblWâˆ—/bardblF) = 2âˆšrÎ»1(Sw)/bardblWâˆ—âˆ’Wk/bardblF.(56)
Since Wk+1=argmaxWf(W)âˆ’F(Wk)g(W) = argmaxWg(W)f(W)
g(W)âˆ’g(W)F(Wk) =
argmaxWg(W)(F(W)âˆ’F(Wk)), we have
g(Wk+1)(F(Wk+1)âˆ’F(Wk))â‰¥g(Wâˆ—)(F(Wâˆ—)âˆ’F(Wk)), (57)
dividing both sides by g(Wk+1)and addF(Wâˆ—)âˆ’F(Wk), we obtain
F(Wâˆ—)âˆ’F(Wk+1)â‰¤g(Wâˆ—)
g(Wk+1)(F(Wk)âˆ’F(Wâˆ—)) +F(Wâˆ—)âˆ’F(Wk)
=g(Wk+1)âˆ’g(Wâˆ—)
g(Wk+1)(F(Wâˆ—)âˆ’F(Wk)).(58)
Thus, based on Eq. (55), Eq. (56) and Eq. (58), we can obtain
Fâˆ—âˆ’F(Wk+1)
Fâˆ—âˆ’F(Wk)â‰¤g(Wk+1)âˆ’g(Wâˆ—)
g(Wk+1)â‰¤2âˆšrÎ»1(Sw)/bardblWâˆ—âˆ’Wk/bardblF/summationtextr
i=1Î»pâˆ’i+1(Sw)
â‰¤2âˆšrÎ»1(Sw)/summationtextr
i=1Î»pâˆ’i+1(Sw)min
Wâˆ—/bardblWk+1âˆ’Wâˆ—/bardblF
â‰¤2âˆšrÎ»1(Sw)/summationtextr
i=1Î»pâˆ’i+1(Sw)/radicalBigg
2/summationtextr
i=1Î»i(Sw)
Î»râˆ’Î»r+1(Fâˆ—âˆ’F(W0))(1âˆ’1
Îº(Sw))k+1
2.(59)
We can see that when kâ†’âˆin Eq. (59), we haveFâˆ—âˆ’F(Wk+1)
Fâˆ—âˆ’F(Wk)= 0, which is the superlinear convergence
rate, and we have
Fâˆ—âˆ’F(Wk)
Fâˆ—âˆ’F(W0)â‰¤Sk(1âˆ’1
Îº(Sw))/summationtextk
n=1n
2=Sk(1âˆ’1
Îº(Sw))k(k+1)
4, (60)
whereS=2âˆšrÎ»1(Sw)/summationtextr
i=1Î»pâˆ’i+1(Sw)/radicalbigg
2/summationtextr
i=1Î»i(Sw)
Î»râˆ’Î»r+1(Fâˆ—âˆ’F(W0)).
7 Experiments
7.1 Toy Experiment
To test our approach, we conduct a toy experiment classifying dogs and cats. Training data deliberately
include mismatched pairs, as seen in Figure 6(a). Despite mislabeled images, both the robust method and
robust 2D method, designed for outlier robustness, correctly classify all images for q= 1, as shown in the
lower part of Figure 6(a). To further illustrate the robust metric learning method, we also provide the
details in Figure 2 example. Given the following sentences: â€˜He/She is happy/angryâ€™, â€˜He/She is very/quite
happy/angryâ€™ and â€˜Happy/Angryâ€™, with a total number of 14. We manually give 20 correct side constraints,
for example: â€˜He is happyâ€™ and â€˜She is angryâ€™ in diï¬€erent sets, while â€˜He is quite happyâ€™ and â€˜Happyâ€™ in the
same. Also, there are some adversarial examples, where 5 links are mistakenly given, say â€˜She is happyâ€™ and
â€˜He is quite angryâ€™ should be separated but they are put in the same set. Each sentence xis represented as a
14Under review as submission to TMLR
(a) Image recognition
p=2p=1SheHeishappyangryveryquiteWeights for each Word
-0.4221-0.4576
0.033860.069040.0045680.0045680.007688-0.70711.047e-093.246e-070.45340.50410.38310.7071
-0.6-0.4-0.200.20.40.6 (b) Sentiment recognition
Figure 6: Results from toy experiments. From left to right: (a) Image recognition: Training set (upper) and
recognition results (lower). Even with the existence of incorrect pairs, our robust metric learning method
still yields correct recognition; (b) Sentiment recognition: Our robust metric learning (p = 1) can learn
reasonable weights for features even under adversarial attack while the traditional one (p =2) will fail.
15 20 25 30
#nearest neighbors in knn0.550.60.650.70.75Sentiment recognition accuracyEuclidean
2D, r = 40
2D, r = 35
2D, r = 30
(a) IMDB
1020304050607080
#columns in transformation matrix0.90.920.940.960.981Face recognition accuracy2D gray
2D RGB
robust 2D gray
robust 2D RGB
kernel gray
kernel RGB (b) Headpose
12345678
#iteration0100200300400500Objective
headpose dataset
ORL dataset (c) Objective
Figure 7: From left to right: (a) Accuracy of the 2D metric learning with varying projected dimension r and k
ink-NN for the IMDB dataset; (b) Face recognition accuracy for the headpose dataset, where X-axis denotes
the projected dimension; (c) The objective of the 2D metric learning is monotonically non-decreasing, same
for the kernel method and the robust 2D method.
7-dimensional word-count vector (with each denoting a word such as â€˜happyâ€™, â€˜angryâ€™, etc.). As demonstrated
in Figure 6(b), for vanilla squared Frobenius ( q= 2), the learned weights for â€˜isâ€™, â€˜happyâ€™, and â€˜angryâ€™ are
close, which is not as they should be. However, if we set q= 1, which is supposed to remain robust with
outliers/attacks, it can obtain signiï¬cantly diï¬€erent weights for â€˜happyâ€™ (0.707) and â€˜angryâ€™ (-0.707), while
the rest are all set close to 0. This is in perfect accordance with our common sense, which indicates the
potential application of our robust metric learning in other domains.
7.2 Sentiment Recognition
We evaluate the 2D metric learning method in a sentiment recognition task with the IMDB dataset. 5000
data instances are randomly sampled from the IMDB review dataset and are split into the training set and
test set evenly. For each review, only the ï¬rst 50 processed text words are embedded in a 50-dimension tensor
and are labeled as positive or negative. We obtain Wusing samples from the training set, and then apply
it when we use k-NN to do sentiment classiï¬cation. We test the 2D metric learning method with varying
numbers of columns in the transformation matrix and kin thek-NN classiï¬er. Figure 7(a) shows the result,
our method can achieve stable and better performance than Euclidean distance-based classiï¬cation.
15Under review as submission to TMLR
Table 1: Time consumption (in seconds) and mean recognition accuracy (10 test runs) for headpose dataset
MS GMML LMNN KISSME ITML
GrayscaleTime 155.981 56.221 6601.881 792.331 5310.871
k= 3 0.940 0.928 0.917 0.935 0.917
k= 5 0.931 0.922 0.825 0.931 0.883
k= 9 0.933 0.917 0.817 0.922 0.883
RGBTime 312.212 93.125 9925.917 1238.569 7555.825
k= 3 0.983 0.967 0.928 0.962 0.931
k= 5 0.983 0.933 0.917 0.958 0.925
k= 9 0.967 0.933 0.917 0.945 0.917
MRL RDML 2D Robust 2D Kernel
GrayscaleTime 698.329 1005.72 2.062 8.185 2.517
k= 3 0.933 0.933 0.933 0.967 0.967
k= 5 0.917 0.933 0.933 0.967 0.967
k= 9 0.883 0.917 0.933 0.967 0.933
RGBTime 1025.978 2955.96 5.959 10.121 5.012
k= 3 0.965 0.967 0.985 0.985 0.985
k= 5 0.932 0.933 0.983 0.985 0.983
k= 9 0.923 0.917 0.967 0.983 0.983
Table 2: Time consumption (in seconds) and mean recognition accuracy (10 test runs) for ORL dataset,
with full test images, with random missing pixels as noise on test images, and with mismatched pairs
MS GMML LMNN KISSME ITML
VanillaTime 102.763 35.758 5721.998 603.992 4125.722
k= 3 0.913 0.898 0.897 0.901 0.883
k= 5 0.891 0.885 0.852 0.882 0.867
k= 7 0.847 0.839 0.792 0.828 0.813
Noisek= 3 0.895 0.879 0.892 0.891 0.852
k= 5 0.873 0.868 0.839 0.852 0.839
k= 7 0.839 0.807 0.768 0.819 0.793
Miss-matchedk= 3 0.892 0.872 0.853 0.858 0.863
k= 5 0.875 0.827 0.822 0.839 0.817
k= 7 0.819 0.808 0.767 0.795 0.792
MRL RDML 2D Robust 2D Kernel
VanillaTime 465.827 805.386 2.287 8.552 2.817
k= 3 0.905 0.902 0.933 0.933 0.933
k= 5 0.887 0.872 0.917 0.917 0.902
k= 7 0.835 0.851 0.861 0.867 0.867
Noisek= 3 0.857 0.867 0.892 0.913 0.917
k= 5 0.825 0.845 0.873 0.892 0.892
k= 7 0.817 0.769 0.833 0.877 0.837
Miss-matchedk= 3 0.851 0.817 0.875 0.917 0.892
k= 5 0.818 0.813 0.835 0.902 0.875
k= 7 0.785 0.767 0.819 0.875 0.825
7.3 Image Segmentation and Recognition
We conduct image segmentation on some natural images (Martin et al., 2001) and evaluate our methods in
an image classiï¬cation task with k-NN classiï¬er on two datasets, the headpose dataset (Gourier et al., 2004)
and the ORL dataset (Samaria & Harter, 1994). For the headpose dataset, we conduct the experiment with
two settings: (1)with grayscale images; (2)with RGB images. To deal with RGB images, we treat the three
layers of images as three matrix blocks and append them together. Thus for an input image of size pÃ—m, in
2D methods we stretch it into a matrix of size pÃ—3m. In other methods, we vectorize the input image to get
16Under review as submission to TMLR
1020304050607080
#columns in transformation matrix0.80.850.90.95Face recognition accuracy, vanilla2D
Robust 2D
kernel
(a) Vanilla
1020304050607080
#columns in transformation matrix0.80.850.90.95Face recognition accuracy, noise2D
Robust 2D
kernel (b) Noise
1020304050607080
#columns in transformation matrix0.80.850.90.95Face recognition accuracy, mispaired2D
Robust 2D
kernel (c) Mispaired
Figure 8: Accuracy for the ORL dataset with varying projected dimensions, from left to right is obtained
with vanilla images, with noise, and with mispaired images, respectively.
a vector with length 3Ã—pÃ—m. For the Robust metric learning, we set q= 1. To evaluate the robustness of
the algorithms, we test on the ORL dataset in three situations: (1)learn with correct pairwise relationships,
test on vanilla images; (2)learn with correct information but test on images with 10% noises; (3)learn the
metric while there exist 7% miss-matched pairwise relationships, test on vanilla images. We also compare
our method with several metric learning methods, including Multi-Similarity-based deep metric learning
(MS) (Wang et al., 2019), GMML (Zadeh et al., 2016), ITML (Davis et al., 2007), LMNN (Weinberger et al.,
2006), KISSME (Koestinger et al., 2012), MRL(-ADMM) (Lim et al., 2013), and RDML (Liu et al., 2019).
Both GMML and MRL-ADMM claim their superiority in terms of low computation time, which will be
compared with our methods in computation time. We evaluate both the time consumption and recognition
accuracy of each algorithm. The time consumption to get W, and the recognition accuracy with varying k
ofk-NN classiï¬er are listed in Table 1 and Table 2, best results are highlighted. It is obvious that the time
consumption of our 2D methods and kernel method is a huge advantage and this merit is more signiï¬cant
with RGB images. Our methods require negligible computation time to get the transformation matrix, while
othermethodshavemuchhighercomputationalcosts. EvencomparedwiththeGMMLmethod, whichserves
as a breakthrough in terms of computation time, our proposed methods still have a great advantage in high
eï¬ƒciency. Our methods are able to achieve the best recognition accuracy almost on all tested datasets, at
most times they are signiï¬cantly better than most other methods, and they have comparable performance
with deep metric learning on the two datasets. In Table 2, when we introduce noise and adversarial attack
in the training process, the robust 2D metric learning method and robust metric learning method are proved
to be able to achieve robust performance.
We also investigate the impact of varying the number of columns rin the transformation matrix W. By
testing diï¬€erent values of rwhile keeping kof thek-NN classiï¬er set to 3, Figure 7(b) illustrates that higher
accuracy can be achieved as rincreases, reaching a threshold where the incremental gain diminishes. For
a more detailed exploration of how the number of columns rin the transformation matrix Winï¬‚uences
accuracy, refer to Figure 8. Figure 7(c) illustrates the objective change in the 2D version, with kernel and
robust methods exhibiting similar trends. Notably, an optimal transformation matrix Wcan be obtained
within very few iterations. The presented results collectively aï¬ƒrm that the four proposed metric learning
algorithms eï¬€ectively address real-world cases. This validation aligns with our earlier analyses and suggests
their superiority over their counterparts. Figure 9 showcases image segmentation results utilizing RGB
pixel values and X,Ylocations as input features. The presence of red/green lines and pixels indicates
must-link and cannot-link relationships, respectively. In the ï¬rst row, images display user-speciï¬ed pixels
denoting the background and foreground. Subsequent rows reveal the impact of learning an appropriate
distance metric transformation matrix Wfrom user-speciï¬ed pixels. The improved performance of the
k-NN classiï¬er in segmentation is evident. Our algorithm consistently outperforms GMML and RDML
methods, as demonstrated in the lower rows. For instance, in the pyramid image, the black circled area,
situated far from the labeled foreground region, is accurately classiï¬ed by our method but not by others.
Figure 10 demonstrates the results from the face recognition experiment. After imposing 10 %noise on the
query image randomly, our method excels in identifying the nearest anchor images compared to others.
17Under review as submission to TMLR
Figure 9: Image segmentation results. First row: Original images with labeled pixels. Second: Euclidean
distance.Third:GMML method. Fourth: RDML method. Fifth Row: Robust Algorithm 2.
Fig. 5. Face recognition results with missing pixelsFor papers published in translation journals, please give theEnglish citation ï¬rst, followed by the original foreign-languagecitation [6].REFERENCES[1]G. Eason, B. Noble, and I. N. Sneddon, â€œOn certain integrals ofLipschitz-Hankel type involving products of Bessel functions,â€ Phil.Trans. Roy. Soc. London, vol. A247, pp. 529â€“551, April 1955.[2]J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol.2. Oxford: Clarendon, 1892, pp.68â€“73.[3]I. S. Jacobs and C. P. Bean, â€œFine particles, thin ï¬lms and exchangeanisotropy,â€ in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. NewYork: Academic, 1963, pp. 271â€“350.[4]K. Elissa, â€œTitle of paper if known,â€ unpublished.[5]R. Nicole, â€œTitle of paper with only ï¬rst word capitalized,â€ J. NameStand. Abbrev., in press.[6]Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, â€œElectron spectroscopystudies on magneto-optical media and plastic substrate interface,â€ IEEETransl. J. Magn. Japan, vol. 2, pp. 740â€“741, August 1987 [Digests 9thAnnual Conf. Magnetics Japan, p. 301, 1982].[7]M. Young, The Technical Writerâ€™s Handbook. Mill Valley, CA: Univer-sity Science, 1989.[8]S. Xiang, F. Nie, C Zhang, â€œLearning a Mahalanobis distance metricfor data clustering and classiï¬cation,â€in Pattern Recognition, vol. 41,pp. 3600â€“3612, December 2008.IEEE conference templates contain guidance text for compos-ing and formatting conference papers. Please ensure that alltemplate text is removed from your conference paper prior tosubmission to the conference. Failure to remove the templatetext from your paper may result in your paper not beingpublished.
Figure 10: Face recognition results. First row: Euclidean distance. Second row: GMML method. Third
Row:RDML method. Fourth Row: Robust Algorithm 4.
18Under review as submission to TMLR
8 Conclusion
We introduce a robust metric learning approach that leverages the /lscript2,q-norm distance, oï¬€ering enhanced
resilience against data outliers and adversarial attacks. Additionally, we present 2D metric learning and
kernel metric learning algorithms, tailored to mitigate the computational challenges associated with eigen-
value decomposition on high-dimensional covariance matrices. Our methods come with a strong theoretical
foundation, ensuring the objective is monotonically increasing. Within each iteration, we obtain a closed-
form optimal solution for 2D and kernel metric learning respectively. In addition, we rigorously establish the
convergence rate of these proposed algorithms. Experiments on diverse real-world datasets are conducted to
validate the eï¬€ectiveness of our methods. The results highlight the eï¬ƒciency and superior accuracy of our
approaches in addressing a range of practical tasks in comparison with the counterparts.
References
Shunichi Amari and Si Wu. Improving support vector machine classiï¬ers by modifying kernel functions.
Neural Networks , 12(6):783â€“789, 1999.
A. Baccini, P. Besse, and A. de Faguerolles. A l1-norm pca and heuristic approach. International Conference
on Ordinal and Symbolic Data Analysis , pp. 359â€“368, 1996.
AurÃ©lien Bellet, Amaury Habrard, and Marc Sebban. A survey on metric learning for feature vectors and
structured data. arXiv preprint arXiv:1306.6709 , 2013.
Nicolas Boumal, Pierre-Antoine Absil, and Coralia Cartis. Global rates of convergence for nonconvex opti-
mization on manifolds. IMA Journal of Numerical Analysis , 39(1):1â€“33, 2019.
Deng Cai, Xiaofei He, and Jiawei Han. Speed up kernel discriminant analysis. The VLDB Journal , 20:21â€“33,
2011.
Fatih Cakir, Kun He, Xide Xia, Brian Kulis, and Stan Sclaroï¬€. Deep metric learning to rank. In Proceedings
of the IEEE/CVF conference on computer vision and pattern recognition , pp. 1861â€“1870, 2019.
Ingrid Daubechies. Orthonormal bases of compactly supported wavelets ii. variations on a theme. SIAM
Journal on Mathematical Analysis , 24(2):499â€“519, 1993.
Jason V Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit S Dhillon. Information-theoretic metric
learning. In Proceedings of the 24th international conference on Machine learning , pp. 209â€“216. ACM,
2007.
Roy De Maesschalck, Delphine Jouan-Rimbaud, and DÃ©sirÃ© L Massart. The mahalanobis distance. Chemo-
metrics and intelligent laboratory systems , 50(1):1â€“18, 2000.
C. Ding, D. Zhou, X. He, and H. Zha. R1-pca: rotational invariant l 1-norm principal component analysis
for robust subspace factorization. In ICML, pp. 281â€“288. ACM, 2006.
Ronald A Fisher. The use of multiple measurements in taxonomic problems. Annals of eugenics , 7(2):
179â€“188, 1936.
J. Gao. Robust l1 principal component analysis and its bayesian variational inference. Neural Computation ,
20:555â€“572, 2008.
Jacob Goldberger, Geoï¬€rey E Hinton, Sam Roweis, and Russ R Salakhutdinov. Neighbourhood components
analysis. Advances in neural information processing systems , 17, 2004.
Nicolas Gourier, Daniela Hall, and James L Crowley. Estimating face orientation from robust detection
of salient facial features. In ICPR International Workshop on Visual Observation of Deictic Gestures .
Citeseer, 2004.
Steven CH Hoi, Michael R Lyu, and Rong Jin. A uniï¬ed log-based relevance feedback scheme for image
retrieval. IEEE TRANSACTIONS on knowledge and Data Engineering , 18(4):509â€“524, 2006.
19Under review as submission to TMLR
Leonid Karlinsky, Joseph Shtok, Sivan Harary, Eli Schwartz, Amit Aides, Rogerio Feris, Raja Giryes, and
Alex M Bronstein. Repmet: Representative-based metric learning for classiï¬cation and few-shot object
detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp.
5197â€“5206, 2019.
Mahmut Kaya and Hasan Åakir Bilge. Deep metric learning: A survey. Symmetry , 11(9):1066, 2019.
Q.KeandT.Kanade. Robustl1normfactorizationinthepresenceofoutliersandmissingdatabyalternative
convex programming. IEEE Conf. Computer Vision and Pattern Recognition , pp. 592â€“599, 2004.
Martin Koestinger, Martin Hirzer, Paul Wohlhart, Peter M Roth, and Horst Bischof. Large scale metric
learning from equivalence constraints. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE
Conference on , pp. 2288â€“2295. IEEE, 2012.
Brian Kulis et al. Metric learning: A survey. Foundations and Trends Â®in Machine Learning , 5(4):287â€“364,
2013.
N. Kwak. Principal component analysis based on l1-norm maximization. IEEE Transactions on Pattern
Analysis and Machine Intelligence , 30:1672â€“1680, 2008.
Christina Leslie, Eleazar Eskin, and William Staï¬€ord Noble. The spectrum kernel: A string kernel for svm
protein classiï¬cation. In Biocomputing 2002 , pp. 564â€“575. World Scientiï¬c, 2001.
Ming Li and Baozong Yuan. 2d-lda: A statistical linear discriminant analysis for image matrix. Pattern
Recognition Letters , 26(5):527â€“532, 2005.
Daryl Lim, Gert Lanckriet, and Brian McFee. Robust structural metric learning. In Sanjoy Dasgupta
and David McAllester (eds.), Proceedings of the 30th International Conference on Machine Learning ,
volume 28 of Proceedings of Machine Learning Research , pp. 615â€“623, Atlanta, Georgia, USA, 17â€“19 Jun
2013. PMLR. URL https://proceedings.mlr.press/v28/lim13.html .
Kai Liu, Lodewijk Brand, Hua Wang, and Feiping Nie. Learning robust distance metric with side information
viaratiominimizationoforthogonallyconstrainedl21-normdistances. In Proceedings of the Twenty-Eighth
International Joint Conference on Artiï¬cial Intelligence , 2019.
Weifeng Liu, Puskal P Pokharel, and Jose C Principe. The kernel least-mean-square algorithm. IEEE
Transactions on signal processing , 56(2):543â€“554, 2008.
Daniel LÃ³pez-SÃ¡nchez, AngÃ©lica GonzÃ¡lez Arrieta, and Juan M Corchado. Visual content-based web page
categorization with deep transfer learning and metric learning. Neurocomputing , 338:418â€“431, 2019.
D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of human segmented natural images and its
application to evaluating segmentation algorithms and measuring ecological statistics. In Proc. 8th Intâ€™l
Conf. Computer Vision , volume 2, pp. 416â€“423, July 2001.
Thanh T Ngo, Mohammed Bellalij, and Yousef Saad. The trace ratio optimization problem. SIAM review ,
54(3):545â€“569, 2012.
Brett Ninness, HÃ¥kan Hjalmarsson, and Fredrik Gustafsson. The fundamental role of general orthonormal
bases in system identiï¬cation. IEEE Transactions on Automatic Control , 44(7):1384â€“1406, 1999.
Arti Patle and Deepak Singh Chouhan. Svm kernel functions for classiï¬cation. In 2013 International
Conference on Advances in Technology and Engineering (ICATE) , pp. 1â€“9. IEEE, 2013.
Ferdinando S Samaria and Andy C Harter. Parameterisation of a stochastic model for human face identi-
ï¬cation. In Proceedings of 1994 IEEE workshop on applications of computer vision , pp. 138â€“142. IEEE,
1994.
Bernhard SchÃ¶lkopf, Alexander Smola, and Klaus-Robert MÃ¼ller. Kernel principal component analysis. In
International conference on artiï¬cial neural networks , pp. 583â€“588. Springer, 1997.
20Under review as submission to TMLR
Chunhua Shen, Junae Kim, and Lei Wang. Scalable large-margin mahalanobis distance metric learning.
IEEE transactions on Neural Networks , 21(9):1524â€“1530, 2010.
Hua Wang, Feiping Nie, and Heng Huang. Robust distance metric learning via simultaneous l1-norm min-
imization and maximization. In International conference on machine learning , pp. 1836â€“1844. PMLR,
2014.
Qianqian Wang, Quanxue Gao, Xinbo Gao, and Feiping Nie. /lscript2,p-norm based pca for image recognition.
IEEE Transactions on Image Processing , 27(3):1336â€“1346, 2018. doi: 10.1109/TIP.2017.2777184.
Xun Wang, Xintong Han, Weilin Huang, Dengke Dong, and Matthew R Scott. Multi-similarity loss with
general pair weighting for deep metric learning. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , pp. 5022â€“5030, 2019.
Kilian Q Weinberger, John Blitzer, and Lawrence K Saul. Distance metric learning for large margin nearest
neighbor classiï¬cation. In Advances in neural information processing systems , pp. 1473â€“1480, 2006.
John Wright, Arvind Ganesh, Shankar Rao, Yigang Peng, and Yi Ma. Robust principal component analysis:
Exact recovery of corrupted. Advances in Neural Information Processing Systems , pp. 116, 2009.
Shiming Xiang, Feiping Nie, and Changshui Zhang. Learning a mahalanobis distance metric for data clus-
tering and classiï¬cation. Pattern Recognition , 41(12):3600â€“3612, 2008.
EricPXing, MichaelIJordan, StuartJRussell, andAndrewYNg. Distancemetriclearningwithapplication
to clustering with side-information. In Advances in neural information processing systems , pp. 521â€“528,
2003.
Liu Yang and Rong Jin. Distance metric learning: A comprehensive survey. Michigan State Universiy , 2(2):
4, 2006.
FeiYe, ZhipingShi, andZhongzhiShi. Acomparativestudyofpca, ldaandkernelldaforimageclassiï¬cation.
In2009 International Symposium on Ubiquitous Virtual Reality , pp. 51â€“54. IEEE, 2009.
PouryaZadeh, ReshadHosseini, andSuvritSra. Geometricmeanmetriclearning. In International conference
on machine learning , pp. 2464â€“2471. PMLR, 2016.
Daoqiang Zhang and Zhi-Hua Zhou. (2d) 2pca: Two-directional two-dimensional pca for eï¬ƒcient face
representation and recognition. Neurocomputing , 69(1-3):224â€“231, 2005.
Lei-Hong Zhang, Li-Zhi Liao, and Michael K Ng. Fast algorithms for the generalized foleyâ€“sammon discrim-
inant analysis. SIAM journal on matrix analysis and applications , 31(4):1584â€“1605, 2010.
Lei-Hong Zhang, Li-Zhi Liao, and Michael K Ng. Superlinear convergence of a general algorithm for the
generalized foleyâ€“sammon discriminant analysis. Journal of Optimization Theory and Applications , 157:
853â€“865, 2013.
21