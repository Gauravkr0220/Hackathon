Under review as submission to TMLR
Representation Balancing with Decomposed Patterns for
Treatment Eï¬€ect Estimation
Anonymous authors
Paper under double-blind review
Abstract
Estimating treatment eï¬€ects from observational data is subject to a covariate shift problem
incurred by selection bias. Recent research has sought to mitigate this problem by balancing
the distribution of representations between the treated and controlled groups. The rationale
behind this is that counterfactual estimation relies on (1) preserving the predictive power
of factual outcomes and (2) learning balanced representations. However, there is a trade-oï¬€
between achieving these two objectives. In this paper, we propose a novel model, DIGNet,
which is designed to capture the patterns that contribute to outcome prediction (task 1)
and representation balancing (task 2) respectively. Speciï¬cally, we derive a theoretical
upper bound that links the concept of propensity confusion to representation balancing,
and further transform the balancing Patterns into Decompositions of Individual propensity
confusion and Group distance minimization (PDIG) to capture more eï¬€ective balancing
patterns. Moreover, we suggest decomposing proxy features into Patterns of Pre-balancing
and Balancing Representations (PPBR) to preserve patterns that are beneï¬cial for outcome
modeling. Extensive experiments conï¬rm that PDIG and PPBR follow diï¬€erent pathways
to achieve the same goal of improving treatment eï¬€ect estimation. We hope our ï¬ndings
can be heuristics for investigating factors inï¬‚uencing the generalization of representation
balancing models in counterfactual estimation.
1 Introduction
In the context of the ubiquity of personalized decision-making, causal inference has sparked a surge of
research exploring causal machine learning in many disciplines, including economics and statistics (Wager &
Athey, 2018; Athey & Wager, 2019; Farrell, 2015; Chernozhukov et al., 2018; Huang et al., 2021), healthcare
(Qian et al., 2021; Bica et al., 2021a;b), and commercial applications (Guo et al., 2020b;c; Chu et al., 2021).
The core of causal inference is to estimate treatment eï¬€ects , which can be tied to a fundamental hypothetical
question: What would be the outcome if one received an alternative treatment? Answering this question
requires the knowledge of counterfactual outcomes , which can only be inferred from observational data, but
cannot be obtained directly.
Selection bias presents a major challenge for estimating counterfactual outcomes (Guo et al., 2020a; Zhang
et al., 2020; Yao et al., 2021). This problem is due to the non-random treatment assignment, that is,
treatment (e.g., vaccination) is usually determined by covariates (e.g., age) that also aï¬€ect the outcome
(e.g., infection rate) (Huang et al., 2022b). The probability of a person receiving treatment is well known
as thepropensity score , and the diï¬€erence between each personâ€™s propensity score can inherently lead to a
covariate shift problem, i.e., the distribution of covariates in the treated units is substantially diï¬€erent from
that in the controlled ones. The covariate shift issue makes it more diï¬ƒcult to infer counterfactual outcomes
from observational data (Yao et al., 2018; Hassanpour & Greiner, 2019a).
Recently, a line of representation balancing works has sought to alleviate the covariate shift problem by
balancing the distribution between the treated group and the controlled group in the representation space
(Shalit et al., 2017; Johansson et al., 2022). The rational insight behind these works is that the counterfactual
estimation should rest on (1)the accuracy of factual outcome estimation and (2)enforcing minimization
1Under review as submission to TMLR
of distributional discrepancy measured by the Integral Probability Metric (IPM) between the treated and
controlled groups. Wasserstein distance (Cuturi & Doucet, 2014) is the most widely-adopted IPM for the
target (2) (Shalit et al., 2017; Huang et al., 2022a; Zhou et al., 2022), whereas other distance metrics such
asH-divergence have still received little attention in causal representation learning literature though H-
divergence is an important distance metric in other ï¬elds (Ben-David et al., 2006; 2010). Unlike previous
studies focusing on group distance minimization, we emphasize that the propensity score is a natural in-
dicator of whether representations are adequately balanced. Speciï¬cally, when it becomes challenging to
distinguish whether each unit in the representation space is treated or controlled, i.e., propensity confusion ,
the representations are believed to be adequately balanced. Ideally, if propensity confusion is extremely
strong, i.e., representations are perfectly balanced, the propensity scores of each unit in the representation
space would be 0.5. Therefore, propensity confusion provides a logical interpretation for representation
balancing, and achieving propensity confusion is naturally connected to minimizing the H-divergence-based
individual treatment eï¬€ect (ITE) error bound. More discusses about the theoretical results and empirical
implementations are presented in Section 3.2 and Section 4.1, respectively.
Moreover, a critical issue that remain to be resolved is that enforcing models to learn only balancing patterns
can weaken the predictive power of the outcome function. This is because of the trade-oï¬€ between targets (1)
and (2) (Zhang et al., 2020; Assaad et al., 2021; Huang et al., 2022a). We give a motivating example below
to help readers better understand this phenomenon. In addition, we provide another illustrative example
and analytical explanations in Section A.4 as supplementary elaboration on the aforementioned trade-oï¬€.
Motivating Example. Consider two individuals who are identical in every aspect except for their age.
One person is older and is designated as the treatment (T) group, while the other person is younger and
serves as the control (C) group. Age is used as a covariate to distinguish between T and C. If it is known
that the older person is more susceptible to a certain disease, the information age (covariate) can be used
to predict the likelihood of one developing the disease (outcome). However, suppose the information age
of each individual is mapped to some representations such that the representations of T and C are highly-
balanced or even identical. In that case, it may be diï¬ƒcult to diï¬€erentiate between T and C based on
these representations. Consequently, these over-balanced representations may lose information to accurately
predict the likelihood of each individual developing the disease.
Theaforementionedissuemotivatesustoexploreapproachesto (i)learningmoreeï¬€ectivebalancingpatterns
(task 2) without aï¬€ecting factual outcome prediction (task 1) or (ii)improving factual outcome prediction
(task 1) without aï¬€ecting learning balancing patterns (task 2). In this paper, we propose a new method,
DIGNet, which learns decomposed patterns to achieve both (i) and (ii). The contributions are threefold:
First, we interpret representation balancing as propensity confusion and derive corresponding theoretical
upper bounds for counterfactual error and ITE error based on H-divergence to ensure its rationality; Sec-
ond, DIGNet transforms the balancing Patterns into Decompositions of Individual propensity confusion and
Group distance minimization ( PDIG) to achieve goal (i), and we empirically ï¬nd that the PDIG structure
learns more eï¬€ective balancing patterns (task 2) without aï¬€ecting factual outcome prediction (task 1); Third,
DIGNet decomposes representative features into Patterns of Pre-balancing and Balancing Representations
(PPBR) to achieve goal (ii), and we experimentally conï¬rm that the PPBR approach improves outcome pre-
diction (task 1) without aï¬€ecting learning balancing patterns (task 2). To better describe our contributions,
we illustrate PPBR, PDIG, and the proposed DIGNet in Figure 1. We also illustrate the model sturecture
of DIGNet with the variants GNet, INet, DGNet, DINet in Figure 2.
1.1 Related Work
The presence of a covariate shift problem stimulates the line of representation balancing works (Johansson
et al., 2016; Shalit et al., 2017; Johansson et al., 2022). These works aim to balance the distributions of
representations between treated and controlled groups and simultaneously try to maintain representations
predictive of factual outcomes. This idea is closely connected with domain adaptation. In particular, the
individual treatment eï¬€ect (ITE) error bound based on Wasserstein distance is similar to the generalization
bound in Ben-David et al. (2010); Long et al. (2014); Shen et al. (2018). In addition to Wasserstein distance-
based model, our paper derives a new ITE error bound based on H-divergence (Ben-David et al., 2006;
2Under review as submission to TMLR
Î¦ğºğº
(b) PPBR (yellow) (c) PDIG (yellow)Î¦ğ¼ğ¼Î¦ğ¸ğ¸
Î¦ğºğº
Î¦ğºğº
(d) DIGNetÎ¦ğ¸ğ¸Î¦ğ¼ğ¼
(a) Classic modelÎ¦ğ¸ğ¸
BalancingBalancing BalancingBalancing
BalancingBalancing
Figure1: (a): Theclassicmodel(e.g., CFRNetShalitetal.(2017))extractsandmapstheoriginaldata Dinto
representations Î¦Eto achieve representation balancing over Î¦E, which are referred to as balancing patterns .
These balanced representations are then used for outcome prediction. (b): The PPBR is represented by
the yellow section, where Î¦Eis used for feature extraction and Î¦Gis used for representation balancing,
which are termed pre-balancing patterns and balancing patterns, respectively. Note that Î¦Galso serves as
decomposed patterns derived from Î¦E. Subsequently, Î¦EandÎ¦Gare concatenated for predicting outcomes.
(c): The PDIG is illustrated as the yellow part, where the balancing patterns consist of two components, Î¦G
andÎ¦I, serving for group distance minimization and individual propensity confusion, as detailed in Section
4.2. Afterward, Î¦GandÎ¦Iare concatenated for predicting outcomes. (d): The proposed model, DIGNet,
incorporates both PPBR and PDIG. In DIGNet, pre-balancing patterns Î¦Eare decomposed into balancing
patterns Î¦GandÎ¦I, which also serve as decomposed patterns. The ï¬nal outcome prediction is obtained by
concatenating Î¦E,Î¦G, and Î¦I.
2010; Ganin et al., 2016). Note that our theoretical results (Section 3.2) and experimental implementations
(Section 4.1) diï¬€er greatly from Shalit et al. (2017) due to the distinction between Wasserstein distance and
H-divergence.
Anotherrecent lineof causalrepresentation learning literatureinvestigateseï¬ƒcient neuralnetwork structures
for treatment eï¬€ect estimation. Kuang et al. (2017); Hassanpour & Greiner (2019b) extract the original co-
variates into treatment-speciï¬c factors, outcome-speciï¬c factors, and confounding factors; X-learner (KÃ¼nzel
et al., 2019) and R-learner (Nie & Wager, 2021) are developed beyond the classic S-learner and T-learner;
Curth & van der Schaar (2021) leverage structures for end-to-end learners to counteract the inductive bias
towards treatment eï¬€ect estimation, which is motivated by Makar et al. (2020).
The proposed DIGNet model is built on the PDIG structure and the PPBR approach. The PDIG structure
is motivated by multi-task learning, where we design a framework incorporating two speciï¬c balancing
patterns that share the same pre-balancing patterns. The PPBR approach is motivated by a so-called over-
enforcing problem mentioned by Zhang et al. (2020); Assaad et al. (2021); Huang et al. (2022a), where the
authors argue that improperly balanced representations can be detrimental predictors for outcome modeling,
since such representations can lose the original information that contributes to outcome prediction. Other
representation learning methods relevant to treatment eï¬€ect estimation include Louizos et al. (2017); Yao
et al. (2018); Yoon et al. (2018); Shi et al. (2019); Du et al. (2021).
2 Preliminaries
Notations. Suppose there are the Ni.i.d. random variables D={(Xi,Ti,Yi)}N
i=1with observed re-
alizations{(xi,ti,yi)}N
i=1, where there are N1treated units and N0controlled units. For each unit i,
Xiâˆˆ X âŠ‚ Rddenotesd-dimensional covariates and Tiâˆˆ {0,1}denotes the binary treatment, with
e(xi) :=p(Ti= 1|Xi=xi)deï¬ned as the propensity score (Rosenbaum & Rubin, 1983). Potential
outcome framework (Rubin, 2005) deï¬nes the potential outcomes Y1,Y0âˆˆY âŠ‚ Rfor treatment T= 1
andT= 0, respectively. We let the observed outcome (factual outcome) be Y=TÂ·Y1+ (1âˆ’T)Â·Y0,
and the unobserved outcome (counterfactual outcome) be Y=TÂ·Y0+ (1âˆ’T)Â·Y1. Fortâˆˆ{0,1}, let
Ï„t(x) :=E[Yt|X=x]be a function of Ytw.r.t. X, then our goal is to estimate the individual treat-
ment eï¬€ect (ITE) Ï„(x) :=E/bracketleftbig
Y1âˆ’Y0|X=x/bracketrightbig
=Ï„1(x)âˆ’Ï„0(x)1, and the average treatment eï¬€ect (ATE)
1The term E/bracketleftbig
Y1âˆ’Y0|X=x/bracketrightbig
is often deï¬ned as the Conditional Average Treatment Eï¬€ect (CATE). In order to maintain
consistency with the notion used in the existing causal representation balancing literature, e.g., Shalit et al. (2017), we refer to
3Under review as submission to TMLR
Ï„ATE :=E/bracketleftbig
Y1âˆ’Y0/bracketrightbig
=/integraltext
XÏ„(x)p(x)dx. We refer to the representations as patterns. The proposed compo-
nents PPBR and PDIG are illustrated in Figure 1, and the necessary representation function Î¦E,Î¦Gand
Î¦Iare illustrated in Figure 2.
2.1 Problem setup
In causal representation balancing works, we denote representation space by RâŠ‚Rd, and Î¦ :X â†’R is
assumed to be a twice-diï¬€erentiable, one-to-one and invertible function with its inverse Î¨ :Râ†’X such
that Î¨(Î¦(x)) =x. The densities of the treated and controlled covariates are denoted by pT=1
x=pT=1(x) :=
p(x|T= 1)andpT=0
x=pT=0(x) :=p(x|T= 0), respectively. Correspondingly, the densities of the treated
and controlled covariates in the representation space are denoted by pT=1
Î¦=pT=1
Î¦(r) :=pÎ¦(r|T= 1)and
pT=0
Î¦=pT=0
Î¦(r) :=pÎ¦(r|T= 0), respectively.
Our study is based on the potential outcome framework (Rubin, 2005). Assumption 1 states standard
and necessary assumptions to ensure treatment eï¬€ects are identiï¬able. Before proceeding with theoretical
analysis, we also present some necessary terms and deï¬nitions in Deï¬nition 1.
Assumption 1 (Consistency, Overlap, and Unconfoundedness) .Consistency: If the treatment is t, then
the observed outcome equals Yt. Overlap: The propensity score is bounded away from 0to1:0<e(x)<1.
Unconfoundedness: YtâŠ¥ âŠ¥T|X,âˆ€tâˆˆ{0,1}.
Deï¬nition 1. Leth:RÃ—{ 0,1}â†’Ybe an hypothesis deï¬ned over the representation space Rsuch that
h(Î¦(x),t)estimatesyt, andL:YÃ—Yâ†’ R+be a loss function (e.g., L(y,y/prime) = (yâˆ’y/prime)2). If we deï¬ne the
expected loss for (x,t)as/lscripth,Î¦(x,t) =/integraltext
YL(yt,h(Î¦(x),t))p(yt|x)dyt, we then have factual and counterfactual
losses, as well as them on the treated and controlled:
/epsilon1F(h,Î¦) =/integraldisplay
XÃ—{ 0,1}/lscripth,Î¦(x,t)p(x,t)dxdt, /epsilon1 CF(h,Î¦) =/integraldisplay
XÃ—{ 0,1}/lscripth,Î¦(x,t)p(x,1âˆ’t)dxdt,
/epsilon1T=1
F(h,Î¦) =/integraldisplay
X/lscripth,Î¦(x,1)pT=1(x)dx, /epsilon1T=0
F(h,Î¦) =/integraldisplay
X/lscripth,Î¦(x,0)pT=0(x)dx,
/epsilon1T=1
CF(h,Î¦) =/integraldisplay
X/lscripth,Î¦(x,1)pT=0(x)dx, /epsilon1T=0
CF(h,Î¦) =/integraldisplay
X/lscripth,Î¦(x,0)pT=1(x)dx.
If we letf(x,t)beh(Î¦(x),t), wheref:XÃ—{ 0,1}â†’Yis a prediction function for outcome, then the
estimated ITE over fis deï¬ned as Ë†Ï„f(x) :=f(x,1)âˆ’f(x,0). Finally, a better treatment eï¬€ect estimation
can be reformulated as a smaller error in Precision in the expected Estimation of Heterogeneous Eï¬€ect
(PEHE):
/epsilon1PEHE (f) =/integraldisplay
XL(Ë†Ï„f(x),Ï„(x))p(x)dx. (1)
Here,/epsilon1PEHE (f)can also be denoted by /epsilon1PEHE (h,Î¦)if we letf(x,t)beh(Î¦(x),t).
3 Theoretical Results
In this section, we ï¬rst prove /epsilon1PEHEis bounded by /epsilon1Fand/epsilon1CFin Lemma 1. Next, we revisit and extend
the upper bound (Theorem 1) concerning the group distance minimization guided method in Section 3.1.
Section 3.2 further discusses the new concept of propensity confusion and the theoretical results based on
the individual propensity confusion guided method (Theorem 2). Proofs and additional theoretical results
are deferred to Appendix.
Lemma 1. Let functions handÎ¦be as deï¬ned in Deï¬nition 1, and Lbe the squared loss function. Recall that
Ï„t(x) =E[Yt|X=x]. Deï¬ning Ïƒ2
y= min{Ïƒ2
yt(p(x,t)),Ïƒ2
yt(p(x,1âˆ’t))}âˆ€tâˆˆ{0,1}, whereÏƒ2
yt(p(x,t)) =/integraltext
XÃ—{ 0,1}Ã—Y(ytâˆ’Ï„t(x))2p(yt|x)p(x,t)dytdxdt, we have
/epsilon1PEHE (h,Î¦)â‰¤2(/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦)âˆ’2Ïƒ2
y).
this term as ITE throughout this paper. Note that the original deï¬nition of ITE for the i-th individual is commonly expressed
as the diï¬€erence between their potential outcomes, represented as Y1
iâˆ’Y0
i.
4Under review as submission to TMLR
Note that similar results will hold as long as Ltakes forms that satisfy the triangle inequality, so Lis not
limited to the squared loss. For instance, we give the result for absolute loss in Lemma 6 in Appendix. This
extends the result shown in Shalit et al. (2017) that Lonly takes the squared loss.
3.1 GNet: Group Distance Minimization Guided Representation Balancing
Previous causal learning models commonly adopt the group distance minimization guided approach to seek
representation balancing via minimizing the distance measured by the Integral Probability Metric (IPM)
deï¬ned in Deï¬nition 2.
Deï¬nition 2. LetGbe a function family consisting of functions g:Sâ†’R. For a pair of distributions p1,
p2overS, the Integral Probability Metric is deï¬ned as
IPMG(p1,p2) := sup
gâˆˆG|/integraldisplay
Sg(s)(p1(s)âˆ’p2(s))ds|.
IfGis the family of 1-Lipschitz functions, we can obtain the so-called 1-Wasserstein distance, denoted by
Wass (p1,p2)(Sriperumbudur et al., 2012). Next, we present the bounds for counterfactual error /epsilon1CFand
ITE error/epsilon1PEHEusing Wasserstein distance in Theorem 1.
Theorem 1. LetÎ¦ :X â†’ R be an invertible representation with Î¨being its inverse. Deï¬ne
Ïƒ2
y= min{Ïƒ2
yt(p(x,t)),Ïƒ2
yt(p(x,1âˆ’t))}andAy= max{Ayt(p(x,t)),Ayt(p(x,1âˆ’t))} âˆ€tâˆˆ {0,1},
whereÏƒ2
yt(p(x,t)) =/integraltext
XÃ—{ 0,1}Ã—Y(ytâˆ’Ï„t(x))2p(yt|x)p(x,t)dytdxdtandAyt(p(x,t)) =/integraltext
XÃ—{ 0,1}Ã—Y|ytâˆ’
Ï„t(x)|p(yt|x)p(x,t)dytdxdtâˆ€tâˆˆ{0,1}. LetpT=1
Î¦(r),pT=0
Î¦(r)be as deï¬ned before, h:RÃ—{ 0,1}â†’Y,
u:=Pr(T= 1)andGbe the family of 1-Lipschitz functions. Assume there exists a constant BÎ¦â‰¥0, such
that fortâˆˆ{0,1}, the function gÎ¦,h(r,t) :=1
BÎ¦Â·/lscripth,Î¦(Î¨(r),t)âˆˆG. IfLis a loss function that satisï¬es the
triangle inequality, we have
/epsilon1CF(h,Î¦)â‰¤(1âˆ’u)Â·/epsilon1T=1
F(h,Î¦) +uÂ·/epsilon1T=0
F(h,Î¦) +BÎ¦Â·Wass (pT=1
Î¦,pT=0
Î¦). (2)
Let loss function Lbe the squared loss such that L(y1,y2) = (y1âˆ’y2)2. Then we have:
/epsilon1PEHE (h,Î¦)â‰¤2(/epsilon1T=1
F(h,Î¦) +/epsilon1T=0
F(h,Î¦) +BÎ¦Â·Wass (pT=1
Î¦,pT=0
Î¦)âˆ’2Ïƒ2
y). (3)
Let loss function Lbe the absolute loss such that L(y1,y2) =|y1âˆ’y2|. Then we have:
/epsilon1PEHE (h,Î¦)â‰¤/epsilon1T=1
F(h,Î¦) +/epsilon1T=0
F(h,Î¦) +BÎ¦Â·Wass (pT=1
Î¦,pT=0
Î¦) + 2Ay. (4)
Our Theorem 1 is a more general result compared to previous literature since it holds for any Lthat takes
forms satisfying the triangle inequality. For instance, Theorem 1 will reduce to the results in Shalit et al.
(2017) ifLis the squared loss as shown in equation 3. We also give the result for absolute loss in Theorem
1 as shown in equation 4. We refer to a model built on Theorem 1 as GNet(aka CFR-Wass in Shalit et al.
(2017)) since it is based on group distance minimization.
3.2 INet: Individual Propensity Confusion Guided Representation Balancing
The propensity score plays a central role to treatment eï¬€ect estimation because it characterizes the prob-
ability that one receives treatment (Rosenbaum & Rubin, 1983). Unlike previous studies that primarily
employ propensity scores for matching or weighting, we emphasize that the propensity score can also serve
as a natural indicator of whether representations are adequately balanced. Speciï¬cally, when it becomes
challenging to distinguish whether each unit in the representation space is treated or controlled, the repre-
sentations are believed adequately balanced. Consequently, the concept of representation balancing can be
intuitively understood as propensity confusion, which provides a logical interpretation and justiï¬cation for
minimizing theH-divergence-based error bound for ITE. In the following content, we will ï¬rst establish the
upper bounds for counterfactual error and ITE error utilizing the H-divergence, as stated in Theorem 2.
5Under review as submission to TMLR
Deï¬nition 3. Given a pair of distributions p1,p2overS, and a hypothesis binary function class H, the
H-divergence between p1andp2is deï¬ned as
dH(p1,p2) := 2 sup
Î·âˆˆH|Prp1[Î·(s) = 1]âˆ’Prp2[Î·(s) = 1]|. (5)
Theorem 2. LetÎ¦ :X â†’ R be an invertible representation with Î¨being its inverse. Deï¬ne
Ïƒ2
y= min{Ïƒ2
yt(p(x,t)),Ïƒ2
yt(p(x,1âˆ’t))}andAy= max{Ayt(p(x,t)),Ayt(p(x,1âˆ’t))} âˆ€tâˆˆ {0,1},
whereÏƒ2
yt(p(x,t)) =/integraltext
XÃ—{ 0,1}Ã—Y(ytâˆ’Ï„t(x))2p(yt|x)p(x,t)dytdxdtandAyt(p(x,t)) =/integraltext
XÃ—{ 0,1}Ã—Y|ytâˆ’
Ï„t(x)|p(yt|x)p(x,t)dytdxdtâˆ€tâˆˆ{0,1}. LetpT=1
Î¦(r),pT=0
Î¦(r)be as deï¬ned before, h:RÃ—{ 0,1}â†’Y,
u:=Pr(T= 1)andHbe the family of binary functions. Assume that there exists a constant Kâ‰¥0such
that/integraltext
YL(y,y/prime)dyâ‰¤Kâˆ€y/primeâˆˆY. IfLis a loss function that satisï¬es the triangle inequality, we have
/epsilon1CF(h,Î¦)â‰¤(1âˆ’u)Â·/epsilon1T=1
F(h,Î¦) +uÂ·/epsilon1T=0
F(h,Î¦) +K
2dH(pT=1
Î¦,pT=0
Î¦). (6)
Let loss function Lbe the squared loss such that L(y1,y2) = (y1âˆ’y2)2. Then we have:
/epsilon1PEHE (h,Î¦)â‰¤2(/epsilon1T=1
F(h,Î¦) +/epsilon1T=0
F(h,Î¦) +K
2dH(pT=1
Î¦,pT=0
Î¦)âˆ’2Ïƒ2
y). (7)
Let loss function Lbe the absolute loss such that L(y1,y2) =|y1âˆ’y2|. Then we have:
/epsilon1PEHE (h,Î¦)â‰¤/epsilon1T=1
F(h,Î¦) +/epsilon1T=0
F(h,Î¦) +K
2dH(pT=1
Î¦,pT=0
Î¦) + 2Ay. (8)
The details of the proof of Theorem 2 are given in Theorem 2 in Appendix. Theorem 2 holds for forms of
Las long asLtakes forms that satisfy the triangle inequality. For example, we give the result for squared
loss in equation 7, and the result for absolute loss in equation 8. Note that detailed proofs of Theorem 2 in
Appendix suggest that our theoretical derivations are not trivial extensions from other H-divergence related
works (Ben-David et al., 2006; 2010; Ganin et al., 2016) and causal representation balancing works (Shalit
et al., 2017; Johansson et al., 2022), which is also one of our main theoretical contributions. We refer to a
model built on Theorem 2 as INetsince it is based on individual propensity confusion.
4 Method
In the preceding section, we presented theoretical results that guarantee the rationale behind representation
balancingmethodsrelyingonWassersteindistanceand H-divergence. MovingontoSection4.1, wewillbegin
by revisiting GNet, which can be considered as CFRNet Shalit et al. (2017), a Wasserstein distance-based
representation balancing network. Additionally, we will demonstrate how Theorem 2 can be connected with
propensity confusion, leading us to introduce INet, a H-divergence-based representation balancing network.
Subsequently, inSection4.2, we willintroducethePDIGand PPBRcomponentsforrepresentationbalancing
within the scheme of decomposed patterns. Building upon GNet, INet, PPBR, and PDIG, we will design
DIGNet, a novel representation balancing network with decomposed patterns.
4.1 Representation Balancing without decomposed Patterns
In representation balancing models, given the input data tuples (x,t,y) ={(xi,ti,yi)}N
i=1, the original
covariates xare extracted by some representation function Î¦(Â·), and representations Î¦(x)are then fed
into the outcome functions h1(Â·) :=h(Â·,1)andh0(Â·) :=h(Â·,0)that estimate the potential outcome y1and
y0, respectively. Finally, the factual outcome can be predicted by ht(Â·) =th1(Â·) + (1âˆ’t)h0(Â·), and the
corresponding outcome loss is
Ly(x,t,y; Î¦,ht) =1
NN/summationdisplay
i=1L(ht(Î¦(xi)),yi). (9)
If models such as GNet and INet do not have decomposition modes, both outcome prediction and represen-
tation balancing will rely on the extracted features Î¦(x). Below we will introduce the objectives of GNet
and INet.
6Under review as submission to TMLR
Objective of GNet. GNet learns the balancing patterns over Î¦by minimizing the group distance loss
LG(x,t; Î¦) =Wass ({Î¦(xi)}i:ti=0,{Î¦(xi)}i:ti=1). If the original covariates xare extracted by the feature
extractor Î¦E(Â·), then the ï¬nal objective of GNet is
min
Î¦E,htLy(x,t,y; Î¦E,ht) +Î±1LG(x,t; Î¦E). (10)
For the convenience of the reader, we illustrate the structure of GNet in Figure 2(a).
Objective of INet. Next, we detail how Theorem 2 is related to propensity confusion and give the
objective of INet. Let I(a)be an indicator function that gives 1ifais true, andHbe the family of binary
functions as deï¬ned in Theorem 2. The representation balancing seeks to minimize empirical H-divergence
Ë†dH(pT=1
Î¦,pT=0
Î¦)such that
Ë†dH(pT=1
Î¦,pT=0
Î¦) = 2ï£«
ï£­1âˆ’min
Î·âˆˆHï£®
ï£°1
N/summationdisplay
i:Î·(Î¦(xi))=0I[ti= 1] +1
N/summationdisplay
i:Î·(Î¦(xi))=1I[ti= 0]ï£¹
ï£»ï£¶
ï£¸.(11)
The â€œminâ€ part in equation 11 indicates that the optimal classiï¬er Î·âˆ—âˆˆHminimizes the classiï¬cation
error between the estimated treatment Î·âˆ—(Î¦(xi))and the observed treatment ti, i.e., discriminating whether
Î¦(xi)is controlled ( T= 0) or treated ( T= 1). As a result, Ë†dH(pT=1
Î¦,pT=0
Î¦)will be large if Î·âˆ—can easily
distinguish whether Î¦(xi)is treated or controlled, i.e., the optimal classiï¬cation error is small. In contrast,
Ë†dH(pT=1
Î¦,pT=0
Î¦)will be small if it is hard for Î·âˆ—to determine whether Î¦(xi)is treated or controlled, i.e., the
optimal classiï¬cation error is large. Therefore, the prerequisite of a small H-divergence is to ï¬nd a map Î¦
such that any classiï¬er Î·âˆˆHwill get confused about the probability of Î¦(xi)being treated or controlled. To
achieve this goal, we deï¬ne a discriminator Ï€(r) :Râ†’ [0,1]that estimates the propensity score of r,which
can be regarded as a surrogate for Î·(r). The classiï¬cation error for the ithindividual can be empirically
approximated by the cross-entropy loss between Ï€(Î¦(xi))andti:
Lt(ti,Ï€(Î¦(xi))) =âˆ’[tilogÏ€(Î¦(xi)) + (1âˆ’ti) log(1âˆ’Ï€(Î¦(xi)))]. (12)
As a consequence, we aim to ï¬nd an optimal discriminator Ï€âˆ—for equation 11 such that Ï€âˆ—maximizes the
probability that treatment is correctly classiï¬ed of the total population:
max
Ï€âˆˆHLI(x,t; Î¦,Ï€) = max
Ï€âˆˆH/bracketleftBigg
âˆ’1
NN/summationdisplay
i=1Lt(ti,Ï€(Î¦(xi)))/bracketrightBigg
. (13)
Given the feature extractor Î¦E(Â·), the objective of INet can be formulated as a min-max game:
min
Î¦E,htmax
Ï€Ly(x,t,y; Î¦E,ht) +Î±2LI(x,t; Î¦E,Ï€). (14)
As stated in equation 14, INet achieves the representation balancing through a min-max formulation, fol-
lowing a strategy of empirical approximation of H-divergence in Ganin et al. (2016). In the maximization,
the discriminator Ï€is trained to maximize the probability that treatment is correctly classiï¬ed. This forces
Ï€(Î¦E(xi))closer to the true propensity score e(xi). In the minimization, the feature extractor Î¦Eis trained
to fool the discriminator Ï€. This confuses Ï€such thatÏ€(Î¦E(xi))cannot correctly specify the true propensity
scoree(xi). Eventually, the representations are balanced as it is diï¬ƒcult for Ï€to determine the propensity
ofÎ¦(xi)being treated or controlled. For the convenience of the reader, we illustrate the structure of INet
in Figure 2(b).
4.2 Representation Balancing with Decomposed Patterns
PDIG. Previous demonstrations have shown that GNet is thriving and widely adopted, while INet is
meaningful and interpretable. Nevertheless, they still face the trade-oï¬€ between representation balancing
and outcome modeling. To this end, we expect to capture more eï¬€ective balancing patterns by turning the
7Under review as submission to TMLR
Î¦ğºğº
(a) GNet (CFR-Wass) (b) INet (c) DGNet (d) DINet (e) DIGNetÎ¦ğ¸ğ¸Î¦ğ¼ğ¼
ğœ‹ğœ‹ğœ‹ğœ‹ğœ‹ğœ‹Î¦ğ¸ğ¸
Î¦ğ¼ğ¼Î¦ğ¸ğ¸ Î¦ğ¸ğ¸Î¦ğ¸ğ¸
Î¦ğºğº
Figure 2: Illustrations of the network architecture of the ï¬ve models studied in Section 5.
balancing Patterns into Decompositions of Individual propensity confusion and Group distance minimization
(PDIG). More speciï¬cally, the covariates xare extracted by the feature extractor Î¦E(Â·), and then Î¦E(x)are
fed into the balancing networks Î¦G(Â·)andÎ¦I(Â·)for group distance minimization and individual propensity
confusion, respectively. Finally, the losses for the two separate balancing patterns are
min
Î¦GLG(x,t; Î¦Gâ—¦Î¦E),
min
Î¦Imax
Ï€LI(x,t; Î¦Iâ—¦Î¦E,Ï€). (15)
Here,â—¦denotes the composition of two functions, indicating that Î¦(Â·)inLG(x,t; Î¦)andLI(x,t; Î¦,Ï€)are
replaced by Î¦G(Î¦E(Â·))andÎ¦I(Î¦E(Â·)), respectively.
PPBR. Motivated by the discussion in Section 1, we aim to design a framework that is capable of captur-
ing Patterns of Pre-balancing and Balancing Representations (PPBR) to improve outcome modeling. To this
end, therepresentationbalancingpatterns Î¦G(Î¦E(x))andÎ¦I(Î¦E(x))areï¬rstlearnedover Î¦GandÎ¦I, while
Î¦Eis remained ï¬xed as pre-balancing patterns. Furthermore, we concatenate the balancing representations
Î¦G(Î¦E(x))andÎ¦I(Î¦E(x))with the pre-balancing representations Î¦E(x)as attributes for outcome predic-
tion. Asaresult, theproxyfeaturesusedforoutcomepredictionsare Î¦E(x)âŠ•Î¦G(Î¦E(x))âŠ•Î¦I(Î¦E(x)), where
âŠ•indicates the concatenation by column. For example, if a= [1,2]andb= [3,4], then aâŠ•b= [1,2,3,4].
ObjectiveofDIGNet. CombiningwithPDIGandPPBR,weproposeanewmodelarchitecture, DIGNet,
as illustrated in Figure 2(e). The objective of DIGNet is separated into four stages:
min
Î¦GÎ±1LG(x,t; Î¦Gâ—¦Î¦E), (16)
max
Ï€Î±2LI(x,t; Î¦Iâ—¦Î¦E,Ï€), (17)
min
Î¦IÎ±2LI(x,t; Î¦Iâ—¦Î¦E,Ï€), (18)
min
Î¦E,Î¦I,Î¦G,htLy(x,t,y; Î¦EâŠ•(Î¦Iâ—¦Î¦E)âŠ•(Î¦Gâ—¦Î¦E),ht). (19)
Within each iteration, DIGNet manages to minimize the group distance via equation 16, and plays an
adversarial game to achieve propensity confusion through equation 17 and equation 18. In equation 19,
DIGNet updates both the pre-balancing and balancing patterns Î¦E,Î¦I,Î¦Galong with the outcome function
htto minimize the outcome prediction loss.
DGNet and DINet. For further ablation studies, we also designed two models, DGNet and DINet. The
twomodelscanbeconsideredaseitherDIGNetwithoutPDIG,orGNetandINetwithPPBR.Thestructures
of DGNet and DINet are shown in Figure 2(c) and Figure 2(d), and the objectives of DGNet and DINet are
deferred to Section A.6 in Appendix.
5 Experiments
In non-randomized observational data, the ground truth regarding treatment eï¬€ects remains inaccessible
due to the absence of counterfactual information. Therefore, we use simulated data and semi-synthetic
8Under review as submission to TMLR
Figure 3: T-SNE visualizations of the covariates as Î³varies. Red represents the treatment group and blue
represents the control group. A larger Î³indicates a greater imbalance between the two groups.
benchmark data to test the performance of our methods and other baseline models. In this section, our
primary focus revolves around addressing two key questions:
Q1.Is PDIG helpful in ITE estimation by learning more eï¬€ective balancing patterns without aï¬€ecting
factual outcome prediction? In other words, can DIGNet which incorporates the PDIG structure achieve
superior ITE estimation performances with more balanced representations compared to DGNet and DINet?
Q2.Is PPBR helpful in ITE estimation by improving factual outcome prediction without aï¬€ecting learning
balancing patterns? In other words, can DGNet and DINet that involve PPBR enhance ITE estimation
performances with smaller factual outcome errors compared to standard representation balancing models
such as GNet and INet?
5.1 Experimental Settings
Simulation data. Previous causal inference works assess the model eï¬€ectiveness by varying the distribu-
tion imbalance of covariates in treated and controlled groups at diï¬€erent levels Yao et al. (2018); Yoon et al.
(2018); Du et al. (2021). As suggested in Assaad et al. (2021), we draw 1000observational data points from
the following data generating strategy:
Xiâˆ¼N(0,Ïƒ2Â·[Ï1p1/prime
p+ (1âˆ’Ï)Ip]),
Ti|Xiâˆ¼Bernoulli (1/(1 + exp(âˆ’Î³Xi))),
Y0
i=Î²/prime
0Xi+Î¾i, Y1
i=Î²/prime
1Xi+Î¾i, Î¾iâˆ¼N(0,1).
Here, 1pdenotes the p-dimensional all-ones vector and Ipdenotes the identity matrix of size p. We ï¬x
p= 10,Ï= 0.3,Ïƒ2= 2,Î²/prime
0= [0.3,...,0.3],Î²/prime
1= [1.3,...,1.3]and varyÎ³âˆˆ{0.25,0.5,0.75,1,1.5,2,3}to yield
diï¬€erent levels of selection bias. As seen in Figure 3, selection bias becomes more severe with Î³increasing.
For eachÎ³, we repeat the above data generating process to generate 30diï¬€erent datasets, with each dataset
split by the ratio of 56%/24%/20%as training/validation/test sets.
Semi-synthetic data. The IHDP dataset is introduced by Hill (2011). This dataset consists of 747
samples with 25-dimensional covariates collected from real-world randomized experiments. Selection bias is
created by removing some of treated samples. The goal is to estimate the eï¬€ect of special visits (treatment)
on cognitive scores (outcome). The potential outcomes are generated using the NPCI package Dorie (2021).
We use the same 1000datasets as used in Shalit et al. (2017), with each dataset split by the ratio of
63%/27%/10%as training/validation/test sets.
Models and metrics. In simulation experiments, we perform comprehensive comparisons between INet,
GNet, DINet, DGNet, and DIGNet in terms of the mean and standard error for the following metrics:âˆš/epsilon1PEHE,âˆš/epsilon1CF, andâˆš/epsilon1FwithLdeï¬ned in Deï¬nition 1 being the squared loss, as well as the empirical
approximations of Wass (pT=1
Î¦,pT=0
Î¦)anddH(pT=1
Î¦,pT=0
Î¦)(denoted by Wassand Ë†dH, respectively). Note
that as shown in Figure 2, Wassis over Î¦Efor GNet while over Î¦Gfor DGNet and DIGNet; Ë†dHis over
Î¦Efor INet while over Î¦Ifor DINet and DIGNet. To analyze the source of gain in simulation studies, we
fairly compare models by ensuring that each model shares the same hyperparameters, e.g., learning rate,
the number of layers and units for (Î¦E,Î¦G,Î¦I,ft), and (Î±1,Î±2). Note that we apply an early stopping
9Under review as submission to TMLR
Figure 4: Plots of model performances on test set for diï¬€erent metrics as Î³varies in
{0.25,0.5,0.75,1,1.5,2,3}. Each graph shows the average of 30runs with standard errors shaded.
Figure 5: Plots of model performances on test set forâˆš/epsilon1F,âˆš/epsilon1CF,Ë†dH, andWasswhenÎ³= 3. Each graph
plots the metric for 30runs. MeanÂ±std of each metric averaged across 30runs are reported on the top.
rule to all models as Shalit et al. (2017) do. In IHDP experiment, we useâˆš/epsilon1PEHE, as well as an additional
metric/epsilon1ATE =|Ë†Ï„ATEâˆ’Ï„ATE|to evaluate performances of various causal models (see them in Table 3). More
descriptions of the implementation details, as well as the analysis of training time and training stability, are
detailed in Section A.5 of Appendix.
Device. All the experiments are run on Dell 7920 with one 16-core Intel Xeon Gold 6250 3.90GHz CPU
and three NVIDIA Quadro RTX 6000 GPUs.
5.2 Results and Analysis
Varying selection bias. We ï¬rst make a general comparison between models with the degree of covariate
imbalance increasing, and the relevant results are shown in Figure 4. There are four main observations:
1. DIGNet attains the lowestâˆš/epsilon1PEHEacross all datasets, while GNet have inferior performances than
other models;
2. DINet and DGNet outperform INet and GNet regardingâˆš/epsilon1CFandâˆš/epsilon1PEHE;
3. INet, DINet, and DGNet perform similarly to DIGNet on factual outcome estimations (âˆš/epsilon1F), but
cannot compete with DIGNet in terms of counterfactual estimations (âˆš/epsilon1CF);
4. DIGNet achieves smaller Ë†dH(orWass) than DINet and INet (or DGNet and GNet), especially when
the covariate shift problem is severe (e.g., when Î³ >1).
In conclusion, the above study has produced several noteworthy ï¬ndings. Firstly, ï¬nding (1) reveals that
our proposed DIGNet model consistently performs well in ITE estimation. Secondly, as indicated by ï¬nding
(2), implementing the PPBR approach can enhance the predictive accuracy of factual and counterfactual
outcomes. Lastly, ï¬ndings (3) and (4) highlight the role of PDIG structure in promoting the simultaneous
reinforcement and complementarity of group distance minimization and individual propensity confusion.
10Under review as submission to TMLR
Figure 6: Plots of model performances on test set for diï¬€erent metrics when Î³= 3. Each graph plots the
metric for 30runs, with meanÂ±std averaged across 30runs reported on the top.
Table 1: Training- & test- setâˆš/epsilon1PEHE&/epsilon1ATEwhen
Î³= 3. MeanÂ±standard error of 30runs.
Training set Test setâˆš/epsilon1PEHE /epsilon1ATEâˆš/epsilon1PEHE /epsilon1ATE
GNet 3.30Â±0.15 2.58Â±0.14 3.30Â±0.16 2.59Â±0.14
INet 3.24Â±0.11 2.46Â±0.09 3.22Â±0.12 2.47Â±0.10
DGNet 2.86Â±0.06 2.15Â±0.03 2.83Â±0.07 2.15Â±0.04
DINet 2.70Â±0.06 2.12Â±0.04 2.69Â±0.08 2.13Â±0.05
DIGNet 2.66Â±0.07 2.04Â±0.05 2.63Â±0.07 2.03Â±0.04Table 2: Training- & test- setâˆš/epsilon1PEHE&/epsilon1ATEon
IHDP. MeanÂ±standard error of 100runs.
Training set Test setâˆš/epsilon1PEHE /epsilon1ATEâˆš/epsilon1PEHE /epsilon1ATE
GNet 0.71Â±0.15 0.12Â±0.01 0.77Â±0.18 0.15Â±0.02
INet 0.66Â±0.09 0.13Â±0.01 0.72Â±0.11 0.15Â±0.02
DGNet 0.53Â±0.07 0.11Â±0.01 0.60Â±0.09 0.13Â±0.01
DINet 0.57Â±0.12 0.13Â±0.01 0.60Â±0.11 0.14Â±0.01
DIGNet 0.42Â±0.02 0.11Â±0.01 0.45Â±0.04 0.12Â±0.01
Movingforward, oursubsequentanalysiswillstepfurtherintounderstandingtheeï¬€ectivenessofourproposed
methods, building upon these preliminary conclusions.
Source of gain. To further investigate the above ï¬ndings, we choose the case with high selection bias
(Î³= 3) to explore the source of gain for PDIG and PPBR. We report model performances (mean Â±std)
averaged over 30training and test sets in Table 1 and plot speciï¬c metrics of 30runs on test set in Figure
5 and Figure 6. Below we discuss the source of gain in detail.
(1) Ablation study for PDIG : The PDIG structure is manifest to be eï¬€ective in capturing more balanced
patterns, without aï¬€ecting factual outcome predictions. As depicted in Figure 4, DIGNet exhibits more bal-
anced representations, irrespective of whether the discrepancy is measured by Ë†dHorWass, while DIGNet,
DINet, and DGNet demonstrate comparable estimates of factual outcomes (âˆš/epsilon1F). In particular, by com-
paring DIGNet with DGNet and DINet in Figure 5, we ï¬nd that the PDIG structure does not aï¬€ect the
factual outcome estimation (âˆš/epsilon1F). Nevertheless, DIGNet achieves smaller Ë†dHwith a|1.94/1.96âˆ’1|= 1.0%
reduction (or Wasswith a|0.06/0.10âˆ’1|= 40%reduction) compared with DINet (or DGNet). This indi-
cates that PDIG enables group distance minimization and individual propensity confusion to complement
and reinforce each other, thereby learning better balancing patterns. This advantage translates into superior
counterfactualestimation, withDIGNetreduceingâˆš/epsilon1CFby|2.89/2.95âˆ’1|= 2.0%and|2.89/3.08âˆ’1|= 6.2%
compared to DINet and DGNet, respectively. Consequently, due to the eï¬€ective capture of balancing pat-
terns by PDIG, DIGNet shows superiority in treatment eï¬€ect estimation (âˆš/epsilon1PEHEand/epsilon1ATE) compared to
DGNet and DINet, as demonstrated in Table 1.
(2) Ablation study for PPBR : ThePPBRapproachplaysanessentialroleinimprovingoutcomepredictions,
withoutaï¬€ectinglearningbalancingpatterns. FromFigure6, wegainanimportantinsightthatthediï¬€erence
in learned representation balancing patterns, measured by Wass(orË†dH), between DGNet and GNet (or
DINet and INet), is negligible. This implies that PPBR does not impact the representation balancing task.
However, PPBR can improve the predictive power of factual outcomes, resulting in a |1.07/1.12âˆ’1|= 4.5%
reduction inâˆš/epsilon1Ffor GNet and a|1.07/1.08âˆ’1|= 0.9%reduction for INet. Notably, this improvement is
particularly pronounced in counterfactual estimation, whereâˆš/epsilon1CFis reduced by|3.08/3.55âˆ’1|= 13.2%for
GNet and|2.95/3.47âˆ’1|= 15.0%for INet. Beneï¬ting from the advantage of PPBR, the treatment eï¬€ect
errors (âˆš/epsilon1PEHEand/epsilon1ATE) attained by DINet and DGNet are signiï¬cantly smaller than those attained by
INet and GNet, as shown in Table 1.
11Under review as submission to TMLR
Comparisons on IHDP benchmark. We ï¬rst conduct an ablation study for PDIG and PPBR on 1-100
IHDP datasets and report the results in Table 2. Further, we undergo comparisons between DIGNet and
other causal models on 1-1000 IHDP datasets and report the results in Table 3. Note that â€œ-â€ indicates either
the result is not reproducible or the original paper does not report relevant values. Table 2 shows that DINet
and DGNet are superior to INet and GNet but inferior to DIGNet concerning treatment eï¬€ect estimation,
suggesting that each component of PDIG and PPBR is advantageous for treatment eï¬€ect estimation. For
example, on the test set, DINet reducesâˆš/epsilon1PEHEby|0.60/0.72âˆ’1|= 16.7%for INet, and DIGNet achieves
|0.45/0.60âˆ’1|= 25%error reduction regardingâˆš/epsilon1PEHEfor DINet. This is consistent with the ï¬ndings
before: PPBR and PDIG are beneï¬cial to treatment eï¬€ect estimation. Table 3 demonstrates that models
that involve either propensity score or representation balancing (e.g., DKLITE, CFR-X, BWCFR-X, and
MBRL) attainâˆš/epsilon1PEHEand/epsilon1ATEof0.57âˆ¼0.70and0.13âˆ¼0.19, respectively. Compared to the second-
best method, DIGNet improves performance by |0.45/0.57âˆ’1|= 21%and|0.12/0.13âˆ’1|= 7.7%regardingâˆš/epsilon1PEHEand/epsilon1ATE, respectively, revealingtheprominentoutperformanceoftheproposedmethod. Moreover,
itisnoticeablethatDIGNetachievesthelowesterrorsoverwhelminglyacrossdatasetsandmetrics, indicating
that the proposed method has the most robust performance.
6 Conclusion
Table 3: Training- & test- setâˆš/epsilon1PEHE&/epsilon1ATEon IHDP. Mean Â±
standard error of 1000runs.
Training set Test setâˆš/epsilon1PEHE/epsilon1ATEâˆš/epsilon1PEHE/epsilon1ATE
OLS/LR 1(Johansson et al., 2016) 5.8Â±.3.73Â±.04 5.8Â±.3.94Â±.06
OLS/LR 2(Johansson et al., 2016) 2.4Â±.1.14Â±.01 2.5Â±.1.31Â±.02
k-NN (Crump et al., 2008) 2.1Â±.1.14Â±.01 4.1Â±.2.79Â±.05
BART (Chipman et al., 2010) 2.1Â±.1.23Â±.01 2.3Â±.1.34Â±.02
CF (Wager & Athey, 2018) 3.8Â±.2.18Â±.01 3.8Â±.2.40Â±.03
CEVAE (Louizos et al., 2017) 2.7Â±.1.34Â±.01 2.6Â±.1.46Â±.02
SITE (Yao et al., 2018) .69Â±.0.22Â±.01.75Â±.0.24Â±.01
GANITE (Yoon et al., 2018) 1.9Â±.4.43Â±.05 2.4Â±.4.49Â±.05
BLR (Johansson et al., 2016) 5.8Â±.3.72Â±.04 5.8Â±.3.93Â±.05
BNN (Johansson et al., 2016) 2.2Â±.1.37Â±.03 2.1Â±.1.42Â±.03
TARNet (Shalit et al., 2017) .88Â±.0.26Â±.01.95Â±.0.28Â±.01
CFR-Wass (GNet) (Shalit et al., 2017) .73Â±.0.12Â±.01.81Â±.0.15Â±.01
Dragonnet (Shi et al., 2019) 1.3Â±.4.14Â±.01 1.3Â±.5.20Â±.05
DKLITE (Zhang et al., 2020) .52Â±.0âˆ’.65Â±.03âˆ’
CFR-ISW (Hassanpour & Greiner, 2019a) âˆ’ âˆ’ .70Â±.0.19Â±.03
BWCFR-OW (Assaad et al., 2021) âˆ’ âˆ’ .65Â±.0.18Â±.01
BWCFR-MW (Assaad et al., 2021) âˆ’ âˆ’ .63Â±.0.19Â±.01
BWCFR-TruncIPW (Assaad et al., 2021) âˆ’ âˆ’ .63Â±.0.19Â±.01
MBRL (Huang et al., 2022a) .52 Â±.0 .12Â±.01 .57Â±.0 .13Â±.01
DIGNet (Ours) .42Â±.0.11Â±.01.45Â±.0.12Â±.01In this paper, we derive a the-
oretical ITE bound based on H-
divergence and connect representa-
tion balancing with the concept of
propensity confusion. More impor-
tantly, we propose the components
of PDIG and PPBR, on which we
construct a decomposition network
structure DIGNet for treatment ef-
fect estimation. Comprehensive ex-
periments verify that PDIG and
PPBR follow diï¬€erent pathways to
improve the generalization of coun-
terfactual and ITE estimation, and
such improvements are conï¬rmed
to be very signiï¬cant. In particu-
lar, PDIG helps the model capture
more eï¬€ective representation bal-
ancing patterns without aï¬€ecting
outcome prediction, while PPBR
preservespatternspredictiveof out-
comes to enhance the outcome pre-
diction without inï¬‚uencing learning balancing patterns. We sincerely hope that our ï¬ndings can constitute
an important step to inspire more research concerning the generalization of representation balancing models
in counterfactual estimation.
Our paper primarily oï¬€ers eï¬€ective empirical solutions to address the trade-oï¬€ challenge between domain
invariance and domain discrimination given the absence of a well-established theoretical solution in the
current research ï¬eld. Therefore, it is also important to step beyond these empirical insights into future
theoretical studies aimed at resolving the trade-oï¬€ problem. A promising avenue for future theoretical
investigations involves the development of new distributional divergences or theoretical upper bounds that
can robustly handle the trade-oï¬€ issue. Exploring the integration of distributionally robust optimization and
nonparametric inference methods in this context would be intriguing. Furthermore, deriving an upper bound
with an analytically optimal solution to the trade-oï¬€ problem could be valuable, albeit possibly requiring
additional assumptions. Empirical studies can focus on discouraging the redundancy of shared information
within the PDIG structure and improving the optimization eï¬ƒcacy of DIGNetâ€™s objective.
12Under review as submission to TMLR
References
Serge Assaad, Shuxi Zeng, Chenyang Tao, Shounak Datta, Nikhil Mehta, Ricardo Henao, Fan Li, and
Lawrence Carin. Counterfactual representation learning with balancing weights. In International
Conference onArtiï¬cial Intelligence andStatistics, pp. 1972â€“1980. PMLR, 2021.
Susan Athey and Stefan Wager. Estimating treatment eï¬€ects with causal forests: An application.
Observational Studies, 5(2):37â€“51, 2019.
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain
adaptation. Advances inneuralinformation processing systems, 19, 2006.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from diï¬€erent domains. Machine learning, 79(1):151â€“175, 2010.
Ioana Bica, Ahmed M Alaa, Craig Lambert, and Mihaela Van Der Schaar. From real-world patient data to
individualized treatment eï¬€ects using machine learning: current and future methods to address underlying
challenges. ClinicalPharmacology &Therapeutics, 109(1):87â€“100, 2021a.
Ioana Bica, Daniel Jarrett, Alihan HÃ¼yÃ¼k, and Mihaela van der Schaar. Learning â€what-ifâ€ explanations
for sequential decision-making. In International Conference onLearning Representations, 2021b. URL
https://openreview.net/forum?id=h0de3QWtGG .
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duï¬‚o, Christian Hansen, Whitney Newey,
and James Robins. Double/debiased machine learning for treatment and structural parameters. The
Econometrics Journal, 21(1):C1â€“C68, 2018.
Hugh A Chipman, Edward I George, and Robert E McCulloch. Bart: Bayesian additive regression trees.
TheAnnalsofApplied Statistics, 4(1):266â€“298, 2010.
Zhixuan Chu, Stephen L. Rathbun, and Sheng Li. Graph infomax adversarial learning for treatment eï¬€ect
estimation with networked observational data. In KDD, pp. 176â€“184, 2021. URL https://doi.org/10.
1145/3447548.3467302 .
RichardKCrump, VJosephHotz, GuidoWImbens, andOscarAMitnik. Nonparametrictestsfortreatment
eï¬€ect heterogeneity. TheReviewofEconomics andStatistics, 90(3):389â€“405, 2008.
Alicia Curth and Mihaela van der Schaar. On inductive biases for heterogeneous treatment eï¬€ect estimation.
Advances inNeuralInformation Processing Systems, 34:15883â€“15894, 2021.
Alicia Curth, David Svensson, Jim Weatherall, and Mihaela van der Schaar. Really doing great at estimating
cate? acriticallookatmlbenchmarkingpracticesintreatmenteï¬€ectestimation. In Thirty-ï¬fth conference
onneuralinformation processing systemsdatasets andbenchmarks track(round2), 2021.
Marco Cuturi and Arnaud Doucet. Fast computation of wasserstein barycenters. In International conference
onmachine learning, pp. 685â€“693. PMLR, 2014.
Vincent Dorie. Nonparametric methods for causal inference. https://github.com/vdorie/npci, 2021.
Xin Du, Lei Sun, Wouter Duivesteijn, Alexander Nikolaev, and Mykola Pechenizkiy. Adversarial balancing-
based representation learning for causal eï¬€ect inference with observational data. DataMiningand
Knowledge Discovery, 35(4):1713â€“1738, 2021.
MaxHFarrell. Robustinferenceonaveragetreatmenteï¬€ectswithpossiblymorecovariatesthanobservations.
JournalofEconometrics, 189(1):1â€“23, 2015.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette,
Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. Thejournalof
machine learning research, 17(1):2096â€“2030, 2016.
13Under review as submission to TMLR
Ruocheng Guo, Lu Cheng, Jundong Li, P Richard Hahn, and Huan Liu. A survey of learning causality with
data: Problems and methods. ACMComputing Surveys(CSUR), 53(4):1â€“37, 2020a.
Ruocheng Guo, Jundong Li, Yichuan Li, K SelÃ§uk Candan, Adrienne Raglin, and Huan Liu. Ignite: A
minimax game toward learning individual treatment eï¬€ects from networked observational data. In IJCAI,
pp. 4534â€“4540, 2020b.
Ruocheng Guo, Jundong Li, and Huan Liu. Learning individual causal eï¬€ects from networked observational
data. In Proceedings ofthe13thInternational Conference onWebSearchandDataMining, pp. 232â€“240,
2020c.
Negar Hassanpour and Russell Greiner. Counterfactual regression with importance sampling weights. In
IJCAI, pp. 5880â€“5887, 2019a.
Negar Hassanpour and Russell Greiner. Learning disentangled representations for counterfactual regression.
InInternational Conference onLearning Representations, 2019b.
Jennifer L Hill. Bayesian nonparametric modeling for causal inference. Journal ofComputational and
Graphical Statistics, 20(1):217â€“240, 2011.
Yiyan Huang, Cheuk Hang Leung, Xing Yan, Qi Wu, Nanbo Peng, Dongdong Wang, and Zhixiang Huang.
The causal learning of retail delinquency. In Proceedings oftheAAAIConference onArtiï¬cial Intelligence,
volume 35, pp. 204â€“212, 2021.
Yiyan Huang, Cheuk Hang Leung, Shumin Ma, Qi Wu, Dongdong Wang, and Zhixiang Huang. Moderately-
balanced representation learning for treatment eï¬€ects with orthogonality information. In Paciï¬cRim
International Conference onArtiï¬cial Intelligence, pp. 3â€“16. Springer, 2022a.
YiyanHuang, CheukHangLeung, QiWu, XingYan, ShuminMa, ZhiriYuan, DongdongWang, andZhixiang
Huang. Robust causal learning for the estimation of average treatment eï¬€ects. In 2022International Joint
Conference onNeuralNetworks (IJCNN 2022). IEEE, 2022b.
GuidoWImbensandJeï¬€reyMWooldridge. Recentdevelopmentsintheeconometricsofprogramevaluation.
Journalofeconomic literature, 47(1):5â€“86, 2009.
Fredrik Johansson, Uri Shalit, and David Sontag. Learning representations for counterfactual inference. In
International conference onmachine learning, pp. 3020â€“3029. PMLR, 2016.
Fredrik D. Johansson, Uri Shalit, Nathan Kallus, and David Sontag. Generalization bounds and repre-
sentation learning for estimation of potential outcomes and causal eï¬€ects. JournalofMachine Learning
Research, 23(166):1â€“50, 2022. URL http://jmlr.org/papers/v23/19-511.html .
Kun Kuang, Peng Cui, Bo Li, Meng Jiang, Shiqiang Yang, and Fei Wang. Treatment eï¬€ect estimation with
data-driven variable decomposition. In Proceedings oftheAAAIConference onArtiï¬cial Intelligence,
volume 31, 2017.
SÃ¶ren R KÃ¼nzel, Jasjeet S Sekhon, Peter J Bickel, and Bin Yu. Metalearners for estimating heterogeneous
treatment eï¬€ects using machine learning. Proceedings ofthenational academy ofsciences, 116(10):4156â€“
4165, 2019.
Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip S Yu. Transfer joint matching for
unsupervised domain adaptation. In Proceedings oftheIEEEconference oncomputer visionandpattern
recognition, pp. 1410â€“1417, 2014.
Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling. Causal eï¬€ect
inference with deep latent-variable models. Advances inneuralinformation processing systems, 30, 2017.
Maggie Makar, Fredrik Johansson, John Guttag, and David Sontag. Estimation of bounds on potential
outcomes for decision making. In International Conference onMachine Learning, pp. 6661â€“6671. PMLR,
2020.
14Under review as submission to TMLR
Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treatment eï¬€ects. Biometrika, 108
(2):299â€“319, 2021.
Zhaozhi Qian, Yao Zhang, Ioana Bica, Angela Wood, and Mihaela van der Schaar. Synctwin: Treatment
eï¬€ect estimation with longitudinal outcomes. Advances inNeuralInformation Processing Systems, 34:
3178â€“3190, 2021.
Paul R Rosenbaum and Donald B Rubin. The central role of the propensity score in observational studies
for causal eï¬€ects. Biometrika, 70(1):41â€“55, 1983.
Donald B Rubin. Causal inference using potential outcomes: Design, modeling, decisions. Journalofthe
American Statistical Association, 100(469):322â€“331, 2005.
Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: Fromtheorytoalgorithms.
Cambridge university press, 2014.
Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment eï¬€ect: generalization
bounds and algorithms. In International Conference onMachine Learning, pp. 3076â€“3085. PMLR, 2017.
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided representation learning for
domain adaptation. In Proceedings oftheAAAIConference onArtiï¬cial Intelligence, volume 32, 2018.
Claudia Shi, David Blei, and Victor Veitch. Adapting neural networks for the estimation of treatment eï¬€ects.
Advances inneuralinformation processing systems, 32, 2019.
Bharath K Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard SchÃ¶lkopf, and Gert RG Lanckriet.
On the empirical estimation of integral probability metrics. Electronic JournalofStatistics, 6:1550â€“1599,
2012.
Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment eï¬€ects using random
forests.JournaloftheAmerican Statistical Association, 113(523):1228â€“1242, 2018.
Liuyi Yao, Sheng Li, Yaliang Li, Mengdi Huai, Jing Gao, and Aidong Zhang. Representation learning for
treatment eï¬€ect estimation from observational data. Advances inNeuralInformation Processing Systems,
31, 2018.
Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, and Aidong Zhang. A survey on causal inference.
ACMTransactions onKnowledge Discovery fromData(TKDD), 15(5):1â€“46, 2021.
Jinsung Yoon, James Jordon, and Mihaela Van Der Schaar. Ganite: Estimation of individualized treatment
eï¬€ects using generative adversarial nets. In International Conference onLearning Representations, 2018.
Yao Zhang, Alexis Bellot, and Mihaela Schaar. Learning overlapping representations for the estimation of
individualized treatment eï¬€ects. In International Conference onArtiï¬cial Intelligence andStatistics, pp.
1005â€“1014. PMLR, 2020.
Guanglin Zhou, Lina Yao, Xiwei Xu, Chen Wang, and Liming Zhu. Cycle-balanced representation learning
for counterfactual inference. In Proceedings ofthe2022SIAMInternational Conference onDataMining
(SDM), pp. 442â€“450. SIAM, 2022.
A Appendix
A.1 Preliminaries
We start by making some assumptions about the distribution we concern, and give some necessary deï¬nitions
and results. We make the strong ignorability assumption, which assume that there exists a joint distribution
p(X,T,Y0,Y1)such that conditioning on covariate X, the potential outcomes Y0,Y1are independent of T,
i.e.,(Y0,Y1)âŠ¥ âŠ¥T|X, and the propensity score e(x) :=p(T= 1|X=x)is bounded away from 0 to 1, i.e.
15Under review as submission to TMLR
0<e(x)<1. Recall that we also assume consistency, i.e., if the treatment is t, the observed outcome equals
Yt. These assumptions are crucial conditions that make individual treatment eï¬€ect identiï¬able (Imbens &
Wooldridge, 2009).
Deï¬nition 1. The individual treatment eï¬€ect (ITE) for unit xis:
Ï„(x) =E/bracketleftbig
Y1âˆ’Y0|X=x/bracketrightbig
.
LetÏ„t(x) :=E[Yt|X=x], we haveÏ„(x) =Ï„1(x)âˆ’Ï„0(x). Letf:XÃ—{ 0,1}â†’Ybe a prediction function.
Deï¬nition 2. The individual treatment eï¬€ect estimate can be deï¬ned as:
Ë†Ï„f(x) :=f(x,1)âˆ’f(x,0).
Deï¬nition 3. (Hill, 2011) Let L:YÃ—Yâ†’ R+be a loss function. The expected Precision in Estimation of
Heterogeneous Eï¬€ect (PEHE) loss of fis:
/epsilon1PEHE (f) =/integraldisplay
XL(Ë†Ï„f(x),Ï„(x))p(x)dx.
Deï¬nition4. The covariatesâ€™ distributions in the treated and controlled groups can be denoted by pT=1(x) :=
p(x|T= 1)andpT=0(x) :=p(x|T= 0), respectively.
In our causal representation balancing approach, we assume that the representation function Î¦ :Xâ†’Ris
a twice-diï¬€erentiable, one-to-one function, where RâŠ‚Rdis the representation space. Then, we can denote
Î¨ :Râ†’Xby the inverse of Î¦and the induced distribution of rbypÎ¦.
Deï¬nition 5. The covariatesâ€™ distributions in the treated and controlled groups over Rcan be denoted by
pT=1
Î¦(r) :=pÎ¦(r|T= 1)andpT=0
Î¦(r) :=pÎ¦(r|T= 0), respectively.
Leth:RÃ—{ 0,1}â†’Ybe an hypothesis deï¬ned over the representation space R, such that f(x,t) =
h(Î¦(x),t).
Deï¬nition 6. The expected loss for the unit and treatment pair (x,t)is :
/lscripth,Î¦(x,t) =/integraldisplay
YL(yt,h(Î¦(x),t))p(yt|x)dyt.
Deï¬nition 7. The expected factual loss and counterfactual losses of handÎ¦are, respectively:
/epsilon1F(h,Î¦) =/integraldisplay
XÃ—{ 0,1}/lscripth,Î¦(x,t)p(x,t)dxdt,
/epsilon1CF(h,Î¦) =/integraldisplay
XÃ—{ 0,1}/lscripth,Î¦(x,t)p(x,1âˆ’t)dxdt.
Deï¬nition 8. The expected treated and control losses are:
/epsilon1T=1
F(h,Î¦) =/integraldisplay
X/lscripth,Î¦(x,1)pT=1(x)dx,
/epsilon1T=0
F(h,Î¦) =/integraldisplay
X/lscripth,Î¦(x,0)pT=0(x)dx,
/epsilon1T=1
CF(h,Î¦) =/integraldisplay
X/lscripth,Î¦(x,1)pT=0(x)dx,
/epsilon1T=0
CF(h,Î¦) =/integraldisplay
X/lscripth,Î¦(x,0)pT=1(x)dx.
Letu:=Pr(T= 1)be the proportion of treated in the population. We then have the result:
16Under review as submission to TMLR
Lemma 1.
/epsilon1F(h,Î¦) =uÂ·/epsilon1T=1
F(h,Î¦) + (1âˆ’u)Â·/epsilon1T=0
F(h,Î¦),
/epsilon1CF(h,Î¦) = (1âˆ’u)Â·/epsilon1T=1
CF(h,Î¦) +uÂ·/epsilon1T=0
CF(h,Î¦).
Noting that p(x,t) =uÂ·pT=1(x) + (1âˆ’u)Â·pT=0(x), the results can be easily obtained from the Deï¬nitions
7 and 8. This Lemma follows the results in Shalit et al. (2017).
Deï¬nition 9. LetGbe a function family consisting of functions g:Sâ†’R. For a pair of distributions p1,
p2overS, deï¬ne the Integral Probability Metric:
IPMG(p1,p2) = sup
gâˆˆG|/integraldisplay
Sg(s)(p1(s)âˆ’p2(s))ds|.
LetGbe the family of 1-Lipschitz functions, we obtain the so-called 1-Wasserstein distance between distri-
butions, which we denote Wass (p1,p2)(Sriperumbudur et al., 2012).
Deï¬nition 10. Given a pair of distributions p1,p2overS, and a hypothesis binary function class H, the
H-divergence between p1andp2is
dH(p1,p2) = 2supÎ·âˆˆH|Prp1[Î·(s) = 1]âˆ’Prp2[Î·(s) = 1]|.
Lemma 2. LetGin Deï¬nition 9 be the family of binary functions. Then we obtain
supÎ·âˆˆH/vextendsingle/vextendsingle/integraltext
SÎ·(s)(p1(s)âˆ’p2(s))ds/vextendsingle/vextendsingle=1
2dH(p1,p2).
Proof.LetI(Â·)denotes an indicator function.
dH(p1,p2)
=2 sup
Î·âˆˆH/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplay
Î·(s)=1(p1(s)âˆ’p2(s))ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
=2 sup
Î·âˆˆH/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplay
SI(Î·(s) = 1)(p1(s)âˆ’p2(s))ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle
=2 sup
Î·âˆˆH/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplay
SÎ·(s)(p1(s)âˆ’p2(s))ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle(20)
The last equation is because an indicator function is also a binary function.
A.2 Bounds for conterfactual error /epsilon1CF
We ï¬rst derive the counterfactual error bounds when using Wasserstein distance. The following Lemma 3
and corresponding proof is identical to the Lemma 1 in (Shalit et al., 2017).
Lemma 3. LetÎ¦ :Xâ†’Rbe an invertible representation with Î¨being its inverse. Let pT=1
Î¦(r),pT=0
Î¦(r)
be as deï¬ned before. Let h:RÃ—{ 0,1}â†’Y,u:=Pr(T= 1)andGbe the family of 1-Lipschitz functions.
Assume there exists a constant BÎ¦â‰¥0, such that for t= 0,1, the function gÎ¦,h(r,t) :=1
BÎ¦Â·/lscripth,Î¦(Î¨(r),t)âˆˆG.
Then we have:
/epsilon1CF(h,Î¦)â‰¤(1âˆ’u)Â·/epsilon1T=1
F(h,Î¦) +uÂ·/epsilon1T=0
F(h,Î¦) +BÎ¦Â·Wass (pT=1
Î¦,pT=0
Î¦).
17Under review as submission to TMLR
Proof.
/epsilon1CF(h,Î¦)âˆ’[(1âˆ’u)Â·/epsilon1T=1
F(h,Î¦) +uÂ·/epsilon1T=0
F(h,Î¦)]
=[(1âˆ’u)Â·/epsilon1T=1
CF(h,Î¦) +uÂ·/epsilon1T=0
CF(h,Î¦)]âˆ’[(1âˆ’u)Â·/epsilon1T=1
F(h,Î¦) +uÂ·/epsilon1T=0
F(h,Î¦)]
=(1âˆ’u)Â·[/epsilon1T=1
CF(h,Î¦)âˆ’/epsilon1T=1
F(h,Î¦)] +uÂ·[/epsilon1T=0
CF(h,Î¦)âˆ’/epsilon1T=0
F(h,Î¦)]
=(1âˆ’u)/integraldisplay
X/lscripth,Î¦(x,1)(pT=0(x)âˆ’pT=1(x))dx+u/integraldisplay
X/lscripth,Î¦(x,0)(pT=1(x)âˆ’pT=0(x))dx (21)
=(1âˆ’u)/integraldisplay
R/lscripth,Î¦(Î¨(r),1)(pT=0
Î¦(r)âˆ’pT=1
Î¦(r))dr+u/integraldisplay
R/lscripth,Î¦(Î¨(r),0)(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr(22)
=BÎ¦Â·(1âˆ’u)/integraldisplay
R1
BÎ¦/lscripth,Î¦(Î¨(r),1)(pT=0
Î¦(r)âˆ’pT=1
Î¦(r))dr
+BÎ¦Â·u/integraldisplay
R1
BÎ¦/lscripth,Î¦(Î¨(r),0)(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr
â‰¤BÎ¦Â·(1âˆ’u) sup
gâˆˆG|/integraldisplay
Rg(r)(pT=0
Î¦(r)âˆ’pT=1
Î¦(r))dr|
+BÎ¦Â·uÂ·sup
gâˆˆG|/integraldisplay
Rg(r)(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr| (23)
=BÎ¦Â·Wass (pT=1
Î¦,pT=0
Î¦) (24)
Equation (21) is by Deï¬nition 8; equation (22) is by the change of formula, pT=0
Î¦(r) =pT=0(Î¨(r))JÎ¨(r),
pT=1
Î¦(r) =pT=1(Î¨(r))JÎ¨(r), whereJÎ¨(r)is the absolute of the determinant of the Jacobian of Î¨(r); in-
equality (23) is by the premise that1
BÎ¦Â·/lscripth,Î¦(Î¨(r),t)âˆˆGfort= 0,1, and (24) is by Deï¬nition 9 of an
IPM.
The crucial condition in Lemma 3 is that gÎ¦,h(r,t) :=1
BÎ¦Â·/lscripth,Î¦(Î¨(r),t)âˆˆG. Bounds for BÎ¦can be given to
evaluate this constant when under more assumptions about the loss function L, the Lipschitz constants of
p(yt|x),h, and the condition number of the Jacobian of Î¦. These assumptions and the speciï¬c bounds for
BÎ¦can be seen in supplement Section A.3 of (Shalit et al., 2017).
Now we turn to derive the counterfactual error bounds for the H-divergence case.
Assumption 1. There exists a constant K > 0such that sup
y2âˆˆY,xâˆˆX/integraltext
YL(y1,y2)p(y1|x)dy1â‰¤K.
Lemma 4. LetÎ¦ :Xâ†’Rbe an invertible representation with Î¨being its inverse. Let pT=1
Î¦(r),pT=0
Î¦(r)be
as deï¬ned before. Let h:RÃ—{ 0,1}â†’Y,u:=Pr(T= 1)andHbe the family of binary functions. Assume
loss function Lobeys the Assumption 1. Then we have:
/epsilon1CF(h,Î¦)â‰¤(1âˆ’u)Â·/epsilon1T=1
F(h,Î¦) +uÂ·/epsilon1T=0
F(h,Î¦) +K
2dH(pT=1
Î¦,pT=0
Î¦).
18Under review as submission to TMLR
Proof.
/epsilon1CF(h,Î¦)âˆ’[(1âˆ’u)Â·/epsilon1T=1
F(h,Î¦) +uÂ·/epsilon1T=0
F(h,Î¦)]
=(1âˆ’u)/integraldisplay
R/lscripth,Î¦(Î¨(r),1)(pT=0
Î¦(r)âˆ’pT=1
Î¦(r))dr+u/integraldisplay
R/lscripth,Î¦(Î¨(r),0)(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr(25)
â‰¤(1âˆ’u)/integraldisplay
pT=0
Î¦>pT=1
Î¦/lscripth,Î¦(Î¨(r),1)(pT=0
Î¦(r)âˆ’pT=1
Î¦(r))dr
+u/integraldisplay
pT=1
Î¦>pT=0
Î¦/lscripth,Î¦(Î¨(r),0)(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr (26)
â‰¤(1âˆ’u)K/integraldisplay
pT=0
Î¦>pT=1
Î¦(pT=0
Î¦(r)âˆ’pT=1
Î¦(r))dr+uÂ·K/integraldisplay
pT=1
Î¦>pT=0
Î¦(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr (27)
=(1âˆ’u)K/integraldisplay
RI(pt=0
Î¦>pT=1
Î¦)(pT=0
Î¦(r)âˆ’pT=1
Î¦(r))dr
+uÂ·K/integraldisplay
RI(pT=1
Î¦>pT=0
Î¦)(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr
â‰¤(1âˆ’u)Ksup
Î·âˆˆH|/integraldisplay
RÎ·(r)(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr|
+uÂ·KÂ·sup
Î·âˆˆH|/integraldisplay
RÎ·(r)(pT=1
Î¦(r)âˆ’pT=0
Î¦(r))dr| (28)
â‰¤KÂ·sup
Î·âˆˆH|/integraldisplay
RÎ·(r)((pT=1
Î¦(r)âˆ’pT=0
Î¦(r)))dr|
=K
2dH(pT=1
Î¦,pT=0
Î¦) (29)
Equation (25) is same to equation (22); equation (26) is by /lscripth,Î¦â‰¥0for all randt; inequality (27) is by
Deï¬nition 6 and Assumption 1; inequality (28) is because an indicator function is also a binary function;
equation (29) is by (20) in Lemma 2.
A.3 Bounds for the PEHE loss /epsilon1PEHE
We ï¬rst state two lemmas for /epsilon1PEHEwith respect to two diï¬€erent loss functions: the squared loss and the
absolute loss. In fact, similar lemmas hold for loss functions that satisfy the (relaxed) triangle inequalities.
Deï¬nition 11. The expected variance of ytwith regard to p(x,t)is:
Ïƒ2
yt(p(x,t)) =/integraldisplay
XÃ—{ 0,1}Ã—Y(ytâˆ’Ï„t(x))2p(yt|x)p(x,t)dytdxdt,
and deï¬ne:
Ïƒ2
y= min{Ïƒ2
yt(p(x,t)),Ïƒ2
yt(p(x,1âˆ’t))}.
Lemma 5. Let loss function Lbe the squared loss, L(y1,y2) = (y1âˆ’y2)2. For any function f:XÃ—{ 0,1}â†’
Y, and distribution p(x,t)overXÃ—{ 0,1}, we have the same results in Shalit et al. (2017):
/epsilon1PEHE (h,Î¦)â‰¤2(/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦)âˆ’2Ïƒ2
y)
19Under review as submission to TMLR
Proof.We denote /epsilon1PEHE (f) =/epsilon1PEHE (h,Î¦),/epsilon1F(f) =/epsilon1F(h,Î¦),/epsilon1CF(f) =/epsilon1CF(h,Î¦)forf(x,t) =h(Î¦(x),t).
/epsilon1PEHE (f)
=/integraldisplay
X((f(x,1)âˆ’f(x,0))âˆ’(Ï„1(x)âˆ’Ï„0(x)))2p(x)dx
â‰¤2/integraldisplay
X((f(x,1)âˆ’Ï„1(x))2+ (f(x,0)âˆ’Ï„0(x))2)p(x)dx (30)
=2/integraldisplay
X(f(x,1)âˆ’Ï„1(x))2p(x,T= 1)dx+ 2/integraldisplay
X(f(x,0)âˆ’Ï„0(x))2p(x,T= 0)dx
+ 2/integraldisplay
X(f(x,1)âˆ’Ï„1(x))2p(x,T= 0)dx+ 2/integraldisplay
X(f(x,0)âˆ’Ï„0(x))2p(x,T= 1)dx (31)
=2/integraldisplay
XÃ—{ 0,1}(f(x,t)âˆ’Ï„t(x))2p(x,t)dxdt+ 2/integraldisplay
XÃ—{ 0,1}(f(x,t)âˆ’Ï„t(x))2p(x,1âˆ’t)dxdt.
Inequality (30) is because the relaxed triangle inequality, (x+y)2â‰¤2(x2+y2); equation (31) is because
p(x) =p(x,T= 0) +p(x,T= 1).
/epsilon1F(f)
=/integraldisplay
XÃ—{ 0,1}Ã—Y(f(x,t)âˆ’yt)2p(yt|x)p(x,t)dytdxdt
=/integraldisplay
XÃ—{ 0,1}Ã—Y(f(x,t)âˆ’Ï„t(x))2p(yt|x)p(x,t)dytdxdt
+/integraldisplay
XÃ—{ 0,1}Ã—Y(Ï„t(x)âˆ’yt)2p(yt|x)p(x,t)dytdxdt
+ 2/integraldisplay
XÃ—{ 0,1}Ã—Y(f(x,t)âˆ’Ï„t(x))(Ï„t(x)âˆ’yt)p(yt|x)p(x,t)dytdxdt (32)
=/integraldisplay
XÃ—{ 0,1}(f(x,t)âˆ’Ï„t(x))2p(x,t)dxdt+Ïƒ2
yt(p(x,t)) (33)
Equation (33) is by Deï¬nition 11 and last term in equation (32) equals to zero, since Ï„t(x) =/integraltext
Yytp(yt|x)dyt.
A similar result can be obtained for /epsilon1CF:
/epsilon1CF(f) =/integraldisplay
XÃ—{ 0,1}(f(x,t)âˆ’Ï„t(x))2p(x,1âˆ’t)dxdt+Ïƒ2
yt(p(x,1âˆ’t)).
Combining these results and Deï¬nition 11, we have
/epsilon1PEHE (h,Î¦)â‰¤2(/epsilon1F(f)âˆ’Ïƒ2
yt(p(x,t))) + 2(/epsilon1CF(f)âˆ’Ïƒ2
yt(p(x,1âˆ’t)))
â‰¤2(/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦)âˆ’2Ïƒ2
y).
For the absolute loss L(y1,y2) =|y1âˆ’y2|that satisï¬es triangle inequality, the upper bound in Lemma 5 will
replace the standard deviation Ïƒ2
yby mean absolute deviation Ay.
Deï¬nition 12. The mean absolute deviation of ytwith regard to p(x,t)is:
Ayt(p(x,t)) =/integraldisplay
XÃ—{ 0,1}Ã—Y|ytâˆ’Ï„t(x)|p(yt|x)p(x,t)dytdxdt,
and deï¬ne:
Ay= max{Ayt(p(x,t)),Ayt(p(x,1âˆ’t))}.
20Under review as submission to TMLR
Lemma 6. Let loss function Lbe the absolute loss, L(y1,y2) =|y1âˆ’y2|. For any function f:XÃ—{ 0,1}â†’Y,
and distribution p(x,t)overXÃ—{ 0,1}:
/epsilon1PEHE (h,Î¦)â‰¤/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦) + 2Ay.
Proof.Recall that /epsilon1PEHE (f) =/epsilon1PEHE (h,Î¦),/epsilon1F(f) =/epsilon1F(h,Î¦),/epsilon1CF(f) =/epsilon1CF(h,Î¦)forf(x,t) =h(Î¦(x),t).
/epsilon1PEHE (f)
=/integraldisplay
X|(f(x,1)âˆ’f(x,0))âˆ’(Ï„1(x)âˆ’Ï„0(x))|p(x)dx
â‰¤/integraldisplay
X(|f(x,1)âˆ’Ï„1(x)|+|f(x,0)âˆ’Ï„0(x)|)p(x)dx (34)
=/integraldisplay
X|f(x,1)âˆ’Ï„1(x)|p(x,T= 1)dx+/integraldisplay
X|f(x,0)âˆ’Ï„0(x)|p(x,T= 0)dx
+/integraldisplay
X|f(x,1)âˆ’Ï„1(x)|p(x,T= 0)dx+/integraldisplay
X|f(x,0)âˆ’Ï„0(x)|p(x,T= 1)dx (35)
=/integraldisplay
XÃ—{ 0,1}|f(x,t)âˆ’Ï„t(x)|p(x,t)dxdt+/integraldisplay
XÃ—{ 0,1}|f(x,t)âˆ’Ï„t(x)|p(x,1âˆ’t)dxdt.
Inequality (34) is because triangle inequality, |x+y|â‰¤|x|+|y|; equation (35) is because p(x) =p(x,T=
0) +p(x,T= 1).
/epsilon1F(f)
=/integraldisplay
XÃ—{ 0,1}Ã—Y|f(x,t)âˆ’yt|p(yt|x)p(x,t)dytdxdt
â‰¥/integraldisplay
XÃ—{ 0,1}Ã—Y|f(x,t)âˆ’Ï„t(x)|p(yt|x)p(x,t)dytdxdt
âˆ’/integraldisplay
XÃ—{ 0,1}Ã—Y|Ï„t(x)âˆ’yt|p(yt|x)p(x,t)dytdxdt (36)
=/integraldisplay
XÃ—{ 0,1}|f(x,t)âˆ’Ï„t(x)|p(x,t)dxdtâˆ’Ayt(p(x,t)). (37)
Inequality (36) is also because |x+y|â‰¥|x|âˆ’|y|, equation (37) is by Deï¬nition 12. A similar result can be
obtained for /epsilon1CF:
/epsilon1CF(f) =/integraldisplay
XÃ—{ 0,1}|f(x,t)âˆ’Ï„t(x)|p(x,1âˆ’t)dxdtâˆ’Ayt(p(x,1âˆ’t)).
Combining these results and Deï¬nition 12, we have
/epsilon1PEHE (h,Î¦)â‰¤/epsilon1F(f) +Ayt(p(x,t)) +/epsilon1CF(f) +Ayt(p(x,1âˆ’t))
â‰¤/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦) + 2Ay.
We summarize the upper bounds of /epsilon1CFand/epsilon1PEHEabove, and give the ï¬nal bounds for these two distance
using the squared and absolute loss, respectively.
Theorem 1. LetÎ¦ :Xâ†’Rbe an invertible representation with Î¨being its inverse. Let pT=1
Î¦(r),pT=0
Î¦(r)
be as deï¬ned before. Let h:RÃ—{ 0,1}â†’Y,u:=Pr(T= 1)andGbe the family of 1-Lipschitz functions.
Assume there exists a constant BÎ¦â‰¥0, such that for t= 0,1, the function gÎ¦,h(r,t) :=1
BÎ¦Â·/lscripth,Î¦(Î¨(r),t)âˆˆG.
21Under review as submission to TMLR
Let loss function Lbe the squared loss, L(y1,y2) = (y1âˆ’y2)2. Then we have (same results in Shalit et al.
(2017)):
/epsilon1PEHE (h,Î¦)
â‰¤2(/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦)âˆ’2Ïƒ2
y) (38)
â‰¤2(/epsilon1T=1
F(h,Î¦) +/epsilon1T=0
F(h,Î¦) +BÎ¦Â·Wass (pT=1
Î¦,pT=0
Î¦)âˆ’2Ïƒ2
y) (39)
Let loss function Lbe the absolute loss, L(y1,y2) =|y1âˆ’y2|. Then we have:
/epsilon1PEHE (h,Î¦)
â‰¤/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦) + 2Ay (40)
â‰¤/epsilon1T=1
F(h,Î¦) +/epsilon1T=0
F(h,Î¦) +BÎ¦Â·Wass (pT=1
Î¦,pT=0
Î¦) + 2Ay (41)
Proof.Inequality (38) is by Lemma 5, inequality (39) is by Lemma 1 and Lemma 3; Inequality (40) is by
Lemma 6, inequality (41) is by Lemma 1 and Lemma 3;
Theorem 2. LetÎ¦ :Xâ†’Rbe an invertible representation with Î¨being its inverse. Let pT=1
Î¦(r),pT=0
Î¦(r)
be as deï¬ned before. Let h:RÃ—{ 0,1}â†’Y,u:=Pr(T= 1)andHbe the family of binary functions.
Let loss function Lbe the squared loss such that L(y1,y2) = (y1âˆ’y2)2. Then we have:
/epsilon1PEHE (h,Î¦)
â‰¤2(/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦)âˆ’2Ïƒ2
y) (42)
â‰¤2(/epsilon1T=1
F(h,Î¦) +/epsilon1T=0
F(h,Î¦) +K
2dH(pT=1
Î¦,pT=0
Î¦)âˆ’2Ïƒ2
y) (43)
Let loss function Lbe the absolute loss such that L(y1,y2) =|y1âˆ’y2|. Then we have:
/epsilon1PEHE (h,Î¦)
â‰¤/epsilon1CF(h,Î¦) +/epsilon1F(h,Î¦) + 2Ay (44)
â‰¤/epsilon1T=1
F(h,Î¦) +/epsilon1T=0
F(h,Î¦) +K
2dH(pT=1
Î¦,pT=0
Î¦) + 2Ay (45)
Proof.Inequality (42) is by Lemma 5, inequality (43) is by Lemma 1 and Lemma 4; Inequality (44) is by
Lemma 6, inequality (45) is by Lemma 1 and Lemma 4;
Obviously, when using Wasserstein distance, there are various versions of bounds for diï¬€erent loss functions
as long as they satisfy the (relaxed) triangle inequality and assumptions about /lscripth,Î¦in Theorem 1. Similarly,
when usingH-divergence, there are also various versions of bounds for loss functions that satisfy Assumption
1 and the (relaxed) triangle inequality.
For an empirical sample and a family of representations and hypotheses, we can further upper bound /epsilon1T=0
F
and/epsilon1T=1
Fbytheirrespectiveempiricallossesandamodelcomplexitytermusingstandardarguments(Shalev-
Shwartz & Ben-David, 2014). Both the Wasserstein distance and H-divergence can be consistently estimated
from ï¬nite samples (Sriperumbudur et al., 2012; Ben-David et al., 2006; 2010).
A.4 Illustrative examples
Examples for the motivation for decomposed patterns. To explain the dilemma between repre-
sentation balancing and outcome prediction, we give an intuitive examples and the analytical explanation
below to help readers better understand the motivation and importance of involving decomposed patterns
in representation balancing models.
22Under review as submission to TMLR
Adjust 
covariates 
Figure 7: Example for illustrating the importance of decomposed patterns.
Example 1. Suppose there is a vaccine to prevent some kind of disease. Let Xdenote the covariate (age),
T= 1denote the treatment (getting vaccinated), T= 0denote the control (not getting vaccinated), and Y
denotetheoutcome(probabilityofgettingthedisease). Supposethatthevaccineisassignedaccordingtoage,
and we have found that the older, the higher the probability of getting the disease. The left graph in Figure
7 shows the distribution of pre-balancing covariate Xfor treated and controlled groups, which indicates
that vaccines are more likely to distribute to older people. Technically, the pre-balancing data preserve
the outcome-predictive information: if we want to estimate Yusing the covariate X, we are conï¬dent that
people in the treatment/control group (orange/blue) are susceptible/unsusceptible to the disease since they
are older/younger. The right panel of Figure 7 shows the distribution of the adjusted covariate ËœX, over
which the distributions of treated and controlled groups are highly balanced. In this case, however, the
distribution of ËœXis too balanced, making it hard to distinguish the treatment samples from the control
samples. Consequently, if we want to estimate Yusing ËœX, we may get confused about which group is
susceptible to the disease because the distributions of ËœXare almost identical between the treated and
controlled groups. Therefore, only considering balancing patterns can result in a loss of outcome-predictive
information.
Analytical explanation. Recall that, as deï¬ned in Deï¬nition 1, Î¦ :Xâ†’Ris a representation function,
andh:RÃ—{ 0,1}â†’Yisanoutcomefunctionsuchthat h(Î¦(x),t)estimatesyt. Fornotationalsimpliï¬cation,
we deï¬neFas a function family consisting f=hâ—¦Î¦ :XÃ—{ 0,1}â†’Ysuch thatf(x,t)estimatesyt. Then, as
demonstrated in equation 9, the goal of outcome prediction is to learn the global optimal outcome predictor
fâˆ—such that
fâˆ—=argmin
fâˆˆFL(x,t,y;f).
For models without pre-balancing representations such as GNet (Figure 2a) and INet (Figure 2b), the
outcome is predicted using only balancing patterns. Speciï¬cally, their objectives incorporate the constraint
of distance minimization between treatment and control groups over Î¦, i.e., dist (pT=1
Î¦,pT=0
Î¦)â‰¤Cfor some
small constant C, where â€œdistâ€ can be â€œWassâ€ for GNet or dHfor INet. We deï¬ne F/primeas a function family
consistingf=hâ—¦Î¦ :XÃ—{ 0,1}â†’Ysuch thatf(x,t)estimatesytwith Î¦simultaneously minimizing
dist(pT=1
Î¦,pT=0
Î¦). It is obvious that F/primeâŠ†F. The outcome predictor for models without pre-balancing
representations is learned by
fâˆ—âˆ—=argmin
fâˆˆF/primeL(x,t,y;f).
Due toF/primeâŠ†F, we haveL(x,t,y;fâˆ—)â‰¤L(x,t,y;fâˆ—âˆ—). That is, if the outcome predictor is only learned
by balancing patterns, the learned outcome predictor fâˆ—âˆ—will be suboptimal of fâˆ—. Instead, compared to
fâˆ—âˆ—learned by only balancing patterns, the outcome predictor learned by both pre-balancing and balancing
patterns can give a better estimate, as the corresponding feasible region will be larger than F/prime.
23Under review as submission to TMLR
In summary, on the one hand, involving representation balancing can beneï¬t treatment eï¬€ect estimation. On
the other hand, if pT=1
Î¦andpT=0
Î¦are too balanced, a model may fail to preserve pre-balancing information
that is useful to outcome predictions. Such a dilemma motivates us to incorporate PPBR and PDIG such
thatPPBRimprovesoutcomepredictionwithoutharmingrepresentationbalancing, andPDIGhelpsamodel
to achieve more balanced representations without harming outcome prediction.
A.5 Additional Experimental details
Additional results on Twins Benchmark. To investigate the applicability of our model DIGNet to
benchmark datasets beyond the commonly used IHDP benchmark, we conducted additional comparisons
with several baseline models, including linear, tree, matching, and representation learning methods, on the
Twins benchmark, as presented in Table 4.
The Twins dataset comprises records of twin births in the USA between 1989 and 1991. After preprocessing,
each unit contains 30 covariates relevant to parents, pregnancy, and birth. The treatment D= 1indicates
the heavier twin, while D= 0indicates the lighter twin. The binary outcome variable Yrepresents 1-year
mortality. For more comprehensive details on this dataset and the limitation of IHDP, refer to Curth et al.
(2021).
Notably, for /epsilon1ATE, the simple linear or matching estimator performs best across diï¬€erent methods. On the
other hand, when assessing ITE performance using the AUC of potential outcomes, representation learning
models all demonstrate strong performance, with AUC values exceeding 0.800on both training and test sets.
Among all the models, our DIGNet achieves the highest AUC results. This observation might stem from the
fact that representation balancing models are based on ITE error bounds, rather than ATE error bounds,
thereby optimizing for AUC instead of /epsilon1ATE. This, in turn, inspires us to explore ATE error bounds based
on IPM andH-divergence in future research.
Table 4: Training- & test- set AUC & /epsilon1ATEon Twins. MeanÂ±standard error of 100 runs.
Training set Test set
AUC /epsilon1ATE AUC /epsilon1ATE
OLS/LR 1Johansson et al. (2016) .660Â±.005.004Â±.003.500Â±.028.007Â±.006
OLS/LR 2Johansson et al. (2016) .660Â±.004.004Â±.003.500Â±.016.007Â±.006
k-NN Crump et al. (2008) .609Â±.010.003Â±.002.492Â±.012.005Â±.004
BART Chipman et al. (2010) .506Â±.014.121Â±.024.500Â±.011.127Â±.024
CEVAE Louizos et al. (2017) .845Â±.003.022Â±.002.841Â±.004.032Â±.003
SITE Yao et al. (2018) .862Â±.002.016Â±.001.853Â±.006.020Â±.002
BLR Johansson et al. (2016) .611Â±.009.006Â±.004.510Â±.018.033Â±.009
BNN Johansson et al. (2016) .690Â±.008.006Â±.003.676Â±.008.020Â±.007
TARNet Shalit et al. (2017) .849Â±.002.011Â±.002.840Â±.006.015Â±.002
CFR-Wass (GNet) Shalit et al. (2017) .850Â±.002.011Â±.002.842Â±.005.028Â±.003
DIGNet (Ours) .874Â±.001.004Â±.001.871Â±.001.008Â±.001
Hyperparameters. Insimulationstudies, weensureafaircomparisonbyï¬xingallthehyperparametersin
all datasets across diï¬€erent models. The relevant details are stated in Table 5. In IHDP studies, to compare
Table 5: Hyperparameters of diï¬€erent models in simulation studies.
Î¦E Î¦G Î¦I Ï€ h1h0Î±1Î±2batchsize iteration learning rate learning rate for Ï€
Gnet (100,100,100,100)âˆ’ âˆ’ âˆ’ (100,100) (100 ,100)0.1âˆ’100 300 1eâˆ’3âˆ’
Inet (100,100,100,100)âˆ’ âˆ’ (100,100,100) (100 ,100) (100 ,100)âˆ’0.1 100 300 1eâˆ’31eâˆ’4
DGNet (100,100,100,100) (100 ,100)âˆ’ âˆ’ (100,100) (100 ,100)0.1âˆ’100 300 1eâˆ’3âˆ’
DINet (100,100,100,100)âˆ’ (100,100) (100 ,100,100) (100 ,100) (100 ,100)âˆ’0.1 100 300 1eâˆ’31eâˆ’4
DIGNet (100,100,100,100) (100 ,100) (100 ,100) (100 ,100,100) (100 ,100) (100 ,100)0.1 0.1 100 300 1eâˆ’31eâˆ’4
24Under review as submission to TMLR
with the baseline model CFR-Wass (GNet), we remain the hyperparameters of INet, DGNet, DINet and the
early stopping rule the same as those used in CFR-Wass Shalit et al. (2017). Since DIGNet is more complex
than other four models, we adjust the hyperparameters of Î¦E,Î¦G,Î¦I,Î±1, andÎ±2for DIGNet as Shalit
et al. (2017) do. The relevant details are stated in Table 6.
Table 6: Hyperparameters of diï¬€erent models in IHDP experiments.
Î¦E Î¦G Î¦I Ï€ h1h0Î±1Î±2batchsize iteration learning rate learning rate for Ï€
Gnet (100,100,100,100) âˆ’ âˆ’ âˆ’ (100,100,100) (100 ,100,100)1âˆ’100 600 1eâˆ’3âˆ’
Inet (100,100,100,100) âˆ’ âˆ’ (200,200,200) (100 ,100,100) (100 ,100,100)âˆ’1 100 600 1eâˆ’31eâˆ’3
DGNet (100,100,100,100) (100 ,100)âˆ’ âˆ’ (100,100,100) (100 ,100,100)1âˆ’100 600 1eâˆ’3âˆ’
DINet (100,100,100,100) âˆ’ (100,100) (200 ,200,200) (100 ,100,100) (100 ,100,100)âˆ’1 100 600 1eâˆ’31eâˆ’3
DIGNet (100,100,100,100,100,100) (100 ,100,100) (100 ,100,100) (200 ,200,200) (100 ,100,100) (100 ,100,100)0.1 1 100 600 1eâˆ’31eâˆ’3
Analysis of training time and training stability. We record the time it took for diï¬€erent models to
run through 100 IHDP datasets, and each model is trained within 600 epochs. Following Shalit et al. (2017),
all models adopt the early stopping rule. We also record the average early stopping epoch on 100 runs
and the actual time on 100 runs, where (actual time) = (total time) Ã—(average early stopping epoch)/600.
Not surprisingly, GNet took the least amount of time with 3096 seconds since the objective of GNet is the
simplest. However, it is very interesting that the proposed methods, DGNet and DINet, are the ï¬rst two
to early stop. As a result, though DGNet and DINet have multi-objectives, they spent less actual training
time but achieved better ITE estimation compared to GNet and INet. Since GNet and INet are actually
DGNet and DINet with PPBR ablated, we ï¬nd that PPBR component can help a model achieve better ITE
estimates with less time. In addition, we ï¬nd that DIGNet spent the longest time to optimize since it has
the most complex objective. To further study the stability of the model training, we also plot the metricsâˆš/epsilon1F, Wass, Ë†dH, andâˆš/epsilon1PEHEfor the ï¬rst 100 epochs of each model on the ï¬rst IHDP dataset. We ï¬nd
that the training process of DIGNet is stable, even steadier than GNet and INet. From this perspective, we
havenâ€™t seen a diï¬ƒculty of optimizing DIGNet.
Table 7: Training time records on 100 IHDP datasets.
Model Time for 600 epochs Avg early stopping Actual timeâˆš/epsilon1PEHEon test set
GNet 3096s 240.61 1241s 0.77 Â±0.18
INet 4042s 254.19 1712 0.72 Â±0.11
DGNet 3775s 169.17 1064s 0.60 Â±0.09
DINet 3212s 157.98 846s 0.60 Â±0.11
DIGNet 4984s 226.76 1884s 0.45 Â±0.04
A.6 Objectives of Diï¬€erent Models
Objective of GNet.
min
Î¦E,htLy(x,t,y; Î¦E,ht) +Î±1LG(x,t; Î¦E).
Objective of INet.
max
Ï€Î±2LI(x,t; Î¦E,Ï€),
min
Î¦E,htLy(x,t,y; Î¦E,ht) +Î±2LI(x,t; Î¦E,Ï€).
25Under review as submission to TMLR
Figure 8: Training loss plots for the ï¬rst 100 epochs on the ï¬rst IHDP dataset.
Objective of DINet. Note that similar to DIGNet, the pre-balancing patterns are preserved by only
updating Î¦Ibut ï¬xing Î¦Ein the second step.
max
Ï€Î±2LI(x,t; Î¦Iâ—¦Î¦E,Ï€),
min
Î¦IÎ±2LI(x,t; Î¦Iâ—¦Î¦E,Ï€),
min
Î¦E,Î¦I,htLy(x,t,y; Î¦EâŠ•(Î¦Iâ—¦Î¦E),ht).
Objective of DGNet. Note that similar to DIGNet, the pre-balancing patterns are preserved by only
updating Î¦Gbut ï¬xing Î¦Ein the ï¬rst step.
min
Î¦GÎ±1LG(x,t; Î¦Gâ—¦Î¦E),
min
Î¦E,Î¦G,htLy(x,t,y; Î¦EâŠ•(Î¦Gâ—¦Î¦E),ht).
Objective of DIGNet.
min
Î¦GÎ±1LG(x,t; Î¦Gâ—¦Î¦E),
max
Ï€Î±2LI(x,t; Î¦Iâ—¦Î¦E,Ï€),
min
Î¦IÎ±2LI(x,t; Î¦Iâ—¦Î¦E,Ï€),
min
Î¦E,Î¦I,Î¦G,htLy(x,t,y; Î¦EâŠ•(Î¦Iâ—¦Î¦E)âŠ•(Î¦Gâ—¦Î¦E),ht).
26