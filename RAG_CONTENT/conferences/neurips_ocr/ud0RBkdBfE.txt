Convergence Analysis of Split Federated Learning on
Heterogeneous Data
Pengchao Hanâˆ—
Guangdong University of Technology, China
hanpengchao@gdut.edu.cnChao Huangâˆ—
Montclair State University, USA
huangch@montclair.edu
Geng Tian
Southern University of Science and Technology, China
12332463@mail.sustech.edu.cn
Ming Tangâ€ 
Southern University of Science and Technology, China
tangm3@sustech.edu.cnXin Liu
University of California, Davis, USA
xinliu@ucdavis.edu
Abstract
Split federated learning (SFL) is a recent distributed approach for collaborative
model training among multiple clients. In SFL, a global model is typically split into
two parts, where clients train one part in a parallel federated manner, and a main
server trains the other. Despite the recent research on SFL algorithm development,
the convergence analysis of SFL is missing in the literature, and this paper aims to
fill this gap. The analysis of SFL can be more challenging than that of federated
learning (FL), due to the potential dual-paced updates at the clients and the main
server. We provide convergence analysis of SFL for strongly convex and general
convex objectives on heterogeneous data. The convergence rates are O(1/T)and
O(1/3âˆš
T), respectively, where Tdenotes the total number of rounds for SFL
training. We further extend the analysis to non-convex objectives and the scenario
where some clients may be unavailable during training. Experimental experiments
validate our theoretical results and show that SFL outperforms FL and split learning
(SL) when data is highly heterogeneous across a large number of clients.
1 Introduction
1.1 Motivation
Federated learning (FL) [ 18,9] allows distributed clients to train a global machine learning model
collaboratively without sharing raw data. FL leverages the parallel computing capabilities of clients
to enhance model training efficiency. However, FL is usually computationally intensive. Clients
need to train the entire global model multiple times, which can be infeasible for resource-constrained
edge devices. This challenge is further exacerbated as the trend towards increasingly larger model
architectures demands more substantial resources [ 1]. Moreover, FL suffers from the client drift
*Equal contribution.
â€ Corresponding author.
This work was partially supported by the National Natural Science Foundation of China (Grants 62202214
and 62401161), Guangdong Basic and Applied Basic Research Foundation (Grants 2023A1515012819 and
2022A1515110056), and USDA-020-67021-32855.
38th Conference on Neural Information Processing Systems (NeurIPS 2024)....
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
 . . . . . . . . . . . . . . . . . . . . . . . .Fed ServerMain ServerClientsCut Layerxc,1xs,1xc,2xc,Nxc...
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
 . . . . . . . . . . . . . . . . . . . . . . . .Fed ServerMain ServerClientsCut Layerxc,1xsxc,2xc,Nxc . . . . . . . . . . . .xs,2 . . . . . . . . . . . .xs,NSFL-V1SFL-V2Figure 1: An illustration of SFL framework, and there are two major algorithms, i.e., SFL-V1 (left)
and SFL-V2 (right) [27]. More discussions on SFL-V1 and SFL-V2 are given in Sec. 2.
problem when clientsâ€™ data distributions are heterogeneous, aka non-identically and independently
distributed (non-IID). A large number of studies have proposed algorithms to address the client drift
issue, e.g., [15, 10, 14, 25].
Split learning (SL) [ 28] is another distributed approach. By splitting the model across clients and a
main server, SL can substantially reduce the computational workload on edge devices. Moreover,
recent studies in [ 34,17] show that SL can outperform FL when data is highly heterogeneous.
However, SLâ€™s sequential training among clients can lead to high latency in each training round
and potential performance loss (e.g., caused by catastrophic forgetting), which impedes its practical
applicability in real-world distributed systems.
In light of above challenges, Thapa et. al in [ 27] proposed split federated learning (SFL) as a hybrid
approach that synergizes the strengths of both FL and SL. SFL combines parallel training of FL with
partial model training of SL. They proposed two major SFL algorithms: SFL-V1 and SFL-V2. An
illustration of these SFL algorithms are shown in Fig. 1. Specifically, the global model (to be trained)
is first split at a cut layer into two parts: a client-side model and a server-side model. Then, the clients
are responsible for training only the client-side model under the coordination of a fed server (similar
to FL). Another server, known as the main server , is tasked with training the server-side model by
collaborating with the clients (similar to SL). SFL aims to leverage parallel processing to reduce
latency, while benefiting from the reduced computational workloads and enhanced data heterogeneity
handling of SL.
Following [ 27], there has been an emerging volume of empirical studies on SFL. e.g., [ 22,21,3,
23,8,31,5]. However, a convergence analysis of SFL is missing in the literature , and this paper
aims to provide a comprehensive convergence analysis under different conditions. Convergence
theory is crucial for understanding the learning performance of SFL, particularly in the context of
heterogeneous data andpartial participation scenarios. In practical distributed systems, clients are
prone to have different data distributions. Moreover, not all clients may be active or available at all
times. These two issues can significantly affect the learning performance of SFL. We aim to provide
convergence guarantees for SFL on heterogeneous data (under both full and partial participation). We
further compare the results to FL and SL, which provides insights into the practical deployment of
various distributed approaches.
1.2 Related Work
Convergence theories of FL and SL . There are many convergence results on FL. Most studies
focus on data heterogeneity, e.g., [ 30,16,11,10,12]. Some studies look at partial participation, e.g.,
[35,29,26]. There are also convergence results on Mini-Batch SGD, e.g., [ 24,33,32], where [ 33]
argued that the key difference between FL and Mini-Batch SGD is the communication frequency.
To our best knowledge, there is only one recent study [ 17] discussing the convergence of SL. The
major difference to SL analysis lies in the sequential training manner across clients, while SFL clients
perform parallel training.
21.3 Challenges and Contributions
Challenges of SFL convergence analysis . When data is homogeneous (IID) across clients, the
convergence theory in [ 12] (mainly developed for FL) can be applied to SFL. When data is het-
erogeneous, however, the theory cannot be directly applied due to the client drift problem. The
challenge is intensified with clientsâ€™ partial participation, which induces bias in the training process.
Despite that prior FL theories have handled data heterogeneity [ 16] and partial participation [ 29],
SFL convergence analysis imposes unique challenges due to the dual-paced model aggregation and
model updates at the client-side and server-side. More specifically,
Dual-paced model aggregation in SFL-V1 : In SFL-V1, the main server maintains one server-side
model for each client, and it periodically aggregates the server-side models. When the main server
aggregates its models at the same frequency as the clients, the analysis is the same to that of FL.
However, FL analysis cannot be applied when aggregations occur at different frequencies, and it is
challenging to analyze the impact of such discrepancy on SFL convergence.
Dual-paced model updates in SFL-V2 : In SFL-V2, the main server only maintains one version of
server-side model. The clients update the client-side models in a parallel manner while the main
server updates the server-side model in a sequential fashion. Hence, each clientâ€™s local update depends
on the randomness of the previous clients who have interacted with the main server. While [ 17]
handled sequential client training, their theory cannot be applied to SFL-V2 as they did not consider
the aggregation of client-side models. This makes our analysis more challenging than FL and SL.
Contributions . We summarize our contributions as follows:
â€¢We provide the first comprehensive convergence analysis of SFL. The analysis is more
challenging than prior FL analysis due to the dual-paced model aggregation and model
updates. To this end, we derive a key decomposition result (Proposition 3.5) that enables us
to analyze the convergence from the server-side and client-side separately.
â€¢Based on the decomposition result, we prove that the convergence guarantees of both SFL-
V1 and SFL-V2 are O(1/T)for strongly convex objective and O(1/3âˆš
T)for general convex
objective, where Tdenotes the total number of rounds for SFL training. We further extend
the analysis to non-convex objectives and more practical scenarios where some clients may
be unavailable during training.
â€¢We conduct simulations on various datasets. We show that the results are consistent with
our theories. We further show two surprising results: (i) SFL achieves a better performance
when clients maintain a larger portion of the global model; (ii) SFL-V2 outperforms FL and
SL when clients have highly heterogeneous data and the number of client is large.
The rest of the paper is organized as follows. Sec. 2 formulates the SFL model. Sec. 3 presents the
convergence results for SFL. We conduct experiments in Sec. 4 and conclude in Sec. 5.
2 Problem Formulation
2.1 Model
We consider a set of clients N={1,2,Â·Â·Â·, N}, where each client nâˆˆ N has a local private dataset
Dnof size Dn=|Dn|. Suppose the global model parameterized by xhasLlayers. In SFL, the
global model is split at the Lc-th layer (i.e., the cut layer) into two segments: a client-side model
xc(from the first layer to layer Lc) and a server-side model xs(from layer Lc+ 1to layer L),
where x= [xc;xs]. Letxc,ndenote the local client-side model of client n. The clients train models
with the help of two servers: (i) fed server, which periodically aggregates clientsâ€™ local models xc,n
(similar to FL), and (ii) main server, who trains the server-side model xs. In this work, we consider
two major SFL algorithms: SFL-V1 and SFL-V2 [ 27]. In SFL-V1, the main server maintains a
separate server-side model xs,ncorresponding to each client n. In comparison, in SFL-V2, the main
server only maintains one model xs.
LetFn(x;Î¶n)denote the loss of model xover client nâ€™s mini-batch instance Î¶n, which is randomly
sampled from client nâ€™s dataset Dn. Let Fn(x)â‰œEÎ¶nâˆ¼Dn[Fn(x;Î¶n)]denote the expected loss of
model xover client nâ€™s dataset. The goal of SFL is to minimize the expected loss of the model x
3over the datasets of all clients:
min
xf(x) =NX
n=1anFn(x), (1)
where anâˆˆ[0,1]is the weight of client nsatisfyingP
nâˆˆNan= 1 . Typically, an=
Dn/P
nâ€²âˆˆNDnâ€², where a client with a larger data size is assigned a larger weight [34].
2.2 Algorithm Description
We provide a brief description of SFL. Refer to Appendix B for a more detailed discussion. SFL
takes a total number of Trounds to solve (1). At the beginning of each round t, clients download the
recent global client-side model from the fed server, where the model is an aggregated version of the
client-side models of the clients from the previous round tâˆ’1. Each round tcontains two stages:
Stage 1: model training . Clients and the main server train the full global model for Ï„iterations in
each round. In each iteration i < Ï„ , there are three steps:
Step 1: client forward propagation . Each client nsamples a mini-batch of data Î¶t,i
nfromDn,
computes the intermediate features (e.g., activation values at the cut layer) over its current model
xt,i
c,n, and sends the activation to the main server. The clients perform forward propagation in parallel.
Step 2: main server training . Upon receiving the activation of each client n,
â€¢SFL-V1: the main server computes the loss using the current server-side model xt,i
s,n. It then
computes the gradients over xt,i
s,nto update the model. It also computes the gradient over
the activation at the cut layer, and sends it to client n.
â€¢SFL-V2: the main server computes the loss Fn(
xt,i
c,n,xt,i
s	
), based on which it then
updates the server-side model xt,i
s. It also computes and sends the gradient over activation
at the cut layer to client n. Note that the main server sequentially interacts with the clients
in a randomized order.
Step 3: client backward propagation . Receiving gradient at the cut layer, each client ncomputes the
client-side gradient using the chain rule, and then updates its model xt,i
c,n.
Stage 2: model aggregation . Model aggregation can occur for both client-side and server-side
models. For the client side, after Ï„iterations of model training (i.e., at the end of round t), each client
sends its current client-side model to the fed server. The fed server aggregates the clientsâ€™ models
(e.g., weighted averaging), which will be downloaded in the next round t+ 1:
xt+1
câ†X
nâˆˆNanxt,Ï„
c,n. (2)
For the server side, (i) in SFL-V1, after ËœÏ„iterations of training, the main server aggregates all server-
side models. Note that ËœÏ„does not necessarily need to equal Ï„, but when equality holds, SFL-V1 can
be regarded as FL (despite the model splitting). (ii) In SFL-V2, no aggregation occurs since the main
server only maintains one model.
2.3 Client Participation
We consider two cases: (i) full participation where all clients are available during training. This
can model the scenarios where clients are organizations or companies who likely have sufficient
computation and communication resources [ 7]; (ii) partial participation where some clients may be
unavailable during training. This can model the cases where clients are edge devices (e.g., mobile
phones) that are usually resource-constrained and may be disconnected from the SFL process.
To model partial participation, we consider independent participation probabilities for each client,
allowing for arbitrary and heterogeneous participation probabilities. Specifically, we use qnâˆˆ[0,1]
to denote client nâ€™s participation level (or probability), and q= (qn, nâˆˆ N). Ifqn= 1, client
nparticipates in every round of SFL with probability one. If qn<1, client nis unavailable in
some rounds. Denote Pt(q)as the set of participating clients in round t. In the presence of partial
4participation, we need to modify (2) (and the potential server-side aggregation) to offset the incurred
bias:
xt+1
câ†X
nâˆˆPt(q)an
qnxt,Ï„
c,n. (3)
3 Convergence Analysis
We first make technical assumptions in Sec. 3.1. Then, we present a key technical result in Sec. 3.2
to support the SFL convergence analysis. Finally, we provide the convergence results under full
participation and partial participation in Sec. 3.3 and Sec. 3.4, respectively.
3.1 Assumptions
We start with some conventional assumptions for convergence analysis in the FL literature.
Assumption 3.1. (S-Smoothness ) Each client nâ€™s loss function FnisS-smooth. That is, for all
x,yâˆˆRd,
Fn(y)â‰¤Fn(x) +âŸ¨âˆ‡Fn(x),yâˆ’xâŸ©+S
2âˆ¥yâˆ’xâˆ¥2. (4)
The smoothness assumption holds for many loss functions in, for example, logistic regression,
softmax classifier, and l2-norm regularized linear regression [16].
Assumption 3.2. (Unbiased and bounded stochastic gradients with bounded variance ) The stochastic
gradients gn(Â·)ofFn(Â·)is unbiased with the variance bounded by Ïƒ2
n.
EÎ¶nâˆ¼Dn[gn(x, Î¶n)] =âˆ‡Fn(x), (5)
EÎ¶nâˆ¼Dnh
âˆ¥gn(x, Î¶n)âˆ’ âˆ‡Fn(x)âˆ¥2i
â‰¤Ïƒ2
n. (6)
Assumption 3.3. (Bounded gradients ) The expected squared norm of stochastic gradients is bounded
byG2.
EÎ¶nâˆ¼Dnâˆ¥gn(x, Î¶n)âˆ¥2â‰¤G2. (7)
The value of Ïƒnmeasures the level of stochasticity.
Assumption 3.4. (Heterogeneity ) There exists an Ïµ2such that the divergence between local and
global gradients is bounded by Ïµ2.
âˆ¥âˆ‡Fn(x)âˆ’ âˆ‡f(x)âˆ¥2â‰¤Ïµ2. (8)
A larger Ïµ2indicates a larger degree of data heterogeneity.
3.2 Decomposition
As discussed in Sec. 1.3, analyzing the performance bound of SFL can be more challenging than that
of conventional FL counterparts due to the dual-paced model aggregation and model updates. To
address this challenge, we decompose the convergence analysis into the server-side and client-side
updates, respectively. We give the decomposition below.
Proposition 3.5. (Convergence decomposition) Let xâˆ—â‰œ[xâˆ—
c;xâˆ—
s]denote the optimal global model
that minimizes f(Â·), andxTâ‰œ[xT
c;xT
s]is the global model obtained after Trounds of SFL training.
Under Assumption 3.1, we have
E
f(xT)
âˆ’f(xâˆ—)â‰¤S
2 
E||xT
sâˆ’xâˆ—
s||2+E||xT
câˆ’xâˆ—
c||2
. (9)
The proof is given in Appendix C.4. Proposition 3.5 is particularly useful. It shows that despite the
challenging dual-paced updates, to bound the SFL performance gap, it suffices to separately bound
the gap at the server-side and client-side models. Note that our decomposition can be easily applied
to other distributed approaches such as SL. In addition, such a decomposition is not necessarily loose,
as our derived bounds for SFL achieve the same order as in FL (see Appendix H.2 for details).
53.3 Results under Full Participation
Built upon Proposition 3.5, we first present the convergence results under full participation. For
convenience, define
Ierrâ‰œx0âˆ’xâˆ—2, Î³â‰œ8S/Âµâˆ’1, Ï„ minâ‰œmin{Ï„,ËœÏ„}, Ï„ maxâ‰œmax{Ï„,ËœÏ„},(10)
and let Î·trepresent the learning rate at round t. Let fâˆ—denotes the optimal global loss, i.e.,
fâˆ—â‰œf(xâˆ—). All results are obtained based on Assumptions 3.1-3.4. The convergence results for
SFL-V1 and SFL-V2 are summarized in Theorems 3.6 and 3.7, respectively1.
Theorem 3.6. ( SFL-V1: full participation )
Âµ-strongly convex : Let Assumptions 3.1 - 3.3 hold, and Î·t=4
ÂµËœÏ„(Î³+t)for client-side model and
Î·t=4
ÂµÏ„(Î³+t)for server-side model,
E
f(xT)
âˆ’fâˆ—â‰¤8SNPN
n=1a2
n 
2Ïƒ2
n+G2
Âµ2(Î³+T)+768S2PN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³+T) (Î³+ 1)+S(Î³+ 1)Ierr
2(Î³+T).(11)
General convex : Let Assumptions 3.1 - 3.3 hold, and Î·tâ‰¤1
2SÏ„max,
E
f 
xT
âˆ’fâˆ—â‰¤SIerr
2(T+ 1)+1
2 
(ËœÏ„2+Ï„2)IerrN
Ï„2
min(T+ 1)NX
n=1a2
n 
2Ïƒ2
n+G2!1
2
+1
2 
24(ËœÏ„2+Ï„2)SIerr
Ï„2
min(T+ 1)NX
n=1an 
2Ïƒ2
n+G2!1
3
.(12)
Non-convex : Let Assumptions 3.1, 3.2, and 3.4 hold, and Î·tâ‰¤minn
1
16SÏ„max,Ï„min
8SNÏ„2maxPN
n=1a2no
,
1
TTâˆ’1X
t=0Î·tEhâˆ‡xf 
xt2i
â‰¤4
TÏ„min 
f 
x0
âˆ’fâˆ—
+8NS(Ï„2+ËœÏ„2)
TÏ„minNX
n=1a2
n 
Ïƒ2
n+Ïµ2Tâˆ’1X
t=0 
Î·t2.(13)
Theorem 3.7. ( SFL-V2: full participation )
Âµ-strongly convex : Let Assumptions 3.1 - 3.3 hold, and Î·t=4
ÂµËœÏ„(Î³+t)for client-side model and
Î·t=4
ÂµÏ„(Î³+t)for server-side model,
E
f(xT)
âˆ’fâˆ—â‰¤8SNPN
n=1(a2
n+1) 
2Ïƒ2
n+G2
Âµ2(Î³+T)+768S2PN
n=1(an+1) 
2Ïƒ2
n+G2
Âµ3(Î³+T) (Î³+1)+S(Î³+1)Ierr
2(Î³+T).
(14)
General convex : Let Assumptions 3.1 - 3.3 hold, and Î·tâ‰¤1
2SÏ„,
E
f 
xT
âˆ’fâˆ—â‰¤SIerr
2 (T+1)+1
2 
NIerr
T+1NX
n=1(a2
n+1 ) 
2Ïƒ2
n+G2!1
2
+1
2 
24SIerr
T+1NX
n=1(an+1 ) 
2Ïƒ2
n+G2!1
3
.
(15)
Non-convex : Let Assumptions 3.1, 3.2, and 3.4 hold, and Î·tâ‰¤min1
16SÏ„,1
8SN2Ï„	
,
1
TTâˆ’1X
t=0Î·tEhâˆ‡xf 
xt2i
â‰¤4
TÏ„ 
f 
x0
âˆ’fâˆ—
+8NSÏ„
TNX
n=1(a2
n+ 1) 
Ïƒ2
n+Ïµ2Tâˆ’1X
t=0 
Î·t2.(16)
1Following many existing works in FL (e.g., [ 10]), we consider E
f(xT)
âˆ’fâˆ—and
1
TPTâˆ’1
t=0Î·tE[âˆ¥âˆ‡xf(xt)âˆ¥2]as the performance metrics for (strongly) convex and non-convex objectives,
respectively.
6Proofs of Theorems 3.6-3.7 are given in Appendices D-E, respectively. We summarize the key
findings below.
Convergence rate . The convergence bounds of both SFL-V1 and SFL-V2 achieve an order of O(1/T)
on strongly convex (and non-convex) objectives. For general convex objectives, the convergence rate
becomes O(1/3âˆš
T).2Note that our bounds match the existing bounds for FL and SL (in terms of the
order of T) on heterogeneous data for strongly convex objectives. For a more detailed comparison,
please refer to Appendix H.2.3
Impact of data heterogeneity . The convergence bounds increase as the level of data heterogeneity
increases. For example, in (13), the bound increases in Ïµ2(see Assumption 3.4). This means that SFL
tends to perform worse when clientsâ€™ data are more heterogeneous, which is a commonly observed
phenomenon in distributed learning, e.g., FL.
Choice of learning rate. One should use a smaller learning rate when the number of local iteration Ï„
increases. This bears a similar spirit to [ 16]. In addition, our results indicate that a proper choice of
constant learning rate suffices for SFL convergence. It would be an interesting direction to investigate
whether diminishing learning rates are able to achieve faster convergence.
Comparison between SFL-V1 and SFL-V2 . The convergence results between the two SFL versions
are very similar, except that a2
n(andan) in SFL-V1 are replaced by a2
n+ 1(andan+ 1) in SFL-V2.
See (11) and (14) for an inspection. We will show in Sec. 4 that SFL-V1 and SFL-V2 achieve similar
accuracy (except under highly heterogeneous data).
3.4 Results under Partial Participation
Now, we present the results under partial participation.
Theorem 3.8. ( SFL-V1: partial participation )
Âµ-strongly convex : Let Assumptions 3.1 - 3.3 hold, and Î·t=4
ÂµËœÏ„(Î³+t)for client-side model and
Î·t=4
ÂµÏ„(Î³+t)for server-side model,
E
f(xT)
âˆ’fâˆ—â‰¤8SNPN
n=1a2
n
2Ïƒ2
n+G2+G2
qn
Âµ2(Î³+T)+768S2PN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³+T) (Î³+ 1)+S(Î³+1)Ierr
2(Î³+T).(17)
General convex : Let Assumptions 3.1 - 3.3 hold, and Î·tâ‰¤1
2SÏ„max,
E
f 
xT
âˆ’fâˆ—â‰¤SIerr
2(T+ 1)+1
2 
(ËœÏ„2+Ï„2)IerrN
Ï„2
min(T+ 1)NX
n=1a2
n
2Ïƒ2
n+G2+G2
qn!1
2
+1
2 
24(ËœÏ„2+Ï„2)SIerr
Ï„2
min(T+ 1)NX
n=1an 
2Ïƒ2
n+G2!1
3
.(18)
Non-convex : Let Assumptions 3.1, 3.2, and 3.4 hold, and Î·tâ‰¤min{1
16SÏ„max,Ï„min
8SNÏ„2maxPN
n=1a2n
qn},
1
TTâˆ’1X
t=0Î·tEhâˆ‡xf 
xt2i
â‰¤4
TÏ„min 
f 
x0
âˆ’fâˆ—
+8NS(Ï„2+ËœÏ„2)
TÏ„minNX
n=1a2
n
qn 
Ïƒ2
n+Ïµ2Tâˆ’1X
t=0 
Î·t2.(19)
Theorem 3.9. ( SFL-V2: partial participation )
Âµ-strongly convex : Let Assumptions 3.1 - 3.3 hold, and Î·t=4
ÂµËœÏ„(Î³+t)for client-side model and
Î·t=4
ÂµÏ„(Î³+t)for server-side model,
E
f 
xT
âˆ’fâˆ—â‰¤8SNPN
n=1(a2
n+1 )
2Ïƒ2
n+G2+G2
qn
Âµ2(Î³+T)+768S2PN
n=1(an+1 ) 
2Ïƒ2
n+G2
Âµ3(Î³+T) (Î³+ 1)+S(Î³+1)Ierr
2(Î³+T).
(20)
2Note that it might be counter-intuitive to observe looser bounds on general convex objectives than on
non-convex objectives. This is associated with different performance metrics used in the analysis, e.g., see the
left hand side of (12) and (13).
3We also compared SFL to FL and SL in terms of communication/computation overheads in Appendix H.3.
70 50 100 150 200
Training Round020406080100Accuracy
Lc=1
Lc=2Lc=3
Lc=4(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
Lc=1
Lc=2Lc=3
Lc=4 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
Lc=1
Lc=2Lc=3
Lc=4 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round020406080100Accuracy
Lc=1
Lc=2Lc=3
Lc=4 (d) SFL-V2 on CIFAR-100.
Figure 2: Impact of the choice of cut layer on SFL performance.
General convex : Let Assumptions 3.1 - 3.3 hold, and Î·tâ‰¤1
2SÏ„,
E
f 
xT
âˆ’fâˆ—â‰¤SIerr
2(T+ 1)+1
2 
NIerr
T+ 1NX
n=1(a2
n+ 1)
2Ïƒ2
n+G2+G2
n
qn!1
2
+1
2 
24SIerr
T+ 1NX
n=1(an+ 1) 
2Ïƒ2
n+G2!1
3
.(21)
Non-convex : Let Assumptions 3.1, 3.2, and 3.4 hold, and Î·tâ‰¤min
1
16SÏ„,1
8SN2Ï„PN
n=1a2n
qn
,
1
TTâˆ’1X
t=0Î·tEhâˆ‡xf 
xt2i
â‰¤4
TÏ„(f(x0)âˆ’fâˆ—)+8NSÏ„
TNX
n=1a2
n+ 1
qn 
Ïƒ2
n+Ïµ2Tâˆ’1X
t=0 
Î·t2.(22)
The proofs are given in Appendices F-G.
Impact of partial participation . In practical cross-device settings, some clients may not participate
in all rounds of training, i.e., qn<1for some n. This brings an additional term G2/qnto the conver-
gence bound (e.g., see (12) and (18)), meaning that partial participation worsens SFL performance.
This is also observed in FL literature (e.g., [29]) and is consistent with our experimental results.
4 Experimental Results
4.1 Setup
We conduct experiments on CIFAR-10 and CIFAR-100 [ 13].4To simulate data heterogeneity, we
adopt the widely used Dirichlet distribution [ 6] with a controlling parameter Î². Here, a smaller
Î²corresponds to a higher level of data heterogeneity across clients. We use ResNet-18, which
contains four blocks, as the model structure and consider four types of model splitting represented
byLc={1,2,3,4}, where Lc=nmeans the model is split after the n-th residual block. We
consider two major distributed approaches as the benchmark, i.e., FL (in particular FedAvg [ 18])
and SL [ 28]. The learning rates for SFL-V1, SFL-V2, FL, and SL are set as 0.01. The batch-
sizebsis 128, and we run experiments for T= 200 rounds. Unless stated otherwise, we use
N= 10 ,Î²= 0.1,E= 5, where Eis the number of local epochs for client-side model aggregation
(i.e., every Etimes of training performed over each clientâ€™s dataset, their client-side models are
aggregated at the fed server), and hence Ï„=âŒˆDn
bsâŒ‰ Ã—E. We set Ï„= ËœÏ„for the fair comparison
to vanilla FL. The experiments are run on a CPU (Intel(R) Xeon(R) Gold 5320 at 2.20GHz) and
a GPU (A100-PCIE-80GB). Our codes are provided in https://github.com/TIANGeng708/
Convergence-Analysis-of-Split-Federated-Learning-on-Heterogeneous-Data .
4.2 Impact of system parameters on SFL performance
Impact of cut layer . We first investigate how the choice of the cut layer Lcaffects the SFL
performance. The results are reported in Fig. 2. We observe that for both SFL-V1 and SFL-V2,
4More experiments on FEMNIST are given in Appendix I.5.
80 50 100 150 200
Training Round020406080100Accuracy
=0.1
=0.5
=1
=
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
=0.1
=0.5
=1
=
 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
=0.1
=0.5
=1
=
 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round020406080100Accuracy
=0.1
=0.5
=1
=
 (d) SFL-V2 on CIFAR-100.
Figure 3: Impact of data heterogeneity on SFL performance.
0 50 100 150 200
Training Round020406080100Accuracy
q=0.2
q=0.5q=1
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
q=0.2
q=0.5q=1 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
q=0.2
q=0.5q=1 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round020406080100Accuracy
q=0.2
q=0.5q=1 (d) SFL-V2 on CIFAR-100.
Figure 4: Impact of client participation on SFL performance.
the performance increases in Lc(i.e., clients have a larger proportion of the global model). This is
associated with our empirical observation that the average client gradient variance gets smaller with
Lc. Intuitively, a smaller gradient variance implies a lower degree of the client drift issue, which
leads to a better algorithm performance.5Based on this observation, we use Lc= 4for SFL (and SL)
for the following experiments.
Impact of data heterogeneity . We study the impact of data heterogeneity on SFL performance,
where we use Î²âˆˆ {0.1,0.5,1,âˆž}, andÎ²=âˆžmeans clients have IID data. The results are reported
in Fig. 3. We observe that a higher level of data heterogeneity (i.e., a smaller Î²) leads to slower
algorithm convergence and a lower accuracy for both SFL-V1 and SFL-V2. The observation is
consistent with our convergence bound, e.g., in (16), the performance bound increases in Ïµ2. Note
that the negative impact of heterogeneity is commonly observed in distributed learning literature
including FL [7] and SL [21].
Impact of partial participation . We study the impact of client participation and let qn=qâˆˆ
{0.2,0.5,1},âˆ€n.The results are reported in Fig. 4. We observe that a lower level of participation
leads to less stable convergence and also a smaller accuracy. This is consistent with our convergence
results, e.g., in (20), the bound decreases in clientsâ€™ participation level qn. Partial participation is
expected in practical cross-device scenarios where clients are resourced-constrained edge devices. It
is important to develop efficient algorithms as well as effective incentive mechanisms to encourage
clientsâ€™ participation in SFL.
4.3 Comparison among SFL, FL, and SL.
We now compare SFL to FL and SL. We consider different combinations of data heterogeneity
Î²âˆˆ {0.1,0.5}and cohort sizes Nâˆˆ {10,50,100}. The results are reported in Fig. 5. When data
is mildly heterogeneous (i.e., Î²= 0.5), SFL and FL have similar convergence rates and accuracy
performance. Note that SL seems to under-perform SFL and FL. We think this is mainly due to the
catastrophic forgetting issue, which has been observed in [21, 2].
SFL outperforms FL and SL under highly heterogeneous data and a large client number .
When data becomes more non-IID (i.e., Î²= 0.1), SFL-V2 tends to outperform FL and SL. The
improvement becomes more significant as the cohort size gets larger. The bottleneck of FL is the client
drift issue caused by data heterogeneity. The bottleneck of SL is associated with the catastrophic
forgetting. SFL-V2 is a hybrid combination of FL and SL, which can lead to a better tradeoff
between client drift and forgetting. By appropriately choosing the cut layer, SFL-V2 outperforms
5See Appendix I.4 for more detailed discussions on this point.
90 50 100 150 200
Training Round020406080100Accuracy
SFL-V1
SFL-V2FL
SL(a)Î²= 0.5, N= 10 .
0 50 100 150 200
Training Round020406080100AccuracySFL-V1
SFL-V2FL
SL (b)Î²= 0.1, N= 10 .
0 50 100 150 200
Training Round020406080100AccuracySFL-V1
SFL-V2FL
SL (c)Î²= 0.1, N= 50 .
0 50 100 150 200
Training Round020406080100AccuracySFL-V1
SFL-V2FL
SL (d)Î²= 0.1, N= 100 .
Figure 5: Performance comparison on CIFAR-10.
FL and SL. This observation also indicates that SFL-V2 can be a more appealing solution than
FL for practical cross-device systems, as it achieves a better performance while requiring smaller
computation overheads from edge devices.
5 Conclusion
In this work, we provided the first comprehensive convergence analysis of SFL for strongly convex,
general-convex, and non-convex objectives on heterogeneous data. One key challenge is the dual-
paced model updates. We get around this issue by decomposing the performance gap of the global
model into the client-side and server-side gaps. We further extend our analysis to the more practical
scenario with partial client participation. Experimental experiments validate our theories and further
show that SFL can outperform FL and SL under highly heterogeneous data and a large client number.
One limitation of our work is that our bounds for SFL achieve the same order (in terms of training
rounds) as in FL, yet the experiments showed that SFL outperforms FL under high heterogeneity.
This is possibly due to that tighter bounds for SFL are to be derived, which is an important future
work. For future work, one can apply our derived bounds to optimize SFL system performance,
considering model accuracy, communication overhead, and computational workload of clients. It is
also interesting to theoretically analyze how the choice of the cut layer affects the SFL performance.
10References
[1]Ahmed M Abdelmoniem, Atal Narayan Sahu, Marco Canini, and Suhaib A Fahmy. Refl:
Resource-efficient federated learning. In Proceedings of the Eighteenth European Conference
on Computer Systems , pages 215â€“232, 2023.
[2]Yansong Gao, Minki Kim, Sharif Abuadbba, Yeonjae Kim, Chandra Thapa, Kyuyeon Kim,
Seyit A Camtepe, Hyoungshick Kim, and Surya Nepal. End-to-end evaluation of federated
learning and split learning for internet of things. arXiv preprint arXiv:2003.13376 , 2020.
[3]Dong-Jun Han, Hasnain Irshad Bhatti, Jungmoon Lee, and Jaekyun Moon. Accelerating
federated learning with split learning on locally generated losses. In ICML workshop on
federated learning for user privacy and data confidentiality , 2021.
[4]Dong-Jun Han, Do-Yeon Kim, Minseok Choi, Christopher G Brinton, and Jaekyun Moon.
Splitgp: Achieving both generalization and personalization in federated learning. Proc. of IEEE
INFOCOM , 2023.
[5]Pengchao Han, Chao Huang, Xingyan Shi, Jianwei Huang, and Xin Liu. Incentivizing partici-
pation in splitfed learning: Convergence analysis and model versioning. In 2024 IEEE 44th
International Conference on Distributed Computing Systems (ICDCS) , pages 846â€“856, 2024.
[6]Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical
data distribution for federated visual classification. arXiv preprint arXiv:1909.06335 , 2019.
[7]Chao Huang, Shuqi Ke, and Xin Liu. Duopoly business competition in cross-silo federated
learning. IEEE Transactions on Network Science and Engineering , 2023.
[8]Chao Huang, Geng Tian, and Ming Tang. When minibatch sgd meets splitfed learning: Conver-
gence analysis and performance evaluation. arXiv preprint arXiv:2308.11953 , 2023.
[9]Yang Jiao, Kai Yang, Tiancheng Wu, Chengtao Jian, and Jianwei Huang. Provably convergent
federated trilevel learning. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 38, pages 12928â€“12937, 2024.
[10] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International conference on machine learning , pages 5132â€“5143. PMLR, 2020.
[11] Ahmed Khaled, Konstantin Mishchenko, and Peter RichtÃ¡rik. Tighter theory for local sgd on
identical and heterogeneous data. In International Conference on Artificial Intelligence and
Statistics , pages 4519â€“4529. PMLR, 2020.
[12] Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A
unified theory of decentralized sgd with changing topology and local updates. In International
Conference on Machine Learning , pages 5381â€“5393. PMLR, 2020.
[13] Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
[14] Qinbin Li, Bingsheng He, and Dawn Song. Model-contrastive federated learning. In Proceedings
of the IEEE/CVF conference on computer vision and pattern recognition , pages 10713â€“10722,
2021.
[15] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia
Smith. Federated optimization in heterogeneous networks. Proceedings of Machine learning
and systems , 2:429â€“450, 2020.
[16] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence
of fedavg on non-iid data. In Proc. of ICLR , 2020.
[17] Yipeng Li and Xinchen Lyu. Convergence analysis of sequential federated learning on het-
erogeneous data. In Thirty-seventh Conference on Neural Information Processing Systems ,
2023.
11[18] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial
intelligence and statistics , pages 1273â€“1282. PMLR, 2017.
[19] Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Kone Ë‡cn`y,
Sanjiv Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint
arXiv:2003.00295 , 2020.
[20] Sashank Reddi, Zachary Burr Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub
Kone Ë‡cnÃ½, Sanjiv Kumar, and Brendan McMahan, editors. Adaptive Federated Optimization ,
2021.
[21] Jinglong Shen, Nan Cheng, Xiucheng Wang, Feng Lyu, Wenchao Xu, Zhi Liu, Khalid Al-
dubaikhy, and Xuemin Shen. Ringsfl: An adaptive split federated learning towards taming
client heterogeneity. IEEE Transactions on Mobile Computing , 2023.
[22] Chamani Shiranthika, Zahra Hafezi Kafshgari, Parvaneh Saeedi, and Ivan V Baji Â´c. Splitfed
resilience to packet loss: Where to split, that is the question. In International Conference on
Medical Image Computing and Computer-Assisted Intervention , pages 367â€“377. Springer, 2023.
[23] Veronika Stephanie, Ibrahim Khalil, and Mohammed Atiquzzaman. Digital twin enabled
asynchronous splitfed learning in e-healthcare systems. IEEE Journal on Selected Areas in
Communications , 41(11):3650â€“3661, 2023.
[24] Sebastian U Stich. Unified optimal analysis of the (stochastic) gradient method. arXiv preprint
arXiv:1907.04232 , 2019.
[25] Yue Tan, Yixin Liu, Guodong Long, Jing Jiang, Qinghua Lu, and Chengqi Zhang. Federated
learning on non-iid graphs via structural knowledge sharing. In Proceedings of the AAAI
conference on artificial intelligence , volume 37, pages 9953â€“9961, 2023.
[26] Ming Tang and Vincent WS Wong. Tackling system induced bias in federated learning:
Stratification and convergence analysis. In Proc. of IEEE INFOCOM , pages 1â€“10, 2023.
[27] Chandra Thapa, Pathum Chamikara Mahawaga Arachchige, Seyit Camtepe, and Lichao Sun.
Splitfed: When federated learning meets split learning. In Proc. of AAAI , volume 36, pages
8485â€“8493, 2022.
[28] Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, and Ramesh Raskar. Split learning for
health: Distributed deep learning without sharing raw patient data. ICLR Workshop on AI for
Social Good , 2019.
[29] Shiqiang Wang and Mingyue Ji. A unified analysis of federated learning with arbitrary client
participation. Advances in Neural Information Processing Systems , 35:19124â€“19137, 2022.
[30] Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian Makaya, Ting He,
and Kevin Chan. Adaptive federated learning in resource constrained edge computing systems.
IEEE journal on selected areas in communications , 37(6):1205â€“1221, 2019.
[31] Dinah Waref and Mohammed Salem. Split federated learning for emotion detection. In 2022
4th Novel Intelligent and Leading Emerging Sciences Conference (NILES) , pages 112â€“115.
IEEE, 2022.
[32] Blake Woodworth, Kumar Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, Brendan
Mcmahan, Ohad Shamir, and Nathan Srebro. Is local sgd better than minibatch sgd? In
International Conference on Machine Learning , pages 10334â€“10343. PMLR, 2020.
[33] Blake E Woodworth, Kumar Kshitij Patel, and Nati Srebro. Minibatch vs local sgd for heteroge-
neous distributed learning. Advances in Neural Information Processing Systems , 33:6281â€“6292,
2020.
[34] Wen Wu, Mushu Li, Kaige Qu, Conghao Zhou, Xuemin Shen, Weihua Zhuang, Xu Li, and
Weisen Shi. Split learning over wireless networks: Parallel design and resource management.
IEEE Journal on Selected Areas in Communications , 41(4):1051â€“1066, 2023.
[35] Haibo Yang, Minghong Fang, and Jia Liu. Achieving linear speedup with partial worker
participation in non-iid federated learning. Proc. of ICLR , 2021.
12A Appendix / supplemental material
We organize the entire appendix file as follows:
In Sec. B, we provide detailed algorithmic descriptions.
In Sec. C, we provide notations and some technical lemmas.
â€¢ In Sec. C.1, we provide some notations
â€¢ In Sec. C.2, we recall SFL-V1 and SFL-V2
â€¢ In Sec. C.3, we recall the assumptions
â€¢ In Sec. C.4, we provide some useful technical lemmas together with their proofs
In Sec. D, we prove Theorem 3.6, i.e., convergence of SFL-V1 under full participation .
â€¢ In Sec. D.1, we prove the strongly convex case
â€¢ In Sec. D.2, we prove the general convex case
â€¢ In Sec. D.3, we prove the non-convex case
In Sec. E, we prove Theorem 3.7, i.e., convergence of SFL-V2 under full participation .
â€¢ In Sec. E.1, we prove the strongly convex case
â€¢ In Sec. E.2, we prove the general convex case
â€¢ In Sec. E.3, we prove the non-convex case
In Sec. F, we prove Theorem 3.8, i.e., convergence of SFL-V1 under partial participation .
â€¢ In Sec. F.1, we prove the strongly convex case
â€¢ In Sec. F.2, we prove the general convex case
â€¢ In Sec. F.3, we prove the non-convex case
In Sec. G, we prove Theorem 3.9, i.e., convergence of SFL-V2 under partial participation .
â€¢ In Sec. G.1, we prove the strongly convex case
â€¢ In Sec. G.2, we prove the general convex case
â€¢ In Sec. G.3, we prove the non-convex case
In Sec. H, we SFL to other distributed approaches, i.e., FL, SL, and Mini-Batch SGD.
â€¢ In Sec. H.2, we compare their convergence bounds
â€¢ In Sec. H.3, we compare their overheads in terms of communication and computation
In Sec. I, we provide more experimental results.
13B Algorithm description
For version 1, the client-side model parameter and M-server-side model parameter are aggregated
every Ï„andËœÏ„iterations, respectively. In iteration iof round t, each client nsamples a mini-batch
of data Î¶t,i
nfromDn, computes the intermediate features h(xt,i
c,n;Î¶t,i
n)(e.g., activation values at
the cut layer) over its current model xt,i
c,n, and sends h(xt,i
c,n;Î¶t,i
n)to the M-server. For each client
n, the M-server computes the loss Fn(h(xt,i
c,n;Î¶t,i
n),xt,i
s,n)based on xt,i
s,n. Letâˆ‡denote a gradient
operator and âˆ‡wFrepresents the gradient of Fw.r.t.w. The M-server computes the M-server-side
gradient gt,i
s,n(xt,i
s,n;Î¶t,i
n) =âˆ‡xsFn(h(xt,i
c,n;Î¶t,i
n),xt,i
s,n), the gradient over the intermediate features
(activations) at the cut layer rt,i
c,n(xt,i
s,n;Î¶t,i
n) =âˆ‡hFn(h(xt,i
c,n;Î¶t,i
n),xt,i
s,n), and sends rt,i
c,n(xt,i
s,n;Î¶t,i
n)
to client n. Each client ncomputes the client-side gradient gt,i
c,n(xt,i
c,n;Î¶t,i
n)based on rt,i
c,n(xt,i
s,n;Î¶t,i
n)
using the chain rule.
For version 2, the client-side model is aggregated every Ï„iterations, while the M-server trains only
one version of the M-server-side model.
Algorithm 1: SFL-V1 under clientsâ€™ partial participation
Input: Ï„,ËœÏ„, T, and learning rate Î·t
Output: Global model xT={xT
c,xT
s}
1Initialize x0={x0
c,x0
s};
2fori= 0, . . . , (Tâˆ’1)Ï„maxdo
3 Determine participating client set PtâŠ† N according to qn;
Phase 1: model training.
4 each client nâˆˆ Pt:
5 Sample a mini-batch Î¶t,i
n;
6 Send h(xt,i
c,n;Î¶t,i
n)to the M-server;
7 the M-server:
8 Compute Fn(h(xt,i
c,n;Î¶t,i
n),xt,i
s),gt,i
s,n(xt,i
s,n;Î¶t,i
n), and
rt,i
c,n(xt,i
s,n;Î¶t,i
n);
9 Sendrt,i
c,n(xt,i
s,n;Î¶t,i
n)to client nâˆˆ Pt;
10 xt,i+1
s,nâ†xt,i
s,nâˆ’Î·tgt,i
s,n(xt,i
s,n;Î¶t,i
n);
11 Compute gt,i
c,n(xt,i
c,n;Î¶t,i
n);
12 xt,i+1
c,nâ†xt,i
c,nâˆ’Î·tgt,i
c,n(xt,i
c,n;Î¶t,i
n);
Phase 2: model aggregation.
13 ifi%Ï„= 0then
14 each client nâˆˆ Pt:
15 Sendxt,Ï„
c,nto the F-server;
16 the F-server:
17 xt+1
câ†P
nâˆˆPtan
qnxt,Ï„
c,n;
18 each client nâˆˆ N :
19 xt,0
c,nâ†xt
c;
20 ifi%ËœÏ„= 0then
21 the M-server:
22 xt+1
sâ†P
nâˆˆPtan
qnxt,ËœÏ„
s,n.
23 xt,0
s,nâ†xt
s,âˆ€nâˆˆ N ;
14Algorithm 2: SFL-V2 under clientsâ€™ partial participation
Input: Ï„, T, and learning rate Î·t
Output: Global model xT={xT
c,xT
s}
1Initialize x0={x0
c,x0
s};
2fort= 0, . . . , T âˆ’1do
3 Determine participating client set PtâŠ† N according to qn;
Phase 1: model training.
4 each client nâˆˆ Pt:
5 xt,0
c,nâ†xt
c;
6 fori= 0, . . . , Ï„ âˆ’1do
7 Sample a mini-batch Î¶t,i
n;
8 Send h(xt,i
c,n;Î¶t,i
n)to the M-server;
9 the M-server:
10 Compute Fn(h(xt,i
c,n;Î¶t,i
n),xt,i
s),gt,i
s,n(xt,i
s;Î¶t,i
n), and
rt,i
c,n(xt,i
s;Î¶t,i
n);
11 Sendrt,i
c,n(xt,i
s;Î¶t,i
n)to client nâˆˆ Pt;
12 xt,i+1
sâ†xt,i
sâˆ’Î·t
qngt,i
s,n(xt,i
s;Î¶t,i
n);
13 Compute gt,i
c,n(xt,i
c,n;Î¶t,i
n);
14 xt,i+1
c,nâ†xt,i
c,nâˆ’Î·tgt,i
c,n(xt,i
c,n;Î¶t,i
n);
15 the M-server:
16 xt+1,0
sâ†xt,Ï„
s;
Phase 2: model aggregation.
17 each client nâˆˆ Pt:
18 Sendxt,Ï„
c,nto the F-server;
19 the F-server:
20 xt+1
câ†P
nâˆˆPtan
qnxt,Ï„
c,n.
15C Notations and technical lemmas
C.1 Notations
Recall that the objective of SFL is given by
min
xf(x) :=NX
n=1anFn(x) (23)
We define
â€¢xcandxs: global model parameter on the clients and server sides, respectively.
â€¢xc,nandxs,n: local forms of parameter on client nand on the main server corresponding
to client n(in SFL-V1).
â€¢âˆ‡Fc,n(Â·)andâˆ‡Fs,n(Â·): the gradients of Fn(Â·)overxcandxs, respectively.
â€¢gc,n(Â·)andgs,n(Â·): the stochastic gradients of Fn(Â·)overxcandxs, respectively.
For convenience, we omit the notation for mini-batch training data when referring to stochastic
gradients.
Further, we recall how SFL-V1 and SFL-V2 update models below.
C.2 SFL-V1 and SFL-V2 model updates
Letqndenote the participating probability of client nand define q:={q1, . . . , q N}. We denote It
n
as a binary variable, taking 1 if client nparticipates in model training in round t, and 0 otherwise. It
n
follows a Bernoulli distribution with an expectation of qn. Denote Pt(q)as the set of participating
clients in round t.
Parameter update for SFL-V1:
â€¢ Local training of client n:xt,0
c,nâ†xt
c,xt,i+1
c,nâ†xt,i
c,nâˆ’Î·tgt,i
c,n 
xt,i
c,n
,xt+1
c,nâ†xt,Ï„
c,n;
â€¢ Client-side global aggregation:
â€“Full participation: xt+1
câ†xt
câˆ’Î·tP
nâˆˆNanPÏ„
i=0gt,i
c,n 
xt,i
c,n
;
â€“Partial participation: xt+1
câ†xt
câˆ’Î·tP
nâˆˆPt(q)an
qnPÏ„
i=0gt,i
c,n 
xt,i
c,n
;
â€¢ M-server-side model update:
â€“Full participation: xt+1
sâ†xt
sâˆ’Î·tP
nâˆˆNanPËœÏ„âˆ’1
i=0gt,i
s,n 
xt,i
s,n
;
â€“Partial participation: xt+1
sâ†xt
sâˆ’Î·tP
nâˆˆPt(q)an
qnPËœÏ„âˆ’1
i=0gt,i
s,n 
xt,i
s,n
.
Parameter update for SFL-V2:
â€¢ Local training of client n:xt,0
c,nâ†xt
c,xt,i+1
c,nâ†xt,i
c,nâˆ’Î·tgt,i
c,n 
xt,i
c,n
,xt+1
c,nâ†xt,Ï„
c,n;
â€¢ Client-side global aggregation:
â€“Full participation: xt+1
câ†xt
câˆ’Î·tP
nâˆˆNanPÏ„
i=0gt,i
c,n 
xt,i
c,n
;
â€“Partial participation: xt+1
câ†xt
câˆ’Î·tP
nâˆˆPt(q)an
qnPÏ„
i=0gt,i
c,n 
xt,i
c,n
;
â€¢ M-server-side model update:
â€“Full participation: xt+1
sâ†xt
sâˆ’Î·tP
nâˆˆNPÏ„âˆ’1
i=0gt,i
s,n 
xt,i
s,n
;
â€“Partial participation: xt+1
sâ†xt
sâˆ’Î·tP
nâˆˆPt(q)1
qnPÏ„âˆ’1
i=0gt,i
s,n 
xt,i
s,n
.
C.3 Assumptions
We further recall the following assumptions for clientsâ€™ loss functions in the proof.
Assumption C.1. For each client nâˆˆ N :
16â€¢ The loss Fn(Â·)isS-smooth:
âˆ¥âˆ‡Fn(x)âˆ’ âˆ‡Fn(y)âˆ¥ â‰¤Sâˆ¥xâˆ’yâˆ¥,âˆ€x,y, (24)
Fn(y)â‰¤Fn(x) +âŸ¨âˆ‡Fn(x),yâˆ’xâŸ©+S
2âˆ¥yâˆ’xâˆ¥2,âˆ€x,yâˆˆRd. (25)
â€¢ The stochastic gradients of Fn(Â·)are unbiased with the variance bounded by Ïƒ2
n:
E[gn(x)] =âˆ‡Fn(x), (26)
Eh
âˆ¥gn(x)âˆ’ âˆ‡Fn(x)âˆ¥2i
â‰¤Ïƒ2
n. (27)
â€¢ The expected squared norm of stochastic gradients is bounded by G2:
Eâˆ¥gn(x)âˆ¥2â‰¤G2. (28)
â€¢(Bounded gradient divergence) There exists a constant Ïµ >0, such that the divergence
between local and global gradients is bounded by Ïµ2:
âˆ¥âˆ‡Fn(x)âˆ’ âˆ‡f(x)âˆ¥2â‰¤Ïµ2. (29)
Assumption C.2. For each client nâˆˆ N :
â€¢ The loss Fn(Â·)isÂµ-strongly convex for some Âµâ‰¥0:
Fn(y)â‰¥Fn(x) +âŸ¨âˆ‡Fn(x),yâˆ’xâŸ©+Âµ
2âˆ¥yâˆ’xâˆ¥2,âˆ€x,yâˆˆRd. (30)
Here, we allow that Âµ= 0, referring to this case of the general convex.
C.4 Technical Lemmas
Lemma C.3. [Lemma 5 in [ 10]] The following holds for any S-smooth and Âµ-strongly convex
function h, and any x, y, z in the domain of h:
âŸ¨âˆ‡h(x),zâˆ’yâŸ© â‰¥h(z)âˆ’h(y) +Âµ
4âˆ¥yâˆ’zâˆ¥2âˆ’Sâˆ¥zâˆ’xâˆ¥2. (31)
Proof of Proposition 3.5
Proposition 3.5 (Convergence decomposition) Let xâˆ—â‰œ[xâˆ—
c;xâˆ—
s]denote the optimal global model
that minimizes f(Â·), andxTâ‰œ[xT
c;xT
s]is the global model obtained after Trounds of SFL training.
Under Assumption 3.1, we have
E
f(xT)
âˆ’f(xâˆ—)â‰¤S
2 
E||xT
sâˆ’xâˆ—
s||2+E||xT
câˆ’xâˆ—
c||2
. (32)
Proof. Since Fnâ€™s are S-smooth, it is easy to show that the global loss function f(Â·)is also S-smooth.
Thus, we have
E
f(xT)
âˆ’f(xâˆ—)â‰¤E
âŸ¨xTâˆ’xâˆ—,âˆ‡f(xâˆ—)âŸ©
+S
2E
||xTâˆ’xâˆ—||2
=S
2E
||xTâˆ’xâˆ—||2
. (33)
SincexTâ‰œ[xT
c;xT
s], andxâˆ—â‰œ[xâˆ—
c;xâˆ—
s], we have
E
||xTâˆ’xâˆ—||2
=E
||[xT
c;xT
s]âˆ’[xâˆ—
c;xâˆ—
s]||2
=E
||[xT
câˆ’xâˆ—
c;xT
sâˆ’xâˆ—
s]||2
=E
||xT
câˆ’xâˆ—
c||2
+E
||xT
sâˆ’xâˆ—
s||2
.(34)
Substituting (34) into (33), we complete the proof.
Proposition C.4 (Decomposition in each round) .Under Assumption C.1, we have
E
f 
xt+1
âˆ’f 
xt
â‰¤E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
+S
2Ehxt+1
câˆ’xt
c2i
+ (35)
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
+S
2Ehxt+1
sâˆ’xt
s2i
. (36)
17Proof. The proposition can be easily proved by the S-smoothness of f(Â·).
Lemma C.5. [Multiple iterations of local training in each round] Under Assumption C.1, if we let
Î·tâ‰¤1âˆš
6SÏ„and run client nâ€™s local model for Ï„iteration continuously in any round t, we have
Ï„âˆ’1X
i=0Ehxt,i
nâˆ’xt2i
â‰¤12Ï„3 
Î·t2 
2Ïƒ2
n+G2
. (37)
Proof. Similar to Lemma 3 in [20], we have
Ehxt,i
nâˆ’xt2i
â‰¤Ehxt,iâˆ’1
nâˆ’Î·tgt,iâˆ’1
nâˆ’xt2i
â‰¤Ehxt,iâˆ’1
nâˆ’xtâˆ’Î·t 
gt,iâˆ’1
nâˆ’âˆ‡xFn 
xt,iâˆ’1
n
+âˆ‡xFn 
xt,iâˆ’1
n
âˆ’âˆ‡xFn 
xt
+âˆ‡xFn 
xt2i
â‰¤
1 +1
Ï„
Ehxt,iâˆ’1
nâˆ’xt2i
+ 3 (1 + Ï„)EhÎ·t 
gt,iâˆ’1
nâˆ’ âˆ‡xFn 
xt,iâˆ’1
n2i
+ 3 (1 + Ï„)EhÎ·t 
âˆ‡xFn 
xt,iâˆ’1
n
âˆ’ âˆ‡xFn 
xt2i
+ 3 (1 + Ï„)EhÎ·t 
âˆ‡xFn 
xt2i
â‰¤
1 +1
Ï„
Ehxt,iâˆ’1
nâˆ’xt2i
+ 3 (1 + Ï„) 
Î·t2Ïƒ2
n
+ 3 (1 + Ï„) 
Î·t2S2Ehxt,iâˆ’1
nâˆ’xt2i
+ 3 (1 + Ï„) 
Î·t2Ehâˆ‡xFn 
xt2i
â‰¤
1 +1
Ï„+ 6Ï„ 
Î·t2S2
Ehxt,iâˆ’1
nâˆ’xt2i
+ 6Ï„ 
Î·t2Ïƒ2
n+ 6Ï„ 
Î·t2Ehâˆ‡xFn 
xt2i
â‰¤
1 +2
Ï„
Ehxt,iâˆ’1
nâˆ’xt2i
+ 6Ï„ 
Î·t2Ïƒ2
n+ 6Ï„ 
Î·t2Ehâˆ‡xFn 
xt2i
,
â‰¤
1+2
Ï„
Ehxt,iâˆ’1
nâˆ’xt2i
+6Ï„ 
Î·t2Ïƒ2
n+6Ï„ 
Î·t2
Ehâˆ‡xFn 
xt
âˆ’gt
n2i
+Ehâˆ‡xgt
n2i
,
â‰¤
1 +2
Ï„
Ehxt,iâˆ’1
nâˆ’xt2i
+ 6Ï„ 
Î·t2 
2Ïƒ2
n+G2
, (38)
where we use Assumption C.1, (X+Y)2â‰¤(1 +a)X2+ 
1 +1
a
Y2for some positive a, and
Î·tâ‰¤1âˆš
6SÏ„.
Let
At,i:=Ehxt,i
nâˆ’xt2i
B:= 6Ï„ 
Î·t2 
2Ïƒ2
n+G2
C:= 1 +2
Ï„
We have
At,iâ‰¤CAt,iâˆ’1+B (39)
We can show that
At,1â‰¤CAt+B
At,2â‰¤CAt,1+Bâ‰¤C2At+CB+B
At,3â‰¤CAt,2+Bâ‰¤C3At+C2B+CB+B
. . .
At,iâ‰¤CiAt+Biâˆ’1X
j=0Cj
18Note that At:=At,0=Eh
âˆ¥xtâˆ’xtâˆ¥2i
= 0. Accumulate the above for Ï„iterations, we have
Ï„âˆ’1X
i=0Ehxt,i
nâˆ’xt2i
=Ï„âˆ’1X
i=0Biâˆ’1X
j=0Cj
=BÏ„âˆ’1X
i=0Ciâˆ’1
Câˆ’1=B
Câˆ’1Ï„âˆ’1X
i=0 
Ciâˆ’1
=B
Câˆ’1CÏ„âˆ’1
Câˆ’1âˆ’Ï„
=B
2
Ï„  
1 +2
Ï„Ï„âˆ’1
2
Ï„âˆ’Ï„!
(40)
â‰¤Ï„2B
2e2âˆ’1
2âˆ’1
â‰¤2Ï„2B
â‰¤2Ï„26Ï„ 
Î·t2 
2Ïƒ2
n+G2
â‰¤12Ï„3 
Î·t2 
2Ïƒ2
n+G2
. (41)
The first inequality is due toPNâˆ’1
i=0xi=xNâˆ’1
Xâˆ’1and the third line results from (1 +n
x)xâ‰¤en. Thus,
we finish the proof.
Lemma C.6. [Multiple iterations of local training in each round] Under Assumption C.1, if we let
Î·tâ‰¤1âˆš
8SÏ„and run client nâ€™s local model for Ï„iteration continuously in any round t, we have
Ï„âˆ’1X
i=0Ehxt,i
nâˆ’xt2i
â‰¤2Ï„2
8Ï„ 
Î·t2Ïƒ2
n+ 8Ï„ 
Î·t2Ïµ2+ 8Ï„ 
Î·t2âˆ‡xf 
xt2
. (42)
Proof.
Ehxt,i
nâˆ’xt2i
â‰¤Ehxt,iâˆ’1
nâˆ’Î·tgt,iâˆ’1
nâˆ’xt2i
â‰¤Ext,iâˆ’1
nâˆ’xtâˆ’Î·t 
gt,iâˆ’1
nâˆ’ âˆ‡xFn 
xt,iâˆ’1
n
+âˆ‡xFn 
xt,iâˆ’1
n
âˆ’ âˆ‡xFn 
xt
+âˆ‡xFn 
xt
âˆ’ âˆ‡xf 
xt
+âˆ‡xf 
xt2i
â‰¤
1 +1
Ï„
Ehxt,iâˆ’1
nâˆ’xt2i
+ 8Ï„EhÎ·t 
gt,iâˆ’1
nâˆ’ âˆ‡xFn 
xt,iâˆ’1
n2i
+ 8Ï„EhÎ·t 
âˆ‡xFn 
xt,iâˆ’1
n
âˆ’ âˆ‡xFn 
xt2i
+ 8Ï„EhÎ·t 
âˆ‡xFn 
xt
âˆ’ âˆ‡xf 
xt2i
+ 8Ï„Î·tâˆ‡xf 
xt2
â‰¤
1 +1
Ï„
Ehxt,iâˆ’1
nâˆ’xt2i
+ 8Ï„ 
Î·t2Ïƒ2
n+ 8Ï„ 
Î·t2S2Ehxt,iâˆ’1
nâˆ’xt2i
+ 8Ï„ 
Î·t2Ïµ2
+ 8Ï„ 
Î·t2âˆ‡xf 
xt2
â‰¤
1+1
Ï„+8Ï„ 
Î·t2S2
Ehxt,iâˆ’1
nâˆ’xt2i
+8Ï„ 
Î·t2Ïƒ2
n+8Ï„ 
Î·t2Ïµ2+8Ï„ 
Î·t2âˆ‡xf 
xt2
â‰¤
1 +2
Ï„
Ehxt,iâˆ’1
nâˆ’xt2i
+ 8Ï„ 
Î·t2Ïƒ2
n+ 8Ï„ 
Î·t2Ïµ2+ 8Ï„ 
Î·t2âˆ‡xf 
xt2(43)
where we have applied Assumption C.1, (X+Y)2â‰¤(1 +a)X2+ 
1 +1
a
Y2for some positive
a, and Î·tâ‰¤1âˆš
8SÏ„.
Let
At,i:=Ehxt,i
nâˆ’xt2i
19B:= 8Ï„ 
Î·t2Ïƒ2
n+ 8Ï„ 
Î·t2Ïµ2+ 8Ï„ 
Î·t2âˆ‡xf 
xt2
C:= 1 +2
Ï„
We have
At,iâ‰¤CAt,iâˆ’1+B (44)
We can show that
At,iâ‰¤CiAt+Biâˆ’1X
j=0Cj
Note that At=Eh
âˆ¥xtâˆ’xtâˆ¥2i
= 0. Accumulate the above for Ï„iterations, we have
Ï„âˆ’1X
i=0Ehxt,i
nâˆ’xt2i
=Ï„âˆ’1X
i=0Biâˆ’1X
j=0Cj
â‰¤2Ï„2B
â‰¤2Ï„2
8Ï„ 
Î·t2Ïƒ2
n+ 8Ï„ 
Î·t2Ïµ2+ 8Ï„ 
Î·t2âˆ‡xf 
xt2
(45)
where we usePNâˆ’1
i=0xi=xNâˆ’1
Xâˆ’1and(1 +n
x)xâ‰¤en. Therefore, we complete the proof.
Lemma C.7. [Multiple iterations of local gradient accumulation in each round] Under Assumption
C.1, if we let Î·tâ‰¤1
2SÏ„and run client nâ€™s local model for Ï„iteration continuously in any round t, we
have
Ï„âˆ’1X
i=0Ehgt,i
nâˆ’gt
n2i
â‰¤8Ï„3 
Î·t2S2âˆ‡xFn 
xt2+Ïƒ2
n
. (46)
Proof.
Ehgt,i
nâˆ’gt
n2i
â‰¤Ehgt,i
nâˆ’gt,iâˆ’1
n+gt,iâˆ’1
nâˆ’gt
n2i
â‰¤(1 +Ï„)Ehgt,i
nâˆ’gt,iâˆ’1
n2i
+
1 +1
Ï„
Ehgt,iâˆ’1
nâˆ’gt
n2i
â‰¤(1 +Ï„)S2Ehxt,i
nâˆ’xt,iâˆ’1
n2i
+
1 +1
Ï„
Ehgt,iâˆ’1
nâˆ’gt
n2i
â‰¤(1 +Ï„) 
Î·t2S2Ehgt,iâˆ’1
n2i
+
1 +1
Ï„
Ehgt,iâˆ’1
nâˆ’gt
n2i
â‰¤(1 +Ï„) 
Î·t2S2Ehgt,iâˆ’1
nâˆ’gt
n+gt
n2i
+
1 +1
Ï„
Ehgt,iâˆ’1
nâˆ’gt
n2i
â‰¤2 (1 + Ï„) 
Î·t2S2Ehgt,iâˆ’1
nâˆ’gt
n2i
+ 2 (1 + Ï„) 
Î·t2S2Ehgt
n2i
+
1 +1
Ï„
Ehgt,iâˆ’1
nâˆ’gt
n2i
â‰¤
1 +2
Ï„
Ehgt,iâˆ’1
nâˆ’gt
n2i
+ 2 (1 + Ï„) 
Î·t2S2Ehgt
n2i
. (47)
We define the following notation for simplicity:
At,i:=Ehgt,i
nâˆ’gt
n2i
(48)
20B:= 2 (1 + Ï„) 
Î·t2S2Ehgt
n2i
(49)
C:=
1 +2
Ï„
(50)
We have
At,iâ‰¤CAt,iâˆ’1+B (51)
We can show that
At,iâ‰¤CiAt+Biâˆ’1X
j=0Cj
Note that At=Eh
âˆ¥gt
nâˆ’gt
nâˆ¥2i
= 0. For the second part, we have
Ï„âˆ’1X
i=0Ehgt,i
nâˆ’gt
n2i
=Ï„âˆ’1X
i=0Biâˆ’1X
j=0Cjâ‰¤2Ï„2B
â‰¤4Ï„2(1 +Ï„) 
Î·t2S2Ehgt
n2i
â‰¤8Ï„3 
Î·t2S2Ehgt
n2i
â‰¤8Ï„3 
Î·t2S2âˆ‡xFn 
xt2+Ïƒ2
n
. (52)
21D Proof for Theorem 3.6
We organize the proof of Theorem 3.6 as follows:
â€¢ In Sec. D.1, we prove the strongly convex case.
â€¢ In Sec. D.2, we prove the general convex case.
â€¢ In Sec. D.3, we prove the non-convex case.
D.1 Strongly convex case for SFL-V1
D.1.1 One-round Parallel Update for M-Server-Side Model
Lemma D.1. Under Assumptions C.1 and C.2, if Î·tâ‰¤1
2SËœÏ„, in round t, the M-server-side model
evolves as
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤
1âˆ’Î·tËœÏ„Âµ
2
Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2(ËœÏ„)2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24S(ËœÏ„)3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (53)
We prove Lemma D.1 as follows.
Proof. We use xt,i
s,nas the M-server-side model when the M-server interacts with client nfor
thei-th iteration of model training at round t. Using the (sequential) gradient update rule of
xt+1
s=xt
sâˆ’Î·tPN
n=1PËœÏ„âˆ’1
i=0angt,i
s,n 
xt,i
c,n,xt,i
s,n	
, we have
Ehxt+1
sâˆ’xâˆ—
s2i
=Eï£®
ï£°xt
sâˆ’Î·tËœÏ„âˆ’1X
i=0gt,i
sâˆ’xâˆ—
sâˆ’Î·tËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	
+Î·tËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
=Eï£®
ï£°xt
sâˆ’xâˆ—
sâˆ’Î·tËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
+ 2Î·tE"*
xt
sâˆ’xâˆ—
sâˆ’Î·tËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	
,ËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	
âˆ’ËœÏ„âˆ’1X
i=0gt,i
s+#
+Eï£®
ï£° 
Î·t2ËœÏ„âˆ’1X
i=0gt,i
sâˆ’ËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
â‰¤Eï£®
ï£°xt
sâˆ’xâˆ—
sâˆ’Î·tËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
+ 
Î·t2Eï£®
ï£°NX
n=1ËœÏ„âˆ’1X
i=0angt,i
s,nâˆ’ËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£». (54)
where the second equality is from (a+b)2=a2+ 2ab+b2and the last inequality is due to
E
âˆ‡xsf 
xt,i
c,xt,i
s	
âˆ’gt,i
s
= 0.
The first part in (54) is
Eï£®
ï£°xt
sâˆ’xâˆ—
sâˆ’Î·tËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
22â‰¤Ehxt
sâˆ’xâˆ—
s2i
+ 
Î·t2ËœÏ„NNX
n=1ËœÏ„âˆ’1X
i=0a2
nEhâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	2i
âˆ’2Î·tE"NX
n=1ËœÏ„âˆ’1X
i=0an
xt
sâˆ’xâˆ—
s,âˆ‡xsFn 
xt,i
c,xt,i
s	#
, (55)
where we use âˆ‡xsf({xc,xs}) =PN
n=1anâˆ‡xsFn({xc,xs}).
For (55), we have
 
Î·t2ËœÏ„NNX
n=1ËœÏ„âˆ’1X
i=0a2
nEhâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	2i
= 
Î·t2ËœÏ„NNX
n=1ËœÏ„âˆ’1X
i=0a2
nEâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’gt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
+Ehgt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
â‰¤ 
Î·t2(ËœÏ„)2NNX
n=1a2
n 
Ïƒ2
n+G2
, (56)
where the first inequality applies triangle inequality. In the last inequality, we apply the bound of
variance and expected squared norm for stochastic gradients in Assumption C.1.
Since Fn(x)isS-smooth and Âµ-strongly convex, using Lemma C.3 we have
âˆ’2Î·tE"NX
n=1ËœÏ„âˆ’1X
i=0an
xt
sâˆ’xâˆ—
s,âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	#
â‰¤ âˆ’2Î·tNX
n=1ËœÏ„âˆ’1X
i=0anE 
Fn 
xt
âˆ’Fn(xâˆ—)
+Âµ
4xt
sâˆ’xâˆ—
s2âˆ’Sxt,i
s,nâˆ’xt
s2i
. (57)
By Lemma C.5, we have
NX
n=1ËœÏ„âˆ’1X
i=0anEhxt,i
s,nâˆ’xt
s2i
â‰¤12NX
n=1an(ËœÏ„)3 
Î·t2 
2Ïƒ2
n+G2
. (58)
From Assumption C.1, the second part in (54) is bounded by
ENX
n=1ËœÏ„âˆ’1X
i=0angt,i
s,nâˆ’ËœÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2
â‰¤ËœÏ„ËœÏ„âˆ’1X
i=0ENX
n=1an 
gt,i
s,nâˆ’ âˆ‡xsFn 
xt,i
c,xt,i
s	2
â‰¤NNX
n=1a2
nÏƒ2
n(ËœÏ„)2. (59)
Thus, byPN
n=1an= 1, (54) becomes
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤Ehxt
sâˆ’xâˆ—
s2i
+ 
Î·t2(ËœÏ„)2NNX
n=1a2
n 
Ïƒ2
n+G2
23âˆ’2Î·tËœÏ„NX
n=1anE
f 
xt
âˆ’f(xâˆ—)
âˆ’ÂµËœÏ„Î·tPN
n=1an
2xt
sâˆ’xâˆ—
s2+ 2Î·t 
12NX
n=1anS(ËœÏ„)3 
Î·t2 
2Ïƒ2
n+G2!
+NNX
n=1a2
n 
Î·t2Ïƒ2
n(ËœÏ„)2
â‰¤
1âˆ’Î·tËœÏ„Âµ
2
Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2(ËœÏ„)2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24S(ËœÏ„)3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (60)
We now prove the convergence error. Let âˆ†t+1â‰œEhxt+1
sâˆ’xâˆ—
s2i
. We can rewrite (60) as:
âˆ†t+1â‰¤
1âˆ’Î·tËœÏ„Âµ
2
âˆ†tâˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
,
+ 
Î·t2(ËœÏ„)2NNX
n=1 
2Ïƒ2
n+G2
+ 24S(ËœÏ„)3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
,
â‰¤
1âˆ’Î·tËœÏ„Âµ
2
âˆ†t+(Î·t)2(ËœÏ„)2
4B1+(Î·t)3(ËœÏ„)3
8B2. (61)
where B1:= 4NPN
n=1a2
n 
2Ïƒ2
n+G2
andB:= 192 SPN
n=1an 
2Ïƒ2
n+G2
.
Consider a diminishing stepsize Î·t=2Î²
ËœÏ„(Î³+t), i.e,Î·tËœÏ„
2=Î²
Î³+t, where Î²=2
Âµ, Î³=8S
Âµâˆ’1. It
is easy to show that Î·tâ‰¤1
2SËœÏ„for all t. Next, we will prove that âˆ†t+1â‰¤v
Î³+t+1, where v=
maxn
4B1
Âµ2+8B2
Âµ3(Î³+1),(Î³+ 1)âˆ†0o
. We prove this by induction. First, the definition of vensures
that it holds for t=âˆ’1. Assume the conclusion holds for some t, it follows that
âˆ†t+1â‰¤
1âˆ’Î·tËœÏ„Âµ
2
âˆ†t+(Î·t)2(ËœÏ„)2
4B1+(Î·t)3(ËœÏ„)3
8B2 (62)
â‰¤
1âˆ’ÂµÎ²
Î³+tv
Î³+t+(Î·t)2(ËœÏ„)2
4B1+(Î·t)3(ËœÏ„)3
8B2 (63)
=Î³+tâˆ’1
(Î³+t)2v+Î²2B1
(Î³+t)2+Î²3B2
(Î³+t)3âˆ’Î²Âµâˆ’1
(Î³+t)2v
(64)
=Î³+tâˆ’1
(Î³+t)2v+Î²2B1
(Î³+t)2+Î²3B2
(Î³+t)3âˆ’Î²Âµâˆ’1
(Î³+t)2max4B1
Âµ2+8B2
Âµ3(Î³+ 1),(Î³+ 1)âˆ†0
(65)
=Î³+tâˆ’1
(Î³+t)2v+Î²2B1
(Î³+t)2+Î²3B2
(Î³+t)3âˆ’Î²Âµâˆ’1
(Î³+t)2maxÎ²2B1
Î²Âµâˆ’1+Î²3B2
(Î²Âµâˆ’1)(Î³+ 1),(Î³+ 1)âˆ†0
(66)
â‰¤Î³+tâˆ’1
(Î³+t)2v (67)
â‰¤v
Î³+t+ 1. (68)
24Hence, we have proven that âˆ†tâ‰¤v
Î³+t,âˆ€t. Therefore, we have
Ehxt
sâˆ’xâˆ—
s2i
= âˆ†tâ‰¤v
Î³+t=maxn
4B1
Âµ2+8B2
Âµ3(Î³+1),(Î³+ 1)Ehx0
sâˆ’xâˆ—
s2io
Î³+t
â‰¤16NPN
n=1a2
n 
2Ïƒ2
n+G2
Âµ2(Î³+t)+1536SPN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³+t) (Î³+ 1)+(Î³+ 1)Ehx0
sâˆ’xâˆ—
s2i
Î³+t.
(69)
D.1.2 One-round Parallel Update for Client-Side Models
Under Assumptions C.1 and C.2, if Î·tâ‰¤1
2SÏ„, in round t, Lemma D.1 gives
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤
1âˆ’Î·tÏ„Âµ
2
Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2(Ï„)2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24S(Ï„)3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (70)
Letâˆ†t+1â‰œEhxt+1
câˆ’xâˆ—
c2i
. We can rewrite (70) as:
âˆ†t+1â‰¤
1âˆ’Î·tÏ„Âµ
2
âˆ†t+(Î·t)2(Ï„)2
4B1+(Î·t)3(Ï„)3
8B2. (71)
where B1:= 4NPN
n=1a2
n 
2Ïƒ2
n+G2
andB2:= 192 SPN
n=1an 
2Ïƒ2
n+G2
.
Consider a diminishing stepsize Î·t=2Î²
Ï„(Î³+t), i.e,Î·tÏ„
2=Î²
Î³+t, where Î²=2
Âµ, Î³=8S
Âµâˆ’1. It is easy
to show that Î·tâ‰¤1
2SÏ„for all t. For v= maxn
4B1
Âµ2+8B2
Âµ3(Î³+1),(Î³+ 1)âˆ†0o
, we can prove that
âˆ†tâ‰¤v
Î³+t,âˆ€t. Therefore, we have
Ehxt
câˆ’xâˆ—
c2i
= âˆ†tâ‰¤v
Î³+t=maxn
4B1
Âµ2+8B2
Âµ3(Î³+1),(Î³+ 1)Ehx0
câˆ’xâˆ—
c2io
Î³+t
â‰¤16NPN
n=1a2
n 
2Ïƒ2
n+G2
Âµ2(Î³+t)+1536SPN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³+t) (Î³+ 1)+(Î³+ 1)Ehx0
câˆ’xâˆ—
c2i
Î³+t.
(72)
D.1.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (69) and(72) using Proposition 3.5 by setting
Î·tâ‰¤1
2Smax{Ï„,ËœÏ„}. We have
E
f(xT)
âˆ’f(xâˆ—)
â‰¤S
2 
E||xT
sâˆ’xâˆ—
s||2+E||xT
câˆ’xâˆ—
c||2
â‰¤8SNPN
n=1a2
n 
2Ïƒ2
n+G2
Âµ2(Î³+T)+768S2PN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³+T) (Î³+ 1)+S(Î³+ 1)Ehx0âˆ’xâˆ—2i
2(Î³+T).
(73)
25D.2 General convex case for SFL-V1
D.2.1 One-round Parallel Update for M-Server-Side Model
By Lemma D.1 with Âµ= 0andÎ·tâ‰¤1
2SËœÏ„, we have
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2ËœÏ„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SËœÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (74)
D.2.2 One-round Parallel Update for Client-Side Models
By Lemma D.1 with Âµ= 0andÎ·tâ‰¤1
2SÏ„, we have
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (75)
D.2.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (74) and (75) as follows
Ehxt+1âˆ’xâˆ—2i
â‰¤Ehxt+1
sâˆ’xâˆ—
s2i
+Ehxt+1
câˆ’xâˆ—
c2i
,
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2ËœÏ„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SËœÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
=Ehxtâˆ’xâˆ—2i
âˆ’4Î·tmin{Ï„,ËœÏ„}E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2NNX
n=1a2
n(ËœÏ„2+Ï„2) 
2Ïƒ2
n+G2
+ 24S 
Î·t3NX
n=1an(ËœÏ„3+Ï„3) 
2Ïƒ2
n+G2
. (76)
Then, we can obtain the relation between Ehxt+1âˆ’xâˆ—2i
andEh
âˆ¥xtâˆ’xâˆ—âˆ¥2i
, which is related to
E[f(xt)âˆ’f(xâˆ—)]. Applying Lemma 8 in [ 17] and let Ï„min:= min {ËœÏ„, Ï„}andÎ·tâ‰¤1
2Smax{Ï„,ËœÏ„},
we obtain the performance bound as
E
f 
xT
âˆ’f(xâˆ—)
â‰¤1
2 
ËœÏ„2+Ï„2
Ï„2
minNNX
n=1a2
n 
2Ïƒ2
n+G2!1
2 x0âˆ’xâˆ—2
T+ 1!1
2
+1
2 
ËœÏ„2+Ï„2
Ï„2
min24SNX
n=1an 
2Ïƒ2
n+G2!1
3 x0âˆ’xâˆ—2
T+ 1!1
3
+Sx0âˆ’xâˆ—2
2(T+ 1). (77)
26D.3 Non-convex case for SFL-V1
D.3.1 One-round Parallel Update for M-Server-Side Model
For the server, we have
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
â‰¤E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s+Î·tËœÏ„âˆ‡xsf 
xt
âˆ’Î·tËœÏ„âˆ‡xsf 
xt
â‰¤E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s+Î·tËœÏ„âˆ‡xsf 
xt
âˆ’
âˆ‡xsf 
xt
s
, Î·tËœÏ„âˆ‡xsf 
xt
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1ËœÏ„âˆ’1X
i=0angt,i
s,n#
+Î·tËœÏ„âˆ‡xsf 
xt+
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1ËœÏ„âˆ’1X
i=0anâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	#
+Î·tËœÏ„âˆ‡xsf 
xt+
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1ËœÏ„âˆ’1X
i=0anâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
+Î·tNX
n=1ËœÏ„âˆ’1X
i=0anâˆ‡xsFn 
xt#+
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤Î·tËœÏ„*
âˆ‡xsf 
xt
,E"
âˆ’1
ËœÏ„NX
n=1ËœÏ„âˆ’1X
i=0anâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
+1
ËœÏ„NX
n=1ËœÏ„âˆ’1X
i=0anâˆ‡xsFn 
xt#+
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤Î·tËœÏ„
2âˆ‡xsf 
xt2+Î·t
2ËœÏ„Eï£®
ï£°NX
n=1ËœÏ„âˆ’1X
i=0anâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’NX
n=1ËœÏ„âˆ’1X
i=0anâˆ‡xsFn 
xt2ï£¹
ï£»
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤ âˆ’Î·tËœÏ„
2âˆ‡xsf 
xt2+Î·t
2ËœÏ„Eï£®
ï£°NX
n=1anËœÏ„âˆ’1X
i=0 
âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’ âˆ‡xsFn 
xt2ï£¹
ï£»
â‰¤ âˆ’Î·tËœÏ„
2âˆ‡xsf 
xt2+NÎ·t
2ËœÏ„NX
n=1a2
nEï£®
ï£°ËœÏ„âˆ’1X
i=0 
âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’ âˆ‡xsFn 
xt2ï£¹
ï£»
â‰¤ âˆ’Î·tËœÏ„
2âˆ‡xsf 
xt2+NÎ·tS2
2NX
n=1a2
nËœÏ„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
, (78)
where we apply Assumption C.1, âˆ‡xsf(xt) =PN
n=1anâˆ‡xsFn(xt), andâŸ¨a, bâŸ© â‰¤a2+b2
2.
By Lemma C.6 with Î·tâ‰¤1âˆš
8SËœÏ„, we have
ËœÏ„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
â‰¤2ËœÏ„2
8ËœÏ„ 
Î·t2Ïƒ2
n+ 8ËœÏ„ 
Î·t2Ïµ2+ 8ËœÏ„ 
Î·t2âˆ‡xsf 
xt
s2
.(79)
Thus, (78) becomes
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
â‰¤âˆ’Î·tËœÏ„
2âˆ‡xsf 
xt2+NÎ·tS2
2NX
n=1a2
n2ËœÏ„2
8ËœÏ„ 
Î·t2Ïƒ2
n+8ËœÏ„ 
Î·t2Ïµ2+8ËœÏ„ 
Î·t2âˆ‡xsf 
xt
s2
â‰¤ 
âˆ’Î·tËœÏ„
2+ 8N 
Î·t3ËœÏ„3S2NX
n=1a2
n!
âˆ‡xsf 
xt2+ 8NÎ·tS2ËœÏ„3NX
n=1a2
n 
Î·t2 
Ïƒ2
n+Ïµ2
.
(80)
27Furthermore, we have
S
2Ehxt+1
sâˆ’xt
s2i
=SN(Î·t)2
2NX
n=1Eï£®
ï£°ËœÏ„âˆ’1X
i=0angt,i
s,n2ï£¹
ï£»
â‰¤SN(Î·t)2
2NX
n=1a2
nEï£®
ï£°ËœÏ„âˆ’1X
i=0gt,i
s,n2ï£¹
ï£»
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
nËœÏ„âˆ’1X
i=0Ehgt,i
s,n2i
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
nËœÏ„âˆ’1X
i=0Ehgt,i
s,nâˆ’gt
s,n+gt
s,n2i
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
nËœÏ„âˆ’1X
i=0
Ehgt,i
s,nâˆ’gt
s,n2i
+Ehgt
s,n2i
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
nËœÏ„âˆ’1X
i=0
Ehgt,i
s,nâˆ’gt
s,n2i
+Ehâˆ‡xsFn 
xt2+Ïƒ2
ni
, (81)
where the last line uses Assumption C.1 and E
âˆ¥zâˆ¥2
=âˆ¥E[z]âˆ¥2+E[âˆ¥zâˆ’E[z]âˆ¥2
for any random
variable z.
By Lemma C.7 with Î·tâ‰¤1
2SËœÏ„, we have
ËœÏ„âˆ’1X
i=0Ehgt,i
s,nâˆ’gt
s,n2i
â‰¤8ËœÏ„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
. (82)
Thus, (81) becomes
S
2Ehxt+1
sâˆ’xt
s2i
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
8ËœÏ„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
+ ËœÏ„Ehâˆ‡xsFn 
xt2+Ïƒ2
ni
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
ËœÏ„+ 8ËœÏ„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
ËœÏ„+ 8ËœÏ„3 
Î·t2S2âˆ‡xsFn 
xt
âˆ’ âˆ‡xsf 
xt
+âˆ‡xsf 
xt2+Ïƒ2
n
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
ËœÏ„+ 8ËœÏ„3 
Î·t2S2
2âˆ‡xsf 
xt2+ 2Ïµ2+Ïƒ2
n
. (83)
D.3.2 One-round Parallel Update for Client-Side Models
The analysis of the client-side model update is similar to the server. Thus, we have
E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
â‰¤ 
âˆ’Î·tÏ„
2+ 8N 
Î·t3Ï„3S2NX
n=1a2
n!
âˆ‡xcf 
xt2+ 8NÎ·tS2Ï„3NX
n=1a2
n 
Î·t2 
Ïƒ2
n+Ïµ2
.
(84)
28ForÎ·tâ‰¤1
2SÏ„,
S
2Ehxt+1
câˆ’xt
c2i
â‰¤SN(Î·t)2Ï„
2NX
n=1a2
n
Ï„+ 8Ï„3 
Î·t2S2
2âˆ‡xcf 
xt2+ 2Ïµ2+Ïƒ2
n
. (85)
D.3.3 Superposition of M-Server and Clients
Applying (80),(83),(85) and(84) into (36) in Proposition C.4 and define Ï„minâ‰œmin{Ï„,ËœÏ„},
Ï„maxâ‰œmax{Ï„,ËœÏ„}, we have
E
f 
xt+1
âˆ’f 
xt
â‰¤E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
+S
2Ehxt+1
câˆ’xt
c2i
+E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
+S
2Ehxt+1
sâˆ’xt
s2i
â‰¤ 
âˆ’Î·tmin{Ï„,ËœÏ„}
2+ 8N 
Î·t3(max{Ï„,ËœÏ„})3S2NX
n=1a2
n!
âˆ‡xf 
xt2
+ 8NÎ·tS2 
Ï„3+ ËœÏ„3NX
n=1 
Î·t2a2
n 
Ïƒ2
n+Ïµ2
+SN(Î·t)2max{Ï„,ËœÏ„}
2NX
n=1a2
n
max{Ï„,ËœÏ„}+ 8 (max {Ï„,ËœÏ„})3 
Î·t2S2
2âˆ‡xf 
xt2
+SN(Î·t)2Ï„
2NX
n=1a2
n
Ï„+ 8Ï„3 
Î·t2S2 
2Ïµ2+Ïƒ2
n
+SN(Î·t)2ËœÏ„
2NX
n=1a2
n
ËœÏ„+ 8ËœÏ„3 
Î·t2S2 
2Ïµ2+Ïƒ2
n
(86)
â‰¤ 
âˆ’Î·tÏ„min
2+8N 
Î·t3S2Ï„3
maxNX
n=1a2
n+SN 
Î·t2Ï„maxNX
n=1a2
n
Ï„max+8Ï„3
max 
Î·t2S2!
âˆ‡xf 
xt2
+ 8NÎ·tS2 
Ï„3+ ËœÏ„3NX
n=1a2
n 
Î·t2 
Ïƒ2
n+Ïµ2
+1
2SN 
Î·t2Ï„
Ï„+ 8Ï„3 
Î·t2S2NX
n=1a2
n 
2Ïµ2+Ïƒ2
n
+1
2SN 
Î·t2ËœÏ„
ËœÏ„+8ËœÏ„3 
Î·t2S2NX
n=1a2
n 
2Ïµ2+Ïƒ2
n
â‰¤ 
âˆ’Î·tÏ„min
2+SN 
Î·t2Ï„2
maxNX
n=1a2
n+8N 
Î·t3vS2Ï„3
maxNX
n=1a2
n+8S3N 
Î·t4Ï„4
maxNX
n=1a2
n!
âˆ‡xf 
xt2
+ 8N 
Î·t3S2Ï„3NX
n=1a2
nÏƒ2
n+ 8N 
Î·t3S2Ï„3Ïµ2NX
n=1a2
n
+SN 
Î·t2Ï„2Ïµ2NX
n=1a2
n+1
2SN 
Î·t2ËœÏ„2NX
n=1a2
nÏƒ2
n+8NS3 
Î·t4Ï„4Ïµ2NX
n=1a2
n+ 4NS3 
Î·t4Ï„4NX
n=1a2
nÏƒ2
n
+ 8N 
Î·t3S2ËœÏ„3NX
n=1a2
nÏƒ2
n+ 8N 
Î·t3S2ËœÏ„3Ïµ2NX
n=1a2
n
+SN 
Î·t2ËœÏ„2Ïµ2NX
n=1a2
n+1
2SN 
Î·t2ËœÏ„2NX
n=1a2
nÏƒ2
n+8NS3 
Î·t4ËœÏ„4Ïµ2NX
n=1a2
n+4NS3 
Î·t4ËœÏ„4NX
n=1a2
nÏƒ2
n
29â‰¤ âˆ’Î·tÏ„min
2 
1âˆ’2SNÎ·tÏ„2
max
Ï„minNX
n=1a2
n
1 + 8 SÎ·tÏ„+ 8S2 
Î·t2Ï„2
max!
âˆ‡xf 
xt2
+1
2NS 
Î·t2Ï„2+ 8N 
Î·t3S2Ï„3+ 4NS3 
Î·t4Ï„4NX
n=1a2
nÏƒ2
n
+
NS 
Î·t2Ï„2+ 8N 
Î·t3S2Ï„3+ 8NSL3 
Î·t4Ï„4NX
n=1a2
nÏµ2
+1
2NS 
Î·t2ËœÏ„2+ 8N 
Î·t3S2ËœÏ„3+ 4NS3 
Î·t4ËœÏ„4NX
n=1a2
nÏƒ2
n
+
NS 
Î·t2Ï„2+ 8N 
Î·t3S2ËœÏ„3+ 8NSL3 
Î·t4ËœÏ„4NX
n=1a2
nÏµ2
â‰¤ âˆ’Î·tÏ„min
2 
1âˆ’2NSÎ·tÏ„2
max
Ï„minNX
n=1a2
n
1 +1
2+1
32!
âˆ‡xf 
xt2
+NS 
Î·t2Ï„21
2+1
2+1
64NX
n=1a2
nÏƒ2
n+ 2SN 
Î·t2Ï„21
2+1
4+1
64NX
n=1a2
nÏµ2
+NS 
Î·t2ËœÏ„21
2+1
2+1
64NX
n=1a2
nÏƒ2
n+ 2SN 
Î·t2ËœÏ„21
2+1
4+1
64NX
n=1a2
nÏµ2
â‰¤ âˆ’Î·tÏ„min
2 
1âˆ’4NSÎ·tÏ„2
max
Ï„minNX
n=1a2
n!
âˆ‡xf 
xt2+ 2NS 
Î·t2 
Ï„2+ ËœÏ„2NX
n=1a2
n 
Ïƒ2
n+Ïµ2
â‰¤ âˆ’Î·tÏ„min
4âˆ‡xf 
xt2+ 2NS 
Î·t2 
Ï„2+ ËœÏ„2NX
n=1a2
n 
Ïƒ2
n+Ïµ2
, (87)
where we first let Î·tâ‰¤1
16SÏ„maxand then let Î·tâ‰¤1
8SNÏ„2max
Ï„minPN
n=1a2n. We also use âˆ¥âˆ‡xf(xt)âˆ¥2=
âˆ¥âˆ‡xcf(xt)âˆ¥2+âˆ¥âˆ‡xsf(xt)âˆ¥2.
Rearranging the above we have
Î·tâˆ‡xf 
xt2â‰¤4
Ï„min 
f 
xt
âˆ’E
f 
xt+1
s
+ 8NS 
Î·t2Ï„2+ ËœÏ„2
Ï„minNX
n=1a2
n 
Ïƒ2
n+Ïµ2
.
(88)
Taking expectation and averaging over all t, we have
1
TTâˆ’1X
t=0Î·tEhâˆ‡xf 
xt2i
â‰¤4
TÏ„min(f(x0)âˆ’fâˆ—) +8NSÏ„2+ËœÏ„2
Ï„min
TNX
n=1a2
n 
Ïƒ2
n+Ïµ2Tâˆ’1X
t=0 
Î·t2.
(89)
30E Proof of Theorem 3.7
â€¢ In Sec. E.1, we prove the strongly convex case.
â€¢ In Sec. E.2, we prove the general convex case.
â€¢ In Sec. E.3, we prove the non-convex case.
E.1 Strongly convex case for SFL-V2
E.1.1 One-round Sequential Update for M-Server-Side Model
Lemma E.1. Under Assumptions C.1 and C.2, if Î·tâ‰¤1
2SÏ„, in round t, the M-server-side model
evolves as
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤
1âˆ’NÎ·tÏ„Âµ
2
Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
. (90)
We prove Lemma E.1 as follows.
Proof. We use xt,i
s,nas the M-server-side model when the M-server interacts with client nfor
thei-th iteration of model training at round t. Using the (sequential) gradient update rule of
xt+1
s=xt
sâˆ’Î·tPN
n=1PÏ„âˆ’1
i=0gt,i
s 
xt,i
c,n,xt,i
s,n	
, we have
Ehxt+1
sâˆ’xâˆ—
s2i
=Eï£®
ï£°xt
sâˆ’Î·tÏ„âˆ’1X
i=0gt,i
sâˆ’xâˆ—
sâˆ’Î·tÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	
+Î·tÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
=Eï£®
ï£°xt
sâˆ’xâˆ—
sâˆ’Î·tÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
+ 2Î·tE"*
xt
sâˆ’xâˆ—
sâˆ’Î·tÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	
,Ï„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	
âˆ’Ï„âˆ’1X
i=0gt,i
s+#
+Eï£®
ï£° 
Î·t2Ï„âˆ’1X
i=0gt,i
sâˆ’Ï„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
â‰¤Eï£®
ï£°xt
sâˆ’xâˆ—
sâˆ’Î·tÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
+ 
Î·t2Eï£®
ï£°NX
n=1Ï„âˆ’1X
i=0gt,i
s,nâˆ’Ï„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£». (91)
where the first equality is from (a+b)2=a2+ 2ab+b2and the last inequality is due to
E
âˆ‡xsf 
xt,i
c,xt,i
s	
âˆ’gt,i
s
= 0.
The first part in (91) is
Eï£®
ï£°xt
sâˆ’xâˆ—
sâˆ’Î·tÏ„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2ï£¹
ï£»
31â‰¤Ehxt
sâˆ’xâˆ—
s2i
+ 
Î·t2Ï„NNX
n=1Ï„âˆ’1X
i=0Ehâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	2i
âˆ’2Î·tE"NX
n=1Ï„âˆ’1X
i=0
xt
sâˆ’xâˆ—
s,âˆ‡xsFn 
xt,i
c,xt,i
s	#
, (92)
where we use âˆ‡xsf({xc,xs}) =PN
n=1âˆ‡xsFn({xc,xs}).
For (92), we have
 
Î·t2Ï„NNX
n=1Ï„âˆ’1X
i=0Ehâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	2i
= 
Î·t2Ï„NNX
n=1Ï„âˆ’1X
i=0Eâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’gt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
+Ehgt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
â‰¤ 
Î·t2Ï„2NNX
n=1 
Ïƒ2
n+G2
, (93)
where the first inequality applies triangle inequality. In the last inequality, we apply the bound of
variance and expected squared norm for stochastic gradients in Assumption C.1.
Since Fn(x)isS-smooth and Âµ-strongly convex, using Lemma C.3 we have
âˆ’2Î·tE"NX
n=1Ï„âˆ’1X
i=0
xt
sâˆ’xâˆ—
s,âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	#
â‰¤ âˆ’2Î·tNX
n=1Ï„âˆ’1X
i=0E 
Fn 
xt
âˆ’Fn(xâˆ—)
+Âµ
4xt
sâˆ’xâˆ—
s2âˆ’Sxt,i
s,nâˆ’xt
s2i
. (94)
By Lemma C.5, we have
NX
n=1Ï„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
â‰¤12NX
n=1Ï„3 
Î·t2 
2Ïƒ2
n+G2
. (95)
From Assumption C.1, the second part in (91) is bounded by
ENX
n=1Ï„âˆ’1X
i=0gt,i
s,nâˆ’Ï„âˆ’1X
i=0âˆ‡xsf 
xt,i
c,xt,i
s	2
â‰¤Ï„Ï„âˆ’1X
i=0ENX
n=1gt,i
s,nâˆ’ âˆ‡xsFn 
xt,i
c,xt,i
s	2
â‰¤NNX
n=1Ïƒ2
nÏ„2. (96)
Thus, (91) becomes
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤Ehxt
sâˆ’xâˆ—
s2i
+ 
Î·t2Ï„2NNX
n=1 
Ïƒ2
n+G2
32âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
âˆ’ÂµNÏ„Î·t
2xt
sâˆ’xâˆ—
s2+ 2Î·t 
12NX
n=1SÏ„3 
Î·t2 
2Ïƒ2
n+G2!
+NNX
n=1 
Î·t2Ïƒ2
nÏ„2
â‰¤
1âˆ’Î·tNÏ„Âµ
2
Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
. (97)
Using the above lemma, we can prove the convergence error. Let âˆ†t+1â‰œEhxt+1
sâˆ’xâˆ—
s2i
. We
can rewrite (97) as:
âˆ†t+1â‰¤
1âˆ’Î·tNÏ„Âµ
2
âˆ†tâˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
,
+ 
Î·t2Ï„2NNX
n=1 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
,
â‰¤
1âˆ’Î·tNÏ„Âµ
2
âˆ†t+(Î·t)2Ï„2
4B1+(Î·t)3Ï„3
8B2. (98)
where B1:= 4NPN
n=1 
2Ïƒ2
n+G2
andB:= 192 SPN
n=1 
2Ïƒ2
n+G2
.
Consider a diminishing stepsize Î·t=2Î²
NÏ„(Î³s+t), i.e,NÎ·tÏ„
2=Î²
Î³s+t, where Î²=2
Âµ, Î³s=8S
NÂµâˆ’1.
It is easy to show that Î·tâ‰¤1
2SÏ„for all t. Next, we will prove that âˆ†t+1â‰¤v
Î³s+t+1, where
v= maxn
4B1
Âµ2+8B2
Âµ3(Î³s+1),(Î³s+ 1)âˆ†0o
. We prove this by induction. First, the definition of v
ensures that it holds for t=âˆ’1. Assume the conclusion holds for some t, it follows that
âˆ†t+1â‰¤
1âˆ’NÎ·tÏ„Âµ
2
âˆ†t+(Î·t)2Ï„2
4B1+(Î·t)3Ï„3
8B2 (99)
â‰¤
1âˆ’ÂµÎ²
Î³s+tv
Î³s+t+(Î·t)2Ï„2
4B1+(Î·t)3Ï„3
8B2 (100)
=Î³s+tâˆ’1
(Î³s+t)2v+Î²2B1
(Î³s+t)2+Î²3B2
(Î³s+t)3âˆ’Î²Âµâˆ’1
(Î³s+t)2v
(101)
=Î³s+tâˆ’1
(Î³s+t)2v+Î²2B1
(Î³s+t)2+Î²3B2
(Î³s+t)3âˆ’Î²Âµâˆ’1
(Î³s+t)2max4B1
Âµ2+8B2
Âµ3(Î³s+ 1),(Î³s+ 1)âˆ†0
(102)
=Î³s+tâˆ’1
(Î³s+t)2v+Î²2B1
(Î³s+t)2+Î²3B2
(Î³s+t)3âˆ’Î²Âµâˆ’1
(Î³s+t)2maxÎ²2B1
Î²Âµâˆ’1+Î²3B2
(Î²Âµâˆ’1)(Î³s+1),(Î³s+1)âˆ†0
(103)
â‰¤Î³s+tâˆ’1
(Î³s+t)2v (104)
â‰¤v
Î³s+t+ 1. (105)
33Hence, we have proven that âˆ†tâ‰¤v
Î³s+t,âˆ€t. Therefore, we have
Ehxt
sâˆ’xâˆ—
s2i
= âˆ†tâ‰¤v
Î³s+t=maxn
4B1
Âµ2+8B2
Âµ3(Î³s+1),(Î³s+ 1)Ehx0
sâˆ’xâˆ—
s2io
Î³s+t
â‰¤16NPN
n=1 
2Ïƒ2
n+G2
Âµ2(Î³s+t)+1536SPN
n=1 
2Ïƒ2
n+G2
Âµ3(Î³s+t) (Î³s+ 1)+(Î³s+ 1)Ehx0
sâˆ’xâˆ—
s2i
Î³s+t.(106)
E.1.2 One-round Parallel Update for Client-Side Models
Under Assumptions C.1 and C.2, if Î·tâ‰¤1
2SÏ„, in round t, Lemma D.1 gives
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤
1âˆ’Î·tÏ„Âµ
2
Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (107)
Letâˆ†t+1â‰œEhxt+1
câˆ’xâˆ—
c2i
. We can rewrite (107) as:
âˆ†t+1â‰¤
1âˆ’Î·tÏ„Âµ
2
âˆ†t+(Î·t)2Ï„2
4B1+(Î·t)3Ï„3
8B2. (108)
where B1:= 4NPN
n=1a2
n 
2Ïƒ2
n+G2
andB2:= 192 SPN
n=1an 
2Ïƒ2
n+G2
.
Consider a diminishing stepsize Î·t=2Î²
Ï„(Î³c+t), i.e,Î·tÏ„
2=Î²
Î³c+t, where Î²=2
Âµ, Î³c=8S
Âµâˆ’1. It is
easy to show that Î·tâ‰¤1
2SÏ„for all t. For v= maxn
4B1
Âµ2+8B2
Âµ3(Î³c+1),(Î³c+ 1)âˆ†0o
, we can prove
thatâˆ†tâ‰¤v
Î³c+t,âˆ€t. Therefore, we have
Ehxt
câˆ’xâˆ—
c2i
= âˆ†tâ‰¤v
Î³c+t=maxn
4B1
Âµ2+8B2
Âµ3(Î³c+1),(Î³c+ 1)Ehx0
câˆ’xâˆ—
c2io
Î³c+t
â‰¤16NPN
n=1a2
n 
2Ïƒ2
n+G2
Âµ2(Î³c+t)+1536SPN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³c+t) (Î³c+ 1)+(Î³c+ 1)Ehx0
câˆ’xâˆ—
c2i
Î³c+t.
(109)
E.1.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (106) and(109) using Proposition 3.5. For
Î·tâ‰¤1
2SÏ„andÎ³=8S
Âµâˆ’1, we have
E
f(xT)
âˆ’f(xâˆ—)
â‰¤S
2 
E||xT
sâˆ’xâˆ—
s||2+E||xT
câˆ’xâˆ—
c||2
â‰¤8SNPN
n=1(a2
n+1 ) 
2Ïƒ2
n+G2
Âµ2(Î³+T)+768S2PN
n=1(an+1 ) 
2Ïƒ2
n+G2
Âµ3(Î³+T) (Î³+ 1)+S(Î³+1 )Ehx0âˆ’xâˆ—2i
2(Î³+T)
(110)
34E.2 General convex case for SFL-V2
E.2.1 One-round Sequential Update for M-Server-Side Model
By Lemma E.1 with Âµ= 0andÎ·tâ‰¤1
2SÏ„, we have
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
. (111)
E.2.2 One-round Parallel Update for Client-Side Models
By Lemma D.1 with Âµ= 0andÎ·tâ‰¤1
2SÏ„, we have
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (112)
E.2.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (111) and (112) as follows
Ehxt+1âˆ’xâˆ—2i
â‰¤Ehxt+1
sâˆ’xâˆ—
s2i
+Ehxt+1
câˆ’xâˆ—
c2i
,
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1(a2
n+ 1) 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1(an+ 1) 
2Ïƒ2
n+G2
=Ehxtâˆ’xâˆ—2i
âˆ’4Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1(a2
n+ 1) 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1(an+ 1) 
2Ïƒ2
n+G2
. (113)
Then, we can obtain the relation between Ehxt+1âˆ’xâˆ—2i
andEh
âˆ¥xtâˆ’xâˆ—âˆ¥2i
, which is related to
E[f(xt)âˆ’f(xâˆ—)]. Applying Lemma 8 in [17], we obtain the performance bound as
E
f 
xT
âˆ’f(xâˆ—)
â‰¤1
2 
NNX
n=1(a2
n+ 1) 
2Ïƒ2
n+G2!1
2 x0âˆ’xâˆ—2
T+ 1!1
2
+1
2 
24SNX
n=1(an+ 1) 
2Ïƒ2
n+G2!1
3 x0âˆ’xâˆ—2
T+ 1!1
3
+Sx0âˆ’xâˆ—2
2(T+ 1). (114)
35E.3 Non-convex case for SFL-V2
E.3.1 One-round Sequential Update for M-Server-Side Model
For the server, we have
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
â‰¤E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s+Î·tÏ„âˆ‡xsf 
xt
âˆ’Î·tÏ„âˆ‡xsf 
xt
â‰¤E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s+Î·tÏ„âˆ‡xsf 
xt
âˆ’
âˆ‡xsf 
xt
s
, Î·tÏ„âˆ‡xsf 
xt
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1Ï„âˆ’1X
i=0gt,i
s,n#
+Î·tÏ„âˆ‡xsf 
xt+
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1Ï„âˆ’1X
i=0âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	#
+Î·tÏ„âˆ‡xsf 
xt+
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1Ï„âˆ’1X
i=0âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
+Î·tNX
n=1Ï„âˆ’1X
i=0âˆ‡xsFn 
xt#+
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤Î·tÏ„*
âˆ‡xsf 
xt
,E"
âˆ’1
Ï„NX
n=1Ï„âˆ’1X
i=0âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
+1
Ï„NX
n=1Ï„âˆ’1X
i=0âˆ‡xsFn 
xt#+
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤Î·tÏ„
2âˆ‡xsf 
xt2+Î·t
2Ï„Eï£®
ï£°NX
n=1Ï„âˆ’1X
i=0âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’NX
n=1Ï„âˆ’1X
i=0âˆ‡xsFn 
xt2ï£¹
ï£»
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤ âˆ’Î·tÏ„
2âˆ‡xsf 
xt2+Î·t
2Ï„Eï£®
ï£°NX
n=1Ï„âˆ’1X
i=0 
âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’ âˆ‡xsFn 
xt2ï£¹
ï£»
â‰¤ âˆ’Î·tÏ„
2âˆ‡xsf 
xt2+NÎ·t
2Ï„NX
n=1Eï£®
ï£°Ï„âˆ’1X
i=0 
âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’ âˆ‡xsFn 
xt2ï£¹
ï£»
â‰¤ âˆ’Î·tÏ„
2âˆ‡xsf 
xt2+NÎ·tS2
2NX
n=1Ï„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
, (115)
where we apply Assumption C.1, âˆ‡xsf(xt) =PN
n=1âˆ‡xsFn(xt), andâŸ¨a, bâŸ© â‰¤a2+b2
2.
By Lemma C.6 with Î·tâ‰¤1âˆš
8SÏ„, we have
Ï„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
â‰¤2Ï„2
8Ï„ 
Î·t2Ïƒ2
n+ 8Ï„ 
Î·t2Ïµ2+ 8Ï„ 
Î·t2âˆ‡xsf 
xt
s2
.(116)
Thus, (115) becomes
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
â‰¤âˆ’Î·tÏ„
2âˆ‡xsf 
xt2+NÎ·tS2
2NX
n=12Ï„2
8Ï„ 
Î·t2Ïƒ2
n+8Ï„ 
Î·t2Ïµ2+8Ï„ 
Î·t2âˆ‡xsf 
xt
s2
â‰¤
âˆ’Î·tÏ„
2+ 8N2 
Î·t3Ï„3S2âˆ‡xsf 
xt2+ 8NÎ·tS2Ï„3NX
n=1 
Î·t2 
Ïƒ2
n+Ïµ2
. (117)
36Furthermore, we have
S
2Ehxt+1
sâˆ’xt
s2i
=SN(Î·t)2
2NX
n=1Eï£®
ï£°Ï„âˆ’1X
i=0gt,i
s,n2ï£¹
ï£»
â‰¤SN(Î·t)2
2NX
n=1Eï£®
ï£°Ï„âˆ’1X
i=0gt,i
s,n2ï£¹
ï£»
â‰¤SN(Î·t)2Ï„
2NX
n=1Ï„âˆ’1X
i=0Ehgt,i
s,n2i
â‰¤SN(Î·t)2Ï„
2NX
n=1Ï„âˆ’1X
i=0Ehgt,i
s,nâˆ’gt
s,n+gt
s,n2i
â‰¤SN(Î·t)2Ï„
2NX
n=1Ï„âˆ’1X
i=0
Ehgt,i
s,nâˆ’gt
s,n2i
+Ehgt
s,n2i
â‰¤SN(Î·t)2Ï„
2NX
n=1Ï„âˆ’1X
i=0
Ehgt,i
s,nâˆ’gt
s,n2i
+Ehâˆ‡xsFn 
xt2+Ïƒ2
ni
, (118)
where the last line uses Assumption C.1 and E
âˆ¥zâˆ¥2
=âˆ¥E[z]âˆ¥2+E[âˆ¥zâˆ’E[z]âˆ¥2
for any random
variable z.
By Lemma C.7 with Î·tâ‰¤1
2SÏ„, we have
Ï„âˆ’1X
i=0Ehgt,i
s,nâˆ’gt
s,n2i
â‰¤8Ï„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
. (119)
Thus, (118) becomes
S
2Ehxt+1
sâˆ’xt
s2i
â‰¤SN(Î·t)2Ï„
2NX
n=1
8Ï„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
+Ï„Ehâˆ‡xsFn 
xt2+Ïƒ2
ni
â‰¤SN(Î·t)2Ï„
2NX
n=1
Ï„+ 8Ï„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
â‰¤SN(Î·t)2Ï„
2NX
n=1
Ï„+ 8Ï„3 
Î·t2S2âˆ‡xsFn 
xt
âˆ’ âˆ‡xsf 
xt
+âˆ‡xsf 
xt2+Ïƒ2
n
â‰¤SN(Î·t)2Ï„
2NX
n=1
Ï„+ 8Ï„3 
Î·t2S2
2âˆ‡xsf 
xt2+ 2Ïµ2+Ïƒ2
n
. (120)
E.3.2 One-round Parallel Update for Client-Side Models
The analysis of the client-side model update is the same as the clientâ€™s model update in version 1.
Thus, we have
E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
â‰¤ 
âˆ’Î·tÏ„
2+ 8N 
Î·t3Ï„3S2NX
n=1a2
n!
âˆ‡xcf 
xt2+ 8NÎ·tS2Ï„3NX
n=1a2
n 
Î·t2 
Ïƒ2
n+Ïµ2
.
(121)
37ForÎ·tâ‰¤1
2SÏ„,
S
2Ehxt+1
câˆ’xt
c2i
â‰¤SN(Î·t)2Ï„
2NX
n=1a2
n
Ï„+ 8Ï„3 
Î·t2S2
2âˆ‡xcf 
xt2+ 2Ïµ2+Ïƒ2
n
. (122)
E.3.3 Superposition of M-Server and Clients
Applying (117), (120), (122) and (121) into (36) in Proposition C.4, we have
E
f 
xt+1
âˆ’f 
xt
â‰¤E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
+S
2Ehxt+1
câˆ’xt
c2i
+E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
+S
2Ehxt+1
sâˆ’xt
s2i
â‰¤
âˆ’Î·tÏ„
2+ 8N2 
Î·t3Ï„3S2âˆ‡xf 
xt2
+ 8NÎ·tS2Ï„3NX
n=1 
Î·t2(a2
n+ 1) 
Ïƒ2
n+Ïµ2
+SN(Î·t)2Ï„
2NX
n=1
Ï„+ 8Ï„3 
Î·t2S2
2âˆ‡xf 
xt2
+SN(Î·t)2Ï„
2NX
n=1(a2
n+ 1)
Ï„+ 8Ï„3 
Î·t2S2 
2Ïµ2+Ïƒ2
n
â‰¤ 
âˆ’Î·tÏ„
2+ 8N2 
Î·t3S2Ï„3+SN 
Î·t2Ï„NX
n=1
Ï„+ 8Ï„3 
Î·t2S2!
âˆ‡xf 
xt2
+ 8NÎ·tS2Ï„3NX
n=1 
Î·t2(a2
n+ 1) 
Ïƒ2
n+Ïµ2
+1
2SN 
Î·t2Ï„
Ï„+ 8Ï„3 
Î·t2S2NX
n=1(a2
n+ 1) 
2Ïµ2+Ïƒ2
n
â‰¤
âˆ’Î·tÏ„
2+SN2 
Î·t2Ï„2+ 8N2 
Î·t3S2Ï„3+ 8S3N2 
Î·t4Ï„4âˆ‡xf 
xt2
+ 8N 
Î·t3S2Ï„3NX
n=1(a2
n+ 1)Ïƒ2
n+ 8N 
Î·t3S2Ï„3Ïµ2NX
n=1(a2
n+ 1)
+SN 
Î·t2Ï„2Ïµ2NX
n=1(a2
n+ 1) +1
2SN 
Î·t2Ï„2NX
n=1(a2
n+ 1)Ïƒ2
n
+ 8NS3 
Î·t4Ï„4Ïµ2NX
n=1(a2
n+ 1) + 4 NS3 
Î·t4Ï„4NX
n=1(a2
n+ 1)Ïƒ2
n
â‰¤ âˆ’Î·tÏ„
2
1âˆ’2SN2Î·tÏ„2
Ï„
1 + 8 SÎ·tÏ„+ 8S2 
Î·t2Ï„2âˆ‡xf 
xt2
+1
2NS 
Î·t2Ï„2+ 8N 
Î·t3S2Ï„3+ 4NS3 
Î·t4Ï„4NX
n=1(a2
n+ 1)Ïƒ2
n
+
NS 
Î·t2Ï„2+ 8N 
Î·t3S2Ï„3+ 8NSL3 
Î·t4Ï„4NX
n=1(a2
n+ 1)Ïµ2
â‰¤ âˆ’Î·tÏ„
2
1âˆ’2N2SÎ·tÏ„2
Ï„
1 +1
2+1
32âˆ‡xf 
xt2
38+NS 
Î·t2Ï„21
2+1
2+1
64NX
n=1(a2
n+ 1)Ïƒ2
n+ 2SN 
Î·t2Ï„21
2+1
4+1
64NX
n=1(a2
n+ 1)Ïµ2
â‰¤ âˆ’Î·tÏ„
2
1âˆ’4N2SÎ·tÏ„2
Ï„âˆ‡xf 
xt2+ 2NS 
Î·t2NX
n=1 
Ï„2a2
n+Ï„2 
Ïƒ2
n+Ïµ2
â‰¤ âˆ’Î·tÏ„
4âˆ‡xf 
xt2+ 2NS 
Î·t2Ï„2NX
n=1 
a2
n+ 1 
Ïƒ2
n+Ïµ2
, (123)
where we first let Î·tâ‰¤1
16SÏ„and then let Î·tâ‰¤1
8SN2Ï„. We have appliedPN
n=1a2
nâ‰¤N.
Rearranging the above we have
Î·tâˆ‡xf 
xt2â‰¤4
Ï„ 
f 
xt
âˆ’E
f 
xt+1
s
+ 8NS 
Î·t2Ï„NX
n=1a2
n+ 1
Ï„ 
Ïƒ2
n+Ïµ2
.(124)
Taking expectation and averaging over all t, we have
1
TTâˆ’1X
t=0Î·tEhâˆ‡xf 
xt2i
â‰¤4
TÏ„(f(x0)âˆ’fâˆ—) +8NSÏ„
TNX
n=1(a2
n+ 1) 
Ïƒ2
n+Ïµ2Tâˆ’1X
t=0 
Î·t2.
(125)
39F Proof of Theorem 3.8
â€¢ In Sec. F.1, we prove the strongly convex case.
â€¢ In Sec. F.2, we prove the general convex case.
â€¢ In Sec. F.3, we prove the non-convex case.
F.1 Strongly convex case for SFL-V1
F.1.1 One-round Parallel Update for M-Server-Side Model
We first bound the M-server-side model update in one round for full participation ( qn= 1for all n),
and then compute the difference between full participation and partial participation ( qn<1for some
n). We denote It
nas a binary variable, taking 1 if client nparticipates in model training in round t,
and 0 otherwise. Practically, It
nfollows a Bernoulli distribution with an expectation of qn.
For full participation, Lemma D.1 gives
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤
1âˆ’Î·tËœÏ„Âµ
2
Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2(ËœÏ„)2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24S(ËœÏ„)3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (126)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
sâˆ’xt+1
s2i
=Ehxt+1
sâˆ’xt
s+xt
sâˆ’xt+1
s2i
â‰¤Ehxt+1
sâˆ’xt
s2i
â‰¤Eï£®
ï£°NX
n=1Î·tanIn
t
qnËœÏ„âˆ’1X
i=0gt,i
s,n 
xt,i
c,n,xt,i
s,n	2ï£¹
ï£»
â‰¤NËœÏ„NX
n=1 
Î·t2a2
n
qnËœÏ„âˆ’1X
i=0Ehgt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
â‰¤N(ËœÏ„)2 
Î·t2G2NX
n=1a2
n
qn, (127)
where we use Eâˆ¥Xâˆ’EXâˆ¥2â‰¤Eâˆ¥Xâˆ¥2,E[It
n] = qn, and xt+1
s =xt
sâˆ’
Î·tP
nâˆˆPt(q)PËœÏ„âˆ’1
i=0a2
n
qngt,i
s,n 
xt,i
c,n,xt,i
s,n	
.
Combining the above gives
Ehxt+1
sâˆ’xâˆ—
s2i
=Ehxt+1
sâˆ’xt+1
s+xt+1
sâˆ’xâˆ—
s2i
â‰¤
1âˆ’Î·tËœÏ„Âµ
2
Ehxt
sâˆ’xâˆ—
s2i
+ 
Î·t2(ËœÏ„)2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24S(ËœÏ„)3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+N(ËœÏ„)2 
Î·t2G2NX
n=1a2
n
qn. (128)
40Letâˆ†t+1â‰œEhxt+1
sâˆ’xâˆ—
s2i
. We can rewrite (128) as:
âˆ†t+1â‰¤
1âˆ’Î·tËœÏ„Âµ
2
âˆ†t+(Î·t)2(ËœÏ„)2
4B1+(Î·t)3(ËœÏ„)3
8B2. (129)
where B1:= 4NPN
n=1a2
n 
2Ïƒ2
n+G2
+4NG2PN
n=1a2
n
qnandB:= 192 SPN
n=1an 
2Ïƒ2
n+G2
.
Consider a diminishing stepsize Î·t=2Î²
ËœÏ„(Î³s+t), i.e,Î·tËœÏ„
2=Î²
Î³s+t, where Î²=2
Âµ, Î³s=8S
Âµâˆ’1. It is
easy to show that Î·tâ‰¤1
2SËœÏ„for all t. We can prove that âˆ†tâ‰¤v
Î³s+t,âˆ€t. Therefore, we have
Ehxt
sâˆ’xâˆ—
s2i
= âˆ†tâ‰¤v
Î³s+t=maxn
4B1
Âµ2+8B2
Âµ3(Î³s+1),(Î³s+ 1)Ehx0
sâˆ’xâˆ—
s2io
Î³s+t
â‰¤16NPN
n=1a2
n 
2Ïƒ2
n+G2
+ 16NG2PN
n=1a2
n
qn
Âµ2(Î³s+t)+1536SPN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³s+t) (Î³s+ 1)
+(Î³s+ 1)Ehx0
sâˆ’xâˆ—
s2i
Î³s+t. (130)
F.1.2 One-round Parallel Update for Client-Side Models
Define xc
t=PN
n=1anxt
c,n, which represents the aggregating weights in round tfor full par-
ticipation. Using a similar derivation as the M-server side, we first bound the client-side
model update in one round for full participation Ehxt+1
câˆ’xâˆ—
c2i
and then bound the dif-
ference of client-side model parameters between full participation and partial participation
Ehxt+1
câˆ’xâˆ—
c2i
. The overall gradient update rule of clients in each training round is xt+1
c=
xt
câˆ’Î·tP
nâˆˆPt(q)PÏ„âˆ’1
i=0an
qngt,i
c,n 
xt,i
c,n,xt,i
s,n	
.
Under Assumptions C.1 and C.2, if Î·tâ‰¤1
2SÏ„, in round t, Lemma D.1 gives
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤
1âˆ’Î·tÏ„Âµ
2
Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2(Ï„)2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24S(Ï„)3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (131)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
câˆ’xt+1
c2i
=Ehxt+1
câˆ’xt
c+xt
câˆ’xt+1
c2i
â‰¤Ehxt+1
câˆ’xt
c2i
â‰¤Eï£®
ï£°NX
n=1Î·tanIn
t
qnÏ„âˆ’1X
i=0gt,i
c,n 
xt,i
c,n,xt,i
s,n	2ï£¹
ï£»
â‰¤NÏ„NX
n=1 
Î·t2a2
n
qnÏ„âˆ’1X
i=0Ehgt,i
c,n 
xt,i
c,n,xt,i
s,n	2i
â‰¤N(Ï„)2 
Î·t2G2NX
n=1a2
n
qn, (132)
41where we use Eâˆ¥Xâˆ’EXâˆ¥2â‰¤Eâˆ¥Xâˆ¥2,E[It
n] = qn, and xt+1
c =xt
câˆ’
Î·tP
nâˆˆPt(q)PÏ„âˆ’1
i=0an
qngt,i
c,n 
xt,i
c,n,xt,i
s,n	
.
We obtain the client-side model parameter update in one round for partial participation by combining
the two terms and we have
Ehxt+1
câˆ’xâˆ—
c2i
=Ehxt+1
câˆ’xt+1
c+xt+1
câˆ’xâˆ—
c2i
â‰¤
1âˆ’Î·tÏ„Âµ
2
Ehxt
câˆ’xâˆ—
c2i
+ 
Î·t2(Ï„)2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24S(Ï„)3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+N(Ï„)2 
Î·t2G2NX
n=1a2
n
qn, (133)
where we consider E[f(xt)âˆ’f(xâˆ—)]â‰¥0.
Letâˆ†t+1â‰œEhxt+1
câˆ’xâˆ—
c2i
. We can rewrite (163) as:
âˆ†t+1â‰¤
1âˆ’Î·tÏ„Âµ
2
âˆ†t+(Î·t)2(Ï„)2
4B1+(Î·t)3(Ï„)3
8B2. (134)
where B1 := 4 NPN
n=1a2
n 
2Ïƒ2
n+G2
+ 4 NG2PN
n=1a2
n
qnand B2 :=
192SPN
n=1an 
2Ïƒ2
n+G2
.
Consider a diminishing stepsize Î·t=2Î²
Ï„(Î³c+t), i.e,Î·tÏ„
2=Î²
Î³c+t, where Î²=2
Âµ, Î³c=8S
Âµâˆ’1. It is
easy to show that Î·tâ‰¤1
2SÏ„for all t. For v= maxn
4B1
Âµ2+8B2
Âµ3(Î³c+1),(Î³c+ 1)âˆ†0o
, we can prove
thatâˆ†tâ‰¤v
Î³c+t,âˆ€t. Therefore, we have
Ehxt
câˆ’xâˆ—
c2i
= âˆ†tâ‰¤v
Î³c+t=maxn
4B1
Âµ2+8B2
Âµ3(Î³c+1),(Î³c+ 1)Ehx0
câˆ’xâˆ—
c2io
Î³c+t
â‰¤16NPN
n=1a2
n 
2Ïƒ2
n+G2
+ 16NG2PN
n=1a2
n
qn
Âµ2(Î³c+t)+1536SPN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³c+t) (Î³c+ 1)
+(Î³c+ 1)Ehx0
câˆ’xâˆ—
c2i
Î³c+t. (135)
F.1.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (130) and(135) using Proposition 3.5. For
Î·tâ‰¤1
2Smax{Ï„,ËœÏ„}andÎ³=8S
Âµâˆ’1, we have
E
f(xT)
âˆ’f(xâˆ—)
â‰¤S
2 
E||xT
sâˆ’xâˆ—
s||2+E||xT
câˆ’xâˆ—
c||2
â‰¤8SNPN
n=1a2
n
2Ïƒ2
n+G2+G2
qn
Âµ2(Î³+T)+768S2PN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³+T) (Î³+ 1)+S(Î³+ 1)Ehx0âˆ’xâˆ—2i
2(Î³+T).
(136)
42F.2 General convex case for SFL-V1
F.2.1 One-round Parallel Update for M-Server-Side Model
By Lemma D.1 with Âµ= 0andÎ·tâ‰¤1
2SËœÏ„, we have
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2ËœÏ„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SËœÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (137)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
sâˆ’xt+1
s2i
â‰¤NËœÏ„2 
Î·t2G2NX
n=1a2
n
qn. (138)
Thus, we have
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2ËœÏ„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SËœÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+NËœÏ„2 
Î·t2G2NX
n=1a2
n
qn.
(139)
F.2.2 One-round Parallel Update for Client-Side Models
By Lemma D.1 with Âµ= 0andÎ·tâ‰¤1
2SÏ„, we have
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (140)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
câˆ’xt+1
c2i
â‰¤NÏ„2 
Î·t2G2NX
n=1a2
n
qn. (141)
Thus, we have
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+NÏ„2 
Î·t2G2NX
n=1a2
n
qn.
(142)
F.2.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (139) and (142) as follows
43Ehxt+1âˆ’xâˆ—2i
â‰¤Ehxt+1
sâˆ’xâˆ—
s2i
+Ehxt+1
câˆ’xâˆ—
c2i
,
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tËœÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2ËœÏ„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SËœÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+NËœÏ„2 
Î·t2G2NX
n=1a2
n
qn
+Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+NÏ„2 
Î·t2G2NX
n=1a2
n
qn
=Ehxtâˆ’xâˆ—2i
âˆ’4Î·tmin{Ï„,ËœÏ„}E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2NNX
n=1a2
n(ËœÏ„2+Ï„2) 
2Ïƒ2
n+G2
+24S 
Î·t3NX
n=1an(ËœÏ„3+Ï„3) 
2Ïƒ2
n+G2
+N 
Ï„2+ËœÏ„2 
Î·t2G2NX
n=1a2
n
qn.
(143)
Then, we can obtain the relation between Ehxt+1âˆ’xâˆ—2i
andEh
âˆ¥xtâˆ’xâˆ—âˆ¥2i
, which is related
toE[f(xt)âˆ’f(xâˆ—)]. Applying Lemma 8 in [ 17] and let Ï„min:= min {ËœÏ„, Ï„}, we obtain the
performance bound as
E
f 
xT
âˆ’f(xâˆ—)
â‰¤1
2 
ËœÏ„2+Ï„2
Ï„2
minNNX
n=1a2
n
2Ïƒ2
n+G2+G2
n
qn!1
2 x0âˆ’xâˆ—2
T+ 1!1
2
+1
2 
ËœÏ„2+Ï„2
Ï„2
min24SNX
n=1an 
2Ïƒ2
n+G2!1
3 x0âˆ’xâˆ—2
T+ 1!1
3
+Sx0âˆ’xâˆ—2
2(T+ 1). (144)
44F.3 Non-convex case for SFL-V1
F.3.1 One-round Parallel Update for M-Server-Side Model
For the server, we have
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
â‰¤E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s+Î·tËœÏ„âˆ‡xsf 
xt
âˆ’Î·tËœÏ„âˆ‡xsf 
xt
â‰¤E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s+Î·tËœÏ„âˆ‡xsf 
xt
âˆ’
âˆ‡xsf 
xt
s
, Î·tËœÏ„âˆ‡xsf 
xt
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1ËœÏ„âˆ’1X
i=0anIt
n
qngt,i
s,n#
+Î·tËœÏ„âˆ‡xsf 
xt+
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1ËœÏ„âˆ’1X
i=0anIt
n
qnâˆ‡xsFn 
v
xt,i
c,n,xt,i
s,n	#
+Î·tËœÏ„âˆ‡xsf 
xt+
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1ËœÏ„âˆ’1X
i=0anIt
n
qnâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
+Î·tNX
n=1ËœÏ„âˆ’1X
i=0anIt
n
qnâˆ‡xsFn 
xt#+
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤Î·tËœÏ„*
âˆ‡xsf 
xt
,E"
âˆ’1
ËœÏ„NX
n=1ËœÏ„âˆ’1X
i=0anIt
n
qnâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
+1
ËœÏ„NX
n=1ËœÏ„âˆ’1X
i=0anIt
n
qnâˆ‡xsFn 
xt#+
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤Î·tËœÏ„
2âˆ‡xsf 
xt2+Î·t
2ËœÏ„Eï£®
ï£°NX
n=1ËœÏ„âˆ’1X
i=0anIt
n
qnâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’NX
n=1ËœÏ„âˆ’1X
i=0anIt
n
qnâˆ‡xsFn 
xt2ï£¹
ï£»
âˆ’Î·tËœÏ„âˆ‡xsf 
xt2
â‰¤ âˆ’Î·tËœÏ„
2âˆ‡xsf 
xt2+Î·t
2ËœÏ„Eï£®
ï£°NX
n=1anIt
n
qnËœÏ„âˆ’1X
i=0 
âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’ âˆ‡xsFn 
xt2ï£¹
ï£»
â‰¤ âˆ’Î·tËœÏ„
2âˆ‡xsf 
xt2+NÎ·t
2ËœÏ„NX
n=1a2
n
qnEï£®
ï£°ËœÏ„âˆ’1X
i=0 
âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’ âˆ‡xsFn 
xt2ï£¹
ï£»
â‰¤ âˆ’Î·tËœÏ„
2âˆ‡xsf 
xt2+NÎ·tS2
2NX
n=1a2
n
qnËœÏ„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
, (145)
where we apply Assumption C.1, âˆ‡xsf(xt) =PN
n=1anâˆ‡xsFn(xt),âŸ¨a, bâŸ© â‰¤a2+b2
2, andE[It
n] =
qn.
By Lemma C.6 with Î·tâ‰¤1âˆš
8SËœÏ„, we have
ËœÏ„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
â‰¤2ËœÏ„2
8ËœÏ„ 
Î·t2Ïƒ2
n+ 8ËœÏ„ 
Î·t2Ïµ2+ 8ËœÏ„ 
Î·t2âˆ‡xsf 
xt
s2
.(146)
Thus, (145) becomes
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
â‰¤âˆ’Î·tËœÏ„
2âˆ‡xsf 
xt2+NÎ·tS2
2NX
n=1a2
n
qn2ËœÏ„2
8ËœÏ„ 
Î·t2Ïƒ2
n+8ËœÏ„ 
Î·t2Ïµ2+8ËœÏ„ 
Î·t2âˆ‡xsf 
xt
s2
â‰¤ 
âˆ’Î·tËœÏ„
2+ 8N 
Î·t3ËœÏ„3S2NX
n=1a2
n
qn!
âˆ‡xsf 
xt2+ 8NÎ·tS2ËœÏ„3NX
n=1a2
n
qn 
Î·t2 
Ïƒ2
n+Ïµ2
.
(147)
45Furthermore, we have
S
2Ehxt+1
sâˆ’xt
s2i
=SN(Î·t)2
2NX
n=1Eï£®
ï£°ËœÏ„âˆ’1X
i=0anIt
n
qngt,i
s,n2ï£¹
ï£»
â‰¤SN(Î·t)2
2NX
n=1a2
n
qnEï£®
ï£°ËœÏ„âˆ’1X
i=0gt,i
s,n2ï£¹
ï£»
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qnËœÏ„âˆ’1X
i=0Ehgt,i
s,n2i
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qnËœÏ„âˆ’1X
i=0Ehgt,i
s,nâˆ’gt
s,n+gt
s,n2i
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qnËœÏ„âˆ’1X
i=0
Ehgt,i
s,nâˆ’gt
s,n2i
+Ehgt
s,n2i
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qnËœÏ„âˆ’1X
i=0
Ehgt,i
s,nâˆ’gt
s,n2i
+Ehâˆ‡xsFn 
xt2+Ïƒ2
ni
, (148)
where the last line uses Assumption C.1 and E
âˆ¥zâˆ¥2
=âˆ¥E[z]âˆ¥2+E[âˆ¥zâˆ’E[z]âˆ¥2
for any random
variable z.
By Lemma C.7 with Î·tâ‰¤1
2SËœÏ„, we have
ËœÏ„âˆ’1X
i=0Ehgt,i
s,nâˆ’gt
s,n2i
â‰¤8ËœÏ„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
. (149)
Thus, (148) becomes
S
2Ehxt+1
sâˆ’xt
s2i
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qn
8ËœÏ„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
+ ËœÏ„Ehâˆ‡xsFn 
xt2+Ïƒ2
ni
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qn
ËœÏ„+ 8ËœÏ„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qn
ËœÏ„+ 8ËœÏ„3 
Î·t2S2âˆ‡xsFn 
xt
âˆ’ âˆ‡xsf 
xt
+âˆ‡xsf 
xt2+Ïƒ2
n
â‰¤SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qn
ËœÏ„+ 8ËœÏ„3 
Î·t2S2
2âˆ‡xsf 
xt2+ 2Ïµ2+Ïƒ2
n
, (150)
F.3.2 One-round Parallel Update for Client-Side Models
The analysis of the client-side model update is similar to the server. Thus, we have
E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
â‰¤ 
âˆ’Î·tÏ„
2+ 8N 
Î·t3Ï„3S2NX
n=1a2
n
qn!
âˆ‡xcf 
xt2+ 8NÎ·tS2Ï„3NX
n=1a2
n
qn 
Î·t2 
Ïƒ2
n+Ïµ2
.
(151)
46ForÎ·tâ‰¤1
2SÏ„,
S
2Ehxt+1
câˆ’xt
c2i
â‰¤SN(Î·t)2Ï„
2NX
n=1a2
n
qn
Ï„+ 8Ï„3 
Î·t2S2
2âˆ‡xcf 
xt2+ 2Ïµ2+Ïƒ2
n
. (152)
F.3.3 Superposition of M-Server and Clients
Applying (147) ,(150) ,(152) and(151) into(36) in Proposition C.4 and define Ï„minâ‰œmin{Ï„,ËœÏ„},
Ï„maxâ‰œmax{Ï„,ËœÏ„}we have
E
f 
xt+1
âˆ’f 
xt
â‰¤E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
+S
2Ehxt+1
câˆ’xt
c2i
+E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
+S
2Ehxt+1
sâˆ’xt
s2i
â‰¤ 
âˆ’Î·tmin{Ï„,ËœÏ„}
2+ 8N 
Î·t3(max{Ï„,ËœÏ„})3S2NX
n=1a2
n
qn!
âˆ‡xf 
xt2
+ 8NÎ·tS2 
Ï„3+ ËœÏ„3NX
n=1 
Î·t2a2
n
qn 
Ïƒ2
n+Ïµ2
+SN(Î·t)2max{Ï„,ËœÏ„}
2NX
n=1a2
n
qn
max{Ï„,ËœÏ„}+ 8 (max {Ï„,ËœÏ„})3 
Î·t2S2
2âˆ‡xf 
xt2
+SN(Î·t)2Ï„
2NX
n=1a2
n
qn
Ï„+ 8Ï„3 
Î·t2S2 
2Ïµ2+Ïƒ2
n
+SN(Î·t)2ËœÏ„
2NX
n=1a2
n
qn
ËœÏ„+8ËœÏ„3 
Î·t2S2 
2Ïµ2+Ïƒ2
n
â‰¤ 
âˆ’Î·tÏ„min
2+8N 
Î·t3S2Ï„3
maxNX
n=1a2
n
qn+SN 
Î·t2Ï„maxNX
n=1a2
n
qn
Ï„max+8Ï„3
max 
Î·t2S2!
âˆ‡xf 
xt2
+ 8NÎ·tS2 
Ï„3+ ËœÏ„3NX
n=1a2
n
qn 
Î·t2 
Ïƒ2
n+Ïµ2
+1
2SN 
Î·t2Ï„
Ï„+ 8Ï„3 
Î·t2S2NX
n=1a2
n
qn 
2Ïµ2+Ïƒ2
n
+1
2SN 
Î·t2ËœÏ„
ËœÏ„+ 8ËœÏ„3 
Î·t2S2NX
n=1a2
n
qn 
2Ïµ2+Ïƒ2
n
â‰¤ 
âˆ’Î·tÏ„min
2+SN 
Î·t2Ï„2
maxNX
n=1a2
n
qn+8N 
Î·t3S2Ï„3
maxNX
n=1a2
n
qn+8S3N 
Î·t4Ï„4
maxNX
n=1a2
n
qn!
âˆ‡xf 
xt2
+ 8N 
Î·t3S2Ï„3NX
n=1a2
n
qnÏƒ2
n+ 8N 
Î·t3S2Ï„3Ïµ2NX
n=1a2
n
qn
+SN 
Î·t2Ï„2Ïµ2NX
n=1a2
n
qn+1
2SN 
Î·t2ËœÏ„2NX
n=1a2
n
qnÏƒ2
n
+ 8NS3 
Î·t4Ï„4Ïµ2NX
n=1a2
n
qn+ 4NS3 
Î·t4Ï„4NX
n=1a2
n
qnÏƒ2
n
+ 8N 
Î·t3S2ËœÏ„3NX
n=1a2
n
qnÏƒ2
n+ 8N 
Î·t3S2ËœÏ„3Ïµ2NX
n=1a2
n
qn
+SN 
Î·t2ËœÏ„2Ïµ2NX
n=1a2
n
qn+1
2SN 
Î·t2ËœÏ„2NX
n=1a2
n
qnÏƒ2
n
47+8NS3 
Î·t4ËœÏ„4Ïµ2NX
n=1a2
n
qn+ 4NS3 
Î·t4ËœÏ„4NX
n=1a2
n
qnÏƒ2
n
â‰¤ âˆ’Î·tÏ„min
2 
1âˆ’2SNÎ·tÏ„2
max
Ï„minNX
n=1a2
n
qn
1 + 8 SÎ·tÏ„+ 8S2 
Î·t2Ï„2
max!
âˆ‡xf 
xt2
+1
2NS 
Î·t2Ï„2+ 8N 
Î·t3S2Ï„3+ 4NS3 
Î·t4Ï„4NX
n=1a2
n
qnÏƒ2
n
+
NS 
Î·t2Ï„2+ 8N 
Î·t3S2Ï„3+ 8NSL3 
Î·t4Ï„4NX
n=1a2
n
qnÏµ2
+1
2NS 
Î·t2ËœÏ„2+ 8N 
Î·t3S2ËœÏ„3+ 4NS3 
Î·t4ËœÏ„4NX
n=1a2
n
qnÏƒ2
n
+
NS 
Î·t2Ï„2+ 8N 
Î·t3S2ËœÏ„3+ 8NSL3 
Î·t4ËœÏ„4NX
n=1a2
n
qnÏµ2
â‰¤ âˆ’Î·tÏ„min
2 
1âˆ’2NSÎ·tÏ„2
max
Ï„minNX
n=1a2
n
qn
1 +1
2+1
32!
âˆ‡xf 
xt2
+NS 
Î·t2Ï„21
2+1
2+1
64NX
n=1a2
n
qnÏƒ2
n+ 2SN 
Î·t2Ï„21
2+1
4+1
64NX
n=1a2
n
qnÏµ2
+NS 
Î·t2ËœÏ„21
2+1
2+1
64NX
n=1a2
n
qnÏƒ2
n+ 2SN 
Î·t2ËœÏ„21
2+1
4+1
64NX
n=1a2
n
qnÏµ2
â‰¤ âˆ’Î·tÏ„min
2 
1âˆ’4NSÎ·tÏ„2
max
Ï„minNX
n=1a2
n
qn!
âˆ‡xf 
xt2+2NS 
Î·t2 
Ï„2+ËœÏ„2NX
n=1a2
n
qn 
Ïƒ2
n+Ïµ2
â‰¤ âˆ’Î·tÏ„min
4âˆ‡xf 
xt2+ 2NS 
Î·t2 
Ï„2+ ËœÏ„2NX
n=1a2
n
qn 
Ïƒ2
n+Ïµ2
, (153)
where we first let Î·tâ‰¤1
16SÏ„maxand then let Î·tâ‰¤1
8SNÏ„2max
Ï„minPN
n=1a2n
qn. We also use âˆ¥âˆ‡xf(xt)âˆ¥2=
âˆ¥âˆ‡xcf(xt)âˆ¥2+âˆ¥âˆ‡xsf(xt)âˆ¥2.
Rearranging the above we have
Î·tâˆ‡xf 
xt2â‰¤4
Ï„min 
f 
xt
âˆ’E
f 
xt+1
s
+ 8NS 
Î·t2Ï„2+ ËœÏ„2
Ï„minNX
n=1a2
n
qn 
Ïƒ2
n+Ïµ2
(154)
Taking expectation and averaging over all t, we have
1
TTâˆ’1X
t=0Î·tEhâˆ‡xf 
xt2i
â‰¤4
TÏ„min(f(x0)âˆ’fâˆ—) +8NSÏ„2+ËœÏ„2
Ï„min
TNX
n=1a2
n
qn 
Ïƒ2
n+Ïµ2Tâˆ’1X
t=0 
Î·t2.
(155)
48G Proof of Theorem 3.9
â€¢ In Sec. G.1, we prove the strongly convex case.
â€¢ In Sec. G.2, we prove the general convex case.
â€¢ In Sec. G.3, we prove the non-convex case.
G.1 Strongly convex case for SFL-V2
G.1.1 One-round Sequential Update for M-Server-Side Model
We first bound the M-server-side model update in one round for full participation ( qn= 1for all n),
and then compute the difference between full participation and partial participation ( qn<1for some
n). We denote It
nas a binary variable, taking 1 if client nparticipates in model training in round t,
and 0 otherwise.
For full participation, Lemma E.1 gives
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤
1âˆ’NÎ·tÏ„Âµ
2
Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
. (156)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
sâˆ’xt+1
s2i
=Ehxt+1
sâˆ’xt
s+xt
sâˆ’xt+1
s2i
â‰¤Ehxt+1
sâˆ’xt
s2i
â‰¤Eï£®
ï£°NX
n=1Î·tIn
t
qnÏ„âˆ’1X
i=0gt,i
s,n 
xt,i
c,n,xt,i
s,n	2ï£¹
ï£»
â‰¤NÏ„NX
n=1 
Î·t21
qnÏ„âˆ’1X
i=0Ehgt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
â‰¤NÏ„2 
Î·t2G2NX
n=11
qn, (157)
where we use Eâˆ¥Xâˆ’EXâˆ¥2â‰¤Eâˆ¥Xâˆ¥2,E[It
n] = qn, and xt+1
s =xt
sâˆ’
Î·tP
nâˆˆPt(q)PÏ„âˆ’1
i=01
qngt,i
s,n 
xt,i
c,n,xt,i
s,n	
.
Combining the above gives
Ehxt+1
sâˆ’xâˆ—
s2i
=Ehxt+1
sâˆ’xt+1
s+xt+1
sâˆ’xâˆ—
s2i
â‰¤
1âˆ’NÎ·tÏ„Âµ
2
Ehxt
sâˆ’xâˆ—
s2i
+ 
Î·t2Ï„2NNX
n=1 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
+NÏ„2 
Î·t2G2NX
n=11
qn. (158)
49Letâˆ†t+1â‰œEhxt+1
sâˆ’xâˆ—
s2i
. We can rewrite (158) as:
âˆ†t+1â‰¤
1âˆ’Î·tNÏ„Âµ
2
âˆ†t+(Î·t)2Ï„2
4B1+(Î·t)3Ï„3
8B2. (159)
where B1:= 4NPN
n=1 
2Ïƒ2
n+G2
+ 4NG2PN
n=11
qnandB:= 192 SPN
n=1 
2Ïƒ2
n+G2
.
Consider a diminishing stepsize Î·t=2Î²
NÏ„(Î³s+t), i.e,NÎ·tÏ„
2=Î²
Î³s+t, where Î²=2
Âµ, Î³s=8S
NÂµâˆ’1. It is
easy to show that Î·tâ‰¤1
2SÏ„for all t. We can prove that âˆ†tâ‰¤v
Î³s+t,âˆ€t. Therefore, we have
Ehxt
sâˆ’xâˆ—
s2i
= âˆ†tâ‰¤v
Î³s+t=maxn
4B1
Âµ2+8B2
Âµ3(Î³s+1),(Î³s+ 1)Ehx0
sâˆ’xâˆ—
s2io
Î³s+t
â‰¤16NPN
n=1 
2Ïƒ2
n+G2
+ 16NG2PN
n=11
qn
Âµ2(Î³s+t)+1536SPN
n=1 
2Ïƒ2
n+G2
Âµ3(Î³s+t) (Î³s+ 1)
+(Î³s+ 1)Ehx0
sâˆ’xâˆ—
s2i
Î³s+t. (160)
G.1.2 One-round Parallel Update for Client-Side Models
Define xc
t=PN
n=1anxt
c,n, which represents the aggregating weights in round tfor full par-
ticipation. Using a similar derivation as the M-server side, we first bound the client-side
model update in one round for full participation Ehxt+1
câˆ’xâˆ—
c2i
and then bound the dif-
ference of client-side model parameters between full participation and partial participation
Ehxt+1
câˆ’xâˆ—
c2i
. The overall gradient update rule of clients in each training round is xt+1
c=
xt
câˆ’Î·tP
nâˆˆPt(q)PÏ„âˆ’1
i=0an
qngt,i
c,n 
xt,i
c,n,xt,i
s,n	
.
Under Assumptions C.1 and C.2, if Î·tâ‰¤1
2SÏ„, in round t, Lemma D.1 gives
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤
1âˆ’Î·tÏ„Âµ
2
Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (161)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
câˆ’xt+1
c2i
=Ehxt+1
câˆ’xt
c+xt
câˆ’xt+1
c2i
â‰¤Ehxt+1
câˆ’xt
c2i
â‰¤Eï£®
ï£°NX
n=1Î·tanIn
t
qnÏ„âˆ’1X
i=0gt,i
c,n 
xt,i
c,n,xt,i
s,n	2ï£¹
ï£»
â‰¤NÏ„NX
n=1 
Î·t2a2
n
qnÏ„âˆ’1X
i=0Ehgt,i
c,n 
xt,i
c,n,xt,i
s,n	2i
â‰¤NÏ„2 
Î·t2G2NX
n=1a2
n
qn, (162)
50where we use Eâˆ¥Xâˆ’EXâˆ¥2â‰¤Eâˆ¥Xâˆ¥2,E[It
n] = qn, and xt+1
c =xt
câˆ’
Î·tP
nâˆˆPt(q)PÏ„âˆ’1
i=0an
qngt,i
c,n 
xt,i
c,n,xt,i
s,n	
.
We obtain the client-side model parameter update in one round for partial participation by combining
the two terms and we have
Ehxt+1
câˆ’xâˆ—
c2i
=Ehxt+1
câˆ’xt+1
c+xt+1
câˆ’xâˆ—
c2i
â‰¤
1âˆ’Î·tÏ„Âµ
2
Ehxt
câˆ’xâˆ—
c2i
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+NÏ„2 
Î·t2G2NX
n=1a2
n
qn. (163)
Letâˆ†t+1â‰œEhxt+1
câˆ’xâˆ—
c2i
. We can rewrite (163) as:
âˆ†t+1â‰¤
1âˆ’Î·tÏ„Âµ
2
âˆ†t+(Î·t)2Ï„2
4B1+(Î·t)3Ï„3
8B2. (164)
where B1 := 4 NPN
n=1a2
n 
2Ïƒ2
n+G2
+ 4 NG2PN
n=1a2
n
qnand B2 :=
192SPN
n=1an 
2Ïƒ2
n+G2
.
Consider a diminishing stepsize Î·t=2Î²
Ï„(Î³c+t), i.e,Î·tÏ„
2=Î²
Î³c+t, where Î²=2
Âµ, Î³c=8S
Âµâˆ’1. It is
easy to show that Î·tâ‰¤1
2SÏ„for all t. For v= maxn
4B1
Âµ2+8B2
Âµ3(Î³c+1),(Î³c+ 1)âˆ†0o
, we can prove
thatâˆ†tâ‰¤v
Î³c+t,âˆ€t. Therefore, we have
Ehxt
câˆ’xâˆ—
c2i
= âˆ†tâ‰¤v
Î³c+t=maxn
4B1
Âµ2+8B2
Âµ3(Î³c+1),(Î³c+ 1)Ehx0
câˆ’xâˆ—
c2io
Î³c+t
â‰¤16NPN
n=1a2
n 
2Ïƒ2
n+G2
+ 16NG2PN
n=1a2
n
qn
Âµ2(Î³c+t)+1536SPN
n=1an 
2Ïƒ2
n+G2
Âµ3(Î³c+t) (Î³c+ 1)
+(Î³c+ 1)Ehx0
câˆ’xâˆ—
c2i
Î³c+t. (165)
G.1.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (160) and(165) using Proposition 3.5. For
Î·tâ‰¤1
2SÏ„andÎ³=8S
Âµâˆ’1, we have
E
f(xT)
âˆ’f(xâˆ—)
â‰¤S
2 
E||xT
sâˆ’xâˆ—
s||2+E||xT
câˆ’xâˆ—
c||2
â‰¤8SNPN
n=1(a2
n+ 1)
2Ïƒ2
n+G2+G2
qn
Âµ2(Î³+T)+768S2PN
n=1(an+ 1) 
2Ïƒ2
n+G2
Âµ3(Î³+T) (Î³+ 1)
+S(Î³+ 1)Ehx0
câˆ’xâˆ—
c2i
2(Î³+T)(166)
51G.2 General convex case for SFL-V2
G.2.1 One-round Sequential Update for M-Server-Side Model
By Lemma E.1 with Âµ= 0andÎ·tâ‰¤1
2SÏ„, we have
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
. (167)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
sâˆ’xt+1
s2i
â‰¤NÏ„2 
Î·t2G2NX
n=11
qn. (168)
Thus, we have
Ehxt+1
sâˆ’xâˆ—
s2i
â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1 
2Ïƒ2
n+G2
+NÏ„2 
Î·t2G2NX
n=11
qn.(169)
G.2.2 One-round Parallel Update for Client-Side Models
By Lemma D.1 with Âµ= 0andÎ·tâ‰¤1
2SÏ„, we have
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
. (170)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
câˆ’xt+1
c2i
â‰¤NÏ„2 
Î·t2G2NX
n=1a2
n
qn. (171)
Thus, we have
Ehxt+1
câˆ’xâˆ—
c2i
â‰¤Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1a2
n 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1an 
2Ïƒ2
n+G2
+NÏ„2 
Î·t2G2NX
n=1a2
n
qn.
(172)
G.2.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (169) and (172) as follows
Ehxt+1âˆ’xâˆ—2i
â‰¤Ehxt+1
sâˆ’xâˆ—
s2i
+Ehxt+1
câˆ’xâˆ—
c2i
,
52â‰¤Ehxt
sâˆ’xâˆ—
s2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+Ehxt
câˆ’xâˆ—
c2i
âˆ’2Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1(a2
n+ 1) 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1(an+ 1) 
2Ïƒ2
n+G2
+NÏ„2 
Î·t2G2NX
n=1a2
n+ 1
qn
=Ehxtâˆ’xâˆ—2i
âˆ’4Î·tÏ„E
f 
xt
âˆ’f(xâˆ—)
+ 
Î·t2Ï„2NNX
n=1(a2
n+ 1) 
2Ïƒ2
n+G2
+ 24SÏ„3 
Î·t3NX
n=1(an+ 1) 
2Ïƒ2
n+G2
+NÏ„2 
Î·t2G2NX
n=1a2
n+ 1
qn. (173)
Then, we can obtain the relation between Ehxt+1âˆ’xâˆ—2i
andEh
âˆ¥xtâˆ’xâˆ—âˆ¥2i
, which is related to
E[f(xt)âˆ’f(xâˆ—)]. Applying Lemma 8 in [17], we obtain the performance bound as
E
f 
xT
âˆ’f(xâˆ—)
â‰¤1
2 
NNX
n=1(a2
n+ 1)
2Ïƒ2
n+G2+G2
n
qn!1
2 x0âˆ’xâˆ—2
T+ 1!1
2
+1
2 
24SNX
n=1(an+ 1) 
2Ïƒ2
n+G2!1
3 x0âˆ’xâˆ—2
T+ 1!1
3
+Sx0âˆ’xâˆ—2
2(T+ 1). (174)
53G.3 Non-convex case for SFL-V2
G.3.1 One-round Sequential Update for M-Server-Side Model
For the server, we have
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
â‰¤E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s+Î·tÏ„âˆ‡xsf 
xt
âˆ’Î·tÏ„âˆ‡xsf 
xt
â‰¤E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s+Î·tÏ„âˆ‡xsf 
xt
âˆ’
âˆ‡xsf 
xt
s
, Î·tÏ„âˆ‡xsf 
xt
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1Ï„âˆ’1X
i=0It
n
qngt,i
s,n#
+Î·tÏ„âˆ‡xsf 
xt+
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1Ï„âˆ’1X
i=0It
n
qnâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	#
+Î·tÏ„âˆ‡xsf 
xt+
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤*
âˆ‡xsf 
xt
,E"
âˆ’Î·tNX
n=1Ï„âˆ’1X
i=0It
n
qnâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
+Î·tNX
n=1Ï„âˆ’1X
i=0It
n
qnâˆ‡xsFn 
xt#+
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤Î·tÏ„*
âˆ‡xsf 
xt
,E"
âˆ’1
Ï„NX
n=1Ï„âˆ’1X
i=0It
n
qnâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
+1
Ï„NX
n=1Ï„âˆ’1X
i=0It
n
qnâˆ‡xsFn 
xt#+
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤Î·tÏ„
2âˆ‡xsf 
xt2+Î·t
2Ï„Eï£®
ï£°NX
n=1Ï„âˆ’1X
i=0It
n
qnâˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’NX
n=1Ï„âˆ’1X
i=0It
n
qnâˆ‡xsFn 
xt2ï£¹
ï£»
âˆ’Î·tÏ„âˆ‡xsf 
xt2
â‰¤ âˆ’Î·tÏ„
2âˆ‡xsf 
xt2+Î·t
2Ï„Eï£®
ï£°NX
n=1Ï„âˆ’1X
i=0It
n
qn 
âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’ âˆ‡xsFn 
xt2ï£¹
ï£»
â‰¤ âˆ’Î·tÏ„
2âˆ‡xsf 
xt2+NÎ·t
2Ï„NX
n=11
qnEï£®
ï£°Ï„âˆ’1X
i=0 
âˆ‡xsFn 
xt,i
c,n,xt,i
s,n	
âˆ’ âˆ‡xsFn 
xt2ï£¹
ï£»
â‰¤ âˆ’Î·tÏ„
2âˆ‡xsf 
xt2+NÎ·tS2
2NX
n=11
qnÏ„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
, (175)
where we apply Assumption C.1, âˆ‡xsf(xt) =PN
n=1âˆ‡xsFn(xt),âŸ¨a, bâŸ© â‰¤a2+b2
2, andE[It
n] =
qn.
By Lemma C.6 with Î·tâ‰¤1âˆš
8SÏ„, we have
Ï„âˆ’1X
i=0Ehxt,i
s,nâˆ’xt
s2i
â‰¤2Ï„2
8Ï„ 
Î·t2Ïƒ2
n+ 8Ï„ 
Î·t2Ïµ2+ 8Ï„ 
Î·t2âˆ‡xsf 
xt
s2
(176)
Thus, (175) becomes
E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
â‰¤âˆ’Î·tÏ„
2âˆ‡xsf 
xt2+NÎ·tS2
2NX
n=11
qn2Ï„2
8Ï„ 
Î·t2Ïƒ2
n+8Ï„ 
Î·t2Ïµ2+8Ï„ 
Î·t2âˆ‡xsf 
xt
s2
â‰¤ 
âˆ’Î·tÏ„
2+ 8N 
Î·t3Ï„3S2NX
n=11
qn!
âˆ‡xsf 
xt2+ 8NÎ·tS2Ï„3NX
n=11
qn 
Î·t2 
Ïƒ2
n+Ïµ2
.
(177)
54Furthermore, we have
S
2Ehxt+1
sâˆ’xt
s2i
=SN(Î·t)2
2NX
n=1Eï£®
ï£°Ï„âˆ’1X
i=0It
n
qngt,i
s,n2ï£¹
ï£»
â‰¤SN(Î·t)2
2NX
n=11
qnEï£®
ï£°Ï„âˆ’1X
i=0gt,i
s,n2ï£¹
ï£»
â‰¤SN(Î·t)2Ï„
2NX
n=11
qnÏ„âˆ’1X
i=0Ehgt,i
s,n2i
â‰¤SN(Î·t)2Ï„
2NX
n=11
qnÏ„âˆ’1X
i=0Ehgt,i
s,nâˆ’gt
s,n+gt
s,n2i
â‰¤SN(Î·t)2Ï„
2NX
n=11
qnÏ„âˆ’1X
i=0
Ehgt,i
s,nâˆ’gt
s,n2i
+Ehgt
s,n2i
â‰¤SN(Î·t)2Ï„
2NX
n=11
qnÏ„âˆ’1X
i=0
Ehgt,i
s,nâˆ’gt
s,n2i
+Ehâˆ‡xsFn 
xt2+Ïƒ2
ni
, (178)
where the last line uses Assumption C.1 and E
âˆ¥zâˆ¥2
=âˆ¥E[z]âˆ¥2+E[âˆ¥zâˆ’E[z]âˆ¥2
for any random
variable z.
By Lemma C.7 with Î·tâ‰¤1
2SÏ„, we have
Ï„âˆ’1X
i=0Ehgt,i
s,nâˆ’gt
s,n2i
â‰¤8Ï„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
. (179)
Thus, (178) becomes
S
2Ehxt+1
sâˆ’xt
s2i
â‰¤SN(Î·t)2Ï„
2NX
n=11
qn
8Ï„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
+Ï„Ehâˆ‡xsFn 
xt2+Ïƒ2
ni
â‰¤SN(Î·t)2Ï„
2NX
n=11
qn
Ï„+ 8Ï„3 
Î·t2S2âˆ‡xsFn 
xt2+Ïƒ2
n
â‰¤SN(Î·t)2Ï„
2NX
n=11
qn
Ï„+ 8Ï„3 
Î·t2S2âˆ‡xsFn 
xt
âˆ’ âˆ‡xsf 
xt
+âˆ‡xsf 
xt2+Ïƒ2
n
â‰¤SN(Î·t)2Ï„
2NX
n=11
qn
Ï„+ 8Ï„3 
Î·t2S2
2âˆ‡xsf 
xt2+ 2Ïµ2+Ïƒ2
n
. (180)
G.3.2 One-round Parallel Update for Client-Side Models
The analysis of the client-side model update is the same as the clientâ€™s model update in version 1.
Thus, we have
E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
â‰¤ 
âˆ’Î·tÏ„
2+ 8N 
Î·t3Ï„3S2NX
n=1a2
n
qn!
âˆ‡xcf 
xt2+ 8NÎ·tS2Ï„3NX
n=1a2
n
qn 
Î·t2 
Ïƒ2
n+Ïµ2
.
(181)
55ForÎ·tâ‰¤1
2SÏ„,
S
2Ehxt+1
câˆ’xt
c2i
â‰¤SN(Î·t)2Ï„
2NX
n=1a2
n
qn
Ï„+ 8Ï„3 
Î·t2S2
2âˆ‡xcf 
xt2+ 2Ïµ2+Ïƒ2
n
. (182)
G.3.3 Superposition of M-Server and Clients
Applying (177), (180), (182) and (181) into (36) in Proposition C.4, we have
E
f 
xt+1
âˆ’f 
xt
â‰¤E
âˆ‡xcf 
xt
,xt+1
câˆ’xt
c
+S
2Ehxt+1
câˆ’xt
c2i
+E
âˆ‡xsf 
xt
,xt+1
sâˆ’xt
s
+S
2Ehxt+1
sâˆ’xt
s2i
â‰¤ 
âˆ’Î·tÏ„
2+ 8N 
Î·t3Ï„3S2NX
n=11
qn!
âˆ‡xf 
xt2
+ 8NÎ·tS2Ï„3NX
n=1a2
n+ 1
qn 
Î·t2 
Ïƒ2
n+Ïµ2
+SN(Î·t)2Ï„
2NX
n=11
qn
Ï„+ 8Ï„3 
Î·t2S2
2âˆ‡xf 
xt2
+SN(Î·t)2Ï„
2NX
n=1a2
n+ 1
qn
Ï„+ 8Ï„3 
Î·t2S2 
2Ïµ2+Ïƒ2
n
â‰¤ 
âˆ’Î·tÏ„
2+ 8N 
Î·t3S2Ï„3NX
n=11
qn+SN 
Î·t2Ï„NX
n=11
qn
Ï„+ 8Ï„3 
Î·t2S2!
âˆ‡xf 
xt2
+ 8NÎ·tS2Ï„3NX
n=1a2
n+ 1
qn 
Î·t2 
Ïƒ2
n+Ïµ2
+1
2SN 
Î·t2Ï„
Ï„+ 8Ï„3 
Î·t2S2NX
n=1a2
n+ 1
qn 
2Ïµ2+Ïƒ2
n
â‰¤ 
âˆ’Î·tÏ„
2+SN 
Î·t2Ï„2NX
n=11
qn+ 8N 
Î·t3S2Ï„3NX
n=11
qn+ 8S3N 
Î·t4Ï„4NX
n=11
qn!
âˆ‡xf 
xt2
+ 8N 
Î·t3S2Ï„3NX
n=1a2
n+ 1
qnÏƒ2
n+ 8N 
Î·t3S2Ï„3Ïµ2NX
n=1a2
n+ 1
qn
+SN 
Î·t2Ï„2Ïµ2NX
n=1a2
n+ 1
qn+1
2SN 
Î·t2Ï„2NX
n=1a2
n+ 1
qnÏƒ2
n
+ 8NS3 
Î·t4Ï„4Ïµ2NX
n=1a2
n+ 1
qn+ 4NS3 
Î·t4Ï„4NX
n=1a2
n+ 1
qnÏƒ2
n
â‰¤ âˆ’Î·tÏ„
2 
1âˆ’2SNÎ·tÏ„2
Ï„NX
n=11
qn
1 + 8 SÎ·tÏ„+ 8S2 
Î·t2Ï„2!
âˆ‡xf 
xt2
+1
2NS 
Î·t2Ï„2+ 8N 
Î·t3S2Ï„3+ 4NS3 
Î·t4Ï„4NX
n=1a2
n+ 1
qnÏƒ2
n
+
NS 
Î·t2Ï„2+ 8N 
Î·t3S2Ï„3+ 8NSL3 
Î·t4Ï„4NX
n=1a2
n+ 1
qnÏµ2
56â‰¤ âˆ’Î·tÏ„
2 
1âˆ’2NSÎ·tÏ„2
Ï„NX
n=11
qn
1 +1
2+1
32!
âˆ‡xf 
xt2
+NS 
Î·t2Ï„21
2+1
2+1
64NX
n=1a2
n+ 1
qnÏƒ2
n+ 2SN 
Î·t2Ï„21
2+1
4+1
64NX
n=1a2
n+ 1
qnÏµ2
â‰¤ âˆ’Î·tÏ„
2 
1âˆ’4N2SÎ·tÏ„2
Ï„NX
n=11
qn!
âˆ‡xf 
xt2+ 2NS 
Î·t2Ï„2NX
n=1a2
n+ 1
qn 
Ïƒ2
n+Ïµ2
â‰¤ âˆ’Î·tÏ„
4âˆ‡xf 
xt2+ 2NS 
Î·t2Ï„2NX
n=1a2
n+ 1
qn 
Ïƒ2
n+Ïµ2
, (183)
where we first let Î·tâ‰¤1
16SÏ„and then let Î·tâ‰¤1
8SN2Ï„PN
n=11
qn. We have appliedPN
n=1a2
nâ‰¤N.
Rearranging the above we have
Î·tâˆ‡xf 
xt2â‰¤4
Ï„ 
f 
xt
âˆ’E
f 
xt+1
s
+ 8NS 
Î·t2Ï„NX
n=1a2
n+ 1
qn 
Ïƒ2
n+Ïµ2
.(184)
Taking expectation and averaging over all t, we have
1
TTâˆ’1X
t=0Î·tEhâˆ‡xf 
xt2i
â‰¤4
TÏ„(f(x0)âˆ’fâˆ—) +8NSÏ„
TNX
n=1a2
n+ 1
qn 
Ïƒ2
n+Ïµ2Tâˆ’1X
t=0 
Î·t2.
(185)
57H Comparative Analysis
H.1 Main technical results
We conclude the convergence results in our paper in Table 1.
Table 1: Performance upper bounds for different objectives (let Q:=PN
n=11
qn).
Scenario Case Method Convergence result
Full participationStrongly convexSFL-V1S
Âµ(S+ÂµT)(N(Ïƒ2+G2) +ÂµSIerr)
SFL-V2S
Âµ(S+ÂµT)(N2(Ïƒ2+G2) +ÂµSIerr)
General convexSFL-V1 (N(Ïƒ2+G2)
T)1
2+ (N(Ïƒ2+G2)
T)1
3+S
TIerr
SFL-V2 (N2(Ïƒ2+G2)
T)1
2+ (N2(Ïƒ2+G2)
T)1
3+S
TIerr
Non-convexSFL-V1NS(Ïƒ2+Ïµ2)
T+Ferr
T
SFL-V2N2S(Ïƒ2+Ïµ2)
T+Ferr
T
Partial participationStrongly convexSFL-V1S
Âµ(S+ÂµT)(N(Ïƒ2+G2(1 +Q)) +ÂµSIerr)
SFL-V2S
Âµ(S+ÂµT)(N2(Ïƒ2+G2(1 +Q)) +ÂµSIerr)
General convexSFL-V1 (N(Ïƒ2+G2(1+Q))
T)1
2+ (N(Ïƒ2+G2)
T)1
3+S
TIerr
SFL-V2 (N2(Ïƒ2+G2(1+Q))
T)1
2+ (N2(Ïƒ2+G2)
T)1
3+S
TIerr
Non-convexSFL-V1NS(Ïƒ2+Ïµ2)Q
T+Ferr
T
SFL-V2N2S(Ïƒ2+Ïµ2)Q
T+Ferr
T
H.2 Comparison of Bounds
We compare our derived bounds for SFL to other distributed approaches. For simplicity, we let
an= 1/Nin (1) and Ïƒn=Ïƒfor all nin (6). The result are summarized in Table 2. Since different
convergence theories make slightly different assumptions, we clarify them below.
In [ 33],Ïƒ2
âˆ—is the variance of the stochastic gradient at the optimum:
EÎ¶nâˆ¼Dnh
âˆ¥gn(xâˆ—, Î¶n)âˆ’ âˆ‡Fn(xâˆ—)âˆ¥2i
â‰¤Ïƒ2
âˆ—.In [16],Î“ = fâˆ—âˆ’PN
n=1Fâˆ—
n/Ncharacterizes
the client heterogeneity. In [ 17],Ïµ2
âˆ—characterizes the client heterogeneity at the optimum, similar to
[12], i.e.,1
NPN
n=1||âˆ‡Fn(xâˆ—)||2=Ïµ2
âˆ—.
Table 2: Performance upper bounds for strongly convex objectives with full client participation. Here,
absolute constants and polylogarithmic factors are omitted. We further relax the upper bounds of
SFL-V2 for an easier comparison.
Method Performance upper bound
Mini-Batch SGD [33]Ïƒ2
âˆ—
ÂµNÏ„T+S(f(x0)âˆ’fâˆ—)
Âµexp
âˆ’ÂµT
S
FL
[16]S
ÂµÏ„+T
Ïƒ2+SÎ“N+NÏ„2G2
ÂµN+SIerr
[10]Ïƒ2
ÂµNÏ„T+SÏƒ2
Âµ2Ï„T2+SÏµ2
Âµ2T2+ÂµIerrexp
âˆ’ÂµT
S
SL [17]Ïƒ2
ÂµNÏ„T+SÏƒ2
Âµ2NÏ„T2+SÏµ2
âˆ—
Âµ2NT2+ÂµIerrexp
âˆ’ÂµT
S
SFL
SFL-V1 (Theorem 3.6)S
Âµ(S+ÂµT) 
N(Ïƒ2+G2) +ÂµSIerr
SFL-V2 (Theorem 3.7)S
Âµ(S+ÂµT) 
N2(Ïƒ2+G2) +ÂµSIerr
The key observation is that our derived bounds match the other distributed approaches in the order of
Tand they all achieve O(1/T).
58Furthermore, we will compare the convergence upper bounds of SFL to those of distributed SGD in
[12] (with parameters p= 1andÂ¯Î¶2= 0) as follows:
Table 3: Performance upper bounds for different objectives with full client participation.
Case Method Convergence results
Strongly convexDistributed SGDÏƒ2
ÂµNT+SIerrexp
âˆ’ÂµT
S
SFL-V1S
Âµ(S+ÂµT)(N(Ïƒ2+G2) +ÂµSIerr)
SFL-V2S
Âµ(S+ÂµT)(N2(Ïƒ2+G2) +ÂµSIerr)
General convexDistributed SGD (Ïƒ2
NT2+S
T)Ierr
SFL-V1 (N(Ïƒ2+G2)
T)1
2+ (N(Ïƒ2+G2)
T)1
3+S
TIerr
SFL-V2 (N2(Ïƒ2+G2)
T)1
2+ (N2(Ïƒ2+G2)
T)1
3+S
TIerr
Non-convexDistributed SGD (Ïƒ2
NT2+1
T)SFerr
SFL-V1NS(Ïƒ2+Ïµ2)
T+Ferr
T
SFL-V2N2S(Ïƒ2+Ïµ2)
T+Ferr
T
In the aforementioned table, we denote Ïƒn=Ïƒ, define Ierrâ‰œ||x0âˆ’xâˆ—||2, and represent Ferrâ‰œ
f(x0)âˆ’fâˆ—. The absolute constants and polylogarithmic factors are omitted for brevity. Our SFL
algorithms show the same convergence rate as the distributed SGD.
H.3 Comparison of Communication and Computation Overheads
There have been are some papers discussing the overhead of SFL, e.g., [ 27,4]. We mainly use the
analysis from [27].
We start with the definitions. Let Krepresent the total number of clients involved, Ddenote the
aggregate size of the data, and vindicate the size of the smashed layer. The rate of communication is
given by R, while Tfbsignifies the duration required for a complete forward and backward propagation
cycle on the entire model for a dataset of size D, applicable across various architectures. The time
needed to aggregate the full model is expressed as Tfedavg . The full modelâ€™s size is denoted by |W|,
andrreflects the proportion of the full modelâ€™s size that is accessible to a client in SFL, specifically,
|WC|=r|W|. The factor 2r|W|in the communication per client arises from the necessity for clients
to download and upload their model updates before and after the training process. These findings are
encapsulated in Table 4. It is observed that as Kescalates, the cumulative cost of training time tends
to rise following the sequence: SFL-V2 being less than SFL-V1.
Table 4: Communication and computation comparison between FL, SL, and SFL.
Method Communication per client Total communication Total model training time
FL 2|W| 2K|W| Tfb+2|W|
R+Tfedavg
SL (2D
K)v+ 2r|W| 2Dv+ 2rK|W| Tfb+2Dv
R+2r|W|K
R
SFL-V1 (2D
K)v+ 2r|W| 2Dv+ 2rK|W| Tfb+2Dv
RK+2r|W|
R+Tfedavg
SFL-V2 (2D
K)v+ 2r|W| 2Dv+ 2rK|W| Tfb+2Dv
RK+2r|W|
R+Tfedavg
2
590 50 100 150 200
Training Round020406080100 AccuracySFL-V1
SFL-V2
FLSL
FedProx
FedOpt(a)Î²= 0.1, N= 10 .
0 50 100 150 200
Training Round020406080100 AccuracySFL-V1
SFL-V2
FLSL
FedProx
FedOpt (b)Î²= 0.1, N= 100 .
Figure 6: Performance comparison on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
E=2
E=5E=10
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
E=2
E=5E=10 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
E=2
E=5E=10 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round020406080100Accuracy
E=2
E=5E=10 (d) SFL-V2 on CIFAR-100.
Figure 7: Impact of local iteration on SFL performance.
I Additional Experiments
I.1 More comparing methods
We compare the SFL methods with the benchmarks, i.e., FedProx [ 15] and FedOpt [ 19]. We have
used the same hyperparameters, and trained the models on CIFAR-10. The results are provided in
Figure 6. From the figures, we observe that SFL-V2 continues to be the best-performing algorithm.
This is consistent with our observations in the main paper.
I.2 Impact of local iteration
We further study the impact of local epoch number Eon the SFL performance. The results are
reported in Fig. 7. We observe that SFL generally converges faster with a larger Ï„, demonstrating the
benefit of SFL in practical distributed systems.
I.3 Results using loss metric
We further report the results using the loss metric. More specifically:
â€¢Impact of cut layer : The results are reported in Figs. 8 and 9.
â€¢Impact of data heterogeneity : The results are reported in Fig. 10.
â€¢Impact of partial participation : The results are reported in Fig. 11.
In general, we see similar (but opposite) trends with the observations in the main paper. That is, a
higher accuracy is associated with a smaller loss. These results are again consistent with our theories.
I.4 Results on the impact of the position of cut layer.
We can observe from the results that the performance of SFL-V1 and SFL-V2 increases in Lc. We
look at the impact of the position of cut layer from the gradient perspective. We plot the gradient
divergence in Fig. 12:
600 50 100 150 200
Training Round0.00.10.20.30.40.5LossLc=1
Lc=2Lc=3
Lc=4(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round0.00.10.20.30.40.5LossLc=1
Lc=2Lc=3
Lc=4 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round0.00.20.40.60.81.0LossLc=1
Lc=2Lc=3
Lc=4 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round0.00.20.40.60.81.0LossLc=1
Lc=2Lc=3
Lc=4 (d) SFL-V2 on CIFAR-100.
Figure 8: Impact of the choice of cut layer on SFL training loss.
0 50 100 150 200
Training Round0246810LossLc=1
Lc=2Lc=3
Lc=4
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round0246810LossLc=1
Lc=2Lc=3
Lc=4 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round0246810LossLc=1
Lc=2Lc=3
Lc=4 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round0246810LossLc=1
Lc=2Lc=3
Lc=4 (d) SFL-V2 on CIFAR-100.
Figure 9: Impact of the choice of cut layer on SFL test loss.
We see for SFL-V1 and SFL-V2, the gradient divergence decreases as we choose a latter cut layer (a
larger Lc). This means that the client drift issue is less severe and hence the performance increases.
In addition, from a theoretical perspective, if we write Ïµ2(i.e., upper bound of gradient divergence
defined in Assumption 3.3) as a function of Lc, we can see that the upper bounds of performance
loss decrease in Lc. This provides a theoretical angle that the performance of SFL-V1 and SFL-V2
increases in Lc.
I.5 Results on FEMNIST dataset
We have conducted more simulations on a larger dataset FEMNIST. In particular, we consider
N= 100 and train FL, SFL-V1, SFL-V2. Note that the data come from different sources and are
heterogeneous across clients. The results are reported in Fig. 13.
We note that our key observation continues to hold. That is, SFL-V2 outperforms FL and SFL-V1
under-performs FL under heterogeneous data and a large number of clients.
610 50 100 150 200
Training Round0.00.10.20.30.40.50.6Loss=0.1
=0.5
=1
=
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round0.00.10.20.30.40.50.6Loss=0.1
=0.5
=1
=
 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round0.00.20.40.60.81.0Loss=0.1
=0.5
=1
=
 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round0.00.20.40.60.81.0Loss=0.1
=0.5
=1
=
 (d) SFL-V2 on CIFAR-100.
Figure 10: Impact of data heterogeneity on SFL training loss.
0 50 100 150 200
Training Round0.00.10.20.30.40.50.6Lossq=0.2
q=0.5q=1
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round0.00.10.20.30.40.50.6Lossq=0.2
q=0.5q=1 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round0.00.10.20.30.40.50.6Lossq=0.2
q=0.5q=1 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round0.00.20.40.60.81.0Lossq=0.2
q=0.5q=1 (d) SFL-V2 on CIFAR-100.
Figure 11: Impact of client participation on SFL training loss.
Figure 12: Results on the impact of the position
of cut layer.
0 100 200 300 400 500
Training Round020406080100Accuracy
V1
V2FLFigure 13: Results on FEMNIST.
62NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: We claim that we provide convergence analysis of split-federated learning
(SFL) for strongly convex, general convex, and non-convex objectives on heterogeneous
data in the abstract and introduction.
Guidelines:
â€¢The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: In Section 5, we claim that it is also important to theoretically analyze how the
choice of the cut layer affects the SFL performance.
Guidelines:
â€¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
â€¢The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
â€¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
â€¢While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
63Answer: [Yes]
Justification: Section 3 presents the theoretical results with full set of assumptions. The
proof of Proposition 3.5 is given in Appendix C.4. The complete proofs of Theorems
3.6-3.7 are given in Appendices D-E, respectively. Proofs of Theorems 3.6-3.7 are given in
Appendices D-E, respectively.
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢All assumptions should be clearly stated or referenced in the statement of any theorems.
â€¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
â€¢Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Section 4.1 presents the setup of our experiments to reproduce the experimental
results. We further provide our codes in the supplementary material.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
â€¢Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
â€¢While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
645.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide our codes in the supplementary material. We will provide open
access to the data and code if the paper is accepted.
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢While we encourage the release of code and data, we understand that this might not be
possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
â€¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We present the setup of our experiments, including the datasets and hyperpa-
rameters, in Section 4.1 and provide our codes in the supplementary material.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
â€¢The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: This is a theory paper. Due to limit of computation resources and time, we
were not able to run more experiments.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
65â€¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
â€¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
â€¢It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
â€¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
â€¢For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We have used one CPU and one GPU. Specifically, the CPU is Intel(R)
Xeon(R) Gold 5320 CPU with 2.20GHz, and the GPU is A100-PCIE-80GB. Memory:
256GB Storage: 10TB. Each experiment curve takes about 10 hours to train.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
â€¢The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We have conformed to all aspects of code of ethics with this submission.
Guidelines:
â€¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
â€¢The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: The goal of this work is to provide a comprehensive analysis on the convergence
of SFL. Our theoretical results have two potential impacts. First, we provide a thorough
understanding on the performance of SFL, which potentially guides the implementation of
SFL (e.g., the choice between FL and SFL, the choice of hyper-parameters and cut layers).
66Second, the convergence results can be used for modeling the training performance of SFL.
Together with an effective modeling of communication and computation overheads of clients,
researchers will be able to perform SFL system optimization. Due to the reduced clientsâ€™
training loads in SFL, such a system optimization can potentially minimize the burden
at clients (e.g., human mobile devices) while maintaining client privacy and satisfactory
training performance.
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
â€¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
â€¢The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks. We use open-access datasets and models.
Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
â€¢Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
â€¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: Our codes are based on the codes provided in [ 27], which was cited in the
main paper.
67Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
â€¢For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
â€¢If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: The paper does not release new assets
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢The paper should discuss whether and how consent was obtained from people whose
asset is used.
â€¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
â€¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
68Justification: The paper does not involve crowdsourcing nor research with human subjects
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
â€¢We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
69