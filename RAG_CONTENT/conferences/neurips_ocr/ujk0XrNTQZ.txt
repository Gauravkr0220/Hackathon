DRAGO : Primal-Dual Coupled Variance Reduction
for Faster Distributionally Robust Optimization
Ronak Mehta1Jelena Diakonikolas2Zaid Harchaoui1
1University of Washington, Seattle2University of Wisconsin, Madison
Abstract
We consider the penalized distributionally robust optimization (DRO) problem
with a closed, convex uncertainty set, a setting that encompasses learning us-
ingf-DRO and spectral/ L-risk minimization. We present DRAGO , a stochastic
primal-dual algorithm that combines cyclic and randomized components with a
carefully regularized primal update to achieve dual variance reduction. Owing to
its design, DRAGO enjoys a state-of-the-art linear convergence rate on strongly
convex-strongly concave DRO problems with a fine-grained dependency on pri-
mal and dual condition numbers. The theoretical results are supported by numer-
ical benchmarks on regression and classification tasks.
1 Introduction
Contemporary machine learning research is increasingly exploring the phenomenon of distribution
shift, in which predictive models encounter differing data-generating distributions in training versus
deployment [Wiles et al., 2022]. A popular approach to learn under potential distribution shift is
distributionally robust optimization (DRO) of an empirical risk-type objective
min
wâˆˆWmax
qâˆˆQh
L0(w, q) :=Pn
i=1qiâ„“i(w)i
, (1)
where â„“i:Rdâ†’Rdenotes the loss on training instance iâˆˆ[n] :={1, . . . , n }, and q=
(q1, . . . , q n)âˆˆ Q is a vector of nweights for each example. The feasible set Q, often called
theuncertainty set , is a collection of possible instance-level reweightings arising from distributional
shifts between train and evaluation data, and is often chosen as a ball about the uniform vector
1/n= (1/n, . . . , 1/n)inf-divergence [Namkoong and Duchi, 2016, Carmon and Hausler, 2022,
Levy et al., 2020] or a spectral/ L-risk-based uncertainty set [Mehta et al., 2023].
We consider here the penalized version of (1), stated as
L(w, q) :=nX
i=1qiâ„“i(w)âˆ’Î½D(qâˆ¥1/n) +Âµ
2âˆ¥wâˆ¥2
2, (2)
where Âµ, Î½â‰¥0are regularization parameters and D(qâˆ¥1/n)denotes some statistical divergence
(such as the Kullback-Leibler (KL) or Ï‡2-divergence) between the original weights 1/nand shifted
weights q. For clarity, we focus on the cases of Âµ, Î½ > 0, but also describe the modifications to
the methods, results, and proofs for cases in which Âµ= 0 orÎ½= 0, in Appx. C.4. See Fig. 1 for
intuition on the relationship between the uncertainty set, divergence D, and hyperparameter Î½.
Standard (1) and penalized (2) DRO objectives have seen an outpour of recent use in reinforcement
learning and control [Lotidis et al., 2023, Yang et al., 2023, Wang et al., 2023a, Yu et al., 2023,
Kallus et al., 2022, Liu et al., 2022] as well as creative applications in robotics [Sharma et al.,
2020], language modeling [Liu et al., 2021], sparse neural network training [Sapkota et al., 2023],
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Figure 1: Visualization of Uncertainty Sets and Penalties. Each plot is a probability simplex in
n= 3 dimensions with the uncertainty set as the colored portion. The black dots are optimal dual
variables qâ‹†
Î½:= arg maxqâˆˆQPn
i=1qiâ„“i(w)âˆ’Î½D(qâˆ¥1/n)for a fixed wâˆˆW. AsÎ½decreases, qâ‹†
Î½
may shift toward the boundary of the uncertainty set. The combination of Î½andDdetermines an
â€œeffectiveâ€ uncertainty set, whose shape is given by the level sets of D. Our methods apply to both.
and defense against model extraction [Wang et al., 2023b]. However, even in a classical supervised
learning setup, current optimization algorithms for DRO have limitations in both theory and practice.
For context, we consider the large-scale setting in which the sample size nis high, and the training
loss on each example is accessed via a collection of nprimal first-order oracles {(â„“i,âˆ‡â„“i)}n
i=1.
Quantitatively, we measure the performance of algorithms by the runtime or global complexity of
elementary operations to reach within Îµof the minimum of Â¯L(w) = max qâˆˆQL(w, q), whereas
qualitatively, we consider the types of uncertainty sets that can be handled by the algorithm and
convergence analysis. Under standard assumptions, Â¯Lis differentiable with gradient computed via
qâ‹†(w) = arg max
qâˆˆQL(w, q),followed by âˆ‡Â¯L(w) =Pn
i=1qâ‹†
i(w)âˆ‡â„“i(w) +Âµw. (3)
In the learning setting, we are interested in stochastic algorithms that can approximate this gradient
withb < n calls to the oracles. For uniformly randomly sampled iâˆˆ[n],nqâ‹†
i(w)âˆ‡â„“i(w) +Âµwis
an unbiased estimator of âˆ‡Â¯L(w). However, computing qâ‹†
i(w)depends on the first step in (3) which
itself requires calling all noracles (see (2)), i.e., is no different than the cost of full batch gradient
descent. A direct minibatch stochastic gradient descent approach would approximate L(w,Â·)in the
first step of (3) with only bcalls to generate approximate weights Ë†q(w). Because Ë†q(w)Ì¸=qâ‹†(w)in
general for b < n , these methods have non-vanishing bias, i.e., do notconverge [Levy et al., 2020].
This motivated research in DRO-specific stochastic algorithms with theoretical convergence guaran-
tees under particular assumptions (see Tab. 1 and Appx. B for details) [Namkoong and Duchi, 2016,
Levy et al., 2020, Carmon and Hausler, 2022]. While we highlight the dependence on sample size n
and suboptimality Îµ, the dependence on all constants is given in Tab. 1. For f-divergence-based un-
certainty sets in the standard oracle framework, several methods achieve a O(Îµâˆ’2)complexity. Levy
et al. [2020] do so by proving uniform bias bounds, so that if bscales as O(Îµâˆ’2), the convergence
guarantee is achieved. However, if the required batch size bexceeds the training set size n, then the
method reduces to the sub-gradient method, as we can see in Tab. 1. These sublinear rates typically
stem from two causes. The first is the adoption of a â€fully stochasticâ€ perspective on the oracles,
wherein each oracleâ€™s output is treated as an independent random sample drawn from a probability
distribution. The second is the non-smoothness of the objective, as we shall see below.
Variance reduction techniques, on the other hand, exploit the fact that the optimization algo-
rithm takes multiple passes through the same dataset, and achieve linear rates of the form
O((n+Îºâ„“) log( Îµâˆ’1))in empirical risk minimization when the objective is both smooth (i.e.,
has Lipschitz continuous gradient) and strongly convex and Îºâ„“is an associated condition number
[Johnson and Zhang, 2013, Defazio et al., 2014]. Assuming access to stronger oracles involving
constrained minimization and applying a variance reduction scheme, Carmon and Hausler [2022]
achieve O(nÎµâˆ’2/3+n3/4Îµâˆ’1)forf-divergences as well, but do not obtain linear convergence due
to the second type of cause: the objective âˆ‡Â¯Lisnon-smooth when Î½= 0.
2Recently, Mehta et al. [2024] handled the Î½ > 0case for spectral risk uncertainty sets, and their
variance-reduced algorithm achieves a linear O((n+ÎºQÎºâ„“) ln(1 /Îµ))convergence guarantee (where
ÎºQâ‰¥1measures the â€œsizeâ€ of the uncertainty set), but only with a lower bound of order â„¦(n)on
the problem parameter Î½. The challenge of this problem, considered from a general optimization
viewpoint beyond DRO, stems from the non-bilinearity of the coupled termPn
i=1qiâ„“i(w)and the
constraint thatPn
i=1qi= 1for probability vectors. If the coupled term was bilinear (i.e., of the form
qâŠ¤AwforAâˆˆRnÃ—d) and the constraints applied separately to each qi, then dual decomposition
techniques could be used. Qualitatively, algorithms and analyses often rely on particular uncertainty
sets; for example, Kumar et al. [2024] use duality arguments specific to the Kullback-Leibler uncer-
tainty set to create a primal-only minimization problem. See Appx. B for a detailed discussion of
related work from the ML and the optimization lenses. Given the interest from both communities,
we address whether a stochastic DRO algorithm can simultaneously 1) achieve a linear convergence
rate for any Î½ >0and 2) apply to many common uncertainty sets.
Contributions We propose DRAGO , a minibatch primal-dual algorithm for the penalized DRO prob-
lem (2) that achieves Îµ-suboptimality in
O "
n
b+ÎºQL
Âµ+n
bs
nG2
ÂµÎ½#
ln1
Îµ!
(4)
iterations, where bâˆˆ {1, . . . , n }is the minibatch size, ÎºQ=nqmax:=nmax qâˆˆQ,iâˆˆ[n]qimea-
sures the size of the uncertainty set, and GandLare the Lipschitz continuity parameters of â„“iand
âˆ‡â„“i, respectively. For commonly used parameters of uncertainty sets, nqmax is bounded above by
an absolute constant independent in n(see Prop. 3), so for d < n andb=n/d, we maintain an
O(n)per-iteration complexity (the dual dimensionality) while reducing the number of iterations to
O((d+nqmaxL/Âµ+dp
nG2/(ÂµÎ½))) ln (1 /Îµ)). Theoretically, the complexity bound we achieve
in (4) is the best one among current penalized DRO algorithms, delineating a clear dependence on
smoothness constants of the coupled term and strong convexity constants of the individual terms
in (2). Practically, DRAGO has a single hyperparameter and operates on any closed, convex un-
certainty set for which the map l7â†’arg maxqâˆˆQ
qâŠ¤lâˆ’Î½D(qâˆ¥1/n)	
is efficiently computable.
DRAGO is also of general conceptual interest as a stochastic variance-reduced primal-dual algorithm
for min-max problems. It delicately combines randomized and cyclic components, which effectively
address the varying dimensions of the two problems (see Sec. 2). The theoretical guarantees of the
algorithm are explained in Sec. 3. Numerical performance benchmarks are shown in Sec. 4.
2 The DRAGO Algorithm
We present here the Distributionally Robust Annular Gradient Optimizer ( DRAGO ). While similar
in spirit to a primal-dual proximal gradient method with a stochastic flavor, there are several inno-
vations that allow the algorithm to achieve its superior complexity guarantee. These include using
1) minibatch stochastic gradient estimates to improve the trade-off between the per-iteration com-
plexity and required number of iterations (especially when nâ‰«d), 2) a combination of randomized
and cyclically updated components in the primal and dual gradient estimates, and 3) a novel regu-
larization term in the primal update which reduces variance in the gradient estimate (i.e., coupled
variance reduction). Here, we describe the algorithm in a manner that helps elucidate the upcoming
theoretical analysis (Sec. 3). On the other hand, in Appx. D, we present an alternate description of
DRAGO that is amenable to direct implementation in code.
Notation & Terminology LetÏˆ:Rnâ†’Râˆª {+âˆ} be a proper, convex function such that
Q âŠ†dom( Ïˆ) :={qâˆˆRn:Ïˆ(q)<+âˆ}. LetÏˆhave a non-empty subdifferential for each qâˆˆ Q,
and denote by âˆ‡Ïˆa map from qâˆˆ Q to an arbitrary but consistently chosen subgradient in âˆ‚Ïˆ(q).
We denote the Bregman divergence generated by Ïˆasâˆ†Ïˆ(q,Â¯q) =Ïˆ(q)âˆ’Ïˆ(Â¯q)âˆ’ âŸ¨âˆ‡ Ïˆ(Â¯q), qâˆ’Â¯qâŸ©.
We define the Bregman divergence in this way for purely technical reasons, to gracefully account
for cases such as computing âˆ†Ïˆ(q,Â¯q)when Ïˆis the negative entropy function and Â¯qlies on the
boundary of the n-dimensional probability simplex. Finding a minimizer of (2) is equivalent to
finding a saddle-point (wâ‹†, qâ‹†)âˆˆ W Ã— Q which satisfies
max
qâˆˆQL(wâ‹†, q) =L(wâ‹†, qâ‹†) = min
wâˆˆWL(w, qâ‹†).
3Method Assumptions Uncertainty Set Runtime / Global Complexity (Big- ËœO)
Sub-Gradient Methodâ„“iisG-Lipschitz
âˆ¥wâˆ’wâ€²âˆ¥2â‰¤R(if included)
Âµ >0(if included)
âˆ‡â„“iisL-Lipschitz and Î½ >0(if included)Support Constrained
Support Constrained
Support ConstrainedndÂ·(GR)2Îµâˆ’2
ndÂ·G2Âµâˆ’1Îµâˆ’1
ndÂ·Âµâˆ’1 
L+Âµ+nG2/Î½
log(1/Îµ)
LCVaR-SGDâ€ 
LÏ‡2-SGDâ€ 
LÏ‡2âˆ’pen-SGDâ€ 
[Levy et al., 2020]â„“iisG-Lipschitz and in [0, B]
âˆ¥wâˆ’wâ€²âˆ¥2â‰¤Rfor all w, wâ€²âˆˆW
Î½ >0(if included)Î¸-CVaR
Ï-ball in Ï‡2-divergence
Ï‡2-divergence penaltymin
n, B2Î¸âˆ’1Îµâˆ’2	
dÂ·(GR)2Îµâˆ’2
min
n,(1 +Ï)B2Îµâˆ’2	
dÂ·(GR)2Îµâˆ’2
min
n, B2Î½âˆ’1Îµâˆ’1	
dÂ·(GR)2Îµâˆ’2
BROOâˆ—
BROOâˆ—
[Carmon and Hausler, 2022]â„“iisG-Lipschitz
âˆ¥wâˆ’wâ€²âˆ¥2â‰¤Rfor all w, wâ€²âˆˆW
âˆ‡â„“iisL-Lipschitz (if included)1-ball in f-divergence
1-ball in f-divergencendÂ·(GR)2/3Îµâˆ’2/3+d(GR)2Îµâˆ’2
ndÂ·(GR)2/3Îµâˆ’2/3+n3/4d 
GRÎµâˆ’1+L1/2RÎµâˆ’1/2
LSVRG
LSVRG
[Mehta et al., 2023]â„“iisG-Lipschitz
âˆ‡â„“iisL-Lipschitz
Âµ >0,Î½ >0,Îº:= (L+Âµ)/ÂµSpectral Risk Measures ( Î½small)
Spectral Risk Measures ( Î½â‰¥â„¦(nG2/Âµ))None
(n+ÎºQÎº)dlog(1/Îµ)
Prospect
Prospect
[Mehta et al., 2024]â„“iisG-Lipschitz
âˆ‡â„“iisL-Lipschitz
Âµ >0,Î½ >0,Îº:= (L+Âµ)/Âµ, Î´ =G2/(ÂµÎ½)Spectral Risk Measures ( Î½small)
Spectral Risk Measures ( Î½â‰¥â„¦(nG2/Âµ))n(n+d) max
nÎ´+Îºnqmax, n3Î´2Îº2, n3Î´3	
log(1/Îµ)
(n+ÎºQÎº) (n+d)log(1 /Îµ)
DRAGO (Ours)â„“iisG-Lipschitz
âˆ‡â„“iisL-Lipschitz
Âµ >0,Î½ >0,b:=Batch SizeSupport Constrained n
d+ÎºQL/Âµ+dp
nG2/(ÂµÎ½)
log(1/Îµ)
Table 1: Complexity Bounds of DRO Methods. Runtime or global complexity (i.e., the total num-
ber of elementary operations required to compute wsatisfying max qâˆˆQL(w, q)âˆ’ L(wâ‹†, qâ‹†)â‰¤Îµ.
Throughout, we assume that each â„“iis convex and Âµ, Î½â‰¥0. The â€œSupport Constrainedâ€ uncertainty
set refers to all closed, convex sets of probability mass vectors and any 1-strongly convex penalty.
This includes f-divergences and spectral risk measures, but not general Wasserstein balls.âˆ—Bounds
hold in high probability.â€ Complexity is measured in our framework; see Appx. B for details.
We denote the Jacobian of â„“:= (â„“1, . . . , â„“ n)atwasâˆ‡â„“(w)âˆˆRnÃ—d. We refer to the gradient of
the coupled term qâŠ¤â„“(w)of (2) with respect to wandq(that is, âˆ‡â„“(w)âŠ¤qandâ„“(w)) as the primal
and dual gradients, respectively. In both the definition of the algorithm as well as the analysis, we
will consider a sequence of positive constants (at)tâ‰¥1with the additional values a0= 0. The partial
sums of this sequence will be denoted At=Pt
Ï„=0aÏ„. Here, trepresents the iteration counter while
the convergence rate will be proportional to Aâˆ’1
t(see Sec. 3), so we wish for the sequence to grow
as fast as possible. As mentioned in Sec. 1, dis the primal dimension, nis the dual dimension as
well as the sample size, and bdenotes a batch size that divides nfor ease of presentation.
Algorithm Description We specify the algorithm by recursively defining a sequence of primal-dual
iterates {(wt, qt)tâ‰¥1}that achieve a particular convergence guarantee. First, we may assume that
0âˆˆWwithout loss of generality, so fix w0=0andq0=1/n. For any tâ‰¥1, we introduce
vP
tâˆ’1andvD
tas to-be-specified stochastic gradient estimates of the quantities âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1and
â„“(wt), respectively. We choose to update wtbefore qt, so that vP
tâˆ’1may depend only on the history
{(wÏ„, qÏ„}tâˆ’1
Ï„=0, whereas vD
tmay depend additionally on wtas well. Letting (Ct)tâ‰¥1and(ct)tâ‰¥1be
to-be-specified sequences of positive constants with C0=c0= 0, we employ primal-dual proximal
approach guided by the updates
wt:= arg min
wâˆˆWn
at
vP
t, w
+atÂµ
2âˆ¥wâˆ¥2
2+Ctâˆ’1Âµ
2âˆ¥wâˆ’wtâˆ’1âˆ¥2
2(5)
+ctâˆ’1Âµ
2tâˆ’2X
s=tâˆ’n/bâˆ¥wâˆ’wsâˆ¨0âˆ¥2
2o
(6)
qt:= arg max
qâˆˆQn
at
vD
t, q
âˆ’atÎ½D(qâˆ¥q0)âˆ’Atâˆ’1Î½âˆ†D(q, qtâˆ’1)o
. (7)
For the primal update, despite the non-standard term (6), wtcan be computed easily in closed form
whenW=Rd. Otherwise, retrieving wtrelies on computing an â„“2-norm projection onto W. On
the other hand, the maximization (7) can often be solved exactly or to high accuracy using methods
specific to each uncertainty set; we describe these in detail in Appx. D.2. The randomized and
cyclic coordinate-wise components mentioned above are contained within the upcoming formulas
forvP
tâˆ’1andvD
t. After specifying these vectors, the constants (Ct, ct)will be chosen in the analysis
to recover the final algorithm.
4Next, we describe the computation of vP
tâˆ’1andvD
t, which will rely on quantities that are stored
by the algorithm along its iterations. We store three tables of values Ë†â„“tâˆˆRn,Ë†qtâˆˆRn, and
Ë†gâˆˆRnÃ—d, which are approximations of â„“(wt),qt, andâˆ‡â„“(wt), respectively. Before explaining
how these tables are updated, consider the data indices {1, . . . , n }to be partitioned into n/bblocks,
written (B1, . . . , B n/b)forBK= (Kâˆ’b+ 1, . . . , Kb ). On each iteration t, we randomly sample
independent block indices It, Jtâˆ¼Unif[ n/b]and define
vP
tâˆ’1= Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1+atâˆ’1
atÂ·n
bX
iâˆˆBIt(qtâˆ’1,iâˆ‡â„“i(wtâˆ’1)âˆ’Ë†qtâˆ’2,iË†gtâˆ’2,i) (8)
vD
t=Ë†â„“t+atâˆ’1
atÂ·n
bX
jâˆˆBJt(â„“j(wt)âˆ’Ë†â„“tâˆ’1,j)ej (9)
As for the tables of approximations, we update them on each iteration without suffering the
O(nd)computational cost of querying every first-order oracle (â„“1,âˆ‡â„“1), . . . , (â„“n,âˆ‡â„“n). We set
(Ë†â„“0,Ë†q0,Ë†g0) = ( â„“(w0), q0,âˆ‡â„“(w0)), and for iteration tâ‰¥1update block Kt:= (n/b) mod t+ 1
via
(Ë†â„“t,k,Ë†qt,k,Ë†gt,k) =(
(â„“k(wt), qt,k,âˆ‡â„“k(wt)) ifkâˆˆBKt
(Ë†â„“tâˆ’1,k,Ë†qtâˆ’1,k,Ë†gtâˆ’1,k) ifk /âˆˆBKt
While qtin particular is always known by the algorithm, we use the approximation Ë†qtwhich is pos-
sibly dual infeasible for every tâ‰¥1, but will approach qtastgrows large. Using this approximation
is essential to controlling the per-iteration time complexity, as described below. In addition, the de-
sign of (8) and (9) is grounded in the long line of work on incremental methods (both deterministic
and randomized). The table of past gradients updated cyclically resembles IAG [Blatt et al., 2007],
whereas the randomized component resembles methods such as SAGA [Defazio et al., 2014] and
stochastic PDHG [Chambolle et al., 2018]. The full algorithm description is given in Algorithm 1.
In the next section, we show that (at, Ct, ct)tâ‰¥0can be determined by a single hyperparameter.
Computational Complexity We also discuss the per-iteration time complexity and the global space
complexity of Algorithm 1, whereas the number of required iterations for Îµ-suboptimality is given
in the next section. We see that the per-iteration time complexity is O(n+bd), as we query b
first-order oracles in both the primal and dual updates and all other operations occur on n-length
ord-length vectors. While we need to employ O(nd)operations to compute Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1in (8) when
t= 1, this quantity can be maintained with O(bd)operations in every subsequent iteration as only
brows of Ë†qtandË†gtare editted in each iteration. For space complexity, we may consider storing
the entire gradient table Ë†gtin memory, resulting in an O(nd)complexity. However, due to our
time complexity calculation, we may reduce the space complexity to O(n+bd)by storing only
wtâˆ’1, . . . , w tâˆ’n/band recomputing the relevant values of Ë†gtin (8) in every iteration. Therefore, the
use of block-cyclic updates in the historical tables may significantly reduce the space complexity as
compared to randomized updates (as in Defazio et al. [2014]).
3 Theoretical Analysis
We provide the theoretical convergence rate and global complexity of DRAGO along with technical
highlights of the proof which may be of independent interest.
Convergence Analysis We measure suboptimality using the primal-dual gap :
Î³t:=L(wt, qâ‹†)âˆ’ L(wâ‹†, qt)âˆ’Âµ
2âˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’Î½
2âˆ¥qtâˆ’qâ‹†âˆ¥2
2,
where the saddle point (wâ‹†, qâ‹†)exists under Asm. 1. Note that Î³tâ‰¥0, as it is the sum of non-
negative quantities
L(wt, qâ‹†)âˆ’ L(wâ‹†, qâ‹†)âˆ’Âµ
2âˆ¥wtâˆ’wâ‹†âˆ¥2
2â‰¥0andL(wâ‹†, qâ‹†)âˆ’ L(wâ‹†, qt)âˆ’Î½
2âˆ¥qtâˆ’qâ‹†âˆ¥2
2â‰¥0.
To state the main result, define Etas the conditional expectation over (It, Jt)given (wtâˆ’1, qtâˆ’1)and
E1as the marginal expectation over the optimization trajectory. Consider the following assumptions.
5Algorithm 1 D istributionally Robust Annular Gradient Optimizer ( DRAGO )
Input: Sequence of constants (at, Ct, ct)tâ‰¥0, block size bâˆˆ {1, . . . , n }, number of iterations T.
Initialize w0= 0d,q0=1/n,Ë†â„“0=â„“(w0),Ë†g0=âˆ‡â„“(w0), and Ë†q0=q0.
fort= 1toTdo
Sample blocks ItandJtuniformly on [n/b], and define Kt=tmod ( n/b) + 1 .
Primal Update:
SetvP
tâˆ’1= Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1+atâˆ’1n
atbP
iâˆˆBIt(qtâˆ’1,iâˆ‡â„“i(wtâˆ’1)âˆ’Ë†qtâˆ’2,iË†gtâˆ’2,i), update wtusing (5).
Update table (Ë†â„“t,k,Ë†gt,k)to(â„“k(wt),âˆ‡â„“k(wt))ifkâˆˆBKtor(Ë†â„“tâˆ’1,k,Ë†gtâˆ’1,k)ifk /âˆˆBKt.
Dual Update:
SetvD
t=Ë†â„“t+atâˆ’1n
atbP
jâˆˆBJt(â„“j(wt)âˆ’Ë†â„“tâˆ’1,j)ej, update qtusing (7).
Update table Ë†qt,ktoqt,kifkâˆˆBKtorË†qtâˆ’1,kifk /âˆˆBKt.
end for
return (wT, qT).
Assumption 1. Letâ„“1, . . . , â„“ nbeG-Lipschitz continuous and L-smooth, in that for all iâˆˆ[n],
âˆ¥â„“i(w)âˆ’â„“i(wâ€²)âˆ¥2â‰¤Gâˆ¥wâˆ’wâ€²âˆ¥2andâˆ¥âˆ‡â„“i(w)âˆ’ âˆ‡â„“i(wâ€²)âˆ¥2â‰¤Lâˆ¥wâˆ’wâ€²âˆ¥2,
i.e., each â„“iisG-Lipschitz continuous and L-smooth with respect to âˆ¥Â·âˆ¥2. Let Âµ > 0andÎ½ >0,
and let q7â†’D(qâˆ¥1n/n)be1-strongly convex with respect to âˆ¥Â·âˆ¥2. Finally, Qis closed, convex, and
contains 1/n.
Regarding Asm. 1, an example of a loss function satisfying both Lipschitzness and smoothness
is given by the Huber loss used in robust statistics [Huber, 1981]. Another setting in which both
assumptions are satisfied is when the domain Wis compact, as smoothness will imply Lipschitz
continuity. Compactness is a common assumption when pursuing statistical guarantees such as
uniform convergence. As for the assumption of strong convexity, we describe modifications of the
algorithm when Âµ= 0orÎ½= 0in Appx. C.4 along with corresponding changes in the analysis.
Theorem 2. For a constant Î± >0, define the sequence
a1= 1, a2= 4Î±,andat= (1 + Î±)atâˆ’1fort >2,
along with its partial sum At=Pt
Ï„=1aÏ„. Under Asm. 1, there is an absolute constant Csuch that
using the parameter
Î±=Cminb
n,Âµ
LÎºQ,b
nrÂµÎ½
nG2
,
the iterates of Algorithm 1 satisfy:
TX
t=1atE1[Î³t] +ATÂµ
4E1âˆ¥wTâˆ’wâ‹†âˆ¥2
2+ATÎ½
4E1âˆ¥qTâˆ’qâ‹†âˆ¥2
2â‰¤nG2
Î½âˆ¥w0âˆ’w1âˆ¥2
2.
We can compute a point (wT, qT)achieving an expected gap no more than Îµwith big- Ocomplexity
(n+bd)Â· 
n
b+LÎºQ
Âµ+n
bs
nG2
ÂµÎ½!
Â·ln1
Îµ
. (10)
By dividing the result of Thm. 2 by AT, we see that both the expected gap and expected distance-
to-optimum in the primal and dual sequences decay geometrically in T. By plugging in b=n/dwe
get the following runtime for Algorithm 1:
O 
nd+ndLÎº Q
Âµ+n3/2ds
G2
ÂµÎ½!
ln1
Îµ
. (11)
6Note in particular the individual dependence on the condition numbers L/Âµ andnG2/(ÂµÎ½), as
opposed to the max-over-min-type condition numbers such as those achievable by generic primal-
dual or variational inequality methods (see Appx. B.3). The proof of Thm. 2 is provided in Appx. C,
along with a high-level overview in Appx. C.1. Our analysis relies on controlling atÎ³tby bounding
atL(wâ‹†, qt)above and bounding atL(wt, qâ‹†)below. Key technical steps occur in the lower bound.
We first apply that w7â†’atqâŠ¤
tâ„“(w)is convex to produce a linear underestimator of the function
supported at wt, and use that wtis the minimizer of a strongly convex function, so
atL(wâ‹†, qt)â‰¥atqâŠ¤
tâ„“(wt) +telescoping and non-positive terms
+at
âˆ‡â„“(wt)âŠ¤qtâˆ’vP
t, wâ‹†âˆ’wt
(12)
+ctÂµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2(13)
Note that the terms above will be negated when combining the upper and lower bounds. The labeled
terms are highly relevant in the analysis, with the second being non-standard. By expanding the
definition of vP
tand adding and subtracting wtâˆ’1, we write
at
âˆ‡â„“(wt)âŠ¤qtâˆ’vP
t, wâ‹†âˆ’wt
=at
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
âˆ’natâˆ’1
b(1 +Î·)X
iâˆˆItâŸ¨âˆ‡â„“i(wtâˆ’1)qtâˆ’1âˆ’Ë†gtâˆ’2,iË†qtâˆ’2,i, wâ‹†âˆ’wtâˆ’1âŸ©
âˆ’natâˆ’1
b(1 +Î·)X
iâˆˆItâŸ¨âˆ‡â„“i(wtâˆ’1)qtâˆ’1âˆ’Ë†gtâˆ’2,iË†qtâˆ’2,i, wtâˆ’1âˆ’wtâŸ©.
When choosing the learning rate Î·correctly, the first two terms will telescope in expecta-
tion (see Lem. 11). The third term, after applying Youngâ€™s inequality, requires controlling
1
bP
iâˆˆItâˆ¥âˆ‡â„“i(wtâˆ’1)qtâˆ’1âˆ’Ë†gtâˆ’2,iË†qtâˆ’2,iâˆ¥2
2in expectation, which we dub the â€œprimal noise boundâ€
(Lem. 5). When we combine the upper and lower bounds, we get a similar inner prod-
uct term at
qâ‹†âˆ’qt, â„“(wt)âˆ’vD
t
, and mirroring the arguments above, we encounter the term
1
bP
jâˆˆJt(â„“j(wt)âˆ’Ë†â„“tâˆ’1,j)2
2which also requires a â€œdual noise boundâ€ (Lem. 6). Without loss of
generality, assume that the blocks are ordered such that
Ë†â„“tâˆ’1,i=â„“i(wtâˆ’1âˆ’Kâˆ¨0)foriâˆˆBK. (14)
By computing the conditional expectation Et[Â·] :=E[Â·|wtâˆ’1], we have that
Etï£®
ï£°1
bX
jâˆˆJt(â„“j(wt)âˆ’Ë†â„“tâˆ’1,j)2
2ï£¹
ï£»=1
nnX
i=1(â„“i(wt)âˆ’Ë†â„“tâˆ’1,i)2
2
=1
nn/bX
K=1X
iâˆˆBK(â„“i(wt)âˆ’â„“i(wtâˆ’1âˆ’Kâˆ¨0))2
2
â‰¤G2b
ntâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’1âˆ’wÏ„âˆ¨0âˆ¥2
2,
where the second line follows from (14) and the third from G-Lipschitzness. This will telescope
with the second term introduced in (13), showing the importance of the regularization. The argument
follows similarly even when (14) does not hold, as the blocks can simply be â€œrenamedâ€ to achieve
the final bound. While the proof is technical, this core idea guides the analysis and the algorithm
design.
4 Experiments
In this section, we provide numerical benchmarks to measure DRAGO against baselines in terms
of evaluations of each component {(â„“i,âˆ‡â„“i)}n
i=1and wall clock time. We consider regression and
classification tasks. Letting (xi, yi)denote a feature-label pair, we have that each â„“irepresents the
70 50000 10000010âˆ’610âˆ’3100Suboptimality
yacht
0 50000 10000010âˆ’710âˆ’410âˆ’1
energy
0 50000 10000010âˆ’610âˆ’3100
concrete
0 1 210âˆ’610âˆ’3100
yacht
0 1 210âˆ’610âˆ’3100
energy
0 1 210âˆ’610âˆ’3100
concrete
0 50000 100000
First-Order Oracle Evaluations10âˆ’410âˆ’2100Suboptimality
acsincome
0 50000 100000
First-Order Oracle Evaluations10âˆ’610âˆ’3100
kin8nm
0 50000 100000
First-Order Oracle Evaluations10âˆ’710âˆ’410âˆ’1
power
0 5
Wall-Clock Time (Seconds)10âˆ’410âˆ’2100
acsincome
0 5
Wall-Clock Time (Seconds)10âˆ’610âˆ’3100
kin8nm
0 5
Wall-Clock Time (Seconds)10âˆ’710âˆ’410âˆ’1
power
SGD LSVRG Drago (b= 16 ) Drago (b=n/d) Drago (b= 1)Figure 2: Regression Benchmarks. In both panels, the y-axis measures the primal suboptimality
gap (15). Individual plots correspond to particular datasets. Left: Thex-axis displays the number of
individual first-order oracle queries to {(â„“i,âˆ‡â„“i)}n
i=1.Right: Thex-axis displays wall-clock time.
squared error loss or multinomial cross-entropy loss, given by
â„“i(w) :=1
2 
yiâˆ’xâŠ¤
iw2andâ„“i(w) :=âˆ’xâŠ¤
iwyi+ logX
yâˆˆYexp 
xâŠ¤
iwy
,
respectively. In the latter case, we denote w= (w1, . . . , w C)âˆˆRCÃ—d, indicating multiclass clas-
sification with label set Y:={1, . . . , C }. We show results for the conditional value-at-risk (CVaR)
[Rockafellar and Royset, 2013] in this section, exploring the effect of sample size n, dimensionality
d, and regularization parameter Î½on optimization performance. The parameter Î½in particular has
interpretations both as a conditioning device (as it is inversely related to the smoothness constant of
w7â†’max qâˆˆQL(w, q)and as a robustness parameter, as it controls the essential size of the uncer-
tainty set. Detailed experimental settings are contained in Appx. E, including additional experiments
with the Ï‡2-divergence ball uncertainty set. The code to reproduce these experiments can be found
at https://github.com/ronakdm/drago.
We compare against baselines that can be used on the CVaR uncertainty set: distributionally robust
stochastic gradient descent (SGD) [Levy et al., 2020] and LSVRG [Mehta et al., 2023]. For SGD,
we use a batch size of 64 and for LSVRG we use the default epoch length of n. For DRAGO , we
investigate the variants in which bis set to 1andb=n/da priori, as well as cases when bis a tuned
hyperparameter. On the y-axis, we plot the primal gap
max qâˆˆQL(wt, q)âˆ’ L(wâ‹†, qâ‹†)
max qâˆˆQL(w0, q)âˆ’ L(wâ‹†, qâ‹†), (15)
where we approximate L(wâ‹†, qâ‹†)by running LBFGS [Nocedal and Wright, 1999] on the primal
objective until convergence. On the x-axis, we display either the exact number of calls to the first-
order oracles of the form (â„“i,âˆ‡â„“i)or the wall clock time in seconds. We fix Âµ= 1 but vary Î½to
study its role as a conditioning parameter, which is especially important as prior work establishes
different convergence rates for different values of Î½(see Tab. 1).
4.1 Regression with Large Block Sizes
In this experiment, we consider six regression datasets, named yacht ( n= 244 , d= 6) [Tsanas and
Xifara, 2012], energy ( n= 614 , d= 8) [Baressi Segota et al., 2020], concrete ( n= 824 , d= 8)
[Yeh, 2006], acsincome ( n= 4000 , d= 202 ) [Ding et al., 2021], kin8nm ( n= 6553 , d= 8)
[Akujuobi and Zhang, 2017], and power ( n= 7654 , d= 4) [TÂ¨ufekci, 2014]. In each case, there is a
univariate, real-valued output. Notice that most datasets, besides acsincome, are low-dimensional as
compared to their sample size. Thus, the default block size n/d becomes relatively large, imposing
an expensive per-iteration cost in terms of oracle queries. However, when the block size is high,
the stochastic gradient estimates in each iteration have lower variance and the table components are
updated more frequently, which could improve convergence in principle. The main question of this
80 100 200 300
First-Order Oracle Evaluations (K)10âˆ’510âˆ’310âˆ’1Suboptimality
Î½=1.0
0 100 200 300
First-Order Oracle Evaluations (K)10âˆ’510âˆ’310âˆ’1
Î½=0.01
0 100 200 300
First-Order Oracle Evaluations (K)10âˆ’510âˆ’310âˆ’1
Î½=0.001
0 2 4
Wall-Clock Time (Seconds)10âˆ’210âˆ’1100
Î½=1.0
0 2 4
Wall-Clock Time (Seconds)10âˆ’310âˆ’210âˆ’1100
Î½=0.01
0 2 4
Wall-Clock Time (Seconds)10âˆ’410âˆ’310âˆ’210âˆ’1100
Î½=0.001Figure 3: Text Classification Benchmarks. In all plots, the y-axis measures the normalized primal
(i.e., DRO risk) suboptimality gap, defined in (15). Columns represent a varying dual regularization
parameter Î½. On the first three columns the x-axis measures the number of individual first-order
oracle queries to {(â„“i,âˆ‡â„“i)}n
i=1and the remaining three the x-axis displays wall-clock time. The
objective becomes ill-conditioned as Î½decreases.
section is whether DRAGO efficiently manages this trade-off via the block size parameter b. Results
for gradient evaluations and wall clock time are on the left and right panels of Fig. 2, respectively.
Results The DRAGO variant for b=n/dis not included on the left plot, as the number of queries (al-
most 2,000 in the case of power) penalizes its performance heavily. Still, the same variant performs
best or near best on all datasets in terms of wall clock time (right plot). Thus, if the computation
of the queries is inexpensive enough, DRAGO can achieve the lowest suboptimality within a fixed
time budget. This is most striking in the case of kin8nm, in which DRAGO achieves 10âˆ’7primal
gap within 1 second, versus LSVRG which is only able to reach within 10âˆ’2of the minimum in
the same amount of time. We also experiment with tuning bto reach a balance between the cost
of queries and distance to optimum in the left plot with the b= 16 variant. In the datasets with
nâ‰¤1,000,DRAGO can match the performance of baselines with only b= 1, whereas in the larger
datasets, a batch size of 16is needed to be comparable.
4.2 Text Classification Under Ill-Conditioning
We consider a natural language processing example using the emotion dataset [Saravia et al., 2018],
which is a classification task consisting of six sentiment categories: sadness, anger, love, fear, joy,
and surprise. To featurize the text, we fine-tune a pre-trained BERT network [Devlin et al., 2019]
on a held-out set of 8,000 training examples to learn a vectorial representation. We then use a
disjoint subset of 8,000 training points and apply PCA to reduce them to 45-dimensional vectors.
Because of the six classes this results in d= 270 parameters to learn. To study the effect of
dual regularization, we consider Î½âˆˆ {1.0,0.01,0.001}. As Î½decreases, the dual solution may
shift further from uniformity, and potentially increase the distributional robustness of the learned
minimizer. However, the objective can also become poorly conditioned, introducing a key trade-off
between optimization and statistical considerations when selecting Î½. The results are in Fig. 3.
Results The run time required for LSVRG to make 500K gradient evaluations is too large to be
considered. We also observe that LSVRG is vulnerable to ill-conditioned objectives, as it is out-
performed by SGD for smaller values of Î½in terms of wall clock time. Within 4 seconds, DRAGO
can achieve close to a 10âˆ’5primal suboptimality gap while the gaps of SGD and LSVRG are 2 to
3 orders of magnitude larger in the same amount of time. We hypothesize that because the dual
variables in LSVRG are updated once every niterations, the primal gradient estimates may accrue
excessive bias. DRAGO withb=n/d, making âˆ¼30individual first-order queries per iteration, is
performant in terms of oracle queries and wall clock time even as Î½drops by 3 orders of magnitude.
5 Conclusion
We proposed DRAGO , a stochastic primal-dual algorithm for solving a host of distributionally robust
optimization (DRO) problems. The method achieves linear convergence without placing conditions
on the dual regularizer, and its empirical performance remains strong across varying settings of the
sample size n, dimension d, and the dual regularization parameter Î½. The method combines ideas of
variance reduction, minibatching, and cyclic coordinate-style updates even though the dual feasible
set (a.k.a. the uncertainty set) is non-separable. Opportunities for future work include extensions to
non-convex settings and applications to min-max problems beyond distributional robustness, such
as missing data imputation and fully composite optimization.
9Acknowledgements This work was supported by NSF DMS-2023166, CCF-2019844, DMS-
2134012, NIH, IARPA 2022-22072200003, U. S. Office of Naval Research under award number
N00014-22-1-2348. Part of this work was done while R. Mehta and Z. Harchaoui were visiting the
Simons Institute for the Theory of Computing.
Broader Impact Distributionally robust optimization (DRO) within machine learning is heavily
motivated by problems in artificial intelligence (AI) safety, such as mitigating catastrophic perfor-
mance of models on minority groups or end-users. While this work is focused on theoretical and
algorithmic aspects of the problem, we intend to increase accessibility and scalability for down-
stream applications as well.
References
U. Akujuobi and X. Zhang. Delve: A Dataset-Driven Scholarly Search and Analysis System.
SIGKDD Explor. Newsl. , 19, 2017.
A. Alacaoglu and Y . Malitsky. Stochastic variance reduction for variational inequality methods. In
Conference on Learning Theory , pages 778â€“816. PMLR, 2022.
A. Alacaoglu, V . Cevher, and S. J. Wright. On the complexity of a practical primal-dual coordinate
method. arXiv preprint arXiv:2201.07684 , 2022.
S. Baressi Segota, N. Andelic, J. Kudlacek, and R. Cep. Artificial Neural Network for Predict-
ing Values of Residuary Resistance per Unit Weight of Displacement. Journal of Maritime &
Transportation Science , 57, 2020.
J. Blanchet, Y . Kang, and K. Murthy. Robust Wasserstein Profile Inference and Applications to
Machine Learning. Journal of Applied Probability , 56, 2019.
D. Blatt, A. O. Hero, and H. Gauchman. A Convergent Incremental Gradient Method with a Con-
stant Step Size. SIAM Journal on Optimization , 2007.
X. Cai, C. Song, S. Wright, and J. Diakonikolas. Cyclic Block Coordinate Descent With Variance
Reduction for Composite Nonconvex Optimization. In ICML , 2023.
X. Cai, A. Alacaoglu, and J. Diakonikolas. Variance reduced Halpern iteration for finite-sum mono-
tone inclusions. In ICLR , 2024.
Y . Carmon and D. Hausler. Distributionally Robust Optimization via Ball Oracle Acceleration. In
NeurIPS , 2022.
A. Chambolle, M. J. Ehrhardt, P. Richt Â´arik, and C.-B. Schonlieb. Stochastic Primal-Dual Hybrid
Gradient Algorithm with Arbitrary Sampling and Imaging Applications. SIAM Journal on Opti-
mization , 28(4):2783â€“2808, 2018.
L. Condat. Fast projection onto the simplex and the â„“1-ball. Mathematical Programming , 2016.
A. Defazio, F. Bach, and S. Lacoste-Julien. SAGA: A Fast Incremental Gradient Method With
Support for Non-Strongly Convex Composite Objectives. NeurIPS , 27, 2014.
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional trans-
formers for language understanding. In Proceedings of the 2019 Conference of the North Amer-
ican Chapter of the Association for Computational Linguistics: Human Language Technologies ,
2019.
F. Ding, M. Hardt, J. Miller, and L. Schmidt. Retiring Adult: New Datasets for Fair Machine
Learning. In NeurIPS , volume 34. Curran Associates, Inc., 2021.
S. S. Du, G. Gidel, M. I. Jordan, and C. J. Li. Optimal Extragradient-Based Bilinearly-Coupled
Saddle-Point Optimization, 2022.
N. He, Z. Harchaoui, Y . Wang, and L. Song. Point Process Estimation with Mirror Prox Algorithms.
Applied Mathematics & Optimization , 2020.
10P. J. Huber. Robust statistics . Wiley New York, 1981.
R. Johnson and T. Zhang. Accelerating Stochastic Gradient Descent using Predictive Variance Re-
duction. In NeurIPS , volume 26, 2013.
N. Kallus, X. Mao, K. Wang, and Z. Zhou. Doubly Robust Distributionally Robust Off-Policy
Evaluation and Learning. In ICML , 2022.
D. Kovalev, A. Gasnikov, and P. Richt Â´arik. Accelerated Primal-Dual Gradient Method for Smooth
and Convex-Concave Saddle-Point Problems with Bilinear Coupling. In NeurIPS , 2022.
D. Kuhn, P. M. Esfahani, V . A. Nguyen, and S. Shafieezadeh-Abadeh. Wasserstein Distributionally
Robust optimization: Theory and Applications in Machine Learning. Operations research &
management science in the age of analytics , 2019.
R. Kumar, K. A. Majmundar, D. M. Nagaraj, and A. Suggala. Stochastic Re-weighted Gradient
Descent via Distributionally Robust Optimization. TMLR , 2024.
D. Levy, Y . Carmon, J. Duchi, and A. Sidford. Large-Scale Methods for Distributionally Robust
Optimization. In NeurIPS , 2020.
C. J. Li, A. Yuan, G. Gidel, Q. Gu, and M. I. Jordan. Nesterov meets optimism: rate-optimal
separable minimax optimization. In ICML , 2023.
T. Lin, C. Jin, and M. I. Jordan. Near-Optimal Algorithms for Minimax Optimization. In COLT ,
2020.
E. Z. Liu, B. Haghgoo, A. S. Chen, A. Raghunathan, P. W. Koh, S. Sagawa, P. Liang, and C. Finn.
Just Train Twice: Improving Group Robustness without Training Group Information. In ICML ,
2021.
Z. Liu, Q. Bai, J. Blanchet, P. Dong, W. Xu, Z. Zhou, and Z. Zhou. Distributionally Robust Q-
Learning. In ICML , 2022.
K. Lotidis, N. Bambos, J. Blanchet, and J. Li. Wasserstein Distributionally Robust Linear-Quadratic
Estimation under Martingale Constraints. In AISTATS , 2023.
R. Mehta, V . Roulet, K. Pillutla, L. Liu, and Z. Harchaoui. Stochastic Optimization for Spectral
Risk Measures. In AISTATS , 2023.
R. Mehta, V . Roulet, K. Pillutla, and Z. Harchaoui. Distributionally Robust Optimization with Bias
and Variance Reduction. In ICLR , 2024.
H. Namkoong and J. C. Duchi. Stochastic Gradient Methods for Distributionally Robust Optimiza-
tion with f-divergences. In NeurIPS , 2016.
H. Namkoong and J. C. Duchi. Variance-based Regularization with Convex Objectives. In NeurIPS ,
2017.
J. Nocedal and S. J. Wright. Numerical Optimization . Springer, 1999.
B. Palaniappan and F. Bach. Stochastic Variance Reduction Methods for Saddle-Point Problems.
NeurIPS , 29, 2016.
R. T. Rockafellar and J. O. Royset. Superquantiles and Their Applications to Risk, Random Vari-
ables, and Regression. In Theory Driven by Influential Applications . Informs, 2013.
H. Sapkota, D. Wang, Z. Tao, and Q. Yu. Distributionally Robust Ensemble of Lottery Tickets
Towards Calibrated Sparse Network Training. In NeurIPS , 2023.
E. Saravia, H.-C. T. Liu, Y .-H. Huang, J. Wu, and Y .-S. Chen. CARER: Contextualized Affect
Representations for Emotion Recognition. In EMNLP , 2018.
V . D. Sharma, M. Toubeh, L. Zhou, and P. Tokekar. Risk-Aware Planning and Assignment for
Ground Vehicles using Uncertain Perception from Aerial Vehicles. In 2020 IEEE/RSJ IROS ,
2020.
11C. Song, S. J. Wright, and J. Diakonikolas. Variance reduction via primal-dual accelerated dual
averaging for nonsmooth convex finite-sums. In ICML , 2021.
C. Song, C. Y . Lin, S. Wright, and J. Diakonikolas. Coordinate Linear Variance Reduction for
Generalized Linear Programming. In NeurIPS , 2022.
A. Tsanas and A. Xifara. Accurate Quantitative Estimation of Energy Performance of Residential
Buildings Using Statistical Machine Learning Tools. Energy and Buildings , 49, 2012.
P. TÂ¨ufekci. Prediction of Full Load Electrical Power Output of a Base Load Operated Combined
Cycle Power Plant using Machine Learning Methods. International Journal of Electrical Power
& Energy Systems , 60, 2014.
S. Wang, N. Si, J. Blanchet, and Z. Zhou. A Finite Sample Complexity Bound for Distributionally
Robust Q-learning. In AISTATS , 2023a.
Z. Wang, L. Shen, T. Liu, T. Duan, Y . Zhu, D. Zhan, D. Doermann, and M. Gao. Defending against
Data-Free Model Extraction by Distributionally Robust Defensive Training. In NeurIPS , 2023b.
O. Wiles, S. Gowal, F. Stimberg, S.-A. Rebuffi, I. Ktena, K. D. Dvijotham, and A. T. Cemgil. A
fine-grained analysis on distribution shift. In ICLR , 2022.
G. Xie, L. Luo, Y . Lian, and Z. Zhang. Lower Complexity Bounds for Finite-Sum Convex-Concave
Minimax Optimization Problems. In ICML , 2020.
J. Yang, S. Zhang, N. Kiyavash, and N. He. A Catalyst Framework for Minimax Optimization. In
NeurIPS , 2020.
Z. Yang, Y . Guo, P. Xu, A. Liu, and A. Anandkumar. Distributionally Robust Policy Gradient for
Offline Contextual Bandits. In AISTATS , 2023.
I. Yeh. Analysis of Strength of Concrete Using Design of Experiments and Neural Networks. Jour-
nal of Materials in Civil Engineering , 18, 2006.
Y . Yu, T. Lin, E. V . Mazumdar, and M. Jordan. Fast Distributionally Robust Learning with Variance-
Reduced Min-Max Optimization. In AISTATS , 2022.
Z. Yu, L. Dai, S. Xu, S. Gao, and C. P. Ho. Fast Bellman Updates for Wasserstein Distributionally
Robust MDPs. In NeurIPS , 2023.
J. Zhang, M. Hong, and S. Zhang. On lower iteration complexity bounds for the convex concave
saddle point problems. Mathematical Programming , 194, 2022.
12Appendix
Appx. A contains all notation introduced throughout the paper. Appx. B discusses convergence rate
comparisons in detail with contemporary work. The full convergence analysis of DRAGO is given
in Appx. C. A description of the algorithm amenable to implementation is given in Appx. D,
whereas experimental settings are described in detail within Appx. E.
Table of Contents
A Notation 14
B Comparisons to Existing Literature 15
B.1 Directly Using Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . 15
B.2 Distributionally Robust Optimization (DRO) . . . . . . . . . . . . . . . . . . . 15
B.3 Primal-Dual Saddle Point Algorithms . . . . . . . . . . . . . . . . . . . . . . . 17
C Convergence Analysis of DRAGO 21
C.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
C.2 Technical Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
C.3 Proof of Main Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
C.4 Modification for Unregularized Objectives . . . . . . . . . . . . . . . . . . . . 40
D Implementation Details 44
D.1 Algorithm Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
D.2 Solving the Maximization Problem . . . . . . . . . . . . . . . . . . . . . . . . 44
E Experimental Details 48
E.1 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
E.2 Hyperparameter Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
E.3 Compute Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
E.4 Additional Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
F NeurIPS Paper Checklist 51
13A Notation
Symbol Description
n Sample size, or number of loss functions.
d Dimensionality of primal variables.
W âŠ†RdPrimal feasible set, which is closed and convex.
Q âˆˆâˆ†nUncertainty set, or dual feasible set, which is closed and convex.
Here, âˆ†n={pâˆˆ[0,1]n:Pn
i=1pi= 1}.
q0 The uniform vector q0=1/n= (1/n, . . . , 1/n). Used as a dual initialization.
D(qâˆ¥q0)A statistical divergence between qâˆˆ Q andq0, which is
1-strongly convex in its first argument with respect to âˆ¥Â·âˆ¥2.
â„“Loss function â„“:W â†’ Rn, which is differentiable
in each component on an open set O âŠ†Rdsuch that W âŠ† O .
Âµâ‰¥0 Primal regularization constant.
Î½â‰¥0 Dual regularization constant.
L(w, q) Objective function L(w, q) :=qâŠ¤â„“(w)âˆ’Î½D(qâˆ¥q0) +Âµ
2âˆ¥wâˆ¥2
2.
(wâ‹†, qâ‹†)Saddle point of L, which satisfies
L(wâ‹†, q)â‰¤ L(wâ‹†, qâ‹†)â‰¤ L(w, qâ‹†)for all (w, q)âˆˆ W Ã— Q .
[n] Index set [n] ={1, . . . , n }.
qmax The value max qâˆˆQâˆ¥qâˆ¥âˆ.
ÎºQ The condition number ÎºQ=nqmaxâ‰¥1.
GLipschitz continuity constant of each â„“iforiâˆˆ[n],
for which |â„“i(w)âˆ’â„“i(wâ€²)| â‰¤Gâˆ¥wâˆ’wâ€²âˆ¥2.
LLipschitz continuity constant of each âˆ‡â„“iforiâˆˆ[n],
for which âˆ¥âˆ‡â„“i(w)âˆ’ âˆ‡â„“i(wâ€²)âˆ¥2â‰¤Lâˆ¥wâˆ’wâ€²âˆ¥2.
âˆ‡â„“(w) Jacobian matrix of â„“:Rdâ†’Rnatw(shape = nÃ—d).
(at) Sequence of positive constants that weigh the average gap criterion.
(At)Sequence of partial sums of (at), orAt=Pt
s=1as. The convergence
rate will be given by Aâˆ’1
t, so we have atincrease geometrically.
b Batch or block size.
M Number of blocks n/b.
(wt, qt)tâ‰¥0 Sequence of primal and dual iterates.
ej Thej-th standard basis vector ejâˆˆ {0,1}n.
Ë†â„“t Loss table, which approximates â„“(wt)âˆˆRn.
Ë†gt Gradient table, which approximates âˆ‡â„“(wt)âˆˆRnÃ—d.
Ë†qt Weight table, which approximates qtâˆˆ Q.
Et[Â·] Shorthand for E[Â·|Htâˆ’1], i.e., expectation conditioned on history Htâˆ’1=Ïƒ 
(Is, Js)}tâˆ’1
s=1
.
Table 2: Notation used throughout the paper.
14B Comparisons to Existing Literature
In this appendix, we compare our work to existing literature along two axes: 1) distributional robust
optimization (DRO), and 2) primal-dual algorithms for saddle-point problems. In the first cate-
gory, we are primarily concerned with questions of practical and statistical interest, such as which
uncertainty sets can be used, how the size of the uncertainty set affects the convergence rate, and
what assumptions are needed on the distribution of losses. In the second category, we discuss com-
putational complexity under various assumptions such as smoothness and strong convexity of the
objective.
B.1 Directly Using Gradient Descent
In the penalized case, we add that the objective w7â†’max qâˆˆQL(w, q)is(L+Âµ+nG2
Î½)-smooth
when the losses â„“iareG-Lipschitz continuous and L-smooth. For this reason, we may consider
simply applying full-batch gradient descent to this objective, which is included in our comparisons.
To see why this smoothness condition holds, define h(l) := max qâˆˆQ
qâŠ¤lâˆ’Î½D(qâˆ¥1/n)	
, so that
when q7â†’D(qâˆ¥1/n)is1-strongly convex with respect to âˆ¥Â·âˆ¥2
2, it holds that âˆ‡his(1/Î½)-Lipschitz
continuous with respect to âˆ¥Â·âˆ¥2
2, and that âˆ‡h(l)is non-negative and sums to one (i.e. is a probability
mass function on [n]). Then, by the chain rule, for any w1, w2âˆˆW, we have that
âˆ‡â„“(w1)âŠ¤âˆ‡h(â„“(w1))âˆ’ âˆ‡â„“(w2)âŠ¤âˆ‡h(â„“(w2))
2
â‰¤âˆ‡â„“(w1)âŠ¤(âˆ‡h(â„“(w1))âˆ’ âˆ‡h(â„“(w2)))
2+(âˆ‡â„“(w1)âˆ’ âˆ‡â„“(w2))âŠ¤âˆ‡h(â„“(w2))
2]
â‰¤nG
Î½âˆ¥â„“(w1)âˆ’â„“(w2)âˆ¥2+Lâˆ¥w1âˆ’w2âˆ¥2
â‰¤nG2
Î½+L
âˆ¥w1âˆ’w2âˆ¥2.
Thus, when referring to the gradient descent on w7â†’max qâˆˆQL(w, q) =h(â„“(w)) +Âµ
2âˆ¥wâˆ¥2
2, we
reference the smoothness constant
L+Âµ+nG2
Î½
.
B.2 Distributionally Robust Optimization (DRO)
Examples of DRO Problems Our problem
min
wâˆˆWmax
qâˆˆQh
L(w, q) :=qâŠ¤â„“(w)âˆ’Î½D(qâˆ¥1/n) +Âµ
2âˆ¥wâˆ¥2
2i
(16)
accommodates several settings of interest across machine learning. For example, f-DRO with pa-
rameter Ï[Namkoong and Duchi, 2016, Carmon and Hausler, 2022] results by defining the uncer-
tainty set and penalty as
Q=Q(Ï) :=n
q:Df(qâˆ¥1/n)â‰¤Ï
no
andD(qâˆ¥1/n) =Df(qâˆ¥1/n),
where Df(qâˆ¥p) =Pn
i=1pif(qi/pi)denotes an f-divergence generated by f(which is always
well-defined when pi=1/n). Common examples include the Kullback-Leibler (KL) divergence,
generated by fKL(x) =âˆ’xlogxand the Ï‡2-divergence generated by fÏ‡2(x) = ( xâˆ’1)2. Spectral
risk measures [Mehta et al., 2023] are parametrized by an n-length vector Ïƒ= (Ïƒ1, . . . , Ïƒ n)such
that0â‰¤Ïƒ1â‰¤. . .â‰¤ÏƒnandPn
i=1Ïƒi= 1. The penalty in that setting may also be in the form of an
f-divergence [Mehta et al., 2024], so that
Q=Q(Ïƒ) := conv ( {permutations of Ïƒ)})andD(qâˆ¥1/n) =Df(qâˆ¥1/n),
where conv (Â·)denotes the convex hull. The most notable example of such an uncertainty set is the
Î¸-conditional value-at-risk, or CVaR [Rockafellar and Royset, 2013], wherein the largest Î¸nvalues
ofÏƒare set to 1/(nÎ¸)and the remaining are set to zero (with a fractional component if Î¸nis not an
integer). Finally, Wasserstein-DRO [Kuhn et al., 2019, Blanchet et al., 2019, Yu et al., 2022] with
parameter Î´typically sets the uncertainty set to be a Î´-ball{Q:Wc(Q, P n)â‰¤Î´}in Wasserstein
distance, where Qis a probability measure, Pnis the empirical measure of the training data, and
15Wcis the Wasserstein distance associated to cost function c. This differs from f-DRO and spectral
risk minimization because in the latter settings, the â€œshiftedâ€ distribution Qis assumed to remain on
the same natoms as before, so that it may simply be specified by a probability vector qâˆˆ[0,1]n
(resp. Pnby1/n). However, as shown by Yu et al. [2022], Wasserstein-DRO can be reformulated
into a problem of the form (16) if the following conditions are satisfied: 1) the loss is of a generalized
linear model â„“i(w) = Î¨( âŸ¨w, xiâŸ©, yi)with feature-label pair (xi, yi)and discrepancy function Î¨, 2)
the cost function c((x, y),(xâ€², yâ€²))is of the form âˆ¥xâˆ’xâ€²âˆ¥2+Î²|yâˆ’yâ€²|forÎ² > 0, and 3) the
function Î¨is Lipschitz continuous with known constant.
Comparison of DRO Approaches The performance of classical and recent algorithms designed
for the problems above is detailed in Tab. 3. The rightmost column displays the oracle complexity ,
meaning the number of queries to individual/component loss functions {(â„“i,âˆ‡â„“i)}as a function of
the desired suboptimality Îµ. The desiderata in the large-scale setting is to decouple the contribution
of the sample size nand the condition number in smooth, strongly convex settings ( Âµ > 0and
L <âˆ) or the quantity 1/Îµin non-smooth or non-strongly convex settings. For readability, we
encode dependence on nin red and dependence on 1/Îµin blue within Tab. 3. In certain cases, such
as in the sub-gradient method, the dependence on nis understood as part of a smoothness constant.
Similarly, because qmax is of order 1/nin the best case and 1in the worst case, we interpret ÎºQto
play the role of a condition number that measures the size of the uncertainty set. That being said, ÎºQ
is upper bounded by a constant independent of nin common cases. We collect examples of these
results below.
Proposition 3. In(16) ifQis chosen to be the CVaR uncertainty set with tail probability Î¸, then
ÎºQâ‰¤1
Î¸. IfQis chosen to be the Ï‡2-DRO uncertainty set with radius Ï, then ÎºQâ‰¤âˆš1 +Ï.
Proof. For the Î¸-CV AR, we have that qiâˆˆ[0,1/(nÎ¸)]for all iâˆˆ[n]. Thus,
nqiâ‰¤1
Î¸for all i= 1, . . . , n.
For the Ï‡2-DRO uncertainty set, we have by direct computation that
nâˆ¥qâˆ’1/nâˆ¥2
2â‰¤Ï
nâ‡â‡’ âˆ¥ qâˆ¥2
2â‰¤1 +Ï
n2.
This implies that for any iâˆˆ[n], we have that q2
iâ‰¤(1 +Ï)/n2which implies that
nqiâ‰¤p
1 +Ï,
the result as desired.
The closest comparison to our setting is that of LSVRG [Mehta et al., 2023] and Prospect [Mehta
et al., 2024]. Including DRAGO , these methods all achieve linear convergence on (16), under the
assumption of strongly convex regularization in the primal objective. However, both LSVRG and
Prospect demand a stringent lower bound of â„¦(nG2/Âµ)on the dual regularization parameter Î½to
achieve this rate, which essentially matches ours in this regime (asp
nG2/(ÂµÎ½)reduces to a con-
stant). When this condition does not hold, however, LSVRG does not have a convergence guarantee
while Prospect underperforms against the sub-gradient method. Furthermore, while Propsect has a
single hyperparameter, LSVRG must search over both a learning rate and an epoch length. DRAGO ,
on the other hand, is the only method that achieves unconditional linear convergence and fully cap-
tures the dependence on the dual regularization parameter Î½, which is a smoothness measure of the
objective max qL(Â·, q).
Moving to methods that are not linearly convergent, Levy et al. [2020] consider a variant of mini-
batch SGD that solves the maximization problem within the mini-batch itself. In Tab. 3, we include
a term min{n, b(Îµ)}, where b(Îµ)denotes a required batch size. This is because Levy et al. [2020]
measures complexities in terms of calls to first-order oracles for a loss summed across an arbitrary
batch size. Thus, our comparison relies on multiplying the required batch size with the number of
iterations required for a desired suboptimality (see Levy et al. [2020, Theorem 2], for example).
In the setting in which there is a fixed training set of size n, we incorporate this requirement on
the batch size in the complexity bound, to account for the case in which the theoretically required
batch size grows so large that it exceeds the full batch size itself. Indeed, as commented by Carmon
16and Hausler [2022], when the uncertainty set is large (i.e. Î¸is small for CVaR and Ïis large for
Ï‡2-divergence), the method may underperform against the sub-gradient method. This is true of
methods such as in Mehta et al. [2024] and ours that depend on ÎºQâ‰¤n. This indicates that across
DRO settings, increased uncertainty set sizes can bring the performance of incremental methods
arbitrarily close to that of the full-batch sub-gradient method. Finally, notice that DRAGO also has a
dependence on the batch size bin Tab. 3. While it would appear that b= 1would minimize oracle
complexity, we describe in the next section how bcan be chosen to minimize global complexity,
which includes the cost of each oracle call as a function of the primal dimension d. Because of
the diversity of settings, a coarser measure such as first-order oracle evaluations may be sufficient
to compare methods along the DRO axis; we use the finer-grained global complexity to compare
methods along the axis of saddle-point algorithms.
B.3 Primal-Dual Saddle Point Algorithms
For context, both (1) and (2) are coupled min-max problems with primal-dual variables (w, q). Ob-
serve that the coupled term in the objective (depending on both wandq) is not bilinear in general.
Such objectives have received much less attention in the optimization literature on primal-dual meth-
ods than their bilinearly-coupled counterparts. For the bilinear setting, methods such as stochastic
Chambolle-Pock-style algorithms [He et al., 2020, Song et al., 2021] use stochastic variance-reduced
updates, and in particular, employ coordinate-style updates of a single dual variable per iteration.
To illustrate the advantage of these updates, notice that the primal and dual dimensions are dandn,
respectively. When nis significantly larger than d, and assuming that each (â„“i,âˆ‡â„“i)call comes at
anO(d)cost, updating the dual variables at O(n)cost every iteration becomes the primary compu-
tational bottleneck. Coordinate-style updates can eliminate this dependence, but apply only when
the dual feasible set Qdecomposes as Q1Ã—. . .Ã— Q n, i.e., is separable .
There is a long line of work on variance-reduced algorithms for general stochastic optimization
problems [Johnson and Zhang, 2013, Defazio et al., 2014, Palaniappan and Bach, 2016, Cai et al.,
2023] and structured and/or bilinearly coupled min-max problems [Yang et al., 2020, Song et al.,
2021, Du et al., 2022, Kovalev et al., 2022, Alacaoglu et al., 2022]. However, few of these results
directly apply to (2) due to non-bilinearity and non-separability of the dual feasible set. These issues
motivated work on reformulating common DRO problems as bilinearly coupled min-max problems
in Song et al. [2022]. However, the guarantees obtained in Song et al. [2022] are of the order O(Îµâˆ’1).
Another viewpoint is that (2) can be written as a monotone variational inequality (VI) problem for
the operator F(w, q) = (âˆ‡wâ„“(w)âŠ¤q+Âµw,âˆ’â„“(w) +Î½âˆ‡qD(qâˆ¥1/n))âˆˆRd+n, where we assumed
1-smoothness of Dfor ease of presentation. Under our assumptions, this operator is min{Âµ, Î½}-
strongly monotone and max
nG2, L	
-Lipschitz continuous, and VI algorithms such as mirror-
prox, Popovâ€™s method, and variance-reduced methods like Alacaoglu and Malitsky [2022], Cai et al.
[2024] can be used. However, the max-over-min dependence on the individual Lipschitz constants
and strong convexity constants is unfavorable compared to the individual condition numbers ob-
served in (4). If Fis called directly, the global complexity will be n2because qisn-dimensional
along with nin the condition number. A finite sum approach could improve dependence on the
number of oracle calls, but the global complexity would still be n2due to the non-separability of the
dual feasible set and again the n-dimensional dual variables.
To summarize the points above and in order to make comparisons among methods for general min-
max problems, we first collect aspects of (16) that make it a highly specialized problem in this
regard. The major points include:
1. The objective has a finite-sum structure, in that it can be written asPn
i=1fi(w, q), where
fi(w, q) :=qiâ„“i(w)âˆ’Î½D(qâˆ¥1/n) +Âµ
2âˆ¥wâˆ¥2
2.
2. The dimension of the dual variable qis equal to n, the number of functions in the sum
(i.e. the sample size), and could be much larger than d.
3. The dual regularizer q7â†’D(qâˆ¥1/n)is not necessarily smooth. This encompasses common
statistical divergences such as the Kullback Leibler (KL).
4. The dual feasible set Qis non-separable, as any feasible dual iterate must sum to 1.
For discussions in which linear convergence is a pre-requisite, it is typically assumed that (w, q)7â†’
L(w, q)is a smooth map, and finer-grained results depend on the individual Lipschitz continuity
17parameters of w7â†’ âˆ‡ wL(w, q),q7â†’ âˆ‡ qL(w, q),w7â†’ âˆ‡ qL(w, q), and q7â†’ âˆ‡ wL(w, q). To make
the regularized DRO setting of (16) comparable to classical and contemporary saddle-point methods,
we make the additional assumption in this section that the (rescaled) Ï‡2-divergence penalty is used,
so that D(qâˆ¥1/n) =1
2âˆ¥qâˆ’1/nâˆ¥2
2and we may compute the smoothness constants as
âˆ¥âˆ‡wL(w, q)âˆ’ âˆ‡ wL(wâ€², q)âˆ¥2â‰¤(L+Âµ)âˆ¥wâˆ’wâ€²âˆ¥2
âˆ¥âˆ‡wL(w, q)âˆ’ âˆ‡ wL(w, qâ€²)âˆ¥2=âˆ‡â„“(w)âŠ¤(qâˆ’qâ€²)
2â‰¤âˆšnGâˆ¥qâˆ’qâ€²âˆ¥2
âˆ¥âˆ‡qL(w, q)âˆ’ âˆ‡ qL(w, qâ€²)âˆ¥2â‰¤Î½âˆ¥qâˆ’qâ€²âˆ¥2(17)
âˆ¥âˆ‡qL(w, q)âˆ’ âˆ‡ qL(wâ€², q)âˆ¥2=âˆ¥â„“(w)âˆ’â„“(wâ€²)âˆ¥2â‰¤âˆšnGâˆ¥wâˆ’wâ€²âˆ¥2(18)
âˆ‡(w,q)L(w, q)âˆ’ âˆ‡ (w,q)L(wâ€², qâ€²)
2â‰¤((L+Âµ)âˆ¨Î½+âˆšnG)âˆš
2âˆ¥(w, q)âˆ’(wâ€², qâ€²)âˆ¥2.(19)
In making this assumption, however, we emphasize that our results do not depend on (17),(18),
and(19) being true . We assume here that calls to the oracles (â„“i,âˆ‡wâ„“i)costO(d)operations while
calls to âˆ‡qLcostO(n)operations, making the total O(n+d). This per-iteration complexity is a
subtlety of DRO which is essential to recognize when comparing methods. With DRAGO , we also
have a batch size parameter b, setting the complexity to O(n+bd). By tuning b, we may achieve
improvements in terms of global complexity over standard primal-dual methods. Results comparing
linearly convergent methods in terms of the global complexity of elementary operations are given
in Tab. 4. The table contains a â€œhalf-lifeâ€ column, which is the constant Ï„multiplied with log(1/Îµ)
when describing the number of iterations needed to reach Îµ-suboptimality as Ï„log(1/Îµ). Before
comparisons, observe that the optimal batch size for DRAGO isb=n/d, in the sense that the global
number of arithmetic operations is of order
nLÎºQ
Âµ+nds
nG2
ÂµÎ½
This is an improvement over setting b= 1, in which case the same number is
(n+d)LÎºQ
Âµ+n(n+d)s
nG2
ÂµÎ½
Next, the most comparable and recent setting is that of Li et al. [2023]. Notice that DRAGO is able
to improve by a factor of don theL
Âµterm, as long as ÎºQ=O(1).
While less comparable, we mention known lower bounds for completeness. In terms of lower
bounds, since (16) enjoys a particular structure, such as decomposability into so-called marginal
terms Î½D(qâˆ¥1/n)andÂµ
2âˆ¥wâˆ¥2
2and a coupled termqâŠ¤â„“(w), we are not necessarily constrained by
the more general lower bounds of Zhang et al. [2022] and Xie et al. [2020]. For example, the prox-
imal incremental first-order (PIFO) model of Xie et al. [2020] assumes that we observe first-order
information from a single component in the sum; in DRAGO , using a batch size of n/d is required
to achieve the desired improvement. Zhang et al. [2022], on the other hand, do not treat the finite
sum class of problems considered here. Furthermore, we still list the per-iteration cost as O(n+d)
because a single PIFO call to the dual gradient is of size n.
18Method Assumptions Uncertainty Set Runtime / Global Complexity (Big- ËœO)
Sub-Gradient Methodâ„“iisG-Lipschitz
âˆ¥wâˆ’wâ€²âˆ¥2â‰¤R(if included)
Âµ >0(if included)
âˆ‡â„“iisL-Lipschitz and Î½ >0(if included)Support Constrained
Support Constrained
Support ConstrainedndÂ·(GR)2Îµâˆ’2
ndÂ·G2Âµâˆ’1Îµâˆ’1
ndÂ·Âµâˆ’1 
L+Âµ+nG2/Î½
log(1/Îµ)
LCVaR-SGDâ€ 
LÏ‡2-SGDâ€ 
LÏ‡2âˆ’pen-SGDâ€ 
[Levy et al., 2020]â„“iisG-Lipschitz and in [0, B]
âˆ¥wâˆ’wâ€²âˆ¥2â‰¤Rfor all w, wâ€²âˆˆW
Î½ >0(if included)Î¸-CVaR
Ï-ball in Ï‡2-divergence
Ï‡2-divergence penaltymin
n, B2Î¸âˆ’1Îµâˆ’2	
dÂ·(GR)2Îµâˆ’2
min
n,(1 +Ï)B2Îµâˆ’2	
dÂ·(GR)2Îµâˆ’2
min
n, B2Î½âˆ’1Îµâˆ’1	
dÂ·(GR)2Îµâˆ’2
BROOâˆ—
BROOâˆ—
[Carmon and Hausler, 2022]â„“iisG-Lipschitz
âˆ¥wâˆ’wâ€²âˆ¥2â‰¤Rfor all w, wâ€²âˆˆW
âˆ‡â„“iisL-Lipschitz (if included)1-ball in f-divergence
1-ball in f-divergencendÂ·(GR)2/3Îµâˆ’2/3+d(GR)2Îµâˆ’2
ndÂ·(GR)2/3Îµâˆ’2/3+n3/4d 
GRÎµâˆ’1+L1/2RÎµâˆ’1/2
LSVRG
LSVRG
[Mehta et al., 2023]â„“iisG-Lipschitz
âˆ‡â„“iisL-Lipschitz
Âµ >0,Î½ >0,Îº:= (L+Âµ)/ÂµSpectral Risk Measures ( Î½small)
Spectral Risk Measures ( Î½â‰¥â„¦(nG2/Âµ))None
(n+ÎºQÎº)dlog(1/Îµ)
Prospect
Prospect
[Mehta et al., 2024]â„“iisG-Lipschitz
âˆ‡â„“iisL-Lipschitz
Âµ >0,Î½ >0,Îº:= (L+Âµ)/Âµ, Î´ =G2/(ÂµÎ½)Spectral Risk Measures ( Î½small)
Spectral Risk Measures ( Î½â‰¥â„¦(nG2/Âµ))n(n+d) max
nÎ´+Îºnqmax, n3Î´2Îº2, n3Î´3	
log(1/Îµ)
(n+ÎºQÎº) (n+d)log(1 /Îµ)
DRAGO (Ours)â„“iisG-Lipschitz
âˆ‡â„“iisL-Lipschitz
Âµ >0,Î½ >0,b:=Batch SizeSupport Constrained n
d+ÎºQL/Âµ+dp
nG2/(ÂµÎ½)
log(1/Îµ)
Table 3: Replicate of Tab. 1.
19Method Assumptions Half-Life Per-Iteration Cost
Sub-Gradient MethodL+Âµ
Âµ+nG2
ÂµÎ½nd
Minimax-APPA
[Lin et al., 2020](L+Âµ)âˆ¨Î½+âˆšnGâˆšÂµÎ½nd
Lower Bound
[Xie et al., 2020]Finite Sum
Single component oracle
May not be decomposablen+(L+Âµ)âˆ¨Î½+âˆšnG
min{Âµ,Î½}n+d
Lower Bound
[Zhang et al., 2022]May not be decomposable
May not be finite sumq
L+Âµ
Âµ+nG2
ÂµÎ½nd
AG-OG with Restarts
[Li et al., 2023]L
Âµâˆ¨q
nG2
ÂµÎ½nd
Drago ( b= 1)
Drago ( b=n/d)
Drago ( b=n)D(Â·âˆ¥1/n)need
not be smoothLÎºQ
Âµ+nq
nG2
ÂµÎ½
LÎºQ
Âµ+dq
nG2
ÂµÎ½
LÎºQ
Âµ+q
nG2
ÂµÎ½n+d
n
nd
Table 4: Complexity of Primal-Dual Saddle Point Methods. Half-life (defined as Ï„such that a
linearly convergent method requires O(Ï„log(1/Îµ)) iterations to achieve Îµ-suboptimality) and per-
iteration cost of linearly convergent optimization algorithms. The global number of arithmetic oper-
ations (under the assumption that (â„“i,âˆ‡wâ„“i)costs O(d)operations and âˆ‡qLcosts O(n)operations)
required to achieve a point (w, q)satisfying L(w, qâ‹†)âˆ’ L(wâ‹†, q)â‰¤Îµcan be computed by multi-
plying the last two columns. The â€œAssumptionsâ€ column contains changes to the assumptions that
eachâ„“iisL-smooth and that D(Â·âˆ¥1/n)isÎ½-smooth.
20C Convergence Analysis of DRAGO
This section provides the convergence analysis for DRAGO . We first recall the quantities of interest
and provide an alternate description of the algorithm that is useful for understanding the analysis.
A high-level overview is given in Appx. C.1, and the remaining subsections comprise steps of the
proof.
C.1 Overview
See Tab. 2 for a reference on notation used throughout the proof, which will also be introduced as it
appears. Define q0=1/nand recall the objective
L(w, q) :=qâŠ¤â„“(w)âˆ’Î½D(qâˆ¥q0) +Âµ
2âˆ¥wâˆ¥2
2. (20)
By strong convexity of w7â†’max qL(w, q)with respect to âˆ¥Â·âˆ¥2and strong concavity of q7â†’
minwL(w, q)with respect to âˆ¥Â·âˆ¥2, a primal-dual solution pair (wâ‹†, qâ‹†)is guaranteed to exist and is
unique, and thus we define
wâ‹†= arg min
wâˆˆWmax
qâˆˆQL(w, q)andqâ‹†= arg max
qâˆˆQmin
wâˆˆWL(w, q).
In other words, we have that max qâˆˆQL(wâ‹†, q) =L(wâ‹†, qâ‹†) = min wâˆˆWL(w, qâ‹†). We proceed to
describe the algorithm, the optimality criterion, and the proof outline.
Algorithm Description First, we describe two sequences of parameters that are used to weigh
various terms in the primal and dual updates. The parameters are set in the analysis, and the version
of the algorithm in Appx. D is a description with these values plugged in. However, we keep them
as variables in this section to better describe the logic of the proof.
Specifically, let (at)tâ‰¥1be a sequence of positive numbers and define a0= 0 in addition. Denote
At=PT
s=1as. These will become the averaging sequence that will aggregate successive gaps
Î³t(see (27)) into the return valuePT
t=1atÎ³t, which will be upper bounded by a constant in T(in
expectation). We also define another similar sequence (ct)tâ‰¥1, and define Ct=Atâˆ’(n/bâˆ’1)ctfor
batch size b. We assume for simplicity that bdivides n. When all constants are set, the algorithm will
reduce to that given in Algorithm 1. We have one hyperparameter Î± >0, which may be interpreted
as a learning rate.
Using initial values w0= 0andq0=1/n, initialize the tables Ë†â„“0=â„“(w0)âˆˆRn,Ë†g0=âˆ‡â„“(w0)âˆˆ
RnÃ—d, and Ë†q0=q0âˆˆRn. In addition, partition the [n]sample indices into M:=n/bblocks of
sizeb, orB1, . . . , B MwithBK:= ((Kâˆ’1)b+ 1, . . . , Kb )forKâˆˆ[M]. We can set the averaging
sequence according to the following scheme:
a1= 1, a2= 4Î±,andat= (1 + Î±)atâˆ’1fort >2.
The initial value a2= 4Î±is a slight modification for theoretical convenience, and the algorithm
operates exactly as in Appx. D in practice. In order to retrieve the Appx. D version, we simply
replace the condition above with at= (1 + Î±)atâˆ’1fortâ‰¥2.
Consider iterate tâˆˆ {1, . . . , T }. We sample a random block Ituniformly from [M]and compute
the primal update.
Î´P
t:=1
bX
iâˆˆBIt(qtâˆ’1,iâˆ‡â„“i(wtâˆ’1)âˆ’Ë†qtâˆ’2,iË†gtâˆ’2,i) (21)
vP
t:= Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1+natâˆ’1
atÎ´P
t (22)
wt:= arg min
wâˆˆWat
vP
t, w
+atÂµ
2âˆ¥wâˆ¥2
2+Ctâˆ’1Âµ
2âˆ¥wâˆ’wtâˆ’1âˆ¥2
2+ctâˆ’1Âµ
2tâˆ’2X
s=tâˆ’n/bâˆ¥wâˆ’wsâˆ¨0âˆ¥2
2
(23)
21We see that Ctâˆ’1+ctâˆ’1(n/bâˆ’1) = Atâˆ’1, so the inner objective of the update (23) is AtÂµ-
strongly convex (as the one in (26) is AtÎ½-strongly concave). Note that when n/b < 1, we simply
treat the method as not including the additional regularization termctâˆ’1Âµ
2Ptâˆ’2
s=tâˆ’n/bâˆ¥wâˆ’wsâˆ¨0âˆ¥2
2.
Proceeding, we then modify the loss and gradient table. The loss update has to occur between the
primal and dual updates to achieve control over the variation in the dual update (see Appx. C.2).
Define Kt=tmod M+ 1as the (deterministic) block to be updated, and set
(Ë†â„“t,k,Ë†gt,k) =(
(â„“k(wt),âˆ‡â„“k(wt)) ifkâˆˆBKt
(Ë†â„“tâˆ’1,k,Ë†gtâˆ’1,k) otherwise.
Define ejto be the j-th standard basis vector. Then, sample a random block Jtuniformly from [M]
compute
Î´D
t:=1
bX
jâˆˆBJt(â„“j(wt)âˆ’Ë†â„“tâˆ’1,j)ej (24)
vD
t:=Ë†â„“t+natâˆ’1
atÎ´D
t (25)
qt:= arg max
qâˆˆQat
vD
t, q
âˆ’atÎ½D(qâˆ¥q0)âˆ’Atâˆ’1Î½âˆ†D(q, qtâˆ’1). (26)
Notice the change in indices between (21) and (25), which accounts for the update in the loss table
that occurs in between. Finally, we must update the remaining table. Set
Ë†qt,k=qt,k ifkâˆˆBKt
Ë†qtâˆ’1,k otherwise.
We define the random variable Ht:={(Is, Js)}t
s=1as the history of blocks selected at all times up
to and including t, and define Et[Â·]to be the conditional expectation operator given Htâˆ’1. In other
words, Etintegrates the randomness {(Is, Js)}T
s=t. Accordingly E1[Â·]is the marginal expectation
of the entire random process. We may now describe the optimality criterion.
Proof Outline Construct the gap function
Î³t=at
L(wt, qâ‹†)âˆ’ L(wâ‹†, qt)âˆ’Âµ
2âˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’Î½
2âˆ¥qtâˆ’qâ‹†âˆ¥2
2
(27)
and aim to bound E1hPt
s=1Î³si
by a constant. Throughout the proof, we will use a free parameter
Î±, with update rule
atâ‰¤min 
1 +Î±
4
atâˆ’1, Î±A tâˆ’1,4Î±(n/bâˆ’1)2Ctâˆ’1	
. (28)
Because we will search for Î±down to an absolute constant, we will often swap 
1 +Î±
4
for(1 +Î±)
for readability. We assume the right-hand side of (28) holds in Step 1 andStep 2 . We then select Î±
to satisfy this condition (and all others) in Step 3 below. The proof occurs in five steps total.
1. Lower bound the dual suboptimality atL(wâ‹†, qt).
2. Upper bound the primal suboptimality atL(wt, qâ‹†), and combine both to derive a bound on
the gap function for tâ‰¥2.
3. Derive all conditions on the learning rate constant Î±and batch size b.
4. Bound Î³1and sum Î³tovertfor aT-step progress bound.
5. Bound the remaining non-telescoping terms to complete the analysis.
We begin with a section of technical lemmas that will not only be useful in various areas of the
proof but also capture the main insights that allow the method to achieve the given rate. Given these
lemmas, the main proof occurs in Appx. C.3 and otherwise follows standard structure.
22C.2 Technical Lemmas
This section contains a number of lemmas that describe common structures in the analysis of quan-
tities in the primal and dual. Lem. 4 bounds cross terms that arise when there are inner products
between the primal-dual iterates and their gradient estimates. Lem. 5 and Lem. 6 are respectively
the primal and dual noise bounds, constructed to control the variation of the terms Î´P
tandÎ´D
tap-
pearing in (21). Finally, Lem. 10 exploits the cyclic style updates of the Ë†qttable to bound the term
âˆ¥Ë†qtâˆ’1âˆ’qtâˆ’2âˆ¥2
2which is used in the primal noise bound.
Cross Term Bound Both of the estimates of the gradient of the coupled term qâŠ¤â„“(w)with respect
to the primal and dual variables share a similar structure (see (22) and compare to (29)). They
are designed to achieve a particular form of telescoping, with a remaining squared term that can
be controlled by case-specific techniques. This can be observed within Lem. 4. In the sequel, we
will refer to a sequence of random vectors (ut)tâ‰¥1asadapted to Ht, where Ht={(Is, Js)}t
s=1
is the history of random blocks. This simply means that ut, when conditioned on Htâˆ’1, is only a
function of the current random block (It, Jt). Similarly, conditioned on Htâˆ’1, we have that utâˆ’1is
not random. In the language of probability theory, {Ïƒ(Ht)}tâ‰¥1forms a filtration and utisÏƒ(Ht)-
measurable, but this terminology is not necessary for understanding the results.
Lemma 4 (Cross Term Bound) .Let(xt)tâ‰¥1,(yt)tâ‰¥1, and (Ë†yt)tâ‰¥1denote random sequences of Rm-
valued vectors, and let xâ‹†âˆˆRmbe a vector. Denote by Itbe the index of a uniform random block
[M].
vt:= Ë†ytâˆ’1+natâˆ’1
at1
bX
iâˆˆBIt(ytâˆ’1,iâˆ’Ë†ytâˆ’2,i) (29)
Finally, let (xt, yt,Ë†yt)tâ‰¥1adapted to Ht(as defined above). Then, for any positive constant Î³ >0,
atEt[âŸ¨ytâˆ’vt, xâ‹†âˆ’xtâŸ©]â‰¤atEt[âŸ¨ytâˆ’Ë†ytâˆ’1, xâ‹†âˆ’xtâŸ©]âˆ’atâˆ’1âŸ¨ytâˆ’1âˆ’Ë†ytâˆ’2, xâ‹†âˆ’xtâˆ’1âŸ©
+n2a2
tâˆ’1
2Î³Et1
bP
iâˆˆBIt(ytâˆ’1,iâˆ’Ë†ytâˆ’2,i)2
2+Î³
2Etâˆ¥xtâˆ’xtâˆ’1âˆ¥2
2.
Proof. By plugging in the value of vtand using xâ‹†âˆ’xt=xâ‹†âˆ’xtâˆ’1+xtâˆ’1âˆ’xt, we have that
atEt[âŸ¨ytâˆ’vt, xâ‹†âˆ’xtâŸ©] =atEt[âŸ¨ytâˆ’Ë†ytâˆ’1, xâ‹†âˆ’xtâŸ©]âˆ’natâˆ’1Etï£®
ï£°*
1
bX
iâˆˆBIt(ytâˆ’1âˆ’Ë†ytâˆ’2), xâ‹†âˆ’xt+ï£¹
ï£»
=atEt[âŸ¨ytâˆ’Ë†ytâˆ’1, xâ‹†âˆ’xtâŸ©]âˆ’atâˆ’1âŸ¨ytâˆ’1âˆ’Ë†ytâˆ’2, xâ‹†âˆ’xtâˆ’1âŸ©
+natâˆ’1Etï£®
ï£°*
1
bX
iâˆˆBIt(ytâˆ’1âˆ’Ë†ytâˆ’2), xtâˆ’xtâˆ’1+ï£¹
ï£»
â‰¤atEt[âŸ¨ytâˆ’Ë†ytâˆ’1, xâ‹†âˆ’xtâŸ©]âˆ’atâˆ’1âŸ¨ytâˆ’1âˆ’Ë†ytâˆ’2, xâ‹†âˆ’xtâˆ’1âŸ©
+n2a2
tâˆ’1
2Î³Et1
bP
iâˆˆBIt(ytâˆ’1,iâˆ’Ë†ytâˆ’2,i)2
2+Î³
2Etâˆ¥xtâˆ’xtâˆ’1âˆ¥2
2,
where the final step follows from Youngâ€™s inequality with parameter Î³.
In the primal case, we have that vt=vP
t,yt=âˆ‡â„“(wt)âŠ¤qt,Ë†yt= Ë†gâŠ¤
tË†qt, and xt=wt. In the dual
case, we have that vt=vD
t,yt=â„“(wt),Ë†yt=Ë†â„“t+1, and xt=qt. The next few lemmas control the
third term appearing in Lem. 4 for the specific case of the primal and dual sequences.
Noise Term Bounds Next, we proceed to control the Î´P
tandÎ´D
tby way of Lem. 5 and Lem. 6.
As discussed in Sec. 3, a key step in the convergence proof is establishing control over these terms.
Define Ï€(t, i)to satisfy Ë†qt,i=qÏ€(t,i),iandË†gt,i=âˆ‡â„“i(wÏ€(t,i)), that is, the time index of the last
update of table element ion or before time t. This notation is used to write the table values such as
Ë†qtin terms of past values of the iterates (e.g., qt).
23Lemma 5 (Primal Noise Bound) .When tâ‰¥2, we have that
EtÎ´P
t2
2â‰¤3qmax
nnX
i=1qtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+3qmax
nnX
i=1qÏ€(tâˆ’2,i),iâˆ‡â„“i(wÏ€(tâˆ’2,i))âˆ’ âˆ‡â„“i(wâ‹†)2
2
+3G2
nâˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2 (30)
Proof. By definition, we have that
EtÎ´P
t2
2=Et1
bP
iâˆˆBItâˆ‡â„“i(wtâˆ’1)qtâˆ’1,iâˆ’Ë†gtâˆ’2,iË†qtâˆ’2,i2
2
=1
b2EtP
iâˆˆBItâˆ‡â„“i(wtâˆ’1)qtâˆ’1,iâˆ’Ë†gtâˆ’2,iË†qtâˆ’2,i2
2
â‰¤1
bEthP
iâˆˆBItâˆ¥âˆ‡â„“i(wtâˆ’1)qtâˆ’1,iâˆ’Ë†gtâˆ’2,iË†qtâˆ’2,iâˆ¥2
2i
=1
nnX
i=1âˆ¥âˆ‡â„“i(wtâˆ’1)qtâˆ’1,iâˆ’Ë†gtâˆ’2,iË†qtâˆ’2,iâˆ¥2
2,
where we use that Itis drawn uniformly over n/b. Continuing again with the term above, we have
1
nnX
i=1âˆ¥âˆ‡â„“i(wtâˆ’1)qtâˆ’1,iâˆ’Ë†gtâˆ’2,iË†qtâˆ’2,iâˆ¥2
2
=1
nnX
i=1âˆ¥(âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†))qtâˆ’1,iâˆ’(Ë†gtâˆ’2,iâˆ’ âˆ‡â„“i(wâ‹†))Ë†qtâˆ’2,i+ (qtâˆ’1,iâˆ’Ë†qtâˆ’2,i)âˆ‡â„“i(wâ‹†)âˆ¥2
2
â‰¤3
nnX
i=1
qtâˆ’1,i2âˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+ Ë†q2
tâˆ’2,iâˆ¥Ë†gtâˆ’2,iâˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+ (qtâˆ’1,iâˆ’Ë†qtâˆ’2,i)2âˆ¥âˆ‡â„“i(wâ‹†)âˆ¥2
2
â‰¤3
nnX
i=1
qmaxqtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+qmaxË†qtâˆ’2,iâˆ¥Ë†gtâˆ’2,iâˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+ (qtâˆ’1,iâˆ’Ë†qtâˆ’2,i)2G2
.
where we use that âˆ¥âˆ‡â„“i(wâ‹†)âˆ¥2
2â‰¤G2because every â„“iisG-Lipschitz with respect to âˆ¥Â·âˆ¥2
2, and that
qiâ‰¤qmax= max qâˆˆQâˆ¥qâˆ¥âˆ. This completes the proof.
The corresponding dual noise bound in Lem. 6 follows similarly, using cyclic updates in the loss
table.
Lemma 6 (Dual Noise Bound) .Fortâ‰¥2,
EtÎ´D
t2
2â‰¤G2
ntâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’1âˆ’wÏ„âˆ¨0âˆ¥2
2.
24Proof. Then, we may exploit the coordinate structure of the noise term to write
EtÎ´D
t2
2=Et1
bX
jâˆˆBJt(â„“j(wtâˆ’1)âˆ’Ë†â„“tâˆ’1,j)ej2
2
=1
b2 
EtX
jâˆˆBJt(â„“j(wtâˆ’1)âˆ’Ë†â„“tâˆ’1,j)ej2
2
+Etï£®
ï£°X
jÌ¸=k(â„“j(wtâˆ’1)âˆ’Ë†â„“tâˆ’1,j)(â„“k(wtâˆ’1)âˆ’Ë†â„“tâˆ’1,k)âŸ¨ej, ekâŸ©ï£¹
ï£»!
=1
b2EtX
jâˆˆBJt(â„“j(wtâˆ’1)âˆ’Ë†â„“tâˆ’1,j)ej2
2
=1
b2EtX
jâˆˆBJt|â„“j(wtâˆ’1)âˆ’Ë†â„“tâˆ’1,j|2
â‰¤1
bnnX
i=1|â„“i(wtâˆ’1)âˆ’Ë†â„“tâˆ’1,i|2
â‰¤G2
ntâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’1âˆ’wÏ„âˆ¨0âˆ¥2
2.
The red term is zero because jÌ¸=k. The sum in the last line has n/bâˆ’1terms because our order
of updates forces one of the blocks of the Ë†â„“tâˆ’1vector to have values equal to wtâˆ’1before defining
Î´D
t.
Controlling the Recency of the Loss Table In this section, we bound the âˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2term
appearing in the primal noise bound Lem. 5. Controlling this term is essential to achieving the
correct rate, as we comment toward the end of this section.
Recall that the [n]indices are partitioned into blocks (B1, . . . , B M)forM:=n/b, where bis
assumed to divide n. For any tâ‰¥1, we first decompose
nX
i=1(qt,iâˆ’Ë†qtâˆ’1,i)2=MX
K=1X
iâˆˆBK(qt,iâˆ’Ë†qtâˆ’1,i)2,
and analyze block-by-block. Our goal is to be able to count this quantity in terms of âˆ¥qtâˆ’qtâˆ’1âˆ¥2
2terms. The main result is given in Lem. 10, which is built up in the following lemmas. Consider a
block index Kâˆˆ[M]. Define the number tK=MâŒŠ(tâˆ’K)/MâŒ‹+Kwhen tâˆ’1â‰¥Kand and
tK= 0otherwise.
Lemma 7. It holds that
X
iâˆˆBK(qt,iâˆ’Ë†qtâˆ’1,i)2â‰¤X
iâˆˆBK(tâˆ’tK)tX
s=tK+1(qs,iâˆ’qsâˆ’1,i)2.
Proof. We define tKto be the earliest time index Ï„on or before tâˆ’1when block KofqÏ„was used
to update Ë†qÏ„. When tâˆ’1< K , then tK= 0. When tâˆ’1â‰¥K, we can compute this number
25tK=MâŒŠ[(tâˆ’1)âˆ’(Kâˆ’1)]/MâŒ‹+K=MâŒŠ(tâˆ’K)/MâŒ‹+K. Then, write
X
iâˆˆBK(qt,iâˆ’Ë†qtâˆ’1,i)2=X
iâˆˆBK(qt,iâˆ’qtK,i)2
=X
iâˆˆBK tX
s=tK+1qs,iâˆ’qsâˆ’1,i!2
â‰¤X
iâˆˆBK(tâˆ’tK)tX
s=tK+1(qs,iâˆ’qsâˆ’1,i)2,
where the last line follows by Youngâ€™s inequality.
While we will not be able to cancel these terms on every iterate, we will be able to when aggregating
over time and then redistributing them. Recall (at)tâ‰¥1as described in Appx. C.1. Indeed, by
summing across iterations, we see that
TX
t=1atnX
i=1(qt,iâˆ’Ë†qtâˆ’1,i)2â‰¤TX
t=1atMX
K=1X
iâˆˆBK(tâˆ’tK)tX
s=tK+1(qs,iâˆ’qsâˆ’1,i)2.
We can start by swapping the first two sums and only considering the values of tthat are greater
than or equal to K.
TX
t=1atMX
K=1X
iâˆˆBK(tâˆ’tK)tX
s=tK+1(qs,iâˆ’qsâˆ’1,i)2
=MX
K=1Kâˆ’1X
t=1atX
iâˆˆBK(tâˆ’tK)tX
s=tK+1(qs,iâˆ’qsâˆ’1,i)2+MX
K=1TX
t=KatX
iâˆˆBK(tâˆ’tK)tX
s=tK+1(qs,iâˆ’qsâˆ’1,i)2
=MX
K=1Kâˆ’1X
t=1atX
iâˆˆBKttX
s=1(qs,iâˆ’qsâˆ’1,i)2
| {z }
S0+MX
K=1TX
t=KatX
iâˆˆBK(tâˆ’tK)tX
s=tK+1(qs,iâˆ’qsâˆ’1,i)2
| {z }
S1,
(31)
where we use in the last line that tK= 0when t < K . We handle the terms S0andS1separately.
In either case, we have to match the sums over Kand over iin order to create complete vectors,
as opposed to differences between coordinates. We also maintain the update rules of the sequence
(at)tâ‰¥1that will be used in the proof.
Lemma 8. Assume that Î±â‰¤1
Mandatâ‰¤(1 +Î±)atâˆ’1. It holds that S0as defined in (31) satisfies
S0â‰¤eM(Mâˆ’1)
2Mâˆ’1X
t=1atâˆ¥qtâˆ’qtâˆ’1âˆ¥2
2.
26Proof. Write
S0=MX
K=1Kâˆ’1X
t=1atX
iâˆˆBKttX
s=1(qs,iâˆ’qsâˆ’1,i)2by definition
=Mâˆ’1X
t=1tatMX
K=t+1X
iâˆˆBKtX
s=1(qs,iâˆ’qsâˆ’1,i)2swap sums over Kandt
=Mâˆ’1X
t=1tattX
s=1MX
K=t+1X
iâˆˆBK(qs,iâˆ’qsâˆ’1,i)2move sum over s
â‰¤Mâˆ’1X
t=1tattX
s=1MX
K=1X
iâˆˆBK(qs,iâˆ’qsâˆ’1,i)2MX
K=t+1(Â·)â‰¤MX
K=1(Â·)
=Mâˆ’1X
t=1tattX
s=1âˆ¥qsâˆ’qsâˆ’1âˆ¥2
2MX
K=1X
iâˆˆBK(Â·) =nX
i=1(Â·)
=Mâˆ’1X
s=1 Mâˆ’1X
t=stat!
âˆ¥qsâˆ’qsâˆ’1âˆ¥2
2swap sums over sandt
â‰¤Mâˆ’1X
s=1 Mâˆ’1X
t=st(1 +Î±)tâˆ’sas!
âˆ¥qsâˆ’qsâˆ’1âˆ¥2
2atâ‰¤(1 +Î±)atâˆ’1
â‰¤Mâˆ’1X
s=1as(1 +Î±)M Mâˆ’1X
t=st!
âˆ¥qsâˆ’qsâˆ’1âˆ¥2
2tâˆ’sâ‰¤M
â‰¤Mâˆ’1X
s=1eas Mâˆ’1X
t=st!
âˆ¥qsâˆ’qsâˆ’1âˆ¥2
2Î±â‰¤1
M=â‡’(1 +Î±)Mâ‰¤e
â‰¤Mâˆ’1X
s=1eas Mâˆ’1X
t=1t!
âˆ¥qsâˆ’qsâˆ’1âˆ¥2
2Mâˆ’1X
t=s(Â·)â‰¤Mâˆ’1X
t=1(Â·)
=eM(Mâˆ’1)
2Mâˆ’1X
s=1asâˆ¥qsâˆ’qsâˆ’1âˆ¥2
2,
the result as desired.
Thus, S0contributes about M3of such terms over the entire trajectory, which can be viewed as an
initialization cost. Next, we control S1.
Lemma 9. Assume that Î±â‰¤1
Mandatâ‰¤(1 +Î±)atâˆ’1. It holds that S1as defined in (31) satisfies
S1â‰¤2e2M2TX
t=1atâˆ¥qtâˆ’qtâˆ’1âˆ¥2
2.
27Proof. We can reparametrize tin terms of r=tâˆ’K, which will help in reasoning with tK. Define
rK=MâŒŠr/MâŒ‹+K, and let
S1=MX
K=1Tâˆ’KX
r=0ar+KX
iâˆˆBK(r+Kâˆ’rK)r+KX
s=rK+1(qs,iâˆ’qsâˆ’1,i)2by definition and r=tâˆ’K
â‰¤MMX
K=1Tâˆ’KX
r=0ar+KX
iâˆˆBKr+KX
s=rK+1(qs,iâˆ’qsâˆ’1,i)2(râˆ’MâŒŠr/MâŒ‹)â‰¤M
â‰¤MMX
K=1Tâˆ’KX
r=0(1 +Î±)KarX
iâˆˆBKr+KX
s=rK+1(qs,iâˆ’qsâˆ’1,i)2atâ‰¤(1 +Î±)atâˆ’1
â‰¤eMMX
K=1Tâˆ’KX
r=0arX
iâˆˆBKr+KX
s=rK+1(qs,iâˆ’qsâˆ’1,i)2Kâ‰¤MandÎ±â‰¤1
M
=eMTâˆ’2X
r=0armin{Tâˆ’r,M}X
K=1X
iâˆˆBKr+KX
s=rK+1(qs,iâˆ’qsâˆ’1,i)2swap sums over randK
â‰¤eMTâˆ’2X
r=0armin{Tâˆ’r,M}X
K=1X
iâˆˆBKmin{r+M,T}X
s=MâŒŠr/MâŒ‹+1(qs,iâˆ’qsâˆ’1,i)2r+KX
s=rK+1(Â·)â‰¤min{r+M,T}X
s=MâŒŠr/MâŒ‹+1(Â·)
=eMTâˆ’2X
r=0armin{r+M,T}X
s=MâŒŠr/MâŒ‹+1min{Tâˆ’r,M}X
K=1X
iâˆˆBK(qs,iâˆ’qsâˆ’1,i)2move sum over s
â‰¤eMTâˆ’2X
r=0armin{r+M,T}X
s=MâŒŠr/MâŒ‹+1MX
K=1X
iâˆˆBK(qs,iâˆ’qsâˆ’1,i)2min{Tâˆ’r,M}X
K=1(Â·)â‰¤MX
K=1(Â·)
=eMTâˆ’2X
r=0armin{r+M,T}X
s=MâŒŠr/MâŒ‹+1âˆ¥qsâˆ’qsâˆ’1âˆ¥2
2MX
K=1X
iâˆˆBK(Â·) =nX
i=1(Â·)
â‰¤eMTâˆ’2X
r=0min{r+M,T}X
s=MâŒŠr/MâŒ‹(1 +Î±)râˆ’sasâˆ¥qsâˆ’qsâˆ’1âˆ¥2
2atâ‰¤(1 +Î±)atâˆ’1
â‰¤e2MTâˆ’2X
r=0min{r+M,T}X
s=MâŒŠr/MâŒ‹asâˆ¥qsâˆ’qsâˆ’1âˆ¥2
2râˆ’sâ‰¤MandÎ±â‰¤1
M
â‰¤2e2M2Tâˆ’1X
s=1asâˆ¥qsâˆ’qsâˆ’1âˆ¥2
2.
The last line follows because the inner sumPmin{r+M,T}
s=MâŒŠr/MâŒ‹asâˆ¥qsâˆ’qsâˆ’1âˆ¥2
2can be thought of as a
sliding window of size at most 2Mcentered at r, which essentially repeats each element in the sum
2Mtimes at most.
In either case, the contribution over the entire trajectory is order M2= (n/b)2terms. Combining
the bounds for S0andS1yields the following.
Lemma 10. Letting M=n/bbe the number of blocks. Assume that Î±â‰¤1
Mandatâ‰¤(1+Î±)atâˆ’1.
We have that
TX
t=1atnX
i=1(qt,iâˆ’Ë†qtâˆ’1,i)2â‰¤3e2M2TX
t=1atâˆ¥qtâˆ’qtâˆ’1âˆ¥2
2.
28Proof. Use Lem. 7 to achieve (31) and apply Lem. 8 and Lem. 9 on each term to get
TX
t=1atnX
i=1(qt,iâˆ’Ë†qtâˆ’1,i)2â‰¤eM(Mâˆ’1)
2Mâˆ’1X
t=1atâˆ¥qtâˆ’qtâˆ’1âˆ¥2
2+ 2e2M2TX
t=1atâˆ¥qtâˆ’qtâˆ’1âˆ¥2
2
â‰¤3e2M2TX
t=1atâˆ¥qtâˆ’qtâˆ’1âˆ¥2
2,
completing the proof.
We close this subsection with comments on how Lem. 10 can be used. The term EtÎ´D
t2
2is
multiplied in (36) by a factorna2
tâˆ’1G2
ÂµCtâˆ’1. Thus, if we apply Lem. 10 when redistributing over time a
termâˆ¥qtâˆ’1âˆ’qtâˆ’2âˆ¥2
2which will be multiplied by a factor (ignoring absolute constants) of
na2
tâˆ’1G2
ÂµCtâˆ’1Â·M2=n3a2
tâˆ’1G2
b2ÂµCtâˆ’1.
In order to cancel such a term, we require the use of âˆ’Atâˆ’1Î½
2âˆ¥qtâˆ’qtâˆ’1âˆ¥2
2. We can reserve half to
be used up by (49), and be left with the condition
n3a2
tâˆ’1G2
b2ÂµCtâˆ’1â‰¤Atâˆ’1Î½â‡â‡’ Î±2â‰¤b2
n2ÂµÎ½
2nG2,
as we have applied that atâˆ’1â‰¤2Î±Ctâˆ’1andatâˆ’1â‰¤Î±Atâˆ’1. Thus, this introduces a dependence of
ordern
bq
nG2
ÂµÎ½onÎ±, which propagates to the learning rate Î±. We now proceed to the main logic of
the convergence analysis.
C.3 Proof of Main Result
C.3.1 Lower Bound on Dual Objective
We first quantify the gap between L(wâ‹†, qt)andL(wâ‹†, qâ‹†)by providing a lower bound in expecta-
tion on L(wâ‹†, qt), given in Lem. 11. As in Lem. 5, recall the notation Ï€(t, i)to satisfy Ë†qt,i=qÏ€(t,i),i
andgt,i=âˆ‡â„“i(wÏ€(t,i)), that is, the time index of the last update of table element ion or before time
t, with Ï€(t, i) = 0 fortâ‰¤0.
Lemma 11. Assume that Î±â‰¤Âµ/(24eLÎºQ). Then, for tâ‰¥2, we have that:
âˆ’Et[atL(wâ‹†, qt)]
â‰¤ âˆ’atEt[qâŠ¤
tâ„“(wt)]âˆ’at
2LnX
i=1qt,iEtâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+atâˆ’1
4LnX
i=1qtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+nX
i=1aÏ€(tâˆ’2,i)
4LqÏ€(tâˆ’2,i),iâˆ‡â„“i(wÏ€(tâˆ’2,i)âˆ’ âˆ‡â„“i(wâ‹†))2
2
+6nÎ±a tâˆ’1G2
Âµâˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2
âˆ’atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
+atâˆ’1
âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1âˆ’Ë†gâŠ¤
tâˆ’2Ë†qtâˆ’2, wâ‹†âˆ’wtâˆ’1
âˆ’atÂµ
2Etâˆ¥wtâˆ¥2
2+atÎ½Et[D(qt||q0)]âˆ’ÂµAt
2Etâˆ¥wâ‹†âˆ’wtâˆ¥2
2
âˆ’ÂµCtâˆ’1
4âˆ¥wtâˆ’wtâˆ’1âˆ¥2
2+ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2
âˆ’ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bEtâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2+ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2.
29Proof. We use convexity and smoothness (1), then add and subtract (2) elements from the primal
update, and finally use the definition of the proximal operator (3) with the optimality of wtfor the
problem that defines it.
atL(wâ‹†, qt) :=atqâŠ¤
tâ„“(wâ‹†) +atÂµ
2âˆ¥wâ‹†âˆ¥2
2âˆ’atÎ½D(qt||q0)
(1)
â‰¥atqâŠ¤
tâ„“(wt) +at
âˆ‡â„“(wt)âŠ¤qt, wâ‹†âˆ’wt
+at
2LnX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+atÂµ
2âˆ¥wâ‹†âˆ¥2
2âˆ’Î½D(qt||q0)
(2)=atqâŠ¤
tâ„“(wt) +at
âˆ‡â„“(wt)âŠ¤qtâˆ’vP
t, wâ‹†âˆ’wt
+at
vP
t, wâ‹†âˆ’wt
+atÂµ
2âˆ¥wâ‹†âˆ¥2
2âˆ’atÎ½D(qt||q0) +at
2LnX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2âˆ’ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2(32)
+ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2âˆ’ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2
(3)
â‰¥atqâŠ¤
tâ„“(wt) +at
âˆ‡â„“(wt)âŠ¤qtâˆ’vP
t, wâ‹†âˆ’wt
| {z }
cross term+at
vP
t, wtâˆ’wt
|{z}
=0
+atÂµ
2âˆ¥wtâˆ¥2
2âˆ’atÎ½D(qt||q0) +at
2LnX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+ÂµCtâˆ’1
2âˆ¥wtâˆ’wtâˆ’1âˆ¥2
2âˆ’ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2 (33)
+ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2âˆ’ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2
+ÂµAt
2âˆ¥wâ‹†âˆ’wtâˆ¥2
2. (34)
Next, we are able to use Lem. 4 with vt=vP
t,yt=âˆ‡â„“(wt)âŠ¤qt,Ë†yt= Ë†gâŠ¤
tË†qt,xt=wt,xâ‹†=wâ‹†, and
Î³=ÂµCtâˆ’1/2which yields that
atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’vP
t, wâ‹†âˆ’wt
â‰¤atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
âˆ’atâˆ’1
âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1âˆ’Ë†gâŠ¤
tâˆ’2Ë†qtâˆ’2, wâ‹†âˆ’wtâˆ’1
+n2atâˆ’12
ÂµCtâˆ’1Eth1
bP
iâˆˆItâˆ‡â„“i(wtâˆ’1)qtâˆ’1,iâˆ’gtâˆ’2,iË†qtâˆ’2,i2
2i
| {z }
Etâˆ¥Î´P
tâˆ¥2
2+ÂµCtâˆ’1
4Etâˆ¥wtâˆ’wtâˆ’1âˆ¥2
2.
(35)
Then, apply Lem. 5 to achieve
EtÎ´P
t2
2â‰¤3qmax
nnX
i=1qtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+3qmax
nnX
i=1qÏ€(tâˆ’2,i),iâˆ‡â„“i(wÏ€(tâˆ’2,i))âˆ’ âˆ‡â„“i(wâ‹†)2
2
+3G2
nâˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2(36)
30In the following, the blue terms indicate what changes from line to line. Combine the previous two
steps to collect all terms for the lower bound. That is, apply (34) to write
Et[atL(wâ‹†, qt)]
:=atqâŠ¤
tâ„“(wâ‹†) +atÂµ
2âˆ¥wâ‹†âˆ¥2
2âˆ’atÎ½D(qt||q0)
â‰¥atqâŠ¤
tâ„“(wt) +Et[at
âˆ‡â„“(wt)âŠ¤qtâˆ’vP
t, wâ‹†âˆ’wt
] +at
2LnX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
+atÂµ
2âˆ¥wtâˆ¥2
2âˆ’atÎ½D(qt||q0) +ÂµAt
2âˆ¥wâ‹†âˆ’wtâˆ¥2
2
+ÂµCtâˆ’1
2âˆ¥wtâˆ’wtâˆ’1âˆ¥2
2âˆ’ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2
+ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2âˆ’ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2,
then apply (35) to the blue term above to write
Et[atL(wâ‹†, qt)]
â‰¥atqâŠ¤
tâ„“(wt) +at
2LnX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
âˆ’n2atâˆ’12
ÂµCtâˆ’1Etâˆ‡â„“itâˆ’1(wtâˆ’1)qtâˆ’1,itâˆ’1âˆ’gtâˆ’2,itâˆ’1Ë†qtâˆ’2,itâˆ’12
2(37)
+atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
âˆ’atâˆ’1
âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1âˆ’Ë†gâŠ¤
tâˆ’2Ë†qtâˆ’2, wâ‹†âˆ’wtâˆ’1
+atÂµ
2âˆ¥wtâˆ¥2
2âˆ’atÎ½D(qt||q0) +ÂµAt
2âˆ¥wâ‹†âˆ’wtâˆ¥2
2
+ÂµCtâˆ’1
4âˆ¥wtâˆ’wtâˆ’1âˆ¥2
2âˆ’ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2
+ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2âˆ’ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2.
Finally, apply (36) to the term (37) to achieve
â‰¥atqâŠ¤
tâ„“(wt) +at
2LnX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2
âˆ’3ÎºQa2
tâˆ’1
ÂµCtâˆ’1nX
i=1qtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2âˆ’3ÎºQa2
tâˆ’1
ÂµCtâˆ’1nX
i=1qÏ€(tâˆ’2,i),iâˆ‡â„“i(wÏ€(tâˆ’2,i)âˆ’ âˆ‡â„“i(wâ‹†))2
2
âˆ’3nG2a2
tâˆ’1
ÂµCtâˆ’1âˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2
+atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
âˆ’atâˆ’1
âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1âˆ’Ë†gâŠ¤
tâˆ’2Ë†qtâˆ’2, wâ‹†âˆ’wtâˆ’1
+atÂµ
2âˆ¥wtâˆ¥2
2âˆ’atÎ½D(qt||q0) +ÂµAt
2âˆ¥wâ‹†âˆ’wtâˆ¥2
2
+ÂµCtâˆ’1
4âˆ¥wtâˆ’wtâˆ’1âˆ¥2
2âˆ’ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2
+ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2âˆ’ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2.
31Next, we apply atâˆ’1â‰¤2Î±Ctâˆ’1andÎ±â‰¤Âµ
24eLÎºQto achieve:
3nG2a2
tâˆ’1
ÂµCtâˆ’1â‰¤6nG2Î±atâˆ’1
Âµ,
3ÎºQa2
tâˆ’1
ÂµCtâˆ’1â‰¤atâˆ’1
4L,
3ÎºQa2
tâˆ’1
ÂµCtâˆ’1â‰¤aÏ€(tâˆ’2,i)
4L,âˆ€iâˆˆ[n]
For terms that contain Ï€(tâˆ’2, i), we recall that Ï€(tâˆ’2, i)can be at most n/btimesteps behind
tâˆ’2, so we have that
atâˆ’1â‰¤
1 +1
n/bn/b
atâˆ’n/bâ‰¤eatâˆ’n/bâ‰¤eaÏ€(tâˆ’2,i).
We use here that atâ‰¤(1 +Î±
4)atâˆ’1and impose the conditionÎ±
4â‰¤b
nin the rate. Substituting this
back into the lower bound achieves the desired claim.
C.3.2 Upper Bound on Gap Criterion
Next, we quantify the gap between L(wt, qâ‹†)andL(wâ‹†, qâ‹†)by upper bounding atL(wt, qâ‹†), as
given in Lem. 12. When combined with the lower bound Lem. 11, we may then control the gap.
Lemma 12. Fortâ‰¥2, we have that:
atL(wt, qâ‹†)â‰¤atqâ‹†âŠ¤(â„“(wt)âˆ’vD
t) +atÂµ
2âˆ¥wtâˆ¥2
2+Atâˆ’1Î½âˆ†D(qâ‹†, qtâˆ’1)
+atqtâŠ¤vD
tâˆ’atÎ½D(qt||q0)âˆ’Atâˆ’1Î½âˆ†D(qt, qtâˆ’1)âˆ’AtÎ½âˆ†D(qâ‹†, qt).
Proof. We add and subtract (1) terms in the dual update step and apply the definition of the proximal
operator (2) with Bregman divergence, and the optimality of qtfor the maximization problem that
defines it.
atL(wt, qâ‹†) :=atqâ‹†âŠ¤â„“(wt)âˆ’atÎ½D(qâ‹†||q0) +atÂµ
2âˆ¥wtâˆ¥2
2
(1)=atqâ‹†âŠ¤(â„“(wt)âˆ’vD
t) +atÂµ
2âˆ¥wtâˆ¥2
2+Atâˆ’1Î½âˆ†D(qâ‹†, qtâˆ’1))
+atqâ‹†âŠ¤vD
tâˆ’atÎ½D(qâ‹†||q0)âˆ’Atâˆ’1Î½âˆ†D(qâ‹†, qtâˆ’1))
(2)
â‰¤atqâ‹†âŠ¤(â„“(wt)âˆ’vD
t) +atÂµ
2âˆ¥wtâˆ¥2
2+Atâˆ’1Î½âˆ†D(qâ‹†, qtâˆ’1))
+atqtâŠ¤vD
tâˆ’atÎ½D(qt||q0)âˆ’Atâˆ’1Î½âˆ†D(qt, qtâˆ’1)âˆ’AtÎ½âˆ†D(qâ‹†, qt).
We can combine the upper bound from Lem. 12 and lower bound from Lem. 11 in Lem. 13. We
identify telescoping terms in blue and non-positive terms in red. The green term is canceled after
aggregation across time t. This bound, like before applies for tâ‰¥2.
32Lemma 13. Assume that Î±â‰¤Âµ/(24eLÎºQ). For t >2, we have that:
Et[Î³t] =Eth
at(L(wt, qâ‹†)âˆ’ L(wâ‹†, qt)âˆ’atÂµ
2âˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’atÎ½
2âˆ¥qtâˆ’qâ‹†âˆ¥2
2i
â‰¤atEt
(qâ‹†âˆ’qt)âŠ¤(â„“(wt)âˆ’Ë†â„“t)
âˆ’atâˆ’1(qâ‹†âˆ’qtâˆ’1)âŠ¤(â„“(wtâˆ’1)âˆ’Ë†â„“tâˆ’1) (38)
+Atâˆ’1Î½âˆ†D(qâ‹†, qtâˆ’1)âˆ’AtÎ½Et[âˆ†D(qâ‹†, qt)] (39)
âˆ’at
2LEt"nX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2#
(40)
+atâˆ’1
4LnX
i=1qtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+nX
i=1aÏ€(tâˆ’2,i)
4LqÏ€(tâˆ’2,i),iâˆ‡â„“i(wÏ€(tâˆ’2,i)âˆ’ âˆ‡â„“i(wâ‹†))2
2
(41)
âˆ’atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
+atâˆ’1
âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1âˆ’Ë†gâŠ¤
tâˆ’2Ë†qtâˆ’2, wâ‹†âˆ’wtâˆ’1
(42)
+6nG2Î±atâˆ’1
Âµâˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2 (43)
âˆ’ÂµAt
2Etâˆ¥wâ‹†âˆ’wtâˆ¥2
2+ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2+ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2(44)
+natâˆ’1Î±G2
Î½tâˆ’3X
Ï„=tâˆ’n/bâˆ¥wtâˆ’1âˆ’wÏ„âˆ¨0âˆ¥2
2âˆ’ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bEtâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2(45)
+natâˆ’1Î±G2
Î½âˆ¥wtâˆ’1âˆ’wtâˆ’2âˆ¥2
2âˆ’ÂµCtâˆ’1
4Etâˆ¥wtâˆ’wtâˆ’1âˆ¥2
2(46)
âˆ’atÂµ
2Eth
âˆ¥wtâˆ’wâ‹†âˆ¥2
2i
âˆ’atÎ½
2Etâˆ¥qtâˆ’qâ‹†âˆ¥2
2âˆ’Atâˆ’1Î½
2Et[âˆ†D(qt, qtâˆ’1)]. (47)
Fort= 2, the above holds with the addition of the termÎ½
4âˆ¥q1âˆ’q0âˆ¥2
2+nG2
Î½âˆ¥w0âˆ’w1âˆ¥2
2.
33Proof. First, combine Lem. 11 and Lem. 12 to write:
Et[Î³t] =Eth
at(L(wt, qâ‹†)âˆ’ L(wâ‹†, qt)âˆ’atÂµ
2âˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’atÎ½
2âˆ¥qtâˆ’qâ‹†âˆ¥2
2i
â‰¤Et
at(qâ‹†âˆ’qt)âŠ¤(â„“(wt)âˆ’vD
t)
| {z }
cross term
+Et[Atâˆ’1Î½âˆ†D(qâ‹†, qtâˆ’1)âˆ’AtÎ½âˆ†D(qâ‹†, qt)]
âˆ’Et"
at
2LnX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2#
+atâˆ’1
4LnX
i=1qtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+nX
i=1aÏ€(tâˆ’2,i)
4LqÏ€(tâˆ’2,i),iâˆ‡â„“i(wÏ€(tâˆ’2,i)âˆ’ âˆ‡â„“i(wâ‹†))2
2
+6nG2Î±atâˆ’1
Âµâˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2
âˆ’atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
+atâˆ’1
âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1âˆ’Ë†gâŠ¤
tâˆ’2Ë†qtâˆ’2, wâ‹†âˆ’wtâˆ’1
âˆ’ÂµAt
2Etâˆ¥wâ‹†âˆ’wtâˆ¥2
2+ÂµCtâˆ’1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2+ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2
âˆ’ÂµCtâˆ’1
4Etâˆ¥wtâˆ’wtâˆ’1âˆ¥2
2âˆ’Atâˆ’1Î½Et[âˆ†D(qt, qtâˆ’1)]
âˆ’atÂµ
2Eth
âˆ¥wtâˆ’wâ‹†âˆ¥2
2i
âˆ’ctâˆ’1Âµ
2tâˆ’2X
Ï„=tâˆ’n/bEtâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2âˆ’atÎ½
2Eith
âˆ¥qtâˆ’qâ‹†âˆ¥2
2i
.
Bound the cross term identified above. In the case that t= 2, use Lem. 4 with vt=vD
t,yt=â„“(wt),
Ë†yt+1=Ë†â„“t,xt=qt,xâ‹†=qâ‹†, and Î³=Î½Atâˆ’1=Î½which yields that
atEt
(qâ‹†âˆ’q2)âŠ¤(â„“(w2)âˆ’vD
2)
â‰¤a2E2
(qâ‹†âˆ’q2)âŠ¤(â„“(wt)âˆ’Ë†â„“2)
âˆ’a1(qâ‹†âˆ’q1)âŠ¤(â„“(w1)âˆ’Ë†â„“1)
+Î½
4E2
âˆ¥q1âˆ’q0âˆ¥2
2
+n2
Î½E21
bP
jâˆˆJt(â„“j(w1)âˆ’Ë†â„“1,j)ej2
2, (48)
where the fourth term above can be bounded as
n2
Î½E21
bP
jâˆˆJt(â„“j(w1)âˆ’Ë†â„“1,j)ej2
2â‰¤nb
Î½1
bPb
j=1(â„“j(w1)âˆ’Ë†â„“1,j)ej2
2â‰¤nG2
Î½âˆ¥w1âˆ’w0âˆ¥2
2.
Using the definition of the update, we have that âˆ¥w1âˆ’w0âˆ¥2
2= (1/Âµ2)âˆ‡â„“(w0)âŠ¤q02
2. In the case
thatt >2, use Lem. 4 as above but instead with Î³=Î½Atâˆ’2which yields that
atEt
(qâ‹†âˆ’qt)âŠ¤(â„“(wt)âˆ’vD
t)
â‰¤atEt
(qâ‹†âˆ’qt)âŠ¤(â„“(wt)âˆ’Ë†â„“t)
âˆ’atâˆ’1(qâ‹†âˆ’qtâˆ’1)âŠ¤(â„“(wtâˆ’1)âˆ’Ë†â„“tâˆ’1)
+Atâˆ’2Î½
4Et
âˆ¥qtâˆ’qtâˆ’1âˆ¥2
2
+n2a2
tâˆ’1
Atâˆ’2Î½Et1
bP
jâˆˆJt(â„“j(wtâˆ’1)âˆ’Ë†â„“tâˆ’1,j)ej2
2| {z }
Etâˆ¥Î´D
tâˆ¥2
2. (49)
We may then apply Lem. 6 and atâˆ’1â‰¤Î±Atâˆ’2to get that
n2a2
tâˆ’1
Atâˆ’2Î½EtÎ´D
t2
2â‰¤natâˆ’1Î±G2
Î½tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wtâˆ’1âˆ’wÏ„âˆ¨0âˆ¥2
2. (50)
We may use strong convexity to get theAtâˆ’2Î½
4Et
âˆ¥qtâˆ’qtâˆ’1âˆ¥2
2
term to cancel with
âˆ’Atâˆ’1Î½
2âˆ†D(qt, qtâˆ’1)and that Atâˆ’2â‰¤Atâˆ’1to complete the proof.
34C.3.3 Determining Constants
In this section, we provide derivations that determine the values of the constant ctthat allow for
cancellation of errors. We slightly adjust the notation in this subsection, in that we assume that for
some Î· >0
atâ‰¤(1 +Î·)atâˆ’1
and determine Î·such that (28) is satisfied. We will see that Î·is simply a constant factor away from
Î±, so the resulting condition we actually be on Î±. The latter is given formally in Lem. 14. We
assume here that n/bâ‰¥2, which is taken as an assumption of Thm. 2.
In the statement of Lem. 13, the lines above (43) will telescope without additional conditions.
For (44), we set ct=at/mfor some parameter m. Note that this condition does not need to
be checked when n/b < 1, as the additional sum term over Ï„will not be included in the update.
Counting all the terms that will appear when matched on the index tâˆ’1, we have the condition that
âˆ’atâˆ’1
4âˆ’Atâˆ’1+Ctâˆ’1+t+n/bâˆ’1X
s=t+1as/mâ‰¤0.
The first term result from the â€œgood termâ€ âˆ’atâˆ’1Âµ
4âˆ¥wtâˆ’1âˆ’wâ‹†âˆ¥2
2from the bottom. The rightmost
term above results because asâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2will have Ï„=tâˆ’1when sâˆˆ {t+1, . . . , t +n/bâˆ’1}.
We will begin by requiring that require that atâ‰¤(1 +Î²)atâˆ’1for all tand some Î² >0, and then
determine Î²below. The condition reads as
4n/bâˆ’4 +m
4matâˆ’1â‰¥(1 +Î²)2
mn/bâˆ’2X
s=0(1 +Î²)satâˆ’1,
which can be summed and represented as
(4n/bâˆ’4 +m)
4â‰¥(1 +Î²)2(1 +Î²)n/bâˆ’1âˆ’1
Î².
Rearranging and taking a logarithm on both sides, this is the same as
lnÎ²(4n/bâˆ’4 +m)
4(1 + Î²)2+ 1
â‰¥(n/bâˆ’1) log(1 + Î²). (51)
Next, using the inequality2x
2+xâ‰¤ln(1 + x)withx=Î²(4n/bâˆ’4+m)
4(1+Î²)2 which holds for all xâ‰¥0, we
have
lnÎ²(4n/bâˆ’4 +m)
4(1 + Î²)2+ 1
â‰¥2Î²(4n/bâˆ’4+m)
4(1+Î²)2
2 +Î²(4n/bâˆ’4+m)
4(1+Î²)2=2Î²(4n/bâˆ’4 +m)
8(1 + Î²)2+Î²(4n/bâˆ’4 +m)(52)
We can also apply the upper bound ln(x+ 1)â‰¤xwithx=Î²(which also holds for any xâ‰¥0) to
write
(n/bâˆ’1) log(1 + Î²)â‰¤(n/bâˆ’1)Î²,
which means that (51) will be satisfied (using (52)) if
2Î²(4n/bâˆ’4 +m)
8(1 + Î²)2+Î²(4n/bâˆ’4 +m)â‰¥(n/bâˆ’1)Î² (53)
â‡â‡’n/bâˆ’1 +m/4
n/bâˆ’1â‰¥(1 +Î²)2+ (Î²/2)(n/bâˆ’1 +m/4). (54)
35In order to satisfy the inequality, substitute m= 4cÎ²(n/bâˆ’1)2for some c >0to be determined
and assume that Î²â‰¤1
n/bâˆ’1, so that Î²(n/bâˆ’1)â‰¤1. The LHS reads as
n/bâˆ’1 +m/2
n/bâˆ’1= 1 + cÎ²(n/bâˆ’1).
The RHS can be upper-bounded as
(1 +Î²)2+ (Î²/2)(n/bâˆ’1 +m/4) = (1 + Î²)2+ (Î²/2)(n/bâˆ’1 +cÎ²(n/bâˆ’1)2)
â‰¤1 +Î²(2 +Î²) +Î²(n/bâˆ’1)1 +c
2,
which makes the inequality satisfied when
câ‰¥24 + 2 Î²
n/bâˆ’1+ 1
,
so we can set c= 16 . We now have the flexibility to control Î², and the telescoping of (44) is
achieved. For (45), set Î²=Î±
4and pass the condition of Î²â‰¤1/(n/bâˆ’1)ontoÎ±, which maintains
the rate (and is already satisfied when Î±â‰¤b
nandnâ‰¥2). Then, we can achieve
natÎ±G2
Î½â‰¤Âµatâˆ’1
m=Âµatâˆ’1
4Î±(n/bâˆ’1)2
by requiring that Î±â‰¤bâˆšÂµÎ½
4n3/2G, which achieves the telescoping of (45). Finally, to address (46), we
may satisfy it if
natÎ±G2
Î½â‰¤ÂµCtâˆ’1
4
which we can achieve by incorporating the condition atâ‰¤4Î±(n/bâˆ’1)2Ctâˆ’1into the update of
at, becausenatÎ±G2
Î½â‰¤Âµat
mby the previous condition on Î±. Having chosen ct, we are prepared to
produce a learning rate parameter Î·to capture all conditions on Î±in one, as given in Lem. 14.
Lemma 14. For all tâ‰¥1, we have the following.
â€¢Setting ct=at/[16Î±(n/bâˆ’1)2]implies that atâ‰¤2Î±Ct.
â€¢Using the update scheme
a2= 4Î·a1,andat= (1 + Î·)atâˆ’1fort >2,
when
Î·=1
4min(
b
32n,Âµ
24eLÎºQ,b
ns
nG2
ÂµÎ½)
.
we have that (28) holds.
Proof. Noting that m= 16Î±(n/bâˆ’1)2we confirm that
Ctâ‰¥Atâˆ’1/2
â‡â‡’ Atâˆ’1
16Î±(n/bâˆ’1)atâ‰¥Atâˆ’1/2
â‡â‡’
1âˆ’1
16Î±(n/bâˆ’1)
atâ‰¥ âˆ’Atâˆ’1/2
â‡â‡’ 21
16Î±(n/bâˆ’1)âˆ’1
atâ‰¤Atâˆ’1.
This condition is satisfied when Î±â‰¤1
32(n/bâˆ’1), so we incorporate Î±â‰¤b
32ninto the rate, implying
thatatâ‰¤2Î±Ct. This concludes the proof of the first bullet point.
36Next, we show that atâ‰¤(1+Î±/4)atâˆ’1will imply that atâ‰¤Î±Atâˆ’1, which is the second part of (28).
First, we define a2=Î±a1as an initialization (which also satisfies a2â‰¤(1+Î±/4)a1when Î±â‰¤4/3),
and show inductively that if atâˆ’1â‰¤Î±Atâˆ’2, then atâ‰¤(1 +Î±/4)atâˆ’1=â‡’atâ‰¤Î±Atâˆ’1. In the
base case, A1=a1, so the condition a2=Î±a1satisfies a2â‰¤Î±A1. Next, fixing tand assuming
that 1) atâˆ’1â‰¤Î±Atâˆ’2and 2) that atâ‰¤(1 +Î±/4)atâˆ’1, we have that
Î±Atâˆ’1=Î±(atâˆ’1+Atâˆ’2)â‰¥(Î±+ 1)atâˆ’1â‰¥at,
the desired result. Finally, we consider the condition atâ‰¤4Î±(n/bâˆ’1)2Ctâˆ’1, the third part of (28).
We wish to show that the following inequality holds:
atâ‰¤4Î±(n/bâˆ’1)2Ctâˆ’1= 4Î±(n/bâˆ’1)2
Atâˆ’1âˆ’1
4Î±(n/bâˆ’1)atâˆ’1
= 4Î±(n/bâˆ’1)2
atâˆ’1+Atâˆ’2âˆ’1
4Î±(n/bâˆ’1)atâˆ’1
which is implied by the inequality
atâ‰¤4Î±(n/bâˆ’1)2
atâˆ’1+ (1/Î±)atâˆ’1âˆ’1
4Î±(n/bâˆ’1)atâˆ’1
= 4(n/bâˆ’1)2
Î±+ 1âˆ’1
4(n/bâˆ’1)
atâˆ’1.
When n/bâ‰¥2, we have that (1 + Î±/4)â‰¤4(n/bâˆ’1)2
Î±+ 1âˆ’1
4(n/bâˆ’1)
, so we require that
bâ‰¤n/2. Thus, our final updates are given by
a2= 4Î·a1â‰¤(1 +Î·)a1andat= (1 + Î·)atâˆ’1fort >2.
Because each condition was satisfied when using at= (1+ Î±/4)atâˆ’1, we define Î·=Î±/4to achieve
the claimed result.
C.3.4 Bound on Sum of Successive Gaps
Lem. 15 is an upper estimate for the expected sum of the gap function over Titerates. Recall
thatE1[Â·]the full expectation over {(It, Jt)}T
t=1. The green term is a quantity that remain as an
initialization term, whereas the blue terms have to be bounded from above. The terms directly
below the blue terms account for all of the â€œnegative Ï€(tâˆ’1, i)â€ terms are not yet used up by the
telescoping in lines (39), (40), and (41), and there are in fact between 1andncopies of those terms
in each iteration, even though we will use only 1.
Lemma 15 (Progress Bound) .Assume that
Î±â‰¤minb
32n,Âµ
24eLÎºQ,b
36e2nrÂµÎ½
nG2
.
37For any Tâ‰¥1, we have that
E0"TX
t=1Î³t#
â‰¤nG2
Î½Âµ2âˆ‡â„“(w0)âŠ¤q02
2
+aTE0h
(qâ‹†âˆ’qT)âŠ¤(â„“(wT)âˆ’Ë†â„“T)i
(55)
âˆ’aTE0
âˆ‡â„“(wT)âŠ¤qTâˆ’Ë†gâŠ¤
Tâˆ’1Ë†qTâˆ’1, wâ‹†âˆ’wT
(56)
âˆ’nX
i=1(nâˆ’T+Ï€(Tâˆ’1, i))aÏ€(Tâˆ’1,i)
4LE0h
qÏ€(Tâˆ’1,i)âˆ‡â„“i(wÏ€(Tâˆ’1,i))âˆ’ âˆ‡â„“i(wâ‹†)2
2i
(57)
+6nG2Î±
ÂµE0TX
t=1atâˆ’1âˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2âˆ’TX
t=1Atâˆ’1Î½
2E0[D(qtâˆ¥qtâˆ’1)] (58)
âˆ’aT
2LnX
i=1E0h
qT,iâˆ¥âˆ‡â„“i(wT)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2i
âˆ’ÂµAT
2E0h
âˆ¥wâ‹†âˆ’wTâˆ¥2
2i
(59)
âˆ’ÂµaTâˆ’1
2[16Î±(n/bâˆ’1)]Tâˆ’2X
Ï„=Tâˆ’âŒˆn/bâŒ‰E0h
âˆ¥wTâˆ’wÏ„âˆ¨0âˆ¥2
2i
(60)
âˆ’ATÎ½E0[D(qâ‹†âˆ¥qT)] (61)
âˆ’TX
t=1atÂµ
4Eâˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’TX
t=1atÎ½
2E0âˆ¥qtâˆ’qâ‹†âˆ¥2
2. (62)
Proof. We proceed by first deriving an upper bound on Î³1, the gap function for t= 1. Note that w1
is non-random, as a0= 0implies that v0=âˆ‡â„“(w0). Using that w1is the optimum for the proximal
operator that defines it, the upper bound can be written as
a1L(w1, qâ‹†)â‰¤a1qâ‹†âŠ¤(â„“(w1)âˆ’Ë†â„“1) +a1Âµ
2âˆ¥w1âˆ¥2
2+a1q1âŠ¤Ë†â„“1âˆ’a1Î½D(q1||q0)âˆ’A1Î½âˆ†D(qâ‹†, q1),
where we use that Ëœâ„“1=Ë†â„“1. For the lower bound, use a similar argument to Lem. 11 to achieve
a1L(wâ‹†, q1)â‰¥a1qâŠ¤
1â„“(w1) +a1
âˆ‡â„“(w1)âŠ¤q1âˆ’ âˆ‡â„“(w0)âŠ¤q0, wâ‹†âˆ’w1
+a1Âµ
2âˆ¥w1âˆ¥2
2
âˆ’a1Î½D(q1||q0) +a1
2LnX
i=1q1,iâˆ¥âˆ‡â„“i(w1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+ÂµA1
2âˆ¥wâ‹†âˆ’w1âˆ¥2
2,
where we use that vP
0=âˆ‡â„“(w0)âŠ¤q0. We combine them to get
Î³1â‰¤a1(qâ‹†âˆ’q1)âŠ¤(â„“(w1)âˆ’Ë†â„“1)âˆ’a1
âˆ‡â„“(w1)âŠ¤q1âˆ’ âˆ‡â„“(w0)âŠ¤q0, wâ‹†âˆ’w1
âˆ’a1
2LnX
i=1q1,iâˆ¥âˆ‡â„“i(w1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2âˆ’ÂµA1
2âˆ¥wâ‹†âˆ’w1âˆ¥2
2âˆ’A1Î½âˆ†D(qâ‹†, q1)
âˆ’a1Âµ
2âˆ¥w1âˆ’wâ‹†âˆ¥2
2âˆ’a1Î½
2âˆ¥q1âˆ’qâ‹†âˆ¥2
2,
where the last two terms are the result of the additional quadratic slack terms in Î³1. All of
the terms from the display above will be telescoped. Thus, we apply Lem. 13 and collect
the unmatched terms from the tâ‰¥2one-step bound (using that A0= 0 ). The term (57)
can be viewed as counting the remainder of (40) after it has telescoped some but not all terms
aÏ€(Tâˆ’1,i)
4LE0h
qÏ€(Tâˆ’1,i)âˆ‡â„“i(wÏ€(Tâˆ’1,i))âˆ’ âˆ‡â„“i(wâ‹†)2
2i
across iterations.
38C.3.5 Completing the Proof
We use similar techniques as before to bound the remaining terms from the T-step progress bound
given in Lem. 15. We may now prove the main result.
Theorem 2. For a constant Î± >0, define the sequence
a1= 1, a2= 4Î±,andat= (1 + Î±)atâˆ’1fort >2,
along with its partial sum At=Pt
Ï„=1aÏ„. Under Asm. 1, there is an absolute constant Csuch that
using the parameter
Î±=Cminb
n,Âµ
LÎºQ,b
nrÂµÎ½
nG2
,
the iterates of Algorithm 1 satisfy:
TX
t=1atE1[Î³t] +ATÂµ
4E1âˆ¥wTâˆ’wâ‹†âˆ¥2
2+ATÎ½
4E1âˆ¥qTâˆ’qâ‹†âˆ¥2
2â‰¤nG2
Î½âˆ¥w0âˆ’w1âˆ¥2
2.
We can compute a point (wT, qT)achieving an expected gap no more than Îµwith big- Ocomplexity
(n+bd)Â· 
n
b+LÎºQ
Âµ+n
bs
nG2
ÂµÎ½!
Â·ln1
Îµ
. (10)
Proof. We first apply Lem. 15, and proceed to bound the inner product terms (55) and (56). Apply
Youngâ€™s inequality with parameter Î½ATâˆ’1/2to get
aTE0h
(qâ‹†âˆ’qT)âŠ¤(â„“(wT)âˆ’Ë†â„“T)i
â‰¤Î½ATâˆ’1
4E0âˆ¥qâ‹†âˆ’qTâˆ¥2
2+a2
T
Î½ATâˆ’1E0âˆ¥â„“(wT)âˆ’Ë†â„“Tâˆ¥2
2
â‰¤Î½ATâˆ’1
4E0âˆ¥qâ‹†âˆ’qTâˆ¥2
2+a2
TG2
Î½ATâˆ’1Tâˆ’2X
Ï„=Tâˆ’n/bE0âˆ¥wTâˆ’wÏ„âˆ¨0âˆ¥2
2
â‰¤Î½ATâˆ’1
4E0âˆ¥qâ‹†âˆ’qTâˆ¥2
2+aTÎ±G2
Î½Tâˆ’2X
Ï„=Tâˆ’n/bE0âˆ¥wTâˆ’wÏ„âˆ¨0âˆ¥2
2.
The left-hand term will be canceled by (61) by applying strong concavity (leaving behind
âˆ’Î½ATâˆ’1
4E0âˆ¥qâ‹†âˆ’qTâˆ¥2
2) and the right-hand term (because of the condition Î±â‰¤âˆšÂµÎ½
4n3/2G) will be
canceled by (60). Next, consider (56). By Youngâ€™s inequality with parameter ÂµATâˆ’1/2, we have
âˆ’aTE0
âˆ‡â„“(wT)âŠ¤qTâˆ’Ë†gâŠ¤
Tâˆ’1Ë†qTâˆ’1, wâ‹†âˆ’wT
â‰¤a2
T
ÂµATâˆ’1E0âˆ‡â„“(wT)âŠ¤qTâˆ’Ë†gâŠ¤
Tâˆ’1Ë†qTâˆ’12
2+ÂµATâˆ’1
4E0âˆ¥wâ‹†âˆ’wTâˆ¥2
2
â‰¤aTÎ±
ÂµE0âˆ‡â„“(wT)âŠ¤qTâˆ’Ë†gâŠ¤
Tâˆ’1Ë†qTâˆ’12
2+ÂµATâˆ’1
4E0âˆ¥wâ‹†âˆ’wTâˆ¥2
2,
where the second term will be canceled by (59). For the remaining term,
E0âˆ‡â„“(wT)âŠ¤qTâˆ’Ë†gâŠ¤
Tâˆ’1Ë†qTâˆ’12
2
â‰¤E0(âˆ‡â„“(wT)âˆ’â„“(wâ‹†))âŠ¤qT+âˆ‡â„“(wâ‹†)âŠ¤(qTâˆ’Ë†qTâˆ’1) + (âˆ‡â„“(wâ‹†)âˆ’Ë†gTâˆ’1)âŠ¤Ë†qTâˆ’12
2
â‰¤3E0(âˆ‡â„“(wT)âˆ’ âˆ‡â„“(wâ‹†))âŠ¤qT2
2+ 3E0âˆ‡â„“(wâ‹†)âŠ¤(qTâˆ’Ë†qTâˆ’1)2
2+ 3E0(âˆ‡â„“(wâ‹†)âˆ’Ë†gTâˆ’1)âŠ¤Ë†qTâˆ’12
2
â‰¤3ÏƒnnX
i=1E0h
qT,iâˆ¥âˆ‡â„“i(wT)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2i
+ 3nG2E0âˆ¥qTâˆ’Ë†qTâˆ’1âˆ¥2
2+ 3ÏƒnnX
i=1E0h
Ë†qTâˆ’1,iâˆ¥âˆ‡â„“i(wâ‹†)âˆ’Ë†gTâˆ’1,iâˆ¥2
2i
39We may add the middle term above to (58), so that the remaining term to bound is
6nG2Î±
ÂµT+1X
t=1atâˆ’1E0âˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2âˆ’TX
t=1Atâˆ’1Î½
2E0[âˆ†D(qt, qtâˆ’1)].
To show that this quantity is non-negative, we use that a0= 0and Lem. 10 (recalling that M=n/b
to see that
6nG2Î±
ÂµE0T+1X
t=1atâˆ¥qtâˆ’Ë†qtâˆ’1âˆ¥2
2â‰¤18e2n3G2Î±
b2ÂµE0T+1X
t=1atâˆ’1âˆ¥qtâˆ’qtâˆ’1âˆ¥2
2â‰¤18e2n3G2Î±2
b2ÂµE0TX
t=1Atâˆ’1âˆ¥qtâˆ’qtâˆ’1âˆ¥2
2,
which will cancel with the rightmost term in (58) provided that Î±â‰¤b
36e2npÂµÎ½
nG2. Thus, plugging
the previous displays into Lem. 15, we have that
E0"TX
t=1Î³t#
â‰¤n2G2
Î½Âµ2âˆ‡â„“(w0)âŠ¤q02
2
+3aTÏƒnÎ±
2ÂµnX
i=1E0h
qT,iâˆ¥âˆ‡â„“i(wT)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2i
âˆ’aT
2LnX
i=1E0h
qT,iâˆ¥âˆ‡â„“i(wT)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2i
+3ÏƒnaTÎ±
2ÂµnX
i=1E0h
qÏ€(Tâˆ’1,i),iâˆ‡â„“i(wâ‹†)âˆ’ âˆ‡â„“i(wÏ€(Tâˆ’1,i))2
2i
âˆ’nX
i=1(nâˆ’T+Ï€(Tâˆ’1, i))aÏ€(Tâˆ’1,i)
4LE0h
qÏ€(Tâˆ’1,i)âˆ‡â„“i(wÏ€(Tâˆ’1,i))âˆ’ âˆ‡â„“i(wâ‹†)2
2i
âˆ’TX
t=1atÂµ
4E0âˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’TX
t=1atÎ½
4E0âˆ¥qtâˆ’qâ‹†âˆ¥2
2
âˆ’ATâˆ’1Âµ
4E0âˆ¥wTâˆ’wâ‹†âˆ¥2
2âˆ’ATâˆ’1Î½
4E0âˆ¥qTâˆ’qâ‹†âˆ¥2
2.
The black lines will cancel given our conditions on Î±. Substituting the definition of Î³tand
moving the final non-positive terms on the last line, that is,(ATâˆ’1+aT)Âµ
4E0âˆ¥wTâˆ’wâ‹†âˆ¥2
2and
(ATâˆ’1+aT)Î½
4E0âˆ¥qTâˆ’qâ‹†âˆ¥2
2to the left-hand side achieves the claim.
C.4 Modification for Unregularized Objectives
For completeness, we describe a modification of DRAGO for unregularized objectives, or (2) when
Âµâ‰¥0andÎ½â‰¥0. The analysis follows similarly to the previous subsections (regarding the Âµ, Î½ > 0
case), and we highlight the steps that differ in this subsection by presenting a slightly different upper
bound on the gap criterion based on the modified primal and dual updates. This will result a different
update for the sequence (at)tâ‰¥1, subsequently affecting the rate.
C.4.1 Overview
The modified algorithm is nearly identical to Algorithm 1, except that the dual and primal updates
can be written as
qt:= arg max
qâˆˆQat
vD
t, q
âˆ’atÎ½D(qâˆ¥q0)âˆ’(Î½Atâˆ’1+Î½1)âˆ†D(q, qtâˆ’1) (63)
and
wt:= arg min
wâˆˆWat
vP
t, w
+atÂµ
2âˆ¥wâˆ¥2
2+Ctâˆ’1Âµ+Âµ1
2âˆ¥wâˆ’wtâˆ’1âˆ¥2
2+ctâˆ’1Âµ+Âµ2
2tâˆ’2X
s=tâˆ’n/bâˆ¥wâˆ’wsâˆ¨0âˆ¥2
2,
(64)
respectively, and Âµ1, Âµ2, Î½1â‰¥0are to-be-set hyperparameters. When Î½ >0, we may set Î½1= 0,
and when Âµ >0, we may set Âµ1=Âµ2= 0, which recover the Algorithm 1 updates exactly. While
40we may set Î½1= 1 when it is positive (and similarly for Âµ1andÂµ2), they may be set to different
values in order to balance the terms appearing in the rate below. As in Appx. C.1, we wish to upper
bound the expectation of the quantity
Î³t=at
L(wt, qâ‹†)âˆ’ L(wâ‹†, qt)âˆ’Âµ
2âˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’Î½
2âˆ¥qtâˆ’qâ‹†âˆ¥2
2
(65)
which is still non-negative in the case of Âµ= 0 orÎ½= 0. By using an appropriate averaging
sequence (at)tâ‰¥1and defining AT=PT
t=1at, we upper boundPT
t=1atE0[Î³t](see Thm. 2) by
a constant value independent of T. Recall that the batch size is denoted by b. As we derive in
Appx. C.4.3, our final update on the (at)sequence is
at= min(
Ctâˆ’1Âµ+Âµ1
12enqmaxL,
1 +b
n
atâˆ’1,b
32np
(Atâˆ’1Î½+Î½1) min{Ctâˆ’1Âµ+Âµ1, ctâˆ’1Âµ+Âµ2}âˆšnG)
.
Observe that when Âµ= 0, we set at=Âµ1
12enqmaxLto achieve a O(1/t)rate. We omit proofs in this
subsection as they follow with the exact same steps as the corresponding lemmas in the strongly
convex-strongly concave setting (which we point to for each result).
C.4.2 Upper Bound on Gap Criterion
Following the steps of Appx. C.3.1 and Appx. C.3.2, we will first derive lower and upper bounds on
Et[atL(wâ‹†, qt)]andatL(wt, qâ‹†)and combine them to upper bound atEt[Î³t]. Recalling that Et[Â·]
denotes the condition expectation given (wtâˆ’1, qtâˆ’1), and we can then take the marginal expectation
to upper bound atE0[Î³t]. The following lower bound is analogous to Lem. 11 and follows the exact
same proof technique.
Lemma 16. Fortâ‰¥2, assuming that atâ‰¤Ctâˆ’1Âµ+Âµ1
12enqmaxLandatâ‰¤(1 +b/n)atâˆ’1, we have that:
âˆ’Et[atL(wâ‹†, qt)]
â‰¤ âˆ’atEt[qâŠ¤
tâ„“(wt)]âˆ’at
2LnX
i=1qt,iEtâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+atÂµ
2âˆ¥wtâˆ¥2
2
+atâˆ’1
4LnX
i=1qtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+nX
i=1aÏ€(tâˆ’2,i)
4LqÏ€(tâˆ’2,i),iâˆ‡â„“i(wÏ€(tâˆ’2,i)âˆ’ âˆ‡â„“i(wâ‹†))2
2
+3nG2a2
tâˆ’1
Ctâˆ’1Âµ+Âµ1âˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2
âˆ’atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
+atâˆ’1
âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1âˆ’Ë†gâŠ¤
tâˆ’2Ë†qtâˆ’2, wâ‹†âˆ’wtâˆ’1
+atÎ½Et[D(qt||q0)]âˆ’AtÂµ+Âµ1+Âµ2
2Etâˆ¥wâ‹†âˆ’wtâˆ¥2
2
âˆ’Ctâˆ’1Âµ+Âµ1
4âˆ¥wtâˆ’wtâˆ’1âˆ¥2
2+Ctâˆ’1Âµ+Âµ1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2
âˆ’ctâˆ’1Âµ+Âµ2
2tâˆ’2X
Ï„=tâˆ’n/bEtâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2+ctâˆ’1Âµ+Âµ2
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2.
Similarly, following the same steps as Lem. 12, one can derive the following upper bound.
Lemma 17. Fortâ‰¥2, we have that:
atL(wt, qâ‹†)â‰¤atqâ‹†âŠ¤(â„“(wt)âˆ’vD
t) + (Atâˆ’1Î½+Î½1)âˆ†D(qâ‹†, qtâˆ’1)
+atqtâŠ¤vD
tâˆ’atÎ½D(qt||q0)âˆ’(Atâˆ’1Î½+Î½1)âˆ†D(qt, qtâˆ’1)âˆ’(AtÎ½+Î½1)âˆ†D(qâ‹†, qt).
By combining Lem. 17 and Lem. 16, we can upper bound the quantity
Et[at(L(wt, qâ‹†)âˆ’ L(wâ‹†, qt)]. Consequently, the following result follows the same steps as
Lem. 13. As before, we identify telescoping terms in blue, non-positive terms in red, where green
term is bounded after aggregation across time t.
41Lemma 18. Assume that atâˆ’1â‰¤Ctâˆ’1Âµ+Âµ1
12eLnq maxandatâ‰¤(1 +b/n)atâˆ’1. For t >2, we have that:
Et[Î³t] =Eth
at(L(wt, qâ‹†)âˆ’ L(wâ‹†, qt)âˆ’atÂµ
2âˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’atÎ½
2âˆ¥qtâˆ’qâ‹†âˆ¥2
2i
â‰¤atEt
(qâ‹†âˆ’qt)âŠ¤(â„“(wt)âˆ’Ë†â„“t)
âˆ’atâˆ’1(qâ‹†âˆ’qtâˆ’1)âŠ¤(â„“(wtâˆ’1)âˆ’Ë†â„“tâˆ’1) (66)
+(Atâˆ’1Î½+Î½1)âˆ†D(qâ‹†, qtâˆ’1)âˆ’(AtÎ½+Î½1)Et[âˆ†D(qâ‹†, qt)] (67)
âˆ’at
2LEt"nX
i=1qt,iâˆ¥âˆ‡â„“i(wt)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2#
(68)
+atâˆ’1
4LnX
i=1qtâˆ’1,iâˆ¥âˆ‡â„“i(wtâˆ’1)âˆ’ âˆ‡â„“i(wâ‹†)âˆ¥2
2+nX
i=1aÏ€(tâˆ’2,i)
4LqÏ€(tâˆ’2,i),iâˆ‡â„“i(wÏ€(tâˆ’2,i)âˆ’ âˆ‡â„“i(wâ‹†))2
2
(69)
âˆ’atEt
âˆ‡â„“(wt)âŠ¤qtâˆ’Ë†gâŠ¤
tâˆ’1Ë†qtâˆ’1, wâ‹†âˆ’wt
+atâˆ’1
âˆ‡â„“(wtâˆ’1)âŠ¤qtâˆ’1âˆ’Ë†gâŠ¤
tâˆ’2Ë†qtâˆ’2, wâ‹†âˆ’wtâˆ’1
(70)
+3nG2a2
tâˆ’1
Ctâˆ’1Âµ+Âµ1âˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2(71)
âˆ’AtÂµ+Âµ1+Âµ2(n/bâˆ’1)
2Etâˆ¥wâ‹†âˆ’wtâˆ¥2
2+Âµ1
2âˆ¥wâ‹†âˆ’wtâˆ’1âˆ¥2
2+ctâˆ’1Âµ+Âµ2
2tâˆ’2X
Ï„=tâˆ’n/bâˆ¥wâ‹†âˆ’wÏ„âˆ¨0âˆ¥2
2
(72)
+na2
tâˆ’1G2
Atâˆ’2Î½+Î½1tâˆ’3X
Ï„=tâˆ’n/bâˆ¥wtâˆ’1âˆ’wÏ„âˆ¨0âˆ¥2
2âˆ’ctâˆ’1Âµ+Âµ2
2tâˆ’2X
Ï„=tâˆ’n/bEtâˆ¥wtâˆ’wÏ„âˆ¨0âˆ¥2
2(73)
+na2
tâˆ’1G2
Atâˆ’2Î½+Î½1âˆ¥wtâˆ’1âˆ’wtâˆ’2âˆ¥2
2âˆ’Ctâˆ’1Âµ+Âµ1
4Etâˆ¥wtâˆ’wtâˆ’1âˆ¥2
2(74)
âˆ’atÂµ
2âˆ¥wtâˆ’wâ‹†âˆ¥2
2âˆ’atÎ½
2Etâˆ¥qtâˆ’qâ‹†âˆ¥2
2âˆ’Atâˆ’1Î½+Î½1
2Et[âˆ†D(qt, qtâˆ’1)]. (75)
Fort= 2, the above holds with the addition of the termnG2
Î½+Î½1âˆ¥w1âˆ’w0âˆ¥2
2and without any term
including Atâˆ’2in the denominator.
We then select constants to achieve the desired telescoping in each line of Lem. 18.
C.4.3 Determining Constants
We now select the constants (Âµ1, Âµ2, Î½1), and the sequences (at)and(ct)to complete the main part
of the analysis.
In the statement of Lem. 18, the lines above (71) will telescope without additional conditions.
For (72), we set ct=at/mfor some parameter m(just as in Appx. C.3.3). Note that this con-
dition does not need to be checked when n/b < 1, as the additional sum term over Ï„will not be
included in the update. Counting all the terms that will appear when matched on the index tâˆ’1, we
have the condition that
Âµï£®
ï£°âˆ’atâˆ’1
4âˆ’Atâˆ’1+Ctâˆ’1+t+n/bâˆ’1X
s=t+1as/mï£¹
ï£»
| {z }
â‰¤0+âˆ’(Âµ1+Âµ2(n/bâˆ’1)) + Âµ1+ (n/bâˆ’1)Âµ2| {z }
=0â‰¤0,
where the first underbrace is non-positive based on the choice of mselected in Appx. C, and the
equality is satisfied for all values of Âµ1andÂµ2. Lines (73) and (74) yield the conditions
na2
tG2
Atâˆ’1Î½+Î½1â‰¤Ctâˆ’1Âµ+Âµ1
4andna2
tG2
Atâˆ’1Î½+Î½1â‰¤ctâˆ’1Âµ+Âµ2
2. (76)
42for the telescoping to be achieved, which can equivalently be rewritten as
atâ‰¤r
(Atâˆ’1Î½+Î½1)(Ctâˆ’1Âµ+Âµ1)
4nG2andatâ‰¤r
(Atâˆ’1Î½+Î½1)(ctâˆ’1Âµ+Âµ2)
2nG2(77)
These can be accomplished by setting
atâ‰¤p
(Atâˆ’1Î½+Î½1) min{Ctâˆ’1Âµ+Âµ1, ctâˆ’1Âµ+Âµ2}
2âˆšnG.
We must also handle the term3nG2a2
tâˆ’1
Ctâˆ’1Âµ+Âµ1âˆ¥qtâˆ’1âˆ’Ë†qtâˆ’2âˆ¥2
2. By the argument of Lem. 10 using a2
t
instead of at, we have that when summing over t, we have that
TX
t=13nG2a2
t
Âµtâˆ¥qtâˆ’Ë†qtâˆ’1âˆ¥2
2â‰¤3nG2
Ctâˆ’1Âµ+Âµ1Â·3e4M2TX
t=1a2
tâˆ¥qtâˆ’qtâˆ’1âˆ¥2
2
â‰¤512nG2M2
Ctâˆ’1Âµ+Âµ1TX
t=1a2
tâˆ¥qtâˆ’qtâˆ’1âˆ¥2
2
where M=n/bis the number of blocks, and the e4term appears from the squared constants (as
opposed to e2). Using that we will sum the non-positive termsPT
t=1Atâˆ’1Î½Et[âˆ†D(qt, qtâˆ’1,]), so
that the final condition needed to cancel this term is
512nG2M2
Ctâˆ’1Âµ+Âµ1a2
tâ‰¤Atâˆ’1Î½+Î½1
2
which can also be rewritten as
atâ‰¤1
32Mr
(Atâˆ’1Î½+Î½1)(Ctâˆ’1Âµ+Âµ1)
nG2
Thus, combining the previous conditions, our final update on the (at)sequence is
at= min(
Ctâˆ’1Âµ+Âµ1
12enqmaxL,
1 +b
n
atâˆ’1,b
32np
(Atâˆ’1Î½+Î½1) min{Ctâˆ’1Âµ+Âµ1, ctâˆ’1Âµ+Âµ2}âˆšnG)
,
as alluded to in Appx. C.4.1.
43D Implementation Details
In this section, we provide additional background on implementing DRAGO in practice. This in-
volves a description of the algorithm amenable for direct translation into code and procedures for
computing the dual proximal mapping for common uncertainty sets and penalties. We assume in
this section that W=Rdand provide multiple options for the uncertainty set Q.
D.1 Algorithm Description
The full algorithm is given in Algorithm 2. We first describe the notation. Recall that M=n/b, or
the number of blocks. We partition [n]into(B1, . . . , B M), where each BKdenotes a b-length list
of contiguous indices. For any matrix uâˆˆRnÃ—m(including m= 1), we denote by u[BK]âˆˆRbÃ—m
the rows of ucorresponding to the indices in BK. Finally, for a vector sâˆˆRb, we denote by seBK
the vector that contains skin indices kâˆˆBK, and has zeros elsewhere. Next, we comment on
particular aspects regarding the implementation version as compared to Algorithm 1 (Sec. 2).
â€¢ We store two versions of each table, specifically Ë†â„“,Ë†â„“1âˆˆRn,Ë†g1,Ë†g2âˆˆRnÃ—d, and Ë†q1,Ë†q2âˆˆ
Rn. For any iterate t, these variables are meant to store Ë†â„“t,Ë†â„“tâˆ’1âˆˆRn,Ë†gtâˆ’1,Ë†gtâˆ’2âˆˆRnÃ—d,
andË†qtâˆ’1,Ë†qtâˆ’2âˆˆRn.
â€¢ The quantities Ë†gaggâˆˆRdandË†waggâˆˆRdare introduced as to not recompute the sums in
the primal update on each iteration (which would cost O(nd)operations). Instead, these
aggregates are updated using O(bd)operations.
â€¢ The loss and gradient tables are not updated immediately after the primal update. However,
the values that fill the tables are computed, and the update occurs at the end of the loop.
This is because Ë†â„“[BKt]is used to fill Ë†â„“1[BKt]at the end of the loop, we we must maintain
knowledge of Ë†â„“[BKt]temporarily.
â€¢ While the proximal operator is specified for the primal in the case of W=Rd, the proximal
operator for the dual os computed by a subroutine DualProx , which we describe in the next
subsection.
D.2 Solving the Maximization Problem
As discussed in Appx. B, the primary examples of DRO uncertainty sets Qare balls in f-divergence
(specifically, KL and Ï‡2) and spectral risk measure sets. For the penalty D, it is also common to
usef-divergences. We review these concepts in this section and provide recipes for computing the
maximization problem.
f-Divergences We first recall the definition of f-divergences used throughout this section.
Definition 19. Letf: [0,âˆ)7â†’Râˆª{+âˆ}be a convex function such that f(1) = 0 ,f(x)is finite
forx > 0, and limxâ†’0+f(x) = 0 . Let qandÂ¯qbe two probability mass functions defined on n
atoms. The f-divergence from qtoÂ¯qgenerated by this function fis given by
Df(qâˆ¥Â¯q) :=nX
i=1fqi
Â¯qi
Â¯qi,
where we define 0f(0/0) := 0 . For any isuch that Â¯qi= 0butqi>0, we define Df(qâˆ¥Â¯q) =: + âˆ.
The two running examples we use are the Ï‡2-divergence generated by fÏ‡2(x) =x2âˆ’1and the
KL divergence generated by fKL(x) =xlnxon(0,âˆ)and define 0 ln 0 = 0 . For any convex set
X âŠ†Rk, we also introduce the convex indicator function
Î¹X(x) :=0ifxâˆˆ X
1otherwise.
In either of the two cases below, we select the penalty D(qâˆ¥1/n) = Df(qâˆ¥1/n)to be an f-
divergence. Denote in addition fâˆ—as the Fenchel conjugate of f.
44Algorithm 2 DRAGO : Implementation Version
Input: Learning rate parameter Î± >0, batch size bâˆˆ {1, . . . , n }, number of iterations T.
Initialization:
wâ†0dandqâ†1/n
Ë†â„“â†â„“(w),Ë†â„“1â†â„“(w),Ë†g1â† âˆ‡â„“(w),Ë†g2â† âˆ‡â„“(w),Ë†q1â†qandË†q2â†q
Ë†wKâ†wforKâˆˆ {1, . . . , M }forM=n/b
Ë†gaggâ†Ë†gâŠ¤
1Ë†q1andË†waggâ†PM
K=1Ë†wK
Â¯Î²= 1/[16Î±(1 +Î±)(n/bâˆ’1)2]ifn/b > 1and0otherwise
fort= 1toTdo
Sample blocks ItandJtuniformly on [n/b]and compute Kt=tmod ( n/b) + 1
Î²tâ†(1âˆ’(1 +Î±)1âˆ’t)/(Î±(1 +Î±))
Primal Update:
gâ†[âˆ‡â„“i(w)]iâˆˆBItâˆˆRbÃ—dandvPâ†Ë†gagg+1
1+Î±Î´P.
wâ†1
(1+Î²t) 
(Î²tâˆ’Â¯Î²(Mâˆ’1))w+Â¯Î²( Ë†waggâˆ’Ë†wKt)âˆ’vP/Âµ
Ë†waggâ†Ë†wagg+wâˆ’Ë†wKtandË†wKtâ†w
Compute Loss and Gradient Table Updates:
(lt, gt)â†[â„“k(w),âˆ‡â„“k(w)]kâˆˆBKtâˆˆRbÃ—RbÃ—d
Dual Update:
lâ†[â„“j(w)]jâˆˆBJtâˆˆRb
Î´Dâ†M(lâˆ’Ë†â„“1[Jt])andvDâ†Ë†â„“+ (lâˆ’Ë†â„“[BKt])eBKt+1
1+Î±Î´DeBJt
qâ†DualProx( q, vD, Î²t) = arg maxÂ¯qâˆˆQ
vD,Â¯q
âˆ’Î½D(Â¯qâˆ¥1n/n)âˆ’Î²tÎ½âˆ†D(Â¯q, q)	
Update All Tables:
Ë†g2[BKt]â†Ë†g1[BKt]andË†g1[BKt]â†gt
Ë†â„“1[BKt]â†Ë†â„“[BKt]andË†â„“[BKt]â†lt
Ë†q2[BKt]â†Ë†q1[BKt]andË†q1[BKt]â†q[BKt]
Ë†gaggâ†Ë†gagg+ Ë†g1[BKt]âŠ¤Ë†q1[BKt]âˆ’Ë†g2[BKt]âŠ¤Ë†q2[BKt]
end for
return (w, q).
D.2.1 Spectral Risk Measure Uncertainty Sets
As in Appx. B, the spectral risk measure uncertainty set is defined by a set of non-decreasing, non-
negative weights Ïƒ= (Ïƒ1, . . . , Ïƒ n)that sum to one. Our uncertainty set is given by
Q=Q(Ïƒ) := conv ( {permutations of Ïƒ)}),
and we use Dfhas the penalty for either fÏ‡2orfKL. The set Q(Ïƒ)is referred to the permutahedron
onÏƒ. In this case, the maximization problem can be dualized and solved via the following result.
Proposition 20. [Mehta et al., 2024, Proposition 3] Let lâˆˆRnbe a vector and Ï€be a permutation
that sorts its entries in non-decreasing order, i.e., lÏ€(1)â‰¤. . .â‰¤lÏ€(n). Consider a function fstrictly
convex with strictly convex conjugate defining a divergence Df. Then, the maximization over the
permutahedron subject to the shift penalty can be expressed as
max
qâˆˆQ(Ïƒ)
qâŠ¤lâˆ’Î½Df(qâˆ¥1n/n)	
= min
zâˆˆRn
z1â‰¤...â‰¤znnX
i=1gi(z;l), (78)
where we define gi(z;l) :=Ïƒiz+Î½
nfâˆ— 
(lÏ€(i)âˆ’z)/Î½
.The optima of both problems, denoted
zopt(l) = arg min
zâˆˆRn
z1â‰¤...â‰¤znnX
i=1gi(z;l), qopt= arg max
qâˆˆQ(Ïƒ)qâŠ¤lâˆ’Î½Df(qâˆ¥1n/n),
45are related as qopt(l) =âˆ‡(Î½Df(Â·âˆ¥1n/n))âˆ—(lâˆ’zopt
Ï€âˆ’1(l)),that is,
qopt
i(l) =1
n[fâˆ—]â€²
1
Î½(liâˆ’zopt
Ï€âˆ’1(i)(l))
. (79)
As described in Mehta et al. [2024, Appendix C], the minimization problem (78) is an exact instance
of isotonic regression and can be solved efficiently with the pool adjacent violators (PA V) algorithm.
D.2.2 Divergence-Ball Uncertainty Sets
Another common uncertainty set format is a ball in f-divergence, or
Q=Q(Ï) :=
qâˆˆRn:Df(qâˆ¥1/n)â‰¤Ï, qâ‰¥0,and1âŠ¤q= 1	
.
We describe the case of the rescaled Ï‡2-divergence in particular, in which the feasible set is an
â„“2-ball intersected with the probability simplex. Given a vector lâˆˆRn, we aim to compute the
mapping
l7â†’ arg max
qâˆˆPn
1
2âˆ¥qâˆ’1/nâˆ¥2
2â‰¤ÏâŸ¨l, qâŸ© âˆ’Î½
2âˆ¥qâˆ’1/nâˆ¥2
2, (80)
wherePn:=
qâˆˆRn:qâ‰¥0,1âŠ¤q= 1	
denotes the n-dimensional probability simplex. We apply
a similar approach to Namkoong and Duchi [2017], in which we take a partial dual of the problem
above. Indeed, note first that for any qâˆˆ Pn, we have that1
2âˆ¥qâˆ’1n/nâˆ¥2
2=1
2âˆ¥qâˆ¥2
2âˆ’1
2n. Thus,
the optimal solution to (80) can be computed by solving
max
qâˆˆPnmin
Î»â‰¥0âŸ¨l, qâŸ© âˆ’Î½
2âˆ¥qâˆ¥2
2âˆ’Î»1
2âˆ¥qâˆ¥2
2âˆ’Ïâˆ’1
2n
,
or equivalently, by strong duality via Slaterâ€™s condition, solving
max
Î»â‰¥0
f(Î») := ( Î½+Î») min
qâˆˆPn1
2âˆ¥qâˆ’l/(Î½+Î»)âˆ¥2
2âˆ’Î»
Ï+1
2n
âˆ’1
2(Î½+Î»)âˆ¥lâˆ¥2
2
.
Notice that evaluation of the outer objective itself requires Euclidean projection onto the probability
simplex as a subroutine, after which the maximization problem can be computed via the bisection
method, as it is a univariate concave maximization problem over a convex set. In order to determine
which half to remove in the bisection search, we also compute the derivative of Î»7â†’f(Î»), which is
given by
fâ€²(Î») :=1
2qopt(Î»)2
2âˆ’Ïâˆ’1
2n,
where qopt(Î»)achieves the minimum in minqâˆˆPn1
2âˆ¥qâˆ’l/(Î½+Î»)âˆ¥2
2for a fixed Î»â‰¥0. For pro-
jection onto the probability simplex, we apply Algorithm 1 from Condat [2016], which is a solution
relying on sorting the projected vector. The overall method consists of three steps.
1.Sorting: Projection onto the simplex relies on sorting the vector l/(Î½+Î»)on each eval-
uation. However, because l/(Î½+Î»)varies from evaluation to evaluation simply by mul-
tiplying by a positive scalar, we may pre-sort land use the same sorted indices on each
evaluation of (f(Î»), fâ€²(Î»))listed below.
2.Two-Pointer Search: We find the upper and lower limits for Î»by initializing Î»min= 0
andÎ»max= 1, and repeatedly making the replacement (Î»min, Î»max)â†(Î»max,2Î»max)
untilfâ€²(Î»max)<âˆ’Îµfor some tolerance Îµ >0. This, along with fâ€²(Î»min)> Îµindicates
that the optimal value of Î»lies within (Î»min, Î»max). For any Î»with|fâ€²(Î»)|< Îµ, we return
the associated qopt(Î»)as the solution.
3.Binary Search: Finally, we repeatedly evaluate fâ€²(Î»)forÎ»= (Î»min+Î»max)/2. If
fâ€²(Î»)> Îµ, we set Î»minâ†Î», whereas if fâ€²(Î»)<âˆ’Îµ, then we set Î»maxâ†Î». We
terminate when Î»maxâˆ’Î»min< Îµor|fâ€²(Î»)|< Îµ.
46The parameter Îµis set to 10âˆ’10in our experiments. Note that the same procedure can be used to com-
pute the dual proximal operator in Algorithm 1. In particular, when âˆ†D((, q), qtâˆ’1) =1
2âˆ¥qâˆ’qtâˆ¥2
2,
which is true when Dis the Ï‡2-divergence, then
qt= arg max
qâˆˆPn
1
2âˆ¥qâˆ’1/nâˆ¥2
2â‰¤Ï
nâŸ¨l+Î½Î²tqt, qâŸ© âˆ’Î½(1 +Î²t)
2âˆ¥qâˆ’1/nâˆ¥2
2,
which is a particular case of (80), and hence can be solved using the exact same procedure. The
runtime of this subroutine is O(nlogn+nlog(1/Îµ)), accounting for both the initial sorting at
O(nlogn)cost, and the O(log(1 /Îµ))iterations of the exponential and binary searches. Each itera-
tion requires a linear scan of nelements at cost O(n).
Hardware Acceleration Finally, note that the computations in Appx. D.2 and Appx. D.2.2 involve
primitives such as sorting, linear scanning through vectors, and binary search. Due to their serial
nature (as opposed to algorithms that rely on highly parallelizable operations such as matrix multi-
plication), we also utilize just-in-time compilation on the CPU via the Numba package for increased
efficiency.
47Dataset d n Task Source
yacht 6 244 Regression UCI
energy 8 614 Regression UCI
concrete 8 824 Regression UCI
kin8nm 8 6,553 Regression OpenML
power 4 7,654 Regression UCI
acsincome 202 4,000 Regression Fairlearn
emotion 270 8,000 Multiclass Classification Hugging Face
Table 5: Dataset attributes such as sample size n, parameter dimension d, and sources.
E Experimental Details
We describe details of the experimental setup, including datasets, compute environment, and hyper-
paramater tuning. We largely maintain the benchmarks of Mehta et al. [2023].
E.1 Datasets
The sample sizes, dimensions, and source of the datasets are summarized in Tab. 5. The tasks
associated with each dataset are listed below.
(a)yacht : predicting the residuary resistance of a sailing yacht based on its physical attributes
Tsanas and Xifara [2012].
(b)energy : predicting the cooling load of a building based on its physical attributes Baressi Segota
et al. [2020].
(c)concrete : predicting the compressive strength of a concrete type based on its physical and chem-
ical attributes Yeh [2006].
(d)kin8nm : predicting the distance of an 8 link all-revolute robot arm to a spatial endpoint [Aku-
juobi and Zhang, 2017].
(e)power : predicting net hourly electrical energy output of a power plant given environmental
factors [T Â¨ufekci, 2014].
(f)acsincome : predicting income of US adults given features compiled from the American Com-
munity Survey (ACS) Public Use Microdata Sample (PUMS) [Ding et al., 2021].
(g)emotion : predicting the sentiment of sentence in the form of six emotions. Each input is a
segment of text and we use a BERT neural network Devlin et al. [2019] as an initial feature
map. This representation is fine-tuned using 2 epochs on a random half (8,000 examples) of
the original emotion dataset, and then applied to the remaining half. We then apply principle
components analysis (PCA) to reduce the dimension of each vector to 45.
E.2 Hyperparameter Selection
We fix a minibatch size of 64SGD and an epoch length of N=nfor LSVRG. In practice, the
regularization parameter Âµand shift cost Î½are tuned by a statistical metric, i.e. generalization error
as measured on a validation set.
For the tuned hyperparameters, we use the following method. Let kâˆˆ {1, . . . , K }be a seed that
determines algorithmic randomness. This corresponds to sampling a minibatch without replacement
for SGD and SRDA and a single sampled index for LSVRG. Letting Lk(Î·)denote the average
value of the training loss of the last ten passes using learning rate Î·and seed k, the quantity L(Î·) =
1
KPK
k=1Lk(Î·)was minimized to select Î·. The learning rate Î·is chosen in the set {1Ã—10âˆ’4,3Ã—
10âˆ’4,1Ã—10âˆ’3,3Ã—10âˆ’3,1Ã—10âˆ’2,3Ã—10âˆ’2,1Ã—10âˆ’1,3Ã—10âˆ’1,1Ã—100,3Ã—100}, with two orders
of magnitude lower numbers used in acsincome due to its sparsity. We discard any learning rates
that cause the optimizer to diverge for any seed.
480 50000 10000010âˆ’810âˆ’510âˆ’2Suboptimality
yacht
0 50000 10000010âˆ’610âˆ’3100
energy
0 50000 10000010âˆ’510âˆ’2
concrete
0 1 210âˆ’610âˆ’3100
yacht
0 1 210âˆ’810âˆ’510âˆ’2
energy
0 110âˆ’510âˆ’2
concrete
0 50000 100000
First-Order Oracle Evaluations10âˆ’210âˆ’1100Suboptimality
kin8nm
0 50000 100000
First-Order Oracle Evaluations10âˆ’210âˆ’1100
power
0 200000 400000
First-Order Oracle Evaluations10âˆ’1100
emotion
0 5
Wall-Clock Time (Seconds)10âˆ’510âˆ’2
kin8nm
0 5
Wall-Clock Time (Seconds)10âˆ’610âˆ’3100
power
0 20
Wall-Clock Time (Seconds)10âˆ’510âˆ’2
emotion
SGD Drago (b= 16 ) Drago (b=n/d) Drago (b= 1)Figure 4: Benchmarks on the Ï‡2Uncertainty Set. In both panels, the y-axis measure the primal
suboptimality gap, defined in (15). Individual plots correspond to particular datasets. Left: The
x-axis displays the number of individual first-order oracle queries to {(â„“i,âˆ‡â„“i)}n
i=1.Right: The
x-axis displays wall-clock time.
E.3 Compute Environment
Experiments were run on a CPU workstation with an Intel i9 processor, a clock speed of 2.80GHz, 32
virtual cores, and 126G of memory. The code used in this project was written in Python 3 using the
Numba packages for just-in-time compilation. Run-time experiments were conducted without CPU
parallelism. The algorithms are primarily written in PyTorch and support automatic differentiation.
E.4 Additional Experiments
We explore the sensitivity of the results to alterations of the objective and algorithm hyperparame-
ters.
Sensitivity to Uncertainty Set Choice In Sec. 4, we mainly show performance on spectral risk-
based uncertainty sets, in particular the conditional value-at-risk (CVaR). In this section, we also
consider f-divergence ball-based uncertainty sets, with the procedure described in Appx. D.2.2.
As in Namkoong and Duchi [2017], we use a radius that is inversely proportional to the sample
size, namely Ï=1
n, and the strong convexity-strong concavity parameter Âµ=Î½= 1. In Fig. 4,
we demonstrate the performance of DRAGO withb= 1,b= 16 (as chosen heuristically), and
b=n/d. We compare against the biased stochastic gradient descent, which can be defined using
oracle to compute the optimal dual variables given a vector of losses; however, note that LSVRG is
designed only for spectral risk measures, so the method does not apply in the divergence ball setting.
We observe that the optimization performance across both regression and multi-class classification
tasks are qualitatively similar to that seen in Fig. 2 nad Fig. 3. The b= 1 variant performs well on
smaller datasets ( nâ‰¤1,000), whereas the b= 16 heuristic generally does not dominate in terms of
gradient evaluations or wall time. While the number of gradient evaluations is significantly larger
for the b=n/dvariant, implementation techniques such as just-in-time complication (see Appx. D)
allow for efficient computation, resulting in better overall optimization performance as a function of
wall time.
Sensitivity to Batch Size In Fig. 5, we consider the datasets with the largest ratio of ntod(hence
the largest theoretically prescribed batch size) and assess the performance of DRAGO with smaller
batch sizes. For both datasets, we have that in magnitude, n/dâ‰ˆ1000 . Intuitively, the smaller batch
size methods would perform better in terms of oracle queries but the large batch methods would be
more performant in terms of wall time. With only a batch size of b= 64 , this variant of DRAGO
generally matches the best-performing setting when viewed from either oracle calls or direct wall
time. This is approximately 16Ã—smaller than the n/d benchmark, indicating that tuning the batch
size can significantly reduce the memory overhead of the algorithm while increasing speed.
490 50 100 150 20010âˆ’810âˆ’610âˆ’410âˆ’2100kin8nm
Âµ=1.0,Î½=1.0
0 50 100 150 200
Âµ=10.0,Î½=1.0
0 50 100 150 200
Âµ=1.0,Î½=10.0
0 50 100 150 200
Âµ=10.0,Î½=10.0
0 50 100 150 200
First-Order Oracle Evaluations (K)10âˆ’810âˆ’610âˆ’410âˆ’2100power
0 50 100 150 200
First-Order Oracle Evaluations (K)
0 50 100 150 200
First-Order Oracle Evaluations (K)
0 50 100 150 200
First-Order Oracle Evaluations (K)
0 20 40 6010âˆ’810âˆ’610âˆ’410âˆ’2100kin8nm
Âµ=1.0,Î½=1.0
0 20 40 60
Âµ=10.0,Î½=1.0
0 20 40 60
Âµ=1.0,Î½=10.0
0 20 40 60
Âµ=10.0,Î½=10.0
0 20 40 60
Wall-Clock Time (Seconds)10âˆ’810âˆ’610âˆ’410âˆ’2100power
0 20 40 60
Wall-Clock Time (Seconds)
0 20 40 60
Wall-Clock Time (Seconds)
0 20 40 60
Wall-Clock Time (Seconds)
Drago (b= 1024 ) Drago (b= 256 ) Drago (b= 64 ) Drago (b= 16 ) Drago (b= 4) Drago (b= 1)Figure 5: DRAGO on varying batch sizes and strong convexity parameters. Each row indicates a
dataset, where as each column denotes the CVaR objective with the given regularization parameters.
Top Rows: Thex-axis displays the number of individual first-order oracle queries to {(â„“i,âˆ‡â„“i)}n
i=1.
Bottom Rows: Thex-axis displays wall-clock time.
50F NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: Sec. 3 for direct theoretical claims and Appx. B for detailed comparisons to
other work.
Guidelines:
â€¢ The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢ The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢ The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢ It is fine to include aspirational goals as motivation as long as it is clear that these
goals are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: See Sec. 1 and Sec. 5 for general points, whereas Sec. 4 mentions specific
cases of algorithm performance. The assumptions made are otherwise standard.
Guidelines:
â€¢ The answer NA means that the paper has no limitation while the answer No means
that the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate â€Limitationsâ€ section in their paper.
â€¢ The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The au-
thors should reflect on how these assumptions might be violated in practice and what
the implications would be.
â€¢ The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢ The authors should reflect on the factors that influence the performance of the ap-
proach. For example, a facial recognition algorithm may perform poorly when image
resolution is low or images are taken in low lighting. Or a speech-to-text system might
not be used reliably to provide closed captions for online lectures because it fails to
handle technical jargon.
â€¢ The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢ If applicable, the authors should discuss possible limitations of their approach to ad-
dress problems of privacy and fairness.
â€¢ While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
51Answer: [Yes]
Justification: This is done for every theoretical statement.
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢ All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢ All assumptions should be clearly stated or referenced in the statement of any theo-
rems.
â€¢ The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a
short proof sketch to provide intuition.
â€¢ Inversely, any informal proof provided in the core of the paper should be comple-
mented by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main
experimental results of the paper to the extent that it affects the main claims and/or conclu-
sions of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Appx. D contains detailed descriptions of experimental details and code with
an associated environment and quickstart guide is provided.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢ If the contribution is a dataset and/or model, the authors should describe the steps
taken to make their results reproducible or verifiable.
â€¢ Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture
fully might suffice, or if the contribution is a specific model and empirical evaluation,
it may be necessary to either make it possible for others to replicate the model with
the same dataset, or provide access to the model. In general. releasing code and data
is often one good way to accomplish this, but reproducibility can also be provided via
detailed instructions for how to replicate the results, access to a hosted model (e.g., in
the case of a large language model), releasing of a model checkpoint, or other means
that are appropriate to the research performed.
â€¢ While NeurIPS does not require releasing code, the conference does require all sub-
missions to provide some reasonable avenue for reproducibility, which may depend
on the nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear
how to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to re-
produce the model (e.g., with an open-source dataset or instructions for how to
construct the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case au-
thors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
52Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: The code is made public at https://github.com/ronakdm/drago.
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢ Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢ While we encourage the release of code and data, we understand that this might not
be possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢ The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢ The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢ The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
â€¢ At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢ Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: See Appx. D and Appx. E for implementation and experiment details.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ The experimental setting should be presented in the core of the paper to a level of
detail that is necessary to appreciate the results and make sense of them.
â€¢ The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropri-
ate information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Training curves and hyperparameter selection experiments are averaged over
multiple seeds, but error bars are not shown to make the plots visible.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ The authors should answer â€Yesâ€ if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
â€¢ The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
53â€¢ The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
â€¢ It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
â€¢ It is OK to report 1-sigma error bars, but one should state it. The authors should prefer-
ably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of
Normality of errors is not verified.
â€¢ For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢ If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: Yes, as written in Appx. E.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
â€¢ The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢ The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments
that didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: NA
Guidelines:
â€¢ The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢ If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
â€¢ The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: It is written after the main text of the paper.
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
â€¢ If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢ Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact spe-
cific groups), privacy considerations, and security considerations.
54â€¢ The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢ The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢ If there are negative societal impacts, the authors could also discuss possible mitiga-
tion strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [No]
Justification: Generative and related large-scale models are not used in this work.
Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
â€¢ Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by re-
quiring that users adhere to usage guidelines or restrictions to access the model or
implementing safety filters.
â€¢ Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢ We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: NA
Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢ The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢ For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢ If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/
datasets has curated licenses for some datasets. Their licensing guide can help
determine the license of a dataset.
â€¢ For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
55â€¢ If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documenta-
tion provided alongside the assets?
Answer: [Yes]
Justification: Documented code is provided.
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢ Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢ The paper should discuss whether and how consent was obtained from people whose
asset is used.
â€¢ At submission time, remember to anonymize your assets (if applicable). You can
either create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the pa-
per include the full text of instructions given to participants and screenshots, if applicable,
as well as details about compensation (if any)?
Answer: [NA]
Justification: Human participants are not used.
Guidelines:
â€¢ The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
â€¢ Including this information in the supplemental material is fine, but if the main contri-
bution of the paper involves human subjects, then as much detail as possible should
be included in the main paper.
â€¢ According to the NeurIPS Code of Ethics, workers involved in data collection, cura-
tion, or other labor should be paid at least the minimum wage in the country of the
data collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: No IRM approvals were needed for this work.
Guidelines:
â€¢ The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
â€¢ Depending on the country in which research is conducted, IRB approval (or equiva-
lent) may be required for any human subjects research. If you obtained IRB approval,
you should clearly state this in the paper.
â€¢ We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢ For initial submissions, do not include any information that would break anonymity
(if applicable), such as the institution conducting the review.
56