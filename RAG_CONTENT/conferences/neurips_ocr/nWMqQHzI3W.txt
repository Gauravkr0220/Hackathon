SEEV: Synthesis with Efficient Exact Verification for
ReLU Neural Barrier Functions
Hongchao Zhang‚àó
Electrical & Systems Engineering
Washington University in St. Louis
hongchao@wustl.eduZhizhen Qin‚àó
Computer Science & Engineering
University of California, San Diego
zhizhenqin@ucsd.edu
Sicun Gao
Computer Science & Engineering
University of California, San Diego
scungao@ucsd.eduAndrew Clark
Electrical & Systems Engineering
Washington University in St. Louis
andrewclark@wustl.edu
Abstract
Neural Control Barrier Functions (NCBFs) have shown significant promise in en-
forcing safety constraints on nonlinear autonomous systems. State-of-the-art exact
approaches to verifying safety of NCBF-based controllers exploit the piecewise-
linear structure of ReLU neural networks, however, such approaches still rely on
enumerating all of the activation regions of the network near the safety boundary,
thus incurring high computation cost. In this paper, we propose a framework for
Synthesis with Efficient Exact Verification (SEEV). Our framework consists of two
components, namely (i) an NCBF synthesis algorithm that introduces a novel regu-
larizer to reduce the number of activation regions at the safety boundary, and (ii) a
verification algorithm that exploits tight over-approximations of the safety condi-
tions to reduce the cost of verifying each piecewise-linear segment. Our simulations
show that SEEV significantly improves verification efficiency while maintaining
the CBF quality across various benchmark systems and neural network structures.
Our code is available at https://github.com/HongchaoZhang-HZ/SEEV .
1 Introduction
Safety is a crucial property for autonomous systems that interact with humans and critical infras-
tructures in applications including medicine, energy, and robotics [ 1,2], which has motivated recent
research into safe control [ 3,4,5,6,7]. Control Barrier Functions (CBFs), which apply a constraint on
the control input at each time in order to ensure that safety constraints are not violated, have attracted
significant research attention due to their ease of implementation and compatibility with a variety of
safety and performance criteria [ 8]. Recently, CBFs that are defined by neural networks, denoted
as Neural Control Barrier Functions (NCBFs), have been proposed to leverage the expressiveness
of NNs for safe control of nonlinear systems [9, 10, 11]. NCBFs have shown substantial promise in
applications including robotic manipulation [10], navigation [12, 13], and flight control [14].
A key challenge in NCBF-based control is safety verification, which amounts to ensuring that the
constraints on the control can be satisfied throughout the state space under actuation limits. The
NCBF safety verification problem effectively combines two problems that are known to be difficult,
namely, input-output verification of neural networks (VNN) [ 15,16,17,18,19,20] and reachability
verification of nonlinear systems. While sound and complete verifiers such as dReal can be applied to
‚àóEqual contribution
38th Conference on Neural Information Processing Systems (NeurIPS 2024).NCBFs, they typically can only handle systems of dimension three or small neural networks [ 21,22].
In [23], exact conditions for safety verification of NCBFs with ReLU activation functions were
proposed that leverage the piecewise-linearity of ReLU-NNs to reduce verification time compared
to dReal for general activation functions. The exact conditions, however, still require checking
correctness of the NCBF by solving a nonlinear optimization problem along each piecewise-linear
segment. Hence, the NCBF verification problem remains intractable for high-dimensional systems.
In this paper, we propose a framework for Synthesis with Efficient Exact Verification (SEEV) for
piecewise-linear NCBFs. The main insight of SEEV is that the computational bottleneck of NCBF
verification is the inherent requirement of verifying each linear segment of the neural network. We
mitigate this bottleneck by (i) developing a training procedure that reduces the number of segments
that must be verified and (ii) constructing verification algorithms that efficiently enumerate the
linear segments at the safety boundary and exploit easily-checked sufficient conditions to reduce
computation time. Towards (i), we introduce a regularizer to the loss function that penalizes the
dissimilarity of activation patterns along the CBF boundary. Towards (ii), we propose a breadth-
first search algorithm for efficiently enumerating the boundary segments, as well as tight linear
over-approximations of the nonlinear optimization problems for verifying each segment. Moreover,
we integrate the synthesis and verification components by incorporating safety counterexamples
returned by the safety verifier into the training dataset. Our simulation results demonstrate significant
improvements in verification efficiency and reliability across a range of benchmark systems.
Related Work: Neural control barrier functions have been proposed to describe complex safety sets
to remain inside and certify safety of a controlled system [ 24,21,25,26] or synthesize control input
based on NCBFs to ensure safety [ 8,9,10,27]. However, the synthesized NCBF may not ensure safety.
Safety verification of NCBFs is required. Sum-of-squares (SOS) optimization [ 28,29,30,31,32]
has been widely used for polynomial barrier functions, however, they are not applicable due to
the non-polynomial and potentially non-differentiable activation functions of NCBFs. VNN [ 33,
34,35] and methods for ReLU neural networks [ 36,37] are also not directly applicable to NCBF
verification. Nonlinear programming approach [ 23] provides another route for exact verification but
is computationally intensive and relies on VNN tools. To synthesize neural networks with verifiable
guarantees, Counterexample Guided Inductive Synthesis (CEGIS) has been applied using SMT-
based techniques [ 21,38,39,40,41]. Other verification-in-the-loop approaches utilize reachability
analysis [ 42] and branch-and-bound neural network verification tools [ 43]. However, existing
works suffer from the difficulty of performing verification and generating counterexamples in a
computationally efficient manner. Sampling-based approaches [ 41,11] aim to prove safety using
Lipschitz conditions, but they rely on dense sampling over the state space, which is computationally
prohibitive. In this work, we present SEEV to integrate the synthesis and efficient verification by
incorporating safety counterexamples from the exact verification.
Organization The remainder of the paper is organized as follows. Section 2 gives the system model
and background on neural networks and the conditions of valid NCBFs. Section 3 presents the SEEV
framework. Section 4 presents our efficient and exact verification. Section 5 contains simulation
results. Section 6 concludes the paper.
2 Preliminaries
This section presents the system model, notations on neural networks, and exact conditions of safety.
2.1 System Model
We consider a system with state x(t)‚àà X ‚äÜ Rnand input u(t)‚àà U ‚äÜ Rm, with initial condition
x(t0) =x0where x0lies in an initial set I ‚äÜ X . The continuous-time nonlinear control-affine
system has the dynamics given by
Àôx(t) =f(x(t)) +g(x(t))u(t) (1)
where f:Rn‚ÜíRnandg:Rn‚ÜíRn√ómare known continuous functions.
We consider the case that the system is required to remain inside a given set of states, i.e., x(t)‚àà C
for all time t‚â•t0. The set C, referred to as the safe set , is defined as C={x:h(x)‚â•0}by some
given continuous function h:Rn‚ÜíR. The unsafe region is given by X \ C .
22.2 Neural Network Model and Notations
We let Wandrdenote the weight and bias of a neural network, and let Œ∏be a parameter vector
obtained by concatenating Wandr. We consider a Œ∏-parameterized feedforward neural network
bŒ∏:Rn‚ÜíRconstructed as follows. The network consists of Llayers, with each layer iconsisting
ofMineurons. We let (i, j)‚àà {1, . . . , L }√ó{1, . . . , M i}denote the j-th neuron at the i-th layer. We
denote the pre-activation input as z(i)
j, piecewise linear activation function œÉand the post-activation
output as ÀÜz(i)
j=œÉ(z(i)
j). Specifically, we assume that the NN has the Rectified Linear Unit (ReLU)
activation function, defined by œÉ(z) =zforz‚â•0andœÉ(z) = 0 forz <0. We define the neuron
(i, j)asactive ifz(i)
j>0,inactive ifz(i)
j<0andunstable ifz(i)
j= 0. LetS=œÑS(x) ={(i, j) :
z(i)
j‚â•0} ‚äÜ { (i, j) :i= 1, . . . , L, j = 1, . . . , M i}denote the set of activated and unstable neurons,
produced by state xand function œÑS. LetT(x) =œÑT(x) ={(i, j) :z(i)
j= 0}denote the set of
unstable neurons produced by xandœÑT.T(S1, . . . ,Sr)denote the set of unstable neurons produced
by activation sets S1, . . . ,Sr. The set of inactive neurons is given by Sc, i.e., the complement of
S, and consists of neurons with negative pre-activation input. We define vectors Wij(S)‚ààRn
and scalars rij(S)‚ààRsuch that z(i)
j=Wij(S)Tx+rij(S)in the Appendix A.1. The symmetric
difference between two sets AandB, denoted by A‚àÜB, is defined as A‚àÜB= (A\B)‚à™(B\A).
Finally, we define the terms hyperplane andhinge . For any S‚äÜ {1, . . . , L }√ó{1, . . . , M i}, we define
X(S) :={x:S(x) =S}. The collection of X(S)for all Sis the set of hyperplanes associated
with the ReLU neural network. A hyperplane that intersects the set {x:bŒ∏(x) = 0}is aboundary
hyperplane . The intersection of hyperplanes X(S1), . . . ,X(Sr)is called a hinge . A hinge that
intersects the set {x:bŒ∏(x) = 0}is aboundary hinge .
2.3 Guaranteeing Safety via Control Barrier Functions
Barrier certificates [ 28] ensure the safety of a feedback-controlled system under policy ¬µ(x|Œª)by
identifying a CBF to represent the invariant safe set. The barrier certificate defines an inner safe
region D:={x:b(x)‚â•0}for some continuous function b. The verifiable invariance of Dis
obtained from the following result.
Theorem 1 (Nagumo‚Äôs Theorem [ 44], Section 4.2) .A closed set Dis controlled positive invariant if,
whenever x‚àà‚àÇD, where ‚àÇDdenotes the boundary of D. we have
(f(x) +g(x)u)‚àà AD(x) (2)
for some u‚àà U whereAD(x)is the tangent cone to Datx.
We denote a state ÀÜxc
cewith ÀÜxc
ce‚àà‚àÇDthat violates (2)as a safety counterexample . In the case
where bis continuously differentiable, (2)can be satisfied by selecting uto satisfy the condition
‚àÇb
‚àÇx(f(x(t)) +g(x(t))u(t))‚â• ‚àíŒ±(b(x(t))), where Œ±:R‚ÜíRis a strictly increasing function with
Œ±(0) = 0 . When bis not continuously differentiable, as in a ReLU NCBFs, a modified condition
is needed. Prior work [ 23] introduces exact conditions for safety verification of ReLU NCBFs,
based on the following proposition. A collection of activation sets S1, . . . ,Sris complete if, for any
S‚Ä≤/‚àà {S1, . . . ,Sr}, we have X(S1)‚à© ¬∑¬∑¬∑ ‚à© X(Sr)‚à©X(S‚Ä≤) =‚àÖ.
Proposition 1. Suppose the function ReLU neural network-defined function bsatisfies the following
conditions:
(i)For all activation sets S1, . . . ,Srwith{S1, . . . ,Sr}complete and any xsatisfying b(x) = 0
and
x‚àà r\
l=1X(Sl)!
, (3)
there exist l‚àà {1, . . . , r }andu‚àà U such that
(Wi‚àí1(Sl)Wij)T(f(x) +g(x)u)‚â•0‚àÄ(i, j)‚ààT(S1, . . . ,Sr)‚à©Sl (4)
(Wi‚àí1(Sl)Wij)T(f(x) +g(x)u)‚â§0‚àÄ(i, j)‚ààT(S1, . . . ,Sr)\Sl (5)
W(Sl)T(f(x) +g(x)u)‚â•0 (6)
3(ii) For all activation sets S, we have
(X(S)‚à© D)\ C=‚àÖ (7)
Ifb(x(0))‚â•0, then x(t)‚àà Cfor all t‚â•0.
Any feedback control law ¬µ:X ‚Üí U that satisfies (4)‚Äì(6)is guaranteed to ensure safety and is
referred to as an NCBF control policy. Given a nominal control policy œÄnom(x), safe actions can be
derived from a ReLU NCBF as a safety filter[ 29,9] by solving the following optimization problem
proposed in [23, Lemma 2]:
min
S‚ààS(x),u||u‚àíœÄnom(x)||2
2s.t.W(S)T(f(x) +g(x)u)‚â• ‚àíŒ±(b(x)), u‚àà U,(4)‚àí(6) (8)
The solution to this optimization problem provides a control uthat minimally deviates from the
nominal control œÄnom(x)while satisfying NCBF constraints derived in Proposition 1 ensuring that
Dis positive invariant and is contained in C. Based on Proposition 1, we can define different
types of safety counterexamples. Correctness counterexamples, denoted by ÀÜxc
ce, refers to a state
ÀÜxc
ce‚àà D ‚à© (X \ C ). Hyperplane verification counterexamples refer to states ÀÜxh
cethat violate (6).
Hinge verification counterexamples are states xwithT(x)Ã∏=‚àÖthat violate (4)‚Äì(6).
3 Synthesis
In this section, we present the framework to synthesize NCBF bŒ∏(x)to ensure the safety of the system
(1). The synthesis framework aims to train an NCBF and construct an NCBF-based safe control
policy. We first formulate the problem and present an overview of the framework in 3.1. Then we
demonstrate the design of the loss function in 3.2.
3.1 Overall Formulation
Our primary objective is to synthesize a ReLU Neural Control Barrier Function (ReLU-NCBF) for
(1) and develop a safe control policy to ensure system safety.
Problem 1. Given a system (1), initial set Iand a safety set C, synthesize a ReLU NCBF bŒ∏(x)
parameterized by Œ∏such that the conditions in Proposition 1 are satisfied. Then construct a control
policy to synthesize utsuch that the system remains positive invariant in D:={x:bŒ∏(x)‚â•0} ‚äÜ C .
We propose SEEV to address this problem with the synthesis framework demonstrated in Fig. 1. The
training dataset Tis initialized by uniform sampling over X. The training framework consists of
two loops. The inner loop attempts to choose parameter Œ∏forbŒ∏(x)to satisfy the safety condition by
minimizing the loss function over training data T. The outer loop validates a given NCBF bŒ∏(x)by
searching for safety counterexamples ÀÜxceand updates the training dataset as T ‚à™ { ÀÜxce}.
To train the parameters of the NCBF to satisfy the conditions of Proposition 1, we propose a loss
function that penalizes the NCBF for violating constraints (i) and (ii) at a collection of sample points.
The loss function is a weighted sum of three terms. The first term is the correctness loss penalizing
state ÀÜx‚àà X \ C withbŒ∏(x)‚â•0. The second term is verification loss that penalizes states ÀÜxthat
‚àÑusuch that (4)-(6)hold. The third term is a regularizer minimizing the number of hyperplanes
and hinges along the boundary. However, minimizing the loss function is insufficient to ensure
safety [ 9] because there may exist safety counterexamples outside of the training dataset. In order
to guarantee safety, SEEV introduces an efficient exact verifier to certify whether bŒ∏(x)meets the
safety conditions outlined in Proposition 1. The verifier either produces a proof of safety or generates
a safety counterexample that can be added to the training dataset to improve the NCBF.
The integration of the verifier can improve safety by adding counterexamples to guide the training
process, however, it may also introduce additional computation complexity. We propose a combined
approach, leveraging two complementary methods to address this issue. First, the verification of SEEV
introduces an efficient algorithm in Section 4 to mitigate the computational scalability challenges that
arise as neural network depth and dimensionality increase. Second, SEEV introduces a regularizer to
limit the number of boundary hyperplanes and hinges to be verified, addressing the complexity that
arises as neural network size increases.
4EnumerationSec. 4.1Efficient VerificationSec. 4.2Training DatasetNCBF TrainingSec.3NCBFHyperplanes & HingesYesNoCounterexamplesValidNCBF(i)	inProposition	1(ii)	inProposition	1Boundary	Activation	RegularizerFigure 1: SEEV: Synthesis with Efficient Exact Verifier for ReLU NCBF
3.2 Loss Function Design and NCBF Training
The goal of the inner loop is to choose parameters Œ∏so that the conditions of Proposition 1 are
satisfied for all ÀÜx‚àà T and the computational cost of verifying safety is minimized. To achieve the
latter objective, we observe (based on results presented in Table 2) that the computational complexity
of verification grows with the cardinality of the collection of activation sets that intersect the safety
boundary ‚àÇD. The collection is defined as B:={Si:‚àÇD ‚à©X(Si)Ã∏=‚àÖ}. Hence, we formulate the
following unconstrained optimization problem to search for Œ∏.
min
Œ∏ŒªBLB(T) +ŒªfLf(T) +ŒªcLc(T) (9)
where LB(T)regularizer to minimize |B|,Lf(T)is the loss penalizing the violations of constraint
(4)-(6)((i) of Proposition 1), Lc(T)penalizes the violations of constraint (7)((ii) of Proposition 1),
andŒªB,ŒªfandŒªcare non-negative coefficients defined as follows.
LfRegularizer: For each sample ÀÜx‚àà T the safe control signal is calculated by
min
u,r||u‚àíœÄnom(x)||2
2 s.t.W(Sl)T(f(ÀÜx) +g(ÀÜx)u) +r‚â•0 (10)
whereW=Wfor differentiable points and W=ÀúWdefined as the subgradient at non-differentiable
points. The regularizer Lfenforces the satisfaction of the constraint by inserting a positive relaxation
termrin the constraint and minimizing rwith a large penalization in the objective function. We have
the loss Lfdefined as Lf=||u‚àíœÄnom(x)||2
2+r. We use [ 45] to make this procedure differentiable,
allowing us to employ the relaxation loss into the NCBF loss function design.
LcRegularizer: Lcregularizer enforces the correctness of the NCBF. In particular, it enforces the
bŒ∏(x)of safe samples x‚àà TIto be positive, and bŒ∏(x)of unsafe samples TX\Cto be negative. Define
Nsafe=|TI|andNunsafe =|TX\C|, and with a small positive tuning parameter œµ >0, the loss term
Lccan be defined as
Lc=a11
NsafeX
x‚ààTI[œµ‚àíbŒ∏(x)]++a21
NunsafeX
x‚ààTX\C[œµ+bŒ∏(x)]+ (11)
where [¬∑]+=max(¬∑,0).a1anda2are positive parameters controlling penalization strength of the
violations of safe and unsafe samples.
LBRegularizer: We propose a novel regularizer to limit the number of boundary hyperplanes and
hinges by penalizing the dissimilarity, i.e., S(ÀÜxi)‚àÜS(ÀÜxj)of boundary activation sets S(ÀÜx)‚àà B.
However, the dissimilarity measure of boundary activation sets is inherently nondifferentiable. To
address this issue the regularizer introduces the generalized sigmoid function œÉk(z) =1
1+exp( ‚àík¬∑z)
to compute the vector of smoothed activation defined as œïœÉk(x) := [ œÉk(zi,j),‚àÄi, j‚àà {1, . . . , L } √ó
{1, . . . , M i}]. TheLBregularizer conducts the following two steps to penalize dissimilarity.
In the first step, the regularizer identifies the training data in the boundary hyperplanes and hinges
denoted as ÀÜx‚àà T‚àÇD. The set is defined as T‚àÇD:={ÀÜx: ÀÜx‚ààX(S),‚àÄS‚àà B} . To further improve
the efficiency, the regularizer approximates T‚àÇDwith a range-based threshold œµon the output of the
NCBF, i.e., |bŒ∏(ÀÜx)| ‚â§œµ.
The second step is to penalize the dissimilarity of S‚àà B. To avoid the potential pitfalls of enforcing
similarity across the entire boundary B, the regularizer employs an unsupervised learning approach to
5group the training data into NBclusters. We define the collection of the activation set in each cluster
asBi‚äÜ B and the collection in each cluster as TBi:={ÀÜx: ÀÜx‚ààS
S‚ààBiX(S)}. TheLBis then
defined as follows, with an inner sum over all pairs of ÀÜx‚àà TBiand an outer sum over all clusters.
LB=1
NBX
Bi‚ààB1
|TBi|2X
ÀÜxi,ÀÜxj‚ààTBi‚à•œïœÉk(xi)‚àíœïœÉk(xj)‚à•2
2, (12)
4 Verification
Enumerate boundary hyperplanes using NBFS (LP)Correctness Verification (18)Safety CESufficient Condition VerificationInterval ùí∞(20)ùí∞‚àà‚Ñù!(21)ùë∫!=[1 1 0 ‚Ä¶ 1 0]ùë∫"=[1 1 1 ‚Ä¶ 0 0]ùë∫#=[1 1 0 ‚Ä¶ 0 0]ùë∫$=[1 1 1 ‚Ä¶ 0 0]‚ãÆExact Condition Verification for Hyperplanes (19)FailFailPass{ùë∫!,ùë∫$,ùë∫",ùë∫#,ùë∫!,ùë∫$,ùë∫#}Enumerate hinges (LP)Sufficient Condition HeuristicsFailExact Condition Verification for Hinges (22)Safety Guarantee Theorem 2PassPassSafety CEFail
Safety CEFailPass
Figure 2: Overview of the Efficient Exact Verifier for ReLU NCBFs
In this section, we demonstrate the efficient exact verification of the given NCBF bŒ∏(x)to ensure the
positive invariance of the set Dunder the NCBF-based control policy. In what follows, we propose
an efficient enumeration and progressive verification moving from sufficient to exact conditions.
The overview of the proposed approach is as shown in Fig. 2. SEEV decomposes the NCBF into
hyperplanes and hinges and verifies each component hierarchically, with novel tractable sufficient
conditions verified first and the more complex exact conditions checked only if the sufficient condi-
tions fail. Given an NCBF bŒ∏(x), the verification of SEEV returns (i) a Boolean variable that is ‚Äòtrue‚Äô
if the conditions of Proposition 1 are satisfied and ‚Äòfalse‚Äô otherwise, and (ii) a safety counterexample
ÀÜxthat violates the conditions of Proposition 1 if the result is ‚Äòfalse‚Äô. Algorithm 1 presents an overview
of the verification of SEEV. The algorithm consists of an enumeration stage to identify all boundary
hyperplanes and hinges, and a verification stage to certify satisfaction of conditions in Proposition 1
for all hyperplanes and hinges.
Algorithm 1 Efficient Exact Verification
1:Input: n,TX\C,TI
2:Output: Verification Boolean result r, Categorized counterexample ÀÜxce
3:procedure EFFICIENT EXACT VERIFICATION (TX\C,TI)
4: S0‚ÜêENUMINIT (TX\C,TI) ‚ñ∑Initial Activation Set Identification, Section 4.1
5: S ‚Üê NBFS (S0) ‚ñ∑Activation Sets Enumeration, Section 4.1
6: r,ÀÜx(c)
ce‚ÜêCorrectnessVerifier (S) ‚ñ∑Correctness Verification, Section 4.2
7: r,ÀÜx(h)
ce‚ÜêHyperplaneVerifier (S) ‚ñ∑Hyperplane Verification, Section 4.2
8: V ‚Üê HingeEnum (S, n) ‚ñ∑Hinges Enumeration, Section 4.1
9: r,ÀÜx(g)
ce‚ÜêHingeVerifier (V) ‚ñ∑Hinge Verification, Section 4.2
10: Return r,ÀÜxce
4.1 Enumeration of Hyperplanes and Hinges
The boundary enumeration identifies the boundary hyperplanes S0‚àà B. It initially identifies the
initial boundary activation set S0‚àà B, enumerates all S‚àà B by NBFS starting from S0, and finally
enumerates all hinges consisting of the intersections of hyperplanes. The NBFS approach avoids
over-approximation of the set of boundary hyperplanes that may be introduced by, e.g., interval
propagation methods, and hence is particularly suited to deep neural networks.
In what follows, we assume that the unsafe region X \ C and initial safe set Iare connected, and
use‚àÇDto refer to the connected component of the boundary of Dthat separates IandX \ C . This
6assumption is without loss of generality since we can always repeat the following procedure for each
connected component of IandX \ C .
Initial Activation Set Identification: First, we identify the initial boundary activation set S0. Given
ÀÜxU‚àà X \ C andÀÜxI‚àà I, define a line segment
ÀúL=
x‚ààRn|x= (1‚àíŒª)ÀÜxX\C+ŒªÀÜxI, Œª‚àà[0,1]	
(13)
The following lemma shows the initial boundary activation set S0can always be produced as
S0=S(Àúx)for some Àúx‚ààÀúL.
Lemma 1. Given two sample points ÀÜxU, such that b(ÀÜxU)<0, and ÀÜxI, such that b(ÀÜxU)>0, letÀúL
denote the line segment connecting these two points. Then, there exists a point Àúx‚ààÀúLwithbŒ∏(Àúx) = 0 .
Lemma 1 follows from the intermediate value theorem and continuity of bŒ∏(x). In order to search
forS0, we choose a sequence of NÀúLpoints x0
1, . . . , x0
NÀúL‚ààÀúL. For each x0
i, we check to see if
X(S(x0
i))‚à©‚àÇD Ã∏=‚àÖby solving boundary linear program BoundaryLP (S(x0
i))(14) in Appendix A.4
Activation Sets Enumeration: We next describe Neural Breadth-First Search (NBFS) for enumerat-
ing all activation sets along the zero-level set, given an initial set S0. NBFS enumerates a collection
of boundary hyperplanes denoted as Sby repeating the following two steps.
Step 1: Given a set S, NBFS identifies a collection of neighbor activation sets denoted as ÀúBas follows.
For each (i, j)withi= 1, . . . , L andj= 1, . . . , M i, construct S‚Ä≤asS‚Ä≤=S\(i, j),(i, j)‚ààS‚Ä≤
S‚à™(i, j),(i, j)/‚ààS‚Ä≤.
We check whether S‚Ä≤‚àà B by solving the linear program USLP (S,(i, j))(15) in Appendix A.4.
If there exists such a state x, then S‚Ä≤is added to ÀúB. To further improve efficiency, we employ
the simplex algorithm to calculate the hypercube that overapproximates the boundary hyperplane,
denoted as H(S)‚äáX(S), and relax the last constraint of (14) to x‚àà H(S).
Step 2: For each S‚Ä≤‚ààÀúB, NBFS determines if the activation region X(S‚Ä≤)is on the boundary (i.e.,
satisfies X(S‚Ä≤)‚à©‚àÇD Ã∏=‚àÖ) by checking the feasibility of BoundaryLP (S‚Ä≤). If there exists such a
statex, then S‚Ä≤is added to S. This process continues in a breadth-first search manner until all such
activation sets on the boundary have been enumerated. When this phase terminates, S=B. Detailed
procedure is described as Algorithm 3 in Appendix A.3.
Hinge Enumeration: The verifier of SEEV enumerates a collection Vof boundary hinges, where
each boundary hinge V‚àà V is a subset S1, . . . ,SrofBwithX(S1)‚à©X(Sr)‚à©‚àÇD Ã∏=‚àÖ.
Given Si‚äÜ B andS, hinge enumeration filter the set of neighbor activation sets of Sdefined as
NS(Si) :={S‚Ä≤:S‚Ä≤‚àÜS= 1,S‚Ä≤‚àà Si}. Then, hinge enumeration identifies hinges Vby solving
linear program HingeLP (N(d)
S(Si))(16) in Appendix A.4. If ‚àÉx, hinge enumeration includes the
hinge into the set V ‚à™V. The efficiency can be further improved by leveraging the sufficient condition
verification proposed in Section 4.2. The following result describes the completeness guarantees of S
andVenumerated in Line 5 and 8 of Algorithm 1.
Proposition 2. LetSandVdenote the output of Algorithm 1. Then the boundary ‚àÇDsatisfies
‚àÇD ‚äÜS
S‚ààSX(S). Furthermore, if Sis complete and Tr
i=1X(Si)
‚à© {x:b(x) = 0} Ã∏=‚àÖ, then
{S1, . . . ,Sr} ‚àà V .
The proof is omitted due to the space limit. A detailed proof is provided in Appendix A.2
4.2 Efficient Verification
The efficient verification component takes the sets of boundary hyperplanes Sand boundary hinges
Vand checks that the conditions of Proposition 1 hold for each of them. As pointed out after
Proposition 1, the problem of searching for safety counterexamples can be decomposed into searching
for correctness, hyperplane, and hinge counterexamples. In order to maximize the efficiency of our
approach, we first consider the least computationally burdensome verification task, namely, searching
for correctness counterexamples. We then search for hyperplane counterexamples, followed by hinge
counterexamples.
7Correctness Verification: The correctness condition ( (7)) can be verified for boundary hyperplane
X(S)by solving the nonlinear program (17) in Appendix A.5. When h(x)is convex, (17) can be
solved efficiently. Otherwise, dReal can be used to check satisfiability of (17) in a tractable runtime.
Hyperplane Verification: Hyperplane counterexamples can be identified by solving the optimization
problem (18) in Appendix A.5. Solving (18) can be made more efficient when additional structures
on the input set Uand dynamics fandgare present. Consider a case U={Dœâ:||œâ||‚àû‚â§1}. In
this case, the problem reduces to the nonlinear program (19) in Appendix A.5. If f(x)andg(x)are
linear in x, then the problem boils down to a linear program. If bounds on the Lipschitz coefficients
offandgare available, then they can be used to derive approximations of (19).
IfU=Rm, then by [ 23, Corollary 1], the problem can be reduced to the nonlinear program
(20) in Appendix A.5. If g(x)is a constant matrix G, then safety is automatically guaranteed if
W(S)TGÃ∏= 0. Iff(x)is linear in xas well, then (20) is a linear program.
Hinge Verification: The hinge V={S1, . . . ,Sr}can be certified by solving the nonlinear
optimization problem (21) in Appendix A.5. In practice, simple heuristics are often sufficient to verify
safety of hinges without resorting to solving (21). IfW(S)Tf(x)>0for all x‚ààX(S1)‚à©¬∑¬∑¬∑‚à©X(Sr),
then the control input u=0suffices to ensure safety. Furthermore, if U=Rmand there exists
i‚àà {1, . . . , m }ands‚àà {0,1}such that sign((W(Sl)Tg(x))i) =sfor all x‚ààX(S1)‚à© ¬∑¬∑¬∑X(Sr)
andl= 1, . . . , r , then ucan be chosen as ui=Ksfor some sufficiently large K > 0to ensure that
the conditions of Proposition 1.
Safety Guarantee: The safety guarantees of our proposed approach are summarized in Theorem 2.
Theorem 2. Given a NCBF bŒ∏(x),bŒ∏(x)is a valid NCBF if it passes the verification of Algorithm 1
using dReal to solve the optimization problems (17),(18), and (21).
The proof is derived from completeness of the enumeration in Algorithm 1 and dReal. A detailed
proof can be found in Appendix A.6
5 Experiments
In this section, we evaluate the proposed SEEV in regularizer efficacy and verification efficiency.
We also demonstrated the improved performance with counter-example guidance in the synthesis
framework, whose results are detailed in B.2. We experiment on four systems, namely Darboux,
obstacle avoidance, hi-ord 8, and spacecraft rendezvous. The experiments run on a workstation with
an Intel i7-11700KF CPU, and an NVIDIA GeForce RTX 3080 GPU. We include experiment settings
in Appendix B.1 and hyperparameters settings in Table 4 in Appendix B.3.
5.1 Experiment Setup
Darboux: We consider the Darboux system [ 46], a nonlinear open-loop polynomial system with
detailed settings presented in Appendix B.1
Obstacle Avoidance (OA): We evaluate our proposed method on a controlled system [ 47]. We
consider Unmanned Aerial Vehicles (UA Vs) avoiding collision with a tree trunk. The system state
consists of a 2-D position and aircraft yaw rate x:= [x1, x2, œà]T. The system is manipulated by the
yaw rate input uwith detailed settings presented in Appendix B.1.
Spacecraft Rendezvous (SR): We evaluate our approach on a spacecraft rendezvous problem
from [ 48]. The system state is x= [px, py, pz, vx, vy, vz]Tand control input is u= [ux, uy, uz]T
with with detailed settings presented in Appendix B.1.
hi-ord 8:We evaluate our approach on an eight-dimensional system that first appeared in [ 21] to
evaluate the scalability of the proposed method. Detailed settings can be found in Appendix B.1
5.2 Regularizer Efficacy Evaluation
Table 2 and Figure 3 illustrates the impact of regularization on the CBF boundary‚Äôs activation sets.
Table 2 compares various configurations, where ndenotes the input dimensions, Lrepresents the
number of layers, and Mindicates the number of hidden units per layer. NoandNrare the number of
81.0
0.5
0.0
0.5
1.0 X01.0
0.5
0.00.51.0
X10.25
0.00
0.25
0.50
0.75
1.00(a)r= 0
1.0
0.5
0.0
0.5
1.0 X01.0
0.5
0.00.51.0
X10.25
0.00
0.25
0.50
0.75
1.00 (b)r= 50
Figure 3: Effects of boundary regularization ( r) on activation sets along the boundary. The figures
show the results from a neural network with 4 layers of 8 hidden units, applied to the Spacecraft case.
The surface represents the first two dimensions with the last four dimensions fixed at 0. Increasing r
results in more organized boundary activation sets.
Table 1: Comparison of Nthe number of boundary hyperplanes and Ccoverage of the safe region D
of NCBF trained with and without boundary hyperplane regularizer denoted with subscripts rando.
Case n L M No Co Nr=1 œÅr=1 Nr=10 œÅr=10 Nr=50 œÅr=50
OA3 2 8 26 89.46% 25 0.996 23.3 0.994 13.3 1.006
3 2 16 116 83.74% 119 1.012 111 1.005 98 1.055
3 4 8 40 91.94% 38 0.988 36 0.993 13 0.937
3 4 16 156 87.81% 170 0.971 147 1.003 64 1.038
SR6 2 8 2868 98.58% 2753 1 1559 1 418 1
6 4 8 6371 98.64% 6218 1 3055 1 627 1
6 2 16 N/A N/A 204175 N/A 68783 N/A 13930 N/A
hyperplanes along the zero-level boundary of the CBF without and with regularization, respectively,
withrindicating the regularization strength. Cocaptures the CBF‚Äôs coverage of the safe region,
while œÅ(¬∑)=C(¬∑)/Corepresents the safety coverage ratio relative to the unregularized CBF. Notably,
"N/A" entries indicate configurations where training a fully verifiable network was infeasible due to
the excessive number of boundary hyperplanes, which leads the verification process to time out.
The results demonstrate that regularization effectively reduces the number of activation sets along the
CBF boundary without compromising the coverage of the safe region. The efficiency is especially
improved in cases with a greater number of hidden layers, where the unregularized model results
in a significantly higher number of hyperplanes. For instance, in the SR case with n= 6,L= 4,
andM= 8, the regularization reduces Nr=50to627from No= 6218 , maintaining the same safety
coverage ( œÅr=50= 1). See Appendix B.4 for hyperparameter sensitivity analysis.
Figure 3 illustrates the level sets of two CBFs trained for the SR case with n= 6,L= 4, and
M= 8. These level sets are extracted from the first two dimensions with the rest set to zero. Each
colored patch represents an activation pattern. The regularizer organizes the activation sets around
the boundary, reducing unnecessary rapid changes and thereby enhancing the verification efficiency.
5.3 Efficient Verification Evaluation
The results presented in Table 2 illustrate a significant improvement in verification efficiency for
Neural Control Barrier Functions NCBFs using the proposed method. In the table threpresents the
time spent searching for hyperplanes containing the CBF boundary and verifying CBF sufficient
conditions on these boundaries, and tgrepresents the time spent in hinge enumeration and verification.
The total time, T, is the sum of thandtg. We compare our approach with three baselines, exact
verification [ 23], SMT-based verification [ 21] with dReal and Z3. Baseline methods‚Äô run times are
represented by Baseline [23], dReal, and Z3.
In the Darboux cases, our method achieves verification in 2.5 seconds and 3.3 seconds for M= 256
andM= 512 respectively, whereas baseline methods take substantially longer, with Baseline [ 23]
9Table 2: Comparison of verification run-time of NCBF in seconds. We denote the run-time as ‚ÄòUTD‚Äô
when the method is unable to be directly used for verification.
Case n L M N t h tg SEEV Baseline [23] dReal Z3
Darboux2 2 256 15 2.5s 0 2.5s 315s >3h >3h
2 2 512 15 3.3s 0 3.3s 631s >3h >3h
OA3 2 16 86 0.41s 0 0.41s 16.0s >3h >3h
3 4 8 15 0.39 0 0.39 16.1s >3h >3h
3 4 16 136 0.65s 0 0.65s 36.7s >3h >3h
3 1 128 5778 20.6s 0 20.6s 207s >3h >3h
hi-ord 88 2 8 73 0.54s 0 0.54s >3h >3h >3h
8 2 16 3048 11.8s 0 11.8s >3h >3h >3h
8 4 16 3984 22.4s 0 22.4s >3h >3h >3h
SR6 2 8 2200 7.1s 2.7s 9.8s 179s UTD UTD
6 4 8 4918 45.8s 14.3s 60.1s 298.7s UTD UTD
taking 315 seconds and 631 seconds, and both dReal and Z3 taking more than 3 hours. Similarly,
in the OA cases, our method‚Äôs run times range from 0.39 seconds to 20.6 seconds, faster than the
baseline methods. In the more higher dimensional systems high-ord 8and SR, our method significantly
outperforms Baseline [ 23]. Specifically, in high-ord 8our methods finishes within 22.4 seconds while
Baseline [ 23], dReal and Z3 times out, due to the need to enumerate the 8-dimensional input space.
For the SR case, SEEV‚Äôs run time are 9.8 seconds and 60.1 seconds, beating Baseline [ 23] which
takes 179 seconds and 298.7 seconds respectively. Neural barrier certificate based dReal and Z3 are
able to directly applicable since they require an explicit expression of the controlled feedback system.
However, the SR system is manipulated by an NCBF-based safe controller that is nontrivial to derive
an explicit expression.
Note that hinge enumeration and certification may be time-consuming procedure, since they involve
enumerating all combinations of hyperplanes. However, the results from Table 2 show that the
certification can be completed on most hyperplanes with sufficient condition verification in Section
4.2, greatly improving the overall run time.
6 Conclusion
This paper considered the problem of synthesizing and verifying NCBFs with ReLU activation
function in an efficient manner. Our approach is guided by the fact that the main contribution to the
computational cost of verifying NCBFs is enumerating and verifying safety of each piecewise-linear
activation region at the safety boundary. We proposed Synthesis with Efficient Exact Verification
(SEEV), which co-designs the synthesis and verification components to enhance scalability of the
verification process. We augment the NCBF synthesis with a regularizer that reduces the number of
piecewise-linear segments at the boundary, and hence reduces the total workload of the verification.
We then propose a verification approach that efficiently enumerates the linear segments at the boundary
and exploits tractable sufficient conditions for safety.
Limitations: The method proposed in this paper mitigated the scalability issue. However, the
synthesis and verification of NCBFs for higher-dimensional systems is challenging. Exact verification
of non-ReLU NCBFs, which lack ReLU‚Äôs simple piecewise linearity, remains an open problem.
Acknowledgements and Disclosure of Funding
This research was partially supported by NSF grant CNS-1941670, CMMI-2418806, AFOSR grant
FA9550-22-1-0054, NSF Career CCF 2047034, NSF CCF DASS 2217723, NSF AI Institute CCF
2112665, and Amazon Research Award.
10References
[1]Shao-Chen Hsu, Xiangru Xu, and Aaron D Ames. Control barrier function based quadratic
programs with application to bipedal robotic walking. In 2015 American Control Conference
(ACC) , pages 4542‚Äì4548. IEEE, 2015.
[2]Devansh R Agrawal and Dimitra Panagou. Safe control synthesis via input constrained control
barrier functions. In 2021 60th IEEE Conference on Decision and Control (CDC) , pages
6113‚Äì6118. IEEE, 2021.
[3]Xiangru Xu, Jessy W Grizzle, Paulo Tabuada, and Aaron D Ames. Correctness guarantees for
the composition of lane keeping and adaptive cruise control. IEEE Transactions on Automation
Science and Engineering , 15(3):1216‚Äì1229, 2017.
[4]Joseph Breeden and Dimitra Panagou. High relative degree control barrier functions under input
constraints. In 2021 60th IEEE Conference on Decision and Control (CDC) , pages 6119‚Äì6124.
IEEE, 2021.
[5]Hongkai Dai and Frank Permenter. Convex synthesis and verification of control-lyapunov and
barrier functions with input constraints. In 2023 American Control Conference (ACC) , pages
4116‚Äì4123. IEEE, 2023.
[6]Shucheng Kang, Yuxiao Chen, Heng Yang, and Marco Pavone. Verification and synthesis of
robust control barrier functions: Multilevel polynomial optimization and semidefinite relaxation,
2023.
[7]Nicholas Rober, Michael Everett, Songan Zhang, and Jonathan P How. A hybrid partition-
ing strategy for backward reachability of neural feedback loops. In 2023 American Control
Conference (ACC) , pages 3523‚Äì3528. IEEE, 2023.
[8]Charles Dawson, Sicun Gao, and Chuchu Fan. Safe control with learned certificates: A survey of
neural Lyapunov, barrier, and contraction methods for robotics and control. IEEE Transactions
on Robotics , 2023.
[9]Oswin So, Zachary Serlin, Makai Mann, Jake Gonzales, Kwesi Rutledge, Nicholas Roy, and
Chuchu Fan. How to train your neural control barrier function: Learning safety filters for
complex input-constrained systems. arXiv preprint arXiv:2310.15478 , 2023.
[10] Charles Dawson, Zengyi Qin, Sicun Gao, and Chuchu Fan. Safe nonlinear control using robust
neural Lyapunov-barrier functions. In Conference on Robot Learning , pages 1724‚Äì1735. PMLR,
2022.
[11] Manan Tayal, Hongchao Zhang, Pushpak Jagtap, Andrew Clark, and Shishir Kolathaya. Learn-
ing a formally verified control barrier function in stochastic environment. arXiv preprint
arXiv:2403.19332 , 2024.
[12] Kehan Long, Cheng Qian, Jorge Cort√©s, and Nikolay Atanasov. Learning barrier functions with
memory for robust safe navigation. IEEE Robotics and Automation Letters , 6(3):4931‚Äì4938,
2021.
[13] Wei Xiao, Tsun-Hsuan Wang, Ramin Hasani, Makram Chahine, Alexander Amini, Xiao Li,
and Daniela Rus. Barriernet: Differentiable control barrier functions for learning of safe robot
control. IEEE Transactions on Robotics , 2023.
[14] Hengjun Zhao, Xia Zeng, Taolue Chen, Zhiming Liu, and Jim Woodcock. Learning safe neural
network controllers with barrier certificates. Formal Aspects of Computing , 33:437‚Äì455, 2021.
[15] Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient neu-
ral network robustness certification with general activation functions. Advances in Neural
Information Processing Systems , 31:4939‚Äì4948, 2018.
[16] Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie Huang, Bhavya
Kailkhura, Xue Lin, and Cho-Jui Hsieh. Automatic perturbation analysis for scalable certified
robustness and beyond. Advances in Neural Information Processing Systems , 33, 2020.
11[17] Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang. A convex
relaxation barrier to tight robustness verification of neural networks. Advances in Neural
Information Processing Systems , 32:9835‚Äì9846, 2019.
[18] Kaidi Xu, Huan Zhang, Shiqi Wang, Yihan Wang, Suman Jana, Xue Lin, and Cho-Jui Hsieh.
Fast and Complete: Enabling complete neural network verification with rapid and massively
parallel incomplete verifiers. In International Conference on Learning Representations , 2021.
[19] Shiqi Wang, Huan Zhang, Kaidi Xu, Xue Lin, Suman Jana, Cho-Jui Hsieh, and J Zico Kolter.
Beta-CROWN: Efficient bound propagation with per-neuron split constraints for complete and
incomplete neural network verification. Advances in Neural Information Processing Systems ,
34, 2021.
[20] Huan Zhang, Shiqi Wang, Kaidi Xu, Yihan Wang, Suman Jana, Cho-Jui Hsieh, and Zico
Kolter. A branch and bound framework for stronger adversarial attacks of ReLU networks. In
Proceedings of the 39th International Conference on Machine Learning , volume 162, pages
26591‚Äì26604, 2022.
[21] Alessandro Abate, Daniele Ahmed, Alec Edwards, Mirco Giacobbe, and Andrea Peruffo. Fossil:
A software tool for the formal synthesis of Lyapunov functions and barrier certificates using
neural networks. In Proceedings of the 24th International Conference on Hybrid Systems:
Computation and Control , pages 1‚Äì11, 2021.
[22] Alec Edwards, Andrea Peruffo, and Alessandro Abate. Fossil 2.0: Formal certificate synthesis
for the verification and control of dynamical models. arXiv preprint arXiv:2311.09793 , 2023.
[23] Hongchao Zhang, Junlin Wu, Yevgeniy V orobeychik, and Andrew Clark. Exact verification of
relu neural control barrier functions. Advances in Neural Information Processing Systems , 36,
2024.
[24] Felix Berkenkamp, Matteo Turchetta, Angela Schoellig, and Andreas Krause. Safe model-based
reinforcement learning with stability guarantees. Advances in Neural Information Processing
Systems , 30, 2017.
[25] Zengyi Qin, Kaiqing Zhang, Yuxiao Chen, Jingkai Chen, and Chuchu Fan. Learning safe multi-
agent control with decentralized neural barrier certificates. arXiv preprint arXiv:2101.05436 ,
2021.
[26] Zhizhen Qin, Tsui-Wei Weng, and Sicun Gao. Quantifying safety of learning-based self-
driving control using almost-barrier functions. In 2022 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS) , pages 12903‚Äì12910. IEEE, 2022.
[27] Simin Liu, Changliu Liu, and John Dolan. Safe control under input limits with neural control
barrier functions. In Conference on Robot Learning , pages 1970‚Äì1980. PMLR, 2023.
[28] Stephen Prajna, Ali Jadbabaie, and George J Pappas. A framework for worst-case and stochas-
tic safety verification using barrier certificates. IEEE Transactions on Automatic Control ,
52(8):1415‚Äì1428, 2007.
[29] Aaron D Ames, Samuel Coogan, Magnus Egerstedt, Gennaro Notomista, Koushil Sreenath, and
Paulo Tabuada. Control barrier functions: Theory and applications. In 2019 18th European
control conference (ECC) , pages 3420‚Äì3431. IEEE, 2019.
[30] Weiye Zhao, Tairan He, Tianhao Wei, Simin Liu, and Changliu Liu. Safety index synthesis via
sum-of-squares programming. In 2023 American Control Conference (ACC) , pages 732‚Äì737.
IEEE, 2023.
[31] Michael Schneeberger, Florian D√∂rfler, and Silvia Mastellone. SOS construction of compatible
control Lyapunov and barrier functions. arXiv preprint arXiv:2305.01222 , 2023.
[32] Andrew Clark. Verification and synthesis of control barrier functions. In 2021 60th IEEE
Conference on Decision and Control (CDC) , pages 6105‚Äì6112. IEEE, 2021.
12[33] Claudio Ferrari, Mark Niklas Muller, Nikola Jovanovic, and Martin Vechev. Complete verifica-
tion via multi-neuron relaxation guided branch-and-bound. arXiv preprint arXiv:2205.00263 ,
2022.
[34] Patrick Henriksen and Alessio Lomuscio. Deepsplit: An efficient splitting method for neural
network verification via indirect effect analysis. In IJCAI , pages 2549‚Äì2555, 2021.
[35] Huan Zhang, Shiqi Wang, Kaidi Xu, Linyi Li, Bo Li, Suman Jana, Cho-Jui Hsieh, and J Zico
Kolter. General cutting planes for bound-propagation-based neural network verification. Ad-
vances in Neural Information Processing Systems , 35:1656‚Äì1670, 2022.
[36] Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An
efficient SMT solver for verifying deep neural networks. In Computer Aided Verification: 29th
International Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings,
Part I 30 , pages 97‚Äì117. Springer, 2017.
[37] Guy Katz, Derek A Huang, Duligur Ibeling, Kyle Julian, Christopher Lazarus, Rachel Lim,
Parth Shah, Shantanu Thakoor, Haoze Wu, Aleksandar Zelji ¬¥c, et al. The Marabou framework
for verification and analysis of deep neural networks. In Computer Aided Verification: 31st
International Conference, CAV 2019, New York City, NY, USA, July 15-18, 2019, Proceedings,
Part I 31 , pages 443‚Äì452. Springer, 2019.
[38] Hengjun Zhao, Xia Zeng, Taolue Chen, and Zhiming Liu. Synthesizing barrier certificates
using neural networks. In Proceedings of the 23rd international conference on hybrid systems:
Computation and control , pages 1‚Äì11, 2020.
[39] Alessandro Abate, Daniele Ahmed, Mirco Giacobbe, and Andrea Peruffo. Formal synthesis of
lyapunov neural networks. IEEE Control Systems Letters , 5(3):773‚Äì778, 2020.
[40] Andrea Peruffo, Daniele Ahmed, and Alessandro Abate. Automated and formal synthesis of
neural barrier certificates for dynamical models. In Tools and Algorithms for the Construction
and Analysis of Systems , pages 370‚Äì388. Springer International Publishing, 2021.
[41] Mahathi Anand and Majid Zamani. Formally verified neural network control barrier certificates
for unknown systems. IFAC-PapersOnLine , 56(2):2431‚Äì2436, 2023.
[42] Yixuan Wang, Chao Huang, Zhaoran Wang, Zhilu Wang, and Qi Zhu. Design-while-verify:
correct-by-construction control learning with verification in the loop. In Proceedings of the
59th ACM/IEEE Design Automation Conference , pages 925‚Äì930, 2022.
[43] Xinyu Wang, Luzia Knoedler, Frederik Baymler Mathiesen, and Javier Alonso-Mora. Simulta-
neous synthesis and verification of neural control barrier functions through branch-and-bound
verification-in-the-loop training. In 2024 European Control Conference (ECC) , pages 571‚Äì578.
IEEE, 2024.
[44] Franco Blanchini and Stefano Miani. Set-Theoretic Methods in Control , volume 78. Springer,
2008.
[45] A. Agrawal, B. Amos, S. Barratt, S. Boyd, S. Diamond, and Z. Kolter. Differentiable convex
optimization layers. In Advances in Neural Information Processing Systems , 2019.
[46] Xia Zeng, Wang Lin, Zhengfeng Yang, Xin Chen, and Lilei Wang. Darboux-type barrier
certificates for safety verification of nonlinear hybrid systems. In Proceedings of the 13th
International Conference on Embedded Software , pages 1‚Äì10, 2016.
[47] Andrew J Barry, Anirudha Majumdar, and Russ Tedrake. Safety verification of reactive
controllers for uav flight in cluttered environments using barrier certificates. In 2012 IEEE
International Conference on Robotics and Automation , pages 484‚Äì490. IEEE, 2012.
[48] Christopher Jewison and R Scott Erwin. A spacecraft benchmark problem for hybrid control and
estimation. In 2016 IEEE 55th Conference on Decision and Control (CDC) , pages 3300‚Äì3305.
IEEE, 2016.
13A Supplement
A.1 Definition of Wij(S)andrij(S)
In what follows, we define vectors Wij(S)‚ààRnand scalars rij(S)‚ààRsuch that z(i)
j=
Wij(S)Tx+rij(S). The weight and bias of the input layer is defined by
W1j(S) =
W1j,(1, j)‚ààS
0, elser1j(S) =
r1j,(1, j)‚ààS
0, else
Proceeding inductively, define Wi(S)‚ààRMi√ónto be a matrix with columns Wij(S)forj=
1, . . . , M iandri(S)‚ààRMito be a vector with elements rij(S). We then define
Wij(S) =
Wi‚àí1(S)Wij,(i, j)‚ààS
0, elserij(S) =
WT
ijri‚àí1(S) +rij,(i, j)‚ààS
0, else
At the last layer, let W(S) =WL(S)‚Ñ¶andr(S) = ‚Ñ¶TrL(S) +œà, so that y=W(S)Tx+r(S)if
S={(i, j) :z(i)
j‚â•0}.
A.2 Proof of Proposition 2
Proof. Suppose that x‚Ä≤‚àà‚àÇD \ S
S‚ààSX(S)
, and let xdenote the state on ‚àÇDfound by Line 5 of
Algorithm 1. Since ‚àÇDis connected, there exists a path Œ≥withŒ≥(0) = xandŒ≥(1) = x‚Ä≤contained
in‚àÇD. LetS0,S1, . . . ,SKdenote a sequence of activation sets with S0‚ààS(x),SK‚ààS(x‚Ä≤), and
S0equal to the set computed at Line 5 of Algorithm 1. Then there exists i‚â•2such that Si‚àí1‚àà S
andSi/‚àà S, and there exists t‚Ä≤such that Œ≥(t‚Ä≤)‚ààX(Si‚àí1)‚à©X(Si)‚à© {x:b(x) = 0}. We then have
thatT(Si‚àí1,Si)is a subset of the set T, and hence Siwill be identified and added to Sat Line 5 of
Algorithm 1.
Now, suppose that S1, . . . ,Sr‚àà S is complete and Tr
i=1X0(Si)
‚à© {x:b(x) = 0} Ã∏=‚àÖ. Let
T=T(S1, . . . ,Sr). Then Tis a subset of the sets S1, . . . ,Sr‚àà S. Since the intersection of the
X(S)sets with {x:b(x) = 0}is nonempty, {S1, . . . ,Sr}is added to V.
A.3 Algorithm for Verification
SEEV identifies the initial activation set by conducting a BoundaryLP-based binary search as shown
in Algorithm. 2. The algorithm presents a procedure to identify a hyperplane characterized by
an initial activation set S0that may contain the boundary ‚àÇD. It iterates over pairs of sample
states from the unsafe training set TX\Cand the safe training set TI. For each pair (ÀÜxX\C,ÀÜxI), the
algorithm initializes the left and right points of a search interval. It then performs a binary search by
repeatedly computing the midpoint xmidand checking the feasibility of the boundary linear program
BoundaryLP (xmid). The algorithm terminates when BoundaryLP (xmid)is feasible, returning the
activation set S(xmid)asS0.
SEEV utilizes NBFS for enumerating all activation sets along the zero-level set in a breadth-first
search manner, starting from an initial set S0. The algorithm initializes a queue Qand a set Swith
S0. While Qis not empty, it dequeues an activation set Sand checks if the set S‚àà B by solving the
boundary linear program BoundaryLP (S). If so, Sis identified and added to S. The algorithm then
explores its neighboring activation sets by flipping each neuron activation (i, j)inS. For each flip, it
solves the unstable neuron linear program USLP (S,(i, j)). IfUSLP is feasible, the new activation
setS‚Ä≤obtained by flipping (i, j)is added to Qfor further search on its neighbors. This process
continues until all relevant activation sets are explored, resulting in a set Sthat contains activation
sets potentially on the boundary.
SEEV enumerates all hinges V‚àà V with Algorithm 4. Algorithm 4 outlines a method to enumerate
all feasible hinge hyperplanes formed by combinations of activation sets up to size n. The algorithm
takes as input a set of activation sets Sand a maximum combination size n. It initializes an empty
list to store feasible hinges. For each combination size kfrom 2ton, the algorithm iterates over
all activation sets in S. For each activation set S, it generates candidate combinations Vcbased
on adjacency‚Äîeither the set of adjacent activation sets when k= 2, or the feasible combinations
14Algorithm 2 Binary Search for S0
1:Input: TX\C,TI
2:Output: initial activation set S0
3:procedure ENUM INIT(TX\C,TI)
4: forÀÜxX\C‚àà TX\CandÀÜxI‚àà TIdo ‚ñ∑Loop over all pairs of samples
5: xleft, xright‚ÜêÀÜxX\C,ÀÜxI
6: xmid= 0.5(xleft+xright)
7: while xleft< xright do
8: ifBoundaryLP (xmid)then ‚ñ∑Check if the BoundaryLP is feasible
9: Return S(xmid) ‚ñ∑Return S(xmid)asS0
10: ifW(S(x‚Ä≤))xmid+r(S(x‚Ä≤))‚â•0then ‚ñ∑Check if b(xmid)>0
11: xright‚Üêxmid ‚ñ∑Update the right point
12: else
13: xleft‚Üêxmid ‚ñ∑Update the left point
Algorithm 3 Enumerate Activated Sets
1:Input: S0
2:Output: Set of activation sets S
3:procedure NBFS( S0)
4: Initialize queue Qwith initial activation set S0
5: Initialize sets SwithS0
6: while queueQis not empty do
7: Dequeue SfromQ ‚ñ∑Dequeue the first activation set from the queue
8: ifBoundaryLP (S)is feasible then ‚ñ∑Check if Sis on a boundary activation set
9: ifS/‚àà S then ‚ñ∑IfSis not already in S
10: AddStoS
11: for(i, j)‚àà {1, . . . , L } √ó { 1, . . . , M i}do ‚ñ∑For activation (i, j)of each neurons
12: ifUSLP (S,(i, j))then ‚ñ∑Check if the neighbor may contain zero-level set
13: Create S‚Ä≤by flipping activation (i, j)
14: AddS‚Ä≤toQ ‚ñ∑Add adjacent activation set S‚Ä≤to the queue
15: Return S
from the previous iteration when k >2. It then checks each candidate combination Scby verifying
adjacency and solving the hinge linear program HingeLP (Sc‚à™ {S}). If the HingeLP is feasible, the
combination is added to the list of feasible hinges V. This process continues until all combinations
up to size nhave been examined, resulting in a comprehensive list of feasible hinge hyperplanes that
are essential for understanding the intersections of activation regions.
A.4 Linear Programs for Enumeration
Given a state x0
i, we define the activation set is S=œÑS(x0
i). To determine if the activation set S‚àà B,
we solve a linear program referred to as the boundary linear program. The program checks the
existence of a state x‚ààX(S(x0
i))that satisfies W(S(x0
i))Tx+r(S(x0
i)) = 0 . The boundary linear
program (BoundaryLP (S(x0
i))) is defined as follows.
BoundaryLP (S(x0
i)) =Ô£±
Ô£≤
Ô£≥find x
s.t. W(S(x0
i))Tx+r(S(x0
i)) = 0
x‚ààX(S(x0
i))(14)
NBFS conducts its search in a breadth-first manner. To determine if a neighboring activation set,
resulting from a flip in its (i, j)neuron, may contain the boundary, NBFS solves a linear program,
referred to as the unstable neuron linear program of USLP (S,(i, j)). This linear program checks
the existence of a state x‚ààX(S)‚à© {x:Wijx+rij= 0}that satisfies W(S)x+r(S) = 0 . The
15Algorithm 4 Enumerate Hinges
1:Input: S,n
2:Output: V
3:procedure HINGE ENUM (S, n)
4: Initialize hinge_list as an empty list
5: forkfrom 2tondo ‚ñ∑Outer loop to iterate over combination sizes
6: forS‚àà S do ‚ñ∑Iterate over all activation set
7: ifk= 2then
8: Vc‚Üê N S(S)
9: else
10: Vc‚Üê V(k‚àí1)
11: foreach combination Sc‚àà VcandS/‚àà Scdo ‚ñ∑Iterate over combinations
12: ifSandScare not adjacent then
13: Continue ‚ñ∑skip non-adjacent combinations
14: ifHingeLP (Sc‚à™ {S})then
15: AddV‚Üê S c‚à™ {S}toV(k)‚ñ∑Add to set of corresponding k
16: AddV(k)toV
17: return hinge_list
unstable neuron linear program is defined as follows.
USLP (S,(i, j)) =Ô£±
Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥Ô£≥find x
s.t. W(S)Tx+r(S) = 0
Wij(S)Tx+rij(S) = 0
x‚ààX(S)(15)
Finally, we enumerate all hinges by solving the hinge linger program HingeLP (Si), defined as
follows.
HingeLP (N(d)
S(Si)) =Ô£±
Ô£≤
Ô£≥find x
s.t. W(S)Tx+r(S) = 0 ,‚àÄS‚àà NS(Si)
x‚àà X(S),‚àÄS‚àà NS(Si)(16)
A.5 Nonlinear Programs for Verification
The correctness condition ( (7)) can be verified for boundary hyperplane X(S)by solving the nonlinear
program
minxh(x)
s.t. W(S)Tx+r(S) = 0 , x‚ààX(S)(17)
If we found some state xsuch that h(x)<0andW(S)Tx+r(S) = 0 , it indicates that the state lies
on the boundary of the set Dbut not inside the set C, i.e., x‚àà‚àÇD/‚àà C. This implies a violation of
the condition D ‚äÜ C .
Hyperplane counterexamples can be identified by solving the optimization problem
minxmax{W(S)T(f(x) +g(x)u) :u‚àà U}
s.t. W(S)Tx+r(S) = 0 , x‚ààX(S)(18)
Consider a case U={Dœâ:||œâ||‚àû‚â§1}. The bounded input set Uallows us to replace the
maximization over uwithL-1 norm term ‚à•W(S)Tg(x)D‚à•1, which simplifies the computational
complexity. In this case, the problem reduces to the nonlinear program
min
xW(S)Tf(x) +‚à•W(S)Tg(x)D‚à•1
s.t.W(S)Tx+r(S) = 0 , x‚ààX(S)(19)
IfU=Rm, then by [23, Corollary 1], the problem can be reduced to the nonlinear program
minxW(S)Tf(x)
s.t. W(S)Tg(x) = 0 ,W(S)x+r(S) = 0 , x‚ààX(S)(20)
16The hinge V={S1, . . . ,Sr}can be certified by solving the nonlinear optimization problem
minxmax{W(Sl)T(f(x) +g(x)u) :l= 1, . . . , r, u satisfies (4)‚Äì(5) }
s.t. x‚ààX(S1)‚à© ¬∑¬∑¬∑ ‚à© X(Sr),W(S1)Tx+r(S1) = 0(21)
A.6 Proof of Theorem 2
Proof. By Lemma 1, the initial boundary activation set S0is ensured to be identified by the verifica-
tion of SEEV in Line 4 Algorithm. 1. Given S0and the enumeration in Line 5 and 6 Algorithm. 1
being complete, the completeness of SandVis guaranteed by Proposition 2. By dReal solving the
equivalent NLPs, the conditions of Proposition 1, are satisfied. Therefore, bŒ∏(x)is a valid NCBF
B Experiments
B.1 Experiment Settings
Experiment Settings of Darboux: The dynamic model of Darboux is given as follows.
Àôx1
Àôx2
=
x2+ 2x1x2
‚àíx1+ 2x2
1‚àíx2
2
. (22)
We define state space, initial region, and safe region as X:
x‚ààR2:x‚àà[‚àí2,2]√ó[‚àí2,2]	
,
I:
x‚ààR2: 0‚â§x1‚â§1,1‚â§x2‚â§2	
andC:
x‚ààR2:x1+x2
2‚â•0	
respectively.
Experiment Settings of the Obstacle Avoidance: The dynamic model of obstacle avoidance is
given as follows.Ô£Æ
Ô£∞Àôx1
Àôx2
ÀôœàÔ£π
Ô£ª="vsinœà
vcosœà
0#
+"0
0
u#
. (23)
We define the state space, initial region and safe region as X,IandC, respectively as
X:
x‚ààR3:x1, x2, œà‚àà[‚àí2,2]√ó[‚àí2,2]√ó[‚àí2,2]	
I:
x‚ààR3:‚àí0.1‚â§x1‚â§0.1,‚àí2‚â§x2‚â§ ‚àí1.8,‚àíœÄ/6< œà < œÄ/ 6	
C:
x‚ààR3:x2
1+x2
2‚â•0.04	(24)
Experiment Settings of the Spacecraft Rendezvous: The state of the chaser is expressed relative to
the target using linearized Clohessy‚ÄìWiltshire‚ÄìHill equations, with state x= [px, py, pz, vx, vy, vz]T,
control input u= [ux, uy, uz]Tand dynamics defined as follows.Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞Àôpx
Àôpy
Àôpz
Àôvx
Àôvy
ÀôvzÔ£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª=Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞1 0 0 0 0 0
0 1 0 0 0 0
0 0 1 0 0 0
3n20 0 0 2 n0
0 0 0 ‚àí2n0 0
0 0 ‚àín20 0 0Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ªÔ£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞px
py
pz
vx
vy
vzÔ£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª+Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞0 0 0
0 0 0
0 0 0
1 0 0
0 1 0
0 0 1Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª"ux
uy
uz#
. (25)
We define the state space and safe region as X, initial safe region XIandC, respectively as
X:
x‚ààR3:p, v,‚àà[‚àí5,5]√ó[‚àí1,1]	
I:n
r‚â•0.75, where r=q
p2x+p2y+p2zo
C:n
r‚â•0.25, where r=q
p2x+p2y+p2zo(26)
hi-ord 8:The dynamic model of hi-ord 8is given as follows.
x(8)+ 20x(7)+ 170 x(6)+ 800 x(5)+ 2273 x(4)+ 3980 x(3)+ 4180 x(2)+ 2400 x(1)+ 576 = 0 (27)
where we denote the i-th derivative of variable xbyx(i). We define the state space X, initial region
XIand safe region C, respectively as
X:
x2
1+. . .+x2
8‚â§4	
I:
(x1‚àí1)2+. . .+ (x8‚àí1)2‚â§1	
C:n
(x1+ 2)2+. . .+ (x8+ 2)2‚â•3o(28)
17B.2 Synthesis Framework Evaluation
The experimental results presented in Table 3 demonstrate the effectiveness of Counter Example
(CE) guided training on Darboux and hi-ord 8system. In this method, after each training epoch, we
calculate the Control Barrier Function (CBF) outputs on representative samples. If the CBF correctly
categorizes the samples into safe and unsafe regions, the certification procedure is initiated. If the
CBF fails certification, the counter example is added to the training dataset for retraining. Otherwise,
training is stopped early.
We capped the maximum training epochs at 50 and conducted three rounds of training for each
network structure and system using different random seeds. The results indicate that without CE, the
training process could basrely generate a CBF that passes certification. In contrast, with CE enabled,
there was a success rate of at least 1/3 for most network structure, with verifiable policies generated
in as few as 10 epochs. This highlights the improvement in training efficiency and reliability with the
incorporation of CEs.
Case L MNo CE With CE
sr sr min epoch
Darboux2 8 0/3 3/3 38
2 16 0/3 1/3 10
4 8 0/3 1/3 43
4 16 0/3 2/3 26
hi-ord 82 8 1/3 1/3 15
2 16 0/3 2/3 19
4 8 0/3 0/3 -
4 16 0/3 2/3 13
Table 3: Success rates (sr) and minimum epochs required for certification with and without Counter
Example (CE) guided training for different network structures on Darboux and hi-ord 8systems.
B.3 Hyperparameters
Table 4 shows values the following hyperparameters used during CBF synthesis:
‚Ä¢Ndata: number of samples to train CBF on.
‚Ä¢a1: weight penalizing incorrect classification of safe samples in Equation 11.
‚Ä¢a2: weight penalizing incorrect classification of unsafe samples Equation 11.
‚Ä¢Œªf: weight penalizing violation of Lie derivative condition of CBF in Equation 9.
‚Ä¢Œªc: weight penalizing correct loss for in Equation 9.
‚Ä¢ncluster : number of clusters in LBregularization.
‚Ä¢kœÉ: value of kused in generalized sigmoid function to perform differentiable activation
pattern approximation.
‚Ä¢œµboundary : the threshold for range-based approximation of CBF boundary.
Case Ndata a1a2ŒªfŒªcncluster kœÉ œµboundary
Darboux 5000 100 100 4.0 1.0 N/A N/A N/A
hi-ord 8 50000 100 200 1.0 1.0 N/A N/A N/A
OA 10000 100 100 2.0 1.0 5 4 1.0
SR 10000 100 100 2.0 1.0 5 4 1.0
Table 4: Hyperparameters of CBF synthesis.
B.4 Sensitivity Analysis of Hyperparameters
Next, we performed a sensitivity analysis of the hyperparameters. We chose the case study of
Spacecraft Rendezvous with the number of layers L= 4and the number of hidden units per layer
18Œªc SR ME N
1 0/3 x x
10 0/3 x x
100 3/3 17 3265
200 3/3 17.7 2922
(a) Ablation study on ŒªcŒªfSR ME N
1 3/3 16.3 3254
2 3/3 17 3265
4 3/3 17 3352
8 2/3 29.5 3419.5
(b) Ablation study on ŒªfkSR ME N
13/3 18 3842
23/3 15.7 3523
43/3 17 3265
81/3 10 1984
(c) Ablation study on k
Table 5: Ablation study for training hyperparameters. In each table, the bold lines indicate the
baseline setting. SR: the success rate among runs with three random seeds. ME: the average first
training epoch when a valid NCBF is obtained. N: the average number of boundary hyperplanes.
N= 8. We studied the sensitivity of the training performance to the hyperparameters ŒªB,Œªf,
andŒªcin Equation 8, corresponding to the weightings for regularizing the number of boundary
hyperplanes, NCBF value violation, and NCBF Lie derivative violation, respectively. We also
studied the sensitivity to the hyperparameter kemployed in the modified sigmoid function œÉk(z) =
1
1+exp( ‚àík¬∑z)to approximate the regularization pattern. We compared against the settings used in the
original paper: ŒªB= 10 ,Œªf= 2,Œªc= 100 , and k= 4. For each hyperparameter, we chose four
values to perform the ablation study: ŒªB‚àà {0,1,10,50},Œªf‚àà {1,2,4,8},Œªc‚àà {1,10,100,200},
andk‚àà {1,2,4,8}. For each setting, we performed three runs with different random seeds. We
measured the results by Success Rate (SR) ,Min Epoch (ME) , andN, as described in the caption of
Table 5.
Œªcregularizes the shape of the NCBF by penalizing incorrectly categorized samples. Table 5a
indicates that when Œªcis too small, the training procedure fails to train an NCBF that correctly
separates the safe and unsafe regions, resulting in failure of certification. Meanwhile, a larger weight
delivers similarly good performance.
Œªfpenalizes violations of Lie derivative conditions. Table 5b shows that the result is not sensitive to
this hyperparameter, as this term quickly goes down to 0 when the Lie derivative condition is satisfied.
We note that over-penalizing this condition should be avoided since the NCBF would otherwise learn
an unrecoverable incorrect shape, as demonstrated by the failure case when Œªf= 8.
ŒªBhas been studied in the original paper, with detailed analysis in Section 5.2. The boundary
regularization term reduces the number of boundary hyperplanes and benefits convergence.
Table 5c shows the importance of the term kused in the modified sigmoid function. Since this
term appears in the exponential part of the sigmoid function, when it is too large, it leads to
gradient explosions during backpropagation, which crashes the training process. Conversely, a
reasonably larger kbetter approximates the activation pattern, leading to a reduced number of
boundary hyperplanes.
In summary, balancing the hyperparameters is relatively straightforward, as the training performance
remains robust across a wide range of hyperparameter values. When training failures do occur, we
can systematically identify the cause from observation. This enables proper guidance in choosing
and adjusting the appropriate hyperparameters.
19NeurIPS Paper Checklist
The checklist is designed to encourage best practices for responsible machine learning research,
addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
the checklist: The papers not including the checklist will be desk rejected. The checklist should
follow the references and follow the (optional) supplemental material. The checklist does NOT count
towards the page limit.
Please read the checklist guidelines carefully for information on how to answer these questions. For
each question in the checklist:
‚Ä¢ You should answer [Yes] , [No] , or [NA] .
‚Ä¢[NA] means either that the question is Not Applicable for that particular paper or the
relevant information is Not Available.
‚Ä¢ Please provide a short (1‚Äì2 sentence) justification right after your answer (even for NA).
The checklist answers are an integral part of your paper submission. They are visible to the
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
(after eventual revisions) with the final version of your paper, and its final version will be published
with the paper.
The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a
proper justification is given (e.g., "error bars are not reported because it would be too computationally
expensive" or "we were unable to find the license for the dataset we used"). In general, answering
"[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we
acknowledge that the true answer is often more nuanced, so please just use your best judgment and
write a justification to elaborate. All supporting evidence can appear either in the main paper or the
supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification
please point to the section(s) where related material for the question can be found.
IMPORTANT, please:
‚Ä¢Delete this instruction block, but keep the section heading ‚ÄúNeurIPS paper checklist" ,
‚Ä¢Keep the checklist subsection headings, questions/answers and guidelines below.
‚Ä¢Do not modify the questions and only use the provided macros for your answers .
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper‚Äôs contributions and scope?
Answer: [Yes]
Justification: The abstract and introduction clearly states the paper‚Äôs contributions and scope.
Guidelines:
‚Ä¢The answer NA means that the abstract and introduction do not include the claims
made in the paper.
‚Ä¢The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
‚Ä¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
‚Ä¢It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We point out the limitation on dynamical models in Section 2.1 and limitations
on the type of activation functions throughout the paper.
20Guidelines:
‚Ä¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
‚Ä¢ The authors are encouraged to create a separate "Limitations" section in their paper.
‚Ä¢The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
‚Ä¢The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
‚Ä¢The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
‚Ä¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
‚Ä¢If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
‚Ä¢While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren‚Äôt acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We present assumptions in Section 2, and theoretical contributions in Section
4 with proof in the appendix.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include theoretical results.
‚Ä¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
‚Ä¢All assumptions should be clearly stated or referenced in the statement of any theorems.
‚Ä¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
‚Ä¢Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
‚Ä¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We specified random seeds for reproducibility. The code is uploaded with all
the commands containing random seeds.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include experiments.
21‚Ä¢If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
‚Ä¢If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
‚Ä¢Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
‚Ä¢While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: The code is submitted with the paper.
Guidelines:
‚Ä¢ The answer NA means that paper does not include experiments requiring code.
‚Ä¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
‚Ä¢While we encourage the release of code and data, we understand that this might not be
possible, so ‚ÄúNo‚Äù is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
‚Ä¢The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
‚Ä¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
‚Ä¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
‚Ä¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
22‚Ä¢Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We provide the detailed experiment settings with hyperparameters in the
appendix. We present how to generate training data in Section 3.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include experiments.
‚Ä¢The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
‚Ä¢The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: All verification experiments are conducted in a deterministic manner. We also
present the success rate of training with random seeds in the appendix.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include experiments.
‚Ä¢The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
‚Ä¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
‚Ä¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
‚Ä¢ The assumptions made should be given (e.g., Normally distributed errors).
‚Ä¢It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
‚Ä¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
‚Ä¢For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
‚Ä¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We present the details of the machine we experiment on in Section 5.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include experiments.
23‚Ä¢The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
‚Ä¢The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
‚Ä¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn‚Äôt make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: the research conducted in the paper conforms, in every respect, with the
NeurIPS Code of Ethics
Guidelines:
‚Ä¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
‚Ä¢If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
‚Ä¢The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: This paper focuses on the safe control problem of dynamical systems. There-
fore it would not harm or raise technology to harm the society.
Guidelines:
‚Ä¢ The answer NA means that there is no societal impact of the work performed.
‚Ä¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
‚Ä¢Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
‚Ä¢The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
‚Ä¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
‚Ä¢If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
24Answer: [NA]
Justification: the paper poses no such risks. The experiments we conduct only generate
simulation-based data of dynamic systems with no such risks.
Guidelines:
‚Ä¢ The answer NA means that the paper poses no such risks.
‚Ä¢Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
‚Ä¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
‚Ä¢We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We cited all references in the both the paper and the code Readme file.
Guidelines:
‚Ä¢ The answer NA means that the paper does not use existing assets.
‚Ä¢ The authors should cite the original paper that produced the code package or dataset.
‚Ä¢The authors should state which version of the asset is used and, if possible, include a
URL.
‚Ä¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
‚Ä¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
‚Ä¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
‚Ä¢For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
‚Ä¢If this information is not available online, the authors are encouraged to reach out to
the asset‚Äôs creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: We upload our code with the submission.
Guidelines:
‚Ä¢ The answer NA means that the paper does not release new assets.
‚Ä¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
‚Ä¢The paper should discuss whether and how consent was obtained from people whose
asset is used.
‚Ä¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
25Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
the paper does not involve crowdsourcing nor research with human subjects
Guidelines:
‚Ä¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
‚Ä¢Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
‚Ä¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: the paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
‚Ä¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
‚Ä¢Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
‚Ä¢We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
‚Ä¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
26