Approximation-Aware Bayesian Optimization
Natalie Maus
University of Pennsylvania
nmaus@seas.upenn.eduKyurae Kim
University of PennsylvaniaGeoff Pleiss
University of British Columbia
Vector Institute
David Eriksson
MetaJohn P. Cunningham
Columbia UniversityJacob R. Gardner
University of Pennsylvania
Abstract
High-dimensionalBayesianoptimization(BO)taskssuchasmoleculardesignoften
require>10,000functionevaluationsbeforeobtainingmeaningfulresults. While
methods like sparse variational Gaussian processes (SVGPs) reduce computational
requirements in these settings, the underlying approximations result in suboptimal
dataacquisitionsthatslowtheprogressofoptimization. Inthispaperwemodify
SVGPstobetteralignwiththegoalsofBO:targetinginformeddataacquisitionrather
than global posterior fidelity. Using the framework of utility-calibrated variational
inference,weunifyGPapproximationanddataacquisitionintoajointoptimization
problem, thereby ensuring optimal decisions under a limited computational budget.
Our approach can be used with any decision-theoretic acquisition function and
isreadilycompatible withtrustregion methodslikeTuRBO. We deriveefficient
joint objectives for the expected improvement and knowledge gradient acquisition
functionsforstandardandbatchBO.OurapproachoutperformsstandardSVGPs
on high-dimensional benchmark tasks in control and molecular design.
1 Introduction
Bayesianoptimization(BO;Frazier,2018;Garnett,2023;Jonesetal.,1998;Mockus,1982;Shahriari
etal.,2015)castsoptimizationasasequentialdecision-makingproblem. ManyrecentsuccessesofBO
have involved complex and high-dimensional problems. In contrast to â€œclassicâ€ low-dimensional BO
problemsâ€”where expensive black-box function evaluations far exceeded computational costsâ€”these
modern problems necessitate tens of thousands of function evaluations, and it is often the complexity
and dimensionality of the search space that makes optimization challenging, rather than a limited
evaluationbudget(Erikssonetal.,2019;GriffithsandHernÃ¡ndez-Lobato,2020;Mausetal.,2022,
2023;Stantonetal.,2022). Becauseofthesescenarios,BOisenteringaregimewherecomputational
costsare becominga primarybottleneck(Maddox etal.,2021; Mauset al.,2023;Moss etal.,2023;
Vakili et al., 2021), as the Gaussian process (GP; Rasmussen and Williams, 2005) surrogate models
that underpin most of Bayesian optimization scale cubically with the number of observations.
In this new regime, we require scalable GP approximations, an area that has made tremendous
progress over the last decade. In particular, sparse variational Gaussian processes (SVGP; Hensman
et al., 2013; QuiÃ±onero-Candela and Rasmussen, 2005; Titsias, 2009) have seen an increase in
use(GriffithsandHernÃ¡ndez-Lobato,2020;Maddoxetal.,2021;Mausetal.,2022,2023;Stanton
et al., 2022; Tripp et al., 2020; Vakili et al., 2021), but many challenges remain to effectively deploy
SVGPs for large-budget BO. In particular, the standard SVGP training objective is not aligned
with the goals of black-box optimization. SVGPs construct an inducing point approximation that
maximizes the standard variational evidence lower bound (ELBO; Jordan et al., 1999), yielding a
posteriorapproximation ğ‘âˆ—(ğ‘“)thatmodelsallobserveddata(Matthewsetal.,2016;Mossetal.,2023).
However,theoptimalposteriorapproximation ğ‘âˆ—issuboptimalforthedecision-makingtasksinvolved
38th Conference on Neural Information Processing Systems (NeurIPS 2024).in BO (Lacosteâ€“Julien et al., 2011). In BO, we do not care about posterior fidelity at the majority
ofpriorobservations;rather,weonlycareaboutthefidelityofdownstreamfunctionsinvolvingthe
posterior, such as the expected utility. To illustrate this point intuitively, consider using the common
expectedimprovement(EI;Jonesetal.,1998)acquisitionfunctionforselectingnewobservations.
MaximizingtheELBOmightresultinaposteriorapproximationthatmaintainsfidelityfortraining
examples in regions of virtually zero EI, thus wasting â€œapproximation budget.â€
To solve this problem, we focus on the deep connections between statistical decision theory (Robert,
2001;Wasserman,2013,Â§12)andBayesianoptimization(Garnett,2023,Â§6-7),whereacquisition
maximizationcan beviewed asmaximizing posterior-expected utility. Following thisperspective,
we leverage the utility-calibrated approximate inference framework (Jaiswal et al., 2020, 2023;
Lacosteâ€“Julien et al., 2011), and solve the aforementioned problem through a variational bound (Blei
etal.,2017;Jordanetal.,1999)â€“the(log) expectedutilitylowerbound( EULBO)â€”ajointfunction
of the decision (the BO query) and the posterior approximation (the SVGP). When optimized
jointly, the EULBOautomatically yields the approximately optimal decision through the minorize-
maximize principle (Lange, 2016). The EULBOis reminiscent of the standard variational ELBO
(Jordan et al., 1999), and can indeed be viewed as a standard ELBO for a generalized Bayesian
inferenceproblem(Bissirietal.,2016;Knoblauchetal.,2022),whereweseektoapproximatethe
utility-weighted posterior. This work represents the first application of utility-calibrated approximate
inference towards BO despite its inherent connection with utility maximization.
The benefits of our proposed approach are visualized in Fig. 1. Furthermore, it can be applied
to acquisition function that admits a decision-theoretic interpretation, which includes the popular
expectedimprovement(EI;Jonesetal.,1998)andknowledgegradient(KG;Wuetal.,2017)acquisition
functions, and is trivially compatible with local optimization techniques like TuRBO (Eriksson et al.,
2019) for high-dimensional problems. We demonstrate that our joint SVGP/acquisition optimization
approachyieldssignificantimprovementsacrossnumerousBayesianoptimizationbenchmarks. Asan
added benefit, our approach can simplify the implementation and reduce the computational burden of
complex(decision-theoretic)acquisitionfunctionslikeKG.Wedemonstrateanovelalgorithmderived
from our joint optimization approach for computing and optimizing the KG that expands recent work
on one-shot KG (Balandatet al., 2020) and variational GP posterior refinement(Maddox et al.,2021).
Overall, our contributions are summarized as follows:
âˆ™We propose utility-calibrated variational inference of SVGPs in the context of large-budget BO.
âˆ™Westudythisframeworkintwospecialcasesusingtheutilityfunctionsoftwocommonacquisition
functions: EI and KG. For each, we derive tractable EULBOexpressions that can be optimized.
âˆ™For KG, we demonstrate that the computation of the EULBOtakes only negligible additional
work over computing the standard ELBO by leveraging an online variational update. Thus, as a
byproduct of optimizing the EULBO, optimizing KG becomes comparable to the cost of the EI.
âˆ™We extend this framework to be capable of running in batch mode, by introducing q-EULBO
analogs of q-KG and q-EI as commonly used in practice (Wilson et al., 2018).
âˆ™We demonstrate the effectiveness of our proposed method against standard SVGPs trained with
ELBO maximization on high-dimensional benchmark tasks in control and molecular design,
where the dimensionality and evaluation budget go up to 256 and 80k, respectively.
2 Background
Noisy Black-Box Optimization. Noisy black-box optimization refers to problems of the form:
maximize ğ’™âˆˆğ’³ğ¹(ğ’™),where ğ’³âŠ‚â„ğ‘‘is some compact domain, ğ¹âˆ¶ğ’³â†’ğ’´is some objective
function, and we assume that only zeroth-order information of ğ¹is available. More formally, for
someğ‘–âˆˆâ„•>0, we assume that observations of the objective function (ğ’™ğ‘–,ğ‘¦ğ‘–=Ë†ğ¹(ğ’™ğ‘–))have been
corrupted by independently and identically distributed (i.i.d.) Gaussian noise Ë†ğ¹(ğ’™ğ‘–)â‰œğ¹(ğ’™ğ‘–)+ğœ–,
whereğœ–âˆ¼ğ’©(0,ğœ2
n). The noise variance ğœ2
nis also unknown.
Bayesian optimization. Bayesian Optimization (BO) is and iterative approach to noisy black-box
optimization that iterates the following steps: â¶At each step ğ‘¡â‰¥0, we use a set of observations
ğ’Ÿğ‘¡= {(ğ’™ğ‘–,ğ‘¦ğ‘–=Ë†ğ¹(ğ’™ğ‘–))}ğ‘›ğ‘¡
ğ‘–=1ofË†ğ¹to fit a surrogate supervised model ğ‘“âˆˆâ„±. Typically, â„±is taken
to be the sample space of a Gaussian process such that the function-valued posterior distribution
2ELBO fit (m=4)
 ELBO EULBO (Ours)
Data True function Inducing points GP mean EI (approx) EI (exact)Figure 1: (Left.)Fitting an SVGP model with only ğ‘š=4inducing points sacrifices modeling areas
ofhighEI(fewdatapointsatright)becausetheELBOfocusesonlyonglobaldataapproximation
(left data) and is ignorant of the downstream decision making task. (Middle.) Because of this,
(normalized)EIwiththeSVGPmodelpeaksinanincorrectlocationrelativetotheexactposterior.
(Right.)UpdatingtheGPfitandselectingacandidatejointlyusingthe EULBO(ourmethod)resultsin
candidate selection much closer to the exact model.
ğœ‹(ğ‘“âˆ£ğ’Ÿ)forms a distribution over surrogate models at step ğ‘¡.â·The posterior is then used to
form a decision problem where we choose which point we should evaluate next, ğ’™ğ‘¡+1=ğ›¿ğ›¼(ğ’Ÿğ‘¡), by
maximizing an acquisition function ğ›¼âˆ¶ğ’³â†’â„as
ğ›¿ğ›¼(ğ’Ÿğ‘¡)â‰œargmax
ğ’™âˆˆğ’³ğ›¼(ğ’™;ğ’Ÿğ‘¡). (1)
â¸After selecting ğ’™ğ‘¡+1,Ë†ğ¹isevaluated to obtainthe new datapoint (ğ’™ğ‘¡+1,ğ‘¦ğ‘¡+1=Ë†ğ¹(ğ’™ğ‘¡+1)). This is
then added to the dataset, forming ğ’Ÿğ‘¡+1=ğ’Ÿğ‘¡âˆª(ğ’™ğ‘¡+1,ğ‘¦ğ‘¡+1)to be used in the next iteration.
Utility-BasedAcquisitionFunctions. Manycommonlyusedacquisitionfunctions,includingEI
and KG, can be expressed as posterior-expected utility functions
ğ›¼(ğ’™;ğ’Ÿ)â‰œâˆ«ğ‘¢(ğ’™,ğ‘“;ğ’Ÿ)ğœ‹(ğ‘“âˆ£ğ’Ÿ)dğ‘“, (2)
whereğ‘¢(ğ’™,ğ‘“;ğ’Ÿ)âˆ¶ğ’³Ã—â„±â†’â„is some utility function associated with ğ›¼(Garnett, 2023, Â§6-7). In
statistical decision theory, posterior-expected utility maximization policies such as ğ›¿ğ›¼are known as
Bayespolicies . Theseareimportantbecause,foragivenutilityfunction,theyattaincertainnotionsof
statistical optimality such as Bayes optimality and admissibility (Robert, 2001, Â§2.4; Wasserman,
2013, Â§12). However, this only holds true if we can exactly compute Eq. (2) over the posterior. Once
approximate inference is involved, making optimal Bayes decisions becomes challenging.
SparseVariationalGaussianProcesses. Whilethe ğ’ª(ğ‘›3)complexityofexactGaussianprocess
model selection and inference is not necessarily a roadblock in the traditional regression setting
with10,000-50,000training examples, BO amplifies the scalability challenge by requiring us to
sequentially train or update manylarge scale GPs as we iteratively acquire more data.
To address this, sparse variational GPs (SVGP; Hensman et al., 2013; Titsias, 2009) have become
commonly used in high-throughput Bayesian optimization. SVGPs modify the original GP prior
fromğ‘(ğ‘“)toğ‘(ğ‘“âˆ£ğ’–)ğ‘(ğ’–), where we assume the latent function ğ‘“is â€œinducedâ€ by a finite set of
inducing values ğ’–=(ğ‘¢1,â€¦,ğ‘¢ğ‘š)âˆˆâ„ğ‘šlocated at inducing points ğ’›ğ‘–âˆˆğ’³forğ‘–=1,â€¦,ğ‘š. Inference
isdonethroughvariationalinference(Bleietal.,2017;Jordanetal.,1999),wheretheposteriorofthe
inducing points is approximated using ğ‘ğ€(ğ’–)=ğ’©(ğ’–;ğ€=(ğ’,ğ‘º))and that of the latent functions
withğ‘(ğ‘“âˆ£ğ’–)=ğ‘(ğ‘“âˆ£ğ’–). Here, the variational parameters ğ’andğ‘ºare defined as the learned mean
andcovarianceofthevariationaldistribution ğ‘ğ€(ğ’–). Itisstandardpracticetodefine ğ€=(ğ’,ğ‘º)so
thatğ€can be used as shorthand to represent all of the trainable variational parameters. As is typical
in the BO literature, we use the subscript ğ€âˆˆÎ›to denote that the distribution denoted as ğ‘contains
trainable parameters in ğ€.
Forapositivedefinitekernelfunction ğ‘˜âˆ¶ğ’³Ã—ğ’³â†’â„>0,theresultingELBOobjective,whichcan
be computed in a closed form (Hensman et al., 2013), is then
â„’ELBO(ğ€;ğ’Ÿğ‘¡)â‰œğ”¼ğ‘ğœ†(ğ‘“)[âˆ‘ğ‘›ğ‘¡
ğ‘–=1logğ“(ğ‘¦ğ‘–âˆ£ğ‘“(ğ’™ğ‘–))]
âˆ’DKL(ğ‘ğœ†(ğ’–),ğ‘(ğ’–)), (3)
where ğ“(ğ‘¦ğ‘–âˆ£ğ‘“(ğ’™ğ‘–)) =ğ’©(ğ‘¦ğ‘–âˆ£ğ‘“(ğ’™ğ‘–),ğœğœ–)is a Gaussian likelihood. The marginal variational
approximation can be computed as
ğ‘ğœ†(ğ‘“)=âˆ«ğ‘ğ€(ğ‘“,ğ’–)dğ’–=âˆ«ğ‘(ğ‘“âˆ£ğ’–)ğ‘ğœ†(ğ’–)dğ’–
3such that the point-wise function evaluation on some ğ’™âˆˆğ’³is
ğ‘ğœ†(ğ‘“(ğ’™))=ğ’©(
ğ‘“(ğ’™);ğœ‡ğ‘“(ğ’™)â‰œğ‘²ğ’™ğ’ğ‘²âˆ’1
ğ’ğ’ğ’, ğœ2
ğ‘“(ğ’™)â‰œËœğ‘˜ğ’™ğ’™+ğ’ŒâŠ¤
ğ’™ğ’ğ‘²âˆ’1
ğ’ğ’ğ‘ºğ‘²âˆ’1
ğ’ğ’ğ’Œğ’ğ’™)
,(4)
withËœğ‘˜ğ’™ğ’™â‰œğ‘˜(ğ’™,ğ’™)âˆ’ğ’Œğ’™ğ’ğ‘²âˆ’1
ğ’ğ’ğ’ŒâŠ¤
ğ’ğ’™, the vectorğ’Œğ’ğ’™âˆˆâ„ğ‘šis formed as [ğ’Œğ’ğ’™]ğ‘–=ğ‘˜(ğ’›ğ‘–,ğ’™), and the
matrixğ‘²ğ’ğ’âˆˆâ„ğ‘šÃ—ğ‘šisformedas [ğ‘²ğ’ğ’]ğ‘–ğ‘—=ğ‘˜(ğ’›ğ‘–,ğ’›ğ‘—). Additionally,theGPlikelihoodandkernel
contain hyperparameters, which we denote as ğœ½âˆˆÎ˜, and we collectively denote the set of inducing
point locations as ğ’=(ğ’›1,â€¦,ğ’›ğ‘š)âˆˆğ’³ğ‘š. We therefore denote the ELBO as â„’ELBO(ğ€,ğ’,ğœ½;ğ’Ÿğ‘¡).
3 Approximation-Aware Bayesian Optimization
WhenSVGPsareusedinconjunctionwithBO(Maddoxetal.,2021;Mossetal.,2023)atiteration
ğ‘¡â‰¥0, acquisition functions of the form of Eq. (2) are naÃ¯vely approximated as
ğ›¼(ğ’™;ğ’Ÿ)â‰ˆâˆ«ğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)ğ‘ğ€(ğ‘“)dğ‘“,
whereğ‘ğ€(ğ‘“)is the approximate SVGP posterior given by Eq. (4). The acquisition policy implied by
this approximation contains two separate optimization problems:
ğ’™ğ‘¡+1=argmax
ğ’™âˆˆğ’³âˆ«ğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)ğ‘ğ€âˆ—
ELBO(ğ‘“)dğ‘“andğ€âˆ—
ELBO=argmax
ğ€âˆˆÎ›â„’ELBO(ğ€;ğ’Ÿğ‘¡).(5)
Treating these optimization problems separately creates an artificial bottleneck that results in
suboptimaldataacquisitiondecisions. Intuitively, ğ€âˆ—
ELBOischosentofaithfullymodelallobserved
data(Matthewsetal.,2016;Mossetal.,2023),withoutregardforhowtheresultingmodelperformsat
selecting thenextfunction evaluation in theBOloop. Foran illustrationof this, see Figure 1. Instead,
weproposeamodificationtoSVGPsthatcouplestheposteriorapproximationanddataacquisition
through a joint problem of the form:
(ğ’™ğ‘¡+1,ğ€âˆ—)=argmax
ğ€âˆˆÎ›,ğ’™âˆˆğ’³â„’EULBO(ğ€,ğ’™;ğ’Ÿğ‘¡). (6)
Thisresultsin ğ’™ğ‘¡+1directlyapproximatingasolutiontoEq.(2),wherethe expectedutilitylower-
bound(EULBO) is an ELBO-like objective function derived below.
3.1 Expected Utility Lower-Bound
ConsideranacquisitionfunctionoftheformofEq.(2),wheretheutility ğ‘¢âˆ¶ğ’³Ã—â„±â†’â„>0isstrictly
positive. Wecanderiveasimilarvariationalformulationoftheacquisitionfunctionmaximization
problem following Lacosteâ€“Julien et al. (2011). That is, given any distribution ğ‘ğ€indexed byğ€âˆˆÎ›
and considering theSVGPprioraugmentation ğ‘(ğ‘“)â†’ğ‘(ğ‘“âˆ£ğ’–)ğ‘(ğ’–), theacquisition function canbe
lower-bounded through Jensenâ€™s inequality as
logğ›¼(ğ’™;ğ’Ÿğ‘¡)=log âˆ«ğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)ğœ‹(ğ‘“âˆ£ğ’Ÿğ‘¡)dğ‘“
=log âˆ«ğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)ğœ‹(ğ‘“,ğ’–âˆ£ğ’Ÿğ‘¡)ğ‘ğ€(ğ‘“,ğ’–)
ğ‘ğ€(ğ‘“,ğ’–)dğ‘“dğ’–
=log âˆ«ğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)ğ“(ğ’Ÿğ‘¡âˆ£ğ‘“)ğ‘(ğ‘“âˆ£ğ’–)ğ‘(ğ’–)ğ‘ğ€(ğ’–)ğ‘(ğ‘“âˆ£ğ’–)
ğ‘ğ€(ğ’–)ğ‘(ğ‘“âˆ£ğ’–)dğ‘“dğ’–âˆ’logğ‘
â‰¥âˆ«log(ğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)ğ“(ğ’Ÿğ‘¡âˆ£ğ‘“)ğ‘(ğ’–)
ğ‘ğ€(ğ’–))ğ‘(ğ‘“âˆ£ğ’–)ğ‘ğ€(ğ’–)dğ‘“dğ’–âˆ’logğ‘, (7)
whereğ‘is a normalizing constant. A restriction on ğ‘¢comes from the inequality in Eq. (7), where the
utility needs to be strictly positive. This means that non-strictly positive utilities need to be modified
tobeincorporatedintothisframework. (Seetheexamplesby KuÅ›mierczyketal.,2019.) Also,notice
that the derivation is reminiscent of expectation-maximization (Dempster et al., 1977) and variational
lower bounds (Jordan et al., 1999). That is, through the minorize-maximize principle (Lange, 2016),
maximizingthelowerboundwithrespectto ğ’™andğ€approximatelysolvestheoriginalproblemof
maximizing the posterior-expected utility.
4ExpectedUtilityLower-Bound. Uptoaconstantandrearrangingterms,maximizingEq.(7)is
equivalent to maximizing
â„’EULBO(ğ€,ğ’™;ğ’Ÿğ‘¡)â‰œğ”¼ğ‘(ğ‘“âˆ£ğ’–)ğ‘ğœ†(ğ’–)[logğ“(ğ’Ÿğ‘¡âˆ£ğ‘“)+logğ‘(ğ’–)âˆ’logğ‘ğœ†(ğ’–)+logğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)]
=ğ”¼ğ‘ğœ†(ğ‘“)[âˆ‘ğ‘›ğ‘¡
ğ‘–=1logğ“(ğ‘¦ğ‘–âˆ£ğ‘“)]
âˆ’DKL(ğ‘ğ€(ğ’–),ğ‘(ğ’–))+ğ”¼ğ‘ğœ†(ğ‘“)logğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)
=â„’ELBO(ğ€;ğ’Ÿğ‘¡)+ğ”¼ğ‘ğ€(ğ‘“)logğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡), (8)
whichisthejointobjectivefunctionalludedtoinEq.(6). Wemaximize EULBOtoobtain(ğ’™ğ‘¡+1,ğ€âˆ—)=
argmaxğ’™âˆˆğ’³,ğ€âˆˆÎ›â„’EULBO(ğ’™,ğ€), whereğ’™ğ‘¡+1corresponds our next BO â€œqueryâ€.
From Eq. (8), the connection between the EULBOand ELBO is obvious: the EULBOis now â€œnudgingâ€
theELBOsolutiontowardhighutilityregions. Analternativeperspectiveisthatweareapproximating
ageneralized posterior weighted by the utility (Table. 1 by Knoblauch et al., 2022; Bissiri et al.,
2016). Furthermore,Jaiswaletal.(2020,2023)provethattheresultingactionssatisfyconsistency
guarantees under assumptions typical in such results for variational inference (Wang and Blei, 2019).
Hyperparameters and Inducing Point Locations. For the hyperparameters ğœ½and inducing point
locationsğ’, we use the marginal likelihood to perform model selection, which is common practice in
BO (Shahriari et al., 2015, Â§V.A). (Optimizing over ğ’was popularized by Snelson and Ghahramani,
2005.) Following suit, we also optimize the EULBOas a function of ğœ½andğ’as
maximize
ğ€,ğ’™,ğœ½,ğ’{â„’EULBO(ğ€,ğ’™,ğœ½,ğ’;ğ’Ÿğ‘¡)â‰œ â„’ELBO(ğ€,ğ’,ğœ½;ğ’Ÿğ‘¡)+ğ”¼ğ‘ğ€(ğ‘“)logğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)}.
WeemphasizeherethattheSVGP-associated parameters ğ€,ğœ½,ğ’havegradientsthat aredetermined
bybothterms above. Thus, the expected log-utility term ğ”¼ğ‘“âˆ¼ğ‘ğ€(ğ‘“)logğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)simultaneously
results in acquisition of ğ’™ğ‘¡+1and directly influences the underlying SVGP regression model.
3.2 EULBOfor Expected Improvement (EI)
The EI acquisition function can be expressed as a posterior-expected utility, where the underlying
â€œimprovementâ€ utility function is given by the difference between the objective value of the query,
ğ‘“(ğ’™), and the current best objective value ğ‘¦âˆ—
ğ‘¡=maxğ‘–=1,â€¦,ğ‘¡{ğ‘¦ğ‘–âˆ£ğ‘¦ğ‘–âˆˆğ’Ÿğ‘¡}:
ğ‘¢EI(ğ’™,ğ‘“;ğ’Ÿğ‘¡)â‰œReLU(ğ‘“(ğ’™)âˆ’ğ‘¦âˆ—
ğ‘¡),(EI; Jones et al., 1998) (9)
whereReLU(ğ‘¥)â‰œmax(ğ‘¥,0). Unfortunately,thisutilityisnotstrictlypositivewhenever ğ‘“(ğ’™)â‰¤ğ‘¦âˆ—.
Thus, we cannot immediately plug ğ‘¢EIinto the EULBO. While it is possible to add a small positive
constant to ğ‘¢EIand make it strictly positive as done by KuÅ›mierczyk et al. (2019), this results in a
looser Jensen gap in Eq. (7), which could be detrimental. This also introduces the need for tuning the
constant, which is not straightforward. Instead, we define the following â€œsoftâ€ EI utility:
ğ‘¢SEI(ğ’™,ğ‘“;ğ’Ÿğ‘¡)â‰œsoftplus(ğ‘“(ğ’™)âˆ’ğ‘¦âˆ—
ğ‘¡),
where the ReLU in Eq. (9) is replaced with softplus(ğ‘¥)â‰œlog(1+exp(ğ‘¥)).softplus(ğ‘¥)converges
totheReLUinbothextremesof ğ‘¥â†’Â±âˆ. Thus,ğ‘¢SEIwillbehavecloselyto ğ‘¢EI,whilebeingslightly
more explorative due to positivity.
Computingthe EULBOanditsderivativesnowrequiresthecomputationof ğ”¼ğ‘“âˆ¼ğ‘ğ€(ğ‘“)logğ‘¢SEI(ğ’™,ğ‘“;ğ’Ÿğ‘¡),
which, unlike EI, does not have a closed-form. However, since the utility function only depends
on the function values of ğ‘“, the expectation can be efficiently computed to high precision through
one-dimensional Gauss-Hermite quadrature. Crucially, the expensive ğ¾âˆ’1
ğ‘§ğ‘§ğ‘šandğ¾âˆ’1
ğ‘§ğ‘§ğ‘†ğ¾âˆ’1
ğ‘§ğ‘§solves
that dominate both the asymptotic and practical running time of both the ELBO and the EULBO are
fixedacrossthelogutilityevaluationsneededbyquadrature. Becausequadratureonlydependson
theseprecomputedmoments, theadditionalworknecessaryduetolackingaclosedformsolutionis
negligible: Gauss-Hermite quadrature converges extremely quickly in the number of quadrature sites,
and only requires on the order of 10 or so of these post-solve evaluations to achieve near machine
precision.
3.3 EULBOfor Knowledge Gradient (KG)
Although non-trivial, the KG acquisition is also a posterior-expected utility, where the underlying
utilityfunction isgiven bythe maximumpredictive meanvalueanywhereinthe inputdomain after
5conditioning on a new observation (ğ’™,ğ‘¦)âˆˆğ’³Ã—ğ’´:
ğ‘¢KG(ğ’™,ğ‘¦;ğ’Ÿğ‘¡)â‰œmax
ğ’™â€²âˆˆğ’³ğ”¼[ğ‘“(ğ’™â€²)âˆ£ğ’Ÿğ‘¡âˆª{(ğ’™,ğ‘¦)}].(KG; Frazier, 2009; Garnett, 2023)
Notethattheutilityfunctionasdefinedaboveisnotnon-negative: themaximumpredictivemeanofa
Gaussianprocesscanbenegative. Forthisreason,theutilityfunctioniscommonly(andoriginally,
e.g.Frazier, 2009, Eq. 4.11) written in the literature as the difference between the new maximum
mean after conditioning on (ğ’™,ğ‘¦)and the maximum mean beforehand:
ğ‘¢KG(ğ’™,ğ‘¦;ğ’Ÿğ‘¡)â‰œmax
ğ’™â€²âˆˆğ’³ğ”¼[ğ‘“(ğ’™â€²)âˆ£ğ’Ÿğ‘¡âˆª{(ğ’™,ğ‘¦)}]âˆ’ğœ‡+
ğ‘¡,
whereğœ‡+
ğ‘¡â‰œmaxğ’™â€²â€²âˆˆğ’³ğ¸[ğ‘“(ğ’™â€²â€²)âˆ£ğ’Ÿğ‘¡]
. Notethatğœ‡+
ğ‘¡playstheroleofasimpleconstantasitdepends
on neitherğ’™norğ‘¦. Similarly to the EI acquisition, this utility is still not strictly positive, and we thus
define its â€œsoftplus-edâ€ variant:
ğ‘¢SKG(ğ’™,ğ‘¦;ğ’Ÿğ‘¡)â‰œsoftplus(ğ‘¢KG(ğ’™,ğ‘¦;ğ’Ÿğ‘¡)âˆ’ğ‘+).
Here,ğ‘+acts asğœ‡+
ğ‘¡by makingğ‘¢KGpositive as often as possible. This is particularly important when
the GP predictive mean is negative as a consequence of the objective values being negative. One
naturalchoiceofconstantisusing ğœ‡+
ğ‘¡;however,wefindthatsimplychoosing ğ‘+=ğ‘¦+
ğ‘¡workswell
and is more computationally efficient. Here, ğ‘¦+
ğ‘¡is the highest value of ğ‘¦ğ‘¡(the highest objective value
observed so far).
One-Shot KG EULBO.TheEULBOusingğ‘¢SKGresults in an expensive nested optimization problem.
Toaddressthis,weuseanapproachsimilartotheone-shotknowledgegradientmethodofBalandat
et al. (2020). For clarity, we will define the reparameterization function
ğ‘¦ğ€(ğ’™;ğœ–ğ‘–)â‰œğœ‡ğ‘ğœ†(ğ’™)+ğœğ‘ğœ†(ğ’™)ğœ–ğ‘–,
where, for an i.i.d. sample ğœ–ğ‘–âˆ¼ğ’©(0,1), computing ğ‘¦ğ‘–=ğ‘¦ğ€(ğ’™,ğœ–ğ‘–)is equivalent to sampling
ğ‘¦ğ‘–âˆ¼ğ’©(ğœ‡ğ‘ğœ†(ğ’™),ğœğ‘ğœ†(ğ’™))
. This enables the use of the reparameterization gradient estimator (Kingma
andWelling,2014;Rezendeet al.,2014;TitsiasandLÃ¡zaro-Gredilla, 2014). Now, noticethat theKG
acquisition function can be approximated through Monte Carlo as
ğ›¼KG(ğ’™;ğ’Ÿ)â‰ˆ1
ğ‘†ğ‘†âˆ‘
ğ‘–=1ğ‘¢KG(ğ’™,ğ‘¦ğ€(ğ’™;ğœ–ğ‘–);ğ’Ÿğ‘¡)=1
ğ‘†ğ‘†âˆ‘
ğ‘–=1max
ğ’™â€²ğ”¼[ğ‘“(ğ’™â€²)âˆ£ğ’Ÿğ‘¡âˆª{ğ’™,ğ‘¦ğ€(ğ’™;ğœ–ğ‘–)}],
where, for ğ‘–= 1,â€¦,ğ‘†,ğœ–ğ‘–âˆ¼ğ’©(0,1)are i.i.d. The one-shot KG approach absorbs the nested
optimization over ğ’™â€²into a simultaneous joint optimization over ğ’™and a mean maximizer for each of
the S samples, ğ’™â€²
1,...,ğ’™â€²
ğ‘†such thatmaxğ’™ğ›¼KG(ğ’™;ğ’Ÿğ‘¡)â‰ˆmaxğ’™,ğ’™â€²
1,...,ğ’™â€²
ğ‘†ğ›¼1-KG(ğ’™;ğ’Ÿ),where
ğ›¼1-KG(ğ’™;ğ’Ÿğ‘¡)â‰œ1
ğ‘†ğ‘†âˆ‘
ğ‘–=1ğ‘¢1-KG(ğ’™,ğ’™â€²
ğ‘–,ğ‘¦ğ€(ğ’™;ğœ–ğ‘–);ğ’Ÿğ‘¡)=1
ğ‘†ğ‘†âˆ‘
ğ‘–=1ğ”¼[ğ‘“(ğ’™â€²
ğ‘–)âˆ£ğ’Ÿğ‘¡âˆª{ğ’™,ğ‘¦ğ€(ğ’™;ğœ–ğ‘–)}],
Evidently, thereisnolonger aninneroptimization problemover ğ’™â€². To estimatethe ğ‘–thterm ofthis
sum, we draw a sample of the objective value of ğ’™,ğ‘¦ğ€(ğ’™;ğœ–ğ‘–), and condition the model on this sample.
We then compute the new posterior predictive mean at ğ’™â€²
ğ‘–. After summing, we compute gradients
with respect to both the candidate ğ’™and the mean maximizers ğ’™â€²
1,...,ğ’™â€²
ğ‘†. Again, we use the â€œsoftâ€
version of one-shot KG in our EULBOoptimization problem:
ğ‘¢1-SKG(ğ’™,ğ’™â€²,ğ‘¦;ğ’Ÿğ‘¡)=softplus(ğ”¼[ğ‘“(ğ’™â€²)âˆ£ğ’Ÿğ‘¡âˆª{(ğ’™,ğ‘¦)}]âˆ’ğ‘+),
wherethisutilityfunctioniscruciallyafunctionofboth ğ’™andafreeparameter ğ’™â€². Aswithğ›¼1-KG,
maximizing the EULBOcan be set up as a joint optimization problem:
maximize
ğ’™,ğ’™â€²
1,...,ğ’™â€²
ğ‘†,ğ€,ğ’,ğœ½â„’ELBO(ğ€,ğ’,ğœ½)+1
ğ‘†ğ‘†âˆ‘
ğ‘–=1logğ‘¢1-SKG(ğ’™,ğ’™â€²
ğ‘–,ğ‘¦ğ€(ğ’™;ğœ–ğ‘–);ğ’Ÿğ‘¡)(10)
EfficientKG- EULBOComputation. Thecomputationtimeofthenon-ELBOterminEq.(10)is
dominated by having to compute ğ”¼[ğ‘“(ğ’™â€²
ğ‘–)âˆ£ğ’Ÿğ‘¡âˆª{(ğ’™,ğ‘¦ğ€(ğ’™;ğœ–ğ‘–))}]ğ‘†-times. Notice that we only need
to compute an updated posterior predictive mean, and can ignore predictive variances. For this,
we can leverage the online updating strategy of Maddox et al. (2021). In particular, the predictive
mean can be updated in ğ’ª(ğ‘š2)time using a simple Cholesky update. The additional ğ’ª(ğ‘†ğ‘š2)cost of
computing the EULBOis therefore amortized by the original ğ’ª(ğ‘š3)cost of computing the ELBO.
63.4 Extension to q-EULBO for Batch Bayesian Optimization
TheEULBOcan be extended to support batch Bayesian optimization by using the Monte Carlo batch
mode analogs of utility functions as discussed e.g.by Balandat et al. (2020); Wilson et al. (2018).
Given a set of candidates ğ‘¿=(ğ’™1,...,ğ’™ğ‘)âˆˆğ’³ğ‘, theğ‘-EI utility function is given by:
ğ‘¢ğ‘-EI(ğ‘¿,ğ’‡;ğ’Ÿğ‘¡)â‰œmax
ğ‘—=1...ğ‘ReLU(ğ‘“(ğ’™ğ‘—)âˆ’ğ‘¦âˆ—
ğ‘¡)(q-EI; Balandat et al., 2020; Wilson et al., 2018)
This utility can again be softened as:
ğ‘¢ğ‘-SEI(ğ‘¿,ğ’‡;ğ’Ÿğ‘¡)â‰œmax
ğ‘—=1â€¦ğ‘softplus(ğ‘“(ğ’™ğ‘—)âˆ’ğ‘¦âˆ—
ğ‘¡)
Because this is now a ğ‘-dimensional integral, Gauss-Hermite quadrature is no longer applicable.
However, we can apply Monte Carlo as
ğ”¼ğ‘ğ€(ğ‘“)logğ‘¢ğ‘-SEI(ğ‘¿,ğ’‡;ğ’Ÿğ‘¡)â‰ˆ1
ğ‘†ğ‘†âˆ‘
ğ‘–=1max
ğ‘—=1...ğ‘softplus(ğ‘¦ğ€(ğ’™;ğœ–ğ‘–)âˆ’ğ‘¦âˆ—
ğ‘¡).
As done in the BoTorch software package (Balandat et al., 2020), we observe that fixing the set of
base samples ğœ–1,...,ğœ–ğ‘†during each BO iteration results in better optimization performance at the cost
ofnegligible q-EULBO bias. Now,optimizingthe q-EULBO isdoneoverthefullsetof ğ‘candidates(ğ’™1,...,ğ’™ğ‘)jointly, as well as the GP hyperparameters, inducing points, and variational parameters.
KnowledgeGradient. TheKGversionofthe EULBOcanbesimilarlyextended. Theexpectedlog
utility term in the maximization problem Eq. (10) becomes:
maximize
ğ’™1,...,ğ’™ğ‘,ğ’™â€²
1,...,ğ’™â€²
ğ‘†,ğ€,ğ’,ğœ½â„’ELBO(ğ€,ğ’,ğœ½)+1
ğ‘†ğ‘†âˆ‘
ğ‘–=1max
ğ‘—=1..ğ‘logğ‘¢1-SKG(ğ’™ğ‘—,ğ’™â€²
ğ‘–,ğ‘¦ğ€(ğ’™;ğœ–ğ‘–);ğ’Ÿğ‘¡),
resulting in a similar analog to q-KG as described by Balandat et al. (2020).
3.5 Optimizing the EULBO
Optimizing the ELBO for SVGPs is known to be challenging (Galy-Fajou and Opper, 2021; Terenin
etal.,2024)astheoptimizationlandscapefortheinducingpointsisnon-convex,multi-modal,and
non-smooth. Naturally,these are alsochallenges for EULBO; wefound thatcare must betaken when
implementing and initializing the EULBOmaximization problem. In this subsection, we outline some
key ideas, while a detailed description with pseudocode is presented in Appendix A.
Initialization and Warm-Starting. We warm-start the EULBOmaximization procedure by solving
the conventional two-step scheme in Eq. (5): At each BO iteration, we obtain the â€œwarmâ€ initial
valuesfor(ğ€,ğ’,ğœ½)byoptimizingthestandardELBO.Then,weusethistomaximizetheconventional
acquisition function corresponding to the chosen utility function ğ‘¢(the expectation of ğ‘¢overğ‘ğ€(ğ‘“)),
which provides the warm-start initialization for ğ’™.
Alternating MaximizationScheme. To optimize â„’EULBO(ğ’™,ğ€,ğ’,ğœ½), wealternate between opti-
mizing over the query ğ’™and the SVGP parameters ğ€,ğ’,ğœ½. We find this block-coordinate descent
scheme to be more stable and robust than jointly updating all parameters, though the reason why this
is more stable than jointly optimizing all parameters requires further investigation.
4 Experiments
We evaluate EULBO-based SVGPs on a number of benchmark BO tasks, described in detail in
Section 4.1. These tasks include standard low-dimensional BO problems, e.g., the 6D Hartmann
function, as well as 7 high-dimensional and high-throughput optimization tasks.
Baselines. We compare EULBOto several baselines withthe main goal ofachievinga high reward
usingasfewfunctionevaluationsaspossible. OurprimarypointofcomparisonisELBO-basedSVGPs.
We consider two approaches for inducing point locations: 1. optimizing inducing point locations via
theELBO(denoted as ELBO),2.placingtheinducingpoints usingthestrategyproposedbyMoss
et al. (2023) at each stage of ELBO optimization (denoted as Moss et al. ). The latter offers improved
BO performance over standard ELBO-SVGP in BO settings, yetâ€”unlike our methodâ€”it exclusively
7Figure 2: Optimization results on the 8 considered tasks. We compare all methods for both
standardBOand TuRBO-basedBO(onalltasksexceptHartmann). Eachline/shadedregionrepresents
the mean/standard error over 20 runs See subsection B.1 for additional molecule results.
targets inducing point placement and does not affect variational parameters or hyperparameters of the
model. Inaddition,wecomparetoBOusingexactGPsusing 2,000functionevaluationsastheuse
of exact GP is intractable beyond this point due to the need to repeatedly fit models.
Acquisition Functions and BO algorithms. ForEULBO, we test the versions based on both the
Expected Improvement (EI) and Knowledge Gradient (KG) acquisition functions as well as the
batch variant. We test the baseline methods using EI only. On high-dimensional tasks (tasks with
dimensionalityabove10),werun EULBOandbaselinemethodswithstandardBOandwithtrustregion
Bayesianoptimization( TuRBO)(Erikssonetal.,2019). Forthelargesttasks(Lasso,Molecules)we
use acquisition batch size of 20 ( ğ‘=20), and batch size 1 ( ğ‘=1) for all others.
Implementation Details and Hyperparameters. Code to reproduce all results in the paper
is available at https://github.com/nataliemaus/aabo . We implement EULBOand baseline
methodsusingtheGPyTorch(Gardneretal.,2018)andBoTorch(Balandatetal.,2020)packages. For
allmethods,weinitializeusingasetof100datapointssampleduniformlyatrandominthesearch
space. We use the same trust region hyperparameters as in (Eriksson et al., 2019). In Appendix B.1,
we also evaluate an additional initialization strategy for the molecular design tasks. This alternative
initialization matches prior work in using 10,000molecules from the GuacaMol dataset Brown et al.
(2019) rather than the details we used above for consistency across tasks, but does achieve higher
overall performance.
4.1 Tasks
Hartmann6D. ThewidelyusedHartmann benchmarkfunction(SurjanovicandBingham,2013).
LunarLander. Thegoalofthistaskistofindanoptimal 12-dimensionalcontrolpolicythatallows
an autonomous lunar lander to consistently land without crashing. The final objective value we
optimize is the reward obtained by the policy averaged over a set of 50 random landing terrains. For
this task, we use the same controller setup used by Eriksson et al. (2019).
Rover.TherovertrajectoryoptimizationtaskintroducedbyWangetal.(2018)consistsoffinding
a60-dimensional policy that allows a rover to move along some trajectory while avoiding a set of
obstacles. We use the same obstacle set up as in Maus et al. (2023).
8Figure 3: Ablation study measuring the impact of EULBOoptimization on various SVGP
parameters. At each BO iteration, we use the standard ELBO objective to optimize the SVGP
hyperparameters, variational parameters, and inducing point locations. We then refine some subset of
these parameters by further optimizing them with respect to the EULBOobjective.
Lasso DNA. We optimize the 180âˆ’dimensional DNA task from the LassoBench library (Å ehiÄ‡
et al., 2022) of benchmarks based on weighted LASSO regression (Gasso et al., 2009).
Molecular design tasks (x4). We select four challenging tasks from the Guacamol benchmark
suite of molecular design tasks (Brown et al., 2019): Osimertinib MPO, Fexofenadine MPO, Median
Molecules 1, and Median Molecules 2. We use the SELFIES-VAE introduced by Maus et al. (2022)
to enable continuous 256dimensional optimization.
4.2 Optimization Results
InFigure2,weplottherewardofthebestpointfoundbytheoptimizerafteragivennumberoffunction
evaluations. Errorbarsshowthestandarderrorofthemeanover 20replicateruns. EULBOwithTuRBO
outperforms the other baselines with TuRBO. Similarly, EULBOwith standard BO outperforms the
other standard BO baselines. One noteworthy observation is that neither acquisition function appears
to consistently outperform the other. However, EULBO-SVGP almost always dominates ELBO-SVGP
and often requires a small fraction of the number of oracle calls to achieve comparable performance.
These results suggest that coupling data acquisition with approximate inference/model selection
results in significantly more sample-efficient optimization.
4.3 Ablation Study
While the results in Fig. 2 demonstrate that EULBO-SVGP improves the BO performance it is not
immediatelycleartowhatextentjointoptimizationmodifiestheposteriorapproximationbeyondwhat
isobtainedby standardELBOoptimization. Tothatend,in Fig.3werefineanELBO-SVGP model
withvaryingdegreesofadditional EULBOoptimization. AteveryBOiterationwebeginbyobtaininga
SVGPmodel(wherethevariationalparameters,inducingpointlocations,andGPhyperparametersare
all obtained by optimizing the standard ELBO objective). We then refine some subset of parameters
(eithertheinducingpoints,thevariationalparameters,theGPhyperparameters,oralloftheabove)
through additional optimization with respect to the EULBOobjective. Interestingly, we find that tasks
respond differently to the varying levels of EULBOrefinement. In the case of Lasso DNA, there is not
muchofadifferencebetween EULBOrefinementonallparametersversusrefinementonthevariational
parametersalone. Ontheotherhand,theperformanceonMedianMolecules2isclearlydominatedby
refinement on all parameters. Nevertheless, we see that EULBOis always beneficial, whether applied
to all parameters or some subset.
5 Related Work
Scaling Bayesian Optimization to the Large-Budget Regime. BO has traditionally been confined
to the small-budget optimization regime with a few hundred objective evaluations at most. However,
recent interest in high-dimensional optimization problems has demonstrated the need to scale BO
to large data acquisition budgets. For problems with âˆ¼103data acquisitions, HernÃ¡ndez-Lobato
et al. (2017); Snoek et al. (2015); Springenberg et al. (2016) consider Bayesian neural networks
(BNN;Neal, 1996),McIntireetal.(2016)useSVGP,andWangetal.(2018) turntoensembles of
9subsampledGPs. Forproblemswith â‰«103acquisitions,SVGPhasbecomethe defactoapproach
to alleviate computational complexity (Griffiths and HernÃ¡ndez-Lobato, 2020; Maus et al., 2022,
2023; Stanton et al., 2022; Tripp et al., 2020; Vakili et al., 2021). As in this paper, many works
have proposed modifications to SVGP to improve its performance in BO applications. Moss et al.
(2023) proposed an inducing point placement based on a heuristic modification of determinantal
point processes (Kulesza and Taskar, 2012), which we used for initialization, while Maddox et al.
(2021)proposedamethodforafastonlineupdatestrategyforSVGPs,whichweutilizefortheKG
acquisition strategy.
Utility-Calibrated Approximate Inference. The utility-calibrated VI objective was first proposed
by Lacosteâ€“Julien et al. (2011), where they used a coordinate ascent algorithm to maximize it.
Sincethen,variousextensionshavebeenproposed: KuÅ›mierczyketal.(2019)leverageblack-box
variational inference (Ranganath et al., 2014; Titsias and LÃ¡zaro-Gredilla, 2014); Morais and Pillow
(2022) use expectation-propagation (EP; Minka, 2001); Abbasnejad et al. (2015) employ importance
sampling; Cobb et al. (2018) and Li and Zhang (2023) derive a specific variant for BNNs; and (Wei
et al., 2021) derive a specific variant for GP classification. Closest to our work is the GP-based
recommendation model learning algorithm by Abbasnejad et al. (2013), which sparsifies an EP-based
GP approximation by maximizing a utility similar to those used in BO.
6 Limitations and Discussion
The main limitation of our proposed approach is increased computational cost. While EULBO-SVGP
still retains the ğ‘‚(ğ‘š3)computational complexity of standard SVGP, our practical implementation
requires a warm-start: first fitting SVGP with the ELBOloss and then maximizing the acquisition
functionbeforejointlyoptimizingwiththe EULBOloss. Furthermore, EULBOoptimizationcurrently
requires multiple tricks such as clipping and block-coordinate updates. In future work, we aim
to develop a better understanding of the EULBOgeometry in order to develop developing more
stable, efficient, and easy-to-use EULBOoptimization schemes. Nevertheless, our results in Section 4
demonstratethattheadditionalcomputationof EULBOyieldssubstantialimprovementsinBOdata-
efficiency, a desirable trade-off in many applications. Moreover, EULBO-SVGP is modular, and
our experiments capture a fraction of its potential use. It can be applied to any decision-theoretic
acquisitionfunction,anditislikelycompatiblewithnon-standardBayesianoptimizationproblems
such as cost-constrained BO (Snoek et al., 2012), causal BO (Aglietti et al., 2020), and many more.
More importantly, our paper highlights a new avenue for research in BO, where surrogate modeling,
approximate inference, and data selection are jointly determined from a unified objective. Extending
this idea to GP approximations beyond SVGP and acquisition functions beyond EI/KG may yield
further improvements, especially in the increasingly popular high-throughput BO setting.
10Acknowledgments and Disclosure of Funding
The authors thank the anonymous reviewers for suggestions that improved the quality of the work.
N. Maus was supported by the National Science Foundation Graduate Research Fellowship; K. Kim
wassupportedbyagiftfromAWSAItoPennEngineeringâ€™sASSETCenterforTrustworthyAI;G.
PleisswassupportedbyNSERCandtheCanadaCIFARAIChairprogram;J.P.Cunninghamwas
supportedbytheGatsbyCharitableFoundation(GAT3708),theSimonsFoundation(542963),the
NSFAIInstituteforArtificialandNaturalIntelligence(ARNI:NSFDBI2229929),andtheKavli
Foundation; J. R. Gardner was supported by NSF awards IIS-2145644 and DBI-2400135.
References
EhsanAbbasnejad,JustinDomke,andScottSanner. Loss-calibratedMonteCarloactionselection. In
ProceedingsoftheAAAIConferenceonArtificialIntelligence ,volume29of AAAI.AAAIPress,
March 2015. ( page 10)
M. Ehsan Abbasnejad, Edwin V. Bonilla, and Scott Sanner. Decision-theoretic sparsification for
Gaussianprocesspreferencelearning.In MachineLearningandKnowledgeDiscoveryinDatabases ,
volume 13717 of LNCS, pages 515â€“530, Berlin, Heidelberg, 2013. Springer. ( page 10)
Virginia Aglietti, Xiaoyu Lu, Andrei Paleyes, and Javier GonzÃ¡lez. Causal Bayesian optimization. In
ProceedingsoftheInternationalConferenceonArtificialIntelligenceandStatistics ,volume108of
PMLR, pages 3155â€“3164. JMLR, June 2020. ( page 10)
Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, An-
drew Gordon Wilson, and Eytan Bakshy. BoTorch: A framework for efficient Monte-Carlo
Bayesian optimization. In Advances in Neural Information Processing Systems , volume 33, pages
21524â€“21538. Curran Associates, Inc., 2020. ( pages 2, 6, 7, 8, 16 )
P. G. Bissiri, C. C. Holmes, and S. G. Walker. A general framework for updating belief distributions.
Journal of the Royal Statistical Society Series B: Statistical Methodology , 78(5):1103â€“1130, 2016.
(pages 2, 5)
DavidM.Blei,AlpKucukelbir,andJonD.McAuliffe. Variationalinference: Areviewforstatisticians.
Journal of the American Statistical Association , 112(518):859â€“877, April 2017. ( pages 2, 3)
NathanBrown,MarcoFiscato,MarwinH.S.Segler,andAlainC.Vaucher. Guacamol: Benchmarking
models for de novo molecular design. Journal of Chemical Information and Modeling , 59(3):
1096â€“1108, Mar 2019. ( pages 8, 9)
Adam D. Cobb, Stephen J. Roberts, and Yarin Gal. Loss-Calibrated Approximate Inference in
Bayesian Neural Networks. arXiv Preprint arXiv:1805.03901, arXiv, May 2018. ( page 10)
A.P.Dempster,N.M.Laird,andD.B.Rubin. Maximumlikelihoodfromincompletedataviathe
EMalgorithm. JournaloftheRoyalStatisticalSociety: SeriesB(Methodological) ,39(1):1â€“22,
September 1977. ( page 4)
DavidEriksson,MichaelPearce,JacobGardner,RyanDTurner,andMatthiasPoloczek. Scalable
globaloptimizationvialocalBayesianoptimization. In AdvancesinNeuralInformationProcessing
Systems, volume 32, pages 5496â€“5507. Curran Associates, Inc., 2019. ( pages 1, 2, 8 )
PeterIFrazier. Knowledge-gradientmethodsforstatisticallearning . PhDthesis,PrincetonUniversity
Princeton, 2009. ( page 6)
Peter I Frazier. A tutorial on Bayesian optimization. arXiv Preprint arXiv:1807.02811, ArXiv, 2018.
(page 1)
ThÃ©o Galy-Fajou and Manfred Opper. Adaptive inducing points selection for Gaussian processes.
arXiv Preprint arXiv:2107.10066, arXiv, 2021. ( page 7)
Jacob Gardner, Geoff Pleiss, Kilian Q. Weinberger, David Bindel, and Andrew G. Wilson. GPyTorch:
Blackboxmatrix-matrixGaussianprocessinferencewithGPUacceleration. In AdvancesinNeural
Information Processing Systems , volume 31, pages 7576â€“7586. Curran Associates, Inc., 2018.
(pages 8, 16 )
Roman Garnett. Bayesian Optimization . Cambridge University Press, Cambridge, United Kingdom ;
New York, NY, 2023. ( pages 1, 2, 3, 6 )
11GillesGasso,AlainRakotomamonjy,andStÃ©phaneCanu. Recoveringsparsesignalswithacertain
family of nonconvex penalties and DC programming. IEEE Transactions on Signal Processing , 57
(12):4686â€“4698, 2009. ( page 9)
Ryan-Rhys Griffiths and JosÃ© Miguel HernÃ¡ndez-Lobato. Constrained Bayesian optimization for
automatic chemical design using variational autoencoders. Chemical Science , 11(2):577â€“586,
2020. (pages 1, 10 )
JamesHensman,NicoloFusi,andNeilD.Lawrence. Gaussianprocessesforbigdata. In Proceedings
of the Conference on Uncertainty in Artificial Intelligence , pages 282â€“290. AUAI Press, 2013.
(pages 1, 3)
JosÃ© Miguel HernÃ¡ndez-Lobato, James Requeima, Edward O. Pyzer-Knapp, and AlÃ¡n Aspuru-Guzik.
ParallelanddistributedThompsonsamplingforlarge-scaleacceleratedexplorationofchemical
space. In Proceedings of the International Conference on Machine Learning , volume 70 of PMLR,
pages 1470â€“1479. JMLR, July 2017. ( page 9)
Prateek Jaiswal, Harsha Honnappa, and Vinayak A. Rao. Asymptotic consistency of loss-calibrated
variational Bayes. Stat, 9(1):e258, 2020. ( pages 2, 5)
Prateek Jaiswal, Harsha Honnappa, and Vinayak Rao. On the statistical consistency of risk-sensitive
bayesian decision-making. In Advances in Neural Information Processing Systems , volume 36,
pages 53158â€“53200. Curran Associates, Inc., December 2023. ( pages 2, 5)
MartinJankowiak,GeoffPleiss,andJacobR.Gardner. Parametricgaussianprocessregressors. In
Proceedings of the 37th International Conference on Machine Learning , ICMLâ€™20. JMLR.org,
2020. (page 19)
DonaldR.Jones,MatthiasSchonlau,andWilliamJ.Welch. Efficientglobaloptimizationofexpensive
black-box functions. Journal of Global Optimization , 13(4):455â€“492, 1998. ( pages 1, 2, 5 )
Michael I. Jordan, Zoubin Ghahramani, Tommi S. Jaakkola, and Lawrence K. Saul. An introduction
to variational methods for graphical models. Machine Learning , 37(2):183â€“233, 1999. ( pages 1, 2,
3, 4)
DiederikP.KingmaandJimmyBa. Adam: AMethodforStochasticOptimization. In Proceedings
of the International Conference on Learning Representations , San Diego, California, USA, 2015.
(pages 15, 16 )
Diederik P. Kingma and Max Welling. Auto-encoding variational Bayes. In Proceedings of the
International Conference on Learning Representations , Banff, AB, Canada, April 2014. ( page 6)
JeremiasKnoblauch,JackJewson,andTheodorosDamoulas. Anoptimization-centricviewonBayesâ€™
rule: Reviewingandgeneralizingvariationalinference. JournalofMachineLearningResearch ,23
(132):1â€“109, 2022. ( pages 2, 5)
Alex Kulesza and Ben Taskar. Determinantal point processes for machine learning. Foundations and
TrendsÂ®in Machine Learning , 5(2â€“3):123â€“286, 2012. ( page 10)
Tomasz KuÅ›mierczyk, Joseph Sakaya, and Arto Klami. Variational Bayesian decision-making for
continuous utilities. In Advances in Neural Information Processing Systems , volume 32, pages
6395â€“6405. Curran Associates, Inc., 2019. ( pages 4, 5, 10 )
Simon Lacosteâ€“Julien, Ferenc HuszÃ¡r, and Zoubin Ghahramani. Approximate inference for the
loss-calibrated Bayesian. In Proceedings of the International Conference on Artificial Intelligence
and Statistics , volume 15 of PMLR, pages 416â€“424. JMLR, June 2011. ( pages 2, 4, 10 )
Kenneth Lange. MM Optimization Algorithms . Society for Industrial and Applied Mathematics,
Philadelphia, 2016. ( pages 2, 4)
BolianLi andRuqi Zhang. Long-tailed Classificationfrom aBayesian-decision-theoryPerspective.
arXiv Preprint arXiv:2303.06075, arXiv, 2023. ( page 10)
Wesley J Maddox, Samuel Stanton, and Andrew G Wilson. Conditioning sparse variational Gaussian
processes for online decision-making. In Advances in Neural Information Processing Systems ,
volume 34, pages 6365â€“6379. Curran Associates, Inc., 2021. ( pages 1, 2, 4, 6, 10 )
Alexander G. de G. Matthews, James Hensman, Richard Turner, and Zoubin Ghahramani. On
sparsevariationalmethodsandtheKullback-Leiblerdivergencebetweenstochasticprocesses. In
Proceedings of the International Conference on Artificial Intelligence and Statistics , volume 51 of
PMLR, pages 231â€“239. JMLR, May 2016. ( pages 1, 4)
12NatalieMaus,HaydnJones,JustonMoore,MattJ.Kusner,JohnBradshaw,andJacobGardner. Local
latent space Bayesian optimization over structured inputs. In Advances in Neural Information
Processing Systems , volume 35, pages 34505â€“34518, December 2022. ( pages 1, 9, 10 )
Natalie Maus, Kaiwen Wu, David Eriksson, and Jacob Gardner. Discovering many diverse solutions
withBayesianoptimization.In ProceedingsoftheInternationalConferenceonArtificialIntelligence
and Statistics , volume 206, pages 1779â€“1798. PMLR, April 2023. ( pages 1, 8, 10 )
Mitchell McIntire, Daniel Ratner, and Stefano Ermon. Sparse Gaussian Processes for Bayesian
Optimization. In ProceedingsoftheConferenceonUncertaintyinArtificialIntelligence ,Jersey
City, New Jersey, USA, 2016. AUAI Press. ( page 9)
ThomasP.Minka. Expectationpropagationforapproximatebayesianinference. In Proceedingsof
the Conference on Uncertainty in Artificial Intelligence , pages 362â€“369, San Francisco, CA, USA,
2001. Morgan Kaufmann Publishers Inc. ( page 10)
Jonas Mockus. The Bayesian approach to global optimization. In System Modeling and Optimization ,
pages 473â€“481. Springer, 1982. ( page 1)
Michael J. Morais and Jonathan W. Pillow. Loss-calibrated expectation propagation for approximate
Bayesian decision-making. Technical Report arXiv:2201.03128, arXiv, January 2022. ( page 10)
HenryB.Moss,SebastianW.Ober,andVictorPicheny. InducingpointallocationforsparseGaussian
processesinhigh-throughputBayesianoptimisation. In ProceedingsoftheInternationalConference
on Artificial Intelligence and Statistics , volume 206 of PMLR, pages 5213â€“5230. JMLR, April
2023. (pages 1, 4, 7, 10, 16, 17, 18 )
Radford M. Neal. Bayesian Learning for Neural Networks , volume 118 of Lecture Notes in Statistics .
Springer New York, New York, NY, 1996. ( page 9)
JoaquinQuiÃ±onero-CandelaandCarlEdwardRasmussen. Aunifyingviewofsparseapproximate
Gaussian process regression. Journal of Machine Learning Research , 6(65):1939â€“1959, 2005.
(page 1)
Rajesh Ranganath, Sean Gerrish, and David Blei. Black box variational inference. In Proceedings of
theInternationalConferenceonArtificialIntelligenceandStatistics ,volume33of PMLR,pages
814â€“822. JMLR, April 2014. ( page 10)
Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning .
The MIT Press, November 2005. ( page 1)
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and
approximate inference in deep generative models. In Proceedings of the International Conference
on Machine Learning , volume 32 of PMLR, pages 1278â€“1286. JMLR, June 2014. ( page 6)
Christian P. Robert. The Bayesian Choice: From Decision-Theoretic Foundations to Computational
Implementation . Springer Texts in Statistics. Springer, New York Berlin Heidelberg, 2. ed edition,
2001. (pages 2, 3)
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. Taking the
human out of the loop: A review of Bayesian optimization. Proceedings of the IEEE , 104(1):
148â€“175, 2015. ( pages 1, 5)
Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs. In
Advances in Neural Information Processing Systems , volume 18, pages 1257â€“1264. MIT Press,
2005. (page 5)
Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical Bayesian optimization of machine
learning algorithms. Advances in neural information processing systems , 25:2951â€“2959, 2012.
(page 10)
Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram,
Mostofa Patwary, Mr Prabhat, and Ryan Adams. Scalable Bayesian optimization using deep neural
networks. In Proceedings of the International Conference on Machine Learning , volume 37 of
PMLR, pages 2171â€“2180. JMLR, June 2015. ( page 9)
Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter. Bayesian Optimization
withRobustBayesianNeuralNetworks. In AdvancesinNeuralInformationProcessingSystems ,
volume 29, pages 4134â€“4142. Curran Associates, Inc., 2016. ( page 9)
13Samuel Stanton, Wesley Maddox, Nate Gruver, Phillip Maffettone, Emily Delaney, Peyton Greenside,
and Andrew Gordon Wilson. Accelerating Bayesian optimization for biological sequence design
withdenoisingautoencoders. In ProceedingsoftheInternationalConferenceonMachineLearning ,
volume 162 of PMLR, pages 20459â€“20478. JMLR, June 2022. ( pages 1, 10 )
Sonja Surjanovic and Derek Bingham. Virtual library of simulation experiments: Test functions and
datasets, 2013. ( page 8)
Alexander Terenin, David R. Burt, Artem Artemev, Seth Flaxman, Mark van der Wilk, Carl Edward
Rasmussen, and Hong Ge. Numerically stable sparse Gaussian processes via minimum separation
using cover trees. Journal of Machine Learning Research , 25(26):1â€“36, 2024. ( page 7)
Michalis Titsias. Variational learning of inducing variables in sparse gaussian processes. In
ProceedingsoftheInternationalConferenceonArtificialIntelligenceandStatistics ,volume5of
PMLR, pages 567â€“574. JMLR, April 2009. ( pages 1, 3)
Michalis Titsias and Miguel LÃ¡zaro-Gredilla. Doubly stochastic variational Bayes for non-conjugate
inference. In Proceedings of the International Conference on Machine Learning , volume 32 of
PMLR, pages 1971â€“1979. JMLR, June 2014. ( pages 6, 10 )
AustinTripp,ErikDaxberger,andJosÃ©MiguelHernÃ¡ndez-Lobato. Sample-efficientoptimization
in the latent space of deep generative models via weighted retraining. In Advances in Neural
InformationProcessingSystems ,volume33,pages11259â€“11272.CurranAssociates,Inc.,2020.
(pages 1, 10 )
Sattar Vakili, Henry Moss, Artem Artemev, Vincent Dutordoir, and Victor Picheny. Scalable
ThompsonsamplingusingsparseGaussianprocessmodels. In AdvancesinNeuralInformation
Processing Systems , volume 34, pages 5631â€“5643, 2021. ( pages 1, 10 )
KenanÅ ehiÄ‡,AlexandreGramfort,JosephSalmon,andLuigiNardi. Lassobench: Ahigh-dimensional
hyperparameter optimization benchmark suite for LASSO. In Proceedings of the International
Conference on Automated Machine Learning , volume 188 of PMLR, pages 2/1â€“24. JMLR, 25â€“27
Jul 2022. ( page 9)
YixinWangandDavidM.Blei. FrequentistconsistencyofvariationalBayes. JournaloftheAmerican
Statistical Association , 114(527):1147â€“1161, July 2019. ( page 5)
Zi Wang, Clement Gehring, Pushmeet Kohli, and Stefanie Jegelka. Batched large-scale bayesian
optimization in high-dimensional spaces. In Proceedings of the International Conference on
Artificial Intelligence and Statistics , volume 84 of PMLR, pages 745â€“754. JMLR, March 2018.
(pages 8, 9)
Larry Wasserman. All of statistics: a concise course in statistical inference . Springer Science &
Business Media, 2013. ( pages 2, 3)
Yadi Wei, Rishit Sheth, and Roni Khardon. Direct loss minimization for sparse Gaussian processes.
InProceedingsoftheInternationalConferenceonArtificialIntelligenceandStatistics ,volume130
ofPMLR, pages 2566â€“2574. JMLR, March 2021. ( page 10)
JamesWilson,FrankHutter,andMarcDeisenroth. MaximizingacquisitionfunctionsforBayesian
optimization. In AdvancesinNeuralInformationProcessingSystems ,pages9884â€“9895.Curran
Associates, Inc., 2018. ( pages 2, 7)
Jian Wu, Matthias Poloczek, Andrew G Wilson, and Peter Frazier. Bayesian optimization with
gradients. In Advancesin NeuralInformation ProcessingSystems , volume30,pages5267â€“5278.
Curran Associates, Inc., 2017. ( page 2)
14A Implementation Details
We will now provide additional details on the implementation. For the implementation, we treat
the SVGP parameters, such as the variational parameters ğ€, inducing point locations ğ’, and
hyperparameters ğœ½, equally. Therefore, for clarity, we will collectively denote them as ğ’˜=(ğ€,ğ’,ğœ½)
suchthatğ’˜âˆˆğ’² â‰œÎ›Ã—ğ’³ğ‘šÃ—Î˜,andtheresultingSVGPvariationalapproximationas ğ‘ğ’˜. Then,
the ELBO and EULBO are equivalently denoted as follows:
â„’ELBO(ğ’˜;ğ’Ÿ)â‰œ â„’ELBO(ğ€,ğ’,ğœ½;ğ’Ÿ)
â„’EULBO(ğ’™,ğ’˜;ğ’Ÿğ’™,ğ’Ÿğ’˜)â‰œğ”¼ğ‘“âˆ¼ğ‘ğ’˜(ğ‘“)logğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ’™)+â„’ELBO(ğ’˜;ğ’Ÿğ’˜).
Also,noticethatthe â„’EULBOseparatelydenotethedatasettobepassedtotheutilityandtheELBO.
(Setting ğ’Ÿğ‘¡=ğ’Ÿğ’˜=ğ’Ÿğ’™retrieves the original formulation in Eq. (8).)
Alternating Updates We perform block-coordinate ascent on the EULBO by alternating between
maximizing over ğ’™asğ’˜. Using vanilla gradient descent, the ğ’™-update is equivalent to
ğ’™â†ğ’™+ğ›¾ğ’™âˆ‡ğ’™â„’EULBO(ğ’™,ğ’˜;ğ’Ÿ)=ğ’™+ğ›¾ğ’™âˆ‡ğ’™ğ”¼ğ‘“âˆ¼ğ‘ğ’˜(ğ‘“)logğ‘¢(ğ’™,ğ‘“;ğ’Ÿ),
whereğ›¾ğ’™isthestepsize. Ontheotherhand,forthe ğ’˜-update,wesubsamplethedatasuchthatwe
optimize the ELBO over a minibatch ğ‘† âŠ‚ğ’Ÿof sizeğµ=|ğ‘†|as
ğ’˜â†ğ’˜+ğ›¾ğ’˜âˆ‡ğ’˜â„’EULBO(ğ’™,ğ’˜;ğ‘†,ğ’Ÿ)=ğ’˜+ğ›¾ğ’˜âˆ‡ğ’˜(ğ”¼ğ‘“âˆ¼ğ‘ğ’˜(ğ‘“)logğ‘¢(ğ’™,ğ‘“;ğ’Ÿ)+â„’ELBO(ğ’˜;ğ‘†)),
whereğ›¾ğ’˜isthestepsize. Naturally,the ğ’˜-updateisstochasticduetominibatching,whilethe ğ’™-update
is deterministic. In practice, we leverage the Adam update rule (Kingma and Ba, 2015) instead of
simple gradient descent. Together with gradient clipping, this alternating update scheme is much
more robust than jointly updating (ğ’™,ğ’˜).
Algorithm 1: EULBO Maximization Policy
Input:SVGP parameters ğ’˜0=(ğ€0,ğ’0,ğœ½0), Dataset ğ’Ÿğ‘¡, BO utility function ğ‘¢,
Output: BO queryğ’™ğ‘¡+1
1
âŠ³Compute Warm-Start Initializations
2ğ’˜â†argmaxğ’˜âˆˆğ’²â„’ELBO(ğ’˜;ğ’Ÿğ‘¡)withğ’˜0as initialization.
3ğ’™â†argmaxğ’™âˆˆğ’³âˆ«ğ‘¢(ğ’™,ğ‘“;ğ’Ÿğ‘¡)ğ‘ğ’˜(ğ‘“)dğ‘“
4
âŠ³Maximize EULBO
5repeat
âŠ³Update posterior approximation ğ‘ğ’˜
6Fetch minibatch ğ‘†fromğ’Ÿğ‘¡
7Computeğ’ˆğ’˜â†âˆ‡ğ’˜â„’EULBO(ğ’™,ğ’˜;ğ‘†,ğ’Ÿğ‘¡)
8Clipğ’ˆğ’˜with threshold ğºclip
9ğ’˜â†AdamStepğ›¾ğ’˜(ğ’˜,ğ’ˆğ’˜)
10
âŠ³Update BO query ğ’™
11Computeğ’ˆğ’™â†âˆ‡ğ’™â„’EULBO(ğ’™,ğ’˜;ğ‘†,ğ’Ÿğ‘¡)
12Clipğ’ˆğ’™with threshold ğºclip
13ğ’™â†AdamStepğ›¾ğ’™(ğ’™,ğ’ˆğ’™)
14ğ’™â†projğ’³(ğ’™)
15untiluntil converged
16ğ’™ğ‘¡+1â†ğ’™
17
OverviewofPseudocode. Thecompletehigh-levelviewofthealgorithmispresentedinAlgorithm1,
exceptfortheacquisition-specificdetails. AdamStepğ›¾(ğ’™,ğ’ˆ)appliestheAdamstepsizerule(Kingma
andBa,2015)tothecurrentlocation ğ’™withthegradientestimate ğ’ˆandthestepsize ğ›¾. Inpractice,
Adamisaâ€œstatefulâ€optimizer,whichmaintainstwoscalar-valuedstatesforeachscalarparameter.
For this, we re-initialize the Adam states at the beginning of each BO step.
15Initialization. In the initial BO step ğ‘¡= 0, we initialize ğ’0with the DPP-based inducing point
selection strategy of Moss et al. (2023). For the remaining SVGP parameters ğ€0andğœ½0, we used the
defaultinitializationofGPyTorch(Gardneretal.,2018). FortheremainingBOsteps ğ‘¡>0,weuseğ’˜
from the previous BO step as the initialization ğ’˜0of the current BO step.
Warm-Starting. Duetothenon-convexityandmulti-modalityofboththeELBOandtheacquisition
function, it is critical to appropriately initialize the EULBO maximization procedure. As mentioned
inSection3.5,towarm-starttheEULBOmaximizationprocedure,weusetheconventional2-step
scheme Eq. (5), where we maximize the ELBO and then maximize the acquisition function. For
ELBOmaximization,weapplyAdam(KingmaandBa,2015)withthestepsizesetas ğ›¾ğ‘¤untilthe
convergencecriteria(describedbelow)aremet. Foracquisitionfunctionmaximization,weinvokethe
highly optimized BoTorch.optimize.optimize_acqf function (Balandat et al., 2020).
MinibatchSubsamplingStrategy. Ascommonlydone,weusethereshufflingsubsamplingstrategy
wherethedataset ğ’Ÿğ‘¡isshuffledandpartitionedintominibatchesofsize ğµ. Thenumberofminibatches
constitutes an â€œepoch.â€ The dataset is reshuffled/repartitioned after going through a full epoch.
ConvergenceDetermination. ForbothmaximizingtheELBOduringwarm-startingandmaximizing
theEULBO,wecontinueoptimizationuntilwestopmakingprogressorexceed ğ‘˜epochsnumberof
epochs. That is if the ELBO/EULBO function value fails to make progress for ğ‘›failnumber of steps.
Table 1: Configurations of Hyperparameters used for the Experiments
Hyperparameter Value Description
ğ›¾ğ’™ 0.001ADAM stepsize for the query ğ’™
ğ›¾ğ’˜ 0.01ADAM stepsize for the SVGP parameters ğ’˜
ğµ 32Minibatch size
ğºclip 2.0Gradient clipping threshold
ğ‘˜epochs 30Maximum number of epochs
ğ‘›fail 3Maximum number of failure to improve
ğ‘š 100Number of inducing points
ğ‘›0=|ğ’Ÿ0| 100Number of observations for initializing BO
# quad. 20Number of Gauss-Hermite quadrature points
optimize_acqf: restarts 10
optimize_acqf: raw_samples 256
optimize_acqf: batch_size 1âˆ•20Depends on task; see details in Section 4
Hyperparameters. The hyperparameters used in our experiments are organized in Table 1. For
the full-extent of the implementation details and experimental configuration, please refer to the
supplementary code.
16B Additional Plots
We provide additional results and plots that were omitted from the main text.
B.1 Additional Results on Molecule Tasks
In Fig. 4, we provide plots on additional results that are similar to those in Fig. 2. On three of the
moleculetasks,weuse10,000randommoleculesfromtheGuacaMoldatasetasinitialization. Thisis
more consistent with what has been done in previous works and achieves better overall optimization
performance.
Figure4: Additionaloptimizationresultsonthreemoleculetasksusing10,000randommolecules
fromthe GuacaMoldataset asinitialization . Each line/shadedregion representsthe mean/standard
error over 20 runs. We count oracle calls starting afterthese initialization evaluations for all methods.
B.2 Separate Plots for BO and TuRBOResults
Inthissection,weprovideadditionalplotsseparatingoutBOand TuRBOresultstomakevisualization
easier.
Figure 5: BO-only optimization results of Fig. 2 . We compare EULBO-SVGP, ELBO-SVGP,
ELBO-SVGPwithDPPinducingpointplacement(Mossetal.,2023),andexactGPs. Thesearea
subset of the same results shown in Fig. 2. Each line/shaded region represents the mean/standard
error over 20 runs.
17Figure 6: TuRBO-only optimization results of Fig. 2 . We compare EULBO-SVGP, ELBO-SVGP,
ELBO-SVGPwithDPPinducingpointplacement(Mossetal.,2023),andexactGPs. Thesearea
subset of the same results shown in Fig. 2. Each line/shaded region represents the mean/standard
error over 20 runs.
B.3 Effect of Number of Inducing Points
For theresults withapproximate-GPs in Section4, we used ğ‘š=100inducing points. In Fig. 7,we
evaluate the effect of using a larger number of inducing points ( ğ‘š= 1024) for EULBO-SVGP and
ELBO-SVGP.
0 5000 10000 15000 20000
Number of Oracle Calls0.34
0.33
0.32
0.31
0.30
0.29
Mean Reward
Lasso DNA
TuRBO (EULBO EI) w/ 1024 inducing points
TuRBO (EULBO EI)
TuRBO (ELBO EI) w/ 1024 inducing points
TuRBO (ELBO EI)
Figure 7: Ablating the number of inducing points used by EULBO-SVGP and ELBO-SVGP .
AsinFig.2,wecomparerunning TuRBOwith EULBO-SVGPandwithELBO-SVGPusing ğ‘š=100
inducing points used for both methods. We add two additional curves for TuRBOwith EULBO-SVGP
andTuRBOwith ELBO-SVGP using ğ‘š=1024inducing points. Each line/shaded region represents
the mean/standard error over 20 runs.
Fig. 7 shows that the number of inducing points has limited impact on the overall performance of
TuRBO, and EULBO-SVGP outperforms ELBO-SVGP regardless of the number of inducing points
used.
18B.4 Effect of GP Objective
TheresultsinSection4usedastandardSVGPobjective. Inthissection,weevaluatetheeffectofusing
an alternative objective: the parametric Gaussian process regressor (PPGPR; Jankowiak et al., 2020)
objective. PPGPRdiffersfrom thestandard SVGPobjective inthat thevariationalapproximation is
optimized to maximize the predictive accuracy instead of matching the posterior.
0 5000 10000 15000 20000
Number of Oracle Calls0.34
0.33
0.32
0.31
0.30
0.29
Mean Reward
Lasso DNA
TuRBO (EULBO EI) PPGPR
TuRBO (EULBO EI)
TuRBO (ELBO EI) PPGPR
TuRBO (ELBO EI)
Figure 8: Effect of using the PPGPR objective instead of the SVGP objective for EULBO-EI
andELBO-EI .AsinFig.2,wecomparerunning TuRBOwith EULBO-EIandwithELBO-EIusing
an SVGP model for both methods. We add two additional curves for TuRBOwith EULBO-EI with a
PPGPR model, and TuRBOwith ELBO-EI using a PPGPR model. Each line/shaded region represents
the mean/standard error over 20 runs.
Wecomparethechoiceofobjective(PPGPRvsSVGP)inFig.8andobservethattheobjectivehas
limited impact on the overall performance of TuRBO. In particular, EULBO-EI outperforms ELBO-EI
regardless of the GP objective.
19C Compute Resources
Table 2: Internal Cluster Setup
Type Model and Specifications
System Topology 20 nodes with 2 sockets each with 24 logical threads (total 48 threads)
Processor 1 Intel Xeon Silver 4310, 2.1 GHz (maximum 3.3 GHz) per socket
Cache 1.1 MiB L1, 30 MiB L2, and 36 MiB L3
Memory 250 GiB RAM
Accelerator 1 NVIDIA RTX A5000 per node, 2 GHZ, 24GB RAM
Type of Compute and Memory. All results in the paper required the use of GPU workers (one
GPU per run of each method on each task). The majority of runs were executed on an internal
cluster,wheredetailsareshowninTable2,whereeachnodewasequippedwithanNVIDIARTX
A5000 GPU. In addition, we used cloud compute resources for a short period leading up to the
subsmissionof thepaper. Weused40 RTX4090GPU workersfrom runpod.io ,where eachGPU
hadapproximately24GBofGPUmemory. Whileweused24GBGPUsforourexperiments,each
run of our experiments only requires approximately 15 GB of GPU memory.
Execution Time. Each optimization run for non-molecule tasks takes approximately one day to
finish. Since we run the molecule tasks out to a much larger number of function evaluations than
other tasks ( 80000total function evaluations for each molecule optimization task), each molecule
optimization task run takes approximately 2days of execution time. With all eight tasks, ten methods
run,and20runscompletedpermethod,resultsinFig.2include 1600totaloptimizationruns( 800
for molecule tasks and 800for non-molecule tasks). Additionally, the two added curves in each
plot in Fig. 3 required 160additional runs ( 120for molecule tasks and 40for non-molecule task).
Completingalloftherunsneededtoproducealloftheresultsinthispaperthereforerequiredroughly
2680total GPU hours.
Compute Resources Used During Preliminary Investigations. In addition to the computational
resourcesrequiredtoproduceexperimentalresultsinthepaperdiscussedabove,wespentapproximately
500hours of GPU time on preliminary investigations. This was done on the aforementioned internal
cluster shown in Table 2.
D Wall-clock Run Times
In Table 3, we provide average wall-clock run times of different methods on the Lasso DNA
optimization task.
Table3: Averagewall-clockruntimesforonefullrunofTuRBO
on the Lasso DNA task. We compare the average wall-clock
runtimeofTuRBOonallTuRBOmethodsfromFigure2. Note
that we do not include the wall clock run time for TuRBO with
ExactEI here becauseweonlyran this methodout to 2koracle
calls (rather than the full budget of 20k oracle calls).
Method Wall-clock Run Time in Minutes
EULBO EI 267.30 Â±2.53
EULBO KG 296.95 Â±1.31
ELBO EI 184.40 Â±0.59
Moss et al. 20203 EI 194.32 Â±0.77
20NeurIPS Paper Checklist
1.Claims
Question: Dothemainclaimsmadeintheabstractandintroductionaccuratelyreflectthe
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: All stated claims are backed-up with results in Section 4 and the stated
focus/scopeofthepaperaccuratelyreflectswhatisdiscussedthroughouttherestofthepaper.
Guidelines:
â€¢TheanswerNAmeansthattheabstractandintroductiondonotincludetheclaimsmade
in the paper.
â€¢The abstract and/or introduction should clearly state the claims made, including the
contributionsmadeinthepaperandimportantassumptionsandlimitations. ANoor
NA answer to this question will not be perceived well by the reviewers.
â€¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢Itisfinetoincludeaspirationalgoalsasmotivationaslongasitisclearthatthesegoals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: See Section 6.
Guidelines:
â€¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
â€¢The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢Thepapershouldpointoutanystrongassumptionsandhowrobusttheresultsareto
violations of these assumptions (e.g., independence assumptions, noiseless settings,
modelwell-specification,asymptoticapproximationsonlyholdinglocally). Theauthors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
â€¢Theauthorsshouldreflectonthescopeoftheclaimsmade,e.g.,iftheapproachwas
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢Theauthorsshouldreflectonthefactorsthatinfluencetheperformanceoftheapproach.
Forexample,afacialrecognitionalgorithmmayperformpoorlywhenimageresolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
â€¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢Ifapplicable,theauthorsshoulddiscusspossiblelimitationsoftheirapproachtoaddress
problems of privacy and fairness.
â€¢While the authors might fear that complete honesty about limitations might be used by
reviewersasgroundsforrejection,aworseoutcomemightbethatreviewersdiscover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgmentandrecognizethatindividualactionsinfavoroftransparencyplayanimportant
role in developing norms that preserve the integrity of the community. Reviewers will
be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [NA] .
21Justification: This work does not contain a formal theoretical analysis.
Guidelines:
â€¢The answer NA means that the paper does not include theoretical results.
â€¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢Allassumptionsshouldbeclearlystatedorreferenced inthestatementofanytheorems.
â€¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
â€¢Inversely,anyinformalproofprovidedinthecoreofthepapershouldbecomplemented
by formal proofs provided in appendix or supplemental material.
â€¢Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Doesthepaperfullydisclosealltheinformationneededtoreproducethemain
experimentalresultsofthepapertotheextentthatitaffectsthemainclaimsand/orconclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes] .
Justification: We provide detailed explanation of how our method works in Section 3 and all
additionalrequireddetailstoreproduceresultsinSection4andAppendixA.Additionally,
we have included a link to a public GitHub repository containing all of the source code used
intheworkinSection4. Thissourcecodeallowsanyreadertorunourcodetoreproduce
all results in the paper. Additionally, the README in the repository provides detailed
instructions to make setting up the proper environment and running the code easy for users.
Guidelines:
â€¢The answer NA means that the paper does not include experiments.
â€¢Ifthepaperincludesexperiments,aNoanswertothisquestionwillnotbeperceivedwell
bythereviewers: Makingthepaperreproducibleisimportant,regardlessofwhether
the code and data are provided or not.
â€¢Ifthecontributionisadatasetand/ormodel,theauthorsshoulddescribethestepstaken
to make their results reproducible or verifiable.
â€¢Dependingonthecontribution,reproducibilitycanbeaccomplishedinvariousways.
Forexample, ifthecontributionisanovelarchitecture, describingthearchitecturefully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructionsfor howtoreplicatethe results,accessto ahostedmodel (e.g.,inthe case
ofalargelanguagemodel),releasingofamodelcheckpoint,orothermeansthatare
appropriate to the research performed.
â€¢While NeurIPS does not require releasing code, the conference does require all
submissions to provide some reasonable avenue for reproducibility, which may depend
on the nature of the contribution. For example
(a)Ifthecontributionisprimarilyanewalgorithm,thepapershouldmakeitclearhow
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
eitherbeawaytoaccessthismodelforreproducingtheresultsorawaytoreproduce
themodel(e.g.,withanopen-sourcedatasetorinstructionsforhowtoconstructthe
dataset).
(d)Werecognizethatreproducibilitymaybetrickyinsomecases,inwhichcaseauthors
are welcome to describe the particular way they provide for reproducibility. In the
case of closed-source models, it may be that access to the model is limited in some
way(e.g.,toregisteredusers),butitshouldbepossibleforotherresearcherstohave
some path to reproducing or verifying the results.
225.Open access to data and code
Question: Doesthepaperprovideopenaccesstothedataandcode,withsufficientinstructions
tofaithfullyreproducethemainexperimentalresults,asdescribedinsupplementalmaterial?
Answer: [Yes] Replace by [Yes] , [No] , or [NA] .
Justification: We have included a link to a public GitHub repository containing all of the
source code used in the work in Section 4. This source code allows any reader to run our
code to reproduce all results in the paper. Additionally, the README in the repository
providesdetailedinstructionstomakesettinguptheproperenvironmentandrunningthe
code easy for users.
Guidelines:
â€¢The answer NA means that paper does not include experiments requiring code.
â€¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢While we encourage the release of code and data, we understand that this might not be
possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
includingcode,unlessthisiscentraltothecontribution(e.g.,foranewopen-source
benchmark).
â€¢The instructions should contain the exact command and environment needed to run
to reproduce the results. See the NeurIPS code and data submission guidelines
(https://nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
â€¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢Providing asmuch informationas possiblein supplementalmaterial(appended tothe
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: All chosen hyper-parameters and implementation details are stated in section 4
and Appendix A.
Guidelines:
â€¢The answer NA means that the paper does not include experiments.
â€¢Theexperimentalsettingshouldbepresentedinthecoreofthepapertoalevelofdetail
that is necessary to appreciate the results and make sense of them.
â€¢The fulldetails canbe provided eitherwith thecode, in appendix,or as supplemental
material.
7.Experiment Statistical Significance
Question: Doesthepaperreporterrorbarssuitablyandcorrectlydefinedorotherappropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Onallplots,weplotthemeantakenovermultiplerandomrunsandinclude
error bars to show the standard error over the runs.
Guidelines:
â€¢The answer NA means that the paper does not include experiments.
23â€¢Theauthorsshouldanswer"Yes"iftheresultsareaccompaniedbyerrorbars,confidence
intervals,orstatisticalsignificancetests,atleastfortheexperimentsthatsupportthe
main claims of the paper.
â€¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/testsplit,initialization,randomdrawingofsomeparameter,oroverall
run with given experimental conditions).
â€¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢The assumptions made should be given (e.g., Normally distributed errors).
â€¢Itshouldbeclearwhethertheerrorbaristhestandarddeviationorthestandarderrorof
the mean.
â€¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferablyreporta2-sigmaerrorbarthanstatethattheyhavea96%CI,ifthehypothesis
of Normality of errors is not verified.
â€¢For asymmetric distributions, the authors should be careful not to show in tables or
figuressymmetricerrorbarsthatwouldyieldresultsthatareoutofrange(e.g. negative
error rates).
â€¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: Foreachexperiment,doesthepaperprovidesufficientinformationonthecomputer
resources(typeofcomputeworkers,memory,timeofexecution)neededtoreproducethe
experiments?
Answer: [Yes]
Justification: See Appendix C.
Guidelines:
â€¢The answer NA means that the paper does not include experiments.
â€¢Thepapershouldindicatethetypeofcomputeworkers CPUorGPU,internalcluster,
or cloud provider, including relevant memory and storage.
â€¢Thepapershouldprovidetheamountofcomputerequiredforeachoftheindividual
experimental runs as well as estimate the total compute.
â€¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We have read the NeurIPS Code of Ethics and made sure to adhere to them in
all aspects.
Guidelines:
â€¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢Ifthe authorsanswer No, theyshould explainthe specialcircumstances thatrequire a
deviation from the Code of Ethics.
â€¢The authors should make sure to preserve anonymity (e.g., if there is a special
consideration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [No] .
Justification: The paper is methodological, where the considered algorithm does not
immediately pose societal risks.
24Guidelines:
â€¢The answer NA means that there is no societal impact of the work performed.
â€¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢Examplesofnegativesocietalimpactsincludepotentialmaliciousorunintendeduses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g.,deploymentoftechnologiesthatcouldmakedecisionsthatunfairlyimpactspecific
groups), privacy considerations, and security considerations.
â€¢The conference expects that many papers will be foundational research and not tied
toparticularapplications,letalonedeployments. However,ifthereisadirectpathto
any negative applications, the authors should point it out. For example, it is legitimate
topointoutthatanimprovementinthequalityofgenerativemodelscouldbeusedto
generate deepfakes for disinformation. On the other hand, it is not needed to point out
thatagenericalgorithmforoptimizingneuralnetworkscouldenablepeopletotrain
models that generate Deepfakes faster.
â€¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technologyisbeingusedasintendedbutgivesincorrectresults,andharmsfollowing
from (intentional or unintentional) misuse of the technology.
â€¢Iftherearenegativesocietalimpacts,theauthorscouldalsodiscusspossiblemitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA] .
Justification: The paper does not use data with potential societal concerns.
Guidelines:
â€¢The answer NA means that the paper poses no such risks.
â€¢Releasedmodelsthathaveahighriskformisuseordual-useshouldbereleasedwith
necessary safeguards to allow for controlled use of the model, for example by requiring
thatusersadheretousageguidelinesorrestrictionstoaccessthemodelorimplementing
safety filters.
â€¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢Werecognizethatprovidingeffectivesafeguardsischallenging,andmanypapersdo
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Arethecreatorsororiginalownersofassets(e.g.,code,data,models),usedin
thepaper,properlycreditedandarethelicenseandtermsofuseexplicitlymentionedand
properly respected?
Answer: [Yes]
Justification: All creators of assets used to produce our results are cited in Section 4. All
assets used are open source software or models.
Guidelines:
â€¢The answer NA means that the paper does not use existing assets.
â€¢The authors should cite the original paper that produced the code package or dataset.
â€¢Theauthorsshouldstatewhichversionoftheassetisusedand,ifpossible,includea
URL.
â€¢The name of the license (e.g., CC-BY 4.0) should be included for each asset.
25â€¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
hascuratedlicensesforsomedatasets. Theirlicensingguidecanhelpdeterminethe
license of a dataset.
â€¢Forexistingdatasetsthatarere-packaged,boththeoriginallicenseandthelicenseof
the derived asset (if it has changed) should be provided.
â€¢Ifthisinformationisnotavailableonline,theauthorsareencouragedtoreachouttothe
assetâ€™s creators.
13.New Assets
Question: Arenewassetsintroducedinthepaperwelldocumentedandisthedocumentation
provided alongside the assets?
Answer: [NA] .
Justification: The paper does not introduce new assets.
Guidelines:
â€¢The answer NA means that the paper does not release new assets.
â€¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢Thepapershoulddiscusswhetherandhowconsentwasobtainedfrompeoplewhose
asset is used.
â€¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
includethefulltextofinstructionsgiventoparticipantsandscreenshots,ifapplicable,as
well as details about compensation (if any)?
Answer: [NA] .
Justification: The paper does not involve human participants.
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Including this information in the supplemental material is fine, but if the main
contribution of the paper involves human subjects, then as much detail as possible
should be included in the main paper.
â€¢According to the NeurIPS Code of Ethics, workersinvolvedin data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.InstitutionalReviewBoard(IRB)ApprovalsorEquivalentforResearchwithHuman
Subjects
Question: Doesthepaperdescribepotentialrisksincurredbystudyparticipants,whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals(oranequivalentapproval/reviewbasedontherequirementsofyourcountryor
institution) were obtained?
Answer: [NA] .
Justification: The paper does not involve live participants.
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
26â€¢Dependingonthecountryinwhichresearchisconducted,IRBapproval(orequivalent)
mayberequiredforanyhumansubjectsresearch. IfyouobtainedIRBapproval,you
should clearly state this in the paper.
â€¢Werecognizethattheproceduresforthismayvarysignificantlybetweeninstitutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
27