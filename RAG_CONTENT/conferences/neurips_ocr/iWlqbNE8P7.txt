Physics-Informed Regularization for Domain-Agnostic
Dynamical System Modeling
Zijie Huang1âˆ—Wanjia Zhao2âˆ— â€ Jingdong Gao1Ziniu Hu3Xiao Luo1
Yadi Cao1Yuanzhou Chen1Yizhou Sun1Wei Wang1
1University of California Los Angeles,2Stanford University
3California Institute of Technology
https://treat-ode.github.io/
Abstract
Learning complex physical dynamics purely from data is challenging due to the
intrinsic properties of systems to be satisfied. Incorporating physics-informed
priors, such as in Hamiltonian Neural Networks (HNNs), achieves high-precision
modeling for energy-conservative systems. However, real-world systems often
deviate from strict energy conservation and follow different physical priors. To ad-
dress this, we present a framework that achieves high-precision modeling for a wide
range of dynamical systems from the numerical aspect, by enforcing Time-Reversal
Symmetry (TRS) via a novel regularization term. It helps preserve energies for
conservative systems while serving as a strong inductive bias for non-conservative,
reversible systems. While TRS is a domain-specific physical prior, we present the
firsttheoretical proof that TRS loss can universally improve modeling accuracy by
minimizing higher-order Taylor terms in ODE integration, which is numerically
beneficial to various systems regardless of their properties, even for irreversible
systems. By integrating the TRS loss within neural ordinary differential equation
models, the proposed model TREAT demonstrates superior performance on diverse
physical systems. It achieves a significant 11.5% MSE improvement in a challeng-
ing chaotic triple-pendulum scenario, underscoring TREATâ€™s broad applicability
and effectiveness. Code and further details are available at here.
1 Introduction
Dynamical systems, spanning applications from physical simulations (Kipf et al ., 2018; Wang et al .,
2020; Lu et al ., 2022; Huang et al ., 2023; Luo et al ., 2023a; Xu et al ., 2024; Luo et al ., 2024) to robotic
control (Li et al ., 2022; Ni and Qureshi, 2022), are challenging to model due to intricate dynamic
patterns and potential interactions under multi-agent settings. Traditional numerical simulators
require extensive domain knowledge for design, which is sometimes unknown (Sanchez-Gonzalez
et al., 2020), and can consume significant computational resources (Wang et al ., 2024). Therefore,
directly learning dynamics from the observational data becomes an attractive alternative.
Existing deep learning approaches (Sanchez-Gonzalez et al ., 2020; Pfaff et al ., 2021; Han et al .,
2022a) usually learn a fixed-step transition function to predict system dynamics from timestamp t
to timestamp t+ 1and rollout trajectories recursively. The transition function can have different
inductive biases, such as Graph Neural Networks (GNNs) (Pfaff et al ., 2020; Martinkus et al .,
2021; Lam et al ., 2023; Cao et al ., 2023) for capturing pair-wise interactions among agents through
message passing. Most recently, neural ordinary differential equations (Neural ODEs) (Chen et al .,
âˆ—Equal contribution, Corresponding to Zijie Huang <zijiehuang@cs.ucla.edu>, Wanjia Zhao <wanji-
azh@cs.stanford.edu>
â€ Work done as a visiting student at UCLA
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Time-ReversalDynamicalSystemsunderClassicalMechanicsEnergy-Conservative(a)High-PrecisionModelingofDynamicalSystems
ğ‘‘ğ‘…(ğ‘§)ğ‘‘ğ‘¡=âˆ’ğ¹(ğ‘…ğ‘§)ğ‘¡backwardforwardğ‘§=ğ‘,ğ‘ğ‘…ğ‘§=(ğ‘,âˆ’ğ‘)Identicalpositions(ğ‘)(b.2)Time-ReversalSymmetryTRSLossInjectingPhysicalPriorReducingErrorAccumulationoverIntegrationSteps
(b.1)PhysicalPriors
IntegrationstepsEulerâ€™smethodGrorundtruthğ‘§!"#=ğ‘§!+ğ‘‘ğ¹ğ‘‘ğ‘§!âˆ†ğ‘¡+ğ‘‚âˆ†ğ‘¡$+..NumericalErrors(b.3)ErrorAccumulationFigure 1: (a) High-precision modeling for dynamical systems; (b.1) Classification of classical
mechanical systems based on (Tolman, 1938; Lamb and Roberts, 1998);(b.2) Tim-Reversal Symmetry
illustration;(b.3) Error accumulation in numerical solvers.
2018; Rubanova et al ., 2019) have emerged as a potent solution for modeling system dynamics in a
continuous manner, which offer superior prediction accuracy over discrete models in the long-range,
and can handle systems with partial observations. In particular, GraphODEs (Huang et al ., 2020; Luo
et al., 2023b; Zang and Wang, 2020; Jiang et al ., 2023; Luo et al ., 2023c) extend NeuralODEs to
model interacting (multi-agent) dynamical systems, where agents co-evolve and form trajectories
jointly.
However, the complexity of dynamical systems necessitates large amounts of data. Models trained on
limited data risk violating fundamental physical principles such as energy conservation. A promising
strategy to improve modeling accuracy involves incorporating physical inductive biases (Raissi et al .,
2019; Cranmer et al ., 2020). Existing models like Hamiltonian Neural Networks (HNNs) (Greydanus
et al., 2019; Sanchez-Gonzalez et al ., 2019) strictly enforce energy conservation, yielding more
accurate predictions for energy-conservative systems. However, not all real-world systems strictly
adhere to energy conservation, and they may adhere to various physical priors. Other methods that
model both energy-conserving and dissipative systems, as well as reversible systems, offer more
flexibility (Zhong et al ., 2020; Gruber et al ., 2024). Nevertheless, they often rely on prior knowledge
of the system and are also limited to systems with corresponding physical priors. Such system
diversity largely limits the usage of existing models which are designed for specific physical prior.
To address this, we present a framework that achieves high-precision modeling for a wide range
of dynamical systems from the numerical aspect, by enforcing Time-Reversal Symmetry (TRS)
via a novel regularization term. Specifically, TRS posits that a systemâ€™s dynamics should remain
invariant when time is reversed (Lamb and Roberts, 1998). To incorporate TRS, we propose a
simple-yet-effective self-supervised regularization term that acts as a soft constraint. This term
aligns forward and backward trajectories predicted by a neural network and we use GraphODE as
the backbone. We theoretically prove that the TRS loss effectively minimizes higher-order Taylor
expansion terms during ODE integration, offering a general numerical advantage for improving
modeling accuracy across a wide array of systems, regardless of their physical properties. It forces
the model to capture fine-grained physical properties such as jerk (the derivatives of accelerations)
and provides more regularization for long-term prediction. We also justify our TRS design choice,
showing case its superior performance both analytically and empirically. We name the model as
TREAT ( Time-Reversal Symme try ODE).
Note that TRS itself is a physical prior, that is broader than energy conservation as depicted in
Figure 1(b.1). It covers classical energy-conservative systems such as Newtonian mechanics, and
also non-conservative, reversible systems like Stokes flow (Pozrikidis, 2001), commonly encountered
in microfluidics (Kim and Karrila, 2013; Cao and Li, 2018; Cao et al ., 2019). Therefore, TRS loss
achieves high-precision modeling from both the physical aspect, and the numerical aspect as shown
in Figure 1(a), making it domain-agnostic and widely applicable to various dynamical systems.
We systematically conduct experiments across 9 diverse datasets spanning across 1.) single-agent,
multi-agent systems; 2.) simulated and real-world systems; and 3.) systems with different physical
2priors. TREAT consistently outperforms state-of-the-art baselines, affirming its effectiveness and
versatility across various dynamic scenarios.
Our primary contributions can be summarized as follows:
â€¢We introduce TREAT, a powerful framework that achieves high-precision modeling for a
wide range of systems from the numerical aspect, by enforcing Time-Reversal Symmetry
(TRS) via a regularization term.
â€¢We establish the firsttheoretical proof that the time-reversal symmetry loss could in general
help learn more fine-grained and long-context system dynamics from the numerical aspect,
regardless of systemsâ€™ physical properties (even irreversible systems). This bridges the
specific physical implication and the general numerical benefits of the physical prior -TRS.
â€¢We present empirical evidence of TREATâ€™s state-of-the-art performance in a variety of
systems over 9 datasets, including real-world & simulated systems, etc. It yields a significant
MSE improvement of 11.5% on the challenging chaotic triple-pendulum system.
2 Preliminaries and Related Work
We represent a dynamical system as a graph G= (V,E), where Vdenotes the node set of N
agents3andEdenotes the set of edges representing their physical interactions. For simplicity, we
assumed Gto be static over time. Single-agent dynamical system is a special case where the graph
only has one node. In the following, we use the multi-agent setting by default to illustrate our
model. We denote X(t)âˆˆRNÃ—das the feature matrix at timestamp tfor all agents, with das
the feature dimension. Model input consists of trajectories of feature matrices over Mhistorical
timestamps X(tâˆ’M:âˆ’1) ={X(tâˆ’M), . . . ,X(tâˆ’1)}andG. The timestamps tâˆ’1,Â·Â·Â·, tâˆ’M<0can
have non-uniform intervals and take any continuous values. Our goal is to learn a neural simulator
fÎ¸(Â·) :
X(tâˆ’M:âˆ’1),G
â†’Y(t0:K), which predicts node dynamics Y(t)in the future on timestamps
0 =t0<Â·Â·Â·< tK=Tsampled within [0, T]. We use yi(t)to denote the targeted dynamic vector of
agent iat time t. In some cases when we are only predicting system feature trajectories, Y(Â·)â‰¡X(Â·).
2.1 NeuralODE for Dynamical Systems
NeuralODEs (Chen et al ., 2018; Rubanova et al ., 2019) are a family of continuous models that
define the evolution of dynamical systems by ordinary differential equations (ODEs). The state
evolution can be described as: Ë™zi(t) :=dzi(t)
dt=g(z1(t),z2(t)Â·Â·Â·zN(t)), where zi(t)âˆˆRd
denotes the latent state variable for agent iat timestamp t. The ODE function gis parameterized by a
neural network such as Multi-Layer Perception (MLP), which is automatically learned from data.
GraphODEs (Poli et al ., 2019; Huang et al ., 2020; Luo et al ., 2023b; Wen et al ., 2022; Huang et al .,
2024) are special cases of NeuralODEs, where gis a Graph Neural Network (GNN) to capture the
continuous interaction among agents.
GraphODEs have been shown to achieve superior performance, especially in long-range predictions
and can handle data irregularity issues. They usually follow the encoder-processor-decoder archi-
tecture, where an encoder first computes the latent initial states z1(t0),Â·Â·Â·zN(t0)for all agents
simultaneously based on their historical observations as in Eqn 1.
z1(t0),z2(t0), ...,zN(t0) =fENC 
X(tâˆ’M:âˆ’1),G) (1)
Then the GNN-based ODE predicts the latent trajectories starting from the learned initial states.
The latent state zi(t)can be computed at any desired time using a numerical solver such as Runge-
Kuttais (Schober et al., 2019) as:
zi(t) =ODE-Solver 
g,[z1(t0), ...zN(t0)], t
=zi(t0) +Zt
t0g(z1(t),z2(t)Â·Â·Â·zN(t))dt. (2)
Finally, a decoder extracts the predicted dynamics Ë†yi(t)based on the latent states zi(t)for any
timestamp t:
Ë†yi(t) =fDEC(zi(t)). (3)
3Following (Kipf et al ., 2018), we use â€œagentsâ€ to denote â€œobjectsâ€ in dynamical systems, which is different
from â€œintelligent agentâ€ in AI.
3However, vanilla GraphODEs can violate physical properties of a system, resulting in unrealistic
predictions. We therefore propose to inject physics-informed regularization term to make more
accurate predictions.
2.2 Time-Reversal Symmetry (TRS)
ğ³ğ¢ğŸğ°ğ(ğ­ğŠ)ğ³ğ¢ğŸğ°ğ(ğ­ğŸ)ğ³ğ¢ğŸğ°ğ(ğ­ğŸ)ğ³ğ¢ğŸğ°ğ(ğ­ğŠ(ğŸ)ğ’›ğ’Šğ«ğğ¯(ğ’•ğ‘².)â€¦â€¦LatentforwardtrajectoryLatentreversetrajectoryğ“ğ‘»ğ‘…ğ‘…ğ“ğ‘»ğ‘¹âˆ˜ğ“ğ‘»	âˆ˜ğ‘¹âˆ˜ğ“ğ‘»=ğ‘°ğ’›ğ’Šğ«ğğ¯(ğ’•ğ‘²(ğŸ.)ğ’›ğ’Šğ«ğğ¯(ğ’•ğŸ.)ğ’›ğ’Šğ«ğğ¯(ğ’•ğŸ.)â€¦â€¦
Figure 2: Illustration of time-reversal symmetry based on
Lemma 2.1.The total length of the trajectory is tKâˆ’t0=T.
tâ€²
kis the time index in the reverse trajectory, which points to
the same time as tKâˆ’kin the forward trajectory.Consider a dynamical system de-
scribed in the form ofdx(t)
dt=
F(x(t)), where x(t)âˆˆâ„¦is the ob-
served states such as positions. The
system is said to follow the Time-
Reversal Symmetry if there exists a
reversing operator R: â„¦7â†’â„¦such
that (Lamb and Roberts, 1998):
d 
Râ—¦x(t)
dt=âˆ’F 
Râ—¦x(t)
,(4)
where â—¦denote the action of func-
tional Ron the function x.
Intuitively, we can assume x(t)is the
position of a flying ball and the con-
ventional reversing operator is defined as R:x7â†’Râ—¦x, Râ—¦x(t) =x(âˆ’t). This implies when
x(t)is a forward trajectory position with initial position x(0),x(âˆ’t)is then a position in the time-
reversal trajectory, where x(âˆ’t)is calculated using the same function F, but with the integration
time reversed, i.e. dt7â†’d(âˆ’t). Eqn 4 shows how to create the reverse trajectory of a flying ball: at
each position, the velocity (i.e., the derivative of position with respect to time) should be the opposite.
In neural networks, we usually model trajectories in the latent space via z(Sanchez-Gonzalez et al .,
2020), which can be decoded back to real observation state i.e. positions. Therefore, we apply the
reversal operator for z.
Now we introduce a time evolution operator Ï•Ï„such that Ï•Ï„â—¦z(t) =z(t+Ï„)for arbitrary t, Ï„âˆˆR.
It satisfies Ï•Ï„1â—¦Ï•Ï„2=Ï•Ï„1+Ï„2, where â—¦denotes composition. The time evolution operator helps us
to move forward (when Ï„ >0) or backward (when Ï„ <0) through time, thus forming a trajectory.
Based on (Lamb and Roberts, 1998), in terms of the evolution operator, Eqn 4 implies:
Râ—¦Ï•t=Ï•âˆ’tâ—¦R=Ï•âˆ’1
tâ—¦R, (5)
which means that moving forward tsteps and then turning to the opposite direction is equivalent
to firstly turning to the opposite direction and then moving backwards tsteps4. Eqn 5 has been
widely used to describe time-reversal symmetry in existing literature (Huh et al ., 2020; Valperga
et al., 2022). Nevertheless, we propose the following lemma, which is more intuitive to understand
and straightforward to guide the design of our time-reversal regularizer.
Lemma 2.1. Eqn 5 is equivalent to Râ—¦Ï•tâ—¦Râ—¦Ï•t=I, where Idenotes identity mapping.
Lemma 2.1 means if we move tsteps forward, then turn to the opposite direction, and then move
forward for tmore steps, it shall restore back to the same state. This is illustrated in Figure 2 where
the reverse trajectory should be the same as the forward trajectory.5It can be understood as rewinding
a video to the very beginning. The proof of Lemma 2.1 is in Appendix A.2.
3 Method: TREAT
We present a novel framework TREAT that achieves high-precision modeling for a wide range of
systems from the numerical aspect, by enforcing Time-Reversal Symmetry (TRS) via a regularization
4Time-reversal symmetry is a property of physical systems, which requires the forward and reverse trajectories
to be generated by the same mechanism F(Â·). It differs from reversibility of neural networks (Chang et al ., 2018;
Liu et al ., 2019), which is a property of machine learning models and ensures the recovery of input from output
via a reversed operator fâˆ’1(Â·). We highlight the detailed discussions in Appendix F.
5We explain Figure 2 with implementation in Appendix A.1.
4ğ‘‚ğ·ğ¸ğ‘†ğ‘œğ‘™ğ‘£ğ‘’ğ‘”,(ğ‘§!(ğ‘¡")â€¦ğ‘§#(ğ‘¡"),(ğ‘¡"â€¦ğ‘¡$))
Time-ReversalSymmetry Constraintğ‘¡%&ğ‘¡%'ğ‘‚!ğ‘‚(ğ‘‚'ğ‘¡%(ğ‘¡%!Processor: LearnableODEfunction
Forward trajectory)ğ’šğ’ŠğŸğ°ğReversetrajectory )ğ’šğ’Šğ«ğğ¯Encoder
Inputğ‘¿,ğ“–Outputğ’€ğ‘‚!ğ‘‚"ğ‘‚#ğ‘¡"ğ‘¡$%!ğ‘¡$ğ‘‚!ğ‘‚'ğ‘¡!ğ‘‚(ğ‘§"(0)ğ‘§#(0)ğ‘§!(0)+ğ‘¦()*+ğ‘¡=ğ‘“,-.(ğ‘§()*+(ğ‘¡))Decoder
!ğ’šğ’ŠğŸğ°ğ(ğ’•ğ‘²)!ğ’šğ’Šğ«ğğ¯(ğ’•ğŸ*)ğ’›ğ’ŠğŸğ°ğ(ğ’•ğŸ)ğ’›ğ’ŠğŸğ°ğ(ğ’•ğ‘²+ğŸ)ğ’›ğ’ŠğŸğ°ğ(ğ’•ğ‘²)ğ’›ğ’ŠğŸğ’˜ğ’…(ğ’•ğŸ)ğ‘…ğ“ğ‘»ğ“ğ‘»!ğ’šğ’ŠğŸğ°ğ(ğ’•ğŸ)!ğ’šğ’Šğ«ğğ¯(ğ’•ğ‘²*)=4ğ¢1ğŸğ4ğ’Œ1ğŸğŠ55)ğ’šğ’ŠğŸğ°ğğ‘¡7âˆ’)ğ’šğ’Šğ«ğğ¯(ğ‘¡897:)ğŸğŸğ“›ğ«ğğ¯ğğ«ğ¬ğğ‘¹!ğ’šğ’ŠğŸğ°ğ(ğ’•ğŸ)!ğ’šğ’Šğ«ğğ¯(ğ­ğŠ+ğŸ*)Latentdynamics
!ğ’šğ’ŠğŸğ°ğ(ğ’•ğ‘²+ğŸ)!ğ’šğ’Šğ«ğğ¯(ğ­ğŸ*)1ğ‘¦!"#$ğ‘¡=ğ‘“%&'(ğ‘§!"#$(ğ‘¡))ğ‘§()*+(ğ‘¡=)=ğ‘“->.(ğ‘‹ğ‘¡9?:9A,ğ’¢)Figure 3: Overall framework of TREAT. O1, O2, O3are connected agents. It follows the encoder-
processor-decoder architecture introduced in Sec 2.1. A novel TRS loss is incorporated to improve
modeling accuracy across systems from the numerical aspect, regardless of their physical properties.
term. It improves modeling accuracy regardless of systemsâ€™ physical properties. We first introduce
our architecture design, followed by theoretical analysis to explain its numerical benefits.
TREAT uses GraphODE (Huang et al ., 2020) as the backbone and flexibly incorporates TRS as a
regularization term based on Lemma 2.1. This term aligns model forward and reverse trajectories. In
practice, our model predicts the forward trajectories at a series of timestamps {tk}K
k=0as ground truth
observations are discrete, where 0 =t0< t1<Â·Â·Â·< tK=T. The reverse trajectories are also at the
same series of Ktimestamps so as to be aligned with the forward one, which we denote as {tâ€²
k}K
k=0
satisfying 0 =tâ€²
0< tâ€²
1<Â·Â·Â·< tâ€²
K=T. Itâ€™s important to note that the values of the time variable
tâ€²
kin the reverse trajectories do not represent real time, but serve as indexes of reverse trajectories.
This leads to the relation tâ€²
Kâˆ’k=Tâˆ’tk, which means the reverse trajectories at timestamp tâ€²
Kâˆ’k
correspond to the forward trajectories at time tk. For example, tâ€²
0=Tâˆ’tK= 0. It indicates tâ€²
0and
tKare both pointing to the same real time T, which is the ending point of the forward trajectory as
shown in Figure 3. Based on Lemma 2.1, the difference of the two trajectories at any observed time
should be small, i.e. zfwd(tk)â‰ˆzrev(tâ€²
Kâˆ’k). This serves as the guideline for our regularizer design.
The weight of the regularizer is also adjustable to adapt different systems. The overall framework is
depicted in Figure 3.
3.1 Time-Reversal Symmetry Loss and Training
Forward Trajectory Prediction and Reconstruction Loss. For multi-agent systems, we utilize
the GNN operator described in (Kipf et al ., 2018) as our ODE function g(Â·), which drives the system
to move forward and output the forward trajectories for latent states zfwd
i(t)at each continuous time
tâˆˆ[0, T]and each agent i.We then employ a Multilayer Perceptron (MLP) as a decoder to predict
output trajectories Ë†yfwd
i(t)based on the latent states. We summarize the whole procedure as:
Ë™zfwd
i(t) :=dzfwd
i(t)
dt=g(zfwd
1(t),zfwd
2(t),Â·Â·Â·zfwd
N(t)),
zfwd
i(t0) =fENC(X(tâˆ’M:âˆ’1),G),Ë†yfwd
i(t) =fDEC(zfwd
i(t)).(6)
5To train the model, we use the reconstruction loss that minimizes the L2 distance between predicted
forward trajectories {Ë†yfwd
i(tk)}K
k=0and the ground truth trajectories {yi(tk)}K
k=0as :
Lpred=NX
i=1KX
k=0yi(tk)âˆ’Ë†yfwd
i(tk)2
2. (7)
Reverse Trajectory Prediction and Regularization Loss. We design a novel time-reversal symme-
try loss as a soft constraint to flexibly regulate systemsâ€™ behavior based on Lemma 2.1. Specifically,
we first compute the latent reverse trajectories zrev(t)by starting from the ending state of the forward
one, traversed back over time. We then employ the decoder to output dynamic trajectories yrev(t).
Ë™zrev
i(t) :=dzrev
i(t)
dt=âˆ’g(zrev
1(t),zrev
2(t),Â·Â·Â·zrev
N(t)),
zrev
i(tâ€²
0) =zfwd
i(tK),Ë†yrev
i(t) =fDEC(zrev
i(t)).(8)
Next, based on Lemma 2.1, if the system follows Time-Reversal Symmetry , the forward and backward
trajectories shall be exactly overlap. We thus design the reversal loss by minimizing the L2 distances
between model forward and backward trajectories decoded from the latent trajectories:
Lreverse =NX
i=1KX
k=0Ë†yfwd
i(tk)âˆ’Ë†yrev
i(tâ€²
Kâˆ’k)2
2. (9)
Finally, we jointly train TREAT as a weighted combination of the two losses:
L=Lpred+Î±Lreverse =NX
i=1KX
k=0yi(tk)âˆ’Ë†yfwd
i(tk)2
2+Î±NX
i=1KX
k=0Ë†yfwd
i(tk)âˆ’Ë†yrev
i(tâ€²
Kâˆ’k)2
2,
(10)
where Î±is a positive coefficient to balance the two losses based on different targeted systems.
Remark. The computational time of Lreverse is of the same scale as the reconstruction loss Lpred.
As the computation process of the reversal loss is to first use the ODE solver to generate the reverse
trajectories, which has the same computational overhead as computing the forward trajectories, and
then compute the L2 distances.
3.2 Theoretical Analysis of Time-Reversal Symmetry Loss
We next theoretically show that the time-reversal symmetry loss numerically helps to improve
prediction accuracy in general, regardless of systemsâ€™ physical properties. Specifically, we show that
it minimizes higher-order Taylor expansion terms during the ODE integration steps.
Theorem 3.1. Letâˆ†tdenote the integration step size in an ODE solver and Tbe the prediction
length. The reconstruction loss Lpred defined in Eqn 7 is O(T3âˆ†t2). The time-reversal loss Lreverse
defined in Eqn 9 is O(T5âˆ†t4).
We prove Theorem 3.1 in Appendix A.3. From Theorem 3.1, we can see two nice properties of
our proposed time-reversal loss: 1) Regarding the relationship to âˆ†t,Lreverse is optimizing a high-
order term âˆ†t4, which forces the model to predict fine-grained physical properties such as jerk (the
derivatives of accelerations). In comparison, the reconstruction loss optimizes âˆ†t2, which mainly
guides the model to predict the locations/velocities accurately. Therefore, the combined loss enables
our model to be more noise-tolerable; 2) Regarding the relationship to T,Lreverse is more sensitive
to total sequence length ( T5), thus it provides more regularization for long-context prediction, a key
challenge for dynamic modeling.
TRS Loss Design Choice. We define Lreverse as the distance between model forward trajectories
and backward trajectories. Based on the definition of TRS in Sec. 2.2, there are other implementation
choices. One prior work TRS-ODE (Huh et al ., 2020) designed a TRS loss based on Eqn 5, where
a reverse trajectory shares the same starting point as the forward one. However, we show that our
implementation based on Lemma 2.1 to approximate time-reversal symmetry has a lower maximum
error compared to their implementation below, supported by empirical experiments in Sec. 4.2.
6Lemma 3.2. LetLreverse be the TRS implementation of TREAT based on Lemma 2.1, Lreverse 2
be the one in (Huh et al ., 2020) based on Eqn 5. When the reconstruction loss defined in Eqn 7 of
both methods are equal, and the two TRS losses are equal, i.e. Lreverse =Lreverse 2, the maximum
error between the reversal and ground truth trajectory for each agent, i.e. MaxError gt_rev=
max kâˆˆ[K]âˆ¥yi(tk)âˆ’Ë†yrev
i(tâ€²
Kâˆ’k)âˆ¥2fori= 1,2Â·Â·Â·N, made by TREAT is smaller.
We prove Lemma 3.2 in Appendix A.4. Another implementation is to minimize the distances
between model backward trajectories and ground truth trajectories. When both forward and backward
trajectories are close to ground-truth, they are implicitly symmetric. The major drawback is that at
the early stage of learning when the forward is far away from ground truth ( Lpred), such implicit
regularization does not force time-reversal symmetry, but introduces more noise.
4 Experiments
Datasets. We conduct systematic evaluations over five multi-agent systems including three 5-body
spring systems (Kipf et al ., 2018), a complex chaotic pendulum system and a real-world motion
capture dataset (Carnegie Mellon University, 2003); and four single-agent systems including three
spring systems (with only one node) and a chaotic strange attractors system (Huh et al., 2020).
The settings of spring systems include: 1) conservative, i.e. no interactions with the environments,
we call it Simple Spring ; 2) non-conservative with frictions, we call it Damped Spring ; 3) non-
conservative with periodic external forces, we call it Forced Spring . The Pendulum system contains
three connected sticks in a 2D plane. It is highly sensitive to initial states, with minor disturbances
leading to significantly different trajectories (Shinbrot et al ., 1992; Awrejcewicz et al ., 2008). The real-
world motion capture dataset (Carnegie Mellon University, 2003) describes the walking trajectories
of a person, each tracking a single joint. We call it Human Motion . The strange attractor consists of
symmetric attractor/repellor force pairs and is chaotic (Sprott, 2015). It is also highly sensitive to the
initial states (Koppe et al., 2019). We call it Attractor .
Towards physical properties, Simple Spring andPendulum are conservative and reversible; Force
Spring andAttractor are reversible but non-conservative; Damped Spring are irreversible and non-
conservative. For Human Motion , it does not adhere to specific physical laws since it is a real-world
dataset. Details of the datasets and generation pipelines can be found inAppendix C.
Task Setup. We conduct evaluation by splitting trajectories into two halves: [t1, tM],[tM+1, tK]
where timestamps can be irregular. We condition the first half of observations to make predictions
for the second half as in (Rubanova et al ., 2019). For spring datasets and Pendulum , we generate
irregular-sampled trajectories and set the training samples to be 20,000 and testing samples to be
5,000 respectively. For Attractor , We generate 1,000 and 50 trajectories for training and testing
respectively following Huh et al .(2020). 10% of training samples are used as validation sets and the
maximum trajectory prediction length is 60. Details can be found in Appendix C.
Baselines. We compare TREAT against three baseline types: 1) pure data-driven approaches including
LG-ODE (Huang et al ., 2020) and LatentODE (Rubanova et al ., 2019), where the first one is a multi-
agent approach considering pair-wise interactions, and the second one is a single-agent approach that
predicts each trajectory independently; 2) energy-preserving HODEN (Greydanus et al., 2019); and
3) time-reversal TRS-ODEN (Huh et al., 2020).
The latter two are single-agent approaches and require initial states as given input. To handle missing
initial states in our dataset, we approximate the initial states for the two methods via linear spline
interpolation (Endre SÃ¼li, 2003). In addition, we substitute the ODE network in TRS-ODEN with
a GNN (Kipf et al ., 2018) as TRS-ODEN GNN, which serves as a new multi-agent approach for fair
comparison. HODEN cannot be easily extended to the multi-agent setting as replacing the ODE
function with a GNN can violate energy conservation of the original HODEN. For running LGODE
and TREAT on single-agent datasets, we only include self-loop edges in the graph G= (V,E), which
makes the ODE function ga simple MLP. Implementation details can be found in Appendix D.2.
7Table 1: Evaluation results on MSE ( 10âˆ’2). Best results are in bold numbers and second-best results
are in underline numbers. Human Motion is a real-world dataset and all others are simulated datasets.
Multi-Agent Systems Single-Agent Systems
DatasetSimple
SpringForced
SpringDamped
SpringPendulumHuman
MotionSimple
SpringForced
SpringDamped
SpringAttractor
LatentODE 5.2622 5.0277 3.3419 2.6894 2.9061 5.7957 0.4563 1.3012 0.58394
HODEN 3.0039 4.0668 8.7950 741.2296 1.9855 3.2119 4.004 1.5675 54.2912
TRS-ODEN 3.6785 4.4465 1.7595 741.4988 0.5400 3.0271 0.4056 1.5667 2.2683
TRS-ODEN GNN 1.4115 2.1102 0.5951 596.0319 0.2609 / / / /
LG-ODE 1.7429 1.8929 0.9718 1.4156 0.7610 1.6156 0.1465 1.1223 0.6942
TREAT 1.1178 1.4525 0.5944 1.2527 0.2192 1.6026 0.0960 1.0750 0.5581
(â€”-Ablation of our method with different implementation of Lreverse â€”-)
TREAT Lrev=gt-rev 1.1313 1.5254 0.6171 1.6158 0.2495 1.6190 0.1104 1.1205 0.6364
TREAT Lrev=rev2 1.6786 1.9786 0.9692 1.5631 0.8785 1.6901 0.0983 1.0952 0.7286
4.1 Main Results
Table 1 shows the prediction performance on both multi-agent systems and single-agent systems
measured by mean squared error (MSE). We can see that TREAT consistently surpasses other models,
highlighting its generalizability and the efficacy of the proposed TRS loss.
For multi-agent systems, approaches that consider interactions among agents (LG-ODE, TRS-
ODEN GNN, TREAT) consistently outperform single-agent baselines (LatentODE, HODEN, TRS-
ODEN), and TREAT achieves the best performance across datasets.
The chaotic nature of the Pendulum system and the Attractor system, with their sensitivity to initial
states6, poses extreme challenges for dynamic modeling. This leads to highly unstable predictions
for models like HODEN and TRS-ODEN, as they estimate initial states via inaccurate linear spline
interpolation (Endre SÃ¼li, 2003). In contrast, LatentODE, LG-ODE, and TREAT employ advanced
encoders that infer latent states from observed data and demonstrate superior accuracy. Among them,
TREAT achieves the most accurate predictions, further showing its robust generalization capabilities.
We observe that misapplied inductive biases can degrade results, which limits the usage of physics-
informed methods that are designed for individual physical prior such as HODEN. HODEN only
excels on energy-conservative systems, such as Simple Spring compared with LatentODE and TRS-
ODEN in the multi-agent setting. Its performance drop dramatically on Force Spring ,Damped Spring ,
andAttractor . Note that HODEN naively forces each agent to be energy-conservative, instead of the
whole system. Therefore, it performs poorly than LG-ODE, TREAT in the multi-agent settings.
For the Human Motion dataset, characterized by its dynamic ambiguity as it does not adhere to specific
physical laws, we cannot directly determine whether it is conservative or time-reversal. For such a
system with an unknown nature, TREAT outperforms other purely data-driven methods significantly,
showcasing its strong numerical benefits in improving prediction accuracy across diverse system
types. This is also shown by its superior performance on Damped Spring , which is irreversible.
(a)Simple Spring(b)Damped Spring(c)Forced Spring(d)Pendulum
LG-ODETREATTRS-ODENHODENLG-ODETREATTRS-ODENHODENLG-ODETREATTRS-ODENHODENLG-ODETREATTRS-ODENHODEN
Figure 4: Varying prediction lengths across multi-agent datasets (Pendulum MSE is in log values).
6Video to show Pendulum is highly sensitive to initial states.
8(a)Simple Spring(b)Damped Spring(c)Forced Spring(d)PendulumTREATLG-ODETREATLG-ODETREATLG-ODETREATLG-ODEFigure 5: Varying Î±values across multi-agent datasets.
4.2 Ablation and Sensitivity Analysis
Ablation on implementation of Lreverse .We conduct two ablation by changing the implementation
ofLreverse discussed in Sec. 3.2: 1) TREAT Lrev=gt-rev , which computes the reversal loss as the L2
distance between ground truth trajectories to model backward trajectories; 2) TREAT Lrev=rev2, which
implements the TRS loss based on Eqn 5 as in TRS-ODEN (Huh et al ., 2020). From the last block of
Table 1, we can clearly see that our implementation achieves the best performance against the two.
Evaluation across prediction lengths. We vary the maximum prediction lengths from 20 to 60
and report model performance as shown in Figure 4. As the prediction step increases, TREAT
consistently maintains optimal prediction performance, while other baselines exhibit significant error
accumulations. The performance gap between TREAT and baselines widens when making long-range
predictions, highlighting the superior predictive capability of TREAT.
Evaluation across different Î±.We vary the values of the coefficient Î±defined in Eqn 10, which
balances the reconstruction loss and the TRS loss. Figure 5 demonstrates that the optimal Î±values
being neither too high nor too low. This is because when Î±is too small, the model tends to neglect
the TRS physical bias, resulting in error accumulations. Conversely, when Î±becomes too large, the
model can emphasize TRS at the cost of accuracy. Nonetheless, across different Î±values, TREAT
consistently surpasses the purely data-driven LG-ODE, showcasing its superiority and flexibility in
modeling diverse dynamical systems.
We study TREATâ€™s sensitivity towards solver choice and observation ratios in Appendix E.1 and
Appendix E.2 respectively.
LG-ODETREATHODENLG-ODETREATHODENLG-ODETREATHODENGroundTruthTANGOLG-ODEEnergyHODEN(a)SimpleSpring(b)DampedSpring(c)ForcedSpringTREAT
LG-ODETREATHODENLG-ODETREATHODENLG-ODETREATHODEN
Figure 6: Visualization for 5-body spring systems (trajectory starts from light to dark colors).
9(a)Simple Spring(b)Damped Spring(c)Forced Spring(d)PendulumÃ—1#!"#Ã—1#!"#Ã—1#!"#Ã—1#!"$TREATLG-ODETREATLG-ODETREATLG-ODETREATLG-ODETREATReversalLoss
TREATReversalLoss
TREATReversalLoss
TREATReversalLossLG-ODEReversalLoss
LG-ODEReversalLoss
LG-ODEReversalLoss
LG-ODEReversalLossFigure 7: TRS loss visualization across multi-agent datasets (scales of two y-axes are different).
4.3 Visualizations
Trajectory Visualizations. Model predictions and ground truth are visualized in Figure 6. As
HODEN is a single-agent baseline that individually forces every agentâ€™s energy to be constant over
time which is not valid, the predicted trajectories is having the largest errors and systemsâ€™ total energy
is not conserved for all datasets. The purely data-driven LG-ODE exhibits unrealistic energy patterns,
as seen in the energy spikes in Simple Spring andForce Spring . In contrast, TREAT, incorporating
reversal loss, generates realistic energy trends, and consistently produces trajectories closest to the
ground truth, showing its superior performance.
Reversal Loss Visualizations To illustrate the issue of energy explosion from the purely data-driven
LG-ODE, we visualize the TRS loss over training epochs from LG-ODE7and TREAT in Figure 7.
As results suggest, LG-ODE has increased TRS loss over training epochs, meaning it is violating the
time-reversal symmetry sharply, in contrast to TREAT which has decreased reversal loss over epochs.
5 Conclusions
We propose TREAT, a deep learningframework that achieves high-precision modeling for a wide
range of dynamical systems by injecting time-reversal symmetry as an inductive bias. TREAT
features a novel regularization term to softly enforce time-reversal symmetry by aligning predicted
forward and reverse trajectories from a GraphODE model. Notably, we theoretically prove that
the regularization term effectively minimizes higher-order Taylor expansion terms during the ODE
integration, which serves as a general numerical benefit widely applicable to various systems (even
irreversible systems) regardless of their physical properties. Empirical evaluations on different kinds
of datasets illustrate TREATâ€™s superior efficacy in accurately capturing real-world system dynamics.
6 Limitations
Currently, TREAT only incorporates inductive bias from the temporal aspect, while there are many
important properties in the spatial aspect such as translation and rotation equivariance (Satorras et al .,
2021; Han et al., 2022b; Xu et al., 2022). Future endeavors that combine biases from both temporal
and spatial dimensions could unveil a new frontier in dynamical systems modeling.
7 Acknowledgement
This work was partially supported by NSF 2200274, NSF 2106859, NSF 2312501, NSF 2211557, NSF
1937599, NSF 2119643, NSF 2303037, NSF 2312501, DARPA HR00112290103/HR0011260656,
HR00112490370, NIH U54HG012517, NIH U24DK097771, NASA, SRC JUMP 2.0 Center, Amazon
Research Awards, and Snapchat Gifts.
References
J. Awrejcewicz, G. Kudra, and G. Wasilewski. 2008. Chaotic zones in triple pendulum dynamics
observed experimentally and numerically. Applied Mechanics and Materials (2008), 1â€“17.
7There is no reversal loss backpropagation in LG-ODE, we just compute its value along training.
10Y . Cao, M. Chai, M. Li, and C. Jiang. 2023. Efficient learning of mesh-based physical simulation
with bi-stride multi-scale graph neural network. In International Conference on Machine Learning .
PMLR, 3541â€“3558.
Y . Cao, X. Gao, and R. Li. 2019. A liquid plug moving in an annular pipeâ€“Heat transfer analysis.
International Journal of Heat and Mass Transfer 139 (2019), 1065â€“1076.
Y . Cao and R. Li. 2018. A liquid plug moving in an annular pipeâ€”Flow analysis. Physics of Fluids
30, 9 (2018).
Carnegie Mellon University. 2003. Carnegie-Mellon Motion Capture Database. http://mocap.
cs.cmu.edu Online database.
B. Chang, L. Meng, E. Haber, L. Ruthotto, D. Begert, and E. Holtham. 2018. Reversible architectures
for arbitrarily deep residual neural networks. In Proceedings of the AAAI conference on artificial
intelligence , V ol. 32.
R. T. Q. Chen, B. Amos, and M. Nickel. 2021. Learning Neural Event Functions for Ordinary
Differential Equations. International Conference on Learning Representations (2021).
T. Q. Chen, Y . Rubanova, J. Bettencourt, and D. Duvenaud. 2018. Neural Ordinary Differential
Equations. In Advances in Neural Information Processing Systems .
M. Cranmer, S. Greydanus, S. Hoyer, P. Battaglia, D. Spergel, and S. Ho. 2020. Lagrangian neural
networks. arXiv preprint arXiv:2003.04630 (2020).
D. F. M. Endre SÃ¼li. 2003. An Introduction to Numerical Analysis . Cambridge University Press. 293
pages.
S. Greydanus, M. Dzamba, and J. Yosinski. 2019. Hamiltonian neural networks. Advances in Neural
Information Processing Systems (2019).
Anthony Gruber, Kookjin Lee, and Nathaniel Trask. 2024. Reversible and irreversible bracket-based
dynamics for deep graph neural networks. Advances in Neural Information Processing Systems 36
(2024).
Jiaqi Han, Wenbing Huang, Hengbo Ma, Jiachen Li, Joshua B. Tenenbaum, and Chuang Gan. 2022a.
Learning Physical Dynamics with Subequivariant Graph Neural Networks. In Advances in Neural
Information Processing Systems , Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun
Cho (Eds.). https://openreview.net/forum?id=siG_S8mUWxf
Jiaqi Han, Wenbing Huang, Tingyang Xu, and Yu Rong. 2022b. Equivariant graph hierarchy-based
neural networks. Advances in Neural Information Processing Systems 35 (2022), 9176â€“9187.
Z. Hu, Y . Dong, K. Wang, and Y . Sun. 2020. Heterogeneous Graph Transformer. In Proceedings of
the 2020 World Wide Web Conference .
Zijie Huang, Jeehyun Hwang, Junkai Zhang, Jinwoo Baik, Weitong Zhang, Dominik Wodarz, Yizhou
Sun, Quanquan Gu, and Wei Wang. 2024. Causal Graph ODE: Continuous Treatment Effect
Modeling in Multi-agent Dynamical Systems. In Proceedings of the ACM Web Conference 2024
(Singapore, Singapore) (WWW â€™24) . 4607â€“4617.
Z. Huang, Y . Sun, and W. Wang. 2020. Learning Continuous System Dynamics from Irregularly-
Sampled Partial Observations. In Advances in Neural Information Processing Systems .
Z. Huang, Y . Sun, and W. Wang. 2021. Coupled Graph ODE for Learning Interacting System
Dynamics. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining .
Z. Huang, Y . Sun, and W. Wang. 2023. Generalizing Graph ODE for Learning Complex System Dy-
namics across Environments. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD â€™23) . 798â€“809.
I. Huh, E. Yang, S. J. Hwang, and J. Shin. 2020. Time-Reversal Symmetric ODE Network. In
Advances in Neural Information Processing Systems .
11S. Jiang, Z. Huang, X. Luo, and Y . Sun. 2023. CF-GODE: Continuous-Time Causal Inference
for Multi-Agent Dynamical Systems. In Proceedings of the 29th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining .
S. Kim and S. J. Karrila. 2013. Microhydrodynamics: principles and selected applications . Courier
Corporation.
T. Kipf, E. Fetaya, K. Wang, M. Welling, and R. Zemel. 2018. Neural Relational Inference for
Interacting Systems. arXiv preprint arXiv:1802.04687 (2018).
G. Koppe, H. Toutounji, P. Kirsch, S. Lis, and D. Durstewitz. 2019. Identifying nonlinear dynamical
systems via generative recurrent neural networks with applications to fMRI. PLoS computational
biology 15, 8 (2019), e1007263.
R. Lam, A. Sanchez-Gonzalez, M. Willson, P. Wirnsberger, M. Fortunato, F. Alet, S. Ravuri, T.
Ewalds, Z. Eaton-Rosen, W. Hu, A. Merose, S. Hoyer, G. Holland, O. Vinyals, J. Stott, A. Pritzel,
S. Mohamed, and P. Battaglia. 2023. Learning skillful medium-range global weather forecasting.
Science 382, 6677 (2023), 1416â€“1421.
J. S. Lamb and J. A. Roberts. 1998. Time-reversal symmetry in dynamical systems: a survey. Physica
D: Nonlinear Phenomena (1998), 1â€“39.
C. Li, F. Xia, R. MartÃ­n-MartÃ­n, M. Lingelbach, S. Srivastava, B. Shen, K. E. Vainio, C. Gokmen, G.
Dharan, T. Jain, A. Kurenkov, K. Liu, H. Gweon, J. Wu, L. Fei-Fei, and S. Savarese. 2022. iGibson
2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks. In Proceedings
of the 5th Conference on Robot Learning .
J. Liu, A. Kumar, J. Ba, J. Kiros, and K. Swersky. 2019. Graph normalizing flows. Advances in
Neural Information Processing Systems 32 (2019).
I. Loshchilov and F. Hutter. 2019. Decoupled weight decay regularization. In The International
Conference on Learning Representations .
Y . Lu, S. Lin, G. Chen, and J. Pan. 2022. ModLaNets: Learning Generalisable Dynamics via
Modularity and Physical Inductive Bias. In Proceedings of the 39th International Conference on
Machine Learning (Proceedings of Machine Learning Research, Vol. 162) , Kamalika Chaudhuri,
Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.). PMLR, 14384â€“
14397.
Xiao Luo, Yiyang Gu, Huiyu Jiang, Hang Zhou, Jinsheng Huang, Wei Ju, Zhiping Xiao, Ming Zhang,
and Yizhou Sun. 2024. PGODE: Towards High-quality System Dynamics Modeling. In Forty-first
International Conference on Machine Learning .
Xiao Luo, Haixin Wang, Zijie Huang, Huiyu Jiang, Abhijeet Sadashiv Gangan, Song Jiang, and
Yizhou Sun. 2023a. CARE: Modeling Interacting Dynamics Under Temporal Environmental
Variation. In Thirty-seventh Conference on Neural Information Processing Systems .https:
//openreview.net/forum?id=lwg3ohkFRv
X. Luo, J. Yuan, Z. Huang, H. Jiang, Y . Qin, W. Ju, M. Zhang, and Y . Sun. 2023b. HOPE: High-
order Graph ODE For Modeling Interacting Dynamics. In Proceedings of the 40th International
Conference on Machine Learning .
Xiao Luo, Jingyang Yuan, Zijie Huang, Huiyu Jiang, Yifang Qin, Wei Ju, Ming Zhang, and Yizhou
Sun. 2023c. Hope: High-order graph ode for modeling interacting dynamics. In International
Conference on Machine Learning . PMLR, 23124â€“23139.
Karolis Martinkus, Aurelien Lucchi, and NathanaÃ«l Perraudin. 2021. Scalable graph networks for
particle simulations. In Proceedings of the AAAI Conference on Artificial Intelligence , V ol. 35.
8912â€“8920.
R. Ni and A. H. Qureshi. 2022. Ntfields: Neural time fields for physics-informed robot motion
planning. arXiv preprint arXiv:2210.00120 (2022).
12J. North. 2021. Formulations of classical mechanics. Forthcoming in A companion to the philosophy
of physics. Routledge (2021).
T. Pfaff, M. Fortunato, A. Sanchez-Gonzalez, and P. Battaglia. 2021. Learning Mesh-Based Simula-
tion with Graph Networks. In International Conference on Learning Representations .
Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, and Peter W Battaglia. 2020. Learning
mesh-based simulation with graph networks. arXiv preprint arXiv:2010.03409 (2020).
M. Poli, S. Massaroli, J. Park, A. Yamashita, H. Asama, and J. Park. 2019. Graph neural ordinary
differential equations. arXiv preprint arXiv:1911.07532 (2019).
C. Pozrikidis. 2001. Interfacial dynamics for Stokes flow. J. Comput. Phys. 169, 2 (2001), 250â€“301.
M. Raissi, P. Perdikaris, and G. E. Karniadakis. 2019. Physics-informed neural networks: A
deep learning framework for solving forward and inverse problems involving nonlinear partial
differential equations. Journal of Computational physics 378 (2019), 686â€“707.
Y . Rubanova, R. T. Chen, and D. K. Duvenaud. 2019. Latent ordinary differential equations for
irregularly-sampled time series. In Advances in Neural Information Processing Systems .
A. Sanchez-Gonzalez, V . Bapst, K. Cranmer, and P. Battaglia. 2019. Hamiltonian Graph Networks
with ODE Integrators. In Advances in Neural Information Processing Systems .
A. Sanchez-Gonzalez, J. Godwin, T. Pfaff, R. Ying, J. Leskovec, and P. W. Battaglia. 2020. Learning
to Simulate Complex Physics with Graph Networks. In Proceedings of the 37th International
Conference on Machine Learning .
V . G. Satorras, E. Hoogeboom, and M. Welling. 2021. E (n) equivariant graph neural networks. In
International conference on machine learning . PMLR, 9323â€“9332.
M. Schober, S. SÃ¤rkkÃ¤, and P. Hennig. 2019. A probabilistic model for the numerical solution of
initial value problems. In Statistics and Computing . 99â€“122.
H. Sepp and S. JÃ¼rgen. 1997. Long Short-term Memory. Neural computation (1997).
T. Shinbrot, C. Grebogi, J. Wisdom, and J. A. Yorke. 1992. Chaos in a double pendulum. American
Journal of Physics 6 (1992), 491â€“499.
J. C. Sprott. 2015. Symmetric time-reversible flows with a strange attractor. International Journal of
Bifurcation and Chaos 25, 05 (2015), 1550078.
T. Stachowiak and T. Okada. 2006. A numerical analysis of chaos in the double pendulum. Chaos,
Solitons & Fractals 2 (2006), 417â€“422.
E. C. Tolman. 1938. The Determiners of Behavior at a Choice Point. Psychological Review 45, 1
(1938), 1â€“41.
R. Valperga, K. Webster, D. Turaev, V . Klein, and J. Lamb. 2022. Learning Reversible Symplectic
Dynamics. In Proceedings of The 4th Annual Learning for Dynamics and Control Conference .
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ë™ U. Kaiser, and I. Polosukhin.
2017. Attention is All you Need. In Advances in Neural Information Processing Systems .
Haixin Wang, Yadi Cao, Zijie Huang, Yuxuan Liu, Peiyan Hu, Xiao Luo, Zezheng Song, Wanjia
Zhao, Jilin Liu, Jinan Sun, et al .2024. Recent Advances on Machine Learning for Computational
Fluid Dynamics: A Survey. arXiv preprint arXiv:2408.12171 (2024).
R. Wang, K. Kashinath, M. Mustafa, A. Albert, and R. Yu. 2020. Towards physics-informed deep
learning for turbulent flow prediction. In Proceedings of the 26th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining .
S. Wen, H. Wang, and D. Metaxas. 2022. Social ODE: Multi-agent Trajectory Forecasting with
Neural Ordinary Differential Equations. In European Conference on Computer Vision .
13Minkai Xu, Jiaqi Han, Aaron Lou, Jean Kossaifi, Arvind Ramanathan, Kamyar Azizzadenesheli, Jure
Leskovec, Stefano Ermon, and Anima Anandkumar. 2024. Equivariant Graph Neural Operator for
Modeling 3D Dynamics. In Forty-first International Conference on Machine Learning .https:
//openreview.net/forum?id=dccRCYmL5x
Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, and Jian Tang. 2022. Geodiff: A ge-
ometric diffusion model for molecular conformation generation. arXiv preprint arXiv:2203.02923
(2022).
C. Zang and F. Wang. 2020. Neural dynamics on complex networks. In Proceedings of the 26th ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining .
Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. 2020. Dissipative symoden:
Encoding hamiltonian dynamics with dissipation and control into deep learning. arXiv preprint
arXiv:2002.08860 (2020).
14A Theoretical Analysis
A.1 Implementation of the Time-Reversal Symmetry Loss
Algorithm 1 The implementation of Lreverse
Require: latent initial states zfwd
i(t0); the ODE function g(Â·); number of agents N:
1:foreachiâˆˆNdo
2: Compute the latent forward trajectory at timestamps {tk}K
k=0:
zfwd
i(tk) =ODE-Solver 
g,[zfwd
1(t0),zfwd
2(t0)...zfwd
N(t0)], tk
. Reach the final state zfwd
i(tK).
3: The initial state of the reverse trajectory is defined as zrev
i(tâ€²
0) =zfwd
i(tK), and the dynamics
of the system which is the ODE function g(Â·)is also reversed as âˆ’g(Â·).
4: Compute the latent reverse trajectory at timestamps {tâ€²
k}K
k=0,
zrev
i(tâ€²
k) =ODE-Solver 
g,[zrev
1(tâ€²
0),zrev
2(tâ€²
0)...zrev
N(tâ€²
0)], tâ€²
k
.
5:Ë†yfwd
i(tk) =fDEC(zfwd
i(tk)),Ë†yrev
i(tâ€²
k) =fDEC(zrev
i(tâ€²
k))
6:end for
7:Lreverse =PN
i=1PK
k=0Ë†yfwd
i(tk)âˆ’Ë†yrev
i(tâ€²
Kâˆ’k)2
2
A.2 Proof of Lemma 1
Proof. The definition of time-reversal symmetry is given by:
Râ—¦Ï•t=Ï•âˆ’tâ—¦R=Ï•âˆ’1
tâ—¦R (11)
Here, Ris an involution operator, which means Râ—¦R=I.
First, we apply the time evolution operator Ï•tto both sides of Eqn 11:
Ï•tâ—¦Râ—¦Ï•t=Ï•tâ—¦Ï•âˆ’1
tâ—¦R (12)
Simplifying, we obtain:
Ï•tâ—¦Râ—¦Ï•t=R (13)
Next, we apply the involution operator Rto both sides of the equation:
Râ—¦Ï•tâ—¦Râ—¦Ï•t=Râ—¦R (14)
Since Râ—¦R=I, we finally arrive at:
Râ—¦Ï•tâ—¦Râ—¦Ï•t=I (15)
which means the trajectories can overlap when evolving backward from the final state.
A.3 Proof of Theorem 3.1
Letâˆ†tdenote the integration step size in an ODE solver and Tbe the prediction length. The time
stamps of the ODE solver are {tj}T
j=0, where tj+1âˆ’tj= âˆ†tforj= 0,Â·Â·Â·, T(T > 1). Next
suppose during the forward evolution, the updates go through states zfwd(tj) = (qfwd(tj),pfwd(tj))
forj= 0,Â·Â·Â·, T, where qfwd(tj)is position, pfwd(tj)is momentum, while during the reverse
evolution they go through states zrev(tj) = (qrev(tj),prev(tj))forj= 0,Â·Â·Â·, T, in reverse order.
The ground truth trajectory is zgt(tj) = (qgt(tj),pgt(tj))forj= 0,Â·Â·Â·, T.
For the sake of brevity in the ensuing proof, we denote zgt(tj)byzgt
j,zfwd(tj)byzfwd
jandzrev(tj)
byzrev
j, and we will use Mathematical Induction to prove the theorem.
A.3.1 Reconstruction Loss ( Lpred) Analysis.
First, we bound the forward lossPT
j=0âˆ¥zfwd
jâˆ’zgt
jâˆ¥2
2. Since our method models the momentum and
position of the system, we can write the following Taylor expansion of the forward process, where
15for any 0â‰¤j < T :
ï£±
ï£´ï£²
ï£´ï£³qfwd
j+1=qfwd
j+ (pfwd
j/m)âˆ†t+ (Ë™pfwd
j/2m)âˆ†t2+O(âˆ†t3), (16a)
pfwd
j+1=pfwd
j+Ë™pfwd
jâˆ†t+O(âˆ†t2), (16b)
Ë™pfwd
j+1=Ë™pfwd
j+O(âˆ†t), (16c)
and for the ground truth process, we also have from Taylor expansion that
ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³qgt
j+1=qgt
j+ (pgt
j/m)âˆ†t+ (Ë™pgt
j/2m)âˆ†t2+O(âˆ†t3), (17a)
pgt
j+1=pgt
j+Ë™pgt
jâˆ†t+O(âˆ†t2), (17b)
Ë™pgt
j+1=Ë™pgt
j+O(âˆ†t). (17c)
With these, we aim to prove that for any k= 0,1,Â·Â·Â·, T, the following hold :
(
âˆ¥qfwd
kâˆ’qgt
kâˆ¥2â‰¤Cfwd
2k2âˆ†t2, (18a)
âˆ¥pfwd
kâˆ’pgt
kâˆ¥2â‰¤Cfwd
1kâˆ†t, (18b)
where Cfwd
1andCfwd
2are constants.
Base Case k= 0:Based on the initialization rules, it is obvious thatqfwd
0âˆ’qgt
0
2= 0 andpfwd
0âˆ’pgt
0
2= 0, thus (18a) and (18b) both hold for k= 0.
Inductive Hypothesis: Assume (18a) and (18b) hold for k=j, which means:
(
âˆ¥qfwd
jâˆ’qgt
jâˆ¥2â‰¤Cfwd
2j2âˆ†t2, (19a)
âˆ¥pfwd
jâˆ’pgt
jâˆ¥2â‰¤Cfwd
1jâˆ†t, (19b)
Inductive Proof: We need to prove (18a) and (18b) hold for k=j+ 1.
First, using (16c) and (17c), we have
Ë™pfwd
j+1âˆ’Ë™pgt
j+1
2=Ë™pfwd
jâˆ’Ë™pgt
j
2+O(âˆ†t) =Ë™pfwd
0âˆ’Ë™pgt
0
2+O 
(j+ 1)âˆ† t
=O(1),(20)
where we iterate through j, jâˆ’1,Â·Â·Â·,0in the second equality. Then using (17b) and (16b), we get
forj+ 1that
pfwd
j+1âˆ’pgt
j+1
2= 
pfwd
j+Ë™pfwd
jâˆ†t
âˆ’ 
pgt
j+Ë™pgt
jâˆ†t
+O(âˆ†t2)âˆ¥2
â‰¤pfwd
jâˆ’pgt
j
2+Ë™pfwd
jâˆ’Ë™pgt
j
2âˆ†t+O(âˆ†t2)
â‰¤
Cfwd
1j+O(1)
âˆ†t,
where the first inequality uses the triangle inequality, and in the second inequality we use (19b) as
well as (20). We can see there exists Cfwd
1such that the final expression above is upper bounded by
Cfwd
1(j+ 1)âˆ† t, with which the claim holds for j+ 1.
Next for (18a), using (17a) and (16a), we get for any jthat
qfwd
j+1âˆ’qgt
j+1
2= 
qfwd
j+ (pfwd
j/m)âˆ†t+ (Ë™pfwd
j/2m)âˆ†t2)âˆ’ 
qgt
j+ (pgt
j/m)âˆ†t+ (Ë™pgt
j/2m)âˆ†t2
+O(âˆ†t3)âˆ¥2
â‰¤qfwd
jâˆ’qgt
j
2+1
mpfwd
jâˆ’pgt
j
2âˆ†t+1
2mË™pfwd
jâˆ’Ë™pgt
j
2âˆ†t2+O(âˆ†t3)
â‰¤
Cfwd
2j2+Cfwd
1
mj+O(1)
âˆ†t2,
where the first inequality uses the triangle inequality, and in the second inequality we use (19a) and
(19b) as well as (20). Thus with an appropriate Cfwd
2, we have the final expression above is upper
bounded by Cfwd
2(j+ 1)2âˆ†t2, and so the claim holds for j+ 1.
Since both the base case and the inductive step have been proven, by the principle of mathematical
induction, (18a) and (18b) holds for all k= 0,1,Â·Â·Â·, T.
16With this, we finish the forward proof by plugging (18a) and (18b) into the loss function:
TX
j=0âˆ¥zfwd
jâˆ’zgt
jâˆ¥2
2=TX
j=0âˆ¥pfwd
jâˆ’pgt
jâˆ¥2
2+TX
j=0âˆ¥qfwd
jâˆ’qgt
jâˆ¥2
2
â‰¤ 
Cfwd
12TX
j=0j2âˆ†t2+ 
Cfwd
22TX
j=0j4âˆ†t4
=O(T3âˆ†t2).
A.3.2 Reversal Loss ( Lreverse ) Analysis.
Next we analyze the reversal lossPT
j=0âˆ¥R(zrev
j)âˆ’zfwd
jâˆ¥2
2. For this, we need to refine the Taylor
expansion residual terms for a more in-depth analysis.
First reconsider the forward process. Since the process is generated from the learned network, we
may assume that for some constants c1,c2, andc3, the states satisfy the following for any 0â‰¤j < T :
ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³qfwd
j=qfwd
j+1âˆ’(pfwd
j+1/m)âˆ†t+ (Ë™pfwd
j+1/2m)âˆ†t2+remfwd,3
j, (21a)
pfwd
j=pfwd
j+1âˆ’Ë™pfwd
j+1âˆ†t+remfwd,2
j, (21b)
Ë™pfwd
j=Ë™pfwd
j+1+remfwd,1
j, (21c)
where the remaining termsremfwd,i
j
2â‰¤ciâˆ†tifori= 1,2,3. Similarly, we have approximate
Taylor expansions for the reverse process:ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³qrev
j=qrev
j+1+ (prev
j+1/m)âˆ†t+ (Ë™prev
j+1/2m)âˆ†t2+remrev,3
j, (22a)
prev
j=prev
j+1+Ë™prev
j+1âˆ†t+remrev,2
j, (22b)
Ë™prev
j=Ë™prev
j+1+remrev,1
j, (22c)
whereremrev,i
j
2â‰¤ciâˆ†tifori= 1,2,3.
We will prove via induction that for k=T, Tâˆ’1,Â·Â·Â·,0,ï£±
ï£´ï£²
ï£´ï£³âˆ¥R(qrev
k)âˆ’qfwd
kâˆ¥2â‰¤Crev
3(Tâˆ’k)3âˆ†t3, (23a)
âˆ¥R(prev
k)âˆ’pfwd
kâˆ¥2â‰¤Crev
2(Tâˆ’k)2âˆ†t2, (23b)
âˆ¥R(Ë™prev
k)âˆ’Ë™pfwd
kâˆ¥2â‰¤Crev
1(Tâˆ’k)âˆ†t, (23c)
where Crev
1,Crev
2andCrev
3are constants.
The entire proof process is analogous to the previous analysis of Reconstruction Loss.
Base Case k=T:Since the reverse process is initialized by the forward process variables at k=T,
it is obvious thatqfwd
Tâˆ’qev
T
2=pfwd
Tâˆ’prev
T
2=Ë™pfwd
Tâˆ’Ë™prev
T
2= 0. Thus (23a), (23b) and
(23c) all hold for k= 0.
Inductive Hypothesis: Assume the inequalities (23b), (23a) and (23c) hold for k=j+ 1, which
means:ï£±
ï£´ï£²
ï£´ï£³âˆ¥R(qrev
j+1)âˆ’qfwd
j+1âˆ¥2â‰¤Crev
3(Tâˆ’(j+ 1))3âˆ†t3, (24a)
âˆ¥R(prev
j+1)âˆ’pfwd
j+1âˆ¥2â‰¤Crev
2(Tâˆ’(j+ 1))2âˆ†t2, (24b)
âˆ¥R(Ë™prev
j+1)âˆ’Ë™pfwd
j+1âˆ¥2â‰¤Crev
1(Tâˆ’(j+ 1))âˆ† t, (24c)
Inductive Proof : We need to prove (23b) (23a) and (23c) holds for k=j.
First, for (23c), using (21c) and (22c), we get for any jthatR(Ë™prev
j)âˆ’Ë™pfwd
j
2
=(Ë™prev
j+1+remrev,1
j)âˆ’(Ë™pfwd
j+1+remfwd,1
j)
2
â‰¤R(Ë™prev
j+1)âˆ’Ë™pfwd
j+1
2+âˆ¥remrev,1
jâˆ¥2+âˆ¥remfwd,1
jâˆ¥2
â‰¤Crev
1(Tâˆ’jâˆ’1)âˆ†t+ 2c1âˆ†t,
17where the first inequality uses the triangle inequality, and the second inequality plugs in (24c). Thus
taking Crev
1= 2c1, the above is upped bounded by Crev
1(Tâˆ’j)âˆ†t, and (23b) holds for j.
Second, for (24b), using (21b) and (22b), we get
R(prev
j)âˆ’pfwd
j
2=âˆ’ 
prev
j+1+Ë™prev
j+1âˆ†t+remrev,2
j
âˆ’ 
pfwd
j+1âˆ’Ë™pfwd
j+1âˆ†t+remfwd,2
j
âˆ¥2
â‰¤R(prev
j+1)âˆ’pfwd
j+1
2+R(Ë™prev
j+1)âˆ’Ë™pfwd
j+1
2âˆ†t+âˆ¥remrev,2
jâˆ¥2+âˆ¥remfwd,2
jâˆ¥2
â‰¤
Crev
2(Tâˆ’jâˆ’1)2+Crev
1(Tâˆ’jâˆ’1) + 2 c2
âˆ†t2,
where the first inequality uses the triangle inequality, and in the second inequality we use (24a) and
(24b). Thus taking Crev
2= max {Crev
1/2,2c2}, we have the final expression above is upper bounded
byCrev
2(Tâˆ’j)2âˆ†t2, and so the claim holds for j.
Finally, for (24a), we use (21a) and (22a) to get
R(qrev
j)âˆ’qfwd
j
2
= 
qrev
j+1+ (prev
j+1/m)âˆ†t+ (Ë™prev
j+1/2m)âˆ†t2+remrev,3
j
âˆ’ 
qfwd
j+1âˆ’(pfwd
j+1/m)âˆ†t+ (Ë™pfwd
j+1/2m)âˆ†t2+remfwd,3
j
âˆ¥2
â‰¤R(qrev
j+1)âˆ’qfwd
j+1
2+1
mR(prev
j+1)âˆ’pfwd
j+1
2âˆ†t+1
2mR(Ë™prev
j+1)âˆ’Ë™pfwd
j+1
2âˆ†t2+âˆ¥remrev,3
jâˆ¥2+âˆ¥remfwd,3
jâˆ¥2
â‰¤
Crev
3(Tâˆ’jâˆ’1)3+Crev
2
m(Tâˆ’jâˆ’1)2+Crev
1
2m(Tâˆ’jâˆ’1) + 2 c3
âˆ†t3,
where the first inequality uses the triangle inequality, and in the second inequality we use (24a), (24b)
and (24c). Thus taking Crev
3= max {Crev
2/3m, Crev
1/6m,2c3}, we have the final expression above is
upper bounded by Crev
3(Tâˆ’j)3âˆ†t3, and so the claim holds for j.
Since both the base case and the inductive step have been proven, by the principle of mathematical
induction, (23b), (23a) and (23c) hold for all k=T, Tâˆ’1,Â·Â·Â·,0.
With this we finish the proof by plugging (23b) and (23a) into the loss function:
TX
j=0âˆ¥R(zrev
j)âˆ’zfwd
jâˆ¥2
2=TX
j=0âˆ¥R(prev
j)âˆ’pfwd
jâˆ¥2
2+TX
j=0âˆ¥R(qrev
j)âˆ’qfwd
jâˆ¥2
2
â‰¤ 
Crev
22TX
j=0(Tâˆ’j)4âˆ†t4+ 
Crev
32TX
j=0(Tâˆ’j)6âˆ†t6
=O(T5âˆ†t4).(25)
A.4 Proof of Lemma 3.2
babağ’š$ğ’ŠğŸğ°ğğŸ=ğ’šğ’Š(ğŸ)ğ’šğ’Š(ğŸ)ğ’š$ğ’Šğ«ğğ¯ğŸğŸ=ğ’šğ’ŠğŸ=ğ’š$ğ’ŠğŸğ°ğğŸğ’šğ’Š(ğŸ)ğ’š$ğ’ŠğŸğ°ğğŸğ’š$ğ’ŠğŸğ°ğğŸ
ğ’š$ğ’Šğ«ğğ¯ğŸâˆ’ğŸğ’š$ğ’Šğ«ğğ¯ğŸğŸğ’š$ğ’Šğ«ğğ¯ğŸğ’š$ğ’Šğ«ğğ¯âˆ’ğŸ=ğ‘¹(ğ’š$ğ’ŠğŸğ°ğğŸ)
ğ‘€ğ‘ğ‘¥ğ¸ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ !"#$!=max	{ğ‘,ğ‘}ğ‘€ğ‘ğ‘¥ğ¸ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ !"%-'(#)=ğ‘+ğ‘â„’!"#$=ğ’š$ğ’ŠğŸğ°ğğŸ âˆ’ğ’šğ’Š(ğŸ) ))âˆ¶=ğ‘â„’"#*#"+#=ğ‘…(	ğ’š$ğ’Šğ«ğğ¯ğŸ)âˆ’ğ’š$ğ’ŠğŸğ°ğğŸ  ))â‰”ğ‘â„’!"#$=ğ’š$ğ’ŠğŸğ°ğğŸ âˆ’ğ’šğ’Š(ğŸ) ))âˆ¶=ğ‘â„’"#*#"+#)=ğ’š$ğ’Šğ«ğğ¯ğŸğŸâˆ’ğ’š$ğ’ŠğŸğ°ğğŸ  ))â‰”ğ‘GroundtruthTrajectoryForwardTrajectoryReverseTrajectoryTREAT:	ğ‘…âˆ˜ğœ™!âˆ˜ğ‘…âˆ˜ğœ™!=ğ¼TRS-ODEN:	ğ‘…âˆ˜ğœ™!=ğœ™"!âˆ˜ğ‘…	ğ’š$ğ’Šğ«ğğ¯ğŸğŸ=ğ‘¹(	ğ’š$ğ’Šğ«ğğ¯ğŸâˆ’ğŸ)
Figure 8: Comparison between two reversal loss implementation
18We expect an ideal model to align both the predicted forward and reverse trajectories with the ground
truth. As shown in Figure 8, we integrate one step from the initial state Ë†yfwd
i(0)(which is the same as
yi(0)) and reach the state Ë†yfwd
i(1).
The first reverse loss implementation (ours) follows Lemma 2.1 as Râ—¦Î¦tâ—¦Râ—¦Î¦t=I, which means
when we evolve forward and reach the state Ë†yfwd
i(1)we reverse it into Ë†yrev
i(âˆ’1) = R(Ë†yfwd
i(1)) and go
back to reach Ë†yrev
i(0), then reverse it to get R(Ë†yrev
i(0)), which ideally should be the same as Ë†yfwd
i(0).
The second reverse loss implementation follows Eqn 5as Râ—¦Î¦t= Î¦âˆ’tâ—¦R, which means we first
reverse the initial state as Ë†yrev2
i(0) = R(yi(0)), then evolve the reverse trajectory in the opposite
direction to reach Ë†yrev2
i(âˆ’1), and then perform a symmetric operation to reach Ë†yrev2
i(1), aligning it
with the forward trajectory.
We assume the two reconstruction losses Lpred=âˆ¥Ë†yfwd
i(1)âˆ’yi(1)âˆ¥2
2:=aare the same. For the
time-reversal losses, we also assume they have reached the same value b:
Lreverse =âˆ¥R(Ë†yrev
i(0))âˆ’Ë†yfwd
i(0)âˆ¥2
2+âˆ¥R(Ë†yrev
i(âˆ’1))âˆ’Ë†yfwd
i(1)âˆ¥2
2=âˆ¥R(Ë†yrev
i(0))âˆ’Ë†yfwd
i(0)âˆ¥2
2:=b,
Lreverse 2=âˆ¥Ë†yrev2
i(0)âˆ’Ë†yfwd
i(0)âˆ¥2
2+âˆ¥Ë†yrev2
i(1)âˆ’Ë†yfwd
i(1)âˆ¥2
2=âˆ¥Ë†yrev2
i(1)âˆ’Ë†yfwd
i(1)âˆ¥2
2:=b,
As shown in Figure 8 where we illustrate the worst case scenario MaxError gt_rev =
max kâˆˆ[K]âˆ¥yi(tk)âˆ’Ë†yrev
i(tâ€²
Kâˆ’k)âˆ¥2of TREAT and TRS-ODEN, we can see that in our implementation
the worst error is the maximum of two loss, while the TRS-ODENâ€™s implementation has the risk of
accumulating the error together, making the worst error being the sum of both:
MaxError TREAT = maxR(Ë†yrev
i(0))âˆ’yi(0)
2,R(Ë†yrev
i(âˆ’1))âˆ’yi(1)
2	
=max
a, b	
,
MaxError TRS-ODEN = maxË†yrev2
i(0)âˆ’yi(0)
2,Ë†yrev2
i(1)âˆ’yi(1)
2	
= max
0,R(Ë†yrev
i(âˆ’1))âˆ’yi(1)
2	
=Ë†yrev2
i(1)âˆ’Ë†yfwd
i(1)
2+Ë†yfwd(1)âˆ’y(1)
2=a+b,
(26)
So it is obvious that MaxError TREAT made by TREAT is smaller., which means our model achieves
a smaller error of the maximum distance between the reversal and ground truth trajectory.
B Example of varying dynamical systems
We illustrate the energy conservation and time reversal of the three n-body spring systems used in our
experiments. We use the Hamiltonian formalism of systems under classical mechanics to describe
their dynamics and verify their energy conservation and time-reversibility characteristics.
The scalar function that describes a systemâ€™s motion is called the Hamiltonian, H, and is typically
equal to the total energy of the system, that is, the potential energy plus the kinetic energy (North,
2021). It describes the phase space equations of motion by following two first-order ODEs called
Hamiltonâ€™s equations:
dq
dt=âˆ‚H(q,p)
âˆ‚p,dp
dt=âˆ’âˆ‚H(q,p)
âˆ‚q, (27)
where qâˆˆRn,pâˆˆRn, andH:R2n7â†’Rare positions, momenta, and Hamiltonian of the system.
Under this formalism, energy conservative is defined by dH/dt= 0, and the time-reversal symmetry
is defined by H(q, p, t ) =H(q,âˆ’p,âˆ’t)(Lamb and Roberts, 1998).
B.1 Conservative and reversible systems.
A simple example is the isolated n-body spring system, which can be described by :
dqi
dt=pi
m
dpi
dt=X
jâˆˆNiâˆ’k(qiâˆ’qj),(28)
where q= (q1,q2,Â·Â·Â·,qN)is a set of positions of each object , p= (p1,p2,Â·Â·Â·,pN)is a set of
momenta of each object, miis mass of each object, kis spring constant.
19The Hamiltonâ€™s equations are:
âˆ‚H(q,p)
âˆ‚pi=dqi
dt=pi
m
âˆ‚H(q,p)
âˆ‚qi=âˆ’dpi
dt=X
jâˆˆNik(qiâˆ’qj),(29)
Hence, we can obtain the Hamiltonian through the integration of the above equation.
H(q,p) =NX
i=1pi2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2, (30)
Verify the systemsâ€™ energy conservation
dH 
q,p)
dt=1
dt(NX
i=1pi2
2mi
+1
dt 1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2
= 0, (31)
So it is conservative.
Verify the systemsâ€™ time-reversal symmetry We do the transformation R: (q,p, t)7â†’(q,âˆ’p,âˆ’t).
H(q,p) =NX
i=1pi2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2,
H(q,âˆ’p) =NX
i=1(âˆ’pi)2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2,(32)
It is obvious H(q,p) =H(q,âˆ’p), so it is reversible
B.2 Non-conservative and reversible systems.
A simple example is a n-body spring system with periodical external force, which can be described
by:
dqi
dt=pi
m
dpi
dt=NX
jâˆˆNiâˆ’k(qiâˆ’qj)âˆ’k1cosÏ‰t,(33)
The Hamiltonâ€™s equations are:
âˆ‚H(q,p)
âˆ‚pi=dqi
dt=pi
m
âˆ‚H(q,p)
âˆ‚qi=âˆ’dpi
dt=X
jâˆˆNik(qiâˆ’qj) +k1cosÏ‰t,(34)
Hence, we can obtain the Hamiltonian through the integration of the above equation:
H(q,p) =NX
i=1pi2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2+NX
i=1qiâˆ—k1cosÏ‰t, (35)
Verify the systemsâ€™ energy conservation
dH 
q,p)
dt=1
dt(NX
i=1pi2
2mi
+1
dt 1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2
+1
dt NX
i=1qiâˆ—k1cosÏ‰t
=0 +1
dt NX
i=1qik1cosÏ‰t
= NX
i=1âˆ’Ï‰qik1sinÏ‰t
Ì¸= 0(36)
20So it is non-conservative.
Verify the systemsâ€™ time-reversal symmetry We do the transformation R: (q,p, t)7â†’(q,âˆ’p,âˆ’t).
H(q,p) =NX
i=1pi2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2+NX
i=1qiâˆ—k1cosÏ‰t,
H(q,âˆ’p) =NX
i=1(âˆ’pi)2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2+NX
i=1qiâˆ—k1cosÏ‰(âˆ’t),(37)
It is obvious H(q,p, t) =H(q,âˆ’p, t), so it is reversible
B.3 Non-conservative and irreversible systems.
A simple example is an n-body spring system with frictions proportional to its velocity, Î³is the
coefficient of friction, which can be described by:
dqi
dt=pi
m
dpi
dt=âˆ’k0qiâˆ’Î³pi
m(38)
The Hamiltonâ€™s equations are:
âˆ‚H(q,p)
âˆ‚pi=dqi
dt=pi
m
âˆ‚H(q,p)
âˆ‚qi=âˆ’dpi
dt=X
jâˆˆNik(qiâˆ’qj) +Î³pi
m(39)
Hence, we can obtain the Hamiltonian through the integration of the above equation:
H(q,p) =NX
i=1pi2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2+NX
i=1Î³
mZt
0pi2
mdt, (40)
Verify the systemsâ€™ energy conservation
dH 
q,p)
dt=1
dt(NX
i=1pi2
2mi
+1
dt 1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2
+1
dt NX
i=1Î³
mZt
0pi2
mdt)
=0 +1
dt NX
i=1Î³
mZt
0pi2
mdt)
= NX
i=1Î³
mpi2
m)Ì¸= 0(41)
So it is non-conservative.
Verify the systemsâ€™ time-reversal symmetry We do the transformation R: (q,p, t)7â†’(q,âˆ’p,âˆ’t).
H(q,p) =NX
i=1pi2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2+NX
i=1Î³
mZt
0pi2
mdt,
H(q,âˆ’p) =NX
i=1(âˆ’pi)2
2mi+1
2NX
i=1NX
jâˆˆNi1
2k(qiâˆ’qj)2+NX
i=1Î³
mZ(âˆ’t)
0pi2
md(âˆ’t),(42)
It is obvious H(q,p, t)Ì¸=H(q,âˆ’p, t), so it is irreversible
21C Dataset
In our experiments, all datasets are synthesized from ground-truth physical law via sumulation. We
generate five simulated datasets: three n-body spring systems under damping, periodic, or no external
force, one chaotic tripe pendulum dataset with three sequentially connected stiff sticks that form and
a chaotic strange attractor. We name the first three as Sipmle Spring ,Forced Spring , and Damped
Spring respectively. For multi-agent systems, all n-body spring systems contain 5 interacting balls,
with varying connectivities. Each Pendulum system contains 3 connected stiff sticks. For single-agent
systems, all spring systems contain only one ball. For the chaotic single Attractor , we follow the
setting of (Huh et al., 2020).
For the n-body spring system, we randomly sample whether a pair of objects are connected, and
model their interaction via forces defined by Hookeâ€™s law. In the Damped spring , the objects have an
additional friction force that is opposite to their moving direction and whose magnitude is proportional
to their speed. In the Forced spring , all objects have the same external force that changes direction
periodically. We show in Figure 1(a), the energy variation in both of the Damped spring andForced
spring is significant. For the chaotic triple Pendulum , the equations governing the motion are
inherently nonlinear. Although this system is deterministic, it is also highly sensitive to the initial
condition and numerical errors (Shinbrot et al ., 1992; Awrejcewicz et al ., 2008; Stachowiak and
Okada, 2006). This property is often referred to as the "butterfly effect", as depicted in Figure 9.
Unlike for n-body spring systems, where the forces and equations of motion can be easily articulated,
for the Pendulum , the explicit forces cannot be directly defined, and the motion of objects can only
be described through Lagrangian formulations (North, 2021), making the modeling highly complex
and raising challenges for accurate learning. We simulate the trajectories by using Eulerâ€™s method for
0 100 200 300 400 500 600 700
Time steps10
010203040Joint 
Original initial condition: 0
w/ 1e-3 perturbation: 0
w/ 1e-2 perturbation: 0
1
1
1
2
2
2
Figure 9: Illustration to show the pendulum is highly-sensitive to initial states
n-body spring systems and using the 4th order Runge-Kutta (RK4) method for the Pendulum and
Attractor . For all spring systems and Pendulum , We integrate with a fixed step size and subsample
every 100 steps. For training, we use a total of 6000 forward steps. To generate irregularly sampled
partial observations, we follow (Huang et al ., 2020) and sample the number of observations n from a
uniform distribution U(40, 52) and draw the n observations uniformly for each object. For testing, we
additionally sample 40 observations following the same procedure from PDE steps [6000, 12000],
besides generating observations from steps [1, 6000]. The above sampling procedure is conducted
independently for each object. We generate 20k training samples and 5k testing samples for each
dataset. For Attractor , we integrate a total of 600 forward steps for training and subsample every
10 steps. For testing, we additionally sample 40 observations from step [600,1200].The irregularly
sampled partial observations generation is the same as above. We generate 1000 training samples
and 50 testing samples following (Huh et al ., 2020). Therefore, for all datasets, condition length is
2260 steps and prediction length is 40s steps. The features (position/velocity) are normalized to the
maximum absolute value of 1 across training and testing datasets.
We also compute the Maximum Lyapunov Exponent (MLE) to assess the chaos level of the systems,
using the formula:
Î»=max tâ†’inf(1
tln||Î´(t)||
||Î´(0)||).
We set fixed initial values for each dataset and generate 10 trajectories by perturbing the initial values
with random noise (0, 0.0001). We calculate the Maximum Lyapunov Exponent (MLE) between any
two trajectories. Finally, we compute the average and std of MLE from all pairs to gauge the chaotic
behavior of each dataset. The data is presented in the table below:
Table 2: MLE of different Multi-agent Systems
Dataset Simple Spring Forced Spring Damped Spring Pendulum
MLE(in 60 steps) 0.4031 Â±0.3944 1.0087 Â±1.0577 0.6307 Â±0.7065 34.1832 Â±30.1846
From the table, itâ€™s evident that the order of MLE values is: Pendulum Â» three Spring datasets.
This observation is consistent with the evaluation results based on MSE presented in our previous
responses in Table 3 which indicates that as the prediction length(steps*step size) increases, there is a
more significant performance degradation of all models on Pendulum dataset.
In the following subsections, we show the dynamical equations of each dataset in detail.
C.1 Spring Systems
C.1.1 Simple Spring
The dynamical equations of simple spring are as follows:
dqi
dt=pi
m
dpi
dt=NX
jâˆˆNiâˆ’k(qiâˆ’qj)(43)
where where q= (q1,q2,Â·Â·Â·,qN)is a set of positions of each object , p= (p1,p2,Â·Â·Â·,pN)is a
set of momenta of each object. We set the mass of each object m= 1, the spring constant k= 0.1.
C.1.2 Damped Spring
The dynamical equations of damped spring are as follows:
dqi
dt=pi
m
dpi
dt=X
jâˆˆNiâˆ’k(qiâˆ’qj)âˆ’Î³pi
m(44)
where where q= (q1,q2,Â·Â·Â·,qN)is a set of positions of each object, p= (p1,p2,Â·Â·Â·,pN)is a
set of momenta of each object, We set the mass of each object m= 1, the spring constant k= 0.1,
the coefficient of friction Î³= 10 .
C.1.3 Forced Spring
The dynamical equations of forced spring system are as follows:
dqi
dt=pi
m
dpi
dt=NX
jâˆˆNiâˆ’k(qiâˆ’qj)âˆ’k1cosÏ‰t,(45)
23where where q= (q1,q2,Â·Â·Â·,qN)is a set of positions of each object , p= (p1,p2,Â·Â·Â·,pN)is a
set of momenta of each object. We set the mass of each object m= 1, the spring constant k= 0.1,
the external strength k1= 10 and the frequency of variation Ï‰= 1
We simulate the positions and momentums of three spring systems by using Euler methods as follows:
qi(t+ 1) = qi(t) +dqi
dtâˆ†t
pi(t+ 1) = pi(t) +dpi
dtâˆ†t(46)
wheredqi
dtanddpi
dtwere defined as above for each datasets, and âˆ†t= 0.001is the integration steps.
C.2 Chaotic Pendulum
In this section, we demonstrate how to derive the dynamics equations for a chaotic triple pendulum
using the Lagrangian formalism.
The moment of inertia of each stick about the centroid is
I=1
12ml2(47)
The position of the center of gravity of each stick is as follows:
x1=l
2sinÎ¸1, y 1=âˆ’l
2cosÎ¸1
x2=l(sinÎ¸1+1
2sinÎ¸2), y 2=âˆ’l(cosÎ¸1+1
2cosÎ¸2)
x3=l(sinÎ¸1+ sin Î¸2+1
2sinÎ¸3), y 3=âˆ’l(cosÎ¸1+ cos Î¸2+1
2cosÎ¸3)(48)
The change in the center of gravity of each stick is:
Ë™x1=l
2cosÎ¸1Â·Ë™Î¸1,Ë™y1=l
2sinÎ¸1Â·Ë™Î¸1
Ë™x2=l(cosÎ¸1Â·Ë™Î¸1+1
2cosÎ¸2Â·Ë™Î¸2),Ë™y2=l(sinÎ¸1Â·Ë™Î¸1+1
2sinÎ¸2Â·Ë™Î¸2)
Ë™x3=l(cosÎ¸1Â·Ë™Î¸1+ cos Î¸2Â·Ë™Î¸2+1
2cosÎ¸3Â·Ë™Î¸3),Ë™y3=l(sinÎ¸1Â·Ë™Î¸1+ sin Î¸2Â·Ë™Î¸2+1
2sinÎ¸3Â·Ë™Î¸3)(49)
The Lagrangian L of this triple pendulum system is:
L=Tâˆ’V
=1
2m( Ë™x12+ Ë™x22+ Ë™x32+ Ë™y12+ Ë™y22+ Ë™y32) +1
2I(Ë™Î¸12+Ë™Î¸22+Ë™Î¸32)âˆ’mg(y1+y2+y3)
=1
6ml(9Ë™Î¸2Ë™Î¸1lcos(Î¸1âˆ’Î¸2) + 3 Ë™Î¸3Ë™Î¸1lcos (Î¸1âˆ’Î¸3) + 3 Ë™Î¸2Ë™Î¸3lcos (Î¸2âˆ’Î¸3) + 7 Ë™Î¸2
1l+ 4Ë™Î¸2
2l+Ë™Î¸2
3l
+ 15gcos (Î¸1) + 9gcos (Î¸2) + 3gcos (Î¸3))(50)
The Lagrangian equation is defined as follows:
d
dtâˆ‚L
âˆ‚Ë™Î¸âˆ’âˆ‚L
âˆ‚Î¸=0 (51)
and we also have:
âˆ‚L
âˆ‚Ë™Î¸=âˆ‚T
âˆ‚Ë™Î¸=p
Ë™p=d
dtâˆ‚L
âˆ‚Ë™Î¸=âˆ‚L
âˆ‚Î¸(52)
where p is the Angular Momentum.
We can list the equations for each of the three sticks separately:
p1=âˆ‚L
âˆ‚Ë™Î¸1Ë™p1=âˆ‚L
âˆ‚Î¸1
p2=âˆ‚L
âˆ‚Ë™Î¸2Ë™p2=âˆ‚L
âˆ‚Î¸2
p3=âˆ‚L
âˆ‚Ë™Î¸3Ë™p3=âˆ‚L
âˆ‚Î¸3(53)
24Finally, we have :
ï£±
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³Ë™Î¸1=6(9p1cos(2( Î¸2âˆ’Î¸3))+27 p2cos(Î¸1âˆ’Î¸2)âˆ’9p2cos(Î¸1+Î¸2âˆ’2Î¸3)+21p3cos(Î¸1âˆ’Î¸3)âˆ’27p3cos(Î¸1âˆ’2Î¸2+Î¸3)âˆ’23p1)
ml2(81 cos(2( Î¸1âˆ’Î¸2))âˆ’9 cos(2( Î¸1âˆ’Î¸3))+45 cos(2( Î¸2âˆ’Î¸3))âˆ’169)
Ë™Î¸2=6(27p1cos(Î¸1âˆ’Î¸2)âˆ’9p1cos(Î¸1+Î¸2âˆ’2Î¸3)+9p2cos(2( Î¸1âˆ’Î¸3))âˆ’27p3cos(2Î¸1âˆ’Î¸2âˆ’Î¸3)+57p3cos(Î¸2âˆ’Î¸3)âˆ’47p2)
ml2(81 cos(2( Î¸1âˆ’Î¸2))âˆ’9 cos(2( Î¸1âˆ’Î¸3))+45 cos(2( Î¸2âˆ’Î¸3))âˆ’169)
Ë™Î¸3=6(21p1cos(Î¸1âˆ’Î¸3)âˆ’27p1cos(Î¸1âˆ’2Î¸2+Î¸3)âˆ’27p2cos(2Î¸1âˆ’Î¸2âˆ’Î¸3)+57p2cos(Î¸2âˆ’Î¸3)+81p3cos(2( Î¸1âˆ’Î¸2))âˆ’143p3)
ml2(81 cos(2( Î¸1âˆ’Î¸2))âˆ’9 cos(2( Î¸1âˆ’Î¸3))+45 cos(2( Î¸2âˆ’Î¸3))âˆ’169)
Ë™p1=âˆ’1
2ml
3Ë™Î¸2Ë™Î¸1lsin (Î¸1âˆ’Î¸2) +Ë™Î¸1Ë™Î¸3lsin (Î¸1âˆ’Î¸3) + 5gsin (Î¸1)
Ë™p1=âˆ’1
2ml
âˆ’3Ë™Î¸1Ë™Î¸2lsin (Î¸1âˆ’Î¸2) +Ë™Î¸2Ë™Î¸3lsin (Î¸2âˆ’Î¸3) + 3gsin (Î¸2)
Ë™p1=âˆ’1
2ml
Ë™Î¸1Ë™Î¸3lsin (Î¸1âˆ’Î¸3) +Ë™Î¸2Ë™Î¸3lsin (Î¸2âˆ’Î¸3)âˆ’gsin (Î¸3)
(54)
We simulate the angular of the three sticks by using the Runge-Kutta 4th Order Method as follows:
âˆ†Î¸1(t) =Ë™Î¸(t,Î¸(t))Â·âˆ†t
âˆ†Î¸2(t) =Ë™Î¸(t+âˆ†t
2,Î¸(t) +âˆ†Î¸1(t)
2)Â·âˆ†t
âˆ†Î¸3(t) =Ë™Î¸(t+âˆ†t
2,Î¸(t) +âˆ†Î¸2(t)
2)Â·âˆ†t
âˆ†Î¸4(t) =Ë™Î¸(t+ âˆ†t,Î¸(t) + âˆ†Î¸3(t))Â·âˆ†t
âˆ†Î¸(t) =1
6(âˆ†Î¸1(t) + âˆ†Î¸2(t) + âˆ†Î¸3(t) + âˆ†Î¸4(t))
Î¸(t+ 1) = Î¸(t) + âˆ†Î¸(t)(55)
where Ë™Î¸was defined as above , and âˆ†t= 0.0001 is the integration steps.
C.3 Chaotic Strange Attractor
The dynamical equations of this reversible strange attractor are as follows:
dx
dt= 1 + yz,
dy
dt=âˆ’xz,
dz
dt=y2+ 2yz,
x, y, x âˆˆR(56)
The above equations can be presented as ( Ë™x(t),Ë™y(t),Ë™z(t)) =Dynamic (x(t), y(t), z(t)).
We simulate K(t) = (x(t), y(t), z(t))by using the Runge-Kutta 4th Order Method as follows:
âˆ†K1(t) =Dynamic (K(t))âˆ—âˆ†t
âˆ†K2(t) =Dynamic (K(t) +âˆ†K1(t)
2)âˆ—âˆ†t
âˆ†K3(t) =Dynamic (K(t) +âˆ†K2(t)
2)âˆ—âˆ†t
âˆ†K4(t) =Dynamic (K(t) + âˆ† K3(t))âˆ—âˆ†t
âˆ†K(t) =1
6(âˆ†K1(t) + âˆ† K2(t) + âˆ† K3(t) + âˆ† K4(t))
K(t+ 1) = K(t) + âˆ† K(t)(57)
We sampling z(t0)randomly from uniform distribution [1, 3] while fixing x(t0) =y(t0) = 0 . We set
the trajectory lengths of both training and test dataset to 600, with regular time-step size âˆ†t= 0.03
and the sample frequency of 10. We add Gaussian noise 0.05n,nâˆ¼ N(0,1)to training trajectories.
25C.4 Human Motion
For the real-world motion capture dataset(Carnegie Mellon University, 2003), we focus on the
walking sequences of subject 35. Each sample in this dataset is represented by 31 trajectories, each
corresponding to the movement of a single joint. For each joint, we first randomly sample the number
of observations from a uniform distribution U(30,42)and then sample uniformly from the first 50
frames for training and validation trajectories. For testing, we additionally sampled 40 observations
from frames [51,99].We split different walking sequences into training (15 trials) and test sets (7
trials). For each walking sequence, we further split it into several non-overlapping small sequences
with maximum length 50 for training, and maximum length 100 for testing. In this way, we generate
total 120 training samples and 27 testing samples. We normalize all features (position/velocity) to
maximum absolute value of 1 across training and testing datasets.
D Model Details
In the following we introduce in details how we implement our model and each baseline.
D.1 Initial State Encoder
For multi-agent systems, the initial state encoder computes the latent node initial states zi(t)for all
agents simultaneously considering their mutual interaction. Specifically, it first fuses all observations
into a temporal graph and conducts dynamic node representation through a spatial-temporal GNN as
in (Huang et al., 2020):
hl+1
j(t)=hl
j(t)+Ïƒï£«
ï£­X
i(tâ€²)âˆˆNj(t)Î±l
i(tâ€²)â†’j(t)Ã—WvË†hlâˆ’1
i(tâ€²)ï£¶
ï£¸
Î±l
i(tâ€²)â†’j(t)=
WkË†hlâˆ’1
i(tâ€²)T
Wqhlâˆ’1
j(t)
Â·1âˆš
d,Ë†hlâˆ’1
i(tâ€²)=hlâˆ’1
i(tâ€²)+TE(tâ€²âˆ’t)
TE(âˆ† t)2i= sinâˆ†t
100002i/d
,TE(âˆ† t)2i+1= cosâˆ†t
100002i/d
,(58)
where ||denotes concatenation; Ïƒ(Â·)is a non-linear activation function; dis the dimension of node
embeddings. The node representation is computed as a weighted summation over its neighbors
plus residual connection where the attention score is a transformer-based (Vaswani et al ., 2017)
dot-product of node representations by the use of value, key, query projection matrices Wv,Wk,Wq.
Herehl
j(t)is the representation of agent jat time tin the l-th layer. i(tâ€²)is the general index for
neighbors connected by temporal edges (where tâ€²Ì¸=t) and spatial edges (where t=tâ€²andiÌ¸=j).
The temporal encoding (Hu et al ., 2020) is added to a neighborhood node representation in order
to distinguish its message delivered via spatial and temporal edges. Then, we stack Llayers to get
the final representation for each observation node: ht
i=hL
i(t). Finally, we employ a self-attention
mechanism to generate the sequence representation uifor each agent as their latent initial states:
ui=1
KX
tÏƒ
aT
iË†ht
iË†ht
i
,ai= tanh  
1
KX
tË†ht
i!
Wa!
, (59)
where aiis the average of observation representations with a nonlinear transformation Waand
Ë†ht
i=ht
i+TE(t).Kis the number of observations for each trajectory. Compared with recurrent
models such as RNN, LSTM (Sepp and JÃ¼rgen, 1997), it offers better parallelization for accelerating
training speed and in the meanwhile alleviates the vanishing/exploding gradient problem brought by
long sequences. For single-agent Systems, there only left the self-attention mechanism component.
Given the latent initial states, the dynamics of the whole system are determined by the ODE function
gwhich we parametrize as a GNN as in (Huang et al ., 2020) for Multi-Agent Systems to capture the
continuous interaction among agents. For single-agent systems, we only include self-loop edges in
the graph G= (V,E), which makes the ODE function ga simple MLP.
We then employ Multilayer Perceptron (MLP) as a decoder to predict the trajectories Ë†yi(t)from the
latent states zi(t).
26z1(t),z2(t),z3(t)Â·Â·Â·zN(t) =ODEsolver (g,[z1(t0),z2(t0)Â·Â·Â·zN(t0)],(t0, t1Â·Â·Â·tK))
Ë†yi(t) =fdec(zi(t))(60)
D.2 Implementation Details
TREAT
For multi-agent systems, our implementation of TREAT follows GraphODE pipeline. We implement
the initial state encoder using a 2-layer GNN with a hidden dimension of 64 across all datasets.
We use ReLU for nonlinear activation. For the sequence self-attention module, we set the output
dimension to 128. The encoderâ€™s output dimension is set to 16, and we add 64 additional dimensions
initialized with all zeros to the latent states zi(t)to stabilize the training processes as in (Huang et al .,
2021). The GNN ODE function is implemented with a single-layer GNN from (Kipf et al ., 2018)
with hidden dimension 128. For single-agent systems, we only include self-loop edges in the graph
G= (V,E), which makes the ODE function ga simple MLP. To compute trajectories, we use the
Runge-Kutta method from torchdiffeq python package s(Chen et al ., 2021) as the ODE solver and a
one-layer MLP as the decoder.
We implement our model in pytorch. Encoder, generative model, and the decoder parameters are
jointly optimized with AdamW optimizer (Loshchilov and Hutter, 2019) using a learning rate of
0.0001 for spring datasets and 0.00001 for Pendulum . The batch size for all datasets is set to 512.
TREAT Lrev=gt-rev and TREAT Lrev=rev2share the same architecture and hyparameters as TREAT,
with different implementations of the loss function. In TREAT Lrev=gt-rev, instead of comparing
forward and reverse trajectories, we look at the L2 distance between the ground truth and reverse
trajectories when computing the reversal loss.
For TREAT Lrev=rev2, we implement the reversal loss following (Huh et al ., 2020) with one difference:
we do not apply the reverse operation to the momentum portion of the initial state to the ODE function.
This is because the initial hidden state is an output of the encoder that mixes position and momentum
information. Note that we also remove the additional dimensions to the latent state that TREAT has.
To reproduce our modelâ€™s results, we provide our code implementation link here.
LatentODE
We implement the Latent ODE sequence to sequence model as specified in (Rubanova et al ., 2019).
We use a 4-layer ODE function in the recognition ODE, and a 2-layer ODE function in the generative
ODE. The recognition and generative ODEs use Euler and Dopri5 as solvers (Chen et al ., 2021),
respectively. The number of units per layer is 1000 in the ODE functions and 50 in GRU update
networks. The dimension of the recognition model is set to 100. The model is trained with a learning
rate of 0.001 with an exponential decay rate of 0.999 across different experiments. Note that since
latentODE is a single-agent model, we compute the trajectory of each object independently when
applying it to multi-agent systems.
HODEN
To adapt HODEN, which requires full initial states of all objects, to systems with partial observations,
we compute each objectâ€™s initial state via linear spline interpolation if it is missing. Following the
setup in (Huh et al ., 2020), we have two 2-layer linear networks with Tanh activation in between as
ODE functions, in order to model both positions and momenta. Each network has a 1000-unit layer
followed by a single-unit layer. The model is trained with a learning rate of 0.00001 using a cosine
scheduler.HODEN is a single-agent model, we compute the trajectory of each object independently
when applying it to multi-agent systems.
TRS-ODEN
Similar to HODEN, we compute each objectâ€™s initial state via linear spline interpolation if it is
missing. As in (Huh et al ., 2020), we use a 2-layer linear network with Tanh activation in between as
the ODE functions, and the Leapfrog method for solving ODEs. The network has 1000 hidden units
and is trained with a learning rate of 0.00001 using a cosine scheduler. TRS-ODEN is a single-agent
model, we compute the trajectory of each object independently when applying it to multi-agent
systems.
27TRS-ODEN GNN
For TRSODEN GNN, we substitute the ODE function in TRS-ODEN with a GraphODE network. The
GraphODE generative model is implemented with a single-layer GNN with hidden dimension 128.
As in HODEN and TRS-ODEN, we compute each objectâ€™s missing initial state via linear spline
interpolation and the Leapfrog method for solving ODE. For all datasets, we use 0.5 as the coefficient
for the reversal loss in (Huh et al., 2020), and 0.0002 as the learning rate under cosine scheduling.
LGODE
Our implementation follows (Huang et al ., 2020) except we remove the Variational Autoencoder
(V AE) from the initial state encoder. Instead of using the output from the encoder GNN as the
mean and std of the V AE, we directly use it as the latent initial state. That is, the initial states are
deterministic instead of being sampled from a distribution. We use the same architecture as in TREAT
and train the model using an AdamW optimizer with a learning rate of 0.0001 across all datasets.
E Additional Experiments
E.1 Comparison of different solvers
We next show our modelâ€™s sensitivity regarding solvers with different precisions. Specifically, we
compare against Euler and Runge-Kutta (RK4) where the latter is a higher-precision solver. We show
the comparison against LGODE and TREAT in Table 3.
We can firstly observe that TREAT consistently outperforms LGODE, which is our strongest baseline
across different solvers and datasets, indicating the effectiveness of the proposed time-reversal
symmetry loss. Secondly, we compute the improvement ratio asLGODE âˆ’TREAT
LGODE. We can see that
the improvement ratios get larger when using RK4 over Euler. This can be understood as our reversal
loss is minimizing higher-order Tayler expansion terms (Theoreom 3.1) thus compensating numerical
errors brought by ODE solvers.
Table 3: Evaluation results on MSE ( 10âˆ’2) over different solvers for multi-agent systems.
Dataset Simple Spring Forced Spring Damped Spring Pendulum
Solvers Euler RK4 Euler RK4 Euler RK4 Euler RK4
LGODE 1.8443 1.7429 2.0462 1.8929 1.1686 0.9718 1.4634 1.4156
TREAT 1.4864 1.1178 1.6058 1.4525 0.8070 0.5944 1.3093 1.2527
% Improvement 19.4057 35.8655 21.5228 23.2659 30.9430 38.8352 10.5303 11.5075
E.2 Evaluation across observation ratios.
For LG-ODE and TREAT, the encoder computes the initial states from observed trajectories. To show
modelsâ€™ sensitivity towards data sparsity, we randomly mask out 40 %and 80 %historical observations
and compare model performance. As shown in Table 4, when changing the ratios from 80 %to40%,
we observe that TREAT has a smaller performance drop compared with LG-ODE, especially on the
more complex Pendulum dataset (LG-ODE decreases 22.04 %while TREAT decreases 1.62 %). This
indicates that TREAT is less sensitive toward data sparsity.
Table 4: Results of varying observation ratios on MSE ( 10âˆ’2) of multi-agent datasets.
Dataset Simple Spring Forced Spring Damped Spring Pendulum
Observation Ratios 0.8 0.4 0.8 0.4 0.8 0.4 0.8 0.4
LG-ODE 1.7054 1.6889 1.7554 2.0370 0.9305 1.0217 1.4314 1.7469
TREAT 1.1176 1.1429 1.3611 1.5109 0.6920 0.6964 1.2309 1.2110
F Discussion about Reversible Neural Networks
In literature, there is another line of research about building reversible neural networks (NNs). For
example, (Chang et al ., 2018) formulates three architectures for reversible neural networks to address
28the stability issue and achieve arbitrary deep lengths, motivated by dynamical system modeling. (Liu
et al., 2019) employs normalizing flow to create a generative model of graph structures. They all
propose novel architectures to construct reversible NN where intermediate states across layer depths
do not need to be stored, thus improving memory efficiency.
However, weâ€™d like to clarify that reversible NNs (RevNet) do not resolve the time-reversal symmetry
problem that weâ€™re studying. The core of RevNet is that input can be recovered from output via a
reversible operation (which is another operator), similar as any linear operator W(Â·)have a reversed
projector Wâˆ’1(Â·). In the contrary, what we want to study is that the same operator can be used for
both forward and backward prediction over time, and keep the trajectory the same. That being said,
to generate the forward and backward trajectories, we are using the same g(Â·), instead of g(Â·), gâˆ’1(Â·)
respectively.
In summary, though both reversible NN and time-reversal symmetry share similar insights and
intuition, theyâ€™re talking about different things: reversible NNs make every operator g(Â·)having a
gâˆ’1(Â·), while time-reversible assume the trajectory get from Ë†zfwd=g(z)andË†zbwd=âˆ’g(z)to be
closer. Making gto be reversible cannot make the system to be time-reversible.
G Impact Statement
This paper presents work whose goal is to advance the field of Machine Learning. TREAT is trained
upon physical simulation data (e.g., , spring and pendulum) and implemented by public libraries in
PyTorch. During the modeling, we neither introduces any social/ethical bias nor amplify any bias in
the data. There are many potential societal consequences of our work, none which we feel must be
specifically highlighted here.
29NeurIPS Paper Checklist
The checklist is designed to encourage best practices for responsible machine learning research,
addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
the checklist: The papers not including the checklist will be desk rejected. The checklist should
follow the references and follow the (optional) supplemental material. The checklist does NOT count
towards the page limit.
Please read the checklist guidelines carefully for information on how to answer these questions. For
each question in the checklist:
â€¢ You should answer [Yes] , [No] , or [NA] .
â€¢[NA] means either that the question is Not Applicable for that particular paper or the
relevant information is Not Available.
â€¢ Please provide a short (1â€“2 sentence) justification right after your answer (even for NA).
The checklist answers are an integral part of your paper submission. They are visible to the
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
(after eventual revisions) with the final version of your paper, and its final version will be published
with the paper.
The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a
proper justification is given (e.g., "error bars are not reported because it would be too computationally
expensive" or "we were unable to find the license for the dataset we used"). In general, answering
"[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we
acknowledge that the true answer is often more nuanced, so please just use your best judgment and
write a justification to elaborate. All supporting evidence can appear either in the main paper or the
supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification
please point to the section(s) where related material for the question can be found.
IMPORTANT, please:
â€¢Delete this instruction block, but keep the section heading â€œNeurIPS paper checklist" ,
â€¢Keep the checklist subsection headings, questions/answers and guidelines below.
â€¢Do not modify the questions and only use the provided macros for your answers .
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: [TODO]
Guidelines:
â€¢The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Limitations are discussed in Appendix 6
30Guidelines:
â€¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
â€¢The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
â€¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
â€¢While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Proofs are in Appendix A.3, A.2and A.4.
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢All assumptions should be clearly stated or referenced in the statement of any theorems.
â€¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
â€¢Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: The Datasets, Task Setup, Baselines describtion are in Sec. 4. Pseudo code for
the implementation of the Time-Reversal Symmetry Loss is in Appendix A.1. More Model
Details and Implementation Details are in Appendix D.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
31â€¢If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
â€¢Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
â€¢While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: The Datasets, Task Setup, Baselines description are in Sec. 4. Pseudo code
for the implementation of the Time-Reversal Symmetry Loss is in Appendix A.1. More
Dataset descriptions are in Appendix C. More Model Details and Implementation Details
are in Appendix D.
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢While we encourage the release of code and data, we understand that this might not be
possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
32â€¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: The Datasets, Task Setup, Baselines description are in Sec. 4. More Implemen-
tation Details are in Appendix D.2.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
â€¢The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: In Appendix ??
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
â€¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
â€¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
â€¢It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
â€¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
â€¢For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: [TODO]
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
33â€¢The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
â€¢The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: [TODO]
Guidelines:
â€¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
â€¢The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: In Appendix G.
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
â€¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
â€¢The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: [TODO]
34Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
â€¢Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
â€¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: [TODO]
Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
â€¢For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
â€¢If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: [TODO]
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢The paper should discuss whether and how consent was obtained from people whose
asset is used.
â€¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
35Answer: [NA]
Justification: [TODO]
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
â€¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: [TODO]
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
â€¢We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
36