Identification of Analytic Nonlinear Dynamical
Systems with Non-asymptotic Guarantees
Negin Musavi
nmusavi2@illinois.eduZiyao Guo
ziyaog2@illinois.edu
Geir Dullerud
dullerud@illinois.eduYingying Li
yl101@illinois.edu
Coordinated Science Laboratory
University of Illinois Urbana-Champaign
Abstract
This paper focuses on the system identification of an important class of nonlinear
systems: nonlinear systems that are linearly parameterized, which enjoy wide
applications in robotics and other mechanical systems. We consider two system
identification methods: least-squares estimation (LSE), which is a point estimation
method; and set-membership estimation (SME), which estimates an uncertainty
set that contains the true parameters. We provide non-asymptotic convergence
rates for LSE and SME under i.i.d. control inputs and control policies with i.i.d.
random perturbations, both of which are considered as non-active-exploration
inputs. Compared with the counter-example based on piecewise-affine systems
in the literature, the success of non-active exploration in our setting relies on a
key assumption about the system dynamics: we require the system functions to
be real-analytic. Our results, together with the piecewise-affine counter-example,
reveal the importance of differentiability in nonlinear system identification through
non-active exploration. Lastly, we numerically compare our theoretical bounds
with the empirical performance of LSE and SME on a pendulum example and a
quadrotor example.
1 Introduction
Learning control-dynamical systems with statistical methodology has received significant attention in
the past decade (Sarker et al., 2023; Li et al., 2023b; Chen and Hazan, 2021; Simchowitz and Foster,
2020; Wagenmaker and Jamieson, 2020; Simchowitz et al., 2018; Dean et al., 2018; Abbasi-Yadkori
and SzepesvÃ¡ri, 2011; Li et al., 2021b). In particular, the estimation of linear dynamical systems, e.g.
xt+1=Aâˆ—xt+Bâˆ—ut+wt, is relatively well-studied: it has been shown that non-active exploration by
i.i.d. noises on control inputs utand system disturbances wtare already enough for accurate system
identification, and least square estimation (LSE) can achieve the optimal estimation convergence rate
(Simchowitz and Foster, 2020; Simchowitz et al., 2018).
However, nonlinear control systems are ubiquitous in real-world applications, e.g. robotics (Siciliano
et al., 2010; Alaimo et al., 2013), power systems (Simpson-Porco et al., 2016), transportation (Kong
et al., 2015), etc. Motivated by this, there has been a lot of attention on learning nonlinear systems
recently. One natural and popular direction to study nonlinear system identification is on learning
linearly parameterized nonlinear systems as defined below, which is a straightforward extension from
38th Conference on Neural Information Processing Systems (NeurIPS 2024).the standard linear systems (Mania et al., 2022; Khosravi, 2023; Foster et al., 2020)
xt+1=Î¸âˆ—Ï•(xt, ut) +wt
where Î¸âˆ—is a vector of unknown parameters and Ï•(xt, ut)is a known vector of nonlinear features.
On the one hand, some classes of these systems are shown to enjoy similar benefits of linear systems.
For example, bilinear systems can also be estimated by LSE under non-active exploration with i.i.d.
noises (Sattar et al., 2022), as well as linear systems with randomly perturbed nonlinear policies (Li
et al., 2023b).
On the other hand, it is also known that non-active exploration is insufficient for general linearly
parameterized nonlinear systems. In particular, (Mania et al., 2022) provides a counter example
showing that non-active exploration is insufficient to learn accurate models under piece-wise affine
feature functions. This motivates a sequence of follow-up work on the design of active exploration
for nonlinear system estimation, which is largely motivated by the non-smooth feature functions such
as ReLu in neural networks (Mania et al., 2022; Kowshik et al., 2021; Khosravi, 2023).
However, there is a big gap between bilinear systems, which is infinitely differentiable, and the
counter example by non-smooth systems. A natural question is: to what extent can non-active
exploration still work for linearly parameterized nonlinear systems?
Contributions. One major contribution of this paper is showing that LSE with non-active i.i.d.
noises can efficiently learn any linearly parameterized nonlinear systems with real-analytic feature
functions and provide a non-asymptotic convergence rate. Notice that real-analytic feature functions
are common in physical systems. For example, polynomial systems satisfy this requirement and have
wide applications in power systems (Simpson-Porco et al., 2016), fluid dynamics (Noack et al., 2003),
etc. Further, trigonometric functions also satisfy the real-analytic property so a large range of robotics
and mechanical systems also satisfy this requirement (Siciliano et al., 2010; Alaimo et al., 2013).
A side product of our LSE convergence rate analysis is the convergence rate for another commonly
used uncertainty quantification method in control: set membership estimation (SME).
Numerically, we test our theoretical results in pendulum and quadrotor systems. Simulations show
that LSE and SME can indeed efficiently explore the system and converge to the true parameter under
non-active exploration noises.
Technically, the key step in our proof is establishing the block-martingale-small-ball condition
(BMSB) for general analytic feature functions, which greatly generalizes the bilinear feature function
in Sattar et al. (2022). Our result is built on an intuition inspired by the counter example in (Mania
et al., 2022): the counter example in (Mania et al., 2022) requires that some feature function is zero
in a certain region, so nothing can be learned about its parameter if the states stay in this region.
However, analytic functions cannot be a constant zero in a positive-measure region unless it is a
constant zero everywhere. Therefore, the counter example does not work, and non-active exploration
around any states can provide some useful information. Our proof formalizes this intuition by utilizing
the Paley-Zygmund Petrov inequality (Petrov, 2007).
Related work. Inspired by neural network parameterization, nonlinear systems of the form xt+1=
Ï•(Aâˆ—xt) +wtis also studied in the literature, where Ï•(Â·)is a known nonlinear link function and
Aâˆ—is unknown. The least square cost is no longer quadratic or even convex in this case and various
optimization methods have been proposed to learn this type of systems (Kowshik et al., 2021; Sattar
et al., 2022; Foster et al., 2020).
Another related line of research focuses on nonlinear regression with dependent data (Ziemann and
Tu, 2022; Ziemann et al., 2023, 2024),1which can be applied to nonlinear system identification.
The nonlinear regression in (Ziemann and Tu, 2022; Ziemann et al., 2023, 2024) is based on non-
parametric LSE and its variants, and their convergence rates under different scenarios have been
analyzed. It is interesting to note that this line of work usually assumes certain persistent excitation
assumptions,2whereas our paper demonstrates that persistent excitation holds by establishing the
BMSB condition for linearly parameterized and real-analytic nonlinear control systems.
1yt=fâˆ—(xt) +wtis considered, where xtandytcorrelate with the historical data.
2For example, (Ziemann and Tu, 2022) assumes hyper-contractivity, and (Ziemann et al., 2024) assumes the
empirical covariance of the {xt}tâ‰¥0process is invertible with high probability (Corollary 3.2).
2Uncertainty set estimation is crucial for robust control under model uncertainties Lu and Cannon
(2023); Lorenzen et al. (2019); Li et al. (2021a). SME is a widely adopted uncertainty set estimation
method in robust adaptive control (Lorenzen et al., 2019; Lu and Cannon, 2023; Bertsekas, 1971; Bai
et al., 1995). Recently, there is an emerging interest in analyzing SMEâ€™s convergence and convergence
rate for dynamical systems (Li et al., 2024; Lu et al., 2019; Xu and Li, 2024), because previous
analysis focus more on the linear regression problem (e.g. (AkÃ§ay, 2004; Bai et al., 1998)). There are
also recent applications of SME to online control Yu et al. (2023), power systems Yeh et al. (2024),
and computer vision Gao et al. (2024); Tang et al. (2024).
Notation. The set of non-negative real numbers is denoted by Râ‰¥0. The notation âŒˆÂ·âŒ‰stands for the
ceiling function. For a real vector zâˆˆRn,âˆ¥zâˆ¥2represents its â„“2norm,âˆ¥zâˆ¥âˆžrepresents its â„“âˆžnorm,
andzirepresents its i-th component with i= 1Â·Â·Â·n. The set of real symmetric matrices is denoted
bySn. For a real matrix Z,ZâŠºrepresents its transpose, âˆ¥Zâˆ¥2its maximum singular value, âˆ¥Zâˆ¥Fits
Frobenius norm, Ïƒmin(Z)its minimum singular value, vec(Z)its vectorization obtained by stacking
its columns, and for a real square matrix Z,tr(Z)represents its trace. For a real symmetric matrix
Z,Zâ‰»0andZâª°0indicate that Zis positive definite and positive semi-definite, respectively.
For a measurable set E âŠ‚Rn,Î»n(E)represents its Lebesgue measure in RnandEcrepresents its
complement in Rn. The notation âˆ…stands for the empty set. For a set Tof matrices Î¸âˆˆRnÃ—m,
diam(T)denotes its diameter and it is defined as diam(T) = supÎ¸,Î¸â€²âˆˆTâˆ¥Î¸âˆ’Î¸â€²âˆ¥F. ForziâˆˆRwith
i= 1,Â·Â·Â·, â„“, the notation diag(z1,Â·Â·Â·, zâ„“)denotes a matrix in Râ„“Ã—â„“with diagonal entries of zi.
This paper uses truncated-Gaussian (0, Ïƒw,[âˆ’wmax, wmax])to refer to the truncated Gaussian
distribution generated by Gaussian distribution with zero mean and Ïƒ2
wvariance with truncated range
[âˆ’wmax, wmax]. The same applies to multi-variate truncated Gaussian distributions.
2 Problem Formulation and Preliminaries
This paper studies the system identification/estimation of linearly parameterized nonlinear systems:
xt+1=Î¸âˆ—Ï• 
xt, ut
+wt, (1)
where xtâˆˆRnx,utâˆˆRnu, and wtâˆˆRnxdenote the state, control input, and system disturbance
respectively; Î¸âˆ—âˆˆRnxÃ—nÏ•denotes the unknown parameters to be estimated, and Ï•(Â·)denotes a
vector of known nonlinear feature/basis functions, i.e., Ï•(Â·) = (Ï•1(Â·),Â·Â·Â·, Ï•nÏ•(Â·))âŠº, where Ï•i(Â·) :
Rnx+nuâ†’R. Without loss of generality, we consider zero initial condition, i.e., x0= 0, and linearly
independent feature functions, that is,PnÏ•
i=1ciÏ•i(xt, ut) = 0 implies that ci= 0for all i.3
The linearly parameterized nonlinear system (1)is a natural generalization of linear control systems
xt+1=Aâˆ—xt+Bâˆ—ut+wtand has wide applications in, e.g. robotics (Siciliano et al., 2010; Alaimo
et al., 2013), power systems (Simpson-Porco et al., 2016), transportation (Kong et al., 2015), etc.
Therefore, there has been a lot of research on learning this type of systems (1)by utilizing the
methodology and insights from linear system estimation. For example, it is common to estimate a
linearly parameterized nonlinear system by least square estimation (LSE), which enjoys desirable
performance in linear systems.
In particular, LSE for (1) is reviewed below
Ë†Î¸T= arg min
Ë†Î¸Tâˆ’1X
t=0xt+1âˆ’Ë†Î¸Ï•(xt, ut)2
2. (2)
For linear systems, LSE enjoys the following good property: LSE can achieve the optimal rate of
convergence with i.i.d. noises wtand i.i.d. control inputs utunder proper conditions ( (Simchowitz
et al., 2018)). This good property has been generalized to some linearly parameterized nonlinear
systems, such as bilinear systems, and linear systems with nonlinear control policies. Unfortunately,
general linearly parameterized nonlinear systems do not enjoy this good property of linear systems,
meaning i.i.d. random inputs may not provide enough exploration for non-smooth feature functions
Ï•(Â·). Therefore, a sequence of follow-up work focuses on the design of active exploration methods.
However, due to the simplicity of implementation, i.i.d. random inputs remain a popular method in
empirical research of system identification and enjoy satisfactory performance sometimes, despite
3If the features are not independent, they can be converted to independent ones since the features are known.
3the lack of theoretical guarantees. Therefore, this paper aims to establish more general conditions
that allow provable convergence of nonlinear system estimation under i.i.d. random inputs.
In the rest of this paper, we will show that with certain smoothness and continuous conditions, i.i.d.
random inputs are sufficient for estimation of (1), which recovers the good property of linear systems.
2.1 Assumptions
In the following, we formally describe the smoothness and continuity conditions that enables efficient
exploration of (1) by i.i.d. random inputs.
Assumption 1 (Analytic feature functions) .All the components of feature vector Ï•(Â·)are real
analytic functions in Rnx+nu,4i.e., for every 1â‰¤iâ‰¤nÏ•,Ï•i(x, u)is an infinitely differentiable
function such that the Taylor expansion at every (Â¯x,Â¯u)converges point-wisely to the Ï•i(x, u)in a
neighborhood of (Â¯x,Â¯u).
Analytic functions include polynomial functions and trigonometric functions, which are important
components of many physical systems in real-world applications, e.g. power systems, robotics,
transportation systems, etc. In particular, we provide two illustrative examples below.
Example 1 (Pendulum) .Many multi-link robotic manipulators can be understood as interconnected
pendulum dynamics. The motion equations of a single pendulum, consisting of a mass msuspended
from a weightless rod of length lfixed at a pivot with no friction, can be expressed as:
Â¨Î±=âˆ’g
lsin(Î±) +u
ml2+w,
where Î±represents the angle of the rod relative to the vertical axis, gis the gravity constant, uis the
torque input, and wis the disturbance applied to this system. After discretization the system dynamics
can be rewritten in the structure of (1) with the feature vector consisting of expressions involving
sin(Î±)andu, all of which are analytic functions. The matrix of unknown parameters contains terms
of the pendulumâ€™s mass and the rodâ€™s length.
Example 2 (Quadrotor (Alaimo et al., 2013)) .LetpâˆˆR3andvâˆˆR3represent the center of
mass position and velocity of the quadrotor in the inertial frame, respectively; let Ï‰âˆˆR3denote its
angular velocity in the body-fixed frame, and qâˆˆR4denote the quaternion vector. The quadrotorâ€™s
equations of motion can then be expressed as:
d
dtï£«
ï£¬ï£­p
v
q
Ï‰ï£¶
ï£·ï£¸=ï£«
ï£¬ï£­v
âˆ’gez+1
mQfu
1
2â„¦q
Iâˆ’1(Ï„uâˆ’Ï‰Ã—IÏ‰)ï£¶
ï£·ï£¸+w,
where gis the gravity constant, mis its total mass, I=diag(Ixx, Iyy, Izz)its inertia matrix with
respect to the body-fixed frame, fuâˆˆRthe total thrust, Ï„uâˆˆR3the total moment in the body-fixed
frame, ez= (0,0,1)âŠº,Q=ï£«
ï£­q2
0+q2
1âˆ’q2
2âˆ’q2
32(q1q2âˆ’q0q3) 2( q0q2âˆ’q1q3)
2(q1q2âˆ’q0q3)q2
0âˆ’q2
1+q2
2âˆ’q2
32(q2q3âˆ’q0q1)
2(q1q3âˆ’q0q2) 2( q0q1âˆ’q2q3)q2
0âˆ’q2
1âˆ’q2
2+q2
3ï£¶
ï£¸,and
â„¦ =ï£«
ï£¬ï£­0âˆ’Ï‰1âˆ’Ï‰2âˆ’Ï‰3
Ï‰10 Ï‰3âˆ’Ï‰2
Ï‰2âˆ’Ï‰30 Ï‰1
Ï‰3Ï‰2âˆ’Ï‰10ï£¶
ï£·ï£¸.
Similar to the pendulum example, after discretization the system dynamics can be rewritten in the
structure of (1) with the feature vector consisting of cubic polynomials in states and inputs, which
are real-analytic. The unknown parameters contain terms of the mass and inertial moments of the
quadrotor.
Next, we introduce the assumption on the random inputs, which relies on the following definition.
Definition 1 (Semi-continuous distribution) .We define a probability distribution Pas semi-continuous
if there does not exist a set Ewith Lebesgue measure zero such that P(E) = 1 .
4This assumption can be relaxed to locally analytic functions in a large enough bounded set.
4The semi-continuous distribution is a weaker requirement than continuous distributions. In particular,
any continuous distributions, or a mixture distribution with one component as a continuous distribution
can satisfy the requirement of semi-continuity. The semi-continuity can also be interpreted by the
Lebesgue Decomposition Theorem (Chapter 6 of (Halmos, 2013)) as discussed below.
Remark 1 (Connection with Lebesgue Decomposition Theorem) .Definition 1 can be interpreted
by the Lebesgue Decomposition Theorem, which suggests that any probability distribution can be
decomposed into a purely atomic component and a non-atomic component (see more details in
Halmos (2013)). A semi-continuous distribution as defined in Definition 1 requires the distributionâ€™s
non-atomic component to be nonzero.
In the following, we provide the assumptions on wtandutusing the semi-continuity definition.
Assumption 2 (Bounded i.i.d. and semi-continuous disturbance) .wtis i.i.d. following a semi-
continuous distribution with zero mean and a positive definite covariance matrix Î£wâª°Ïƒ2
wInxâ‰»0
and a bounded support, i.e. âˆ¥wtâˆ¥âˆžâ‰¤wmaxalmost surely for all t.
The i.i.d. assumption is common in the literature of system identification for linear and nonlinear
systems. As for the bounded assumption on wt, though being stronger than the sub-Gaussian
assumption on wtin the literature of linear system estimation, it is a common assumption in the
literature of nonlinear system estimation (Mania et al., 2022; Shi et al., 2021; Kim and Lavaei, 2024).
Further, in many physical applications, noises are usually bounded, e.g. the wind disturbances in
quadrotor systems are bounded, the renewable energy injections in power systems are also bounded,
etc.
The semi-continuity assumption may seem restrictive, since it rules out the discrete distributions.
However, the disturbances in many realistic systems can satisfy the semi-continuity because realistic
noises are usually generated from a mixture distribution where at least one component is continuous,
e.g. the wind disturbances and renewable generations are continuous.
As for the control inputs ut, we first impose the same assumption as Assumption 2 for simplicity.
Later in Section 3, we will also discuss the relaxation of this assumption to include control policies.
Assumption 3 (Bounded i.i.d. and semi-continuous inputs) .utis i.i.d. following a semi-continuous
distribution with zero mean and a positive definite covariance Î£uâª°Ïƒ2
uInxâ‰»0and bounded support,
i.e.âˆ¥utâˆ¥âˆžâ‰¤umaxalmost surely for all t.
Lastly, we introduce our stability assumption based on the input-to-state stability definition below.
Definition 2 (Locally input-to-state stability (LISS)) .Consider the general nonlinear system xt+1=
f(xt, dt)withxtâˆˆRnx,dtâˆˆRnd,fbeing a continuous function such that f(0,0) = 0 . This
system is called locally input-to-state stable (LISS) if there exist constants Ïx>0,Ï > 0and
functions Î³âˆˆ K ,Î²âˆˆ KL such that for all x0âˆˆ {x0âˆˆRnx:âˆ¥x0âˆ¥2â‰¤Ïx}and any input
dtâˆˆ {dâˆˆRnd: suptâˆ¥dtâˆ¥âˆžâ‰¤Ï}, it holds that âˆ¥xtâˆ¥2â‰¤Î² 
âˆ¥x0âˆ¥2, t
+Î³ 
suptâˆ¥dtâˆ¥âˆž
for all
tâ‰¥0.5
Assumption 4 (LISS system) .System (1)is LISS with parameters ÏxandÏsuch that Ïxâ‰¥ âˆ¥x0âˆ¥2
andÏâ‰¥max( wmax, umax), respectively.
Assumption 4 is imposed, together with the bounded disturbances and inputs in Assumptions 2 and 3,
to guarantee bounded states during the control dynamics (for instance, see the proof of Theorem 1in
Appendix A). Notably, many studies on learning-based nonlinear control require certain boundedness
on the states for theoretical analysis Sattar and Oymak (2022); Foster et al. (2020); Li et al. (2023a).
In addition, it is interesting to note that this paper only requires local stability of the dynamics, whereas
several learning-based nonlinear control papers assume certain global properties, such as global
exponential stability in (Foster et al., 2020), global exponential incremental stability in (Sattar and
Oymak, 2022; Li et al., 2023a; Lin et al., 2024), or global Lipschitz smoothness in (Lee et al., 2024).6
This difference in the dynamics assumption reflects a trade-off with the disturbance assumptions:
we assume a stronger assumption on the boundedness of disturbances and a weaker assumption
5A function Î³:Râ‰¥0â†’Râ‰¥0is aKfunction if it is continuous, strictly increasing and Î³(0) = 0 . A function
Î²:Râ‰¥0Ã—Râ‰¥0â†’Râ‰¥0is aKLfunction if, for each fixed tâ‰¥0, the function Î²(Â·, t)is aKfunction, and for
each fixed sâ‰¥0, the function Î²(s,Â·)is decreasing and Î²(s, t)â†’0astâ†’ âˆž .
6Global Lipschitz smoothness may exclude system dynamics with higher-order polynomials.
5on local stability, whereas much of the literature considers (sub)Gaussian distributions (which can
be unbounded) but requires stronger global properties for dynamics. Since this paper is largely
motivated by physical systems, which typically encounter bounded disturbances/inputs and generally
only satisfy local stability (Slotine and Li, 1991), we address this trade-off through our current set of
assumptions, leaving it as an exciting future direction to consider relaxing these assumptions.
3 Main Results
In this section, we provide the estimation error bounds of LSE for linearly parameterized nonlinear
systems under i.i.d. random inputs. The estimation error bounds rely on the establishment of
probabilistic persistent excitation, which will be introduced in the first subsection. Later, we also
generalize the results to include control policies and discuss the convergence rate of another popular
uncertainty quantification method in the control literature, set membership estimation, whose formal
definition is deferred to the corresponding subsection.
3.1 Probabilistic Persistent Excitation
It is well-known that persistent excitation (PE) is a crucial condition for successful system identifi-
cation (Narendra and Annaswamy, 1987). In the following, we introduce the persistent excitation
condition for our linearly parameterized nonlinear systems.
Definition 3 (Persistent excitation (Skantze et al., 2000; Sastry and Bodson, 2011)) .System (1)is
persistently excited if there exist s >0andmâ‰¥1such that for any t0â‰¥0, we have
1
mt0+mâˆ’1X
t=t0Ï• 
xt, ut
Ï•âŠº 
xt, ut
âª°s2InÏ•.
In the stochastic setting, PE is closely related with a block-martingale small-ball (BMSB) condition
proposed in Simchowitz et al. (2018), which can be viewed as a probabilistic version of PE.
Definition 4 (BMSB (Simchowitz et al., 2018)) .Let{Ft}tâ‰¥1denote a filtration and let {yt}tâ‰¥1be
an{Ft}tâ‰¥1-adapted random process taking values in Rny. We say {yt}tâ‰¥1satisfies the (k,Î“sb, p)-
block martingale small-ball (BMSB) condition for a positive integer k, aÎ“sbâ‰»0, and a pâˆˆ[0,1],
if for any fixed vâˆˆRnysuch that âˆ¥vâˆ¥2= 1, the process {yt}tâ‰¥1satisfies1
kPk
i=1P 
|vâŠºyt+i| â‰¥âˆšvâŠºÎ“sbv| Ft
â‰¥palmost surely for any tâ‰¥1.
One major contribution of this paper is formally establishing the BMSB condition for linearly
parameterized nonlinear systems with real-analytic feature functions.
In the following, we first investigate the open-loop system with i.i.d. inputs and later extend the
results to the closed-loop systems with inputs ut=Ï€(xt) +Î·t, where Î·trepresents the noise and
Ï€:Rnxâ†’Rnudenotes a control policy. The following theorem considers the open-loop systems.
Theorem 1 (BMSB for open-loop systems) .Letut=Î·tand consider the filtration Ft=
F(w0,Â·Â·Â·, wtâˆ’1, x0,Â·Â·Â·, xt, Î·0,Â·Â·Â·, Î·t). Suppose Assumptions 1, 2, 3, 4 hold, then there ex-
istsÏ•>0andpÏ•âˆˆ(0,1)such that the {Ft}tâ‰¥1-adapted process
Ï• 
xt, ut	
tâ‰¥1satisfies the 
1, s2
Ï•InÏ•, pÏ•
-BMSB condition.
Proof Sketch. Intuitively, BMSB requires that any linear combination of feature functions remains
positive with a non-vanishing probability. Notice that a linear combination of real-analytic functions
is itself real-analytic, and the zeros of an analytic function have measure zero. These facts allow us to
show that the probability of a linear combination of linearly independent feature functions equaling
zero is less than one, as long as the noises follow semi-continuous distributions, by the connection of
the Lebesgue measure and the probability measure in Definition 1.
In more detail, the proof leverages a variant of the Paley-Zygmund argument (Petrov, 2007), which
provides a lower bound for the tail properties of positive random variables. Specifically, it states that
the probability of a positive random variable being small depends on the ratio of its even moments.
We apply this result to the random variable |vTÏ• 
xt+1, ut+1
| Ft|withâˆ¥vâˆ¥2= 1and aim to show
6that the lower bound is non-trivial for any direction vwithâˆ¥vâˆ¥2= 1and any filtration Ft,tâ‰¥0. We
then use results from measure theory to demonstrate the existence of such a non-trivial lower bound.
This is done by showing that the Lebesgue measure of the set where |vTÏ• 
xt+1, ut+1
|= 0is zero,
and thus the even moments of |vTÏ• 
xt+1, ut+1
| Ft|are non-zero, provided that the noise and
disturbance distributions are semi-continuous. For further details, please refer to Appendix A.
It is worth pointing out that Theorem 1 only establishes the existence of the constants (sÏ•, pÏ•),
and deriving explicit formulas of these constants are left for future work. In particular, it can be
challenging to derive a generic formula for all linearly parameterized nonlinear systems, but an
exciting direction is to study reasonable sub-classes of systems and construct their corresponding
formulas of the constants (sÏ•, pÏ•).
3.2 Non-asymptotic Bounds for LSE
We are now prepared to present the non-asymptotic convergence rate for the LSE in learning the
unknown parameters of the system (1).
Theorem 2 (LSEâ€™s convergence rate for open-loop systems) .Consider the dynamical system de-
scribed in (1) with i.i.d. inputs ut=Î·tand assume that Assumptions 1, 2, 3, 4 are satisfied. Let sÏ•
andpÏ•be as defined in Theorem 1, and define Â¯bÏ•= suptâ‰¥0E
âˆ¥Ï•(zt)âˆ¥2
2
. For a fixed Î´âˆˆ(0,1)and
Tâ‰¥1, ifTsatisfies the condition
Tâ‰¥10
pÏ•
log1
Î´
+ 2nÏ•log10
pÏ•
+nÏ•logÂ¯bÏ•
Î´s2
Ï•
,
then LSEâ€™s estimation Ë†Î¸Tsatisfies the following error bound with probability at least 1âˆ’3Î´.
Ë†Î¸Tâˆ’Î¸âˆ—
2â‰¤90Ïƒw
pÏ•vuuutnx+ log
1
Î´
+nÏ•log
10
pÏ•
+nÏ•log
Â¯bÏ•
Î´s2
Ï•
Ts2
Ï•.
The proof relies on Theorem 1 and Theorem 2.4 in (Simchowitz et al., 2018). The complete proof is
provided in Appendix B.1.
Theorem 2 demonstrates that LSE converges to the true parameters under random control inputs and
random disturbances (non-active exploration) at a rate of1âˆš
Tfor linearly parameterized nonlinear
systems. This is consistent with the convergence rates of LSE for linear systems in terms of T.
Regarding the dimension dependence in the convergence rate, the explicit dependence isâˆšnx+nÏ•,
where nxandnÏ•refer to the dimensions of the state and the feature vector, respectively. Besides, it is
worth mentioning that other parameters, such as sÏ•, pÏ•,Â¯bÏ•, may implicitly depend on the dimensions
as well. For some special systems, such as bilinear systems, it has been shown that these constants are
independent of the dimensions (Sattar et al., 2022). It is left as future work to explore other nonlinear
systemsâ€™ implicit dimension dependence.
Next, we can generalize the i.i.d. inputs utto include control policies, i.e., ut=Ï€(xt) +Î·t, where
Î·tsatisfies Assumption 3 and Ï€(xt)is analytic.
Corollary 1 (LSEâ€™s convergence rate for closed-loop systems) .Consider inputs ut=Ï€(xt) +
Î·t, where Ï€(Â·)is real-analytic, Î·tsatisfies Assumption 3, and the closed-loop system xt+1=
Î¸âˆ—Ï•(xt, Ï€(xt) +Î·t) +wtsatisfies Assumption 4 for both wtandÎ·t. Then, the same convergence
rate in Theorem 2 holds.
The proof is provided in Appendix B.2.
3.3 Non-asymptotic Diameter Bounds for SME
Set membership estimation (SME) is another popular method for uncertainty quantification in control
system estimation (Bertsekas, 1971; Fogel and Huang, 1982; Lu and Cannon, 2023; Li et al., 2024).
Unlike LSE, SME is a set-estimator and directly estimates the uncertainty set. Since the analysis
of SME also relies on the probabilistic persistent excitation analysis, we can also establish the
7convergence rate of SME for linearly parameterized nonlinear systems under i.i.d. noises in the
following. In particular, SME estimates the uncertainty set as
Î˜T=Tâˆ’1\
t=0
Ë†Î¸:xt+1âˆ’Ë†Î¸Ï•(xt, ut)âˆˆ W
, (3)
where Wis a bounded set such that wtâˆˆ W for all tâ‰¥0.
The convergence of SME relies on an additional assumption as shown below: the tightness of the
bound Wonwtâ€™s support. This tightness assumption is commonly considered in SMEâ€™s literature
(Li et al., 2024; Lu et al., 2019; AkÃ§ay, 2004). Further, (Li et al., 2024) discusses the relaxation of
this assumption by learning a tight bound at the same time of learning the uncertainty set of Î¸âˆ—for
linear systems. Similar tricks can be applied to nonlinear systems, but this paper only considers the
vanilla case of SME for simplicity.
Assumption 5 (Tight bound on disturbances) .Assume for any Ïµ >0, there exists qw(Ïµ)>0, such
that for any 1â‰¤jâ‰¤nandtâ‰¥0, we have P(wj
t+wmaxâ‰¤Ïµ)â‰¥qw(Ïµ)>0,P(wmaxâˆ’wj
tâ‰¤Ïµ)â‰¥
qw(Ïµ)>0.
Assumption 5 requires that wtcan visit set Wâ€™s boundary arbitrarily closely with a positive probability.
For example, for a one-dimensional wtbounded by âˆ’wmaxâ‰¤wtâ‰¤wmax, Assumption 5 requires
that there is a positive probability that wtis close to wmaxandâˆ’wmax, i.e., for any Ïµ >0, we have
P(wmaxâˆ’Ïµâ‰¤wtâ‰¤wmax)>0andP(âˆ’wmaxâ‰¤wtâ‰¤ âˆ’wmax+Ïµ)>0.
Next, we state a non-asymptotic bound on the diameter of the uncertainty set estimated by SME.
Theorem 3 (SMEâ€™s diameter bound for open-loop systems) .Consider system (1) with i.i.d. inputs
ut=Î·t. Suppose Assumptions 1, 2, 3, 4 are satisfied. Consider sÏ•andpÏ•defined in Theorem 1 and
letbÏ•= suptâ‰¥0âˆ¥Ï•(zt)âˆ¥2. For any mâ‰¥0andÎ´âˆˆ(0,1), when T > m , we have
P
diam(Î˜T)> Î´
â‰¤T
mËœO 
n2.5
Ï•
anÏ•
2exp(âˆ’a3m) + ËœO 
n2.5
xn2.5
Ï•
anxnÏ•
4
1âˆ’qwa1Î´
4âˆšnx T
m
,
where a1=sÏ•pÏ•
4,a2=64b2
Ï•
s2
Ï•p2
Ï•,a3=p2
Ï•
8,a4=16bÏ•âˆšnx
sÏ•pÏ•. The constants hidden in ËœOare provided in
the Appendix C.1.
The proof of Theorem 3 relies on Theorem 1 in this paper and Theorem 1 from (Li et al., 2024). The
detailed proof is provided in Appendix C.1.
Theorem 3 establishes an upper bound on the "failure" probability of SME, i.e., the probability that
the uncertainty setâ€™s diameter exceeds Î´. To ensure the failure probability is less than 1, one can select
m=O(log(T))and choose a sufficiently large Tsuch that Tâ‰¥m=O(log(T)). Ifwtis more
likely to visit the boundaries of the set W(meaning a larger q(â„“)), SME is less likely to estimate an
uncertainty set with a diameter greater than Î´.
To provide more intuitions on the diameter bound in Theorem 3, we consider qw(â„“) =cwâ„“for some
cw>0. Note that several common distributions, including the uniform distribution and the truncated
Gaussian distribution, satisfy this property on qw(â„“)(see Appendix C.2 for explicit formulas of cw).
With qw(â„“) =cwâ„“, we can provide a convergence rate of SME in terms of Tin the following.
Corollary 2 (SMEâ€™s convergence rate when qw(â„“) =cwâ„“).For any Ïµ >0, let
mâ‰¥O log T
Ïµ
+nÏ•log 8bÏ•
sÏ•pÏ•
p2
Ï•!
.
Ifwtâ€™s distribution satisfies qw(â„“) =cwâ„“for all â„“ >0, then when T > m with probability at least
1âˆ’2Ïµ, we have:
diam(Î˜T)â‰¤O mâˆšnxlog 1
Ïµ
+mn1.5
xnÏ•log bÏ•nx
sÏ•pÏ•
cwsÏ•pÏ•T!
,
where the constants hidden in O(Â·)are provided in Appendix C.
8The proof of Corollary 2 is provided in Appendix C.2.
Finally, similar to LSE, we can extend SMEâ€™s convergence rates from open-loop systems to closed-
loop systems with real-analytic control policies, i.e., ut=Ï€(xt) +Î·t, where Î·tsatisfies Assumption
3 and Ï€(xt)is real-analytic.
Corollary 3 (SMEâ€™s convergence rate for closed-loop systems) .Consider inputs ut=Ï€(xt) +
Î·t, where Ï€(Â·)is real-analytic, Î·tsatisfies Assumption 3, and the closed-loop system xt+1=
Î¸âˆ—Ï•(xt, Ï€(xt) +Î·t) +wtsatisfies Assumption 4 in terms of both wtandÎ·t. Then, the same
convergence rates in Theorem 3 and Corollary 2 still hold.
The proof of Corollary 3 is provided in Appendix C.3.
4 Numerical Experiments
In this section, we evaluate the performance of LSE in estimating the unknown parameter Î¸âˆ—and
SME in estimating the uncertainty set for the unknown parameters using the pendulum and quadrotor
examples outlined in Section 2. We compare the empirical convergence rates of LSE and SME with
the theoretical rates in Theorem 2 and Corollary 2. In each case, the input utis composed of a
control policy and i.i.d. noise, such that ut=Ï€(xt) +Î·t. For our experiments, we employ noise
and disturbances drawn from uniform and truncated-Gaussian distributions. To compute theoretical
rates, we numerically estimate parameters such as sÏ•andpÏ•(see Appendix E). Further details can be
found in our source code.7
The details for these scenarios are outlined below:
â€¢Pendulum 1: In the pendulum example described in Section 2, the control input is ut=
âˆ’kË™Î±t+Î·t. This scenario includes two unknown parameters: Î¸1=1
landÎ¸2=1
ml2.
â€¢Quadrotor 2: For the quadrotor example in Section 2, the control input is defined as
ut=Ï€(xt) +Î·t, where Ï€(xt)follows the controller proposed by Alaimo et al. (2013). The
quadrotor system involves 13states and 4inputs, with the unknown parameter matrix Î¸âˆ—
containing 7parameters, including the mass mand specific elements of the inertia matrix I.
Further details on controller gains and unknown parameters are provided in Appendix D.
LSE Results: Figures 1a and 1b present a comparison between the LSE theoretical bound from
Theorem 2 with its empirical estimation error of the unknown parameters Î¸âˆ—versus trajectory length
Tfor the pendulum example, with uniform and truncated-Gaussian noises and disturbances. Similarly,
Figures 1c and 1d show this comparison for the quadrotor example. In each figure, both the theoretical
bound and empirical error are normalized by the l2norm of the nominal parameter Î¸âˆ—. The log-log
plots for both scenarios demonstrate that the empirical error rate achieves O(1âˆš
T)which in consistent
with the theoretical rate in Theorem 2.
SME Results: Figures 2a and 2b show the empirical convergence rate of SME for the pendulum
example, for uniform and truncated-Gaussian noises and disturbances, in comparison to the theoretical
rate from Corollary 2. Both the theoretical bound and empirical error in the figures are normalized by
thel2norm of the nominal parameter Î¸âˆ—. The log-log plots indicate that the empirical rate achieves
O(1
T), which is consistent with the results from Corollary 2 and with the related results for linear
systems in (Li et al., 2024). A similar result can be observed for the quadrotor example, in Figures 2c
and 2d. Additionally, Figure 3 shows the uncertainty sets estimated by SME for the two unknown
parameters, labeled Î¸1andÎ¸2, in the pendulum example, along with the diameters of these sets as
trajectory length grows. We observe that these sets contract as trajectory length increases, with the
true values of the unknown parameters lying within the estimated uncertainty sets. The illustration of
uncertainty sets for the quadrotor example is provided in Appendix D.2.
7https://github.com/NeginMusavi/real-analytic-nonlinear-sys-id
9(a) Uniform
 (b) Truncated-Gaussian
 (c) Uniform
 (d) Truncated-Gaussian
Figure 1: Convergence rate of the LSE for pendulum and quadrotor scenarios: (a) Pendulum example with
uniform, (b) Pendulum example with truncated-Gaussian, (c) Quadrotor example with uniform, and (d) Quadrotor
example with truncated-Gaussian noises and disturbances. Here, uniform noises and disturbances are i.i.d.
generated from uniform ([âˆ’1,1]), and truncated-Gaussian noises and disturbances are i.i.d. generated from
truncated-Gaussian (0,0.1,[âˆ’1,1]). "theo" denotes the theoretical convergence rate, and "empr" represents
the empirical rate. The mean error across 20 trials is shown by dots on the empirical plots, with shaded areas
illustrating empirical standard deviation.
(a) Uniform
 (b) Truncated-Gaussian
 (c) Uniform
 (d) Truncated-Gaussian
Figure 2: Convergence rate of the SME for pendulum and quadrotor scenarios: (a) Pendulum example with
uniform, (b) Pendulum example with truncated-Gaussian, (c) Quadrotor example with uniform, and (d) Quadrotor
example with truncated-Gaussian noises and disturbances. Here, uniform noises and disturbances are i.i.d.
generated from uniform ([âˆ’1,1]), and truncated-Gaussian noises and disturbances are i.i.d. generated from
truncated-Gaussian (0,0.5,[âˆ’1,1]). "theo" denotes the theoretical convergence rate, and "empr" represents
the empirical rate. The mean error across 10 trials is shown by dots on the empirical plots, with shaded areas
illustrating empirical standard deviation.
5 Concluding Remarks
Conclusion. This study examines the probabilistic persistent excitation in a class of nonlinear systems
influenced by i.i.d. noise and stochastic disturbances, with the stipulation that their distributions do
not concentrate on sets of Lebesgue measure zero. Based on this we then present an explicit bound
on the convergence rate of SME estimations and LSE estimations for this class of dynamical systems.
Additionally, numerical experiments in the context of robotics are provided to illustrate both methods.
Limitations. One limitation of this work is that our analysis relies on a specific class of i.i.d. noises
and stochastic disturbances, where the probability distribution is not concentrated on sets of Lebesgue
measure zero. While this is a sufficient condition, it is possible that the BMSB conditions are satisfied
under other circumstances. Another limitation is that, though we provide sufficient conditions for the
existence of parameters satisfying the BMSB condition, the explicit dependence is not detailed here.
Lastly, imperfect observations are not considered here.
Future Work. Our future work includes several promising directions, e.g., to explore cases that do
not satisfy our semi-continuity assumption, such as discrete noises, and to investigate the explicit
dependence of the BMSB parameter on system attributes, such as state, input, and feature dimensions,
etc. Furthermore, extending this work to imperfect state observations is an important next step.
Finally, a potential direction is to provide a non-asymptotic analysis of the volumes of uncertainty
sets estimated by SME uncertainty sets, as opposed to the current focus on their diameters.
10(a) Pendulum (b) Uncertainty set diameter (c) Uncertainty set
Figure 3: Performance of SME for pendulum in (a) with control input ut=âˆ’kË™Î±t+Î·twhere k= 0.1,
Î·ti.i.d. generated from truncated-Gaussian (0,2,[âˆ’2,2])and disturbed with wti.i.d. generated from
truncated-Gaussian (0,1,[âˆ’1,1]). (b) Diameter of the uncertainty set estimated by SME. (c) Uncertainty
set depicted for T= 50,200,250,400,500.
Broader Impact
This paper is a foundation research and develops theoretical insight to estimation of nonlinear control
systems. We do not see a direct path to negative applications in general. But we want to mention that
successful applications of our theoretical results rely on verifying the assumptions in this paper.
References
Yasin Abbasi-Yadkori and Csaba SzepesvÃ¡ri. Regret bounds for the adaptive control of linear
quadratic systems. In Proceedings of the 24th Annual Conference on Learning Theory , pages 1â€“26.
JMLR Workshop and Conference Proceedings, 2011.
HÃ¼seyin AkÃ§ay. The size of the membership-set in a probabilistic framework. Automatica , 40(2):
253â€“260, 2004.
Andrea Alaimo, Valeria Artale, C Milazzo, Angela Ricciardello, and LUCA Trefiletti. Mathematical
modeling and control of a hexacopter. In 2013 International conference on unmanned aircraft
systems (ICUAS) , pages 1043â€“1050. IEEE, 2013.
Er-Wei Bai, Roberto Tempo, and Hyonyong Cho. Membership set estimators: size, optimal inputs,
complexity and relations with least squares. IEEE Transactions on Circuits and Systems I:
Fundamental Theory and Applications , 42(5):266â€“277, 1995.
Er-Wei Bai, Hyonyong Cho, and Roberto Tempo. Convergence properties of the membership set.
Automatica , 34(10):1245â€“1249, 1998.
Dimitri P Bertsekas. Control of uncertain systems with a set-membership description of the uncertainty.
PhD thesis, Massachusetts Institute of Technology, 1971.
Vladimir Igorevich Bogachev and Maria Aparecida Soares Ruas. Measure theory , volume 1. Springer,
2007.
Xinyi Chen and Elad Hazan. Black-box control for linear dynamical systems. In Conference on
Learning Theory , pages 1114â€“1143. PMLR, 2021.
Alexandru Cr Ë˜aciun and Debarghya Ghoshdastidar. On the stability of gradient descent for large
learning rate. arXiv preprint arXiv:2402.13108 , 2024.
Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht, and Stephen Tu. Regret bounds for robust
adaptive control of the linear quadratic regulator. Advances in Neural Information Processing
Systems , 31:4188â€“4197, 2018.
Eli Fogel and Yih-Fang Huang. On the value of information in system identificationâ€”bounded noise
case. Automatica , 18(2):229â€“238, 1982.
11Dylan Foster, Tuhin Sarkar, and Alexander Rakhlin. Learning nonlinear dynamical systems from a
single trajectory. In Learning for Dynamics and Control , pages 851â€“861. PMLR, 2020.
Yihuai Gao, Yukai Tang, Han Qi, and Heng Yang. Closure: Fast quantification of pose uncertainty
sets. arXiv preprint arXiv:2403.09990 , 2024.
Paul R Halmos. Measure theory , volume 18. Springer, 2013.
Mohammad Khosravi. Representer theorem for learning koopman operators. IEEE Transactions on
Automatic Control , 2023.
Jihun Kim and Javad Lavaei. Online bandit control with dynamic batch length and adaptive learning
rate. 2024.
Jason Kong, Mark Pfeiffer, Georg Schildbach, and Francesco Borrelli. Kinematic and dynamic vehicle
models for autonomous driving control design. In 2015 IEEE intelligent vehicles symposium (IV) ,
pages 1094â€“1099. IEEE, 2015.
Suhas Kowshik, Dheeraj Nagaraj, Prateek Jain, and Praneeth Netrapalli. Near-optimal offline and
streaming algorithms for learning non-linear dynamical systems. Advances in Neural Information
Processing Systems , 34:8518â€“8531, 2021.
Steven G Krantz and Harold R Parks. A primer of real analytic functions . Springer Science &
Business Media, 2002.
Bruce D Lee, Ingvar Ziemann, George J Pappas, and Nikolai Matni. Active learning for control-
oriented identification of nonlinear systems. arXiv preprint arXiv:2404.09030 , 2024.
Yingying Li, Subhro Das, and Na Li. Online optimal control with affine constraints. In Proceedings
of the AAAI Conference on Artificial Intelligence , volume 35, pages 8527â€“8537, 2021a.
Yingying Li, Yujie Tang, Runyu Zhang, and Na Li. Distributed reinforcement learning for decentral-
ized linear quadratic control: A derivative-free policy optimization approach. IEEE Transactions
on Automatic Control , 67(12):6429â€“6444, 2021b.
Yingying Li, James A Preiss, Na Li, Yiheng Lin, Adam Wierman, and Jeff S Shamma. Online
switching control with stability and regret guarantees. In Learning for Dynamics and Control
Conference , pages 1138â€“1151. PMLR, 2023a.
Yingying Li, Tianpeng Zhang, Subhro Das, Jeff Shamma, and Na Li. Non-asymptotic system
identification for linear systems with nonlinear policies. IFAC-PapersOnLine , 56(2):1672â€“1679,
2023b.
Yingying Li, Jing Yu, Lauren Conger, Taylan Kargin, and Adam Wierman. Learning the uncertainty
sets of linear control systems via set membership: A non-asymptotic analysis. In Proceedings of
the 41st International Conference on Machine Learning , pages 29234â€“29265. PMLR, 2024. URL
https://proceedings.mlr.press/v235/li24ci.html .
Yiheng Lin, James A Preiss, Emile Anand, Yingying Li, Yisong Yue, and Adam Wierman. On-
line adaptive policy selection in time-varying systems: No-regret via contractive perturbations.
Advances in Neural Information Processing Systems , 36, 2024.
Matthias Lorenzen, Mark Cannon, and Frank AllgÃ¶wer. Robust mpc with recursive model update.
Automatica , 103:461â€“471, 2019.
Xiaonan Lu and Mark Cannon. Robust adaptive model predictive control with persistent excitation
conditions. Automatica , 152:110959, 2023.
Xiaonan Lu, Mark Cannon, and Denis Koksal-Rivet. Robust adaptive model predictive control:
Performance and parameter estimation. International Journal of Robust and Nonlinear Control ,
2019.
Horia Mania, Michael I Jordan, and Benjamin Recht. Active learning for nonlinear system identifica-
tion with guarantees. Journal of Machine Learning Research , 23(32):1â€“30, 2022.
12Kumpati S Narendra and Anuradha M Annaswamy. Persistent excitation in adaptive systems.
International Journal of Control , 45(1):127â€“160, 1987.
Bernd R Noack, Konstantin Afanasiev, Marek Morzy Â´nski, Gilead Tadmor, and Frank Thiele. A
hierarchy of low-dimensional models for the transient and post-transient cylinder wake. Journal of
Fluid Mechanics , 497:335â€“363, 2003.
Valentin V Petrov. On lower bounds for tail probabilities. Journal of statistical planning and
inference , 137(8):2703â€“2705, 2007.
Arnab Sarker, Peter Fisher, Joseph E Gaudio, and Anuradha M Annaswamy. Accurate parameter
estimation for safety-critical systems with unmodeled dynamics. Artificial Intelligence , page
103857, 2023.
Shankar Sastry and Marc Bodson. Adaptive control: stability, convergence and robustness . Courier
Corporation, 2011.
Yahya Sattar and Samet Oymak. Non-asymptotic and accurate learning of nonlinear dynamical
systems. Journal of Machine Learning Research , 23(140):1â€“49, 2022.
Yahya Sattar, Samet Oymak, and Necmiye Ozay. Finite sample identification of bilinear dynamical
systems. In 2022 IEEE 61st Conference on Decision and Control (CDC) , pages 6705â€“6711. IEEE,
2022.
Guanya Shi, Kamyar Azizzadenesheli, Michael Oâ€™Connell, Soon-Jo Chung, and Yisong Yue. Meta-
adaptive nonlinear control: Theory and algorithms. Advances in Neural Information Processing
Systems , 34:10013â€“10025, 2021.
B. Siciliano, L. Sciavicco, L. Villani, and G. Oriolo. Robotics: Modelling, Planning and Con-
trol. Advanced Textbooks in Control and Signal Processing. Springer London, 2010. ISBN
9781846286414. URL https://books.google.com/books?id=jPCAFmE-logC .
Max Simchowitz and Dylan Foster. Naive exploration is optimal for online lqr. In International
Conference on Machine Learning , pages 8937â€“8948. PMLR, 2020.
Max Simchowitz, Horia Mania, Stephen Tu, Michael I Jordan, and Benjamin Recht. Learning without
mixing: Towards a sharp analysis of linear system identification. In Conference On Learning
Theory , pages 439â€“473. PMLR, 2018.
John W Simpson-Porco, Florian DÃ¶rfler, and Francesco Bullo. V oltage stabilization in microgrids via
quadratic droop control. IEEE Transactions on Automatic Control , 62(3):1239â€“1253, 2016.
Fredrik P Skantze, A Koji Â´c, A-P Loh, and Anuradha M Annaswamy. Adaptive estimation of
discrete-time systems with nonlinear parameterization. Automatica , 36(12):1879â€“1887, 2000.
Jean-Jacques E Slotine and Weiping Li. Applied nonlinear control , volume 199. Prentice hall
Englewood Cliffs, NJ, 1991.
Yukai Tang, Jean-Bernard Lasserre, and Heng Yang. Uncertainty quantification of set-membership
estimation in control and perception: Revisiting the minimum enclosing ellipsoid. In 6th Annual
Learning for Dynamics & Control Conference , pages 286â€“298. PMLR, 2024.
Andrew Wagenmaker and Kevin Jamieson. Active learning for identification of linear dynamical
systems. In Conference on Learning Theory , pages 3487â€“3582. PMLR, 2020.
Haonan Xu and Yingying Li. On the convergence rates of set membership estimation of linear
systems with disturbances bounded by general convex sets. arXiv preprint arXiv:2406.00574 ,
2024.
Christopher Yeh, Jing Yu, Yuanyuan Shi, and Adam Wierman. Online learning for robust voltage
control under uncertain grid topology. IEEE Transactions on Smart Grid , 2024.
Jing Yu, Dimitar Ho, and Adam Wierman. Online adversarial stabilization of unknown networked
systems. Proceedings of the ACM on Measurement and Analysis of Computing Systems , 7(1):1â€“43,
2023.
13Ingvar Ziemann and Stephen Tu. Learning with little mixing. Advances in Neural Information
Processing Systems , 35:4626â€“4637, 2022.
Ingvar Ziemann, Anastasios Tsiamis, Bruce Lee, Yassir Jedra, Nikolai Matni, and George J Pappas.
A tutorial on the non-asymptotic theory of system identification. In 2023 62nd IEEE Conference
on Decision and Control (CDC) , pages 8921â€“8939. IEEE, 2023.
Ingvar Ziemann, Stephen Tu, George J Pappas, and Nikolai Matni. Sharp rates in dependent learning
theory: Avoiding sample size deflation for the square loss. arXiv preprint arXiv:2402.05928 , 2024.
14Appendix
Roadmap
â€¢ Appendix A provides a proof of Theorem 1.
â€¢ Appendix B provides proofs of Theorem 2 and Corollary 1.
â€¢ Appendix C presents a proof of Theorem 3 and Corollaries 2 and 3.
â€¢ Appendix D provides more details of the simulation settings.
â€¢Appendix E discusses the numerical estimation of the BMSB parameters (sÏ•, pÏ•)in Theo-
rem 1.
â€¢ The NeurIPS Paper Checklist is provided after the appendices.
A Proof Theorem 1
Proof. Given that ut=Î·tand satisfies the conditions in Assumption 3, utis bounded, meaning
utâˆˆ U, where Uis a compact set. Moreover, since the system is LISS, there exist functions Î³âˆˆ K
andÎ²âˆˆ KL , such that for all tâ‰¥0, the following holds:
xtâˆˆ X=
xâˆˆRn:âˆ¥xâˆ¥2â‰¤Î²(Ïx,0) +Î³(Ï)
with parameters Ïxâ‰¥ âˆ¥x0âˆ¥2andÏâ‰¥max( wmax, umax). LetZ=X Ã—U , then ztâˆˆ Z for all tâ‰¥0.
The set Zis a compact subset of Rnx+nu.
To show that the {Ft}tâ‰¥1-adapted process {Ï•(zt)}tâ‰¥1satisfies the BMSB condition, it is sufficient
to demonstrate that there exist sÏ•>0andpÏ•âˆˆ(0,1)such that for all tâ‰¥0and for any vâˆˆRnÏ•
withâˆ¥vâˆ¥2= 1, the following holds:
P
|vTÏ•(zt+1)| â‰¥sÏ•âˆ¥vâˆ¥2Ft
â‰¥pÏ•. (4)
To establish this, we apply the Paley-Zygmund inequality, which gives a lower bound on the tail
probability of a non-negative random variable:
Lemma 1. (Paley-Zygmund (Petrov, 2007)) Let xbe a non-negative random variable. Then for any
râˆˆ(0,1), the following holds:
P
x > rp
E[x2]
â‰¥(1âˆ’r2)2E[x2]2
E[x4].
Based on this result, for any râˆˆ(0,1), we have:
P 
vâŠºÏ•(zt+1)> rs
E 
vâŠºÏ•(zt+1)2FtFt!
â‰¥(1âˆ’r2)2E 
vâŠºÏ•(zt+1)2Ft2
E 
vâŠºÏ•(zt+1)4Ft.(5)
LetV={vâˆˆRnÏ•:âˆ¥vâˆ¥2= 1}. To show that the BMSB condition holds, it is sufficient to establish
the following two points:
â€¢inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ•(zt+1)2Ft
>0,
â€¢ and sup
Ft, tâ‰¥0sup
vâˆˆVE 
vâŠºÏ•(zt+1)4Ft
<âˆž.
15These conditions ensure that the {Ft}tâ‰¥1-adapted process {Ï•(zt)}tâ‰¥1satisfies the BMSB condition
with some constants sÏ•>0andpÏ•âˆˆ(0,1). We will divide the proof into two parts:
Step 1. Showing that inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ•(zt+1)2Ft
>0:
We begin by noting the following:
inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ•(zt+1)2Ft
= inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ• 
xt+1, ut+12Ft
= inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ• 
Î¸âˆ—Ï•(zt) +wt, ut+12Ft
.
Since ztâˆˆ Ftwhile wt, ut+1Ì¸âˆˆ Ft, we can treat ztas a constant and wt, ut+1=Î·t+1as random
variables. From the continuity of features Ï•(Â·), we can conclude that:
inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ•(zt+1)2Ft
= inf
zâˆˆZinf
vâˆˆVE 
vâŠºÏ• 
Î¸âˆ—Ï•(z) +w|{z}
=: h(z,w), Î·2
,
where w,Î·are independent random variables, as assumed in Assumptions 2 and 3. Now, let
Nz
v=
(w, Î·)âˆˆ W Ã— U :vâŠºÏ• 
h(z, w), Î·
= 0	
, and we have:
E 
vâŠºÏ• 
h(z, w), Î·2
=E 
vâŠºÏ• 
h(z, w), Î·21
vâŠºÏ• 
h(z, w), Î·
= 0	
| {z }
=0
+E 
vâŠºÏ• 
h(z, w), Î·21
vâŠºÏ• 
h(z, w), Î·
Ì¸= 0	
=E 
vâŠºÏ• 
h(z, w), Î·2(w, Î·)Ì¸âˆˆ Nz
v
P
(w, Î·)Ì¸âˆˆ Nz
v
=E 
vâŠºÏ• 
h(z, w), Î·2(w, Î·)Ì¸âˆˆ Nz
v
1âˆ’P
(w, Î·)âˆˆ Nz
v
.
Therefore, we have:
inf
zâˆˆZinf
vâˆˆVE 
vâŠºÏ• 
h(z, w), Î·2
= inf
zâˆˆZinf
vâˆˆVE 
vâŠºÏ• 
h(z, w), Î·2(w, Î·)Ì¸âˆˆ Nz
v
Ã—
1âˆ’sup
zâˆˆZsup
vâˆˆVP
(w, Î·)âˆˆ Nz
v
.(6)
It is evident that if Nz
v=âˆ…, then
inf
zâˆˆZinf
vâˆˆVE 
vâŠºÏ• 
h(z, w), Î·2
Ì¸= 0,andsup
zâˆˆZsup
vâˆˆVP
(w, Î·)âˆˆ Nz
v
= 0,
leading to inf
zâˆˆZinf
vâˆˆVE 
vâŠºÏ• 
h(z, w), Î·2
>0. Now we proceed with the case where Nz
vÌ¸=âˆ….
For this, we can use the following lemma concerning the zero set of real-analytic functions in terms
of Lebesgue measure.
Lemma 2 (The zero set of real-analytic functions (Cr Ë˜aciun and Ghoshdastidar, 2024)) .The set of
zeros of a non-trivial real-analytic function f:Rnâ†’Rhas a Lebesgue measure zero in Rn.
This is a known result and can be proved using the identity theorem along with Fubiniâ€™s theorem. For
further information on this topic, see sources such as (Krantz and Parks, 2002; Bogachev and Ruas,
2007).
Recall that we defined h(z, w) =Î¸âˆ—Ï•(z) +w. Notice that h(Â·,Â·)is real-analytic. Now consider
vâŠºÏ• 
h(z, w), Î·
=nÏ•X
i=1viÏ•i 
h(z, w), Î·
,
16where Ï•i 
h(z, w), Î·
are linearly independent. Hence, the sumPnÏ•
i=1viÏ•i 
h(z, w), Î·
Ì¸â‰¡0for any
vâˆˆ V. This implies that vâŠºÏ• 
h(z, w), Î·
is real-analytic and non-zero. Consequently, by Lemma 2,
Î»nx+nu(Nz
v) = 0 for any vâˆˆ V.
Under Assumptions 3 and 2, there cannot exist a set E âŠ‚ Z of Lebesgue measure zero in Rnx+nufor
which the P 
(w, Î·)âˆˆ E
= 1. Taking this into account, along with the fact that Î»nx+nu(Nz
v) = 0
and that the sets VandZare closed sets (implying they include all their limit points), we can conclude
that
sup
zâˆˆZsup
vâˆˆVP
(w, Î·)âˆˆ Nz
v
Ì¸= 1.
Moreover, since Î»nx+nu(Nz
v) = 0 andÎ»nx+nu(W Ã— U )Ì¸= 0, it follows that (Nz
v)cÌ¸=âˆ…. This
implies
inf
zâˆˆZinf
vâˆˆVE 
vâŠºÏ• 
h(z, w), Î·2(w, Î·)Ì¸âˆˆ Nz
v
Ì¸= 0.
Substituting these results into (6), we obtain:
inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ•(zt+1)2Ft
>0.
Step 2. Showing that sup
Ft, tâ‰¥0sup
vâˆˆVE 
vâŠºÏ•(zt+1)4Ft
<âˆž:
Since ztâˆˆ Z fortâ‰¥0, and considering that the noise and disturbances are bounded while the
features are real-analytic, it follows that zt+1|Ftis a bounded random variable. Consequently,
vâŠºÏ•(zt+1)|Ftis also bounded. Given that both ZandVare compact setsâ€”meaning they contain
all their limit pointsâ€”and that any random variable with bounded support has finite moments, we
conclude that
sup
Ft, tâ‰¥0sup
vâˆˆVE 
vâŠºÏ•(zt+1)4Ft
<âˆž.
We finalize the proof by combining the results from Step 1 and Step 2.
B Proofs for Theorem 2 and Corollary 1
B.1 Proof of Theorem 2
Proof. The proof hinges on the following key meta-theorem about the LSE convergence rate:
Theorem 4 (LSE meta-theorem (Simchowitz et al., 2018)) .FixÎ´âˆˆ(0,1),Tâ‰¥1, and 0â‰ºÎ“sbâ‰ºÂ¯Î“.
Consider a random process {(yt, xt)}tâ‰¥1âˆˆ(RnyÃ—Rnx)T, and a filtration {Ft}tâ‰¥1. Suppose the
following conditions hold:
â€¢xt=Î¸âˆ—yt+wt, where wt|Ftis a zero mean Ïƒ2
w-sub-Gaussian,
â€¢{yt}tâ‰¥1is an{Ft}tâ‰¥1-adapted random process satisfying the (k,Î“sb, p)-BMSB condition,
â€¢P PT
t=1ytyâŠº
tÌ¸âª¯TÂ¯Î“
â‰¤Î´.
If the trajectory length Tsatisfies
Tâ‰¥10k
p2 
log1
Î´
+ log det
Â¯Î“Î“âˆ’1
sb
+ 2nylog10
p!
,
then with probability at least 1âˆ’3Î´, LSE estimation error is bounded by:
Ë†Î¸Tâˆ’Î¸âˆ—
2â‰¤90Ïƒw
pvuuutnx+ log
1
Î´
+ log det
Â¯Î“Î“âˆ’1
sb
+nylog
10
p
TÏƒmin(Î“sb).
17Since wtsatisfies the Assumption 2), and wt/âˆˆ Ft, then Ïƒw|Ftis sub-Gaussian with parameter Ïƒw.
Additionally, system (1) is linear in unknown parameters Î¸âˆ—. From Theorem 1, the {Ft}tâ‰¥1-adapted
process {Ï•(zt)}tâ‰¥1satisfies the (1, s2
Ï•InÏ•, pÏ•)-BMSB condition for some sÏ•>0andpÏ•âˆˆ(0,1].
To complete the proof, it is left to show that for any Î´âˆˆ(0,1), there exists a Â¯Î“â‰»s2
Ï•InÏ•, such that
PTX
t=1Ï•(zt)Ï•âŠº(zt)âª¯Ì¸TÂ¯Î“
â‰¤Î´.
To see this, note that for Â¯bÏ•= suptâ‰¥0E
âˆ¥Ï•(zt)âˆ¥2
2
, we have:
PTX
t=1Ï•(zt)Ï•âŠº(zt)âª¯Ì¸Â¯bÏ•T
Î´InÏ•
=P 
Î»maxTX
t=1Ï•(zt)Ï•âŠº(zt)
â‰»Î»maxÂ¯bÏ•T
Î´InÏ•!
=PTX
t=1Ï•(zt)Ï•âŠº(zt)
2â‰»Â¯bÏ•T
Î´
â‰¤Î´EPT
t=1Ï•(zt)Ï•âŠº(zt)
2
Â¯bÏ•T.
In addition, we have:
ETX
t=1Ï•(zt)Ï•âŠº(zt)
2
â‰¤TX
t=1EÏ•(zt)Ï•âŠº(zt)
2
â‰¤TX
t=1E
âˆ¥Ï•(zt)âˆ¥2
2
â‰¤Tsup
tâ‰¥0E
âˆ¥Ï•(zt)âˆ¥2
2
,
which implies that:
PTX
t=1Ï•(zt)Ï•âŠº(zt)âª¯Ì¸TÂ¯Î“
â‰¤Î´, (7)
where Â¯Î“ =Â¯bÏ•
Î´InÏ•. since ztâˆˆ Z for all tâ‰¥0, withZbeing a compact set (due to the systemâ€™s LISS
property and features Ï•(Â·)being real-analytic), such a bounded Â¯bÏ•exists, completing the proof.
B.2 Proof of Corollary 1
Proof. We start the proof by stating the following lemma which is extension of Theorem 1 to the case
withut=Ï€(xt) +Î·t.
Lemma 3. Letut=Ï€(xt)+Î·t,Ï€(Â·)is real-analytic, Î·tsatisfies Assumption 3. Consider the filtration
Ft=F(w0,Â·Â·Â·, wtâˆ’1, x0,Â·Â·Â·, xt, Ï€(x0),Â·Â·Â·, Ï€(xt), Î·0,Â·Â·Â·, Î·t). Suppose Assumptions 1, 2 hold
and that the closed-loop system xt+1=Î¸âˆ—Ï•(xt, Ï€(xt) +Î·t) +wtsatisfies Assumption 4 for both
wtandÎ·t. Then there exist sÏ•>0, and pÏ•âˆˆ(0,1)such that the {Ft}tâ‰¥1-adapted process
Ï• 
xt, ut	
tâ‰¥1satisfies the 
1, s2
Ï•InÏ•, pÏ•
-BMSB condition.
Proof of Lemma 3. The proof closely follows the steps of Theorem 1. First, observe that ut=
Ï€(xt) +Î·t. Since Î·tsatisfies the conditions outlined in Assumption 3, and the closed-loop system
xt+1=Î¸âˆ—Ï•(xt, Ï€(xt) +Î·t) +wtadheres to Assumption 4 with respect to both wtandÎ·t, there
exist functions Î³âˆˆ K andÎ²âˆˆ KL such that for all tâ‰¥0the following holds:
xtâˆˆ X=
xâˆˆRn:âˆ¥xâˆ¥2â‰¤Î²(Ïx,0) +Î³(Ï)
with parameters Ïxâ‰¥ âˆ¥x0âˆ¥2andÏâ‰¥max( wmax, umax). LetZ=X Ã— U , where Uis a compact set
containing utfor all tâ‰¥0. Thus, ztâˆˆ Z for all tâ‰¥0. The set Zis a compact subset of Rnx+nu.
The remaining part of the proof, specifically to show that sup
Ft, tâ‰¥0sup
vâˆˆVE 
vâŠºÏ•(zt+1)4Ft
<âˆž
follows similarly to the proof in Theorem 1.
18It remains to show that inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ•(zt+1)2Ft
>0. This can be shown as follows:
inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ•(zt+1)2Ft
= inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ• 
xt+1, ut+12Ft
= inf
Ft, tâ‰¥0inf
vâˆˆVE
vâŠºÏ• 
xt+1, Ï€(xt+1) +Î·t+12Ft
= inf
Ft, tâ‰¥0inf
vâˆˆVE
vâŠºÏ•
Î¸âˆ—Ï•(zt) +wt,
Ï€ 
Î¸âˆ—Ï•(zt) +wt
+Î·t+12Ft
.
Since ztâˆˆ Ftandwt, Î·t+1Ì¸âˆˆ Ftthenztis treated as constant while wt, Î·t+1are considered random
variables. Then, by the continuity of Ï•we conclude that
inf
Ft, tâ‰¥0inf
vâˆˆVE 
vâŠºÏ•(zt+1)2Ft
= inf
zâˆˆZinf
vâˆˆVE
vâŠºÏ•
Î¸âˆ—Ï•(z) +w|{z}
=: h(z,w), Ï€ 
Î¸âˆ—Ï•(z) +w|{z}
=: h(z,w)
+Î·2
= inf
zâˆˆZinf
vâˆˆVE
vâŠºÏ•
h(z, w), Ï€ 
h(z, w)
+Î·2
where wandÎ·are independent random variables constrained as described in Assumptions 2 and 3.
By letting Nz
v=
(w, Î·)âˆˆ W Ã— U :vâŠºÏ• 
h(z, w), Ï€ 
h(z, w)
+Î·
= 0	
, similar to (6) we have:
inf
zâˆˆZinf
vâˆˆVE
vâŠºÏ•
h(z, w),Ï€ 
h(z, w)
+Î·2
= inf
zâˆˆZinf
vâˆˆVE
vâŠºÏ•
h(z, w), Ï€ 
h(z, w)
+Î·2(w, u)Ì¸âˆˆ Nz
v
Ã—
1âˆ’sup
zâˆˆZsup
vâˆˆVP
(w, Î·)âˆˆ Nz
v
.
We aim to show that Î»nx+nu(Nz
v) = 0 by applying Lemma 2. Note that Ï•(Â·),h(Â·), andÏ€(Â·)are real-
analytic. To use the results of Lemma 2, we need to establish that vâŠºÏ•
h(z, w), Ï€ 
h(z, w)
+Î·
is
non-zero for any vâˆˆ V. First, observe that:
vâŠºÏ• 
h(z, w), Ï€(h(z, w)) +Î·
=nÏ•X
i=1viÏ•i 
h(z, w), Ï€(h(z, w)) +Î·)
.
Now consider two scenarios:
â€¢ All components of Ï€ 
h(z, w)
are linearly independent with any component of h(z, w).
â€¢At least one component of Ï€ 
h(z, w)
is linearly dependent with one or more components
ofh(z, w).
In both cases, due to the additive nature of Î·, all the functions Ï•i 
h(z, w), Ï€(h(z, w)) +Î·)
with
i= 1,Â·Â·Â·, nÏ•are linearly independent, ensuring that vâŠºÏ• 
h(z, w), Ï€(h(z, w)) +Î·
Ì¸â‰¡0for any
vâˆˆ V. The remainder of the proof follows similarly to the argument in Theorem 1.
Using this Lemma, Theorem 4, and reasoning similar to that in the proof of Theorem 2, the proof can
be completed.
19C Proofs for Theorem 3, Corollary 2, and Corollary 3
C.1 Proof of Theorem 3
Proof. The proof follows from applying the following meta-theorem on the convergence rate of SME.
Theorem 5 (SME meta-theorem (Li et al., 2024)) .Consider a general time series model with linear
responses as follows:
xt=Î¸âˆ—yt+wt, tâ‰¥0.
Also, define the filtration Ft=F(w0,Â·Â·Â·, wtâˆ’1, y0,Â·Â·Â·, yt). Assume the following conditions are
met:
â€¢wtare i.i.d. with variance Ïƒ2
wInx, and box-constrained, i.e., wtâˆˆ W ={wâˆˆRnx:
âˆ¥wâˆ¥âˆžâ‰¤wmax}for some wmax>0.
â€¢{yt}tâ‰¥1is an{Ft}tâ‰¥1-adapted random process satisfying the (k, s2
yIny, py)-BMSB condi-
tion.
â€¢There exists by>0such that âˆ¥ytâˆ¥2â‰¤byalmost surely for all tâ‰¥0.
â€¢For any â„“ >0, there exists qw(â„“)>0, such that for any 1â‰¤jâ‰¤nandtâ‰¥0, we have
P(wj
t+wmaxâ‰¤â„“)â‰¥qw(â„“)>0,P(wmaxâˆ’wj
tâ‰¤â„“)â‰¥qw(â„“)>0.
Then for any mâ‰¥1and any Î´âˆˆ(0,1), when T > m , the diameter of the uncertainty set
Î˜T=Tâˆ’1\
t=0
Ë†Î¸:xtâˆ’Ë†Î¸ytâˆˆ W
satisfies:
P
diam(Î˜T)> Î´
â‰¤544T
mn2.5
ylog(a2ny)any
2exp(âˆ’a3m)
+ 544 n2.5
xn2.5
ylog(a4nxny)anxny
4
1âˆ’qwa1Î´
4âˆšnxâŒˆT/mâŒ‰
,
where a1=sypy
4,a2=64b2
y
s2yp2y,a3=p2
y
8,a4= max
4byâˆšnx
a1,1
.
Observe that system (1) is linear in the unknown parameters Î¸âˆ—, and we can prove Theorem 3
by showing that the {Ft}tâ‰¥1-adapted process {Ï•(zt)}tâ‰¥1andwtmeet the conditions of the meta-
theorem. By Assumptions 2 and 5, and since wtÌ¸âˆˆ Ft, the noise wtfulfills all the requirements of the
meta-theorem. Moreover, according to Theorem 1, the {Ft}tâ‰¥1-adapted process Ï•(zt)tâ‰¥1satisfies
the(1, s2
Ï•InÏ•, pÏ•)-BMSB condition for some sÏ•>0andpÏ•âˆˆ(0,1]. Lastly, since the system is
LISS, we have ztâˆˆ Z for all tâ‰¥0, where Zis the compact set defined in the proof of Theorem 1.
Therefore, there exists a constant bÏ•>0such that suptâ‰¥0âˆ¥Ï•(zt)âˆ¥2â‰¤bÏ•, completing the proof of
the theorem.
Explicitly, this means that for any mâ‰¥1, for any Î´âˆˆ(0,1), when T > m , we have:
P
diam(Î˜T)> Î´
â‰¤544T
mn2.5
Ï•log(a2nÏ•)anÏ•
2exp(âˆ’a3m)
+ 544 n2.5
xn2.5
Ï•log(a4nxnÏ•)anxnÏ•
4
1âˆ’qwa1Î´
4âˆšnxâŒˆT/mâŒ‰
,(8)
where a1=sÏ•pÏ•
4,a2=64b2
Ï•
s2
Ï•p2
Ï•,a3=p2
Ï•
8,a4=16bÏ•âˆšnx
sÏ•pÏ•.
20C.2 Proof of Corollary 2
Let us provide two example distributions, truncated Gaussian and uniform, along with their corre-
sponding qw(Â·)(from (Li et al., 2024)):
â€¢Ifwtfollows a uniform distribution on [âˆ’wmax, wmax]nx, then qw(â„“) =cwâ„“withcw=
1
2wmax.
â€¢Ifwtfollows a truncated-Gaussian distribution on [âˆ’wmax, wmax]nx, generated by a Gaus-
sian distribution with zero mean and covariance matrix Ïƒ2
wInx, then qw(â„“) =cwâ„“with
cw=1
min(âˆš
2Ï€Ïƒw,2wmax)exp(âˆ’w2
max
2Ïƒ2w).
Now, fix Ïµâˆˆ(0,1). We want to show that if q a1Î´
4âˆšnÏ•
=cwa1Î´
4âˆšnÏ•and we choose mâ‰¥1such that
mâ‰¥1
a3
logT
Ïµ
+nÏ•log(a2) + 2.5 log( nÏ•) + log log( a2nÏ•) + log(544)
, (9)
then for all Tâ‰¥m, we have
Î´â‰¤O âˆšnxlog 1
Ïµ
+n1.5
xnÏ•log bÏ•âˆšnx
sÏ•pÏ•
cwsÏ•pÏ•T!
(10)
with probability at least 1âˆ’2Ïµ.
Let the two terms in right hand-side of (8)be denoted by "term 1" and "term 2". We proceed with the
proof in two steps as follows:
Step 1: showing that with choice of min(9), term 1 â‰¤Ïµ:
With this choice of m, it is straightforward to see that
544Tn2.5
Ï•log(a2nÏ•)anÏ•
2exp(âˆ’a3m)â‰¤Ïµ,
and thus term 1 â‰¤Ïµ.
Step 2: letting term 2 =Ïµand showing that Î´satisfies the inequality in (10):
Assuming without loss of generality thatT
mis an integer, note that term 2 =Ïµimplies:
qwa1Î´
4âˆšnx
=
1âˆ’Ïµ
544n2.5xn2.5
Ï•log(a4nxnÏ•)anxnÏ•
4m
T
â‰¤ âˆ’logÏµ
544n2.5xn2.5
Ï•log(a4nxnÏ•)anxnÏ•
4m
T
=âˆ’m
TlogÏµ
544n2.5xn2.5
Ï•log(a4nxnÏ•)anxnÏ•
4
=m
T
log1
Ïµ
+ log( a4)nxnÏ•+ 2.5 log( nxnÏ•) + log log( a4nxnÏ•) + log(544)
.
Ifqw a1Î´
4âˆšnx
=cwa1Î´
4âˆšnxfor some constant cw>0, then:
Î´â‰¤4âˆšnxm
cwa1T
log1
Ïµ
+ log( a4)nxnÏ•+ 2.5 log( nxnÏ•) + log log( a4nxnÏ•) + log(544)
â‰¤16âˆšnxm
cwsÏ•pÏ•TO 
log1
Ïµ
+nxnÏ•log16bÏ•âˆšnx
sÏ•pÏ•!
â‰¤O âˆšnxlog 1
Ïµ
+n1.5
xnÏ•log bÏ•nx
sÏ•pÏ•
cwsÏ•pÏ•T!
.
Combining these two steps, we conclude that, with probability at least 1âˆ’2Ïµ,
diam(Î˜T)â‰¤O âˆšnxlog 1
Ïµ
+n1.5
xnÏ•log bÏ•nx
sÏ•pÏ•
cwsÏ•pÏ•T!
.
21C.3 Proof of Corollary 3
This corollaryâ€™s proof builds on Lemma 3 in Appendix B.2 and closely aligns with the proofs of
Theorem 3 and Corollary 2.
D Numerical Experiments
This section provides details on the simulation experiments.
D.1 Pendulum
The ground truth for the unknown parameters for pendulum example in Example 1 is set to be
m= 0.1(kg), l= 0.5(m),
and discretization time step in our numerical experiments is dt= 0.01(s). The control input is a
simple feedback controller ut=âˆ’kË™Î±t+Î·t. In Figures 1a and 1b we choose k= 2and in Figures 2a,
2b and 3 we choose k= 0.1. Note there are two unknown parameters in this pendulum example as
follows:
Î¸1=1
l, Î¸2=1
ml2.
D.2 Quadrotor
The ground truth for the unknown parameters for quadrotor example in Example 2 is set to be
m= 0.468 ( kg),
Ixx= 4.856Ã—10âˆ’3(kg/m2), Iyy= 4.856Ã—10âˆ’3(kg/m2), Izz= 8.801Ã—10âˆ’3(kg/m2).
The discretization time step in our numerical experiments is dt= 0.01(s). The control input is a
control policy plus i.i.d. noise. The control policy on altitude and the three Euler angles is borrowed
from (Alaimo et al., 2013). The controller gains in our numerical experiments are chosen as:
kpz= 0.75, kd z= 1.25,
kpÏ•= 0.03, kd Ï•= 0.00875 ,
kpÎ¸= 0.03, kd Î¸= 0.00875 ,
kpÏˆ= 0.03, kd Ïˆ= 0.00875 .
Note that there are seven unknown parameters in this quadrotor example, as follows:
Î¸1=1
m,
Î¸2=1
Ixx, Î¸3=Iyyâˆ’Izz
Ixx, Î¸4=1
Iyy, Î¸5=Izzâˆ’Ixx
Iyy, Î¸6=1
Izz, Î¸7=Ixxâˆ’Izz
Izz.
Figure 4 displays the uncertainty set estimated by SME for the seven unknown parameters in the
quadrotor example for various trajectory lengths, with Î·tandwtbeing i.i.d. samples from truncated-
Gaussian distributions. The uncertainty sets are observed to shrink as the trajectory length increases,
consistent with our theoretical results. Note that the ground truth value is contained within all the
uncertainty sets.
E Numerical Estimation of BMSB Parameters (sÏ•, pÏ•)
We compare the empirical rates of LSE and SME with their theoretical counterparts in Section 4. The
theoretical results presented in Theorem 2 and Corollary 2 rely on the parameters bÏ•,Â¯bÏ•, and the
BMSB parameters (sÏ•, pÏ•). However, the explicit relationship of these parameters with system, noise,
and disturbance characteristics such as nx,nu,nÏ•,Ïƒu, and Ïƒwis not known and we will address
this in our future work. Consequently, we estimate these parameters numerically and utilize these
22Figure 4: 2D projections of the uncertainty set estimated by SME for the unknown parameters of the quadrotor
example. The noises and disturbances are i.i.d generated from truncated-Gaussian (0,0.5,[âˆ’1,1]).
estimates to calculate the theoretical rates discussed in Section 4. While bÏ•andÂ¯bÏ•are straightforward
to estimate, special attention is required to estimate the BMSB parameters. This section is dedicated
to describing this estimation process.
For this, consider a system of the form (1). For this system, our goal is to estimate sÏ•andpÏ•, where
pÏ•= inf
Ft,tâ‰¥0inf
âˆ¥vâˆ¥2=1P
|vTÏ•(zt+1)| â‰¥sÏ•Ft
numerically. First, observe that Ï•(zt+1)| Ft=Ï•(Î¸T
âˆ—Ï•(zt) +wt, ut+1), where ztâˆˆ Ft. This implies
thatÏ•(zt+1)| Ftis a random variable influenced by wtandut+1. We proceed by fixing sÏ•= Â¯s(for
some Â¯s >0) and empirically estimate pÏ•. To accomplish this, we first select a time horizon Tand
generate several trajectories of length Tfor the system. Let DTrepresent the set of these trajectories,
whileDtdenotes a subset containing all trajectories up to tâ‰¤T. Additionally, we create multiple
vectors vâˆˆRnÏ•such that âˆ¥vâˆ¥2= 1; we refer to this collection as Â¯V. These vectors are randomly
sampled from a Gaussian distribution and subsequently normalized.
We then estimate Â¯pas:
Â¯p= min
tâˆˆ[T]min
zâˆˆDtmin
vâˆˆÂ¯VP
|vTÏ•(Î¸T
âˆ—Ï•(z) +wt, ut+1)| â‰¥Â¯s
.
AsTincreases, along with the number of trajectories and vectors v, the minimum estimates will more
accurately reflect the infimums. In this context, Â¯prepresents the minimum of P
|vTÏ•(Î¸T
âˆ—Ï•(z) +
wt, ut+1)| â‰¥Â¯s
across all combinations in [T]Ã— DTÃ—Â¯V. For each combination in this set, we
estimate the probability P
|vTÏ•(Î¸T
âˆ—Ï•(z) +wt, ut+1)| â‰¥Â¯s
using Monte Carlo simulations. This
process entails generating multiple random samples based on the distributions of wtandut+1,
verifying whether each sample satisfies the condition |Â¯vTÏ•(z)| â‰¥Â¯s, and tallying how many samples
meet this criterion. We repeat this procedure for various values of Â¯suntil we identify a pair of (Â¯s,Â¯p)
such that Â¯pâˆˆ(0,1). The estimated probability is calculated as the ratio of the count of successful
samples to the total number of samples. According to the law of large numbers, this ratio converges
to the true probability as the number of samples increases. For our estimations, we select T= 50 ,
|Â¯V|= 1000 , and|DT|= 20 .
23