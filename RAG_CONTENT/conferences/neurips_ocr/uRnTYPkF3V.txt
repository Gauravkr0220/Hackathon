Sequential Probability Assignment with Contexts:
Minimax Regret, Contextual Shtarkov Sums, and
Contextual Normalized Maximum Likelihood
Ziyi Liu
University of Toronto & Vector Institute
kevind.liu@mail.utoronto.caIdan Attias
Ben-Gurion University & Vector Institute
idanatti@post.bgu.ac.il
Daniel M. Roy
University of Toronto & Vector Institute
daniel.roy@utoronto.ca
Abstract
We study the fundamental problem of sequential probability assignment, also
known as online learning with logarithmic loss, with respect to an arbitrary, pos-
sibly nonparametric hypothesis class. Our goal is to obtain a complexity measure
for the hypothesis class that characterizes the minimax regret and to determine
a general, minimax optimal algorithm. Notably, the sequential â„“âˆentropy, ex-
tensively studied in the literature (Rakhlin and Sridharan, 2015, Bilodeau et al.,
2020, Wu et al., 2023), was shown to not characterize minimax regret in general.
Inspired by the seminal work of Shtarkov (1987) and Rakhlin, Sridharan, and
Tewari (2010), we introduce a novel complexity measure, the contextual Shtarkov
sum, corresponding to the Shtarkov sum after projection onto a multiary context
tree, and show that the worst case log contextual Shtarkov sum equals the mini-
max regret. Using the contextual Shtarkov sum, we derive the minimax optimal
strategy, dubbed contextual Normalized Maximum Likelihood (cNML). Our re-
sults hold for sequential experts, beyond binary labels, which are settings rarely
considered in prior work. To illustrate the utility of this characterization, we pro-
vide a short proof of a new regret upper bound in terms of sequential â„“âˆentropy,
unifying and sharpening state-of-the-art bounds by Bilodeau et al. (2020) and Wu
et al. (2023).
1 Introduction
Sequential probability assignment is a fundamental problem with connections to information theory
[Ris84; MF98; XB00], machine learning [CL06; V ov95; RST15; FKLMS18; Sha20], and portfolio
optimization [Kel56; Cov74; Cov91; CO96; Fed91]. In the original non-contextual setup, the learner
aims to assign probabilities to a series of labels, which are revealed sequentially. The goal is to offer
probabilistic forecasts over the label set such that the probability assigned to any observed sequence
is comparable to that assigned by the best model in any fixed class of models.
The celebrated work of Shtarkov [Sht87] characterized minimax regret for context-free sequential
probability assignment in terms of what is now known as the Shtarkov sum , and subsequently de-
scribed the minimax algorithm, Normalized Maximum Likelihood (NML). NML represents the ideal
probabilistic forecast in the sense of minimax regret, providing a benchmark for universal coding
and prediction strategies. While often not used directly due to its computational complexity, NML
has guided the design of practical algorithms and informed the development of efficient approxima-
38th Conference on Neural Information Processing Systems (NeurIPS 2024).tion methods. The principles underlying NML have inspired advances in both information theory
and online learning, establishing fundamental limits and serving as a critical benchmark.
In this work, we study the problem of sequential probability assignment with contexts, which
has been analyzed in recent works (e.g. [RS15; BFR20; WHGS23]) under the framework of on-
line supervised learning formalized by Rakhlin, Sridharan, and Tewari [RST10]. In this setup,
the problem is modeled as a T-round game between a learner and the nature : On each round
t= 1, . . . , T , the learner observes a context xtfrom nature and predicts a distribution Ë†ptover some
finite label space Y. Then nature reveals a label ytâˆˆ Y and the learner incurs a logarithmic loss
â„“(Ë†pt, yt) =âˆ’log(Ë†pt(yt)), where Ë†pt(yt)is the probability assigned to label ytbyË†pt. The perfor-
mance of the learner is measured by the regret with respect to a class Fofexperts , defined as the
difference between the total loss of the learner and that of the best expert in F. The value of primary
interest is the minimax regret , that is, the worst-case regret by the best learner over arbitrarily adap-
tive data sequences. The minimax regret serves as a benchmark for all algorithms and as a target for
studies of adaptivity. Our goal is to address several fundamental questions:
Can we find a natural complexity measure of Fthat characterizes the minimax regret, enabling us
to analyze the minimax regret in new ways? And can we identify, in view of this complexity
measure, a general, minimax optimal algorithm?
Notably, the sequential covering number of F, a well studied measure of complexity, has been
shown not to characterize the minimax regret on its own [RS15; BFR20; WHGS23]. This fact
distinguishes sequential probability assignment and log loss: while sequential covering numbers
enable a tight analysis in online learning problems with convex Lipschitz losses, like absolute loss
[RST15] and square loss [RS14a], they do not yield minimax rates for log loss on some classes.
Tackling such classes evidently requires new techniques.
Main contributions.
1. We introduce a new complexity measure, which we call the contextual Shtarkov sum , that serves
as a natural generalization of the Shtarkov sum from the context-free setting. We show that the
minimax regret is characterized by the worst-case contextual Shtarkov sum.
2. We derive the minimax optimal algorithm, dubbed contextual Normalized Maximum Likelihood
(cNML), using a data-dependent variant of the contextual Shtarkov sum, thereby generalizing
NML from the context-free setting.
3. We apply contextual Shtarkov sums to the study of sequential entropy bounds on minimax.
Doing so, we provide a short proof of a new regret upper bound in terms of sequential entropy
that unifies and even improves on state-of-the-arts bounds by [BFR20] and [WHGS23]. Our
results extend beyond the binary label setting studied by recent work to arbitrary finite label sets.
Related work. Sequential probability assignment has been studied extensively. Various aspects
of this problem have been investigated, including sequences with and without side information
(contexts), parametric and nonparametric hypothesis classes, and stochastic or adversarial data-
generating mechanisms. This problem has a long history in the machine learning community, see
[CL06, Ch. 9] and the references therein. In the information theory community, this problem is also
known as universal prediction [MF98], where the regret is also referred to as redundancy with respect
to a set of codes. This has been studied in both stochastic and adversarial settings [Fre96; Ris86;
Ris96; Sht87; XB97; DS04; MF98; OS04; Sha06; Szp98], where the focus was primarily on the
parametric classes of experts. Closely related topics include universal source coding [Kol65; Sol64;
Fit66; Dav73], data compression with arithmetic coding [Ris76; RL81; ZL77; ZL78; FMG92], and
the minimum description length (MDL) principle [Ris78; Ris84; Ris87; BRY98; GrÃ¼05; HY01].
Lastly, this topic is intimately tied with sequential gambling and portfolio optimization, as pointed
out by [Kel56; Cov74; Cov91; CO96; Fed91].
A classical result in context-free sequential probability assignment is that the minimax regret is
equal to the log contextual Shtarkov sum [Sht87], and the minimax algorithm is the well-known
Normalized Maximum Likelihood. When the set of contexts is known in advance to the forecaster,
namely, a fixed design setting, the minimax regret is equivalent to the log Shtarkov sum of the
function class when projected onto the known set of contexts [JSS21; WHGS23].
2A long line of work has focused on controlling minimax regret for rich classes in terms of covering
numbers. [CL99; OH99] upper bounded the regret in terms of the (non-sequential) uniform covering
number of the class. However, this complexity measure proved to be insufficient for obtaining
optimal rates. [RS15] improved regret upper bounds by proposing a sequential covering measure.
Thereafter, by utilizing the self-concordance property and the curvature of the log loss, [BFR20]
further improved the upper bound in terms of the sequential covering number for nonparametric
Lipschitz classes, through a non-constructive proof. [WHGS23] proposed a Bayesian algorithmic
approach in order to upper bound the regret using a global notion of sequential covering. Notably,
both the global and local sequential covering numbers do not fully characterize the regret, and the
algorithm in [WHGS23] is not minimax optimal. By relaxing the worst-case analysis, [BHS23]
studied this problem within the smoothed analysis framework, where nature is not fully adversarial
but constrained.
Online learning with respect to arbitrary hypothesis classes and the zero-one loss, in the realizable
case, is known to be characterized by the Littlestone dimension [Lit88]. The agnostic case was ad-
dressed by [BPS09; ABDMNY21]. Understanding sequential complexities in online learning with
Lipschitz losses was extensively studied by [RST10; RS14a; RS14b; RST15]. Note that the logarith-
mic loss is neither Lipschitz nor bounded. Recently, [AHKKV23] characterized online regression
in the realizable case, for any approximate pseudo-metric, such as the â„“ploss.
2 Preliminaries
Notation. For a positive integer K, let[K] :={1,2, . . . , K }. For a finite set Kwith|K|=K, we
useâˆ†(K)to denote the set of all distributions on K. We may identify Kwith[K](under arbitrary
enumeration of elements in K) and treat elements of âˆ†(K)as vectors in RK. For a vector pâˆˆRK
andiâˆˆ[K], letp(i)be the i-th coordinate of p. Let âˆ†+(K) ={pâˆˆâˆ†(K) :p(k)>0,âˆ€kâˆˆ K} .
For a general finite sequence (ai)N
i=1, we will use an:mto denote the sub-sequence (an, . . . , a m)for
anynâ‰¤mand the empty sequence for n > m . For any set A, letAâˆ—=âˆªkâ‰¥0Akbe the set of all
finite length sequences over A.
Sequential probability assignment and minimax regret. LetXbe the context space and Ybe
the finite label space. In each round tâˆˆ[T]during the game of sequential probability assignment,
the learner receives a context xtâˆˆ X from nature and assigns a probability distribution Ë†ptâˆˆâˆ†(Y)to
the possible labels. Then nature reveals the true label ytâˆˆ Y and the learner incurs a loss â„“(Ë†pt, yt) =
âˆ’log(Ë†pt(yt)). Throughout, the learner is required to predict nearly as well as the best expert from
an expert class, which is modeled as an arbitrary hypothesis class F âŠ† { (X Ã— Y )âˆ—Ã— X â†’ âˆ†(Y)}.
More formally, the goal of the learner is make their regret with respect to F,
RT(F; Ë†p1:T, x1:T, y1:T) =TX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(f(x1:t, y1:tâˆ’1), yt),
as small as possible for all sequences xandygenerated by nature, possibly in an adversarial manner.
Here f(x1:t, y1:tâˆ’1)âˆˆâˆ†(Y)can be understood as the prediction made by expert fat round tusing
past observations (x1:tâˆ’1, y1:tâˆ’1)as well as the fresh context xt. The main focus is to study the
minimax regret RT(F), which can be written as the following extensive form
RT(F) = sup
x1inf
Ë†p1sup
y1Â·Â·Â·sup
xTinf
Ë†pTsup
yTRT(F; Ë†p1:T, x1:T, y1:T),
where xtâˆˆ X,Ë†ptâˆˆâˆ†(Y)andytâˆˆ Y,âˆ€tâˆˆ[T]. In light of this formulation, we can see that the
minimax regret concerns both the learner and the nature to be adaptive , meaning that their actions
can rely on the revealed history so far.
Remark 2.1 (Sequential vs non-sequential experts) Experts fas mappings from (X Ã—Y )âˆ—Ã—X to
âˆ†(Y)are sometimes called fully sequential experts [WHGS23] due to their ability to predict based
on the past history. However, the literature (e.g. [RS15; BFR20; WHGS23]) often considers the
more limited notion of non-sequential experts, modeled as F âŠ† {X â†’ âˆ†(Y)}, reflecting the fact
that prediction made by each expert fis simply f(xt)in each round t. In contrast, our results are
more general as our novel techniques can be applied to the more flexible sequential experts.
3Multiary trees. The complexity of online learning problems stems from the sequential and adap-
tive nature of the adversary, which we can capture with multiary trees . Formally, for a general
space Aand a finite set K, anA-valued K-ary tree vof depth dis a sequence of mappings
vt:Ktâˆ’1â†’ A fortâˆˆ[d]. A path in a depth- dtree is a sequence Îµ= (Îµ1, . . . , Îµ d)âˆˆ Kd.
We use the notation vt(Îµ)to denote vt(Îµ1, . . . , Îµ tâˆ’1)fortâˆˆ[d]and the boldface notation v(Îµ)to
denote (v1(Îµ), . . . , vd(Îµ))âˆˆ Ad. Throughout we will only consider Y-ary trees valued in either X
orâˆ†(Y), where the paths are denoted by the boldface y. We refer to X-valued trees as context trees
andâˆ†(Y)-valued trees as probabilistic trees .
Time-varying context sets. So far we consider the context set Xto be constant over time. But
all of our results can be extended easily to allow for time-varying context spaces. Details of this
generalization can be found in Appendix C.
2.1 Prior work: the Shtarkov sum in context-free and fixed designs
Before introducing our complexity measure that characterizes RT(F), we review some prior set-
tings where the minimax regret can be characterized by the well-studied Shtarkov sum . First we
introduce the notion of likelihood of a hypothesis fwith respect to a context and label sequence,
which plays a key role in defining complexity measures and optimal algorithms.
Definition 2.2 (Likelihood) Forf: (X Ã— Y )âˆ—Ã— X â†’ âˆ†(Y)and length âˆ’dsequences x1:dâˆˆ
Xd, y1:dâˆˆ Yd, the likelihood Pf(y1:d|x1:d)is defined as
Pf(y1:d|x1:d) =dY
t=1f(x1:t, y1:tâˆ’1)(yt),
where we use the compact notation f(x1:t, y1:tâˆ’1)forf(x1, y1, . . . , x tâˆ’1, ytâˆ’1, xt).
In the classical context-free setting where Xcan be thought of as a singleton, any sequential expert
fdegenerates to a joint distribution over label sequences. Indeed, given any label sequence y1:tâˆ’1,
f(y1:tâˆ’1)âˆˆâˆ†(Y)can be interpreted as the conditional distribution fassigns to the next label yt.
We use Pf(y1:d) =Qd
t=1f(y1:tâˆ’1)(yt)to denote this distribution. Similarly, the learnerâ€™s strategy
is also specified by a joint distribution that is decomposed to a sequence of conditional distributions
Ë†pt= Ë†pt(Â·|y1:tâˆ’1)âˆˆâˆ†(Y). In this setup the minimax regret RT(F)is characterized by the Shtarkov
sum [Sht87].
Proposition 2.3 ([Sht87]) In the context-free setting, for any hypothesis class Fand horizon T, the
Shtarkov sum ST(F)is defined as
ST(F) =X
y1:TâˆˆYTsup
fâˆˆFPf(y1:T).
Moreover, the minimax regret is given by RT(F) = log ST(F), and the unique minimax optimal
strategy is the normalized maximum likelihood (NML) distribution given by
pnml(y1:T) =supfâˆˆFPf(y1:T)P
yâ€²
1:TâˆˆYTsupfâˆˆFPf(yâ€²
1:T),âˆ€y1:Tâˆˆ YT.
To go beyond this classical context-agnostic setting and incorporate contextual information, prior
work (e.g. [JSS21]) also considered an easier problem than the aforementioned sequential probabil-
ity assignment, by forcing nature to reveal the context sequence x1:Tto the learner at the start of the
game. This is known as the fixed design setting or transductive online learning [WHGS23], where
the goal is to characterize the so-called fixed design maximal minimax regret
RFD
T(F) := sup
x1:TâˆˆXTinf
Ë†p1sup
y1Â·Â·Â·inf
Ë†pTsup
yTRT(F; Ë†p1:T, x1:T, y1:T).
It is straightforward to see that after projecting on x1:T, the hypothesis class Fagain collapses to a
set of joint distributions over YTspecified by the likelihood function in Definition 2.2. Moreover,
this set of distributions can be accessed by the learner from the start, so the fixed design setting can
4be essentially reduced to the context-free setting. To be more specific, for any fâˆˆ F, it induces an
expert in the context-free setting after being projected on x1:T, which is denoted by f|x1:Tand
f|x1:T(y1:tâˆ’1) :=f(x1:t, y1:tâˆ’1)âˆˆâˆ†(Y),âˆ€tâˆˆ[T], y1:tâˆ’1âˆˆ Ytâˆ’1,
and let F|x1:T:={f|x1:T:fâˆˆ F} . Then given any predetermined x1:T, the learner is equivalently
competing with F|x1:Tin the context-free setting. With the following natural variant of the Shtarkov
sum, we can easily characterize RFD
T(F).
Definition 2.4 (Conditional Shtarkov sum) Given a context sequence x1:Tâˆˆ XT, the Shtarkov
sum of Fconditioned on x1:Tis
ST(F|x1:T) :=X
y1:TâˆˆYTsup
fâˆˆFPf(y1:T|x1:T).
In fact, ST(F|x1:T)is just the Shtarkov sum of the projected class F|x1:Tin the context-free setting.
The following result characterizes the fixed-design setting:
Proposition 2.5 (Minimax regret, fixed design [JSS21]) In the fixed design setting, for any hy-
pothesis class Fand horizon T, the fixed design maximal minimax regret is
RFD
T(F) = sup
x1:TâˆˆXTlogST(F|x1:T),
and, given any context sequence x1:T, the minimax optimal response is NML with respect to F|x1:T.
3 Minimax regret via contextual Shtarkov sum
Now we state one of our main results about the characterization of the minimax regret of sequential
probability assignment. First we introduce the key concept of contextual Shtarkov sum , which is a
natural generalization of Shtarkov sum in the context-free setting.
Definition 3.1 (Contextual Shtarkov sum) Thecontextual Shtarkov sum ST(F|x)of a hypothesis
classFon a given context tree xof depth Tis defined as
ST(F|x) :=X
yâˆˆYTsup
fâˆˆFPf(y|x(y)).
Just like the conditional Shtarkov sum, the contextual Shtarkov sum ST(F|x)can be interpreted as
the Shtarkov sum of the projected class F|x:={f|x:fâˆˆ F} where f|xis the induced context-free
expert specified by
f|x(y1:tâˆ’1) :=f(x(y1:tâˆ’1), y1:tâˆ’1)âˆˆâˆ†(Y),âˆ€tâˆˆ[T], y1:tâˆ’1âˆˆ Ytâˆ’1,
where we have slightly abused the notation to use x(y1:tâˆ’1)to denote the length- tcontext sequence
obtained by tracing tree xthrough the (partial) path y1:tâˆ’1. Next we show that the minimax regret
RT(F)is characterized by the worst-case contextual Shtarkov sum:
Theorem 3.2 (Main result: minimax regret) For any hypothesis class F âŠ† { (X Ã— Y )âˆ—Ã— X â†’
âˆ†(Y)}and horizon T,
RT(F) = sup
xlogST(F|x),
where the supremum is taken over all X-valued context trees xof depth T.
Since any context sequence x1:Tcan be thought as a special context tree xthat is constant in
each level tâˆˆ[T](i.e.,xt(y) =xt,âˆ€y), we can find that the supremum over context trees in
Theorem 3.2 strictly subsumes the supremum over context sequences in Proposition 2.5. Thus we
can see the separation between RT(F)andRFD
T(F)is clearly exhibited.
The full proof of Theorem 3.2 as well as an overview are provided in Appendix A.
53.1 Applications: an improved regret upper bound in terms of sequential entropy
To illustrate the utility of our characterization in Theorem 3.2, we walk through some examples
where we are able to recover and sharpen existing regret upper bounds with relatively short proofs
via contextual Shtarkov sum. As a start, we provide a short proof in Appendix A.6 of the classical
regret bound for a finite hypothesis class.
Proposition 3.3 (Finite classes) For any F âŠ†[0,1]Xand horizon T,RT(F)â‰¤log|F|.
Let us go back to the binary label setting with non-sequential experts, that is, Y={0,1}and
F âŠ† [0,1]X, and f(x)âˆˆ[0,1]is interpreted as the probability assigned to label 1by this expert f.
We will show a regret bound that outperforms the state-of-the-art ones in [BFR20; WHGS23] with
a surprisingly simple proof. To proceed, we need the following notation. Given a context tree xof
depth T, letF â—¦x={fâ—¦x:fâˆˆ F} , where fâ—¦xis the [0,1]-valued tree such that
(fâ—¦x)t(y) =f(xt(y)),âˆ€yâˆˆ YT.
Next we introduce the definitions of sequential â„“âˆcovers and entropy.
Definition 3.4 (Sequential â„“âˆcover and entropy) Given a hypothesis class F âŠ† [0,1]Xand a
context tree xof depth T, we say a collection of R-valued trees Vx,Î±is a sequential cover of F â—¦x
at scale Î± >0if for any fâˆˆ F,yâˆˆ YT, there exists some vâˆˆVx,Î±such that
|f(xt(y))âˆ’vt(y)| â‰¤Î±,âˆ€tâˆˆ[T].
Let the sequential â„“âˆcovering number Nâˆ(F â—¦x, Î±, T )be the size of the smallest such cover. The
sequential â„“âˆentropy of Fat scale Î±and depth Tis defined as the logarithm of the worst-case
sequential covering number: Hâˆ(F, Î±, T ) := supxlogNâˆ(F â—¦x, Î±, T ).
Definition 3.5 (Global sequential â„“âˆcover and entropy) Given a hypothesis class F âŠ† [0,1]X,
we say a collection of mappings GÎ±âŠ†[0,1]Xâˆ—is aglobal sequential cover of Fat scale Î± >0and
depth Tif for any fâˆˆ F, x1:Tâˆˆ XT, there exists some gâˆˆ GÎ±such that
|f(xt)âˆ’g(x1:t)| â‰¤Î±,âˆ€tâˆˆ[T].
Let the global sequential â„“âˆcovering number NG(F, Î±, T )be the size of the smallest such cover.
Theglobal sequential â„“âˆentropy of Fat scale Î±and depth Tis defined as
HG(F, Î±, T ) := log NG(F, Î±, T ).
Proposition 3.6 ([BFR20; WHGS23]) For any F âŠ†[0,1]Xand horizon T,
RT(F)â‰¤min
inf
Î±>0
4TÎ±+cHâˆ(F, Î±, T )	
| {z }
[BFR20],inf
Î±>0
Tlog(1 + 2 Î±) +HG(F, Î±, T )	
| {z }
[WHGS23]
,
where c=2âˆ’log(2)
log(3)âˆ’log(2)âˆˆ(3,4).
It is easy to show that Hâˆ(F, Î±, T )â‰¤ H G(F, Î±, T ), but, in general, the two bounds in Propo-
sition 3.6 are incomparable due to constants and different dependence on Î±(more discussions on
these bounds are deferred to Appendix C). Starting from the contextual Shtarkov sum, we are able
to derive a bound that combines the best of these two bounds:
Theorem 3.7 (Main result: sequential entropy bound) For any F âŠ†[0,1]Xand horizon T,
RT(F)â‰¤inf
Î±>0n
Tlog(1 + 2 Î±) +Hâˆ(F, Î±, T )o
.
6Proof For any scale Î± >0and depth- Tcontext tree x, letVx,Î±be a sequential cover of F â—¦xat
scale Î±with size Nâˆ(F â—¦x, Î±, T ). We can always assume Vx,Î±to be [0,1]-valued without loss of
generality because otherwise we can just truncate it without violating its coverage guarantee. Define
the smoothed covering set ËœVx,Î±=n
Ëœv:âˆ€tâˆˆ[T],Ëœvt(Â·) =vt(Â·)+Î±
1+2Î±, vâˆˆVx,Î±o
, inspired by [BFR23;
WHGS23]. Then for any fâˆˆ F,yâˆˆ YT, there exists some vâˆˆVx,Î±such that |f(xt(y))âˆ’vt(y)| â‰¤
Î±,âˆ€tâˆˆ[T]and hence Ëœvsatisfies
f(xt(y))
Ëœvt(y)â‰¤1 + 2 Î±,1âˆ’f(xt(y))
1âˆ’Ëœvt(y)â‰¤1 + 2 Î±.
Hence
Pf(y|x(y)) =TY
t=1f(xt(y))yt(1âˆ’f(xt(y)))1âˆ’ytâ‰¤(1 + 2 Î±)TTY
t=1Ëœvt(y)yt(1âˆ’Ëœvt(y))1âˆ’yt,
and
X
ysup
fâˆˆFPf(y|x(y))â‰¤(1 + 2 Î±)TX
ysup
ËœvâˆˆËœVx,Î±TY
t=1Ëœvt(y)yt(1âˆ’Ëœvt(y))1âˆ’yt
â‰¤(1 + 2 Î±)TX
ËœvâˆˆËœVx,Î±X
yTY
t=1Ëœvt(y)yt(1âˆ’Ëœvt(y))1âˆ’yt= (1 + 2 Î±)T|ËœVx,Î±|,
where the last equality follows from Lemma D.1, treating Ëœvas sequential experts. Finally,
RT(F) = sup
xlog X
ysup
fâˆˆFPf(y|x(y))!
â‰¤sup
xlog
(1 + 2 Î±)T|ËœVx,Î±|
=Tlog(1 + 2 Î±) +Hâˆ(F, Î±, T ).
Since our choice of Î±is arbitrary, the result follows. â– 
3.2 The inadequacy of sequential â„“âˆcovering number
We conclude this section with a discussion on the suboptimality of regret bounds based on sequential
covering numbers as in Proposition 3.6 and Theorem 3.7. Let us consider the binary label setting
and the following hypothesis classes over the unit Hilbert ball X=B2:
FLin:=
x7â†’âŸ¨w, xâŸ©+ 1
2:wâˆˆB2
,FAbsLin:={x7â†’ |âŸ¨w, xâŸ©|:wâˆˆB2}. (1)
We can see that the sequential â„“âˆcovering numbers of FLinandFAbsLinare of the same order
for all scales, thus the aforementioned results will yield the same regret bound for these two classes.
However, we have RT(FLin) =ËœO(âˆš
T)whileRT(FAbsLin) =ËœÎ˜(T2/3)[RS15; WHGS23], which
implies that the sequential â„“âˆcovering number, in its current form within the regret bound, cannot
characterize the minimax regret.
It is worth mentioning that an Ëœâ„¦(âˆš
T)lower bound on RT(FLin)is achievable, via an Ëœâ„¦(1/Î±2)
lower bound on the sequential fat-shattering dimension sfatÎ±(FLin)combined with Proposition 2
in [WHGS23]. The same lower bound also holds in the finite-dimensional case, where B2is a unit
d-dimensional Euclidean ball with dâ‰¥âˆš
T[WHGS23, Footnote 6]. Our proof (Appendix A.7) of
the next result works in both the infinite and finite dimensional (with dâ‰¥T) cases.
Lemma 3.8 ( â„¦(âˆš
T)lower bound for the linear class FLin)ForFLindefined as in Eq. (1)with
B2being the unit Hilbert ball or the unit d-dimensional Euclidean ball with dâ‰¥T, then
RT(FLin)â‰¥ RFD
T(FLin)â‰¥âˆš
T/4.
The proof of Lemma 3.8 is based on lower bounding the conditional Shtarkov sums (and hence the
contextual Shtarkov sums) of FLin. From Theorem 3.2 we know that the ËœO(âˆš
T)upper bound holds
for the log of contextual Shtarkov sums as well but we do not have a direct proof of this fact so far.
7Algorithm 1 Contextual Normalized Maximum Likelihood (cNML)
Input: Hypothesis class F, horizon T
Fort= 1,2, ..., T do
1. Observe context xtâˆˆ X
2. If supfâˆˆFPf(y1:tâˆ’1|x1:tâˆ’1)>0, predict Ë†ptâˆˆâˆ†(Y)with
Ë†pt(y) =supxSx1:t,(y1:tâˆ’1,y)
T (F|x)
P
yâ€²âˆˆYsupxSx1:t,(y1:tâˆ’1,yâ€²)
T (F|x),âˆ€yâˆˆ Y, (2)
and otherwise set Ë†ptto be an arbitrary member of âˆ†+(Y)
3. Receive label ytâˆˆ Y
End for
4 Contextual NML, the minimax optimal algorithm
So far we have settled the minimax regret of sequential probability assignment in a nonconstruc-
tive way. Now we switch to the algorithmic lens to study the optimal strategy that achieves the
minimax regret. Remarkably, we show that the minimax optimal algorithm can be described by a
data-dependent variant of the contextual Shtarkov sum, which is named contextual Shtarkov sum
with prefix .
Definition 4.1 (Contextual Shtarkov sum with prefix) Given sequences x1:tâˆˆ Xt, y1:tâˆˆ Yt, tâˆˆ
[T]and a context tree xof depth Tâˆ’t, the contextual Shtarkov sum Sx1:t,y1:t
T (F|x)ofFonxwith
prefix x1:t, y1:tis defined as
Sx1:t,y1:t
T (F|x) =X
yâˆˆYTâˆ’tsup
fâˆˆFPf(y1:t,y|x1:t,x(y)).
Now we present our prediction strategy, contextual normalized maximum likelihood (cNML),
which is summarized in Algorithm 1. In each round t, with x1:t, y1:tâˆ’1as past observations,
the learner first checks whether supfâˆˆFPf(y1:tâˆ’1|x1:tâˆ’1)>0since if that is not the case and
supfâˆˆFPf(y1:tâˆ’1|x1:tâˆ’1) = 0 , the cumulative losses of all experts in Fhave already blown up to
+âˆand the learner only needs to predict any Ë†pâˆˆâˆ†+(Y)in all remaining rounds. On the other
hand, if supfâˆˆFPf(y1:tâˆ’1|x1:tâˆ’1)>0, then
max
yâˆˆYsup
xSx1:t,(y1:tâˆ’1,y)
T (F|x)>0
and the Ë†ptgiven by Eq. (2) is indeed a valid member of âˆ†(Y)(shown in Appendix B) and is used as
the learnerâ€™s prediction. The following theorem shows that cNML is the minimax optimal algorithm,
with proof deferred to Appendix B.
Theorem 4.2 (Main result: optimal algorithm) The contextual normalized maximum likelihood
strategy (Algorithm 1) is minimax optimal.
To see that cNML is reduced to NML in the context-free setting, it suffices to consider the case
where supfâˆˆFPf(y1:T)>0since otherwise NML will simply assign 0probability on this se-
quence y1:Tand during the actual round-wise implementation of NML, it also predicts an arbitrary
element from âˆ†+(Y)in those rounds twhere supfPf(y1:tâˆ’1) = 0 . Now for any y1:Tsuch that
supfâˆˆFPf(y1:T)>0, the prediction by cNML in each round tis
Ë†pt(y) =P
yâˆˆYTâˆ’tsupfâˆˆFPf(y1:tâˆ’1, y,y)P
yâ€²âˆˆYTâˆ’t+1supfâˆˆFPf(y1:tâˆ’1,yâ€²),âˆ€yâˆˆ Y
which can be summarized into a joint density over y1:Tby
Ë†p(y1:T) =supfâˆˆFPf(y1:T)P
yâ€²
1:TâˆˆYTsupfâˆˆFPf(yâ€²
1:T).
Recall that this is exactly the NML prediction pnml(y1:T).
8Remark 4.3 (Relaxations and efficient algorithms) One may wonder if more efficient algorithms
are available when it is not easy to compute contextual Shtarkov sums with prefix. One solution is
to apply the framework of admissible relaxation in [RSS12], which provides a systematic way of
constructing efficient algorithms at the cost of worse regret guarantees. Notice that the worst-case
log contextual Shtarkov sums with prefix constitute a trivially â€œadmissible relaxationâ€ since they are
the exact conditional game values.
5 Perspectives on contextual Shtarkov sums
In this section, we provide further insight into contextual Shtarkov sums, defined in Sections 3 and 4.
5.1 Contextual Shtarkov sums through martingales
We can relate our characterization of the minimax regret to the more extensively studied sequential
Rademacher complexity , which arises in online learning problems with hypothesis class F âŠ†[0,1]X
and bounded convex losses like absolute loss. Specifically, the (conditional) sequential Rademacher
complexity [RST15] is defined by
RT(F;x) :=EÎµh
sup
fâˆˆFTX
t=1Îµtf(xt(Îµ))i
,
where xis a depth- Tbinary context tree and Îµ= (Îµ1, . . . , Îµ T)âˆˆ {Â± 1}Tis a sequence of i.i.d.
Rademacher random variables. A notable feature of RT(F;x)is that it is the expected supremum
of the sum of a martingale differences, i.e., for any f,E[Îµtf(xt(Îµ))|Îµ1, . . . , Îµ tâˆ’1] = 0 . Likewise,
ST(F|x)also admits a martingale interpretation. To see this, let F âŠ† { (X Ã— Y )âˆ—Ã— X â†’ âˆ†(Y)}
and rewrite ST(F|x)for any context tree x:
ST(F|x) =X
yâˆˆYTsup
fâˆˆFPf(y|x(y)) =Eyh
sup
fâˆˆFTY
t=1
|Y| Â·f(x1:t(y), y1:tâˆ’1)(yt)i
,
where y= (y1, . . . , y T)is a sequence of i.i.d. variables following the uniform distribution over Y.
It is easy to check that E[|Y| Â·f(x1:t(y), y1:tâˆ’1)(yt)|y1, . . . , y tâˆ’1] = 1 , and thus
ntY
s=1
|Y| Â·f(x1:s(y), y1:sâˆ’1)(ys)o
tâˆˆ[T]
is a martingale with respect to filtration Ft=Ïƒ(y1, . . . , y t), tâˆˆ[T]. It would be of independent
interest to study the contextual Shtarkov sums more quantitatively by developing new tools for such
product-type martingales.
5.2 General Shtarkov sums
We can also interpret contextual Shtarkov sums as an instance of general Shtarkov sums , which are
defined over sub-probability measures.
Definition 5.1 (Sub-probability measure) A setP={p:K â†’ [0,1]}is a class of sub-probability
measures over a finite set Kif X
kâˆˆKp(k)â‰¤1,âˆ€pâˆˆ P.
Due to Lemma D.1, it is easy to see that for any hypothesis class F âŠ† { (X Ã— Y )âˆ—Ã— X â†’ âˆ†(Y)}
and depth- Tcontext tree x, they induce a class
PF|x:={Pf(Â·|x(Â·)) :fâˆˆ F}
that is a class of sub-probability measures over YT. Moreover, for any F, depth- (Tâˆ’t)context tree
xand sequences x1:tâˆˆ Xt, y1:tâˆˆ Yt, the induced
PFx1:t,y1:t|x:={Pf(y1:t,Â·|x1:t,x(Â·)) :fâˆˆ F}
9is a class of sub-probability measure over YTâˆ’tsince
X
yâˆˆYTâˆ’tPf(y1:t,y|x1:t,x(y)) =Pf(y1:t|x1:t)â‰¤1.
Next we introduce the notion of general Shtarkov sum over classes of sub-probability measures.
Definition 5.2 (General Shtarkov sum) Given any class Pof sub-probability measures over K,
the general Shtarkov sum of Pis defined as
S(P) =X
kâˆˆKsup
pâˆˆPp(k).
With the notion of general Shtarkov sum, it is not hard to verify that the contextual Shtarkov sums
with & without prefix can be interpreted as instances of general Shtarkov sums:
Proposition 5.3 For any horizon T, tâˆˆ[T], data sequence x1:tâˆˆ Xt, y1:tâˆˆ Yt, and context trees
x,xâ€²of depth T, Tâˆ’trespectively, we have
ST(F|x) =S(PF|x), Sx1:t,y1:t
T (F|xâ€²) =S(PFx1:t,y1:t|xâ€²).
It would be interesting to find out other instances of general Shtarkov sums that capture the com-
plexities of other online learning problems with log loss.
6 Discussions
In this paper, we characterize the minimax regret and the optimal prediction strategy for sequen-
tial probability assignment, generalizing the classical results in the context-free setting. Moreover,
our results are general enough to subsume the setting of multiary labels and sequential hypothesis
classes, which has not been sufficiently explored before. Remarkably, our characterization holds
for arbitrary hypothesis classes that may not admit the regularity assumptions implicitly required by
prior works (e.g. [RST15; BFR20]).
For future works, it would be interesting to study the minimax regret of specific classes more quan-
titatively using our contextual Shtarkov sums. It is also intriguing to consider the setting of infinite
labels. Although most of our arguments would go through under sufficient regularity conditions, a
more systematic study is needed. On the practical side, it is important to develop algorithms that are
more computationally efficient than cNML and with provable guarantees.
Acknowledgements
We are grateful to Changlong Wu for telling us about Proposition C.2 and to Zeyu Jia for insights
leading to Lemma 3.8. We would also like to thank Blair Bilodeau and Sasha V oitovych for helpful
discussions and comments on earlier drafts of this work. ZL is supported by the Vector Research
Grant at the Vector Institute. IA is supported by the Vatat Scholarship from the Israeli Council
for Higher Education. DMR is supported by an NSERC Discovery Grant and funding through his
Canada CIFAR AI Chair at the Vector Institute.
References
[ABDMNY21] N. Alon, O. Ben-Eliezer, Y . Dagan, S. Moran, M. Naor, and E. Yogev. â€œAdver-
sarial laws of large numbers and optimal regret in online classificationâ€. In: Pro-
ceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing .
2021, pp. 447â€“455 (cit. on p. 3).
[AHKKV23] I. Attias, S. Hanneke, A. Kalavasis, A. Karbasi, and G. Velegkas. â€œOptimal Learn-
ers for Realizable Regression: PAC Learning and Online Learningâ€. In: Thirty-
seventh Conference on Neural Information Processing Systems . 2023 (cit. on p. 3).
[BRY98] A. Barron, J. Rissanen, and B. Yu. â€œThe minimum description length principle in
coding and modelingâ€. In: IEEE transactions on information theory 44.6 (1998),
pp. 2743â€“2760 (cit. on p. 2).
10[BPS09] S. Ben-David, D. PÃ¡l, and S. Shalev-Shwartz. â€œAgnostic Online Learning.â€ In:
COLT . V ol. 3. 2009, p. 1 (cit. on p. 3).
[BHS23] A. Bhatt, N. Haghtalab, and A. Shetty. â€œSmoothed Analysis of Sequential Prob-
ability Assignmentâ€. In: Thirty-seventh Conference on Neural Information Pro-
cessing Systems . 2023 (cit. on p. 3).
[BFR20] B. Bilodeau, D. Foster, and D. Roy. â€œTight bounds on minimax regret under
logarithmic loss via self-concordanceâ€. In: International Conference on Machine
Learning . PMLR. 2020, pp. 919â€“929 (cit. on pp. 2, 3, 6, 10, 14, 15, 25).
[BFR23] B. Bilodeau, D. J. Foster, and D. M. Roy. â€œMinimax rates for conditional den-
sity estimation via empirical entropyâ€. In: The Annals of Statistics 51.2 (2023),
pp. 762â€“790 (cit. on pp. 7, 15).
[CL06] N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games . Cambridge uni-
versity press, 2006 (cit. on pp. 1, 2).
[CL99] N. Cesa-Bianchi and G. Lugosi. â€œMinimax regret under log loss for general
classes of expertsâ€. In: Proceedings of the Twelfth annual conference on com-
putational learning theory . 1999, pp. 12â€“18 (cit. on p. 3).
[Cov74] T. M. Cover. â€œUniversal gambling schemes and the complexity measures of Kol-
mogorov and Chaitinâ€. In: Technical Report, no. 12 (1974) (cit. on pp. 1, 2).
[Cov91] T. M. Cover. â€œUniversal portfoliosâ€. In: Mathematical finance 1.1 (1991), pp. 1â€“
29 (cit. on pp. 1, 2).
[CO96] T. M. Cover and E. Ordentlich. â€œUniversal portfolios with side informationâ€. In:
IEEE Transactions on Information Theory 42.2 (1996), pp. 348â€“363 (cit. on pp. 1,
2).
[Dav73] L. D. Davisson. â€œUniversal noiseless codingâ€. In: IEEE Trans. Inf. Theory 19
(1973), pp. 783â€“795 (cit. on p. 2).
[DS04] M. Drmota and W. Szpankowski. â€œPrecise minimax redundancy and regretâ€. In:
IEEE Transactions on Information Theory 50.11 (2004), pp. 2686â€“2707 (cit. on
p. 2).
[Fed91] M. Feder. â€œGambling using a finite state machineâ€. In: IEEE Transactions on
Information Theory 37.5 (1991), pp. 1459â€“1465 (cit. on pp. 1, 2).
[FMG92] M. Feder, N. Merhav, and M. Gutman. â€œUniversal prediction of individual se-
quencesâ€. In: IEEE transactions on Information Theory 38.4 (1992), pp. 1258â€“
1270 (cit. on p. 2).
[Fit66] B. Fitingof. â€œOptimal encoding with unknown and variable message statisticsâ€.
In:Probl. Inform. Transm. 2 (1966), pp. 3â€“11 (cit. on p. 2).
[FKLMS18] D. J. Foster, S. Kale, H. Luo, M. Mohri, and K. Sridharan. â€œLogistic regression:
The importance of being improperâ€. In: Conference on learning theory . PMLR.
2018, pp. 167â€“208 (cit. on p. 1).
[Fre96] Y . Freund. â€œPredicting a binary sequence almost as well as the optimal biased
coinâ€. In: Proceedings of the ninth annual conference on Computational learning
theory . 1996, pp. 89â€“98 (cit. on p. 2).
[GrÃ¼05] P. GrÃ¼nwald. â€œMinimum description length tutorialâ€. In: (2005) (cit. on p. 2).
[HY01] M. H. Hansen and B. Yu. â€œModel selection and the principle of minimum descrip-
tion lengthâ€. In: Journal of the American Statistical Association 96.454 (2001),
pp. 746â€“774 (cit. on p. 2).
[JSS21] P. Jacquet, G. Shamir, and W. Szpankowski. â€œPrecise minimax regret for logis-
tic regression with categorical feature valuesâ€. In: Algorithmic Learning Theory .
PMLR. 2021, pp. 755â€“771 (cit. on pp. 2, 4, 5).
[Kel56] J. L. Kelly. â€œA new interpretation of information rateâ€. In: the bell system techni-
cal journal 35.4 (1956), pp. 917â€“926 (cit. on pp. 1, 2).
[Kol65] A. N. Kolmogorov. â€œThree approaches to the definition of the concept â€œquantity
of informationâ€â€. In: Problemy peredachi informatsii 1.1 (1965), pp. 3â€“11 (cit. on
p. 2).
[Lit88] N. Littlestone. â€œLearning quickly when irrelevant attributes abound: A new linear-
threshold algorithmâ€. In: Machine learning 2 (1988), pp. 285â€“318 (cit. on p. 3).
11[MF98] N. Merhav and M. Feder. â€œUniversal predictionâ€. In: IEEE Transactions on Infor-
mation Theory 44.6 (1998), pp. 2124â€“2147 (cit. on pp. 1, 2).
[MG22] J. Mourtada and S. GaÃ¯ffas. â€œAn improper estimator with optimal excess risk in
misspecified density estimation and logistic regressionâ€. In: Journal of Machine
Learning Research 23.31 (2022), pp. 1â€“49 (cit. on p. 22).
[OH99] M. Opper and D. Haussler. â€œWorst case prediction over sequences under log
lossâ€. In: The Mathematics of Information Coding, Extraction and Distribution .
Springer, 1999, pp. 81â€“90 (cit. on p. 3).
[OS04] A. Orlitsky and N. P. Santhanam. â€œSpeaking of infinity [iid strings]â€. In: IEEE
Transactions on Information Theory 50.10 (2004), pp. 2215â€“2230 (cit. on p. 2).
[RS14a] A. Rakhlin and K. Sridharan. â€œOnline non-parametric regressionâ€. In: Conference
on Learning Theory . PMLR. 2014, pp. 1232â€“1264 (cit. on pp. 2, 3).
[RS14b] A. Rakhlin and K. Sridharan. â€œStatistical Learning and Sequential Predictionâ€. In:
2014 (cit. on p. 3).
[RS15] A. Rakhlin and K. Sridharan. â€œSequential probability assignment with binary al-
phabets and large classes of expertsâ€. In: arXiv preprint arXiv:1501.07340 (2015)
(cit. on pp. 2, 3, 7, 14, 25).
[RST10] A. Rakhlin, K. Sridharan, and A. Tewari. â€œOnline learning: Random averages,
combinatorial parameters, and learnabilityâ€. In: Advances in Neural Information
Processing Systems 23 (2010) (cit. on pp. 2, 3).
[RST15] A. Rakhlin, K. Sridharan, and A. Tewari. â€œSequential complexities and uniform
martingale laws of large numbersâ€. In: Probability theory and related fields 161
(2015), pp. 111â€“153 (cit. on pp. 1â€“3, 9, 10, 14).
[RSS12] S. Rakhlin, O. Shamir, and K. Sridharan. â€œRelax and randomize: From value to
algorithmsâ€. In: Advances in Neural Information Processing Systems 25 (2012)
(cit. on p. 9).
[Ris78] J. Rissanen. â€œModeling by shortest data descriptionâ€. In: Automatica 14.5 (1978),
pp. 465â€“471 (cit. on p. 2).
[Ris84] J. Rissanen. â€œUniversal coding, information, prediction, and estimationâ€. In: IEEE
Transactions on Information theory 30.4 (1984), pp. 629â€“636 (cit. on pp. 1, 2).
[Ris86] J. Rissanen. â€œComplexity of strings in the class of Markov sourcesâ€. In: IEEE
Transactions on Information Theory 32.4 (1986), pp. 526â€“532 (cit. on p. 2).
[Ris87] J. Rissanen. â€œStochastic complexityâ€. In: Journal of the Royal Statistical Society:
Series B (Methodological) 49.3 (1987), pp. 223â€“239 (cit. on p. 2).
[RL81] J. Rissanen and G. Langdon. â€œUniversal modeling and codingâ€. In: IEEE Trans-
actions on Information Theory 27.1 (1981), pp. 12â€“23 (cit. on p. 2).
[Ris76] J. J. Rissanen. â€œGeneralized Kraft inequality and arithmetic codingâ€. In: IBM
Journal of research and development 20.3 (1976), pp. 198â€“203 (cit. on p. 2).
[Ris96] J. J. Rissanen. â€œFisher information and stochastic complexityâ€. In: IEEE transac-
tions on information theory 42.1 (1996), pp. 40â€“47 (cit. on p. 2).
[Sha06] G. I. Shamir. â€œOn the MDL principle for iid sources with large alphabetsâ€. In:
IEEE transactions on information theory 52.5 (2006), pp. 1939â€“1955 (cit. on
p. 2).
[Sha20] G. I. Shamir. â€œLogistic regression regret: Whatâ€™s the catch?â€ In: Conference on
Learning Theory . PMLR. 2020, pp. 3296â€“3319 (cit. on p. 1).
[Sht87] Y . M. Shtarkov. â€œUniversal Sequential Coding of Single Messagesâ€. In: Problems
of Information Transmission 23 (3 1987), pp. 3â€“17 (cit. on pp. 1, 2, 4).
[Sio58] M. Sion. â€œOn general minimax theoremsâ€. In: Pacific Journal of Mathematics 8
(1958), pp. 171â€“176 (cit. on p. 15).
[Sol64] R. Solmonoff. â€œA formal theory of inductive inference. Iâ€. In: II Information and
Control 7 (1964), pp. 224â€“254 (cit. on p. 2).
[Szp98] W. Szpankowski. â€œOn asymptotics of certain recurrences arising in universal cod-
ingâ€. In: PROBLEMS OF INFORMATION TRANSMISSION C/C OF PROBLEMY
PEREDACHI INFORMATSII 34 (1998), pp. 142â€“146 (cit. on p. 2).
12[V ov95] V . G. V ovk. â€œA game of prediction with expert adviceâ€. In: Proceedings of the
eighth annual conference on Computational learning theory . 1995, pp. 51â€“60 (cit.
on p. 1).
[WHGS23] C. Wu, M. Heidari, A. Grama, and W. Szpankowski. â€œRegret Bounds for Log-loss
via Bayesian Algorithmsâ€. In: IEEE Transactions on Information Theory (2023)
(cit. on pp. 2â€“4, 6, 7, 15, 25, 26).
[XB97] Q. Xie and A. R. Barron. â€œMinimax redundancy for the class of memoryless
sourcesâ€. In: IEEE Transactions on Information Theory 43.2 (1997), pp. 646â€“
657 (cit. on p. 2).
[XB00] Q. Xie and A. R. Barron. â€œAsymptotic minimax regret for data compression, gam-
bling, and predictionâ€. In: IEEE Transactions on Information Theory 46.2 (2000),
pp. 431â€“445 (cit. on p. 1).
[ZL77] J. Ziv and A. Lempel. â€œA universal algorithm for sequential data compressionâ€.
In:IEEE Transactions on information theory 23.3 (1977), pp. 337â€“343 (cit. on
p. 2).
[ZL78] J. Ziv and A. Lempel. â€œCompression of individual sequences via variable-rate
codingâ€. In: IEEE transactions on Information Theory 24.5 (1978), pp. 530â€“536
(cit. on p. 2).
13A Proofs for Section 3
Notations. When the context and label sequences x1:T, y1:Tare clear from the context, we may
useftto denote the probability vector f(x1:t, y1:tâˆ’1)âˆˆâˆ†(Y)produced by hypothesis fat time t
for notational convenience. We also adopt the notation for repeated operators in [RST15; BFR20],
denoting Opt1Â·Â·Â·OptT[Â·Â·Â·]byâŸªOpttâŸ«T
t=1h
Â·Â·Â·i
. For any discrete distribution Pand discrete
random variables X, Y , letH(P)be the entropy of PandH(X|Y)be the conditional entropy of
Xgiven Y.
A.1 Proof overview of Theorem 3.2
Before presenting the proof of Theorem 3.2 in full details in Appendices A.2 to A.4, we give a
high-level overview here.
The proof starts from swapping the pairs of inf and sup (after randomizing the labels revealed by the
nature) in the extensive formulation of RT(F)to move to the dual game , where the learner predicts
after seeing the action of the nature. Trivially the value of this swapped game is a lower bound for
RT(F), and after rearranging we get that
the value of the swapped game = sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)]â‰¤ R T(F),
where the supremum is taken over all context trees xand probabilistic trees p, of depth T. Also
Eyâˆ¼pmeans the nested conditional expectations Ey1âˆ¼p1(y)Ey2âˆ¼p2(y)Â·Â·Â·EyTâˆ¼pT(y).
Similar to the proof of Lemma 6 in [BFR20] for the binary label setting, we apply the minimax
theorem with a tweak that we devise to handle multiary labels to derive that
RT(F) = sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)](3)
under some mild regularity condition for F. A key observation is that the supremum over depth- T
probabilistic trees pis equivalent to the supremum over joint distributions PoverYT. Based on
this observation and some algebra, for a fixed context tree x, the supremum over pin Eq. (3) is
sup
Pâˆˆâˆ†(YT)H(P) +Eyâˆ¼P
sup
fâˆˆFlogPf(y|x(y))
.
The value of this maximization problem can be easily computed to be
log X
ysup
fâˆˆFPf(y|x(y))!
= log ST(F|x).
Thus,
RT(F) = sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)]
= sup
xsup
Pâˆˆâˆ†(YT)H(P) +Eyâˆ¼P
sup
fâˆˆFlogPf(y|x(y))
= sup
xlogST(F|x).
However, Eq. (3) is not guaranteed when there is no assumed regularity condition for F. To get
away from this, prior works have assumed a particular hypothesis is included in Fsuch that the
enlarged class allows for the minimax swap [RS15; BFR20]. Nevertheless, even adding a mere
hypothesis may lead to suboptimal analysis for some classes F, say when RT(F)is of constant
order. To completely get rid of any regularity assumption and obtain a unified characterization of
the minimax regret for arbitrary class F, we provide a novel argument as follows. For an arbitrary
classF, we study a smooth truncated version of it, denoted by FÎ´for any level Î´âˆˆ(0,1/2), such
thatFÎ´always validates the use of the minimax theorem and hence RT(FÎ´) = supxlogST(FÎ´|x).
Then we give a series of refined analysis comparing the minimax regrets and contextual Shtarkov
sums of FandFÎ´that yields
RT(F)â‰¤ R T(FÎ´) +Tlog(1 + |Y|Î´) = sup
xlogST(FÎ´|x) +Tlog(1 + |Y|Î´)
â‰¤log
sup
xST(F|x) +Î´Â·C(T,|Y|)
+Tlog(1 + |Y|Î´),
where C(T,|Y|)<âˆis a positive constant that only depends on Tand|Y|. Sending Î´â†’0+
will conclude that RT(F)â‰¤supxlogST(F|x), which finishes the whole proof as we already have
RT(F)â‰¥supxlogST(F|x)from the start.
14A.2 Minimax swap
As standard in online learning literature, we will first move to a dual game after applying a minimax
swap at each round of the game. Under mild assumptions, the value of the original game coincides
with the that of the swapped game. More specifically, we have:
Lemma A.1 Whenever Fsatisfies that for every sequence x1:Tâˆˆ XT, y1:Tâˆˆ YT,
inf
fâˆˆFTX
t=1â„“(f(x1:t, y1:tâˆ’1), yt)<âˆ, (4)
we have that
RT(F) = sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)],(5)
where the supremum is taken over all X-valued Y-ary trees xandâˆ†(Y)-valued Y-ary trees p, of
depth T. AlsoEyâˆ¼pmeans the nested conditional expectations Ey1âˆ¼p1(y)Ey2âˆ¼p2(y)Â·Â·Â·EyTâˆ¼pT(y).
To deal with the unboundedness of log loss in the proof, we introduce the following truncation
method inspired by [BFR23; WHGS23], generalizing the one in [BFR20] which was specific to
binary labels.
Definition A.2 (Smooth truncation) The general smooth truncation map Ï„Î´: âˆ†(Y)â†’âˆ†(Y)is
defined such that for all pâˆˆâˆ†(Y)andyâˆˆ Y,
Ï„Î´(p)(y) =p(y) +Î´
1 +|Y|Î´,
given threshold Î´âˆˆ(0,1/2).
It is easy to check that Ï„Î´(p)is indeed a valid member in âˆ†(Y)andÏ„Î´(p)(y)âˆˆ[Î´/(1 +|Y|Î´),(1 +
Î´)/(1 +|Y|Î´)]. Moreover, it is not hard to verify that Ï„Î´(âˆ†(Y)) ={pâˆˆâˆ†(Y) :p(y)âˆˆ[Î´/(1 +
|Y|Î´),(1 +Î´)/(1 +|Y|Î´)],âˆ€yâˆˆ Y} . We will use âˆ†Î´(Y)to denote this image set Ï„Î´(âˆ†(Y)).
Proof of Lemma A.1 FixÎ´âˆˆ(0,1/2). By restricting the learnerâ€™s prediction Ë†pttoâˆ†Î´(Y), we get
an upper bound on RT(F):
RT(F)â‰¤âŸªsup
xtinf
Ë†ptâˆˆâˆ†Î´(Y)sup
ytâŸ«T
t=1hTX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)i
=âŸªsup
xtinf
Ë†ptâˆˆâˆ†Î´(Y)sup
ytâŸ«Tâˆ’1
t=1sup
xTinf
Ë†pTâˆˆâˆ†Î´(Y)sup
pTEyTâˆ¼pThTX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)i
.
Now we can apply Sionâ€™s minimax theorem [Sio58] to the function
A(Ë†pT, pT) =EyTâˆ¼pThTX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)i
to derive that
inf
Ë†pTâˆˆâˆ†Î´(Y)sup
pTâˆˆâˆ†(Y)A(Ë†pT, pT) = sup
pTâˆˆâˆ†(Y)inf
Ë†pTâˆˆâˆ†Î´(Y)A(Ë†pT, pT).
This is because:
1.A(Ë†pT, pT)is convex and continuous in Ë†pTover the compact âˆ†Î´(Y)and
2.A(Ë†pT, pT)is concave and continuous in pTover the compact âˆ†(Y), which is further due
to that A(Ë†pT, pT)is linear in pTand is bounded given Eq. (4).
15Hence
RT(F)â‰¤âŸªsup
xtinf
Ë†ptâˆˆâˆ†Î´(Y)sup
ytâŸ«Tâˆ’1
t=1sup
xTsup
pTinf
Ë†pTâˆˆâˆ†Î´(Y)EyTâˆ¼pThTX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)i
=âŸªsup
xtinf
Ë†ptâˆˆâˆ†Î´(Y)sup
ytâŸ«Tâˆ’2
t=1sup
xTâˆ’1inf
Ë†pTâˆ’1âˆˆâˆ†Î´(Y)sup
pTâˆ’1EyTâˆ’1âˆ¼pTâˆ’1
hTâˆ’1X
t=1â„“(Ë†pt, yt) + sup
xTsup
pT
inf
Ë†pTâˆˆâˆ†Î´(Y)EyTâˆ¼pTâ„“(Ë†pT, yT)âˆ’EyTâˆ¼pTinf
fâˆˆFTX
t=1â„“(ft, yt)i
.
Again the order of infË†pTâˆ’1âˆˆâˆ†Î´(Y)andsuppTâˆ’1âˆˆâˆ†(Y)with respect to
B(Ë†pTâˆ’1, pTâˆ’1) =EyTâˆ’1âˆ¼pTâˆ’1hTâˆ’1X
t=1â„“(Ë†pt, yt) + sup
xTsup
pT
inf
Ë†pTâˆˆâˆ†Î´(Y)EyTâˆ¼pTâ„“(Ë†pT, yT)âˆ’EyTâˆ¼pTinf
fâˆˆFTX
t=1â„“(ft, yt)i
can be swapped due to the same reason as above, leading to
RT(F)â‰¤âŸªsup
xtinf
Ë†ptâˆˆâˆ†Î´(Y)sup
ytâŸ«Tâˆ’2
t=1sup
xTâˆ’1sup
pTâˆ’1inf
Ë†pTâˆ’1âˆˆâˆ†Î´(Y)EyTâˆ’1âˆ¼pTâˆ’1
hTâˆ’1X
t=1â„“(Ë†pt, yt) + sup
xTsup
pT
inf
Ë†pTâˆˆâˆ†Î´(Y)EyTâˆ¼pTâ„“(Ë†pT, yT)âˆ’EyTâˆ¼pTinf
fâˆˆFTX
t=1â„“(ft, yt)i
=âŸªsup
xtinf
Ë†ptâˆˆâˆ†Î´(Y)sup
ytâŸ«Tâˆ’3
t=1sup
xTâˆ’2inf
Ë†pTâˆ’2âˆˆâˆ†Î´(Y)sup
pTâˆ’2EyTâˆ’2âˆ¼pTâˆ’2
nTâˆ’2X
t=1â„“(Ë†pt, yt) + sup
xTâˆ’1sup
pTâˆ’1h
inf
Ë†pTâˆ’1âˆˆâˆ†Î´(Y)EyTâˆ’1âˆ¼pTâˆ’1â„“(Ë†pTâˆ’1, yTâˆ’1)
+EyTâˆ’1âˆ¼pTâˆ’1sup
xTsup
pTh
inf
Ë†pTâˆˆâˆ†Î´(Y)EyTâˆ¼pTâ„“(Ë†pT, yT)âˆ’EyTâˆ¼pTinf
fâˆˆFTX
t=1â„“(ft, yt)iio
.
Repeating this procedure through all Trounds yields
RT(F)â‰¤âŸªsup
xtsup
ptEytâˆ¼ptâŸ«T
t=1sup
fâˆˆFhTX
t=1inf
Ë†ptâˆˆâˆ†Î´(Y)Eytâˆ¼pt[â„“(Ë†pt, yt)]âˆ’â„“(ft, yt)i
.
By Lemma A.7, we know that we do not lose too much by restricting learnerâ€™s prediction to âˆ†Î´(Y):
RT(F)â‰¤âŸªsup
xtsup
ptEytâˆ¼ptâŸ«T
t=1sup
fâˆˆFhTX
t=1inf
Ë†ptEytâˆ¼pt[â„“(Ë†pt, yt)]âˆ’â„“(ft, yt)i
+|Y|Î´T.
Sending Î´â†’0+on the RHS of the above inequality, we get
RT(F)â‰¤âŸªsup
xtsup
ptEytâˆ¼ptâŸ«T
t=1sup
fâˆˆFhTX
t=1inf
Ë†ptEytâˆ¼pt[â„“(Ë†pt, yt)]âˆ’â„“(ft, yt)i
.
It is easy to see that on the RHS of the above inequality, the inner infimum over Ë†ptâˆˆâˆ†(Y)is
achieved at Ë†pt=ptdue to the nature of log loss. So
RT(F)â‰¤âŸªsup
xtsup
ptEytâˆ¼ptâŸ«T
t=1sup
fâˆˆFhTX
t=1Eytâˆ¼pt[â„“(pt, yt)]âˆ’â„“(ft, yt)i
= sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)],
where in the last equality we use the compact notation of trees to further simplify our expression
and this concludes the proof. â– 
16Lemma A.3 For any hypothesis class Fand horizon T,
sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)] = sup
xlogST(F|x).(6)
It is implied that whenever Fsatisfies Eq. (5), we have
RT(F) = sup
xlogST(F|x).
Proof of Lemma A.3 First we can see that the outcome sequence y1:Tgenerated under any tree
pis the same thing as y1:Tgenerated by its associated joint distribution over YT, and vice versa.
So we can replace the supremum over trees pin the LHS of Eq. (6) by the supremum over joint
distributions PoverYT. Hence,
sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)] = sup
x,PEyâˆ¼P[RT(F;p(y),x(y),y)]
= sup
x,PEyâˆ¼PhTX
t=1â„“(Pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)i
,
where Ptdenotes the conditional distribution Pt(Â·|y1:tâˆ’1)âˆˆâˆ†(Y)ofytunder Pgiven y1:tâˆ’1.
Now fix the context tree xand distribution P. Then we can see that Eyâˆ¼P[â„“(Pt, yt)] =
H(yt|y1:tâˆ’1). SoEyâˆ¼P[PT
t=1â„“(Pt, yt)] =PT
t=1H(yt|y1:tâˆ’1) =H(P). Further notice that
inf
fâˆˆFTX
t=1â„“(ft, yt) = inf
fâˆˆF(âˆ’logPf(y1:T|x1:T)) =âˆ’sup
fâˆˆFlogPf(y1:T|x1:T).
So naturally we define the map Fx:YTâ†’Râˆª {âˆ’âˆ} by
Fx(y) = sup
fâˆˆFlogPf(y|x(y)),
and then we see that
Eyâˆ¼PhTX
t=1â„“(Pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“((f(xt(y)), yt)i
=H(P) +Eyâˆ¼P[Fx(y)].
For any given tree x, notice that the optimization problem
sup
Pâˆˆâˆ†(YT)H(P) +Eyâˆ¼P[Fx(y)]
is actually a maximization problem in the form of max Pâˆˆâˆ†(YT)H(P) +âŸ¨P, vâŸ©, where vis some
|Y|Tâˆ’dimensional vector. According to the conjugacy between negative entropy function and log-
sum-exp function, the optimal Pâˆ—is given by
Pâˆ—(y) =exp(Fx(y))P
yâ€²exp(Fx(yâ€²))=supfâˆˆFPf(y|x(y))P
yâ€²supfâˆˆFPf(yâ€²|x(yâ€²)),âˆ€yâˆˆ YT.
Note that the above formula for Pâˆ—is also valid when Fx(y) =âˆ’âˆ for some y, since Pâˆ—should
be supported on {yâˆˆ YT:Fx(y)>âˆ’âˆ} , and Fx(y)cannot be âˆ’âˆ for all ydue to Lemma D.1.
The associated value of this maximization problem is
log X
yexp(Fx(y))!
= log X
ysup
fâˆˆFPf(y|x(y))!
.
Therefore,
sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)] = sup
x,PEyâˆ¼PhTX
t=1â„“(Pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)i
= sup
xsup
Pn
H(P) +Eyâˆ¼P[Fx(y)]o
= sup
xlog X
ysup
fâˆˆFPf(y|x(y))!
= sup
xlogST(F|x).
â– 
17In the proof of Lemma A.1, if we do not restrict the learnerâ€™s prediction and simply swap the order
of inf and sup to produce an inequality at each time t, we will reach the following folklore result.
Lemma A.4 For any hypothesis class Fand horizon T,
RT(F)â‰¥sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)].(7)
Proof of Lemma A.4 To get Eq. (7), we simply need to reverse the order of sup and inf at each time
in the extensive formulation of minimax regret and produce an inequality:
RT(F) = sup
x1inf
Ë†p1sup
y1Â·Â·Â·sup
xTinf
Ë†pTsup
yTRT(F; Ë†p1:T, x1:T, y1:T)
=âŸªsup
xtinf
Ë†ptsup
ytâŸ«T
t=1hTX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(f(x1:t, y1:tâˆ’1), yt)i
=âŸªsup
xtinf
Ë†ptsup
ytâŸ«Tâˆ’1
t=1sup
xTinf
Ë†pTsup
pTEyTâˆ¼pThTX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)i
â‰¥âŸªsup
xtinf
Ë†ptsup
ytâŸ«Tâˆ’1
t=1sup
xTsup
pTinf
Ë†pTEyTâˆ¼pThTX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)i
=âŸªsup
xtinf
Ë†ptsup
ytâŸ«Tâˆ’1
t=1hTâˆ’1X
t=1â„“(Ë†pt, yt) + sup
xTsup
pT
inf
Ë†pTEyTâˆ¼pTâ„“(Ë†pT, yT)âˆ’EyTâˆ¼pTinf
fâˆˆFTX
t=1â„“(ft, yt)i
.
Iterating the argument and rearranging terms as above, we will get that
RT(F)â‰¥âŸªsup
xtsup
ptEytâˆ¼ptâŸ«T
t=1sup
fâˆˆFhTX
t=1inf
Ë†ptEytâˆ¼pt[â„“(Ë†pt, yt)]âˆ’â„“(ft, yt)i
=âŸªsup
xtsup
ptEytâˆ¼ptâŸ«T
t=1sup
fâˆˆFhTX
t=1Eytâˆ¼pt[â„“(pt, yt)]âˆ’â„“(ft, yt)i
= sup
x,pEyâˆ¼p[RT(F;p(y),x(y),y)].
â– 
A.3 Smooth truncated hypothesis class
To remove the reliance on Eq. (4), we introduce a smooth truncated version of Fthat always satisfies
Eq. (4) and study its minimax regret as well as contextual Shtarkov sums, compared to those of the
untruncated class F. To be more specific, we will apply the smooth truncation map to hypotheses:
for any Î´âˆˆ(0,1/2)andf: (X Ã— Y )âˆ—Ã— X â†’ âˆ†(Y), we use fÎ´to denote its smooth truncated
counterpart Ï„Î´â—¦f; for any hypothesis class F, we use FÎ´to denote the corresponding smooth
truncated class Ï„Î´â—¦ F={Ï„Î´â—¦f:fâˆˆ F} . It is easy to verify that any smooth truncated class FÎ´
satisfies Eq. (4) and hence
RT(FÎ´) = sup
xlogST(FÎ´|x).
Next we control the effect of truncation on the minimax regret.
Lemma A.5 For any F, TandÎ´âˆˆ(0,1/2),
RT(F)â‰¤ R T(FÎ´) +TÂ·log(1 + |Y|Î´).
18Proof of Lemma A.5 Fix threshold Î´âˆˆ(0,1/2)and hypothesis f. By Lemma A.7, for any given
sequences x1:T, y1:T, there is
TX
t=1â„“(fÎ´(x1:t, y1:tâˆ’1), yt)âˆ’TX
t=1â„“(f(x1:t, y1:tâˆ’1), yt)â‰¤TÂ·log(1 + |Y|Î´). (8)
Then, for any sequence of predictions Ë†p1:T,
RT(F; Ë†p1:T, x1:T, y1:T) =TX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(ft, yt)
â‰¤TX
t=1â„“(Ë†pt, yt)âˆ’inf
fÎ´âˆˆFÎ´TX
t=1â„“(fÎ´
t, yt) +TÂ·log(1 + |Y|Î´)
=RT(FÎ´; Ë†p1:T, x1:T, y1:T) +TÂ·log(1 + |Y|Î´),
which concludes the proof. â– 
Lemma A.6 There exists a constant M(T)<âˆthat only depends on Tsuch that for any f, x1:Tâˆˆ
XT, y1:Tâˆˆ YTandÎ´âˆˆ(0,1/2),
PfÎ´(y1:T|x1:T)â‰¤Pf(y1:T|x1:T) +Î´Â·M(T).
Proof of Lemma A.6 Fix threshold Î´âˆˆ(0,1/2), hypothesis fand sequences x1:T, y1:T. Then
PfÎ´(y1:T|x1:T) =TY
t=1fÎ´
t(yt) =Y
tft(yt) +Î´
1 +|Y|Î´
â‰¤Y
t(ft(yt) +Î´)
=Y
tft(yt) +Î´Â·X
tY
tâ€²Ì¸=tftâ€²(ytâ€²) +Â·Â·Â·+Î´T
â‰¤Y
tft(yt) +Î´Â·M(T)
=Pf(y1:T|y1:T) +Î´Â·M(T),
where we can set M(T) =T+ T
2
+ T
3
+Â·Â·Â·+ T
T
since ft(yt)â€™s are bounded by 1. â– 
A.4 Putting together
Now we are fully prepared to finish the proof of Theorem 3.2, our main result in Section 3.
Proof of Theorem 3.2 By Lemma A.6, we have that for any context tree xof depth T,X
yâˆˆYTsup
fÎ´âˆˆFÎ´PfÎ´(y|x(y))â‰¤X
yâˆˆYTsup
fâˆˆFPf(y|x(y)) +Î´Â·M(T)Â· |Y|T.
Thus
RT(FÎ´) = sup
xlogST(FÎ´|x)
= sup
xlogï£«
ï£­X
yâˆˆYTsup
fÎ´âˆˆFÎ´PfÎ´(y|x(y))ï£¶
ï£¸
â‰¤sup
xlogï£«
ï£­X
yâˆˆYTsup
fâˆˆFPf(y|x(y)) +Î´Â·M(T)Â· |Y|Tï£¶
ï£¸
= logï£«
ï£­sup
xX
yâˆˆYTsup
fâˆˆFPf(y|x(y)) +Î´Â·M(T)Â· |Y|Tï£¶
ï£¸.
19Together with Lemma A.5, we get that for any Î´âˆˆ(0,1/2),
RT(F)â‰¤logï£«
ï£­sup
xX
yâˆˆYTsup
fâˆˆFPf(y|x(y)) +Î´Â·M(T)Â· |Y|Tï£¶
ï£¸+TÂ·log(1 + |Y|Î´).(9)
After sending Î´â†’0+on the RHS of Eq. (9),
RT(F)â‰¤logï£«
ï£­sup
xX
yâˆˆYTsup
fâˆˆFPf(y|x(y))ï£¶
ï£¸= sup
xlogST(F|x).
Recall that we have RT(F)â‰¥supxlogST(F|x)from Lemma A.4 and Lemma A.3. So finally,
RT(F) = sup
xlogST(F|x).
â– 
A.5 Additional proofs
Lemma A.7 For any pâˆˆâˆ†(Y)andÎ´âˆˆ(0,1/2),
â„“(Ï„Î´(p), y)â‰¤â„“(p, y) + log(1 + |Y|Î´)â‰¤â„“(p, y) +|Y|Î´,âˆ€yâˆˆ Y.
Proof of Lemma A.7 By direct computation, for any yâˆˆ Y,
â„“(Ï„Î´(p), y)âˆ’â„“(p, y) = logp(y)
p(y) +Î´Â·(1 +|Y|Î´)
â‰¤log(1 + |Y|Î´)
â‰¤ |Y| Î´.
â– 
A.6 Proof of Proposition 3.3
Starting from Theorem 3.2 that RT(F) = supxlogST(F|x), we have
RT(F) = sup
xlog X
ysup
fâˆˆFPf(y|x(y))!
â‰¤sup
xlogï£«
ï£­X
yX
fâˆˆFPf(y|x(y))ï£¶
ï£¸
= sup
xlogï£«
ï£­X
fâˆˆFX
yPf(y|x(y))ï£¶
ï£¸= log|F|,
where the last equality is due to Lemma D.1.
A.7 Proof of Lemma 3.8
It suffices to show that RFD
T(FLin)â‰¥âˆš
T/4. In particular, we only need to find some context
sequence x1:Tsuch that logST(FLin|x1:T)â‰¥âˆš
T/4due to Proposition 2.5. Here we pick x1:T
such that xtare unit vectors and xtâŠ¥xtâ€²whenever tÌ¸=tâ€². Such sequence exists because the
20dimension of B2is no smaller than T. In this way, for each possible label sequence y1:Tâˆˆ {0,1}T,
we can see that the fwâˆˆ FLinthat is indexed by
w=TX
t=12ytâˆ’1âˆš
Txt
achieves likelihood Pfw(y1:T|x1:T) = (1+1/âˆš
T
2)T. Therefore,
ST(FLin|x1:T) =X
y1:Tâˆˆ{0,1}Tsup
fâˆˆFLinPf(y1:T|x1:T)â‰¥X
y1:Tâˆˆ{0,1}T 
1 + 1 /âˆš
T
2!T
=
1 + 1 /âˆš
TT
,
which implies that RFD
T(FLin) = log ST(FLin|x1:T)â‰¥Tlog(1 + 1 /âˆš
T)â‰¥âˆš
T/4for all Tâ‰¥1.
B Proofs for Section 4
Notations. Again we may use ftto denote the probability vector f(x1:t, y1:tâˆ’1)âˆˆâˆ†(Y)produced
by hypothesis fat time twhen the context and label sequences x1:T, y1:Tare clear from the context.
For a context tree xof depth Tâˆ’tand a path yâˆˆ YTâˆ’t, we re-index x(y)as(xt+1(y), . . . , xT(y))
whenever it takes the last Tâˆ’tentries of the entire context sequence. And we do the same for the
probabilistic tree pas well. That is, whenever y= (yt+1, . . . , y T)âˆˆ YTâˆ’ttakes the last Tâˆ’t
entries of the whole label sequence and yâˆ¼p, then we will denote this label generating process by
yt+1âˆ¼pt+1(y), . . . , y Tâˆ¼pT(y).
B.1 Proof of Theorem 4.2
Recall that the minimax regret is
RT(F) =âŸªsup
xtinf
Ë†ptsup
ytâŸ«T
t=1hTX
t=1â„“(Ë†pt, yt)âˆ’inf
fâˆˆFTX
t=1â„“(f(x1:t, y1:tâˆ’1), yt)i
.
Through this extensive form of the minimax regret, we know that given x1:t, y1:tâˆ’1, the minimax
prediction Ë†pâˆ—
tat round tis the one that minimizes the following expression over all Ë†ptâˆˆâˆ†(Y):
sup
ytâŸªsup
xsinf
Ë†pssup
ysâŸ«T
s=t+1hTX
s=tâ„“(Ë†ps, ys)âˆ’inf
fâˆˆFTX
s=1â„“(f(x1:s, y1:sâˆ’1), ys)i
. (10)
Define
G(F, x1:t, y1:t) =âŸªsup
xsinf
Ë†pssup
ysâŸ«T
s=t+1hTX
s=t+1â„“(Ë†ps, ys)âˆ’inf
fâˆˆFTX
s=1â„“(f(x1:s, y1:sâˆ’1), ys)i
,
and now
Ë†pâˆ—
t= argmin
Ë†ptâˆˆâˆ†(Y)sup
ytn
â„“(Ë†pt, yt) +G(F, x1:t, y1:t)o
.
The crux of the proof is to show the following:
Lemma B.1 For any hypothesis class Fand sequences x1:tâˆˆ Xt, y1:tâˆˆ Yt,
G(F, x1:t, y1:t) = sup
xlogSx1:t,y1:t
T (F|x).
The proof of Lemma B.1 is done by essentially following the same strategy in Appendix A since
G(F, x1:t, y1:t)admits a similar extensive form with the minimax regret RT(F). For completeness
we provide its proof in Appendix B.2. Given Lemma B.1, we have
Ë†pâˆ—
t= argmin
Ë†ptâˆˆâˆ†(Y)sup
ytn
â„“(Ë†pt, yt) + sup
xlogSx1:t,y1:t
T (F|x)o
= argmin
Ë†ptâˆˆâˆ†(Y)sup
ytlogsupxSx1:t,y1:t
T (F|x)
Ë†pt(yt)
.
We apply the following result to solve the above program:
21Lemma B.2 [MG22, Lemma 15] Let g:Y â†’ [0,+âˆ]be a measurable function such that R
Yg(y)dÂµâˆˆ(0,+âˆ). Then,
inf
psup
yâˆˆYlogg(y)
p(y)= logZ
Yg(y)Âµ(dy)
, (11)
where the infimum in Eq. (11) spans over all probability densities p:Y â†’ [0,+âˆ)with respect to
Âµ, and the infimum is reached at
pâˆ—=gR
Yg(y)dÂµ.
Letting g(y) = supxSx1:t,(y1:tâˆ’1,y)
T (F|x)âˆˆ[0,1]andÂµbe the counting measure on the finite space
Y, we can apply Lemma B.2 whenever not all g(y)â€™s are 0. In this case, we solve that
Ë†pâˆ—
t(y) =g(y)P
yâ€²âˆˆYg(yâ€²)=supxSx1:t,(y1:tâˆ’1,y)
T (F|x)
P
yâ€²âˆˆYsupxSx1:t,(y1:tâˆ’1,yâ€²)
T (F|x),âˆ€yâˆˆ Y.
On the other hand, if g(y) = 0 ,âˆ€yâˆˆ Y, then any Ë†ptsuch that Ë†pt(y)>0,âˆ€yâˆˆ Y, is an minimax
optimal prediction. Moreover, it implies that Pf(y1:tâˆ’1|x1:tâˆ’1) = 0 ,âˆ€fâˆˆ F. This is because for
arbitrary context tree x,
0 =X
ytX
yâˆˆYTâˆ’tPf(y1:t,y|x1:t,x(y))
=X
ytPf(y1:t|x1:t)
=Pf(y1:tâˆ’1|x1:tâˆ’1).
So the cumulative loss for each expert fup to round tâˆ’1already blows up to +âˆand
the learner only needs to predict an arbitrary Ë†pâˆˆâˆ†+(Y)in all remaining rounds to achieve
RT(F; Ë†p1:T, x1:T, y1:T) =âˆ’âˆ.
Overall, we can see that the minimax optimal prediction Ë†pâˆ—
tâˆˆâˆ†(Y)at round tgiven x1:t, y1:tâˆ’1is
Ë†pâˆ—
t(y) =supxSx1:t,(y1:tâˆ’1,y)
T (F|x)
P
yâ€²âˆˆYsupxSx1:t,(y1:tâˆ’1,yâ€²)
T (F|x),âˆ€yâˆˆ Y,
if there exists yâˆˆ Y such that supxSx1:t,(y1:tâˆ’1,y)
T (F|x)>0. Otherwise, select Ë†pâˆ—
tto be an arbitrary
element in âˆ†+(Y)(and so do all remaining rounds).
B.2 Auxiliary lemmas
Recall that for any hypothesis class Fand sequences x1:tâˆˆ Xt, y1:tâˆˆ Yt,
G(F, x1:t, y1:t) =âŸªsup
xsinf
Ë†pssup
ysâŸ«T
s=t+1hTX
s=t+1â„“(Ë†ps, ys)âˆ’inf
fâˆˆFTX
s=1â„“(f(x1:s, y1:sâˆ’1), ys)i
=âŸªsup
xsinf
Ë†pssup
psEysâˆ¼psâŸ«T
s=t+1hTX
s=t+1â„“(Ë†ps, ys)âˆ’inf
fâˆˆFTX
s=1â„“(f(x1:s, y1:sâˆ’1), ys)i
.
To prove Lemma B.1, we need the following lemmas.
Lemma B.3 For any hypothesis class Fand sequences x1:tâˆˆ Xt, y1:tâˆˆ Yt,
G(F, x1:t, y1:t)â‰¥sup
x,pEyâˆ¼phTX
s=t+1Eysâˆ¼ps(y)[â„“(ps(y), ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
. (12)
And whenever for every xt+1:Tâˆˆ XTâˆ’t, yt+1:Tâˆˆ YTâˆ’t, it holds
inf
fâˆˆFTX
s=1â„“(f(x1:s, y1:sâˆ’1), ys)<âˆ, (13)
22then
G(F, x1:t, y1:t) = sup
x,pEyâˆ¼phTX
s=t+1Eysâˆ¼ps(y)[â„“(ps(y), ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
. (14)
Proof of Lemma B.3 First we see that similar to the proof of Lemma A.4, we can reverse every pair
of sup over psand inf over Ë†psin the extensive formulation of G(F, x1:t, y1:t)and rearrange terms
to obtain
G(F, x1:t, y1:t)â‰¥âŸªsup
xssup
psEysâˆ¼psâŸ«T
s=t+1hTX
s=t+1inf
Ë†psEysâˆ¼ps[â„“(Ë†ps, ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
,
and again due to the nature of log loss,
G(F, x1:t, y1:t)â‰¥âŸªsup
xssup
psEysâˆ¼psâŸ«T
s=t+1hTX
s=t+1Eysâˆ¼ps[â„“(ps, ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
= sup
x,pEyâˆ¼phTX
s=t+1Eysâˆ¼ps(y)[â„“(ps(y), ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
,
where in the last step we compress the expression using trees (of depth Tâˆ’t) and Eq. (12) is proved.
To show that the minimax swap is valid under Eq. (13), we follow the same strategy as in the proof
of Lemma A.1 by restricting the learnerâ€™s prediction Ë†pstoâˆ†Î´(Y)for any threshold Î´âˆˆ(0,1/2)
which yields
G(F, x1:t, y1:t)â‰¤âŸªsup
xssup
psEysâˆ¼psâŸ«T
s=t+1hTX
s=t+1inf
Ë†psâˆˆâˆ†Î´(Y)Eysâˆ¼ps[â„“(Ë†ps, ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
â‰¤âŸªsup
xssup
psEysâˆ¼psâŸ«T
s=t+1hTX
s=t+1inf
Ë†psEysâˆ¼ps[â„“(Ë†ps, ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
+|Y|Î´T.
So Eq. (14) is proved by sending Î´â†’0+on the RHS of the last inequality and the established
Eq. (12). â– 
Lemma B.4 For any hypothesis class Fand sequences x1:tâˆˆ Xt, y1:tâˆˆ Yt,
sup
x,pEyâˆ¼phTX
s=t+1Eysâˆ¼ps(y)[â„“(ps(y), ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
= sup
xlogSx1:t,y1:t
T (F|x).
Proof of Lemma B.4 The proof follows that of Lemma A.3. By replacing the probabilistic tree p
by the joint distribution Pâˆˆâˆ†(YTâˆ’t), we get
sup
x,pEyâˆ¼phTX
s=t+1Eysâˆ¼ps(y)[â„“(ps(y), ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
= sup
x,PEyâˆ¼PhTX
s=t+1â„“(Ps, ys)âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
= sup
xsup
Pâˆˆâˆ†(YTâˆ’t)H(P) +Eyâˆ¼Ph
sup
fâˆˆFlogPf(y1:t,y|x1:t,x(y))i
.
Similarly, for any fixed x, define the map Fx1:t,y1:tx :YTâˆ’tâ†’Râˆª {âˆ’âˆ} by
Fx1:t,y1:t
x (y) = sup
fâˆˆFlogPf(y1:t,y|x1:t,x(y)),
23and now we solve
sup
Pâˆˆâˆ†(YTâˆ’t)H(P) +Eyâˆ¼P[Fx1:t,y1:t
x (y)].
If there exists some yâˆˆ YTâˆ’tsuch that Fx1:t,y1:tx (y)>âˆ’âˆ, then the optimal Pâˆ—is given by
Pâˆ—(y) =exp(Fx1:t,y1:tx (y))P
yâ€²exp(Fx1:t,y1:tx (yâ€²))=supfâˆˆFPf(y1:t,y|x1:t,x(y))P
yâ€²supfâˆˆFPf(y1:t,yâ€²|x1:t,x(yâ€²)),âˆ€yâˆˆ YTâˆ’t,
and then
sup
x,pEyâˆ¼phTX
s=t+1Eysâˆ¼ps(y)[â„“(ps(y), ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
= sup
xsup
Pâˆˆâˆ†(YTâˆ’t)H(P) +Eyâˆ¼P[Fx1:t,y1:t
x (y)]
= sup
xlogX
ysup
fâˆˆFPf(y1:t,y|x1:t,x(y))
= sup
xlogSx1:t,y1:t
T (F|x).
However, if Fx1:t,y1:tx (y) =âˆ’âˆ for all y, then it implies that for any context tree x, path y, and
fâˆˆ F,Pf(y1:t,y|x1:t,x(y)) = 0 and hence,
sup
x,pEyâˆ¼phTX
s=t+1Eysâˆ¼ps(y)[â„“(ps(y), ys)]âˆ’inf
fâˆˆFTX
s=1â„“(fs, ys)i
= sup
xsup
Pâˆˆâˆ†(YTâˆ’t)H(P) +Eyâˆ¼P[Fx1:t,y1:t
x (y)]
=âˆ’ âˆ
= sup
xlogX
ysup
fâˆˆFPf(y1:t,y|x1:t,x(y))
= sup
xlogSx1:t,y1:t
T (F|x),
which finishes our proof. â– 
Now we are able to prove the key result Lemma B.1.
Proof of Lemma B.1 Fix any hypothesis class Fand sequences x1:tâˆˆ Xt, y1:tâˆˆ Yt. First we
know
G(F, x1:t, y1:t)â‰¥sup
xlogSx1:t,y1:t
T (F|x)
due to Eq. (12) and Lemma B.4. For the other direction, let us fix any threshold value Î´âˆˆ(0,1/2)
and then
G(F, x1:t, y1:t)â‰¤G(FÎ´, x1:t, y1:t) +TÂ·log(1 + |Y|Î´)
= sup
xlogSx1:t,y1:t
T (FÎ´|x) +TÂ·log(1 + |Y|Î´)
= sup
xlogX
yâˆˆYTâˆ’tsup
fÎ´âˆˆFÎ´PfÎ´(y1:t,y|x1:t,x(y))
+TÂ·log(1 + |Y|Î´)
â‰¤sup
xlogX
yâˆˆYTâˆ’tsup
fâˆˆFPf(y1:t,y|x1:t,x(y)) +Î´Â·M(T)Â· |Y|T
+TÂ·log(1 + |Y|Î´)
= log
sup
xX
yâˆˆYTâˆ’tsup
fâˆˆFPf(y1:t,y|x1:t,x(y)) +Î´Â·M(T)Â· |Y|T
+TÂ·log(1 + |Y|Î´),
where we have applied Lemma A.7, Lemma B.3, Lemma B.4, and Lemma A.6 accordingly. Simi-
larly, we send Î´â†’0+on the RHS of the last inequality and get
G(F, x1:t, y1:t)â‰¤sup
xlogX
yâˆˆYTâˆ’tsup
fâˆˆFPf(y1:t,y|x1:t,x(y))
= sup
xlogSx1:t,y1:t
T (F|x),
which concludes the proof. â– 
24C Additional discussions
C.1 On the time-variant context space
In this section we generalize our analysis to the setting where the context space can evolve over time.
We model time-varying context sets by a sequence of maps Xt:Xtâˆ’1Ã— Ytâˆ’1â†’2X, tâˆˆ[T]as in
[RS15; BFR20]. In each round t, instead of picking any context from X, the nature is now required
to only choose xtfromXt(x1:tâˆ’1, y1:tâˆ’1)âŠ† X . Then the minimax regret with respect to (Xt)tâˆˆ[T]
is rewritten as
RT(F) =âŸª sup
xtâˆˆXt(x1:tâˆ’1,y1:tâˆ’1)inf
Ë†ptsup
ytâŸ«T
t=1RT(F; Ë†p1:T, x1:T, y1:T).
A context tree xisconsistent with respect to (Xt)tâˆˆ[T]if for all tâˆˆ[T]andyâˆˆ YT,xt(y)âˆˆ
Xt(x1:tâˆ’1, y1:tâˆ’1). Then our results in Section 3 and Section 4 can be generalized simply by replac-
ing the supremum over all context trees (of depth T) by the supremum over all consistent context
trees. For example, we will have
RT(F) = sup
x:xis consistentlogST(F|x).
C.2 On the global and non-global sequential cover
Now we go back to consider the usual setting of binary label and constant experts, i.e., Y={0,1}
andF âŠ† [0,1]X. As mentioned in Section 3, previous works [BFR20; WHGS23] provided re-
gret upper bounds based on â„“âˆsequential entropy. More specifically, both of their bounds are in
the form of O(infÎ±>0{Î±T+H(F, Î±, T )}), with H(F, Î±, T )being either the non-global entropy
Hâˆ(F, Î±, T )or the global entropy HG(F, Î±, T ). It is then natural to ask which one of these two
bounds is tighter. It is straightforward to prove that Hâˆ(F, Î±, T )is no larger than HG(F, Î±, T ).
In fact, the gap between them is at most a polylog factor, as we state and prove below.1The proof
ofHâˆ(F, Î±, T )â‰¤ H G(F, Î±, T )is also included for completeness. Before stating the results, we
introduce the definition of sequential fat-shattering dimension.
Definition C.1 We say an X-valued binary tree xof depth disÎ±-shattered by a class F âŠ† [0,1]X
for some Î± >0, if there exists a [0,1]-valued binary tree sof depth dsuch that
âˆ€yâˆˆ {0,1}d,âˆƒfâˆˆ F,s.t.(2ytâˆ’1)Â·(f(xt(y))âˆ’st(y))â‰¥Î±
2,âˆ€tâˆˆ[d].
In this case, sis called the witness of the shattering. The sequential fat-shattering dimension of Fat
scale Î±, denoted by sfatÎ±(F), is the largest dsuch that some depth- dcontext tree is Î±-shattered by
F.
Proposition C.2 For any scale Î± >0, we have
Hâˆ(F, Î±, T )â‰¥min{T,sup
Î±â€²>Î±sfat2Î±â€²(F)} Â·log(2) .
Therefore, together with Hâˆ(F, Î±, T )â‰¤ H G(F, Î±, T )and the folklore HG(F, Î±, T )â‰¤
O(sfat Î±(F) log( T/Î±)), we conclude that the regret upper bounds O(infÎ±>0{Î±T+
H(F, Î±, T )}),H âˆˆ {H âˆ,HG}, differ by at most a polylog factor.
Proof of Proposition C.2 Fix any Î±â€²> Î± > 0and let dÎ±â€²denote min{T,sfat2Î±â€²(F)}. Then there
exists a context tree xand a witness tree s, both of depth dÎ±â€², such that for any path yâˆˆ {0,1}dÎ±â€²,
there exists an fâˆˆ F such that
âˆ€tâˆˆ[dÎ±â€²],(2ytâˆ’1)Â·(f(xt(y))âˆ’st(y))â‰¥Î±â€²> Î±. (15)
1This result and its detailed proof sketch were communicated to the first author by Changlong Wu. The
argument here differs only in minor details that we introduced, perhaps unnecessarily, to arrive at a rigorous
proof.
25LetVx,Î±be an arbitrary sequential â„“âˆcovering of Fonx. Now we select a path yand a sequence
of subsets V(t)
x,Î±âŠ†Vx,Î±, tâˆˆ[dÎ±â€²]in the following recursive way. Define V(0)
x,Î±=Vx,Î±. For
each tâˆˆ[dÎ±â€²], choose ytâˆˆ {0,1}such that 2ytâˆ’1âˆˆ {âˆ’ 1,+1}is the minority among all
sgn(vt(y1:tâˆ’1)âˆ’st(y1:tâˆ’1)), vâˆˆV(tâˆ’1)
x,Î± (ignoring those of 0â€™s). Finally update V(t)
x,Î±={vâˆˆ
V(tâˆ’1)
x,Î±: sgn( vt(y1:tâˆ’1)âˆ’st(y1:tâˆ’1)) = 2 ytâˆ’1}.
First we argue that, if there is any time tâ€²âˆˆ[dÎ±â€²]such that V(tâ€²âˆ’1)
x,Î±Ì¸=âˆ…, V(tâ€²)
x,Î±=âˆ…, then Vx,Î±
is not a valid cover of Fonx. Otherwise, recall we have selected y1, . . . , y tâ€²âˆ’1. Now pick an
arbitrary ytâ€²âˆˆ {0,1}. By Eq. (15) we can find some fâˆˆ F such that (2ytâˆ’1)Â·(f(xt(y1:tâˆ’1))âˆ’
st(y1:tâˆ’1))> Î±,âˆ€tâˆˆ[tâ€²]. Since Vx,Î±is a covering at scale Î±, there is vâˆˆVx,Î±such that |vt(y)âˆ’
f(xt(y))| â‰¤Î±,âˆ€tâˆˆ[tâ€²]. This implies that sgn(f(xt(y))âˆ’st(y)) = sgn( vt(y)âˆ’st(y)) =
2ytâˆ’1,âˆ€tâˆˆ[tâ€²]. So we can always find some member of V(tâ€²âˆ’1)
x,Î± to match the minority sign of
vtâ€²(y1:tâ€²âˆ’1)âˆ’stâ€²(y1:tâ€²âˆ’1), vâˆˆV(tâ€²âˆ’1)
x,Î± , which means that V(tâ€²)
x,Î±Ì¸=âˆ…and yields a contradiction.
Now we know that |V(t)
x,Î±| â‰¥1,âˆ€tâˆˆ[dÎ±â€²]. By design |V(t)
x,Î±| â‰¤ | V(tâˆ’1)
x,Î±|/2,âˆ€tâˆˆ[dÎ±â€²], so we
must have |Vx,Î±|=|V(0)
x,Î±| â‰¥2dÎ±â€². As the choice of covering is arbitrary, the covering number
Nâˆ(F â—¦x, Î±, d Î±â€²)is also lower bounded by 2dÎ±â€²and hence Hâˆ(F, Î±, d Î±â€²)â‰¥dÎ±â€²Â·log(2) . If
supÎ±â€²>Î±sfat2Î±â€²(F)â‰¤T, then we get that
Hâˆ(F, Î±, T )â‰¥sup
Î±â€²>Î±Hâˆ(F, Î±,sfat2Î±â€²(F))â‰¥sup
Î±â€²>Î±sfat2Î±â€²(F)Â·log(2) .
If there is some Î±â€²> Î± such that sfat2Î±â€²(F)â‰¥T, then
Hâˆ(F, Î±, T ) =Hâˆ(F, Î±, d Î±â€²)â‰¥TÂ·log(2) .
Combining these two cases together, we have
Hâˆ(F, Î±, T )â‰¥min{T,sup
Î±â€²>Î±sfat2Î±â€²(F)} Â·log(2) .
â– 
Proposition C.3 LetGÎ±be a global sequential Î±-covering of Fas defined in [WHGS23]. Then for
any context tree x, there exists a sequential cover Vx,Î±ofF â—¦xat scale Î±with|Vx,Î±| â‰¤ |G Î±|. This
implies that Hâˆ(F, Î±, T )â‰¤log|GÎ±|.
Proof of Proposition C.3 Fix arbitrary context tree x. For any gâˆˆ GÎ±, define the [0,1]-valued tree
vgbyvg
t(y) =g(x1:t(y)),âˆ€tâˆˆ[T],yâˆˆ YT. Now let Vx,Î±={vg:gâˆˆ GÎ±}and we will show that
Vx,Î±is indeed a sequential cover of F â—¦xat scale Î±.
For any fâˆˆ F andyâˆˆ YT, tree xyields a length âˆ’Tsequence x1:T(y)and by definition of the
global sequential covering, there exists gâˆˆ GÎ±such that
|f(xt(y))âˆ’g(x1:t(y))| â‰¤Î±,âˆ€tâˆˆ[T].
So by our construction of Vx,Î±,vgâˆˆVx,Î±holds
|f(xt(y))âˆ’vg
t(y)|=|f(xt(y))âˆ’g(x1:t(y))| â‰¤Î±,âˆ€tâˆˆ[T],
which yields our claim after observing |Vx,Î±| â‰¤ |G Î±|. â– 
D Additional proofs
Lemma D.1 For any X-valued Y-ary context tree xof depth T, and f: (X Ã— Y )âˆ—Ã— X â†’ âˆ†(Y),
we have X
yâˆˆYTPf(y|x(y)) = 1 ,(16)
where we recall that x(y)denotes the context sequence (x1(y), . . . , xT(y)).
26Proof of Lemma D.1 This is done by induction on the depth T. The key observation is that for any
label sequence y,xt(y) =xt(y1, . . . , y tâˆ’1)only depends on the first tâˆ’1labels. For T= 1, any
context tree xis represented by its root node x1(Â·) =x1âˆˆ X and hence
X
y1Pf(y1|x1) =X
y1f(x1)(y1) = 1 .
Suppose Eq. (16) holds for all context trees xof depth Tâ‰¤dand all sequential functions f. Now
given any context tree x= (x1, . . . , xd+1)of depth T=d+ 1, we denote its depth dsubtree
(x1, . . . , xd)byx[d]. Then
X
yâˆˆYd+1Pf(y|x(y)) =X
y1:dX
yd+1Pf(y1:d+1|x1,x2(y1), . . . , xd+1(y1:d))
=X
y1:dX
yd+1Pf(y1:d|x1, . . . , xd(y1:dâˆ’1))Â·f(x1, . . . , xd+1(y1:d), y1:d)(yd+1)
=X
y1:dPf(y1:d|x1, . . . , xd(y1:dâˆ’1))X
yd+1f(x1, . . . , xd+1(y1:d), y1:d)(yd+1)
=X
y1:dPf(y1:d|x1, . . . , xd(y1:dâˆ’1))
=X
yâˆˆYdPf(y|x[d](y)) = 1 ,
where the last step is due to induction. We are done. â– 
27NeurIPS Paper Checklist
The checklist is designed to encourage best practices for responsible machine learning research, ad-
dressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
the checklist: The papers not including the checklist will be desk rejected. The checklist should
follow the references and precede the (optional) supplemental material. The checklist does NOT
count towards the page limit.
Please read the checklist guidelines carefully for information on how to answer these questions. For
each question in the checklist:
â€¢ You should answer [Yes] , [No] , or [NA]
â€¢ [NA] means either that the question is Not Applicable for that particular paper or the
relevant information is Not Available.
â€¢ Please provide a short (1â€“2 sentence) justification right after your answer (even for NA).
The checklist answers are an integral part of your paper submission. They are visible to the
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
(after eventual revisions) with the final version of your paper, and its final version will be published
with the paper.
The reviewers of your paper will be asked to use the checklist as one of the factors in their evalu-
ation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No]
" provided a proper justification is given (e.g., "error bars are not reported because it would be too
computationally expensive" or "we were unable to find the license for the dataset we used"). In
general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased
in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your
best judgment and write a justification to elaborate. All supporting evidence can appear either in the
main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question,
in the justification please point to the section(s) where related material for the question can be found.
IMPORTANT, please:
â€¢Delete this instruction block, but keep the section heading â€œNeurIPS paper checklist" ,
â€¢Keep the checklist subsection headings, questions/answers and guidelines below.
â€¢Do not modify the questions and only use the provided macros for your answers .
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: Abstract summarizes theorems we have proven.
Guidelines:
â€¢ The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢ The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢ The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢ It is fine to include aspirational goals as motivation as long as it is clear that these
goals are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
28Justification: We discuss limitations in the Discussion section.
Guidelines:
â€¢ The answer NA means that the paper has no limitation while the answer No means
that the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢ The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The au-
thors should reflect on how these assumptions might be violated in practice and what
the implications would be.
â€¢ The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢ The authors should reflect on the factors that influence the performance of the ap-
proach. For example, a facial recognition algorithm may perform poorly when image
resolution is low or images are taken in low lighting. Or a speech-to-text system might
not be used reliably to provide closed captions for online lectures because it fails to
handle technical jargon.
â€¢ The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢ If applicable, the authors should discuss possible limitations of their approach to ad-
dress problems of privacy and fairness.
â€¢ While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We donâ€™t see how to justify this without machine checkable proofs, which we
have not provided.
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢ All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢ All assumptions should be clearly stated or referenced in the statement of any theo-
rems.
â€¢ The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a
short proof sketch to provide intuition.
â€¢ Inversely, any informal proof provided in the core of the paper should be comple-
mented by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main
experimental results of the paper to the extent that it affects the main claims and/or conclu-
sions of the paper (regardless of whether the code and data are provided or not)?
Answer: [NA]
Justification: There are no experiments.
29Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢ If the contribution is a dataset and/or model, the authors should describe the steps
taken to make their results reproducible or verifiable.
â€¢ Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture
fully might suffice, or if the contribution is a specific model and empirical evaluation,
it may be necessary to either make it possible for others to replicate the model with
the same dataset, or provide access to the model. In general. releasing code and data
is often one good way to accomplish this, but reproducibility can also be provided via
detailed instructions for how to replicate the results, access to a hosted model (e.g., in
the case of a large language model), releasing of a model checkpoint, or other means
that are appropriate to the research performed.
â€¢ While NeurIPS does not require releasing code, the conference does require all sub-
missions to provide some reasonable avenue for reproducibility, which may depend
on the nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear
how to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to re-
produce the model (e.g., with an open-source dataset or instructions for how to
construct the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case au-
thors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [NA]
Justification: There is no data or code.
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢ Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢ While we encourage the release of code and data, we understand that this might not
be possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢ The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢ The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢ The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
30â€¢ At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢ Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA]
Justification: There are no experiments.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ The experimental setting should be presented in the core of the paper to a level of
detail that is necessary to appreciate the results and make sense of them.
â€¢ The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropri-
ate information about the statistical significance of the experiments?
Answer: [NA]
Justification: There are no experiments.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
â€¢ The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
â€¢ The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
â€¢ It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
â€¢ It is OK to report 1-sigma error bars, but one should state it. The authors should prefer-
ably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of
Normality of errors is not verified.
â€¢ For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢ If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
Justification: There are no experiments.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
31â€¢ The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
â€¢ The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢ The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments
that didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We have read the code and do not see any violation. Our work relates to the
mathematical foundations of a basic task in ML.
Guidelines:
â€¢ The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢ If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
â€¢ The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: The paper presents a mathematical characterization of the limits of probabilis-
tic forecasting, and a (meta)algorithm that achieves these limits. For any class of interest,
there remains significant work to realize that algorithm in an efficient way. As such, our
impact is most directly on the theoretical community, who might then have direct societal
impact by producing an minimax optimal algorithm. As such, our societal impact may be
great, but it will always be quite indirect.
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
â€¢ If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢ Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact spe-
cific groups), privacy considerations, and security considerations.
â€¢ The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢ The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢ If there are negative societal impacts, the authors could also discuss possible mitiga-
tion strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
32Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We are not releasing models or data.
Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
â€¢ Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by re-
quiring that users adhere to usage guidelines or restrictions to access the model or
implementing safety filters.
â€¢ Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢ We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: We use no such assets.
Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢ The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢ For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢ If assets are released, the license, copyright information, and terms of use in the pack-
age should be provided. For popular datasets, paperswithcode.com/datasets has
curated licenses for some datasets. Their licensing guide can help determine the li-
cense of a dataset.
â€¢ For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
â€¢ If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documenta-
tion provided alongside the assets?
Answer: [NA]
Justification: No new assets are introduced.
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢ Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢ The paper should discuss whether and how consent was obtained from people whose
asset is used.
33â€¢ At submission time, remember to anonymize your assets (if applicable). You can
either create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the pa-
per include the full text of instructions given to participants and screenshots, if applicable,
as well as details about compensation (if any)?
Answer: [NA]
Justification: No such experiments were performed.
Guidelines:
â€¢ The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
â€¢ Including this information in the supplemental material is fine, but if the main contri-
bution of the paper involves human subjects, then as much detail as possible should
be included in the main paper.
â€¢ According to the NeurIPS Code of Ethics, workers involved in data collection, cura-
tion, or other labor should be paid at least the minimum wage in the country of the
data collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: Paper does not involve crowdsourcing or research with human subjects.
Guidelines:
â€¢ The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
â€¢ Depending on the country in which research is conducted, IRB approval (or equiva-
lent) may be required for any human subjects research. If you obtained IRB approval,
you should clearly state this in the paper.
â€¢ We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢ For initial submissions, do not include any information that would break anonymity
(if applicable), such as the institution conducting the review.
34