Achieving Domain-Independent
Certified Robustness via Knowledge Continuity
Alan Sun1,2, Chiyu Ma2, Kenneth Ge1, Soroush Vosoughi2
1Carnegie Mellon University,2Dartmouth College
{alansun, kkge}@andrew.cmu.edu ,
{chiyu.ma.gr, soroush.vosoughi}@dartmouth.edu
Abstract
Wepresent knowledgecontinuity ,anoveldefinitioninspiredbyLipschitzcontinuity
which aims to certify the robustness of neural networks across input domains (such
as continuous and discrete domains in vision and language, respectively). Most
existing approaches that seek to certify robustness, especially Lipschitz continuity,
lie within the continuous domain with norm and distribution-dependent guarantees.
In contrast, our proposed definition yields certification guarantees that depend only
onthelossfunctionandtheintermediatelearnedmetricspacesoftheneuralnet-
work. These bounds are independent of domain modality, norms, and distribution.
We further demonstrate that the expressiveness of a model class is not at odds with
its knowledge continuity. This implies that achieving robustness by maximizing
knowledgecontinuityshouldnottheoreticallyhinderinferentialperformance. Fi-
nally, to complement our theoretical results, we present several applications of
knowledgecontinuitysuchasregularization,acertificationalgorithm,andshow
thatknowledgecontinuitycanbeusedtolocalizevulnerablecomponentsofaneural
network1.
1 Introduction
Deepneuralnetworks(DNNs)havedemonstratedremarkablegeneralizationcapabilities. Theirrobust-
ness,however,hasbeenconsiderablymoredifficulttoachieve. Robustness referstothepreservationof
modelperformanceundernaturaloradversarialalterationsoftheinput[ 18]. DNNsâ€™lackofrobustness,
highlightedbyseminalworkssuchas[ 24,66]andrecently[ 7,5],posessignificantchallengestotheir
adoptionincriticalapplications,underscoringconcernsforAIsafetyandtrustworthiness[ 20,30,9,7].
Thoughissuesofrobustnessemergedfromcomputervisionapplications,theyhavesincespanned
multipledomains[ 1,35,72,75,7]. Thisresearchtrajectoryhasnotonlypromptedsignificantadvance-
ments in robustness improvements through architectural, training, and dataset augmentations, but
also unveiled the sophistication of adversarial attacks â€”the process through which counterexamples
to robustness are generated [ 1,35,72,75,7]. Along the progress made in these parallel directions, a
greatdealofworkhasgoneinto certifiedrobustness whichseekstoprovidetheoreticalrobustness
guarantees. Certification is desirable as it generally transcends any particular task, dataset, or model.
As a result, Lipschitz continuity has emerged, promising certified robustness by essentially bounding
the derivative of a neural networkâ€™s output with respect to its input. In this way, Lipschitz continuity
directly capturesthe volatilityof amodelâ€™s performance,getting atthe heartof robustness. Such an
approachhasprovenitsmeritincomputervision,facilitatingrobustnessundernormanddistributional
assumptions[ 29,59,78,76]. Itsinherenteaseandinterpretabilityhasleadtowidespreadadoptionas
a means to measure and regulate robustness among practitioners as well [71, 12, 21, 68, 54].
1Codebase for our experiments can be found at https://github.com/alansun17904/kc
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Despite these successes in computer vision, there are fundamental obstacles when one tries to
apply Lipschitz continuity into discrete or non-metrizable domains such as natural language. Firstly,
characterizingdistanceinthisinput-outputspaceishighlynontrivial,aslanguagedoesnothavea
naturally-endoweddistancemetric. Additionally,supposeweimposesomedistancemetriconthe
input-output space [ 49,16]. For such a metric to meaningfully characterize adversarial perturbations,
itcannotbeuniversallytask-invariant. Considerthetwosentences(a)â€œIamhappy,â€(b)â€œIamsad.â€
Theground-truthlabelof(a)isinvarianttotheperturbation(a) â†’(b),ifthetaskissentence-structure
identification, but it would not be preserved for a task like sentiment classification. Lastly, key
architectures such as the Transformer [ 70] are provably notLipschitz continuous [ 36].Most of these
challenges are not unique to language, and they represent a strong divide of our understanding of
robustness in discrete/non-metrizable and continuous domains [22, 46].
Toaddresstheseissues,weproposeanewconceptualframeworkwhichwecall knowledgecontinuity .
At its core, we adopt the following axiom:
Robustness is the stability of a modelâ€™s performance
with respect to its perceived knowledge of input-output relations.
Concretely,ourframeworkisgroundedonthepremisethatrobustnessisbetterachievedbyfocusingon
thevariabilityofamodelâ€™slosswithrespecttoitshiddenrepresentations,ratherthanforcingarbitrary
metrics on its inputs and outputs. Our approach results in certification guarantees independent of
domain modality, norms, and distribution. We demonstrate that the expressiveness of a model class
is not at odds with its knowledge continuity. In other words, achieving robustness by improving
knowledge continuity should not theoretically hinder inferential performance. We show that in
continuous settings (i.e. computer vision) knowledge continuity generalizes Lipschitz continuity
andinheritsits tightrobustnessbounds. Finally,we presentanarrayof practicalapplicationsusing
knowledgecontinuitybothasanindicatortopredictandcharacterizerobustnessaswellasanadditional
term in the loss function to train robust classifiers. In sum, our contributions are threefold:
â€¢Introduction of knowledge continuity , a new concept that frames robustness as variability of a
modelâ€™s loss with respect to its hidden representations.
â€¢We theoretically show that knowledge continuity results in certified robustness guarantees that
generalize across modalities (continuous, discrete, and non-metrizable). Moreover, this robustness
does not come at the expense of inferential performance.
â€¢Wepresentseveralpracticalapplicationsofknowledgecontinuitysuchasusingittrainmorerobust
models,inbothlanguage processingandvision,identifyproblematichiddenlayers, andusingits
theoretical guarantees to formulate a novel certification algorithm.
Althoughourresultsapplytoalldiscrete/non-metrizableandcontinuousspaces,throughoutthepaper
weinvokeexamplesfromnaturallanguageasitculminatestheaforementionedchallenges. Further,
the ubiquity of large language models make their robustness a timely focus.
2 Related Works
There have been extensive studies on developing robust neural networks with theoretical guarantees.
With respect to our contributions, they can be organized into the following categories.
Certified robustness with Lipschitz continuity. The exploration of Lipschitz continuity as a
cornerstoneforimprovingmodelrobustnesshasyieldedsignificantinsights,particularlyinthedomain
ofcomputervision. Thisprinciple,whichensuresboundedderivativesofthemodelâ€™soutputwith
respecttoitsinput,facilitatesasmoothermodelbehaviorandinherentlyencouragesrobustnessagainst
adversarialperturbations. Thismethodology,initiallysuggestedby[ 24],hassincebeenrigorously
analyzed and expanded upon. Most theoretical results in this area focus on certifying robustness
with respect to the ğ“2-norm [11,86,25,2,38,29,4]. A recent push, fueled by new architectural
developments, has also expanded these results into ğ“âˆ-norm perturbations [ 89,88,90]. Further,
Lipschitzcontinuity-inspiredalgorithmsalsoservepractitionersasacomputationallyeffectiveway
totrainmorerobustmodels[ 68,78,69,13]. Thisstandsincontrastto(virtual)adversarialtraining
methodswhichbrute-forcethesetofadversarialexamples,theniterativelyretrainonthem[ 50,63,80].
Though Lipschitz continuity has seen much success in continuous domains, it does not apply to non-
metrizabledomains suchas language. Further, architecturallimitations ofprevalent modelssuch as
2the Transformer [ 70,36] exacerbate this problem. These challenges highlight a critical need for a
new approach that can accommodate the specificities of discrete and non-metrizable domains while
providing robustness guarantees.
Achieving robustness in discrete/non-metrizable spaces. Non-metrizable spaces, where it is non-
trivial to construct a distance metric on the input/output domains, pose a unique challenge to certified
robustness. Instead of focusing on point-wise perturbations, many studies have opted to examine
howtheoutputprobabilitydistributionofamodelchangeswithrespecttoinputdistributionshifts
byleveraginginformationbottleneckmethods[ 67,73,53](seealsoout-of-distributiongeneraliza-
tion: [42,83,60]). Most of these bounds lack granularity and cannot be expressed in closed-form.
In contrast to these theoretical approaches, recent efforts have refocused on directly adapting the
principles underlying Lipschitz continuity to language. Virtual adversarial training methods such
as [43,85] mimic the measurement of Lipschitz continuity by comparing changes in the textual
embeddings with the KL-divergence of the output logits. Along these lines, techniques akin to those
used in adversarial training in vision have also been translated to language, reflecting a shift towards
robustness centered around the learned representation space [ 40,23,35]. Though these approaches
have seen empirical success, they lack theoretical guarantees. As a result, their implementations
and success rate is heavily task-dependent [ 43,85]. There have also been attempts to mitigate the
non-LipschitznessofTransformers[ 87,82]bymodifyingitsarchitecture. Thesechanges,however,
add significant computational overhead.
Other robustness approaches. In parallel, other certified robustness approaches such as randomized
smoothing[ 12,39,37]givestate-of-the-artcertificationfor ğ“2-basedperturbations. Notableworks
suchas[34,74]havesoughttogeneralizethesetechniquesintolanguage,buttheirguaranteesstrongly
depend on the type of perturbation being performed. On the other hand, analytic approaches through
convexrelaxationinductivelyboundtheoutputofneuronsinaReLUnetworkacrosslayers[ 79,81,77].
These works, however, are difficult to scale and also do not transfer easily to discrete/non-metrizable
domains.
Our approach, inspired by Lipschitz continuity, distills the empirical intuitions from the works
of[43,85]andprovidestheoreticalcertificationguaranteesindependentofperturbation-type[ 34,74]
and domain modality. We demonstrate that knowledge continuity yields many practical applications
analogous to Lipschitz continuity which are easy to implement and are computationally competitive.
3 Preliminaries
Notations. Letâ„â‰¥0âˆ¶= [0,âˆ). For any function ğ‘“âˆ¶î‰„â†’î‰…, we denote graph(ğ‘“)âˆ¶= {(ğ‘¥,ğ‘¦) âˆˆ
î‰„Ã—î‰…âˆ¶ğ‘“(ğ‘¥) =ğ‘¦}. Forğ‘›âˆˆâ„•, let[ğ‘›]denote the set {1,2,â€¦,ğ‘›}.(î‰„,îˆ²î‰„,â„™î‰„),(î‰…,îˆ²î‰…,â„™î‰…)
are probability spaces and (î‰„Ã—î‰…,îˆ²î‰„âŠ—îˆ²î‰…,â„™î‰„Ã—â„™î‰…)denotes the product measurable space of
theprobabilityspaces î‰„,î‰…. Sinceourcontributionfocusesonthesupervisedlearningregime,we
colloquially refer to î‰„,î‰…as the input and labels, respectively. We call any probability measure
â„™î‰„Ã—î‰…absolutely continuous to â„™î‰„Ã—â„™î‰…(i.e.(â„™î‰„Ã—â„™î‰…)(ğ¸) = 0 â‡’â„™î‰„Ã—î‰…(ğ¸) = 0) adata
distribution and denote it as îˆ°î‰„,î‰…. If(î‰†,ğ‘‘î‰†)is a metric space with metric ğ‘‘î‰†andğ´ âŠ‚î‰†, then
for anyğ‘§âˆˆî‰†,ğ‘‘î‰†(ğ‘§,ğ´) = infğ‘âˆˆğ´ğ‘‘î‰†(ğ‘,ğ‘§). We say that a metric space, (î‰†,ğ‘‘î‰†), is bounded by
someğµâˆˆâ„â‰¥0, ifsupğ‘§â€²,ğ‘§âˆˆî‰†ğ‘‘(ğ‘§,ğ‘§â€²)<ğµ. Denote by Idî‰†âˆ¶î‰†â†’î‰†the identity function on î‰†. Let
îˆ¸âˆ¶î‰…Ã—î‰…â†’â„â‰¥0bealossfunctionwhere îˆ¸(ğ‘¦,ğ‘¦â€²)=0ifandonlyif ğ‘¦=ğ‘¦â€². Foranyğ‘“âˆ¶î‰„â†’î‰…
and(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆˆî‰„Ã—î‰…, we denoteÎ”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)âˆ¶=|îˆ¸(ğ‘“(ğ‘¥),ğ‘¦)âˆ’îˆ¸(ğ‘“(ğ‘¥â€²),ğ‘¦â€²)|, essentially the
absolute difference in loss between (ğ‘¥,ğ‘¦)and(ğ‘¥â€²,ğ‘¦â€²). Unless otherwise specified, it will be assumed
thatğ‘“is a measurable function from î‰„toî‰…with a metric decomposition (see Def. 1).
Lipschitzcontinuity. Giventwometricspaces (î‰„,ğ‘‘î‰„),(î‰…,ğ‘‘î‰…)afunctionğ‘“âˆ¶î‰„â†’î‰…isğ¾-Lipschitz
continuous if there exists ğ¾âˆˆâ„â‰¥0such that for all ğ‘¥,ğ‘¥â€²âˆˆî‰„,ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))â‰¤ğ¾ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²).
4 Knowledge Continuity
In this section, we provide the formal definition of knowlege continuity and explore its theoretical
properties.
We start by defining a modelâ€™s perceived knowledge through a rigorous treatment of its hidden
representationspaces. Byconsideringthedistancebetweeninputsinsomerepresentationspacein
conjunctionwithchangesinloss,weresultinameasureof volatilityanalogoustoLipschitzcontinuity.
3Boundingthisvolatilityinexpectationthendirectlyleadstoournotionofknowledgecontinuity. With
these tools, we demonstrate a host of theoretical properties of knowledge continuity including its
certification ofrobustness, guarantees ofexpressiveness,and connections toLipschitz continuity in
continuous settings. We summarize our theoretical contributions as follows:
â€¢Wedefinetheperceivedknowledgeofamodelaswellasvolatilityandknowledgecontinuitywithin
a modelâ€™s representation space (see Def. 1, 2, 3, 4, respectively).
â€¢Weprovethatknowledgecontinuityimplies probabilistic certifiedrobustnessunderperturbationsin
therepresentationspaceandconstrainingknowledgecontinuityshouldnothindertheexpressiveness
of the class of neural networks (see Thm. 4.1 and Prop. 4.3, 4.4, respectively).
â€¢Weprovethat in some cases knowledge continuity is equivalent (in expectation) to Lipschitz
continuity. This shows that our axiomization of robustness aligns with existing results when
perturbation with respect to the input is well-defined (see Prop. 4.6, 4.8).
4.1 Defining Perceived Knowledge
Knowledgeisgenerallyunderstoodasarelationalconcept: itarisesfromtheconnectionswemake
between ideas, experiences, and stimuli [ 26]. Herein, we capture the perceived knowledge of a model
byfocusingontherelationsitassignstoinput-inputpairs. Specifically, theserelationsareexposedby
decomposing a function ğ‘“âˆ¶î‰„â†’î‰…into projections to intermediate metric spaces. Formally,
Definition1 (MetricDecomposition) .Wesaythatğ‘“admitsametricdecompositionifthereexists
metric spaces (î‰†1,ğ‘‘1),â€¦,(î‰†ğ‘›,ğ‘‘ğ‘›)with metrics ğ‘‘ğ‘˜forğ‘˜âˆˆ[ğ‘›]such that
1.(î‰†ğ‘˜,ğ‘‘ğ‘˜)is endowed with its Borel ğœ-algebra.
2.Thereexistsmeasurablemappings â„0,â„1,â€¦,â„ğ‘›whereâ„0âˆ¶î‰„â†’î‰†1,â„ğ‘˜âˆ¶î‰†ğ‘˜â†’î‰†ğ‘˜+1for
ğ‘˜âˆˆ[ğ‘›âˆ’1], andâ„ğ‘›âˆ¶î‰†ğ‘›â†’î‰….
3.ğ‘“=â„ğ‘›â—¦â„ğ‘›âˆ’1â—¦â€¦â—¦â„1â—¦â„0.
Remark1.Ifî‰„isametricspacewithmetric ğ‘‘î‰„andîˆ²î‰„isitsBorelğœ-algebra,thenforanymeasurable
mappingğ‘“âˆ¶î‰„â†’î‰…there exists the trivial metric decomposition
ğ‘“=ğ‘“â—¦Idî‰„. (4.1)
Therefore, in computer vision applications where (î‰„,ğ‘‘î‰„)=(â„ğ‘›,ğ“ğ‘)for someğ‘›âˆˆâ„¤+, we can apply
this trivial decomposition to yield bounds which mirror the certification guarantees of Lipschitz
continuity. This is discussed in detail in Section 4.5.
To the best of our knowledge, all deep learning architectures admit metric decompositions, since
their activations are generally real-valued. So, for all subsequent functions from î‰„toî‰…, unless
otherwisespecified,weassumetheyaremeasurableandpossessametricdecomposition. Further,
we denoteğ‘“ğ‘˜=â„ğ‘˜â—¦â„ğ‘˜âˆ’1â—¦â€¦â—¦â„1â—¦â„0and adopt the convention of calling â„ğ‘˜theğ‘˜thhidden layer. In
Appendix A, we present several metric decompositions for a variety of architectures.
For any metric-decomposible function, an immediate consequence of our definition is that its metric
decomposition may not be unique. However, in the context of neural networks, this is a desirable
property. Seminal works from an array of deep learning subfields such as semi-supervised learn-
ing[57],manifoldlearning[ 51],andinterpretability[ 10,47]placegreatemphasisonthequalityof
learnedrepresentationspacesbyexaminingtheinduced-topologyoftheirmetrics. Thisoftendoes
not affect the typical performance of the estimator, but has strong robustness implications [ 33]. Our
results,which aredependentonparticularmetricdecompositions, capturethistrend. InSection 4.4,
we discuss in detail the effects of various metric decompositions on our theoretical results.
4.2 Defining Knowledge Continuity
We first introduce what it means for a modelâ€™s performance to be volatile at a data point relative to its
metricdecomposition. Then,wecontrastknowledgecontinuitywithLipschitzcontinuity,pointing
out key differences that will allow us to prove more general bounds.
Definition2 (ğ‘˜-Volatility) .Letğ‘“âˆ¶î‰„â†’î‰…andîˆ¸beanylossfunction. The ğ‘˜-volatilityofapoint
(ğ‘¥,ğ‘¦)âˆˆî‰„Ã—î‰…which we denote as ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)is given by
ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)âˆ¶=ğ”¼(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…
ğ‘“(ğ‘¥)â‰ ğ‘“(ğ‘¥â€²)â¡
â¢
â¢â£Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))â¤
â¥
â¥â¦, (4.2)
4Sparse Knowledge Continuity Knowledge Continuity Knowledge Discontinuity
Figure1: Examplesofknowledge(dis)continuities. ğ‘“âˆ¶î‰„â†’î‰…isameasurablemap,and (î‰†ğ‘˜,ğ‘‘ğ‘˜)
is one of its hidden representations. The color of the points indicates loss. â™¦denotes knowledge
continuityinducedbysparsity: anisolatedconceptwithnoknowledgerelationsclosetoit. So,any
perturbation moves â™¦far away with high probability. Smooth changes in loss around â˜…implies
knowledge continuity. Finally, â­“is notknowledge continuous dueto drastic changesin loss nearby.
Notice that the classification of points is independent of input/output clustering behavior since î‰„,î‰…
may not be endowed with a metric.
whereğ‘‘ğ‘˜is the distance metric associated with ğ‘“â€™sğ‘˜thhidden layer.
By performing some algebra on the definition, we see that it decomposes nicely into two distinct
terms:sparsityof the representation and variation in loss.
ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)=ğ”¼(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…[|îˆ¸(ğ‘“(ğ‘¥),ğ‘¦)âˆ’îˆ¸(ğ‘“(ğ‘¥â€²),ğ‘¦â€²)|
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))]
,
=îˆ¸(ğ‘“(ğ‘¥),ğ‘¦)ğ”¼(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…[
1
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))
âŸââââââââââŸââââââââââŸ
sparsityâ‹…||||1âˆ’îˆ¸(ğ‘“(ğ‘¥â€²),ğ‘¦â€²)
îˆ¸(ğ‘“(ğ‘¥),ğ‘¦)||||âŸââââââââââŸââââââââââŸ
variation in loss]
,(4.3)
Our notion of volatility essentially measures the change in performance with respect to perturbations
to a modelâ€™s perceived knowledge. In particular, Eq. 4.3 reveals that there are two interactions
in play which we illustrate in Fig. 1. Informally, we say that (ğ‘¥,ğ‘¦)is highly volatile if there is a
large discrepancy in performance between it and points that are perceived to be conceptually similar.
Therefore,highlyvolatilepointscaptureinaccurateinput-inputknowledgerelations. Additionally,
(ğ‘¥,ğ‘¦)experiences low volatility if the space around it is sparse with respect to îˆ°î‰„,î‰…. In other words,
any set of perturbations applied in î‰†ğ‘˜would push(ğ‘¥,ğ‘¦)far away, with high probability. This makes
(ğ‘¥,ğ‘¦)an isolated concept with little knowledge relationships associated with it.
SimilartoLipschitzcontinuity, theboundedness ofthe ğ‘˜-volatility of ğ‘“acrossthe datadistribution is
crucial and we denote this class of functions as knowledge continuous .
Definition 3 (Pointwiseğœ–-Knowledge Continuity) .We say that ğ‘“isğœ–-knowledge continuous at
(ğ‘¥,ğ‘¦)âˆˆî‰„Ã—î‰…with respect to a function ğ‘“, loss function îˆ¸, and hidden layer ğ‘˜ifğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)<ğœ–.
Conversely, we say that (ğ‘¥,ğ‘¦)isğœ–-knowledge discontinuous if the previous inequality does not hold.
Further,(ğ‘¥,ğ‘¦)is simply knowledge discontinuous if ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)is unbounded. Now, we extend this
definition globally by considering the ğ‘˜-volatility between all pairs of points.
5Definition 4 (Expectedğœ–-Knowledge Continuity) .We say that ğ‘“isğœ–-knowledge continuous with
respect to a loss function îˆ¸and hidden layer ğ‘˜if
ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°[ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)]<ğœ–. (4.4)
Though thefunctional forms ofLipschitz continuity andknowledge continuityare similar, thereare
important differences that allow us to prove more general results. Firstly, unlike Lipschitz continuity
which is an analytical property of the model ğ‘“, knowledge continuity is a statistical one. In this
way, non-typical data points, even if they are volatile, are ignored, whereas Lipschitz continuity
treatsallpointsequally. Thisisnecessaryinmanydiscreteapplications,asprojectingacountable
input space onto a non-countable metric space inevitably results in a lack of correspondence thereof.
Moreover,ground-truthrelationsfrom î‰„â†’î‰…maynotbewell-definedon allofî‰„: considersentiment
classification of an alpha-numeric UUID string or dog-cat classification of Gaussian noise. Secondly,
the knowledge continuity of an estimator is measured with respect to the loss function rather than
itsoutput. ThispropertyallowsustoachievetheexpressivenessguaranteesinSection4.4,sinceit
places no restrictions on the function class of estimators. Lastly, knowledge continuity measures the
distancebetweeninputswiththeendowedmetricinitshiddenlayers. Thisflexibilityallowsusto
define knowledge continuity even when the input domain is not a metric space.
4.3 Certification of Robustness
Our first main result demonstrates that ğœ–-knowledge continuity implies probabilistic certified robust-
nessinthehiddenrepresentationspace. InTheorem4.1,givensomereferenceset ğ´âŠ‚î‰„Ã—î‰…,we
bound the probability that a ğ›¿-sized perturbation in the representation space away from ğ´will result
in an expected ğœ‚change in loss. In other words, knowledge continuity is able to characterize the
robustness of any subset of data points with positive measure.
Theorem 4.1. Letğ´ âŠ‚ î‰„Ã—î‰…such that â„™îˆ°î‰„,î‰…[ğ´]>0andğ›¿,ğœ‚ >0. Letğ´â€²={
(ğ‘¥â€²,ğ‘¦â€²)âˆˆî‰„Ã—î‰…âˆ¶ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…
(ğ‘¥,ğ‘¦)âˆˆğ´Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)>ğœ‚}
. Ifğ‘“âˆ¶î‰„â†’î‰…isğœ–-knowledge continuous
with respect to the hidden layer indexed by ğ‘˜and(î‰†ğ‘˜,ğ‘‘ğ‘˜)is bounded by ğµ>0, then
â„™(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…[ğ´â€²âˆ£ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿]â‰¤ğœ–ğ›¿
ğœ‚(
1âˆ’exp[
âˆ’Î©(
ğ›¿
ğµâˆ’âˆš
log1
â„™[ğ´])2]).(4.5)
Proof sketch. We apply the definition of conditional probability ğ‘ƒ(ğ´|ğµ) =ğ‘ƒ(ğ´âˆ©ğµ)âˆ•ğ‘ƒ(ğµ)and
boundğ‘ƒ(ğ´âˆ©ğµ),ğ‘ƒ(ğµ),separately. Thenumerator, â„™[ğ´â€²andğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿],isupper-bounded
through an application of Markovâ€™s Inequality. On the other hand, we apply known concentration
inequalities to lower bound â„™[ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿], combining these results in the theorem. We
present the proof in its entirety in Appendix B. â– 
This demonstrates that knowledge continuity results in certification of robustness, independent of
distancemetricanddomainmodality. Theassumptionofboundednessandrequirementtoknow â„™[ğ´]
canbelostbytakinglimitsofEq.4.5withrespectto ğµandâ„™[ğ´]. Thisyieldsthefollowingcorollary.
Corollary 4.2. If(î‰†ğ‘˜,ğ‘‘ğ‘˜)is unbounded, then
â„™(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…[ğ´â€²âˆ£ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿]â‰¤ğœ–ğ›¿
ğœ‚(1âˆ’â„™[ğ´]). (4.6)
Ifâ„™[ğ´]=0, then
â„™(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…[ğ´â€²âˆ£ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿]â‰¤ğœ–ğ›¿
ğœ‚. (4.7)
Proof.Theseresultsfollowfromdirectlytakingthelimitas ğµâ†’âˆandapplyingsomeofthebounds
acquired in the proof of Thm. 4.1. This yields Eq. 4.6. Next, jointly taking the limit as â„™[ğ´]â†’0and
ğµâ†’âˆresults in Eq. 4.7. â– 
InbothThm.4.1andCor.4.7,weyieldprobabilisticguaranteeslike[ 12],ratherthandeterministic
ones. Though deterministic bounds are desirable, the stochasticity of our framework is necessary
6for its generalization across different domains. For most continuous, metrizable applications (like
computer vision), models learn a hidden representation space where most minute changes in this
spacecorrespondtotangibleinputs. Thesamecannotbesaidformanydiscreteornon-metrizable
applications. In natural language processing, the correspondence between the learned representation
space and the input is sparse, resulting in lots of â€œdead spaceâ€: portions of the hidden representation
space that do not correspond to any input [ 3,19]. And so, by incorporating the data distribution into
our bounds, we implicitly adjust for this: assigning zero-measure to the aforementioned â€œdead space.â€
4.4 Expressiveness
Oursecondmainresultdemonstratesthat ğœ–-knowledgecontinuitycanbeachievedwithouttheoretically
compromising the accuracy of the model. In other words, universal function approximation is an
invariantpropertywithrespectto ğœ–-knowledgecontinuity. Universalapproximationresultshaveseena
greatdealoftheoreticalwork,astheyputlimitsonwhatneuralnetworkscanrepresent[ 15,31,45]. As
discussedinSection2,Lipschitzcontinuousfunctionsdonotachieveuniversalfunctionapproximation
withrespecttothesetofallfunctions,inparticular,non-continuousones. However,weshowthat
under strong conditions this is achievable with knowledge continuity.
First, let us formally define a universal function approximator .
Definition 5 (Universal Function Approximator) .Suppose that îˆ¸is Lebesgue-integrable in both
coordinates. Let îˆ²âŠ‚î‰…î‰„beasetofmeasurablefunctionsfrom î‰„â†’î‰…suchthatforany ğ‘“âˆˆîˆ²,there
existsğœ‡ğ‘“â‰ªîˆ°î‰„,î‰…suchthatğœ‡ğ‘“(graph(ğ‘“))=1. Then, î‰âŠ‚îˆ²isauniversalfunctionapproximator
ofîˆ²if for everyğ‘“âˆˆîˆ²and everyğœ–>0, there exists Ì‚ğ‘“âˆˆî‰such that
âˆ«îˆ¸(Ì‚ğ‘“(ğ‘¥),ğ‘¦)ğ‘‘ğœ‡ğ‘“<ğœ–. (4.8)
We now show any universal function approximator can be made robust through the trivial metric
decomposition.
Proposition 4.3. Letî‰âŠ‚î‰…î‰„be a universal function approximator of î‰…î‰„with respect to some loss
function îˆ¸. Then,forany ğ‘“âˆˆî‰…î‰„andsequence ğœ–1,ğœ–2,â€¦suchthatğœ–ğ‘›â†’0thereare asequenceof
ğœ–ğ‘›-knowledge continuous functions in î‰such that âˆ«îˆ¸(ğ‘“ğ‘›(ğ‘¥),ğ‘¦)ğ‘‘ğœ‡ğ‘“<ğœ–ğ‘›, forğ‘›âˆˆâ„•.
Proof.Chooseğ‘“ğ‘›âˆˆî‰such that âˆ«îˆ¸(ğ‘“ğ‘›(ğ‘¥),ğ‘¦)ğ‘‘ğœ‡ğ‘“<1
2ğœ–ğ‘›. Consider the 1-layer metric decomposi-
tion ofğ‘“,â„1âˆ¶î‰„â†’î‰†1where î‰†1=î‰„equipped with the trivial metric ( ğ‘‘1(ğ‘¥,ğ‘¦)=1ifğ‘¥â‰ ğ‘¦and 0
otherwise). Then, ğ‘“ğ‘›=ğ‘“ğ‘›â—¦â„1. So, it follows that
ğ”¼ğœ1
ğ‘“ğ‘›(ğ‘¥,ğ‘¦)=âˆ«Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“ğ‘›(ğ‘¥â€²,ğ‘¦â€²)
ğ‘‘1(â„1(ğ‘¥),â„1(ğ‘¥â€²))ğ‘‘ğœ‡ğ‘“,
â‰¤âˆ«Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“ğ‘›(ğ‘¥â€²,ğ‘¦â€²)ğ‘‘ğœ‡ğ‘“,
â‰¤ğœ–ğ‘›.
and by the construction of ğ‘“ğ‘›, the proof is completed. â– 
In other words, if our estimator was given â€œinfinite representational capacity,â€ robustness can be
trivially achieved by isolating every point as its own concept (as discussed in Section 4.2). More
generally, if we instead considered a generalized discrete metric (fix ğ‘âˆˆ[0,âˆ],ğ‘‘(ğ‘¥,ğ‘¦)=ğ‘if and
onlyifğ‘¥=ğ‘¦andğ‘‘(ğ‘¥,ğ‘¦)=0,otherwise),thenas ğ‘â†’âˆ,ğ‘˜-volatilityconvergespointwiseto0almost
everywhere assuming that the loss is finite almost everywhere. In practice, we find these degenerate
decompositions tobe unreasonableas they alsotrivializerobustness. Forexample, if ğ‘=âˆ, then
robustnessisnotwell-definedasanyperturbationwouldleadtoapointthatisperceivedtobeinfinitely
far away. In this sense, our framework accounts for different notions of robustness, strong and
weak.The next result builds on Prop. 4.3 and demonstrates how a stronger notion of robustness
will affect expressiveness. These added constraints make it so that trivial metric decompositions
arenolongerpossibleunlessthemetricin î‰„isalsotrivial. Westatethisformallybelow,notethe
highlighted differences between this and Prop. 4.3.
Proposition4.4. Suppose(î‰„,ğ‘‘î‰„),(î‰…,ğ‘‘î‰…)âˆ¶=(î‰„,ğ‘‘î‰„)arecompactmetricspaces, îˆ²âŠ‚î‰…î‰„isthe
set of all continuous functions fromî‰„toî‰…such that âˆ«ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)âˆ’1ğ‘‘ğœ‡ğ‘“<âˆandîˆ¸be Lipschitz
continuous in both coordinates. Then, there exists a universal function approximator î‰ofîˆ²that is
knowledge continuous (i.e. ğ”¼ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)<âˆfor someğ‘˜).
7Proof sketch. We show an outline of the proof here and defer the full proof to Appendix C. By
the Stone-Weierstrass Theorem, the set of Lipschitz continuous functions is dense in the set of all
continuousfunctionsfrom î‰„toî‰…. Since îˆ¸isLipschitzcontinuousinbothcoordinates,throughsome
algebra, ğ”¼ğœ1
ğ‘“(ğ‘¥,ğ‘¦)<âˆ, whereâ„1=Idî‰„and we yield the statement of the theorem. â– 
The additional constraint âˆ«ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)âˆ’1ğ‘‘ğœ‡ğ‘“requires data points to be sparsely layed out in the
representationspace. Asdiscussedpreviously,thisassumptionisgenerallyreasonablefordiscrete
applications. InconjunctionwithProp.4.3,wehaveshownthattheclassofknowledgecontinuous
functionsis strictlylarger thantheclassofLipschitzcontinuousones. Thoughweshowthatuniversal
approximationbyknowledgecontinuousnetworksisachievable,itisunclearwhethertheseresults
stillholdiftheâ€œtightnessâ€ofthemetricdecompositionsisbounded. Specifically,theconstruction
in Prop. 4.3 results in a metric decomposition with infinite Hausdorff dimension. Is it possible to
achieve Prop. 4.3 in its most general form if we only consider the set of all knowledge continuous
functions with metric decompositions with finite Hausdorff dimension? Based on the theoretical and
empirical results of [ 62,33], respectively, we conjecture in the negative and leave its resolution open.
Conjecture 4.5. Ifî‰âŠ‚î‰…î‰„is a universal function approximator with respect to some Lebesgue-
integrablelossfunction îˆ¸. Then,forany ğ‘“âˆˆî‰…î‰„,theredoesnotexist asequenceof functionswith
metricdecompositionsof finiteHausdorffdimension thatachievearbitrarilysmallapproximation
error (i.e. âˆ«îˆ¸(Ì‚ğ‘“(ğ‘¥),ğ‘¦)ğ‘‘ğœ‡ğ‘“) and knowledge continuity.
4.5 Connections to Lipschitz Continuity
WenowdemonstratethatouraxiomizationofrobustnesspresentedinSection1alignswiththenotion
of robustness2commonly prescribed in vision [ 18]. This unifies the certified robustness bounds with
respect to the representation space derived in Thm. 4.1 with existing work certifying robustness with
respect to the input space in continuous applications such as vision.
Our first result identifies conditions under which knowledge continuity, implies Lipschitz continuity.
Proposition 4.6. Suppose that (î‰„,ğ‘‘î‰„),(î‰…,ğ‘‘î‰…)are metric spaces. Let the first ğ‘›metric decompo-
sitionsofğ‘“âˆ¶î‰„â†’î‰…beğ¾ğ‘–-Lipschitzcontinuous,for ğ‘–âˆˆ[ğ‘›]. Ifğ‘“isğœ–-knowledgecontinuouswith
respectto the ğ‘›thhidden layerand ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))â‰¤ğœ‚Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦)for allğ‘¥,ğ‘¥â€²âˆˆî‰„,ğ‘¦âˆˆî‰…, and
someğœ‚>0, thenğ‘“is Lipschitz continuous in expectation. That is,
ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)â‰¤ğœ–ğœ‚ğ‘›âˆ
ğ‘—=1ğ¾ğ‘—. (4.9)
Theproof ispresented inAppendix Dand follows easilythrough somealgebriac manipulation. Itis
easytoseethatif ğ‘“isknowledgecontinuouswithrespecttosomeidentity(orcontractive)metric
decomposition, then we can loose the repeated product. Analogous to Remark 1, the concepts of
Lipschitz continuity and knowledge continuity become similar when we can assign metrics to the
input-output spaces. Next, combining this proposition with an auxiliary result from [ 89], we directly
yield a certification on the input space.
Corollary 4.7. Suppose that assumptions of Prop. 4.6 are true. And also assume that (î‰„,ğ‘‘î‰„) =
(â„ğ‘›,ğ“ğ‘),(î‰…,ğ‘‘î‰…) = (â„ğ‘š,ğ“ğ‘), for1â‰¤ğ‘â‰¤âˆ. Define a classifier from ğ‘“âˆ¶â„ğ‘›â†’â„ğ‘š,ğ‘”, where
ğ‘”(ğ‘¥)âˆ¶=argmaxğ‘˜âˆˆ[ğ‘š]ğ‘“ğ‘˜(ğ‘¥)foranyğ‘¥âˆˆâ„ğ‘›. Then,withprobability 1âˆ’ğœ–ğœ‚
ğ‘¡âˆğ‘›
ğ‘—=1ğ¾ğ‘—,ğ‘”(ğ‘¥)=ğ‘”(ğ‘¥+ğ›¿)
forallâ€–ğ›¿â€–ğ‘<(21âˆ•ğ‘âˆ•2ğ‘¡)margin(ğ‘“(ğ‘¥))andğ‘¡>0.ğ‘“ğ‘˜(ğ‘¥)istheğ‘˜thcoordinateof ğ‘“(ğ‘¥)andmargin(ğ‘“(ğ‘¥))
denotes the difference between the largest and second-largest output logits.
WepresenttheproofinAppendixD.OursecondresultidentifiesconditionsunderwhichLipschitz
continuity, implies knowledge continuity.
Proposition 4.8. Let(î‰„,ğ‘‘î‰„),(î‰…,ğ‘‘î‰…)be a metric spaces. Let ğ‘“âˆ¶î‰„â†’î‰…beğœ–-Lipschitz continuous
andîˆ¸(ğ‘“(ğ‘¥),ğ‘¦)beğœ‚-Lipschitz continuous with respect to both coordinates. If the first ğ‘›metric
decompositions of ğ‘“areğ¾ğ‘–-Lipschitz continuous, then ğ‘“is knowledge continuous with respect to the
ğ‘›thhidden layer. That is,
ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğœğ‘›
ğ‘“(ğ‘¥,ğ‘¦)â‰¤ğœ–ğœ‚ğ‘›âˆ
ğ‘—=11
ğ¾ğ‘—. (4.10)
2Small perturbations on the input result in small changes in performance which implies small changes in
output when the loss function is Lipschitz continuous.
81.0
0.5
0.0
0.5
1.0
Normalized n1n
k= 1k
0.15
0.20
0.25
0.30
0.35
0.40
0.45% of Successful Adversarial Attacks
y= 0.0589x+ 0.3236
2.5
0.0
bert-large-uncased
bert-base-uncased
2.5
0.0
roberta-base
roberta-large
2.5
0.0Normalized k
gpt2
0.0
0.2
0.4
0.6
0.8
1.0
Relative Depth
2.5
0.0
t5-base
t5-small
0.0
0.2
0.4
0.6
0.8
Relative Depth(c)(b) (a)
0.20
0.22
0.24
0.26
0.28
0.30
0.32R2
y= 0.0919x+ 0.2011Figure 2: (a)The averagepercentage ofsuccessful adversarial attacksby TextFooler [ 35] ona host of
models[58,57,16,44]andtheIMDB[ 48]datasetregressedwiththeaverageofknowledgecontinuity
coefficients across all hidden layers ( ğ‘…2= 0.35). (b)ğ‘˜-Volatility as ğ‘˜is varied across a modelâ€™s
relative depth. (c) Correlation between ğ‘˜-volatility and adversarial vulnerability (averaged across all
models shown in (b)) with respect to TextFooler [35] as ğ‘˜varies.
We detail theproof of this proposition in Appendix D.We note that in continuous applicationssuch
as computer vision, the assumptions of both propositions are generally met (i.e. our input-output
spaces are metric spaces, all hidden layers are Lipschitz, and loss functions are locally Lipschitz).
Furthermore, commonarchitecturessuchasfullyconnectednetworks, CNNs, RNNs, andevenvision
transformers are Lipschitz continuous [ 71,55].This implies that our notion of robustness is indeed
an appropriate generalization that transcends domain modality since in continuous settings we
can recover the strong bounds of Lipschitz continuity while expanding into new discrete and
non-metrizable territory.
5 Practical Applications
In addition to the theoretical guarantees given by knowledge continuity in Section 4, we also demon-
strate that knowledge continuity can be easily applied in practice. First, we find that knowledge
continuity, similar to Lipschitz continuity, can be used to gauge adversarial robustness. Along these
lines, our measure of volatility (see Def. 2) can be used to isolate particularly vulnerable hidden
representations. Theseapplicationsthendirectlymotivateregulationofknowledgecontinuityasa
means to enforce robustness.
Unless otherwise specified, we run all of our experiments on the IMDB dataset [ 48] (a sentiment
classification task) using a host of language models from different model families (encoder, decoder,
encoder-decoder). We also present additional experiments on vision tasks. These experiments can be
found in the Appendix G.
Knowledgecontinuitycanpredictadversarialrobustness. Foragivenmodel, ğ‘“,withğ‘›hidden
representations, choose some ğ‘˜âˆˆ [ğ‘›]. Then, consider the hidden representation index by ğ‘˜. For
this fixedğ‘˜, we determine its ğ‘˜-volatility by directly estimating Def. 2 through a naive Monte-Carlo
algorithm (see Appendix G for more details). Repeating this for all ğ‘˜âˆˆ[ğ‘›], we yield a collection of
ğ‘˜-volatilitieswhichwedenoteas {ğœ–1,â€¦,ğœ–ğ‘›},oneforeachhiddenlayer. Whenweregressasimple
average of these coefficients, ğ‘›âˆ’1âˆ‘ğ‘›
ğ‘˜=1ğœ–ğ‘˜, with the empirical adversarial robustness (estimated using
TextFooler[ 35]),astrongcorrelationisobserved. ThisisshowninFig.2(a). Inparticular,knowledge
continuityaloneisabletoexplain35%ofthevarianceinadversarialattacksuccessrate. Whenwe
combineğ‘˜-volatility with other model properties like size, model family, even more variance can
beexplained( ğ‘…2=0.48). Thus,knowledgecontinuitymaybeusedasacomputationallyefficient
method to estimate adversarial vulnerability with respect to the input space as compared to iteratively
applying real adversarial attacks. Moreover, when the adversary is unknown a priori, knowledge
continuitycanalsobeusedinthiswayasadiagnostictool. Adetaileddiscussionoftheseexperiments
are presented in Appendix E.
Knowledgecontinuitycanlocalizevulnerablehiddenrepresentations. Weplottherelationship
between the ğ‘˜-volatility,ğœ–ğ‘˜, and the relative depth of the model (i.e. ğ‘˜âˆ•ğ‘›). We find that language
models belonging to different model families (encoder, decoder, encoder-decoder) admit different ğ‘˜-
volatilitytrajectories. ThisisshowninFig.2(b). Inthisway,knowledgecontinuitymayprovideamore
9Table 1: Comparison of our knowledge continuity algorithm to existing works across various model
families and adversarial attack methods. TF, BA, ANLI denote adversarial attacks [ 35], [40], and
[52],respectively. Regulatingknowledgecontinuitytoimproverobustnessissuperioracrossalmost
all tasks and attacks.
Arch. Method IMDB IMDBTFIMDBBAANLIR1ANLIR2ANLIR3
Base 93.6 47.9 45.2 44.5 45.6 33.8
BERT [16] TF [35] 93.3 69.2 62.5 âœ— âœ— âœ—
âˆ¼110M params ALUM [43] 93.5 56.9 47.8 45.2 46.7 46.3
KCReg (ours) 94.8 75.1 84.9 45.6 46.9 45.3
Base 93.6 63.9 54.9 42.7 44.9 43.4
GPT2 [57] TF [35] 92.0 64.5 51.3 âœ— âœ— âœ—
âˆ¼1.5B params ALUM [43] 94.9 49.4 27.5 43.8 45.2 44.6
KCReg (ours) 94.9 87.8 90.6 47.1 48.1 44.7
Base 93.7 53.9 39.3 46.1 44.7 46.0
T5 [58] TF [35] 96.8 77.8 60.6 âœ— âœ— âœ—
âˆ¼220M params ALUM [43] 95.1 67.1 51.9 44.5 44.8 44.4
KCReg (ours) 94.9 89.3 91.3 48.2 45.0 44.3
nuancedpictureofamodelâ€™sinductivebiasesandrobustnessbeyondascalarvaluelikeâ€œaccuracyunder
adversarialattack.â€ WepresentadetailedanalysisofthisinAppendixF.Further,thesedynamicsmay
actasadiagnostictoolandofferastartingpointfordesigning model-specific robustnessinterventions
oradversarialdefenses. Forexample,wheninsightsfromFig.2(b)arecombinedwithaknowledge
continuityregularizationalgorithm,thisyieldssuperiorempiricalrobustnesscomparedtoexisting
methods. This is shown in the next subsection and in Appendix G. In addition, knowledge continuity
can also quantitatively characterize an adversarial attack against a host of models which is useful for
online or adaptive defenses [ 84,64,14]. This is shown in in Fig. 2(c), where TextFooler [ 35] largely
exploits the knowledge continuities in middle/final layers of the model to decrease performance.
Regulating knowledge continuity. Motivated by the theoretical results in Section 4, we augment the
loss function during training to mitigate knowledge continuity. Specifically, on each training iteration
(batch), we start by choosing a hidden layer at random according to a Beta distribution determined a
priori:ğ‘‹âˆ¼Beta(ğ›¼,ğ›½)and letğ‘˜=âŒŠğ‘›ğ‘‹âŒ‹. Here,ğ›¼,ğ›½are chosen according to Fig. 2(b,c). We assign
larger sampling probability to layers where both ğ‘˜-volatility is high and where knowledge continuity
is highly correlated with adversarial robustness. In this way, our regularization objective is both
modelandattackspecific(iftheattackmethodisunknown,thenweonlyapplytheformer). Then,
we devise a Monte-Carlo algorithm to estimate this layerâ€™s ğ‘˜-volatility,ğœ–ğ‘˜, (see Appendix G) on this
minibatch. And so, the augmented loss function becomes îˆ¸â€²(ğ‘“(ğ‘¥),ğ‘¦)=îˆ¸(ğ‘“(ğ‘¥),ğ‘¦)+ğœ†ğœ–ğ‘˜withğœ†â‰¥0
asahyperparameter,controllingtheregularizationstrength. Incontrasttoexistingadversarialtraining
methods that perform inner-optimization steps [ 50,43,85], our method requires only additional
zeroth-order computations. As a result, it outperforms existing works in training speed (up to 2Ã—for
TextFooler [ 35] and3Ã—for ALUM [ 43]), while improving robustness. We present a discussion of the
results, ablation studies, and training details in Appendix G.
Certifying robustness withknowledgecontinuity. We present analgorithm based on Thm. 4.1 to
certifyrobustnessduringtest-time. Similarto[ 12],weestimatetheprobabilityofthereexistingan
adversarial example within some fixed radius (in the representation space, according to a pre-defiend
distancemetric)throughbootstrappingaone-sideconfidenceinterval. Applyingthesemethodsto
our regularization results, we show that regularizing knowledge continuity increases the certified
robustness. The certification algorithm, its proof of correctness, and certifications of our regularized
models are presented in Appendix H.
6 Conclusion
Inthispaper,wepropose anoveldefinition, knowledgecontinuity ,whichaddressessomeofthe key
limitations of Lipschitz robustness. We demonstrate that our definition certifies robustness across
domainmodality,distribution,andnorms. Wealsoshowthatknowledgecontinuity,incontrastto
Lipschitzcontinuity,doesnotaffecttheuniversalapproximationpropertyofneuralnetworks. We
also establish conditions under which knowledge continuity and Lipschitz continuity are equivalent.
Lastly, we present several practical applications that directly benefit the practitioner. The broader
impacts, reproducibility, and limitations of our work can be found in Appendix I, J, K, respectively.
107 Acknowledgements
Alan Sun thanks Fengwen Sun for the helpful feedback on early drafts of the work as well as Jeffrey
Jiang and Andrew Koulogeorge for thoughtful discussions.
References
[1]M. Alzantot, Y. Sharma, A. Elgohary, B.-J. Ho, M. Srivastava, and K.-W. Chang. Generating natural
language adversarial examples. In E. Riloff, D. Chiang, J. Hockenmaier, and J. Tsujii, editors, Proceedings
ofthe2018ConferenceonEmpiricalMethodsinNaturalLanguageProcessing ,pages2890â€“2896,Brussels,
Belgium, Oct.-Nov. 2018. Association for Computational Linguistics.
[2]C.Anil,J.Lucas,andR.Grosse. Sortingoutlipschitzfunctionapproximation. In InternationalConference
on Machine Learning , pages 291â€“301. PMLR, 2019.
[3]S. Arora, Y. Li, Y. Liang, T. Ma, and A. Risteski. A Latent Variable Model Approach to PMI-based Word
Embeddings. Transactions of the Association for Computational Linguistics , 4:385â€“399, 07 2016.
[4]P. L. Bartlett, D. J. Foster, and M. J. Telgarsky. Spectrally-normalized margin bounds for neural networks.
Advances in Neural Information Processing Systems , 30, 2017.
[5]S.Biderman,U.PRASHANTH,L.Sutawika,H.Schoelkopf,Q.Anthony,S.Purohit,andE.Raff. Emergent
and predictable memorization in large language models. Advances in Neural Information Processing
Systems, 36, 2023.
[6]D.Blackwell. Conditionalexpectationandunbiasedsequentialestimation. TheAnnalsofMathematical
Statistics, pages 105â€“110, 1947.
[7]N. Carlini, M. Nasr, C. A. Choquette-Choo, M. Jagielski, I. Gao, P. W. W. Koh, D. Ippolito, F. Tramer, and
L. Schmidt. Are aligned neural networks adversarially aligned? In A. Oh, T. Naumann, A. Globerson,
K.Saenko,M.Hardt,andS.Levine,editors, AdvancesinNeuralInformationProcessingSystems ,volume36,
pages 61478â€“61500. Curran Associates, Inc., 2023.
[8] G. Casella and R. Berger. Statistical inference . CRC Press, 2024.
[9]P. Chao, A. Robey, E. Dobriban, H. Hassani, G. J. Pappas, and E. Wong. Jailbreaking black box large
language models in twenty queries. In R0-FoMo:Robustness of Few-shot and Zero-shot Learning in Large
Foundation Models , 2023.
[10]C. Chen, O. Li, D. Tao, A. Barnett, C. Rudin, and J. K. Su. This looks like that: deep learning for
interpretable image recognition. Advances in Neural Information Processing Systems , 32, 2019.
[11]M. Cisse, P. Bojanowski, E. Grave, Y. Dauphin, and N. Usunier. Parseval networks: Improving robustness
to adversarial examples. In International Conference on Machine Learning , pages 854â€“863. PMLR, 2017.
[12]J. Cohen, E. Rosenfeld, and Z. Kolter. Certified adversarial robustness via randomized smoothing. In
K. Chaudhuri and R. Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine
Learning, volume 97 of Proceedings of Machine Learning Research , pages 1310â€“1320. PMLR, 09â€“15 Jun
2019.
[13]Z. Cranko, Z. Shi, X. Zhang, R. Nock, and S. Kornblith. Generalised lipschitz regularisation equals
distributionalrobustness. In InternationalConferenceonMachineLearning ,pages2178â€“2188.PMLR,
2021.
[14]F. Croce, S. Gowal, T. Brunner, E. Shelhamer, M. Hein, and T. Cemgil. Evaluating the adversarial
robustnessofadaptivetest-timedefenses. InK.Chaudhuri, S.Jegelka, L.Song, C.Szepesvari, G.Niu, and
S. Sabato, editors, Proceedings of the 39th International Conference on Machine Learning , volume 162 of
Proceedings of Machine Learning Research , pages 4421â€“4435. PMLR, 17â€“23 Jul 2022.
[15] G. Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals
and Systems , 2(4):303â€“314, 1989.
[16]J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional transformers
for language understanding. In J. Burstein, C. Doran, and T. Solorio, editors, Proceedings of the 2019
Conference of the North American Chapter of the Association for Computational Linguistics: Human
LanguageTechnologies,Volume1(LongandShortPapers) ,pages4171â€“4186,Minneapolis,Minnesota,
June 2019. Association for Computational Linguistics.
11[17]A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Min-
derer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers
for image recognition at scale. In International Conference on Learning Representations , 2021.
[18]N. Drenkow, N. Sani, I. Shpitser, and M. Unberath. A systematic review of robustness in deep learning for
computer vision: Mind the gap?, 2022.
[19]N. Elhage, T. Hume, C. Olsson, N. Schiefer, T. Henighan, S. Kravec, Z. Hatfield-Dodds, R. Lasenby,
D. Drain, C. Chen, et al. Toy models of superposition. arXiv preprint arXiv:2209.10652 , 2022.
[20]K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao, A. Prakash, T. Kohno, and D. Song.
Robustphysical-worldattacksondeeplearningvisualclassification. In ProceedingsoftheIEEEConference
on Computer Vision and Pattern Recognition (CVPR) , June 2018.
[21]M.Fazlyab,A.Robey,H.Hassani,M.Morari,andG.Pappas. Efficientandaccurateestimationoflipschitz
constants for deep neural networks. Advances in Neural Information Processing Systems , 32, 2019.
[22]F.Gama,J.Bruna,andA.Ribeiro. Stabilitypropertiesofgraphneuralnetworks. IEEETransactionson
Signal Processing , 68:5680â€“5695, 2020.
[23]S.GargandG.Ramakrishnan. BAE:BERT-basedadversarialexamplesfortextclassification. InB.Webber,
T. Cohn, Y. He, and Y. Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural
Language Processing (EMNLP) , pages 6174â€“6181, Online, Nov. 2020. Association for Computational
Linguistics.
[24]I. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. Proceedings
of 3rd International Conference on Learning Representations , 2014.
[25]H. Gouk, E. Frank, B. Pfahringer, and M. J. Cree. Regularisation of neural networks by enforcing lipschitz
continuity. Machine Learning , 110:393â€“416, 2021.
[26]G.S.Halford,W.H.Wilson,andS.Phillips. Relationalknowledge: thefoundationofhighercognition.
Trends in Cognitive Sciences , 14(11):497â€“505, 2010.
[27]K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2016.
[28]K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition , pages 770â€“778, 2016.
[29]M.HeinandM.Andriushchenko. Formalguaranteesontherobustnessofaclassifieragainstadversarial
manipulation. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and
R.Garnett,editors, AdvancesinNeuralInformationProcessingSystems ,volume30.CurranAssociates,
Inc., 2017.
[30]D.Hendrycks,K.Zhao,S.Basart,J.Steinhardt,andD.Song. Naturaladversarialexamples. In Proceedings
oftheIEEE/CVFConference onComputerVisionandPatternRecognition(CVPR) ,pages15262â€“15271,
June 2021.
[31]K. Hornik, M. Stinchcombe, and H. White. Multilayer feedforward networks are universal approximators.
Neural Networks , 2(5):359â€“366, 1989.
[32]Y. Huang, H. Zhang, Y. Shi, J. Z. Kolter, and A. Anandkumar. Training certifiably robust neural networks
withefficientlocallipschitzbounds. AdvancesinNeuralInformationProcessingSystems ,34:22745â€“22757,
2021.
[33]A. Ilyas, S. Santurkar, D. Tsipras, L. Engstrom, B. Tran, and A. Madry. Adversarial examples are not bugs,
they are features. Advances in Neural Information Processing Systems , 32, 2019.
[34]R. Jia, A. Raghunathan, K. GÃ¶ksel, and P. Liang. Certified robustness to adversarial word substitutions. In
K.Inui,J.Jiang,V.Ng,andX.Wan,editors, Proceedingsofthe2019ConferenceonEmpiricalMethodsin
Natural Language Processing and the 9th International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP) , pages 4129â€“4142, Hong Kong, China, Nov. 2019. Association for Computational
Linguistics.
[35]D.Jin,Z.Jin,J.T.Zhou,andP.Szolovits. IsBERTreallyrobust? astrongbaselinefornaturallanguage
attackontextclassificationandentailment. In ProceedingsoftheAAAIconferenceonartificialintelligence ,
volume 34, pages 8018â€“8025, 2020.
12[36]H.Kim,G.Papamakarios,andA.Mnih. Thelipschitzconstantofself-attention. InM.MeilaandT.Zhang,
editors,Proceedingsofthe38thInternationalConferenceonMachineLearning ,volume139of Proceedings
of Machine Learning Research , pages 5562â€“5571. PMLR, 18â€“24 Jul 2021.
[37]M. Lecuyer, V. Atlidakis, R. Geambasu, D. Hsu, and S. Jana. Certified robustness to adversarial examples
withdifferential privacy. In 2019IEEE SymposiumonSecurity andPrivacy (SP) ,pages 656â€“672.IEEE,
2019.
[38]K. Leino, Z. Wang, and M. Fredrikson. Globally-robust neural networks. In International Conference on
Machine Learning , pages 6212â€“6222. PMLR, 2021.
[39]B. Li, C. Chen, W. Wang, and L. Carin. Certified adversarial robustness with additive noise. Advances in
Neural Information Processing Systems , 32, 2019.
[40]L.Li,R.Ma,Q.Guo,X.Xue,andX.Qiu. BERT-ATTACK:AdversarialattackagainstBERTusingBERT.
In B. Webber, T. Cohn, Y. He, and Y. Liu, editors, Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP) , pages 6193â€“6202, Online, Nov. 2020. Association for
Computational Linguistics.
[41]J. Lin, C. Song, K. He, L. Wang, and J. E. Hopcroft. Nesterov accelerated gradient and scale invariance for
adversarial attacks. In International Conference on Learning Representations , 2020.
[42]J. Liu, Z. Shen, Y. He, X. Zhang, R. Xu, H. Yu, and P. Cui. Towards out-of-distribution generalization: A
survey, 2023.
[43]X. Liu, H. Cheng, P. He, W. Chen, Y. Wang, H. Poon, and J. Gao. Adversarial training for large neural
language models. arXiv preprint arXiv:2004.08994 , 2020.
[44]Y.Liu,M.Ott,N.Goyal,J.Du,M.Joshi,D.Chen,O.Levy,M.Lewis,L.Zettlemoyer,andV.Stoyanov.
RoBERTa: A robustly optimized BERT pretraining approach, 2020.
[45]Z.Lu,H.Pu,F.Wang,Z.Hu,andL.Wang. Theexpressivepowerofneuralnetworks: Aviewfromthe
width.Advances in Neural Information Processing Systems , 30, 2017.
[46]B. LÃ¼tjens, M. Everett, and J. P. How. Certified adversarial robustness for deep reinforcement learning. In
L. P. Kaelbling, D. Kragic, and K. Sugiura, editors, Proceedings of the Conference on Robot Learning ,
volume 100 of Proceedings of Machine Learning Research , pages 1328â€“1337. PMLR, 30 Octâ€“01 Nov
2020.
[47]C.Ma,B.Zhao,C.Chen,andC.Rudin. ThisLooksLikeThose: IlluminatingPrototypicalConceptsUsing
Multiple Visualizations. Advances in Neural Information Processing Systems , 36, 2024.
[48]A.L.Maas,R.E.Daly,P.T.Pham,D.Huang,A.Y.Ng,andC.Potts. Learningwordvectorsforsentiment
analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:
Human Language Technologies , pages 142â€“150, Portland, Oregon, USA, June 2011. Association for
Computational Linguistics.
[49]T.Mikolov,I.Sutskever,K.Chen,G.S.Corrado,andJ.Dean. Distributedrepresentationsofwordsand
phrasesandtheircompositionality. InC.Burges,L.Bottou,M.Welling,Z.Ghahramani,andK.Weinberger,
editors,Advances in Neural Information Processing Systems , volume 26. Curran Associates, Inc., 2013.
[50]T. Miyato, S.-i. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: a regularization method for
supervisedandsemi-supervisedlearning. IEEETransactionsonPatternAnalysisandMachineIntelligence ,
41(8):1979â€“1993, 2018.
[51]M. Moor, M. Horn, B. Rieck, andK. Borgwardt. Topological autoencoders. In International Conference
on Machine Learning , pages 7045â€“7054. PMLR, 2020.
[52]Y.Nie,A.Williams,E.Dinan,M.Bansal,J.Weston,andD.Kiela. AdversarialNLI:Anewbenchmarkfor
natural language understanding. In D. Jurafsky, J. Chai, N. Schluter, and J. Tetreault, editors, Proceedings
ofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics ,pages4885â€“4901,Online,
July 2020. Association for Computational Linguistics.
[53]Y. Oren, S. Sagawa, T. B. Hashimoto, and P. Liang. Distributionally robust language modeling. In
K.Inui,J.Jiang,V.Ng,andX.Wan,editors, Proceedingsofthe2019ConferenceonEmpiricalMethodsin
Natural Language Processing and the 9th International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP) , pages 4227â€“4237, Hong Kong, China, Nov. 2019. Association for Computational
Linguistics.
13[54]P. Pauli, A. Koch, J. Berberich, P. Kohler, and F. AllgÃ¶wer. Training robust neural networks using lipschitz
bounds.IEEE Control Systems Letters , 6:121â€“126, 2021.
[55]X. Qi, J. Wang, Y. Chen, Y. Shi, and L. Zhang. Lipsformer: Introducing lipschitz continuity to vision
transformers. In The Eleventh International Conference on Learning Representations , 2022.
[56]A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin,
J.Clark, etal. Learningtransferablevisualmodelsfromnaturallanguagesupervision. In International
conference on machine learning , pages 8748â€“8763. PMLR, 2021.
[57]A.Radford,K.Narasimhan,T.Salimans,I.Sutskever,etal.Improvinglanguageunderstandingbygenerative
pre-training, 2018.
[58]C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu. Exploring
thelimitsoftransferlearningwithaunifiedtext-to-texttransformer. JournalofMachineLearningResearch ,
21(140):1â€“67, 2020.
[59]W.Ruan,X.Huang,andM.Kwiatkowska. Reachabilityanalysisofdeepneuralnetworkswithprovable
guarantees. In Proceedings of the 27th International Joint Conference on Artificial Intelligence , IJCAIâ€™18,
page 2651â€“2659. AAAI Press, 2018.
[60]M.Salehi,H.Mirzaei,D.Hendrycks,Y.Li,M.H.Rohban,andM.Sabokrou. Aunifiedsurveyonanomaly,
novelty, open-set, and out of-distribution detection: Solutions and future challenges. Transactions on
Machine Learning Research , 2022.
[61]M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen. Mobilenetv2: Inverted residuals and
linearbottlenecks. In ProceedingsoftheIEEEConferenceonComputerVision andPatternRecognition ,
pages 4510â€“4520, 2018.
[62]A.Shafahi,W.R.Huang,C.Studer,S.Feizi,andT.Goldstein. Areadversarialexamplesinevitable? In
International Conference on Learning Representations , 2019.
[63]A.Shafahi,M.Najibi,M.A.Ghiasi,Z.Xu,J.Dickerson,C.Studer,L.S.Davis,G.Taylor,andT.Goldstein.
Adversarial training for free! Advances in Neural Information Processing Systems , 32, 2019.
[64]C. Shi, C. Holtz, and G. Mishne. Online adversarial purification based on self-supervised learning. In
International Conference on Learning Representations , 2021.
[65]M. H. Stone. The generalized weierstrass approximation theorem. Mathematics Magazine , 21(5):237â€“254,
1948.
[66]C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing
properties of neural networks, 2014.
[67]N.Tishby,F.C.Pereira,andW.Bialek.Theinformationbottleneckmethod. arXivpreprintphysics/0004057 ,
2000.
[68]Y.Tsuzuku,I.Sato,andM.Sugiyama. Lipschitz-margintraining: Scalablecertificationofperturbation
invariancefordeepneuralnetworks. InS.Bengio,H.Wallach,H.Larochelle,K.Grauman,N.Cesa-Bianchi,
andR.Garnett,editors, AdvancesinNeuralInformationProcessingSystems ,volume31.CurranAssociates,
Inc., 2018.
[69]M.UsamaandD.E.Chang. Towardsrobustneuralnetworkswithlipschitzcontinuity. In DigitalForensics
andWatermarking: 17thInternationalWorkshop,IWDW2018,JejuIsland,Korea,October22-24,2018,
Proceedings 17 , pages 373â€“389. Springer, 2019.
[70]A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Å. Kaiser, and I. Polosukhin.
Attention is all you need. Advances in Neural Information Processing Systems , 30, 2017.
[71]A.VirmauxandK.Scaman. Lipschitzregularityofdeepneuralnetworks: analysisandefficientestimation.
Advances in Neural Information Processing Systems , 31, 2018.
[72]E.Wallace,S.Feng,N.Kandpal,M.Gardner,andS.Singh. Universaladversarialtriggersforattackingand
analyzingNLP. InK.Inui,J.Jiang,V.Ng,andX.Wan,editors, Proceedingsofthe2019Conferenceon
EmpiricalMethodsinNaturalLanguageProcessingandthe9thInternationalJointConferenceonNatural
Language Processing(EMNLP-IJCNLP) ,pages 2153â€“2162,Hong Kong,China, Nov. 2019.Association
for Computational Linguistics.
14[73]B. Wang, S. Wang, Y. Cheng, Z. Gan, R. Jia, B. Li, and J. Liu. Info{bert}: Improving robustness of
language models from an information theoretic perspective. In International Conference on Learning
Representations , 2021.
[74]W. Wang, P. Tang, J. Lou, and L. Xiong. Certified robustness to word substitution attack with differential
privacy.InK.Toutanova,A.Rumshisky,L.Zettlemoyer,D.Hakkani-Tur,I.Beltagy,S.Bethard,R.Cotterell,
T.Chakraborty,andY.Zhou,editors, Proceedingsofthe2021ConferenceoftheNorthAmericanChapterof
the Association for Computational Linguistics: Human Language Technologies , pages 1102â€“1112, Online,
June 2021. Association for Computational Linguistics.
[75]A. Wei, N. Haghtalab, and J. Steinhardt. Jailbroken: How does llm safety training fail? In A. Oh,
T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information
Processing Systems , volume 36, pages 80079â€“80110. Curran Associates, Inc., 2023.
[76]L. Weng, H. Zhang, H. Chen, Z. Song, C.-J. Hsieh, L. Daniel, D. Boning, and I. Dhillon. Towards fast
computationofcertifiedrobustnessforReLUnetworks. InJ.DyandA.Krause,editors, Proceedingsof
the 35th International Conference on Machine Learning , volume 80 of Proceedings of Machine Learning
Research, pages 5276â€“5285. PMLR, 10â€“15 Jul 2018.
[77]L. Weng, H. Zhang, H. Chen, Z. Song, C.-J. Hsieh, L. Daniel, D. Boning, and I. Dhillon. Towards fast
computation of certified robustness for relu networks. In International Conference on Machine Learning ,
pages 5276â€“5285. PMLR, 2018.
[78]T.-W. Weng, H. Zhang, P.-Y. Chen, J. Yi, D. Su, Y. Gao, C.-J. Hsieh, and L. Daniel. Evaluating the
robustnessofneuralnetworks: Anextremevaluetheoryapproach. In InternationalConferenceonLearning
Representations , 2018.
[79]E.WongandZ.Kolter. Provabledefensesagainstadversarialexamplesviatheconvexouteradversarial
polytope. In International Conference on Machine Learning , pages 5286â€“5295. PMLR, 2018.
[80]E. Wong, L. Rice, and J. Z. Kolter. Fast is better than free: Revisiting adversarial training. In International
Conference on Learning Representations , 2020.
[81]E.Wong,F.Schmidt,J.H.Metzen,andJ.Z.Kolter. Scalingprovableadversarialdefenses. Advancesin
Neural Information Processing Systems , 31, 2018.
[82]X.Xu,L.Li,Y.Cheng,S.Mukherjee,A.H.Awadallah,andB.Li. Certifiablyrobusttransformerswith
1-lipschitz self-attention, 2023.
[83]J. Yang, K. Zhou, Y. Li, and Z. Liu. Generalized out-of-distribution detection: A survey. International
Journal of Computer Vision , pages 1â€“28, 2024.
[84]C. Yao, P. Bielik, P. Tsankov, and M. Vechev. Automated discovery of adaptive attacks on adversarial
defenses. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, Advances in
Neural Information Processing Systems , volume 34, pages 26858â€“26870. Curran Associates, Inc., 2021.
[85]J. Y. Yoo and Y. Qi. Towards improvingadversarial training of NLP models. In M.-F. Moens, X.Huang,
L.Specia,andS.W.-t.Yih,editors, FindingsoftheAssociationforComputationalLinguistics: EMNLP
2021, pages 945â€“956, Punta Cana, Dominican Republic, Nov. 2021. Association for Computational
Linguistics.
[86]Y.YoshidaandT.Miyato. Spectralnormregularizationforimprovingthegeneralizabilityofdeeplearning.
arXiv preprint arXiv:1705.10941 , 2017.
[87]A.Zhang,A.Chan,Y.Tay,J.Fu,S.Wang,S.Zhang,H.Shao,S.Yao,andR.K.-W.Lee. Onorthogonality
constraints for transformers. In C. Zong, F. Xia, W. Li, and R. Navigli, editors, Proceedings of the
59thAnnualMeetingoftheAssociationforComputationalLinguisticsandthe11thInternationalJoint
ConferenceonNaturalLanguageProcessing(Volume2: ShortPapers) ,pages375â€“382,Online,Aug.2021.
Association for Computational Linguistics.
[88]B.Zhang,D.Jiang,D.He,andL.Wang. Boostingthecertifiedrobustnessofl-infinitydistancenets. In
International Conference on Learning Representations , 2022.
[89]B.Zhang,D.Jiang,D.He,andL.Wang. Rethinkinglipschitzneuralnetworksandcertifiedrobustness:
Abooleanfunctionperspective. AdvancesinNeuralInformationProcessingSystems ,35:19398â€“19413,
2022.
15[90]H.Zhang,H.Chen,C.Xiao,S.Gowal,R.Stanforth,B.Li,D.Boning,andC.-J.Hsieh. Towardsstable
and efficient training of verifiably robust neural networks. In International Conference on Learning
Representations , 2020.
[91]A.Zou,Z.Wang,N.Carlini,M.Nasr,J.Z.Kolter,andM.Fredrikson. Universalandtransferableadversarial
attacks on aligned language models, 2023.
16Table of Contents
1 Introduction 1
2 Related Works 2
3 Preliminaries 3
4 Knowledge Continuity 3
4.1 Defining Perceived Knowledge . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
4.2 Defining Knowledge Continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
4.3 Certification of Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
4.4 Expressiveness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
4.5 Connections to Lipschitz Continuity . . . . . . . . . . . . . . . . . . . . . . . . . 8
5 Practical Applications 9
6 Conclusion 10
7 Acknowledgements 11
A More on Metric Decompositions 18
A.1 Metric Decompositions of Common Neural Architectures . . . . . . . . . . . . . . 18
A.2 Beyond Neural Networks: Inducing Metric Decompositions . . . . . . . . . . . . 19
B Proof of Robustness 20
B.1 Technical Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
C Proof of Expressiveness 22
C.1 Technical Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
D Proof of Equivalence Between Lipschitz Continuity and Knowledge Continuity 23
E Predicting Adversarial Robustness with Volatility 25
F Localizing Volatile Hidden Representations 26
F.1 Layerwise Volatility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
F.2 Model-Specific Volatility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
G Regularizing Knowledge Continuity 27
G.1 Estimating Knowledge Continuity Algorithmically . . . . . . . . . . . . . . . . . 27
G.2 Theoretical Guarantees of ğ‘˜-Volatility Estimation . . . . . . . . . . . . . . . . . . 28
G.3 Computer Vision Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
G.4 Ablation Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
G.5 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
H Certifying Robustness at Test-Time 32
I Broader Impacts 33
J Reproducibility 33
K Limitations 33
L NeurIPS Paper Checklist 34
17A More on Metric Decompositions
InSection4.1,weintroducedthenotionofa metricdecomposition torigorouslydefinethehidden
representations of a neural network. Herein, we show that our notion of a metric decomposition
well-describesahostofneuralarchitecturesandalsopointtopossibleapplicationsofthisconcept
beyondjustdeeplearning. Letusfirstconsiderpossiblemetricdecompositionsofcommonneural
architectures.
A.1 Metric Decompositions of Common Neural Architectures
Fully-Connected Neural Network. Suppose that ğ‘“âˆ¶â„ğ‘‘â†’â„ğ‘šis a fully-connected neural network
withğ‘›hiddenlayers. Eachhiddenlayerindexedby ğ‘–âˆˆ[ğ‘›]hasaweightmatrix ğ‘Šğ‘–âˆˆâ„ğ‘‘ğ‘–+1Ã—ğ‘‘ğ‘–,bias
ğ‘ğ‘–âˆˆâ„ğ‘‘ğ‘–+1, and activation function ğœğ‘–âˆ¶â„ğ‘‘ğ‘–+1â†’â„ğ‘‘ğ‘–+1, whereğ‘‘ğ‘–âˆˆâ„•,ğ‘‘1=ğ‘‘,ğ‘‘ğ‘›=ğ‘š. Define the
hidden layers as
â„ğ‘˜(ğ‘¥)=ğœğ‘˜(ğ‘Šğ‘˜ğ‘¥+ğ‘ğ‘˜),
for allğ‘˜âˆˆ[ğ‘›]. Clearly,ğ‘“=â„ğ‘›â—¦â„ğ‘›âˆ’1â—¦â€¦â—¦â„1. Andour intermediatespaces aresimply {â„ğ‘‘ğ‘–}ğ‘›
ğ‘–=1. It
remains to define a metric on these hidden spaces. There are many ways of doing this. For example,
â€¢For any1â‰¤ğ‘â‰¤âˆ, endow each intermediate space with the ğ“ğ‘-norm.
â€¢Defineğ‘‘(ğ‘¥,ğ‘¦)=1âˆ’cos(ğœƒğ‘¥,ğ‘¦)whereğœƒğ‘¥,ğ‘¦istheanglebetween ğ‘¥,ğ‘¦. Then,ifwechoose ğœğ‘–to
restricttheimageof â„ğ‘–tobetheunitsphere,wemayendoweachintermediatespacewith
thiscosine distance .
Note here that there are two steps here: we first identify what the intermediate spaces are, then assign
metrics to them. The process of identfying these intermediate spaces may be independent of the
metrics we end of assigning them.
ConvolutionalNeuralNetwork. Forsimplicity,weonlyconsiderthecaseofasingle2d-convolution
layer, a convolutional network with higher dimensions or more layers can be derived inductively.
Letğ‘“âˆ¶â„ğ‘Ã—â„Ã—ğ‘¤â†’â„ğ‘â€²Ã—â„â€²Ã—ğ‘¤â€². Suppose that this layer is parameterized by kernels ğ‘Šğ‘–âˆˆâ„ğ‘˜Ã—ğ‘˜for
ğ‘–âˆˆ[ğ‘â€²]and someğ‘˜âˆˆâ„•as well as a bias ğ‘âˆˆâ„ğ‘â€². Then, it follows that
ğ‘“(ğ‘¥)ğ‘—=(
ğŸâ„â€²Ã—ğ‘¤â€²ğ‘ğ‘—+ğ‘âˆ‘
ğ‘–=1ğ‘Šğ‘—âˆ—ğ‘¥[ğ‘–,âˆ¶,âˆ¶])
,
forğ‘—âˆˆ[ğ‘â€²]whereğ‘“(ğ‘¥)ğ‘—âˆˆâ„â„â€²Ã—ğ‘¤â€²forâ„â€²,ğ‘¤â€²being the resulting dimension after convolution with a
ğ‘˜Ã—ğ‘˜kernel. Here, ğŸâ„â€²Ã—ğ‘¤â€²âˆˆâ„â„â€²Ã—ğ‘¤â€²isaonematrix. Toinduceadistancemetriconthisoutputspace,
we can simply define a matrix norm on each of the output channels and sum them. Let {â€–â‹…â€–ğ‘–}ğ‘â€²
ğ‘–=1be a
collection of matrix norms. Then, we define
ğ‘‘(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))=ğ‘â€²âˆ‘
ğ‘–=1â€–â€–ğ‘“(ğ‘¥)ğ‘–âˆ’ğ‘“(ğ‘¥â€²)ğ‘–â€–â€–ğ‘–.
Itiseasytoverifythatthisisametric. Thus,theavailabilityofametricdecompositionisnotaffected
by parameter sharing.
Insteadofincorporatingeveryindividualchannelintoourmetric,wemayalsoconsiderapplyinga
pooling operation before passing the result through a single matrix norm, â€–â‹…â€–. For example,
ğ‘‘(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))=1
ğ‘â€²â€–â€–â€–â€–â€–â€–ğ‘â€²âˆ‘
ğ‘–=1ğ‘“(ğ‘¥)ğ‘–âˆ’ğ‘â€²âˆ‘
ğ‘–=1ğ‘“(ğ‘¥â€²)ğ‘–â€–â€–â€–â€–â€–â€–.
This,however,isnolongerametric,asdefinitenessisnotpreserved. Thatis,thereexists ğ‘“(ğ‘¥)â‰ ğ‘“(ğ‘¥â€²)
whereğ‘‘(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))=0. This issue can be easily resolved by having ğ‘‘(â‹…,â‹…)operate on a quotient
space with respect to the equivalence relation ğ‘“(ğ‘¥)âˆ¼ğ‘“(ğ‘¥â€²)if and only ifâˆ‘ğ‘â€²
ğ‘–=1ğ‘“(ğ‘¥)ğ‘–=âˆ‘ğ‘â€²
ğ‘–=1ğ‘“(ğ‘¥â€²)ğ‘–.
This technique is further explored in the next subsection.
ResidualConnections. Wepresenttwodistinctmetricdecompositionsofaresidualnetwork. Consider
two fully-connected layers with one residual connection. This is visualized below.
18ğ‘¥ ğ´(ğ‘¥) ğµ(ğ´(ğ‘¥)) ğµ(ğ´(ğ‘¥))+ğ‘¥ ğ´(â‹…) ğµ(â‹…)
+ğ‘¥
Let us assume that ğ´âˆ¶â„ğ‘‘1â†’â„ğ‘‘2andğµâˆ¶â„ğ‘‘2â†’â„ğ‘‘1. Here, the input ğ‘¥feeds back into the output
layerğµcreating a residual block (the set of layers between the input and the residual connection).
Trivially, we can aggregate the entire residual block as one metric decomposition. That is, let
â„(ğ‘¥) =ğµ(ğ´(ğ‘¥))+ğ‘¥be our metric decomposition. Then, define a metric on the image of â„,â„ğ‘‘1,
analogous to the hidden layers of a fully-connected neural network. This is the approach we use
throughout our practical applications section (Section 5), and it is the standard way to counter layers
in computer vision [27] and natural langauge processing [16].
To operate at a finer lever of granularity, we can also represent each layer within the residual block as
a part of a metric decomposition. Let us redefine the residual block such that at every layer, we keep
track of the input. The computational graph for this is shown below.
ğ‘¥ (ğ´(ğ‘¥),ğ‘¥) (ğµ(ğ´(ğ‘¥)),ğ‘¥) (ğµ(ğ´(ğ‘¥))+ğ‘¥,ğ‘¥) ğ´(â‹…)âŠ•ğ‘¥ ğµ(â‹…) +ğ‘¥
Defineğ´â€²âˆ¶ğ‘¥â†¦(ğ´(ğ‘¥),ğ‘¥),ğµâ€²âˆ¶(ğ´(ğ‘¥),ğ‘¥)â†¦(ğµ(ğ´(ğ‘¥)),ğ‘¥)andğ‘¥â€²âˆ¶(ğµ(ğ´(ğ‘¥)),ğ‘¥)â†¦(ğµ(ğ´(ğ‘¥))+ğ‘¥,ğ‘¥).
Then, it follows that ğ‘¥â†’ğ´â€²â†’ğµâ€²â†’ğ‘¥â€²forms a metric decomposition. Here, the metric in each
layeriswithrespecttothequotientspacewhere (ğ‘,ğ‘â€²)âˆ¼(ğ‘,ğ‘â€²)ifandonlyif ğ‘=ğ‘. Therefore,we
also recover the same vector space structure.
Transformers. By chaining our metric decompositions for the residual blocks with our metric
decompositions for the fully-connected networks we can easily create a metric decomposition for any
transformer. Throughout the paper, we use two distinct methods to generate representations of its
hidden layers:
â€¢After each attention block which consists of multiheaded attention and multilayered percep-
trons, we retrieve the last token.
â€¢We average all of the tokens together.
Inbothofthesemethods,wearesignificantlyreducingthedimensionofthehiddenlayer. Thus,to
formalizethesemetrics,weneedtoquotientoutpointsthatbreakthedefinitenessofourmetric,as
we have done before with the residual block.
A.2 Beyond Neural Networks: Inducing Metric Decompositions
We have shown that our notion of a metric decomposition can well-describe many deep learning
architectures,butwhataboutmodelsthatarenotneuralnetworks(likeadecisiontree)? Herein,we
demonstrate that we can induce metric decompositions even when the model itself does not have
explicit hidden layers.
Let us now consider an arbitrary function ğ‘“âˆ¶î‰„â†’î‰…. We can induce a metric decomposition on
ğ‘“through an auxiliary function ğ‘“â€²âˆ¶î‰„â†’î‰„, for a metric-decomposable ğ‘“â€². Ifğ‘“â€²=Idî‰„, then,
ğ‘“=ğ‘“â—¦ğ‘“â€²and the metric decomposition of ğ‘“would be exactly the metric decomposition of ğ‘“â€². This
is visualized below.
î‰„(î‰†1,ğ‘‘1)
â€¦(î‰†ğ‘›,ğ‘‘ğ‘›) î‰„ î‰…ğ‘“â€²
0ğ‘“â€²
1ğ‘“â€²
ğ‘›âˆ’1ğ‘“â€²
ğ‘› ğ‘“
Metric Decomposition of ğ‘“â€²
Essentially, we have created an autoencoder for î‰„. This is common in many applications where a
neural network or some other method is used as a feature extractor. In this way, we can simply define
our metric with respect to these extracted features. However, this requires that either the autoencoder
19to be exact or that our function ğ‘“is invariant under representations that collide. Thus, this would
allow models such as decision trees to also be metric decomposed.
B Proof of Robustness
Theorem (SeeThm.4.1) .Letğ´âŠ‚î‰„Ã—î‰…suchthat â„™îˆ°î‰„,î‰…[ğ´]>0andğ›¿,ğœ‚>0. Letğ´â€²={(ğ‘¥â€²,ğ‘¦â€²)âˆˆ
î‰„Ã—î‰…âˆ¶ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…
(ğ‘¥,ğ‘¦)âˆˆğ´Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)>ğœ‚}. Ifğ‘“âˆ¶î‰„â†’î‰…isğœ–-knowledge continuous with respect to
the hidden layer indexed by ğ‘˜and(î‰†ğ‘˜,ğ‘‘ğ‘˜)is bounded by ğµ>0, then
â„™(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…[ğ´â€²âˆ£ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿]â‰¤ğœ–ğ›¿
ğœ‚(
1âˆ’exp[
âˆ’Î©(
ğ›¿
ğµâˆ’âˆš
log1
â„™[ğ´])2]),(B.1)
whereğ‘“ğ‘˜(ğ´)={ğ‘“ğ‘˜(ğ‘)âˆ¶ğ‘âˆˆğ´}.
Proof.
â„™(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…[ğ´â€²âˆ£ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿]=â„™(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…[ğ´â€²âˆ©ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿]
â„™(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…[ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿].(B.2)
We bound the numerator and denominator of Eq. B.2 separately. The denominator is given by
Cor. B.3. We upper-bound the numerator using Markovâ€™s inequality. Firstly, we find the expectation
ofîˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)overğ´â€²âˆ©ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿:
ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)=ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…â›
âœ
âœâğ”¼(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…â¡
â¢
â¢â£Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))â¤
â¥
â¥â¦â
âŸ
âŸâ ,(B.3)
=ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼(îˆ°î‰„,î‰…Ã—îˆ°î‰„,î‰…)â¡
â¢
â¢â£Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))â¤
â¥
â¥â¦. (B.4)
The previous inequality follows from Fubiniâ€™s theorem, then
ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)â‰¥ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼(îˆ°î‰„,î‰…Ã—îˆ°î‰„,î‰…)
(ğ‘¥â€²,ğ‘¦â€²)âˆˆğ´
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿â¡
â¢
â¢â£Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))â¤
â¥
â¥â¦, (B.5)
â‰¥1
ğ›¿ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼(îˆ°î‰„,î‰…Ã—îˆ°î‰„,î‰…)
(ğ‘¥â€²,ğ‘¦â€²)âˆˆğ´
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿[
Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)]
, (B.6)
ğ›¿ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)â‰¥ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼(îˆ°î‰„,î‰…Ã—îˆ°î‰„,î‰…)
(ğ‘¥â€²,ğ‘¦â€²)âˆˆğ´
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿[
Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)]
. (B.7)
And byğœ–-knowledge continuity,
ğ›¿ğœ–â‰¥ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼(îˆ°î‰„,î‰…Ã—îˆ°î‰„,î‰…)
(ğ‘¥â€²,ğ‘¦â€²)âˆˆğ´
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿[
Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)]
. (B.8)
Thisgivesusanupper-boundofexpectationof Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)overthesetofallpointsthatarewithin
ğ›¿-radius from ğ‘“ğ‘˜(ğ´). SinceÎ”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)â‰¥0everywhere, by Markovâ€™s inequality,
â„™(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…[ğ´â€²âˆ©ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ´))<ğ›¿]â‰¤ğ›¿ğ”¼ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)
ğœ‚, (B.9)
20â‰¤ğ›¿ğœ–
ğœ‚. (B.10)
The last inequality follows from ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)<ğœ–, by the definition of ğœ–-knowledge continuity.
Now, by applying the complement of Lem. B.2, we lower-bound the denominator and yield the
following
â„™(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°[ğ´â€²âˆ£ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))<ğ›¿]â‰¤ğœ–ğ›¿
ğœ‚(
1âˆ’exp(
âˆ’2
ğµ2(
ğ›¿âˆ’ğµâˆš
1
2log2
â„™[ğ´])2)).(B.11)
The proof is concluded by applying Î©(â‹…)notation to the denominator. â– 
B.1 Technical Lemmas
Definition6. Afunctionğ‘“âˆ¶î‰„1Ã—â€¦Ã— î‰„ğ‘›â†’â„hasboundedvariationifthereare ğ‘1,â€¦,ğ‘ğ‘›âˆˆâ„
such that for all 1â‰¤ğ‘–â‰¤ğ‘›andğ‘¥1âˆˆî‰„1,â€¦,ğ‘¥ğ‘›âˆˆî‰„ğ‘›,
sup
ğ‘¥â€²
ğ‘–âˆˆî‰„ğ‘–|ğ‘“(ğ‘¥1,â€¦,ğ‘¥ğ‘–,â€¦,ğ‘¥ğ‘›)âˆ’ğ‘“(ğ‘¥1,â€¦,ğ‘¥â€²
ğ‘–,â€¦,ğ‘¥ğ‘›)|â‰¤ğ‘ğ‘–. (B.12)
Lemma B.1 (McDiarmidâ€™s Inequality) .Assume that the function ğ‘“âˆ¶î‰„1Ã—â€¦Ã— î‰„ğ‘›â†’â„satisfy the
bounded differences property with bounds ğ‘1,â€¦,ğ‘ğ‘›. Consider the independent random variables
ğ‘‹1,â€¦,ğ‘‹ğ‘›whereğ‘‹ğ‘–âˆˆî‰„ğ‘–for all1â‰¤ğ‘–â‰¤ğ‘›. Then, for any ğœ–>0,
â„™[|ğ‘“(ğ‘‹1,â€¦,ğ‘‹ğ‘›)âˆ’ğ”¼[ğ‘“(ğ‘‹1,â€¦,ğ‘‹ğ‘›)|â‰¥ğœ–]â‰¤2exp(
âˆ’2ğœ–2
âˆ‘ğ‘›
ğ‘–=1ğ‘2
ğ‘–)
. (B.13)
Lemma B.2. Suppose that (î‰„,ğ‘‘)is a bounded metric space such that supğ‘¥,ğ‘¥â€²âˆˆî‰„ğ‘‘(ğ‘¥,ğ‘¥â€²)< ğµfor
someğµ>0. Letğ´âŠ‚ğ‘‹such that â„™[ğ´]>0andğœ–>0. Then,
â„™[ğ‘‘(ğ‘¥,ğ´)â‰¥ğœ–]â‰¤expâ›
âœ
âœââˆ’2
ğµ2(
ğœ–âˆ’ğµâˆš
1
2log2
â„™[ğ´])2â
âŸ
âŸâ .
Proof.Forbrevity,denote ğ‘“ğ´(ğ‘¥)=ğ‘‘(ğ´,ğ‘¥)=infğ‘âˆˆğ´ğ‘‘(ğ‘¥,ğ‘). Since(î‰„,ğ‘‘)isaboundedmetricspace,
by Lem. B.1,
â„™[|ğ‘“ğ´(ğ‘¥)âˆ’ğ”¼ğ‘“ğ´(ğ‘¥)|â‰¥ğœ–]=2exp(
âˆ’2ğœ–2
ğµ2)
, (B.14)
â„™[ğ‘“ğ´(ğ‘¥)âˆ’ğ”¼ğ‘“ğ´(ğ‘¥)â‰¥ğœ–]+â„™[ğ‘“ğ´(ğ‘¥)âˆ’ğ”¼ğ‘“ğ´(ğ‘¥)â‰¤âˆ’ğœ–]â‰¤2exp(
âˆ’2ğœ–2
ğµ2)
,(B.15)
â„™[ğ‘“ğ´(ğ‘¥)âˆ’ğ”¼ğ‘“ğ´(ğ‘¥)â‰¤âˆ’ğœ–]â‰¤2exp(
âˆ’2ğœ–2
ğµ2)
, (B.16)
Letğœ–=ğ”¼ğ‘“ğ´(ğ‘¥). Then,
â„™[ğ‘“ğ´(ğ‘¥)â‰¤0]â‰¤2exp(
âˆ’2(ğ”¼ğ‘“ğ´(ğ‘¥))2
ğµ2)
, (B.17)
â„™[ğ´]â‰¤2exp(
âˆ’2(ğ”¼ğ‘“ğ´(ğ‘¥))2
ğµ2)
, (B.18)
ğ”¼ğ‘“ğ´(ğ‘¥)â‰¤âˆš
ğµ2
2log(
2
â„™[ğ´])
. (B.19)
The second inequality follows from â„™[ğ‘“ğ´(ğ‘¥)â‰¤0]=â„™[ğ‘“ğ´(ğ‘¥)=0] â‰¥â„™[ğ´]. By Eq. B.15,
â„™[ğ‘“ğ´(ğ‘¥)âˆ’ğ”¼ğ‘“ğ´(ğ‘¥)â‰¥ğœ–]+â„™[ğ‘“ğ´(ğ‘¥)âˆ’ğ”¼ğ‘“ğ´(ğ‘¥)â‰¤âˆ’ğœ–]â‰¤2exp(
âˆ’2ğœ–2
ğµ2)
,
21â„™[ğ‘“ğ´(ğ‘¥)âˆ’ğ”¼ğ‘“ğ´(ğ‘¥)â‰¥ğœ–]â‰¤2exp(
âˆ’2ğœ–2
ğµ2)
,
â„™[ğ‘“ğ´(ğ‘¥)â‰¥ğœ–+ğ”¼ğ‘“ğ´(ğ‘¥)]â‰¤2exp(
âˆ’2ğœ–2
ğµ2)
,
â„™â¡
â¢
â¢â£ğ‘“ğ´(ğ‘¥)â‰¥ğœ–+âˆš
ğµ2
2log(
2
â„™[ğ´])â¤
â¥
â¥â¦â‰¤2exp(
âˆ’2ğœ–2
ğµ2)
, (by Eq. B.19,)
for anyğ›¿>0, letğœ–=ğ›¿âˆ’âˆš
ğµ2
2log2
â„™[ğ´]. And so,
â„™[ğ‘“ğ´(ğ‘¥)â‰¥ğ›¿]â‰¤2expâ›
âœ
âœ
âœââˆ’2
ğµ2â›
âœ
âœâğ›¿âˆ’ğµâˆš
1
2log(
2
â„™[ğ´])â
âŸ
âŸâ 2â
âŸ
âŸ
âŸâ ,
which is the desired expression. â– 
Corollary B.3. â„™[ğ‘“ğ´(ğ‘¥)<ğ›¿]â‰¥1âˆ’2expâ›
âœ
âœââˆ’2
ğµ2(
ğ›¿âˆ’ğµâˆš
1
2log(
2
â„™[ğ´]))2â
âŸ
âŸâ .
C Proof of Expressiveness
Proposition (See Prop. 4.4) .Suppose(î‰„,ğ‘‘î‰„),(î‰…,ğ‘‘î‰…)âˆ¶= (î‰„,ğ‘‘î‰„)arecompact metric spaces,
îˆ²âŠ‚î‰…î‰„is theset of all continuous functions fromî‰„toî‰…such that âˆ«ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)âˆ’1ğ‘‘ğœ‡ğ‘“<âˆandîˆ¸
be Lipschitz continuous in both coordinates. Then, there exists a universal function approximator î‰
ofîˆ²that is knowledge continuous (i.e. ğ”¼ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)<âˆfor someğ‘˜).
Proof.By Lem. C.3, the set of Lipschitz continuous functions â„’is dense in the set of all contin-
uous functions ğ’with respect to the uniform metric. By Lem. C.1, since |îˆ¸(ğ‘¥,ğ‘¦)|â‰¤ğ¾ğ‘‘(ğ‘¥,ğ‘¦), if
supğ‘¥âˆˆî‰„ğ‘‘(ğ‘“(ğ‘¥),ğ‘”(ğ‘¥))<ğœ–, then for any probability measure â„™overî‰„,
âˆ«îˆ¸(ğ‘“(ğ‘¥),ğ‘”(ğ‘¥))ğ‘‘â„™â‰¤âˆ«|îˆ¸(ğ‘“(ğ‘¥),ğ‘”(ğ‘¥))|ğ‘‘â„™â‰¤ğ¾ğœ–,
whereğ¾is the Lipschitz constant of îˆ¸. This implies that for any sequence ğœ–1,ğœ–2,â€¦we can
choose Lipschitz continuous functions ğ‘“1,ğ‘“2,â€¦with Lipschitz constants ğ¶1,ğ¶2,â€¦such that
âˆ«îˆ¸(ğ‘“ğ‘›(ğ‘¥),ğ‘¦)ğ‘‘ğœ‡ğ‘“< ğœ–ğ‘›. It remains to show that each of these functions are in fact knowledge
continuous. Since î‰„is a metric space, we consider the trivial metric decomposition of our sequence
of functions (see Remark 1). Specifically, we denote â„1=Idî‰„and proceed to bound ğ”¼ğœ1
ğ‘“(ğ‘¥,ğ‘¦).
ğ”¼ğœ1
ğ‘“ğ‘›(ğ‘¥,ğ‘¦)=âˆ¬Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“ğ‘›(ğ‘¥â€²,ğ‘¦â€²)
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)(ğ‘‘ğœ‡ğ‘“Ã—ğ‘‘ğœ‡ğ‘“), (C.1)
â‰¤âˆ¬|îˆ¸(ğ‘“ğ‘›(ğ‘¥),ğ‘¦)âˆ’îˆ¸(ğ‘“ğ‘›(ğ‘¥â€²),ğ‘¦)+îˆ¸(ğ‘“ğ‘›(ğ‘¥â€²),ğ‘¦)âˆ’îˆ¸(ğ‘“ğ‘›(ğ‘¥â€²),ğ‘¦â€²)|
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)(ğ‘‘ğœ‡ğ‘“Ã—ğ‘‘ğœ‡ğ‘“),(C.2)
â‰¤âˆ¬|îˆ¸(ğ‘“ğ‘›(ğ‘¥),ğ‘¦)âˆ’îˆ¸(ğ‘“ğ‘›(ğ‘¥â€²),ğ‘¦)|
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)ğ‘‘(ğœ‡ğ‘“Ã—ğœ‡ğ‘“) (C.3)
+âˆ¬|îˆ¸(ğ‘“ğ‘›(ğ‘¥â€²),ğ‘¦)âˆ’îˆ¸(ğ‘“ğ‘›(ğ‘¥â€²),ğ‘¦â€²)|
ğ‘‘(ğ‘¥,ğ‘¥â€²)(ğ‘‘ğœ‡ğ‘“Ã—ğ‘‘ğœ‡ğ‘“), (C.4)
â‰¤âˆ¬ğ¾ğ‘‘î‰„(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)ğ‘‘(ğœ‡ğ‘“Ã—ğœ‡ğ‘“)+âˆ¬ğ¾ğ‘‘î‰„(ğ‘¦,ğ‘¦â€²)
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)ğ‘‘(ğœ‡ğ‘“Ã—ğœ‡ğ‘“), (C.5)
ByLem.C.4,anycompactmetricspaceisbounded. So,let (î‰„,ğ‘‘)beboundedby ğ‘>0. Itfollows
thatğ‘‘î‰„(ğ‘¦,ğ‘¦â€²)â‰¤ğ‘and
â‰¤âˆ¬ğ¾ğ¶ğ‘›ğ‘‘(ğœ‡ğ‘“Ã—ğœ‡ğ‘“)+ğ¾ğ‘âˆ«1
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)ğ‘‘ğœ‡ğ‘“, (C.6)
22=ğ¾ğ¶ğ‘›+ğ¾ğ‘âˆ«ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)âˆ’1ğ‘‘ğœ‡ğ‘“, (C.7)
By assumption âˆ«ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)âˆ’1ğ‘‘ğœ‡ğ‘“<âˆand the statement of the proposition follows. â– 
C.1 Technical Lemmas
LemmaC.1. Ifîˆ¸(â‹…,â‹…)isLipschitzcontinuousinbothcoordinates,thenforany ğ‘¥,ğ‘¥â€²âˆˆî‰„,|îˆ¸(ğ‘¥,ğ‘¥â€²)|â‰¤
ğ¾ğ‘‘(ğ‘¥,ğ‘¥â€²), whereğ¾is the Lipschitz constant of îˆ¸.
Proof.By Lipschitz continuity,
|îˆ¸(ğ‘¥,ğ‘¥â€²)âˆ’îˆ¸(ğ‘¥,ğ‘¥)|â‰¤ğ¾ğ‘‘(ğ‘¥,ğ‘¥â€²),
|îˆ¸(ğ‘¥,ğ‘¥â€²)|â‰¤ğ¾ğ‘‘(ğ‘¥,ğ‘¥â€²).
â– 
Lemma C.2. The set of all Lipschitz continuous functions from î‰„â†’î‰„separates all points in î‰„.
Proof.The identity function is 1-Lipschitz continuous and it also separates all points in î‰„.â– 
Corollary C.3. Letğ’âŠ‚î‰„î‰„be the set of all continuous functions from î‰„â†’î‰„andâ„’âŠ‚î‰„î‰„be the
set of all Lipschitz continuous functions from î‰„â†’î‰„. Ifî‰„is compact, then â„’is dense inğ’with
respect to the uniform metric: ğ‘‘â€²(ğ‘“,ğ‘”)=supğ‘¥âˆˆî‰„ğ‘‘(ğ‘“(ğ‘¥),ğ‘”(ğ‘¥)).
Proof.This follows directly from Lem. C.2 and the Stone-Weierstrass theorem [65]. â– 
Lemma C.4. Any compact metric space (î‰„,ğ‘‘)is also bounded.
Proof.Bywayofcontrapositionsupposethat (î‰„,ğ‘‘)isnotbounded. Then, supğ‘¥,ğ‘¥â€²âˆˆî‰„ğ‘‘(ğ‘¥,ğ‘¥â€²)=âˆ.
Pickğ‘¥1âˆˆî‰„arbitrarily and pick ğ‘¥ğ‘›forğ‘›âˆˆâ„¤+,ğ‘›>1such thatğ‘‘(ğ‘¥ğ‘›,ğ‘¥1)>ğ‘›. Clearly, there does
not exist a convergent subsequence of the sequence ğ‘¥1,ğ‘¥2,â€¦. Thus,(î‰„,ğ‘‘)cannot be compact. â– 
D Proof of Equivalence Between Lipschitz Continuity and Knowledge
Continuity
Proposition. (See Prop. 4.6) Suppose that (î‰„,ğ‘‘î‰„),(î‰…,ğ‘‘î‰…)are metric spaces. Let the first ğ‘›metric
decompositionsof ğ‘“âˆ¶î‰„â†’î‰…beğ¾ğ‘–-Lipschitzcontinuous,for ğ‘–âˆˆ[ğ‘›]. Ifğ‘“isğœ–-knowledgecontinuous
withrespecttothe ğ‘›thhiddenlayerand ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))â‰¤ğœ‚Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦)forallğ‘¥,ğ‘¥â€²âˆˆî‰„,ğ‘¦âˆˆî‰…,
and someğœ‚>0, thenğ‘“is Lipschitz continuous in expectation. That is,
ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)â‰¤ğœ–ğœ‚ğ‘›âˆ
ğ‘—=1ğ¾ğ‘—. (D.1)
Proof.We proceed to bound the knowledge continuity of ğ‘“from below.
ğ”¼ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦)â‰¥ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğ”¼(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…
ğ‘¦â€²=ğ‘¦Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦)
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²)), (D.2)
â‰¥ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğ”¼(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°
ğ‘¦â€²=ğ‘¦Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦)
âˆğ‘›
ğ‘—=1ğ¾ğ‘—ğ‘‘î‰„(ğ‘¥â€²,ğ‘¥), (D.3)
â‰¥ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğ”¼(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°
ğ‘¦â€²=ğ‘¦1
ğœ‚ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
âˆğ‘›
ğ‘—=1ğ¾ğ‘—ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²), (D.4)
=ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…1
ğœ‚ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
âˆğ‘›
ğ‘—=1ğ¾ğ‘—ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²). (D.5)
23Eq. D.2 comes from the fact that we take the expectation only over pairs of points (ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)
whereğ‘¦=ğ‘¦â€²andalso becausethe summandisalways nonnegative. Then, weinductively applythe
definitionof ğ¾ğ‘–-Lipschitzcontinuityto yieldEq.D.3. Eq.D.4followsdirectly fromtheassumption
inthestatementoftheproposition. SincetheexpressioninEq.D.4nowhasnodependenceonthe
labeldistribution,wemay expandtheexpectationwhichresultsinEq.D.5. Lastly,bythedefinition
ofğœ–-knowledge continuity,
ğœ–â‰¥ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…1
ğœ‚ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
âˆğ‘›
ğ‘—=1ğ¾ğ‘—ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²),
ğœ–ğœ‚ğ‘›âˆ
ğ‘—=1ğ¾ğ‘—â‰¥ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²),
and this concludes the proof of the proposition. â– 
To prove Cor. 4.7, we need the following auxiliary result from [89].
PropositionD.1 (See[89]).Foraneuralnetwork ğ‘“âˆ¶â„ğ‘›â†’â„ğ¾withLipschitzconstant ğ¿under
ğ“ğ‘-norm, definetheresultingclassifier ğ‘”asğ‘”(ğ‘¥)âˆ¶=argmaxğ‘˜âˆˆ[ğ¾]ğ‘“ğ‘˜(ğ‘¥)for aninput ğ‘¥. Then,ğ‘”is
provably robust under perturbations â€–ğ›¿â€–ğ‘<ğ‘âˆš
2
2ğ¿margin(ğ‘“(ğ‘¥)), i.e.
ğ‘”(ğ‘¥+ğ›¿)=ğ‘”(ğ‘¥)for allâ€–ğ›¿â€–ğ‘<ğ‘âˆš
2
2ğ¿margin(ğ‘“(ğ‘¥)). (D.6)
Here, margin (ğ‘“(ğ‘¥))is the difference between the largest and second largeset output logit.
Corollary (See Cor. 4.7) .Suppose that assumptions of Prop. 4.6 are true. And also assume that
(î‰„,ğ‘‘î‰„) = (â„ğ‘›,ğ“ğ‘),(î‰…,ğ‘‘î‰…) = (â„ğ‘š,ğ“ğ‘), for1â‰¤ğ‘â‰¤âˆ. Define a classifier from ğ‘“âˆ¶â„ğ‘›â†’â„ğ‘š,
ğ‘”, whereğ‘”(ğ‘¥)âˆ¶= argmaxğ‘˜âˆˆ[ğ‘š]ğ‘“ğ‘˜(ğ‘¥)for anyğ‘¥âˆˆâ„ğ‘›. Then, with probability 1âˆ’ğœ–ğœ‚
ğ‘¡âˆğ‘›
ğ‘—=1ğ¾ğ‘—,
ğ‘”(ğ‘¥)=ğ‘”(ğ‘¥+ğ›¿)forallâ€–ğ›¿â€–ğ‘<ğ‘âˆš
2
2ğ‘¡margin(ğ‘“(ğ‘¥))andğ‘¡>0.ğ‘“ğ‘˜(ğ‘¥)istheğ‘˜thcoordinateof ğ‘“(ğ‘¥)and
margin(ğ‘“(ğ‘¥))denotes the difference between the largest and second-largest output logits.
Proof.By Prop. 4.6, we have that
ğ”¼(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)â‰¤ğœ–ğœ‚ğ‘›âˆ
ğ‘—=1ğ¾ğ‘—. (D.7)
By Markovâ€™s inequality,
â„™(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆ¼îˆ°î‰„,î‰…[ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)â‰¥ğ‘¡]
â‰¤ğœ–ğœ‚
ğ‘¡ğ‘›âˆ
ğ‘—=1ğ¾ğ‘—. (D.8)
We yield the corollary by directly applying Prop. D.1 assuming that ğ‘“isğ‘¡-Lipschitz continuous. â– 
Next, we establish conditions under which Lipschitz continuity implies knowledge continuity.
Proposition (Prop. 4.8) .Let(î‰„,ğ‘‘î‰„),(î‰…,ğ‘‘î‰…)be a metric spaces. Let ğ‘“âˆ¶î‰„â†’î‰…beğœ–-Lipschitz
continuousand îˆ¸(ğ‘“(ğ‘¥),ğ‘¦)beğœ‚-Lipschitzcontinuouswithrespecttobothcoordinates. Ifthefirst ğ‘›
metricdecompositionsof ğ‘“areğ¾ğ‘–-Lipschitzcontinuous,then ğ‘“isknowledgecontinuouswithrespect
to theğ‘›thhidden layer. That is,
ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…ğœğ‘›
ğ‘“(ğ‘¥,ğ‘¦)â‰¤ğœ–ğœ‚ğ‘›âˆ
ğ‘—=11
ğ¾ğ‘—. (D.9)
Proof.Let us start with the definition of ğœ–-Lipschitz continuity and lower-bound it. For any
(ğ‘¥,ğ‘¦),(ğ‘¥â€²,ğ‘¦â€²)âˆˆî‰„Ã—î‰…,
ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
ğ‘‘î‰„(ğ‘¥,ğ‘¥â€²)â‰¤ğœ–, (D.10)
24ğ‘‘î‰…(ğ‘“(ğ‘¥),ğ‘“(ğ‘¥â€²))
âˆğ‘›
ğ‘—=11
ğ¾ğ‘—ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))â‰¤ğœ–, (D.11)
1
ğœ‚|îˆ¸(ğ‘¥,ğ‘¦)âˆ’îˆ¸(ğ‘¥â€²,ğ‘¦â€²)|
âˆğ‘›
ğ‘—=11
ğ¾ğ‘—ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))â‰¤ğœ–, (D.12)
|îˆ¸(ğ‘¥,ğ‘¦)âˆ’îˆ¸(ğ‘¥â€²,ğ‘¦â€²)|
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥),ğ‘“ğ‘˜(ğ‘¥â€²))â‰¤ğœ–ğœ‚ğ‘›âˆ
ğ‘—=11
ğ¾ğ‘—. (D.13)
Eq.D.11followsfrominductivelyapplyingthedefinitionofLipschitzcontinuityonthemetricdecom-
positions of ğ‘“. Specifically, ğ‘‘ğ‘–+1(ğ‘“ğ‘–+1(ğ‘¥),ğ‘“ğ‘–+1(ğ‘¥â€²))â‰¤ğ¾ğ‘–ğ‘‘ğ‘–(ğ‘“ğ‘–(ğ‘¥),ğ‘“ğ‘–(ğ‘¥)). Then, by the Lipschitz
continuity of îˆ¸in both coordinateswe yield Eq. D.12. Since the Lebesgueintegral preserves order,
Eq. D.13 directly implies the statement of the proposition and this concludes the proof. â– 
E Predicting Adversarial Robustness with Volatility
In this section, we detail the experimental methods and results that use knowledge continuity to
predict adversarial vulnerability, briefly discussed in Section 5. We focus on langauge models of
varioussizesandtheirabilitytoperformsentimentclassificationontheIMDBdataset[ 48]. Before
computinganystatistics ofthemodel, wefinetuneitagainst theIMDBdatasetand reserveatestset
on which we compute a vulnerability score and estimate the modelâ€™s adversarial vulnerability.
Vulnerability Score. As described in the main text, given a model with ğ‘›hidden layers, we compute
allofitsğ‘˜-volatilityscores. ThisisdonewithanaiveMonto-Carloalgorithmwhichwepresentin
Appendix G. This results in a list of ğ‘˜-volatility scores {ğœ–1,â€¦,ğœ–ğ‘›}, one for each hidden layer. Then,
we perform a simple average ğ‘›âˆ’1âˆ‘ğ‘›
ğ‘˜=1ğœ–ğ‘˜. Let us denote this quantity as the vulnarability score .
Estimating Adversarial Robustness. It remains to estimate the adversarial vulnerability of a
givenmodel. Wedothisempiricallybyapplyinganout-of-the-boxadversarialattack(specifically,
TextFooler[ 35])onthegivenmodelwithrespecttothereservedtestset. Wethenmeasurethenumber
of successful adversarial attacks defined as
â™¯Successful Adversarial Attacks =|î‰„adversarialâˆ©î‰„correct)
|î‰„correct|,
where î‰„correctis the set of examples in the test set that are correctly classified by the model (after
finetuning) without any intervention. And, î‰„adversarialare the set of examples that are incorrectly
classified after an adversarial attack is applied. In other words, we only consider points where a
perturbation will worsenperformance. In expectation, this estimate of adversarial robustness should
bea1âˆ•2factorofthenotionofvulnerabilitywepresentinThm.4.1,wherewealsoconsiderapointto
be vulnerable if perturbation increases its performance.
We then perform a linear regression using vulnerability score and a host of other model properties to
predict the number of successful adversarial attacks. Concretely, we seek to learn the relationship:
â™¯Successful Adversarial Attacks =ğ‘šğ‘‡(
ğ‘›âˆ’1ğ‘›âˆ‘
ğ‘˜=1ğœ–ğ‘˜âŠ• â€¦âŸâŸâŸ
additional architectural variables)
+ğ‘,
whereğ‘šâˆˆâ„ğ‘‘andğ‘âˆˆâ„arethelearnableregressionparameters. Wealsoincorporate ğ‘‘âˆ’1sizeand
architecturalvariablesintoourregressionaswefoundthatsignificantlyincreasesitspredictiveness.
And so, the input variables to our regression and their types are:
Feature Type
Encoder Only {0,1}
Decoder Only {0,1}
Encoder-Decoder {0,1}
log(â™¯Parameters )â„
ğ‘›âˆ’1âˆ‘ğ‘›
ğ‘˜=1ğœ–ğ‘˜ â„
25Variables(1) (2) (3)
Coefficients Î”ğ‘…2Coefficients Î”ğ‘…2Coefficients Î”ğ‘…2
Encoder Only âœ— âœ— 1485 0.40 âˆ’548 0 .07
Decoder Only âœ— âœ— âˆ’2816 0.71 âˆ’557 0 .02
Encoder-Decoder âœ— âœ— 1332 0.29 1105 0 .18
log(â™¯Parameters ) âœ— âœ— 66 âˆ’6 .1Ã—10âˆ’5âˆ’363 0 .04
ğ‘›âˆ’1âˆ‘ğ‘›
ğ‘˜=1ğœ–ğ‘˜ 49 0.35 96 2 .57 âœ— âœ—
ğ‘…20.35 0.48 0.28
Table2: Regressionresultsfromourthreepreviouslydescribedexperimentalsettings. Weregress
the number of successful adversarial attacks against (1) only the vulnerability score (2) vulnerability
score and model characteristics (3) only model characteristics. The coefficients for each of these
regressions results are shown in the column Coefficients . We also run permutation tests for each
coefficient and the change in ğ‘…2is shown in the column Î”ğ‘…2(higher the better).
For the regression itself, we perform a Ridge regression with ğ›¼= 1. We test three experimental
conditions where we regress the modelâ€™s adversarial robustness against: (1) only vulnerability score,
(2) vulnerability score and model characteristics, (3) only model characteristics. We experiment
with seven models: RoBERTa (Base/Large) [ 44],BERT-Uncased (Base/Large) [ 16],GPT2, and T5
(Small/Base) [58]. Our regression results are shown in Table. 2.
After yielding an initial line-of-best fit (see Fig. 2(a)), we run permutation tests to determine the
contribution of each feature to the explained variance. Specifically, for each feature, keeping all else
constant,wepermuteitsvalues. Ifthisfeatureisasignificantcontributortotheexplainedvariance,
intuitively, we should see a large decrease in ğ‘…2after this intervention. If ğ‘ is theğ‘…2without any
intervention and ğ‘ ğœğ‘–(ğ‘‘)is theğ‘…2after permuting the data by ğœğ‘–(â‹…)âˆ¶[ğ‘›]â†’[ğ‘›](for a dataset of ğ‘›data
points). Then, we define
Î”ğ‘…2=ğ‘ âˆ’1
ğ‘ğ‘âˆ‘
ğ‘˜=1ğ‘ ğœğ‘˜(ğ‘‘),
whereğ‘controlsthenumberofpermutationsthatweapply. Forallexperimentswechoose ğ‘=100.
For formal theory on permutation tests, see [8].
We find that when our vulnerability score is added to the regression, it contributes significantly to
the explained variance. Moreover, in (2), we see that vulnerability score has the highest feature
importance among all regression variables.
F Localizing Volatile Hidden Representations
Inthissection,welocalizeadversariallyvulnerablehiddenrepresentationsintwoways. Firstly,we
useğ‘˜-volatility to gauge which layers are vulnerable across a selection of models. Then, we focus on
model-specificcharacterizationsofrobustnesswithrespectto ğ‘˜-volatility. Wepresentexperimentson
the same selection of models in Appendix E, the same dataset (IMDB [ 48]), and the same adversarial
attack (TextFooler [35]) to empirically measure adversarial vulnerability.
F.1 Layerwise Volatility
As mentioned in the previous section (Section E), for a given model with ğ‘›hidden layers, we can
measure its ğ‘˜-volatility for ğ‘˜âˆˆ [ğ‘›]through a Monte-Carlo algorithm. For each model, we then
plot itsğ‘˜-volatility against its relative depth which is defined as âŒŠğ‘˜âˆ•ğ‘›âŒ‹. These curves are shown
in Fig. 2(b). We see that models which have different architectures independent of size have very
differentğ‘˜-volatility curves.
We have already shown in the previous section that there is a positive correlation between ğ‘˜-volatility
andadversarialvulnerability. However,thiscorrelationisderivedfromthesimpleaverageofall ğ‘˜-
volatilityscores. Arethe ğ‘˜-volatilityscoresinsomelayersmorepredictiveofadversarialvulnerability
26thanothers? Ifthe ğ‘˜-volatilityinsomelayersismorecorrelatedwith ğ‘˜-volatilityinothers,thenit
shouldsufficetominimize ğ‘˜-volatilityintheseformerlayers. Thiswouldalsospeedupregularization
and training.
Werepeattheexperimentsintheprevioussettings. But,insteadofcollating ğ‘˜-volatilitythrougha
simple average, we run one regression for each relative depth across all models (which we discretize
into 9 bins). This result is shown in Fig. 2(c). Surprisingly, we find that the magnitude of ğ‘˜-volatility
is not necessarily predictive of adversarial vulnerability. Forexample, inFig.2(b), almost all of the
modelsexhibitlowaverage ğ‘˜-volatilityinthelatterlayers. However,the ğ‘˜-volatilityoflatterlayers
predict adversarial vulnerability the best.
F.2 Model-Specific Volatility
We start by exploring the ğ‘˜-volatility across each of our test models. We notice that ğ‘˜-volatility
cannot be predicted by surface-level features such as size or model type alone. This is shown clearly
inFig.3. Yet,asdiscussedinAppendixE,itisstillabletopredictactualadversarialvulnerability
with moderate power. Thus, we conjecture that ğ‘˜-volatility captures a complex aspect of the modelâ€™s
vulnerability which cannot be solely attributed to its size or type.
18.0 18.5 19.0 19.5
log(Parameters)
0.30.40.50.60.70.80.91.0Scaled n1n
k=1k
t5-small
bert-base
gpt2
roberta-base
t5-base
bert-largeroberta-large
18.0 18.5 19.0 19.5
log(Parameters)
Encoder-Decoder
Encoder
Decoder
Figure3: Average ğ‘˜-volatility plottedagainst thelogofnumberof modelparameters (left). We see
that although there isa strongnegativecorrelation, theexactlyrelationship isnontrivial. Moreover,
this negative correlation is also consistently observed across model families (right).
G Regularizing Knowledge Continuity
In this section, we provide a comprehensive overview of regulating knowledge continuity to achieve
robustness. Wefirstshowasimplealgorithmthatestimates ğ‘˜-volatility. Then,wedemonstratehow
this can incorporated into anyloss function as a regularization term. We then prove guarantees that
revolvearoundtheunbiasednessofourestimationalgorithm. Lastly,wepresentdetaileddiscussionof
the results shown in Table 1 including training details and ablation studies over the hyperparameters.
G.1 Estimating Knowledge Continuity Algorithmically
Wefirstpresentamethodforestimating ğ‘˜-volatility. ThisisshowninAlg.1( ESTKVOL). Intheory,
oneshouldchoose ğ‘€=ğ‘,asthiswillleadtoamostaccurateestimate. Thisissimilartocontrastive
learningmethodswhereitisdesirabletomaketheminibatchsizesaslargeaspossible[ 56]. However,
ifğ‘ â‰«1,thiscanbecomequicklyintractable. Inpractice,duringregularizationwekeep ğ‘tobe
thesameasifweweredoingnormalfinetuning(i.e. 32/64)andset ğ‘€=ğ‘. Thisworkswell,and,
anecdotally, we find that in contrast to contrastive learning increasing ğ‘orğ‘€past this threshold
yields marginal returns. Further work could examine this relationship in more detail.
As discussed in the main text, the choice of metric (or representation space) which we enforce
knowledge continuity against is crucial as it determines the type of robustness we will achieve.
Therefore, in Alg. 1( KCREG), we incorporate this detail by sampling a hidden layer of interest using
a Beta distribution specified by hyperparameters ğ›¼,ğ›½. Then, on that minibatch, regularize ğ‘˜-volatility
27Algorithm 1 A Monte-Carlo algorithm for estimating ğ‘˜-volatility of some metric decomposable
functionğ‘“withğ‘›hidden layers (left). Augmenting any loss function to regularize ğ‘˜-volatility (right),
given some Beta distribution parameterized by ğ›¼,ğ›½and regularization strength ğœ†â‰¥0.
procedure ESTKVOL({(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘
ğ‘–=1,ğ‘€,ğ‘“,ğ‘˜)
Sample{ğ‘›1,â€¦,ğ‘›ğ‘€}âŠ‚[ğ‘]uniformly
ğœğ‘˜
ğ‘“â†0
Losses â†{îˆ¸(ğ‘“(ğ‘¥ğ‘›ğ‘–),ğ‘¦ğ‘›ğ‘–)}ğ‘€
ğ‘–=1
for(ğ‘–,ğ‘—)âˆˆ[ğ‘€]Ã—[ğ‘€]do
Distâ†ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥ğ‘›ğ‘–),ğ‘“ğ‘˜(ğ‘¥ğ‘›ğ‘—))
ğœğ‘˜
ğ‘“â†ğœğ‘˜
ğ‘“+|Lossesğ‘–âˆ’Lossesğ‘—|âˆ•DIST
returnğœğ‘˜
ğ‘“procedure KCREG(ğ›¼,ğ›½,ğ‘€,ğœ† )
ğ‘‹âˆ¼Beta(ğ›¼,ğ›½)
ğ‘˜â†max(âŒŠğ‘‹ğ‘›âŒ‹,1)
ğœğ‘˜
ğ‘“â†ESTKVOL({(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘
ğ‘–=1,ğ‘“,ğ‘€,ğ‘˜)
return1
ğ‘âˆ‘ğ‘
ğ‘–=1îˆ¸(ğ‘“(ğ‘¥ğ‘–),ğ‘¦ğ‘–)+1
ğ‘€2ğœ†ğœğ‘˜
ğ‘“
with respect to that sampled layer. Note that we choose the Beta distribution for simplicity, however,
it can be replaced by any distribution like a mixture of Gaussians.
In contrast to existing adversarial trainingmethods such as [ 32] and [63] which only use the embed-
dings, our algorithm gives the practitioner more control over which hidden layer (or distance metric)
toenforce smoothness. Inthisway, ifthe practitionerhassome knowledge aprioriofthe attackerâ€™s
strategy,theymaychoosetooptimizeagainstthemostsuitablemetricdecomposition. Wepresent
abriefdiscussionofthevarioustradeoffswhenchoosing ğ›¼,ğ›½inthefollowingsectionaswellasa
detailed empirical analysis in the following subsections.
ğœ†is the weight we put on the regularizer in relation to the loss function îˆ¸. We provide a detailed
ablationstudyoftheeffectsof ğœ†inthefollowingsubsections. Wesurprisinglyfindthatevenfor ğœ†â‰ª1
wecanachievesignificantedgeintermsofrobustnessoverexistingmethods. Thisisincontrastto
virtualadversarialtrainingmethodssuchas[ 43]whichrequiresapplyinga ğœ†-valuemagnitudeslarger.
Moreover, for larger ğœ†, we find that the accuracy of the model is not compromised. This provides
some empirical support for Theorem 4.3.
G.2 Theoretical Guarantees of ğ‘˜-Volatility Estimation
In this subsection, we show that our Monte-Carlo algorithm presented in Alg. 1( ESTKVOL) is an
unbiased estimator. The proof is simple and follows from some bookkeeping.
PropositionG.1 (Alg.1(ESTKVOL)isanUnbiasedEstimator) .Assumingthateachdatapointinthe
batch,{(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘
ğ‘–=1âˆ¼îˆ°î‰„,î‰…, is sampled i.i.d., then Alg. 1( ESTKVOL) is an unbiased estimator for
ğ”¼ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦).
Proof.LetÌ‚ğœƒbe the random variable representing the output of Alg. 1. It suffices to show that
ğ”¼[Ì‚ğœƒ]=ğ”¼ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦),
wheretheexpectationontheleft-handsideistakenoverthesetofallbatches. Bythedefinitionof
Alg. 1(E STKVOL),
ğ”¼[Ì‚ğœƒ]=ğ”¼â›
âœ
âœ
âœâğ‘€âˆ‘
ğ‘–=1ğ‘€âˆ‘
ğ‘—=11
ğ‘€2Î”îˆ¸(ğ‘¥ğ‘›ğ‘—,ğ‘¦ğ‘›ğ‘—)
ğ‘“(ğ‘¥ğ‘›ğ‘–,ğ‘¦ğ‘›ğ‘–)
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥ğ‘›ğ‘–),ğ‘“ğ‘˜(ğ‘¥ğ‘›ğ‘—))â
âŸ
âŸ
âŸâ , (G.1)
=ğ‘€âˆ‘
ğ‘–=1ğ‘€âˆ‘
ğ‘—=11
ğ‘€2ğ”¼â›
âœ
âœ
âœâÎ”îˆ¸(ğ‘¥ğ‘›ğ‘—,ğ‘¦ğ‘›ğ‘—)
ğ‘“(ğ‘¥ğ‘›ğ‘–,ğ‘¦ğ‘›ğ‘–)
ğ‘‘ğ‘˜(ğ‘“ğ‘˜(ğ‘¥ğ‘›ğ‘–),ğ‘“ğ‘˜(ğ‘¥ğ‘›ğ‘—))â
âŸ
âŸ
âŸâ , (G.2)
=ğ”¼ğœğ‘˜
ğ‘“(ğ‘¥,ğ‘¦). (G.3)
The second equality follows from the linearity of expectation. â– 
Weemphasizethatourestimatorisverynaive. Improvingitsefficiencycouldformthebasisofpossible
future work. For example, Rao-Blackwellizing [ 6] Alg. 1(ESTKVOL) to yield an estimator with
280.0
0.2
0.4
0.6
0.8
1.0
0.6
0.7
0.8
0.9
1.0
resnet50
0.0
0.2
0.4
0.6
0.8
1.0
0.5
0.6
0.7
0.8
0.9
1.0
mobilenet
0.0
0.2
0.4
0.6
0.8
1.0
0.2
0.4
0.6
0.8
1.0
vit16Ours Base
0.0
0.2
0.4
0.6
0.8
1.0
0.5
0.6
0.7
0.8
0.9
1.0Macro F1
resnet50
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
mobilenet
0.0
0.2
0.4
0.6
0.8
1.0
.88
.90
.92
.94
.96
.98
1.0
vit16
Attack StrengthGoodfellow et al. (2014)
Lin et al. (2020)
0.3
0.2
0.1
0.00.10.20.3
CNN-Based CNN-Based Transformer-BasedFigure4: Regularization ğ‘˜-volatilityforahostofvisionmodels. Weapplytwoadversarialattacks
FGSM [24] (top row) and SI-NI-FGSM [ 41] (bottom row) with various attack strengths. Attack
strength is measured in terms of maximum ğ“2-norm of the applied perturbation to the image.
smaller variance, applying rejection sampling to deal with the potential sparsity of the representation
space discussed in Section 4.4, or adapting the regularization weight based on some bootstrapped
confidenceinterval(iftheestimatehashighervariancethendecreaseweightonregularizationandvice
versa). However, we see that even with this naive algorithm we achieve improvements in robustness
as well as training speed.
G.3 Computer Vision Results
Inadditiontoregulatinglanguagemodels,wealsodemonstratethat KCREGiseffectiveforvision
tasks. This provides empirical support for the equivalences we proved in Section 4.5. The exact
same method of ğ‘˜-volatility estimation and loss augmentation is applied. We finetune threemodels
ResNet50 [ 28], MobileNetV2 [ 61], and ViT16 [ 17] on the MNIST dataset both with and without our
regularization algorithm. We then apply two different adversarial attacks: FGSM [ 24] and SI-NI-
FGSM [41]. We find that in both cases, regularization ğ‘˜-volatility improves/stabilizes robustness
across attack strengths (see Fig. 4).
G.4 Ablation Studies
Herein,wepresentablationstudiesforthecrucialhyperparametersinourregularizationalgorithm
(across the natural language tasks that we explored in the main text), Alg. 1( KCREG):ğœ†which is the
weight we assign the knowledge continuity regulation loss and (ğ›¼,ğ›½)which determines the sampling
behavior of the index of the hidden representation space.
Ablation Study of ğœ†(Fig. 5(right)). The weight given to the regularizer ( ğœ†) is ablated over, with the
resultsshowninFig.5. Foranypositive ğœ†,thereisanimmediatelargeimprovementinadversarial
robustness. Next, as ğœ†is systematically increased by factors of 10, we do not see a significant change
in the accuracy (not under attack). This corroborates Theorem. 4.3, as it demonstrates that regulating
knowledge discontinuities (no matter how strongly) is not at odds with minimizing the empirical risk
ofourmodel. Ontheotherhand,wealsodonotseeasignificantincreaseinadversarialrobustness
asğœ†increases. Thismayimplythatwehavereachedthethresholdofadversarialrobustnessunder
TextFooler [ 35]. Specifically, the adversarial attacks generated by TextFooler may not be valid in
thattheyhaveflippedtheground-truthlabel. Therefore,webelievethatagood ğœ†forthisparticular
application should lie somewhere between 0and1Ã—10âˆ’4.
290.00.20.40.60.8Attack Strength0.000.050.100.150.200.25Attack Success Rate0104103102101100Regularization Strength65707580859095Test AccuracyIMDBIMDB+TextFooler1011e-11e-21e-31e-40Figure 5: Ablation over the strength of regularization and its effect on the attack strength-attack
successratecurves(left). Ablationovertheregularizationstrength(forfixedattackstrength=0.3)
and its effect on test accuracy (right). We see that moderate regularization significantly improves
robustnessacrossallattackstrengths. Thisimprovementdoesnotcomeattheexpenseoftestaccuracy.
The attack-strength is measured using the minimum angular similarity between the perturbed and
original text. Both ablations are done with respect to GPT2 on the IMDB [ 48] dataset with respect to
the TextFooler attack [35].
AblationStudyofAdversarialAttackStrength(Fig.5(left)). Foreveryvalueof ğœ†,wealsovary
the strength of the adversarial attack. The adversarial attack strength is measured through the angular
similarity of the embeddings between the original text and the perturbed text. Intuitively, if this
constraint is loosened the adversary is allowed to find text that is semantically very different and vice
versa. We see that moderate ğ‘˜-volatility regulation achieves the best adversarial robustness across all
attack strengths.
Ablation Study of (ğ›¼,ğ›½)In this subsection, we brieflydiscuss how the ğ›¼,ğ›½hyperparameters which
determine the shape of the Beta distribution in Alg. 1( KCREG) affect the final performance and
robustnessofourmodelontheIMDBdataset. RecallthattheshapeoftheBetadistributiondetermines
the index of the hidden layers we are using the compute the knowledge continuity. Thus, they are
crucial in determining the behavior of our regularizer.
We finetune {BERT, T5, GPT2} models on the IMDB dataset with the hyperparameters described in
the next subsection. The results are displayed in Table 3. Across all models we observe a decrease in
robustness for ğ›¼=1,ğ›½=2. These values correspond to a right-skewed distribution which places
high sampling probability on the earlier (closer to the input) hidden layers. Intuitively, perturbations
in the early layers should correspond to proportional textual perturbations in the input text. Pure
textualperturbationswithrespecttosomemetricliketheLevenshteindistanceshouldbeonlyloosely
ifnotcompletely(un)correlatedwiththeactuallabelsoftheseinputs. Therefore,enforcingknowledge
continuitywithrespecttothismetricshouldnotseeincreaserobustness. Moreover,wealsoobservea
largerdecreaseinaccuracy(notunderattack)withthesameparameters. Thissuggeststhatmaintaining
this sort of knowledge continuity in the earlier layers is harder to converge on and there may be a
â€œpush-and-pullâ€ behavior between optimizing knowledge continuity and accuracy (not under attack).
Surprisingly, we observe no significant difference between the other ğ›¼,ğ›½values shown in the table.
We did not formally benchmark other configurations of ğ›¼,ğ›½such as increasing their magnitude to
imposeasharperdistribution. Anecdotally,duringtraining,wenoticedthatusingthesesharper
distributionsbothsignificantlyslowedthemodelâ€™sconvergenceanddecreasedthemodelâ€™saccuracy
(notunderattack). Itcouldbethatthoughknowledgecontinuityitselfisalocalpropertyandthe
enforcement ofthis localproperty requireschangeon aglobal scale. Inother words, onecannot
simplyreducetheknowledgediscontinuitiesoruniformlyconvergewithrespecttoonelayerwithout
participationfromotherlayers. Theextenttowhichotherlayersareinvolvedintheregularizationof
a specific one is an interesting question that we leave for future research.
30Model IMDB IMDBTF
BERTBASE 93.6 47.9
BERTBASE+Reg(2,1)94.8 75.1
BERTBASE+Reg(2,2)89.2 74.1
BERTBASE+Reg(1,2)87.0 68.2
GPT2 93.6 63.9
GPT2+Reg(2,1) 94.6 85.0
GPT2+Reg(2,2) 94.9 87.8
GPT2+Reg(1,2) 93.1 84.9
T5BASE 93.7 53.9
T5BASE+Reg(2,1) 95.0 88.9
T5BASE+Reg(2,2) 94.9 89.3
T5BASE+Reg(1,2) 94.6 88.1
Table3: Wetrainfinetune{BERT,T5,GPT2}usingknowledgecontinuityregularization,asdescribed
in Alg. 1( KCREG). We varied the ğ›¼,ğ›½hyperparameters for the Beta distribution as to determine the
effectoftheseparametersonmodelperformanceandrobustness. Therowsofthetablearelabeled
with the format: Model+Reg(ğ›¼,ğ›½). The bolded entries of the table correspond to the best performing
metrics out of the knowledge continuity regulated models.
Hyperparameter Value
Optimizer Adam
Adamğ›½1 0.9
Adamğ›½2 0.999
Adamğœ– 1Ã—10âˆ’8
Max Gradient Norm 1.0
Learning Rate Scheduler Linear
Epochs 20
Batch Size 32
Learning Rate 5Ã—10âˆ’5
Weight Decay 1Ã—10âˆ’9
Table4: Traininghyperparametersandoptimizerconfigurationsforfinetuningmodels{BERT,GPT2,
T5} on IMDB without any form of regularization or adversarial training.
G.5 Training Details
In this section, we describe in detail the training objectives, procedures, algorithms, and hyperparme-
ters that we used in the main text and further experiments done in the appendix.
Brute-Force Adversarial Training. For all models undergoing adversarial training, we first finetune
the model against the training set. Then, attack it using the TextFooler [ 35] algorithm with examples
from the training set. After the attacks are concluded, we then incorporate the text of successful
adversarial attacks back into the training set and proceed to finetune again. This procedure iteratively
continues. Forthesakeofcomputationalefficiency,forallmodelsweappliedthisprocedureonce.
Theparametersweareusingduringtheadversarialattackisthesamehyperparametersweactually
use at test-time. Specifically, we impose a query budget of 300 queries.
Plain Finetuning on IMDB. The IMDB dataset consist of 50,000 examples with 25,000 for training
and 25,000 for testing. We split the test set 40%-60% to create a validation and test set of 10,000
and 15,000 examples, respectively. Examples were sampled uniformly at random during the splitting
process. Sinceadversarialattackswerecostly,weuniformlysubsampled5,000examplesfromthis
15,000 to benchmark robustness in the experiments related to the regularizer. However, for the
experimentsestimatingtheknowledgevulnerabilityscore,weperformedadversarialattacksonall
15,000datapointsinthetestset. Wefoundnosignificantdifferencebetweenrobustnessestimationon
this 5,000 subsample versus and the entire 15,000 dataset.
We train all models using the hyperparameter and optimizer configurations shown in Table 4.
31Knowledge Discontinuity Regulation on IMDB. To enforce the knowledge discontinuity on IMDB,
weuseaconstant ğœ†=1Ã—10âˆ’2forallmodels. AsshowninTable3, wevaried ğ›¼,ğ›½âˆˆ{1,2}Ã—{1,2}
and displayed the best models in terms of robustness in Table. 1 in the main text. We train all models
for 50 epochs. Other than that all the other hyperparameters and optimizer configurations are the
same as regular finetuning (see Table 4).
KnowledgeDiscontinuityRegulationonANLI. OptimizingovertheANLIdatasetwassignificantly
harderthanonIMDB.Asaresult,foreachmodelclass{BERT,GPT2,T5}weperformedaquick
hyperparametersearchover ğœ†(1Ã—10âˆ’4),thelearningrate( 5Ã—10âˆ’5),andweightdecay( 1Ã—10âˆ’9)
fixingtheparameterizationoftheBetadistributiontobethebestvaluesontheIMDBdataset. That
is, for T5:ğ›¼=2,ğ›½=1; BERT-Base-Uncased: ğ›¼=2,ğ›½=1; GPT2:ğ›¼=2,ğ›½=2.
ALUM on IMDB and ANLI. We train all ALUM models for 50 epochs (the same as knowledge
discontinuity regularized models). For hyperpararmeters specific to the ALUM algorithm we choose
all of the same ones as its authors, [ 43], with the exception of ğ›¼(analogous to the ğœ†in our algorithm,
essentiallytheweightputonthevirtualadversarialtraininglossterm). Theauthorsoftheoriginal
paper choose ğ›¼=10. We, however, found that this applied to finetuning does not converge at all.
Thus, with a rough grid search in the parameter space we found ğ›¼=1Ã—10âˆ’3to be the best with
respect to both performance and robustness.
We keep the same hyperparameters on ANLI, however, we impose early stopping during the training
process. That is, we choose the best model with respect to its performance on the devset.
H Certifying Robustness at Test-Time
Herein, we present a certification algorithm using Thm. 4.1 and our Monte-Carlo estimate of ğ‘˜-
volatility1( ESTKVOL). Ouralgorithm(showninAlg.2)isbasedontheworkof[ 12]. Weupperbound
theğ‘˜-volatility by bootstrapping a 1âˆ’ğ›¼confidence interval. Then, directly apply Thm. 4.1 using
the 0-1 loss function. Thus, Cor. H.1 follows. We emphasize here that this certification algorithm
may not be directlyinformative, especially in the discrete/non-metrizable setting, unless we have an
inversemap fromtherepresentationspaceback totheinputspace. Thisis discussedfurtherin[ 82].
Nonetheless,itcanbeusedasamethodtoverifywhetherornotcertaininterventiontechniquesare
successful before deploying them in the wild.
Corollary H.1. Letğ´={(ğ‘¥ğ‘–,ğ‘¦ğ‘–)ğ‘›
ğ‘–=1}andğ´â€²={(ğ‘¥â€²,ğ‘¦â€²)âˆˆî‰„Ã—î‰…âˆ¶ğ”¼(ğ‘¥,ğ‘¦)âˆ¼îˆ°î‰„,î‰…
(ğ‘¥,ğ‘¦)âˆˆğ´Î”îˆ¸(ğ‘¥,ğ‘¦)
ğ‘“(ğ‘¥â€²,ğ‘¦â€²)>ğœ‚}.
Then, with probability 1âˆ’ğ›¼, the output of Alg. 2 bounds â„™[ğ´â€²|ğ‘‘ğ‘—(ğ‘“ğ‘—(ğ‘¥),ğ‘“ğ‘—(ğ´))]where îˆ¸is the 0-1
loss.
Algorithm 2 Certifying robustness of a metric decomposable function ğ‘“with respect to one hidden
representation using Alg. 1(E STKVOL) and Thm. 4.1.
procedure CERTIFY(ğ‘“,{(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘›
ğ‘–=1,ğ‘˜,ğ‘—,ğ›¼,ğ›¿,ğœ‚ )
Letîˆ¸be the 0-1 loss function
ğœ–ğ‘ˆâ†UPPERCONFBOUND(ğ‘“,îˆ¸,{(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘›
ğ‘–=1,ğ‘˜,ğ‘—,ğ›¼)
ğµâ†max1â‰¤ğ‘,ğ‘â‰¤ğ‘›ğ‘‘ğ‘—(ğ‘“ğ‘—(ğ‘¥ğ‘),ğ‘“ğ‘—(ğ‘¥ğ‘))
ğ‘‰â†ğœ‚(
1âˆ’exp(
âˆ’2âˆ•ğµ2(
ğ›¿âˆ’ğµâˆš
1
2log2ğ‘›)2))
returnCLIP(1âˆ’ğœ–ğ‘ˆğ›¿âˆ•ğ‘‰,0,1)
procedure UPPERCONFBOUND(ğ‘“,îˆ¸,{(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘›
ğ‘–=1,ğ‘˜,ğ‘—,ğ›¼)
ğ‘ˆâ†ğŸğ‘˜
forğ‘–â†1â€¦ğ‘˜do
ğ‘†â†sample w/ replacement ğ‘›points from{(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘›
ğ‘–=1
ğ‘ˆğ‘–â†ESTKVOL(ğ‘†,îˆ¸,ğ‘“,ğ‘—)
return1
ğ‘˜âˆ‘ğ‘˜
ğ“=1ğ‘ˆğ‘˜+Î¦âˆ’1(ğ›¼)std(ğ‘ˆ)âˆ•âˆš
ğ‘˜
Alongtheselines,weapplyourcertificationalgorithmtoourregularizedmodelstoverifythatthe
certified robustness has indeed improved. These results are shown in Fig. 6.
32Change in Absolute Accuracy
0.00.20.40.60.81.0
0.0
11.2
22.4
33.6
44.8
56.0
67.2
0.0
0.2
0.4
0.6
0.8
1.0
Base
0.0
11.2
22.4
33.6
44.8
56.0
67.2
KCReg (Ours)Certified Robustness
Perturbation DistanceFigure 6: Certification of robustness for GPT2, layer=6. We apply Alg. 2 to certify robustness of the
model before andafter regularization with Alg.1( KDREG). Each line correspondsto the change in
absoluteaccuracyforasetofexamplestobeconsiderednon-robust. The ğ‘¦-axiscorrespondstothe
certified probability measure of the set of non-robust examples under this criterion and the ğ‘¥-axis
corresponds to the maximum perturbation distance in the representation space.
I Broader Impacts
Thiscontributionisconcernedwithrobustdeeplearningmodels. Asdeeplearningbecomesubiquitous
astheprimarymethodforcreatingartificialintelligence,theirapplicationsinincreasinglycriticalareas
to the lay and corporations alike demand not only both high inferential accuracy and confidence but
also safety andtrustworthiness guarantees. Robustnessaddresses thislatter point. Morespecifically,
our contribution unifies separate robustness efforts from continuous and discrete domains.
J Reproducibility
All of our experiments were conducted on four NVIDIA RTX A6000 GPUs as well as four NVIDIA
Quadro RTX 6000 GPUs. The rest of our codebase including implementations of the algorithms and
figures described in the manuscript can be found at https://github.com/alansun17904/kc .
K Limitations
Thecertificationguaranteesofourdefinitionknowledgecontinuityisaprobabilisticone. Specifically,
thisrandomnessisoverthedatadistribution. However,thisdoesnotprotectagainstout-of-distribution
attacksthatplaguelargelanguagemodelssuchas[ 72,91]. Moreworkisneededtoyielddeterministic
resultsthatdonotbecomevacuousindiscretesettings. AsmentionedinSection4.4,ourexpressiveness
boundsonlyapplyunderlittlerestrictionstothemetricdecompositionsoftheestimator ğ‘“. Though
we see some empirical verification for this in Appendix G, it remains unclear whether or not we can
tighten these bounds.
33L NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the paperâ€™s
contributions and scope?
Answer: [Yes]
Justification:
Guidelines:
â€¢TheanswerNAmeansthattheabstractandintroductiondonotincludetheclaimsmadeinthe
paper.
â€¢Theabstractand/orintroductionshouldclearlystatetheclaimsmade,includingthecontributions
madeinthepaperandimportantassumptionsandlimitations. ANoorNAanswertothisquestion
will not be perceived well by the reviewers.
â€¢Theclaimsmadeshouldmatchtheoreticalandexperimentalresults,andreflecthowmuchthe
results can be expected to generalize to other settings.
â€¢It is fine to includeaspirational goals as motivation as long as itis clear that these goals are not
attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We present a detailed discussion of the limitations in Section K.
Guidelines:
â€¢TheanswerNAmeansthatthepaper hasnolimitationwhilethe answerNomeansthatthepaper
has limitations, but those are not discussed in the paper.
â€¢The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢Thepapershouldpointoutanystrongassumptionsandhowrobusttheresultsaretoviolationsof
these assumptions (e.g., independence assumptions, noiseless settings, model well-specification,
asymptotic approximations only holding locally). The authors should reflect on how these
assumptions might be violated in practice and what the implications would be.
â€¢The authors should reflect on the scope of the claims made, e.g., if the approach was only tested
on a few datasets or with a few runs. In general, empirical results often depend on implicit
assumptions, which should be articulated.
â€¢The authors should reflect on the factors that influence the performance of the approach. For
example, a facial recognition algorithm may perform poorly when image resolution is low or
imagesaretakeninlowlighting. Oraspeech-to-textsystemmightnotbeusedreliablytoprovide
closed captions for online lectures because it fails to handle technical jargon.
â€¢The authors should discuss the computational efficiency of the proposed algorithms and how
they scale with dataset size.
â€¢Ifapplicable,theauthorsshoulddiscusspossiblelimitationsoftheirapproachtoaddressproblems
of privacy and fairness.
â€¢While the authors might fear that complete honesty about limitations might be used by reviewers
as grounds for rejection, a worse outcome might be that reviewers discover limitations that
arenâ€™t acknowledged in the paper. The authors should use their best judgment and recognize
thatindividual actionsinfavor oftransparencyplay animportantrole indevelopingnorms that
preserve the integrity of the community. Reviewers will be specifically instructed to not penalize
honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: Foreachtheoreticalresult,doesthepaperprovidethefullsetofassumptionsandacomplete
(and correct) proof?
Answer: [Yes]
Justification: For all of the theoretical results in the paper, we include all of its assumptions. We
include full proofs of each theoretical resultin Appendices A, B,C, G. To thebest of our knowledge,
the proofs are correct.
Guidelines:
â€¢The answer NA means that the paper does not include theoretical results.
â€¢All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
34â€¢All assumptions should be clearly stated or referenced in the statement of any theorems.
â€¢Theproofscaneitherappearinthemainpaperorthesupplementalmaterial,butiftheyappearin
the supplemental material, the authors are encouraged to provide a short proof sketch to provide
intuition.
â€¢Inversely,anyinformalproofprovidedinthecoreofthepapershouldbecomplementedbyformal
proofs provided in appendix or supplemental material.
â€¢Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Doesthepaperfullydisclosealltheinformationneededtoreproducethemainexperimental
results of the paper to the extent that it affects the main claims and/or conclusions of the paper
(regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We present all of the hyperparameters in the experiments that require training in Ap-
pendix G. Additionally, our compute resources are detailed in Appendix J.
Guidelines:
â€¢The answer NA means that the paper does not include experiments.
â€¢If the paper includes experiments, a No answer to this question will not be perceived well by the
reviewers: Making the paper reproducible is important, regardless of whether the code and data
are provided or not.
â€¢If the contribution is a dataset and/or model, the authors should describe the steps taken to make
their results reproducible or verifiable.
â€¢Dependingonthecontribution,reproducibilitycanbeaccomplishedinvariousways. Forexample,
if the contribution is a novel architecture, describing the architecture fully might suffice, or if the
contributionisaspecificmodelandempiricalevaluation,itmaybenecessarytoeithermakeit
possible for others to replicate the model with the same dataset, or provide access to the model.
In general. releasing code and data is often one good way to accomplish this, but reproducibility
can also be providedvia detailed instructions for how toreplicate the results, access to a hosted
model (e.g., in the case of a large language model), releasing of a model checkpoint, or other
means that are appropriate to the research performed.
â€¢While NeurIPS does not require releasing code, the conference does require all submissions
toprovidesomereasonableavenueforreproducibility,whichmaydependonthenatureofthe
contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how to
reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe the
architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should either be
a way to access this model for reproducing the results or a way to reproduce the model (e.g.,
with an open-source dataset or instructions for how to construct the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case authors are
welcometodescribetheparticularwaytheyprovideforreproducibility. Inthecaseofclosed-
source models, it may be that access to the model is limited in some way (e.g., to registered
users),butitshouldbepossibleforotherresearcherstohavesomepathtoreproducingor
verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instructions to
faithfully reproduce the main experimental results, as described in supplemental material?
Answer: [Yes]
Justification: We attach all of the code used to generate the figures and the experimental results in the
supplementary materials.
Guidelines:
â€¢The answer NA means that paper does not include experiments requiring code.
â€¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/public/
guides/CodeSubmissionPolicy ) for more details.
â€¢While we encourage the release of code and data, we understand that this might not be possible,
so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not including code, unless
this is central to the contribution (e.g., for a new open-source benchmark).
35â€¢The instructions should contain the exact command and environment needed to run to reproduce
theresults. SeetheNeurIPScodeanddatasubmissionguidelines( https://nips.cc/public/
guides/CodeSubmissionPolicy ) for more details.
â€¢The authors should provide instructions on data access and preparation, including how to access
the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢Theauthorsshouldprovidescriptstoreproduceallexperimentalresultsforthenewproposed
method and baselines. If only a subset of experiments are reproducible, they should state which
ones are omitted from the script and why.
â€¢At submission time, to preserve anonymity, the authors should release anonymized versions (if
applicable).
â€¢Providingas muchinformation aspossible insupplementalmaterial (appendedtothe paper)is
recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Doesthepaperspecifyallthetrainingandtestdetails(e.g.,datasplits,hyperparameters,
how they were chosen, type of optimizer, etc.) necessary to understand the results?
Answer: [Yes]
Justification: For the experiments that require training, we discuss in detail the hyperparameters
in Appendix G. Moreover, we also attach the code used to generate all results and figures in the
supplementary materials of the submission.
Guidelines:
â€¢The answer NA means that the paper does not include experiments.
â€¢Theexperimentalsettingshouldbepresentedinthecoreofthepapertoalevelofdetailthatis
necessary to appreciate the results and make sense of them.
â€¢The full details can be provided either with the code, in appendix, or as supplemental material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate informa-
tion about the statistical significance of the experiments?
Answer: [No]
Justification: The experimentsinourpaperserveasa typeofsanitycheckanddemonstratepossible
explorations rather than a benchmark against existing state-of-the-art methods.
Guidelines:
â€¢The answer NA means that the paper does not include experiments.
â€¢Theauthorsshouldanswer"Yes"iftheresultsareaccompaniedbyerrorbars,confidenceintervals,
orstatisticalsignificancetests,atleastfortheexperimentsthatsupportthemainclaimsofthe
paper.
â€¢Thefactors ofvariability thatthe errorbarsare capturingshould beclearly stated(for example,
train/test split, initialization, random drawing of some parameter, or overall run with given
experimental conditions).
â€¢The method for calculating the error bars should be explained (closed form formula, call to a
library function, bootstrap, etc.)
â€¢The assumptions made should be given (e.g., Normally distributed errors).
â€¢Itshouldbeclearwhethertheerrorbaristhestandarddeviationorthestandarderrorofthemean.
â€¢ItisOKtoreport1-sigmaerrorbars,butoneshouldstateit. Theauthorsshouldpreferablyreport
a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is
not verified.
â€¢For asymmetric distributions, the authors should be careful not to show in tables or figures
symmetric error bars that would yield results that are out of range (e.g. negative error rates).
â€¢If error bars are reported in tables or plots, The authors should explain in the text how they were
calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: Foreachexperiment,doesthepaperprovidesufficientinformationonthecomputerresources
(type of compute workers, memory, time of execution) needed to reproduce the experiments?
Answer: [Yes]
Justification: We provide details on the compute resources we use in Appendix J.
Guidelines:
36â€¢The answer NA means that the paper does not include experiments.
â€¢ThepapershouldindicatethetypeofcomputeworkersCPUorGPU,internalcluster,orcloud
provider, including relevant memory and storage.
â€¢Thepapershouldprovidetheamountofcomputerequiredforeachoftheindividualexperimental
runs as well as estimate the total compute.
â€¢The paper should disclose whether the full research project required more compute than the
experimentsreportedinthepaper (e.g., preliminary orfailed experimentsthatdidnâ€™tmakeitinto
the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code
of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: The authors have reviewed the NeurIPS Code of Ethics and to the best of our knowledge
it does conform to this in every respect.
Guidelines:
â€¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢If theauthors answer No, they should explain the specialcircumstances that requirea deviation
from the Code of Ethics.
â€¢The authors should make sure to preserve anonymity (e.g., if there is a special consideration due
to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Doesthepaperdiscussbothpotentialpositivesocietalimpactsandnegativesocietalimpacts
of the work performed?
Answer: [Yes]
Justification: We discuss the broader impacts of the work in Appendix I.
Guidelines:
â€¢The answer NA means that there is no societal impact of the work performed.
â€¢IftheauthorsanswerNAorNo,theyshouldexplainwhytheirworkhasnosocietalimpactor
why the paper does not address societal impact.
â€¢Examples of negative societal impacts include potential malicious or unintended uses (e.g.,
disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deploy-
ment of technologies that could make decisions that unfairly impact specific groups), privacy
considerations, and security considerations.
â€¢The conference expects that many papers will be foundational research and not tied to particular
applications,letalonedeployments. However,ifthereisadirectpathtoanynegativeapplications,
the authors should point it out. For example, it is legitimate to point out that an improvement in
the quality of generative models could be used to generate deepfakes for disinformation. On the
other hand, it is not needed to point out that a generic algorithm for optimizing neural networks
could enable people to train models that generate Deepfakes faster.
â€¢Theauthorsshouldconsiderpossibleharmsthatcouldarisewhen thetechnologyisbeingused
as intended and functioning correctly, harms that could arise when the technology is being used
asintendedbutgivesincorrectresults,andharmsfollowingfrom(intentionalorunintentional)
misuse of the technology.
â€¢Iftherearenegativesocietalimpacts,theauthorscouldalsodiscusspossiblemitigationstrategies
(e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitor-
ing misuse, mechanisms to monitor how a system learns from feedback over time, improving the
efficiency and accessibility of ML).
11.Safeguards
Question: Doesthepaperdescribesafeguardsthathavebeenputinplaceforresponsiblereleaseof
data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or
scraped datasets)?
Answer: [NA]
Justification: Thispaper isconcerned withtraining morerobust deeplearningmodels. Thus, itdoes
not pose such risks.
Guidelines:
â€¢The answer NA means that the paper poses no such risks.
37â€¢Releasedmodelsthat have ahighriskformisuse ordual-useshouldbereleasedwithnecessary
safeguards to allow for controlled use of the model, for example by requiring that users adhere to
usage guidelines or restrictions to access the model or implementing safety filters.
â€¢DatasetsthathavebeenscrapedfromtheInternetcouldposesafetyrisks. Theauthorsshould
describe how they avoided releasing unsafe images.
â€¢We recognize that providing effective safeguards is challenging, and many papers do not require
this, but we encourage authors to take this into account and make a best faith effort.
12.Licenses for existing assets
Question: Arethecreatorsororiginalownersofassets(e.g.,code,data,models),usedinthepaper,
properly credited and are the license and terms of use explicitly mentioned and properly respected?
Answer: [NA]
Justification: The paper does not use existing assets.
Guidelines:
â€¢The answer NA means that the paper does not use existing assets.
â€¢The authors should cite the original paper that produced the code package or dataset.
â€¢The authors should state which version of the asset is used and, if possible, include a URL.
â€¢The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢Forscrapeddatafromaparticularsource(e.g.,website),thecopyrightandtermsofserviceof
that source should be provided.
â€¢If assets are released, the license, copyright information, and terms of use in the package should
beprovided. Forpopulardatasets, paperswithcode.com/datasets hascuratedlicensesfor
some datasets. Their licensing guide can help determine the license of a dataset.
â€¢For existing datasets that are re-packaged, both the original license and the license of the derived
asset (if it has changed) should be provided.
â€¢Ifthisinformationisnotavailableonline,theauthorsareencouragedtoreachouttotheassetâ€™s
creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation provided
alongside the assets?
Answer: [NA]
Justification: We do not introduce any new assets in the paper.
Guidelines:
â€¢The answer NA means that the paper does not release new assets.
â€¢Researchersshouldcommunicatethedetailsofthedataset/code/modelaspartoftheirsubmissions
via structured templates. This includes details about training, license, limitations, etc.
â€¢The paper should discuss whether and how consent was obtained from people whose asset is
used.
â€¢At submission time, remember to anonymize your assets (if applicable). You can either create an
anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper include
the full text of instructions given to participants and screenshots, if applicable, as well as details about
compensation (if any)?
Answer: [NA]
Justification: We do not perform any crowdsourcing experiments nor research with human subjects.
Guidelines:
â€¢TheanswerNAmeansthatthepaperdoesnotinvolvecrowdsourcingnorresearchwithhuman
subjects.
â€¢Includingthisinformationinthesupplementalmaterialisfine,butifthemaincontributionofthe
paperinvolveshumansubjects,thenasmuchdetailaspossibleshouldbeincludedinthemain
paper.
â€¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other
labor should be paid at least the minimum wage in the country of the data collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects
38Question: Doesthepaperdescribepotentialrisksincurredbystudyparticipants,whethersuchrisks
weredisclosedtothesubjects,andwhetherInstitutionalReviewBoard(IRB)approvals(oranequivalent
approval/review based on the requirements of your country or institution) were obtained?
Answer: [NA]
Justification: Wedonotperformanyexperimentsthatinvolvecrowdsourcingnorresearchwithhuman
subjects.
Guidelines:
â€¢TheanswerNAmeansthatthepaperdoesnotinvolvecrowdsourcingnorresearchwithhuman
subjects.
â€¢Depending on the country in which research is conducted, IRB approval (or equivalent) may be
required for any human subjects research. If you obtained IRB approval, you should clearly state
this in the paper.
â€¢Werecognizethattheproceduresforthismayvarysignificantlybetweeninstitutionsandlocations,
and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their
institution.
â€¢Forinitialsubmissions,donotincludeanyinformationthatwouldbreakanonymity(ifapplicable),
such as the institution conducting the review.
39