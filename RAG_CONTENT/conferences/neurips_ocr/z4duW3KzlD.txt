Gated Inference Network: Inference and Learning
State-Space Models
Hamidreza Hashempoor
Seoul National University
Department of Electrical and Computer Engineering
hamidreza.hashemp@snu.ac.kr
Wan Choi
Seoul National University
Department of Electrical and Computer Engineering
wanchoi@snu.ac.kr
Abstract
This paper advances temporal reasoning within dynamically changing high-
dimensional noisy observations, focusing on a latent space that characterizes
the nonlinear dynamics of objects in their environment. We introduce the Gated
Inference Network (GIN), an efficient approximate Bayesian inference algorithm
for state space models (SSMs) with nonlinear state transitions and emissions. GIN
disentangles two latent representations: one representing the object derived from a
nonlinear mapping model, and another representing the latent state describing its
dynamics. This disentanglement enables direct state estimation and missing data
imputation as the world evolves. To infer the latent state, we utilize a deep extended
Kalman filter (EKF) approach that integrates a novel compact RNN structure to
compute both the Kalman Gain (KG) and smoothing gain (SG), completing the
data flow. This design results in a computational cost per step that is linearly
faster than EKF but introduces issues such as the exploding gradient problem.
To mitigate the exploding gradients caused by the compact RNN structure in our
model, we propose a specialized learning method that ensures stable training and
inference. The model is then trained end-to-end on videos depicting a diverse range
of simulated and real-world physical systems, and outperforms its counterparts
â€”RNNs, autoregressive models, and variational approachesâ€” in state estimation
and missing data imputation tasks.
1 Introduction
A state-space model is a type of graphical model that effectively represents noise-afflicted data
[1]. Typically, the objective is to conduct inference, which involves obtaining accurate estimates of
the posterior distribution of latent states or noise-free measurements. In videos, inferring the state
space presents a complex challenge owing to the high dimensionality of noisy observations, which
only offer partial information about the states. Previous methods have proposed various inference
approaches such as sampling [ 2], variational inference [ 3], or belief propagation [ 4]. Within the
framework of a hidden Markov process, classical methods like the celebrated Kalman filter (KF) and
smoother [ 5,6], along with their extensions like EKF and UKF, [ 7,8] have been employed to address
the posterior inference problem. However, the reliance of these methods on accurate knowledge of
the underlying dynamics, coupled with computationally intensive matrix inversions, poses challenges
in scalability to high-dimensional latent spaces.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).To address these issues, this paper distinguishes between the sensory observation and its dynamics by
disentangling two representations: a transformed observation wtobtained by mapping the original
sensory observation otthrough a nonlinear function modeled by neural networks, and the latent
state space xtdescribing the dynamics of wtat time step t. To infer high dimensional state space
(dynamics) xt, we introduce filtering and smoothing techniques that build upon classical EKF
updates but incorporate flexible function estimators without relying on a constrained graphical model.
We model temporal dynamics with a linearized Gaussian SSM, which is adapted to accommodate
complex dynamics. To address non-linearity and the multiplicity of dynamics, we learn multiple
transition and emission matrices, each modeling a unique dynamical scenario. Then, the weight
of each matrix during inference is determined by the past state xtâˆ’1through a neural network. To
prevent mode collapse and ensure the systemâ€™s ability to capture diverse dynamics, we introduce a
loss term proportional to the KL divergence of the transition matrices during training. This design
enables our model to handle various state scenarios, similar to approaches found in the switching
linear dynamics systems (SLDS) literature [ 9]. Unlike EKF, which requires precise characterization
and modeling of the underlying dynamics, we operate under the assumption that noise statistics and
the underlying physical dynamics of SSM are entirely unknown.
The main drawback of the EKF is that it takes O(n3)time per step, because we need to invert the
posterior covariance matrix with size of n. This makes the method slow to use. Moreover, we identify
the computation of the KG and SG in the (extended) KF as critical components that rely on noise
statistics and domain knowledge. In this paper, we efficiently model KG and SG using GRU cells,
bypassing the need for matrix inversion in the KF flow. Consequently, the GIN algorithm achieves
a time complexity of O(Î²2n2)per step, making it linearly faster than EKF. To capitalize on the
sparsity of the covariance matrix, we employ a convolutional approach that further reduces the size of
nrelative to Î², where 0< Î² < 1. However, the nonlinear structure of GRU cells can lead to gradient
explosion [ 10], a phenomenon that occurs when the dynamics undergo significant changes as GRU
parameters traverse bifurcation points [ 11] during the learning process. To address this issue, we
propose a learning method based on an analysis of GRU cell dynamics. This method aims to prevent
parameter values from reaching bifurcation points by stabilizing the dynamics of GRU cells, thereby
addressing the issue of gradient explosion.
To summarize, our primary contribution is a novel algorithm designed for the recursive inference of
SSMs with arbitrary nonlinear (and possibly non-Gaussian) emission and transition models, with
high-dimensional noisy stimuli observation. This algorithm utilizes a linearized Gaussian dynamics
approach, with parameter estimation conducted through neural networks. This means that we can
apply the recursive Bayesian updates, akin to the Kalman filter and Kalman smoother. We introduce a
likelihood for inferring the states (dynamics) and another likelihood for inferring the high-dimensional
images (of video). The objective is maximized in a supervised manner, depending on the task. We
propose learning schemes for GRU cells to address issues related to gradient explosion and instability.
Finally, we introduce a loss term proportional to the KL divergence of the learned transition matrices
to prevent the system from becoming stuck in mode collapse.
To substantiate our claims, we conduct five experiments. First, we simulate a nonlinear dynamic
system using the pendulum sequence video, a common benchmark in this literature, to demonstrate
our modelâ€™s ability to infer both dynamics and images. Second, we introduce a more challenging
experiment of a simulated nonlinear double pendulum, where the video sequence is heavily distorted
with noise, showcasing our modelâ€™s resilience of dynamics estimation and image imputation to noisy
observations. Third, we present a switching dynamics irregular bouncing ball experiment to illustrate
our modelâ€™s ability to handle multiple dynamic scenarios. Fourth, we perform visual odometry using
the KITTI dataset, demonstrating the practical applicability of our methods in real-world scenarios.
Finally, we assess the effectiveness of our proposed gradient explosion handling scheme by evaluating
convergence across various simulation seeds.
2 Related Works
EKF and UKF represent early extensions of the original Kalman filter, allowing for nonlinear
transitions and emissions. These methods, categorized as model-based (MB) algorithms, rely on
precise knowledge and modeling of the underlying dynamics within a fully characterized SSM.
Consequently, the performance of these MB methods is heavily contingent on the accuracy of domain
knowledge and model assumptions. Recent approaches, such as BackpropKF [ 12] and SIN [ 13],
perform EKF in the latent state using deep encoders for feature extraction. However, they face similar
2Figure 1: Generated sequences from GIN in the irregular polygon environments. The videos are
shown as single images, with color intensity representing the incremental sequence index.
limitations as EKF, including computational complexity and scalability. To address these issues, a
common approach involves considering a diagonal covariance matrix in the KF flow as in [ 14] and
[15]. However, we aim to find a richer approximation to the posterior.
A significant body of work, including Variational Auto-Encoders (V AE) [ 3], Embed to Control
(E2C) [ 16], and Importance Weighted V AE (IWV AE) [ 17], integrates deep learning with variational
inference (VI), but lacks memory cells and recurrent structures for handling imputation tasks. To
address this, EM-based VI approaches like Structure V AE (SV AE) [ 18], Kalman V AE (KV AE) [ 19],
Disentangled V AE (DV AE) [ 20], Extended KV AE (EKV AE) [ 21], Robust V AE [ 22], and Markovian
V AE (MV AE) [ 23] use original KF equations for filtering and smoothing. However, they cannot
directly optimize states (dynamics), as noted in RKN [ 24] and CRU [ 25]. Classical memory networks
like LSTMs [ 26], GRUs [ 27], and simple RNNs [ 28] infer latent states but fail to provide insights
into uncertainties and dynamics.
LatentNet [ 29], KalmanNet [ 30] and SSI-SSM [ 31] utilize GRU in their structures for state updates,
similar to the parameterization used in the GIN. However, these models typically necessitate access
to complete or partial dynamics information, i.e. they are MB, and their reliance on vanilla GRU
cells can cause instability of the SSM. Liu et al. [ 32] proposes a disentanglement model for audio
data, which shares similarities with the GIN. However, their parameterization and objectives differ
from those of the GIN, and they do not utilize compact RNNs in their inference structure.
We cover the most relevant works in this section. A more detailed discussion, including a comprehen-
sive comparison of recent related works like System Identification (SI) with details of EM algorithm,
auto-regressive (AR) and SLDS models, is provided in Appendix A.8.3 and Table 7. This builds upon
the findings of the RKN with additional complements. We also conduct an empirical complexity
analysis in appendix A.8.2, to evaluate the computational efficiency of our method compared to the
discussed approaches. This analysis involved measuring the execution time per iteration using a clock
on the wall as the benchmark.
3 Background
Linear Gaussian state space models. Linear Gaussian state space models (LGSSMs) are
commonly employed to model vectors of observed time series, denoted as w= [w1, ...,wT].
LGSSMs excel in filtering and smoothing tasks. They model the first-order Markov process on the
state space x= [x1, ...,xT], which may also incorporate external control inputs u= [u1, ...,uT]
under the multivariate normality assumption of the state:
pÎ³t(xt|xtâˆ’1,ut) =N(xt;Ftxtâˆ’1+Btut,Qt), p Î³t(wt|xt) =N(wt;Htxt,Rt). (1)
Î³trepresents the parameters of the system at time t, encapsulating information from matrices
Ft,Bt,Ht,QtandRt, which correspond to the state transition, control, emission, process noise
covariance, and observation noise covariance, respectively. At each time step, the transition and
emission procedures are subject to distortion caused by process noise and observation noise, following
distributions of N(0,Qt)andN(0,Rt), respectively.
Filtering and smoothing algorithms. The goal of filtering is to infer the posterior dis-
tribution pÎ³1:t(xt|w1:t,u1:t), while, the smoothing aims to infer the smoothing distribution
pÎ³1:T(xt|w1:T,u1:T)given the whole observations. Without loss of generality, we drop the in-
put variable uin the rest of paper, while one can condition all of the distributions on the input
variable in the case of its existence. Considering the prior state parameterization pÎ³1:t(xt|w1:tâˆ’1) =
N(Âµt|tâˆ’1,Î£t|tâˆ’1)and relying on [33], the filtering and smoothing parameterizations are as:
3ð‘žð‘¡âˆ’1
xð‘¡âˆ’1
wð‘¡âˆ’1ð‘žð‘¡
xð‘¡
wð‘¡ð‘žð‘¡+1
xð‘¡+1
wð‘¡+1â€¦
â€¦
â€¦â€¦
â€¦
â€¦
oð‘¡âˆ’1sð‘¡âˆ’1 oð‘¡ sð‘¡oð‘¡+1sð‘¡+1Figure 2: Graphical model. Dashed nodes are
task dependent output.
ð‘’(.) Transition Block ð‘‘(.)ð’1:ð‘‡ (ð’˜1:ð‘‡,ð’“1:ð‘‡)(ð’™ðŸ:ð‘‡|ð’˜1:ð‘‡) {ð‘ 1:ð‘‡,ð‘œ1:ð‘‡}Figure 3: The GIN as a HW model for system
identification. By appropriate structure selection
fore(.)andd(.), the GIN can handle high di-
mensional observations. The relation between
the internal variables, wtandxt, is simulated by
the transition block.
pÎ³1:t(xt|w1:t) =N
Âµt|tâˆ’1+Kt[wtâˆ’HtÂµt|tâˆ’1],Î£t|tâˆ’1âˆ’KtSfKT
t
=N 
Âµt|t,Î£t|t
(2)
pÎ³1:T(xt|w1:T) =N
Âµt|t+Jt[Âµt+1|Tâˆ’Ft+1Âµt|t],Î£t|t+JtSsJT
t
=N(Âµt|T,Î£t|T)(3)
Kt=Î£t|tâˆ’1HT
t.
HtÎ£t|tâˆ’1HT
t+Rtâˆ’1,Jt=Î£t|tFT
t+1Î£âˆ’1
t+1|t(4)
withSf= [HtÎ£t|tâˆ’1HT
t+Rt]andSs=
Î£t+1|Tâˆ’Î£t+1|t
. In (4), KtandJtare KG and SG,
respectively. See appendix A.1 for a full derivation of filtering-smoothing distributions.
4 Gated Inference Network
The background section defines key elements for the GIN: original observations o1:T, task-dependent
output which can be either the original denoised-imputed observations o1:Tor physical systemâ€™s
states s1:T, transferred observations w1:TâˆˆRmÃ—T, latent states (dynamics) x1:TâˆˆRnÃ—T, noise
covariance of transferred observations R1:Twith diagonals r1:TâˆˆRmÃ—T, noise covariance of states
process Q1:Twith diagonals q1:TâˆˆRnÃ—T, and the parameters of the SSM Î³1:T. We consider
the dimensions of the transferred observation and state at each time step to be mandn, respec-
tively. The states evolve through transition distribution pÎ³1:T(x1:T) =p(x1)QT
t=2pÎ³t(xt|xtâˆ’1).
Eachwtis assumed to be drawn from noisy emission probability pÎ³t(wt|xt), then the gen-
erative process is assumed to factorize as pÎ³1:T(x1:T,w1:T) = pÎ³1:T(x1:T)QT
t=1pÎ³t(wt|xt).
This factorisation imposes emission conditional independence like wtâŠ¥ âŠ¥(wâˆ’t,xâˆ’t)|xt, where
(wâˆ’t,xâˆ’t) = (w(1:tâˆ’1,t+1:T),x(1:tâˆ’1,t+1:T)). Common models that assume conditional indepen-
dence include linear dynamical systems, hidden Markov models, but also nonlinear SSMs with
higher-order Markov chains in latent space. Graphical model of the GIN is in figure 2, where output
(one of colored nodes) is generated, contingent upon the task. In all of our scenarios, the parameters
of the SSM, Î³1:T, are completely unknown.
From SI perspective, the GIN operates similarly to a Hammerstein-Wiener (HW) model [ 34], employ-
ing non-linear transfer functions e(.)andd(.)(Figure 3). Leveraging encoder-decoder structures for
e(.)andd(.), the GIN conducts the transfer between original sensory observations o1:Tand lower-
dimensional representations w1:Tand task dependent output. The transition block in Figure 3 evolves
states using the proposed deep EKF approach, efficiently approximating filtering-smoothing distribu-
tions while ensuring system stability with the imposed constraint. Further details and formulations
are provided in the inference section. The transition block depicted in Figure 4.
5 Parameterization and Inference
Given original observations o1:Tand transferred observations w1:T, our aim is to infer
the latent states x1:T. To accomplish this, we seek to infer the marginal distributions
4Dynamic NetFilteringxtâˆ’1|w1:ð‘¡âˆ’1
à· Fð‘¡
à·¡Hð‘¡
Smoothingxt|w1:ð‘¡ wð‘¡
xt|w1:ð‘‡ xtâˆ’1|w1:ð‘‡Dynamic NetFilteringxt|w1:ð‘¡
à· Fð‘¡+1
à·¡Hð‘¡+1
Smoothingxt+1|w1:ð‘¡+1 wð‘¡+1
xt+1|w1:ð‘‡ xt|w1:ð‘‡
Dynamic NetFilteringxtâˆ’2|w1:ð‘¡âˆ’2
à· Fð‘¡âˆ’1
à·¡Hð‘¡âˆ’1
Smoothingxtâˆ’1|w1:ð‘¡âˆ’1wð‘¡âˆ’1
xtâˆ’1|w1:ð‘‡ xtâˆ’2|w1:ð‘‡â€¦ â€¦Figure 4: Transition block of figure 3 in details. In each time step, the last posterior xtâˆ’1|w1:tâˆ’1is
fed to the Dynamic Net to compute Î³t. In the filtering steps, by using the last posterior xtâˆ’1|w1:tâˆ’1
and the observation wt, the next posterior xt|w1:tis obtained. Having posterior xt|w1:tand the next
smoothing state xt+1|w1:T, applying smoothing for the current state is feasible so that the smoothing
statext|w1:Tis obtained.
pÎ³1:t(xt|w1:t)for the online inference approach (filtering) and pÎ³1:T(xt|w1:T)for the full in-
ference approach (smoothing). We introduce an advantageous prediction parameterization as
pÎ³t(xt|xtâˆ’1,w1:tâˆ’1) =N(Ftxtâˆ’1,Qt), where xtâˆ’1is sampled from the last filtering distribu-
tion, pÎ³1:tâˆ’1(xtâˆ’1|w1:tâˆ’1). Then, we obtain the prior distribution at time t,pÎ³1:t(xt|w1:tâˆ’1) =
N(FtÂµtâˆ’1|tâˆ’1,FtÎ£tâˆ’1|tâˆ’1FT
t+Qt) =N(Âµt|tâˆ’1,Î£t|tâˆ’1), by marginalizing out xtâˆ’1fromR
pÎ³t(xt|xtâˆ’1,w1:tâˆ’1)pÎ³1:tâˆ’1(xtâˆ’1|w1:tâˆ’1)dxtâˆ’1integration. The Gaussianity of pÎ³1:t(xt|w1:tâˆ’1)
results from the Gaussianity of prediction parameterization. After obtaining pÎ³1:t(xt|w1:tâˆ’1)and
observing wt, it is feasible to derive the filtering parameterization using equation (2). Once all
transferred observations w1:Tare available, backward induction can be employed to propagate to
previous states using the chain rule. This procedure, known as smoothing, is parameterized with (3).
These parameterizations provide valuable insights into two key aspects: 1) appropriately modeling
Î³using neural networks, and 2) illustrating a tractable method to parameterize KG and SG and
construct distributions approximations. These approximations serve the basis for constructing output.
Learning Î³.To handle multiple dynamic scenarios, we learn Ksets of state transition and emission
matrices Ë‡FkandË‡Hk, each representing a distinct dynamic status. These matrices are combined with
state-dependent coefficients Î±k(xtâˆ’1) as :
Ë†Ft=KX
k=1Î±k(xtâˆ’1)Ë‡Fk,Ë†Ht=KX
k=1Î±k(xtâˆ’1)Ë‡Hk. (5)
We model Î±k(xtâˆ’1)with a Kdimension softmax output neural network called the Dynamic Net . It
takes the last filtering state xtâˆ’1as input, containing the systemâ€™s history with lower noise distortion
than the transferred observations wtâˆ’1. This choice enhances noise robustness, demonstrated in our
experiments with time-correlated noise (See Appendix A.6).
In the graphical model shown in Figure 2, we observe two paths for belief propagation from xtâˆ’1to
xt. The first path, xtâˆ’1â†’xt, linked with Ë†Ft. The second path involves an intermediate variable
qtâˆ¼ N (0,Qt):xtâˆ’1â†’qtâ†’xt. Since learned Ë†Fttransfers information from xtâˆ’1toxt, we
argue that it can capture effects similar to those of Qt, as both are intended to convey message
between xtâˆ’1andxt[1]. By incorporating Ë†Ftfrom equation (5) into the prior state distribution
described earlier as pÎ³1:t(xt|w1:tâˆ’1) =N(FtÂµtâˆ’1|tâˆ’1,FtÎ£tâˆ’1|tâˆ’1FT
t+Qt), we can neglect the
Qtterm in the covariance, as its influence is accounted for by the learned Ë†Ft. There are two other
meaningful parameterizations for the process noise matrix. First involves direct parameterization
byxtâˆ’1using a neural network. Second approach is to parameterize it recursively using xtâˆ’1and
qtâˆ’1, resulting in a new graphical model with an edge from qtâˆ’1â†’qt(See Appendix A.2). Both
parameterizations are included in our results, presented in the appendix, to show their effectiveness.
Finally, the diagonal elements of the transferred observation noise vector rtare directly mapped
from the original observation space using the encoder function e(.)shown in Figure 3. The mapping
employs an activation function, elu+1, to handle the positivity of the diagonal elements.
Filtering and Smoothing Approximation. We consider GRUKGnetwork to approximate KG as:
Ë†Kt=Ë†Î£t|tâˆ’1Ë†HT
tMtMT
t,Mt=GRUKG 
[Conv (Ë†Î£t|tâˆ’1),rt]
(6)
5Ë†Âµt|t= Ë†Âµt|tâˆ’1+Ë†Kt.[wtâˆ’Ë†HtË†Âµt|tâˆ’1],Ë†Î£t|t=Ë†Î£t|tâˆ’1+Ë†Kt.[Ë†Ht.Ë†Î£t|tâˆ’1.Ë†HT
T+Rt].Ë†KT
t (7)
In Equation (6), Conv (.)represents a zero bias convolutional layer with pooling, employed to deal
with sparsity of covariance matrix and extract its relevant information while reducing its size. The [,]
symbol denotes the concatenation operator. Furthermore, the presence of a positive rtvector and the
consideration of the Cholesky factor, MtMT
tin (6), ensure the resulting covariance matrices maintain
positive definiteness. This parameterization construct a new filtering distribution qÎ³1:t(xt|w1:t) =
N(Ë†Âµt|t,Ë†Î£t|t)that is an approximation of (2). Consequently, we consider the approximated prior
distribution as qÎ³1:t(xt|w1:tâˆ’1) =N(Ë†FtË†Âµtâˆ’1|tâˆ’1,Ë†FtË†Î£tâˆ’1|tâˆ’1Ë†FT
t) =N(Ë†Âµt|tâˆ’1,Ë†Î£t|tâˆ’1), where
(Ë†Âµt|tâˆ’1,Ë†Î£t|tâˆ’1)are used in (7).
After obtaining filtering states from qÎ³1:t(xt|w1:t), we use GRUSGnetwork to approximate SG in a
similar way we used GRUKGin (6) as:
Ë†Jt=Ë†Î£t|tË†FT
t+1NtNT
t,Nt=GRUSG 
Conv (Ë†Î£t+1|t)
(8)
Ë†Âµt|T= Ë†Âµt|t+Ë†Jt
Ë†Âµt+1|Tâˆ’Ë†Ft+1Ë†Âµt|t
,Ë†Î£t|T=Ë†Î£t|t+Ë†Jt Ë†Î£t+1|Tâˆ’Ë†Ft+1Ë†Î£t|tË†FT
t+1Ë†JT
t(9)
where the first smoothing state is set to the last filtering state. The new smoothing distribution
qÎ³1:T(xt|w1:T) =N(Ë†Âµt|T,Ë†Î£t|T)is an approximation of the exact smoothing distribution in (3). For
a GRU cell with an input size of iand a hidden state size of h, the computational complexity in
the forward pass is O(3h(h+i+ 3)) , which scales linearly with the input size [ 35]. Considering
Conv (Î£)âˆˆRÎ²2n2as the input of our GRU cells in (6) and (8) with Î²âˆˆ[0,1]as the pooling ratio,
the forward pass of GIN for one time step has a time complexity of O(3hÎ²2n2), where nâ‰«h.
Compared with LGSSM matrix inversion time complexity of O(n3), GIN is faster by a factor of
n
3hÎ²2, which is crucial in high-dimensional regimes.
6 Fitting
In the state estimation task, the output from d(.)in figure 3 equals s, the physical systemâ€™s states.
However, in the imputation task, output of d(.)is same as osince the original observation is recon-
structed (see decoder structure for each task in A.8.1). The conditional distributions p(w1:T|o1:T)
andqÎ³1:T(x1:T|w1:T)are modeled using an encoder e(.)and smoothing parameterization, respec-
tively. Meanwhile, the conditional distributions p(s1:T|x1:T,w1:T,o1:T)andp(o1:T|x1:T,w1:T)are
represented by the decoder d(.)for the tasks of state estimation and imputation. These distributions
are modeled using multivariate Gaussian and Bernoulli distributions, respectively. Depending on
the characteristics of the observations and states, alternative likelihood distributions can also be em-
ployed. For instance, the beta likelihood for data in the unit interval, mixtures for multiple marginal
distributions, and the negative-binomial likelihood for positive count data (See appendix A.3).
Likelihood for Inferring States. The following theorem defines objective for inferring physical
systemâ€™s states. The proof is provided in appendix A.4.1.
Theorem 1. The lower bounded conditional log likelihood of the physical systemâ€™s states given
original images is determined as:
L(s1:T|o1:T) =1
NNX
i=1logp(s1:T|x(i)
1:T,w(i)
1:T,o1:T) =1
NNX
i=1TX
t=1logN
stdm(Ë†Âµ(i)
t|T), dc(Ë†Î£(i)
t|T)
(10)
where the dm(.)anddc(.)determines those parts of the decoder obtaining the state mean and variance.
Nsequences of (x(i)
1:T,w(i)
1:T)âˆ¼qÎ³1:T(x1:T,w1:T|o1:T)are sampled for Monte Carlo integration
estimation.
Likelihood for Inferring Images. For the imputation task, consider the ground truth as the
sequence of images o1:Twith the dimension of Do. The following theorem defines objective for
inferring images. See appendix A.4.2 for the proof.
6Theorem 2. The lower bound of log likelihood of the original images is:
L(o1:T) =1
NNX
i=1logp(o1:T|x(i)
1:T,w(i)
1:T) =1
NNX
i=1TX
t=1DoX
k=1o(k)
tlog 
dk(Ë†Âµ(i)
t|T)
+ 
1âˆ’o(k)
t
log(1âˆ’dk(Ë†Âµ(i)
t|T))
(11)
withNsequences of (x(i)
1:T,w(i)
1:T)âˆ¼qÎ³1:T(x1:T,w1:T|o1:T)for Monte Carlo integration estimation.
dk(.)defines the corresponding part of the decoder that maps the k-th pixel of otimage.
We use Wishart distribution as a prior for our covariance matrix of states in (10) and (11), which pushes
the covariance toward a scale of identity matrix. Such prior prevents getting high log-likelihood due
to the high uncertainty. We shrink this scale toward zero as time passes, as we expect the model to
finally perform with very little uncertainty, approaching deterministically.
Mode collapse handling. To address the issue of mode collapse, where the model becomes stuck
in the same state, we propose a loss term on (i, j)pair of transition matrices as follows:
lmc(i, j) =||Ë‡Fiâˆ’Diag(mi)||2
Fâˆ’ ||Ë‡Fiâˆ’Ë‡Fj||2
Fâˆ’ ||Ë‡Fiâˆ’Diag(mj)||2
F (12)
withmiandmjbeing distinct hyper parameter vectors, and ||.||Fis the Frobenius norm. The term
âˆ’1
2PK
i=1PK
j=1,jÌ¸=ilmc(i, j)can be added into (10) and (11). This addition ensures that each Ë‡Fi
captures a unique transition, distinct from others. From a statistical perspective, (12) represents
a term proportional to âˆ’KL 
pi(Ë‡F)||pj(Ë‡F).prij(Ë‡F)
+KL 
pi(Ë‡F)||prii(Ë‡F)
(See appendix A.5).
pi(Ë‡F)âˆ¼ MN nÃ—n(Ë‡Fi,I,I)andpj(Ë‡F)âˆ¼ MN nÃ—n(Ë‡Fj,I,I), are matrix normal distributions with
priors prii(Ë‡F)âˆ¼ MN nÃ—n(Diag(mi),I,I)andprij(Ë‡F)âˆ¼ MN nÃ—n(Diag(mj),I,I), respectively.
Gradient explosion handling. Training (10) and (11) with SGD can be disrupted by a gradient
explosion. Specifically, we limit the optimization in (10) and (11) subject to Ïƒ1(Uh)<2, where
Ïƒi(.)represents the i-th largest singular value and UhâˆˆRhÃ—hdenotes the weight matrix of the
hidden state hâˆˆRhwithhdimension in the GRU cell (see eq.(5) in [ 35] or (53) in appendix A.4.3).
Theorem 3. When Ïƒ1(Uh)<2, a GRU cell is locally stable at a fix point hâˆ—=0.
We use Lyapunov stability and two lemmas for the proof of Theorem 3 in appendix A.4.3. Solving
(10) and (11) with SGD gives an updated Ë†Uhin each iteration that may not satisfy Ïƒ1(Ë†Uh)<2. We
offer two solutions to satisfy the constraint outlined in theorem 3. The first solution relies on the
spectral theorem, offering higher accuracy but with increased computational cost. Alternatively, the
second solution employs the Gershgorin circle theorem, providing lower accuracy but at a reduced
cost. Due to space limitations, we provide the details of the second solution in appendix A.4.5. For
the first solution, we modify Ë†Uhin three steps: (i) Decompose Ë†Uhby singular value decomposition
(SVD) such that Ë†Uh=WÎ›V . (ii) Replace the singular values of diagonal Î›that are greater than 2
with the threshold 2âˆ’Î´and obtain Î›=Diag(min(Ïƒ1,2âˆ’Î´), ..., min (Ïƒh,2âˆ’Î´)). (iii) Reconstruct
Uhâ†WÎ›V. Employing SVD approach, the cost of this solution is proportional to O(h3). In the
next theorem we show that constructed Uhis the optimum solution. The proof is in appendix A.4.4.
Theorem 4. The modified weight matrix Uhobtained from (iii) step above, is a solution of the
following optimization problem: minUh||Ë†Uhâˆ’Uh||2
F, s.t. Ïƒ1(Uh)<2âˆ’Î´.
7 Evaluation and Experiments
The first two experiments are single pendulum and double pendulum, where the dynamics of the latter
one is more complicated. The third experiment is ball bouncing in irregular polygon to demonstrate
the ability of the GIN when it faces irregular environments with multiple underlying dynamics. The
fourth experiment covers visual odometry task for real world data. The last experiment shows the
effectiveness of theorems 3 and 4 for gradient explosion handling. Intuitive python code and training
algorithm are in appendix A.11. Detailed explanations regarding hyperparameter optimization,
network structure, and empirical solutions aimed at avoiding poor local minima are in appendix A.7.
Single Pendulum and Double Pendulum.
In the pendulum experiment, observations are the image sequences comprising 100 time
steps, each has the size of 24Ã—24distorted with time correlated noise. We per-
form the filtering-smoothing by the GIN. In state estimation task, the log-likelihood and
7Table 1: Double (left) and single pendulum (middle) and polygon (left) state estimation results.
(s1, s2, s3, s4)are estimated position of the joints of double pendulum. For single pendulum and
polygon, (s1, s2)denotes the estimated single joint and ball position. sis sampled from eq. (10).
Model SEPos
s1SEPos
s3SEPos
s2SEPos
s4Log Likelihood
V AE 0.212 0.275 0.192 0.285 1.953 Â±0.306
IW-V AE 0.203 0.251 0.201 0.266 2.113 Â±0.391
V AE-RNN (LSTM) 0.154 0.147 0.134 0.152 4.053 Â±0.565
V AE-RNN (GRU) 0.164 0.156 0.162 0.145 3.976 Â±0.231
SV AE (LDS) 0.190 0.211 0.179 0.159 3.495 Â±0.425
KV AE 0.193 0.188 0.178 0.149 3.679 Â±0.101
EKV AE 0.171 0.159 0.151 0.162 3.801 Â±0.116
MV AE 0.168 0.161 0.139 0.149 3.927 Â±0.226
DeepAR 0.175 0.189 0.157 0.147 3.646 Â±0.294
RKN 0.134 0.129 0.139 0.118 4.176 Â±0.294
CRU 0.117 0.127 0.116 0.104 4.269 Â±0.237
Encode-Decoder 0.291 0.284 0.342 0.317 1.877 Â±0.427
AE-RNN (LSTM) 0.163 0.171 0.148 0.167 3.901 Â±0.706
AE-RNN (GRU) 0.189 0.183 0.179 0.177 3.886 Â±0.369
LGSSM filter 0.125 0.119 0.121 0.107 4.192 Â±0.127
LGSSM smooth 0.109 0.111 0.104 0.101 4.231 Â±0.154
GIN filter(n=2m) 0.105 0.099 0.109 0.099 4.524 Â±0.105
GIN filter(n=3m) 0.083 0.081 0.088 0.079 4.829 Â±0.151
GIN smooth (n=2m) 0.081 0.094 0.081 0.082 4.708 Â±0.123
GIN smooth (n=3m) 0.069 0.073 0.075 0.067 4.977 Â±0.168SEPos
s1SEPos
s2Log Likelihood
0.211 0.247 2.191 Â±0.451
0.231 0.197 2.328 Â±0.394
0.111 0.099 5.691 Â±0.151
0.109 0.101 5.749 Â±0.168
0.109 0.096 5.736 Â±0.168
0.104 0.095 5.786 Â±0.098
0.088 0.093 5.858 Â±0.113
0.087 0.087 5.938 Â±0.137
0.107 0.094 5.746 Â±0.294
0.078 0.075 6.161 Â±0.23
0.074 0.069 6.348 Â±0.19
0.248 0.191 2.271 Â±0.215
0.089 0.087 5.751 Â±0.215
0.091 0.085 5.798 Â±0.205
0.077 0.073 6.211 Â±0.265
0.071 0.069 6.242 Â±0.109
0.063 0.06 7.192 Â±0.239
0.057 0.056 7.315 Â±0.220
0.055 0.057 7.292 Â±0.173
0.049 0.047 7.445 Â±0.165SEPos
s1SEPos
s2Log Likelihood
0.769 0.782 2.094 Â±0.392
0.777 0.764 2.117 Â±0.475
0.447 0.411 3.157 Â±0.122
0.439 0.415 3.188 Â±0.091
0.424 0.438 3.229 Â±0.112
0.434 0.439 3.194 Â±0.073
0.340 0.429 3.276 Â±0.064
0.310 0.401 3.305 Â±0.069
0.447 0.434 3.071 Â±0.106
0.314 0.437 3.324 Â±0.039
0.294 0.378 3.366 Â±0.039
0.969 0.914 1.984 Â±0.384
0.349 0.319 3.331 Â±0.124
0.351 0.429 3.267 Â±0.089
0.448 0.312 3.171 Â±0.365
0.327 0.317 3.544 Â±0.029
0.203 0.208 4.125 Â±0.146
0.198 0.199 4.254 Â±0.187
0.186 0.198 4.227 Â±0.048
0.154 0.147 4.342 Â±0.051
Figure 5: Pendulum imputation. Rows from
up to down are the noise distorted ground truth,
observation with uninformed missing frames and
the imputation results of the GIN(smoothed).
Figure 6: D-pendulum imputation.Rows from
up to down are the noise distorted ground truth,
observation with uninformed missing frames and
the imputation results of the GIN(smoothed).
squared error (SE) of the estimated states are given in table 1. With n= 3 m(n
andmrepresenting state and transferred observation dimensions) as shown in Table 1,
Table 2: Image imputation task log likelihood for single pen-
dulum (left), double pendulum (middle) and polygon (right).
The approaches without good results are not included.
Model Single Pendulum Double Pendulum Irregular Polygon
V AE (informed) -36.751 Â±7.227 -44.264 Â±4.232
IW-V AE (informed) -34.241 Â±5.421 -43.728 Â±5.421
V AE-RNN (GRU) (informed) -14.243 Â±0.328 -15.983 Â±0.425 -16.483 Â±0.425
SV AE (LDS) (informed smooth) -14.763 Â±0.419 -16.978 Â±0.551 -16.578 Â±0.551
KV AE (informed smooth) -14.217 Â±0.236 -15.917 Â±0.294 -16.377 Â±0.688
KV AE (unformed smooth) -39.260 Â±5.399 -38.544 Â±6.419
EKV AE (informed smooth) -12.897 Â±0.524 -13.917 Â±0.414 -15.916 Â±0.292
EKV AE (unformed smooth) -29.246 Â±3.328 -33.548 Â±4.516
MKV AE (informed smooth) -12.723 Â±0.428 -13.889 Â±0.298 -15.698 Â±0.344
MKV AE (unformed smooth) -21.524 Â±1.003 -26.773 Â±1.537 -31.634 Â±2.816
DeepAR (informed) -14.019 Â±0.486 -15.881 Â±0.511 -19.322 Â±0.418
RKN (informed) -12.782 Â±0.016 -13.832 Â±0.023 -16.267 Â±0.313
RKN (unformed) -12.789 Â±0.021 -13.891 Â±0.031 -16.538 Â±0.482
CRU (informed) -12.495 Â±0.022 -13.668 Â±0.038 -15.884 Â±0.297
CRU (unformed) -12.554 Â±0.029 -13.739 Â±0.061 -15.972 Â±0.394
Encoder-Decoder (informed) -64.569 Â±9.146 -75.179 Â±21.527
AE-RNN (GRU) (informed) -14.173 Â±0.066 -16.013 Â±0.346 -17.903 Â±0.431
LGSSM(informed smooth) -12.395 Â±0.048 -13.775 Â±0.013 -15.831 Â±0.215
GIN (informed smooth) -11.215 Â±0.027 -12.584 Â±0.021 -14.628 Â±0.226
GIN (unformed smooth) -11.246 Â±0.029 -12.651 Â±0.019 -14.923 Â±0.384intuitively states contain information
about position, velocity, and accelera-
tion, increasing the likelihood com-
pared to n= 2m, where only po-
sition and velocity are allocated to
states. For the imputation task, we
randomly remove half of the images
from the generated sequences and per-
form image imputation by predicting
the missing parts. The numerical re-
sults are in table 2 and imputed im-
ages are in figures 5 and 6. In table
2, the models with informed boolean
masks are aware of available and miss-
ing images, while uninformed masks
use a black image as input for missing
images. This encourages the model
to accurately infer the dynamics for
image generation.
For ablation study, first we compare
GIN with simple encoder-decoder
without latent parameterization, and
8then with LGSSM, where the GRU cells are omitted from the GIN structure and classic filtering-
smoothing equations are used instead. We also check the usefulness of filtering-smoothing parameter-
ization by replacing the GINâ€™s transition block with GRU and LSTM cells and directly parameterize
output distribution (like AE-RNN [ 36] and [ 37]). We compare various VI models, including V AE,
IWV AE, V AE-RNN [ 38] which utilizes V AEs with recurrent cells, and EM-based VI approaches
such as SV AE, KV AE, EKV AE and MV AE. Our comparison also encompasses DeepAR [ 39], an
AR model. Our thorough comparison, covering the CRU, RKN, a group of V AEs, and AR models,
enhances the depth of our analysis. The GIN consistently outperforms all other models. Additionally,
we provide results using the MSE metric to highlight the competitive prediction accuracy of our
approach (See appendix A.10).
Bouncing Ball In Irregular Polygon. To demonstrate the adaptability of the GIN, we
subjected it to a more complex environment. We generated 1000 sequences, each comprising
70 time steps, depicting a ball moving within an irregular polygon featuring random shapes.
s1s2
s1s2
s1s2
s1s2
1520253035s1p(gt135)=(s125)
35|70=24.91
35|70=22.83
35|70=29.15
05101520
p(gt145)=(s112)
45|70=11.86
45|70=8.14
45|70=8.09
GIN LGSSM KVAE05101520s2
p(gt235)=(s210)
35|70=10.07
35|70=12.51
35|70=8.64
GIN LGSSM KVAE05101520
p(gt245)=(s211)
45|70=10.73
45|70=14.11
45|70=15.25
Figure 7: State (position) estimation in irregular poly-
gon (6 edges) at 35-th and 45-th time steps. The upper
row shows the ground truth ball position in 35,39,42
and45-th time steps, respectively.The initial position and velocity of the ball
were randomized. No external forces acted
upon the ball, and collisions with the walls
were elastic. In addition to the aforemen-
tioned models, we include latent SLDS
structure from the SV AE approach for the
comparison. SLDS is particularly relevant
in scenarios such as this one, where sep-
arate dynamics for each state are consid-
ered, as seen when the ball bounces off the
wall. We exclude simple baselines, such as
encoder-decoder, V AE, and IW-V AE, from
the comparison due to their lack of compet-
itive performance. The numerical results
are in tables 1 and 2. In Figure 7, we il-
lustrate samples obtained from the trained
smoothing distributions of GIN, LGSSM,
and KV AE, showcasing their proximity to
the ground truth. For this demonstration,
we specifically select the 35th time step for
sampling, denoted as L(s35|o1:70). Here,
s1ands2represent the estimated xy posi-
tion of the ball within the polygon. Gener-
ating 20 frames with GIN in four different
irregular environments is shown in figure
1. We have created animated files that demonstrate both sequence generation and imputation tasks
within irregular polygons. Please visit: https://sites.google.com/view/ginneurips2024.
Visual Odometry of KITTI Dataset. We also evaluate the GIN with the higher dimensional
observations for the visual odometry task on the KITTI dataset [ 40]. This dataset consists of 11
separated image sequences with their corresponding labels. We use a feature extractor network
proposed by Zhou et al. in [ 41] to obtain the transferred observations of the GIN, i.e. ( w,r).
Additionally, we compare the results with AE-RNN(LSTM), AE-RNN(GRU), DeepVO [ 42] and
KV AE. The numerical results are in table 3, where the common evaluation scheme for the KITTI
dataset is exploited. The results of the KV AE degrades substantially as we have to reduce the size of
the transferred observation to prevent the complexity of matrix inversion. Sampling visualization
from smoothing state distribution are in appendix A.9.
Table 3: Comparison of model performance on KITTI dataset.
SeqAE-RNN(LSTM) AE-RNN(GRU) DeepVO KV AE LGSSM GIN
trel(%) rrel(â—¦)trel(%) rrel(â—¦)trel(%) rrel(â—¦)trel(%) rrel(â—¦)trel(%) rrel(â—¦)trel(%) rrel(â—¦)
03 8.99 4.55 9.34 3.81 8.49 6.89 12.14 4.38 7.51 3.98 6.98 3.27
04 11.88 3.44 12.36 2.89 7.19 6.97 13.17 4.73 9.12 2.64 9.14 2.28
05 8.96 3.43 10.02 3.43 2.62 3.61 11.47 5.14 6.11 3.21 4.38 2.51
06 9.66 2.8 10.99 3.22 5.42 5.82 10.93 3.98 6.70 3.51 6.14 2.90
07 9.83 5.48 13.70 6.52 3.91 4.60 12.73 4.68 6.59 3.49 7.21 2.98
10 13.58 3.49 13.37 3.25 8.11 8.83 14.79 10.91 9.32 2.90 8.37 2.59
mean 10.53 3.87 11.63 3.85 5.96 6.12 12.53 5.63 7.55 3.28 7.03 2.75
9Gradient Explosion Experiment. Table 4 lists the log likelihood and its standard deviation for
three experiments: single pendulum, double pendulum, and irregular polygon. These experiments
were trained under different settings for gradient explosion handling: the conventional Gradient
Clipping (GC), our first solution using Singular Value Decomposition (SVD), and our second solution
using the Gershgorin Circle Theorem (GCT). The table empirically demonstrates that our method
outperforms conventional gradient clipping. In this table, Î¸represents the threshold for gradient
clipping as introduced in [ 10], and Î´is the threshold in our method that keeps the spectral radius less
than 2, i.e., Ïƒ1(Uh) +Î´= 2. As shown in table 4, gradient clipping failed to train for high Î¸, while
our approach achieves lower perplexity and higher log likelihood, ensuring stability compared to
gradient clipping by constraining the GRU to be stable. We provide a comprehensive discussion on
theÎ´variable, including how to tune it in different environments and its impact on model performance,
in the appendix A.8.1.
Table 4: Gradient explosion handling: comparison between GC, SVD and GCT.
Single Pendulum Double Pendulum Irregular Polygon
Objective Success Objective Success Objective Success
SVDÎ´= 0.17.445Â±0.165 100 % 4.977 Â±0.168 100 % 4.342 Â±0.051 100 %
Î´= 0.47.281Â±0.149 100 % 4.847 Â±0.241 100 % 4.191 Â±0.094 100 %
(Ours) Î´= 0.77.127Â±0.197 100 % 4.692 Â±0.237 100 % 4.019 Â±0.214 100 %
Î´= 1 6.935Â±0.271 100 % 4.471 Â±0.341 100 % 3.839 Â±0.207 100 %
GCTÎ´= 0.17.318Â±0.214 100 % 4.849 Â±0.197 100 % 4.217 Â±0.114 100 %
Î´= 0.47.184Â±0.170 100 % 4.711 Â±0.179 100 % 4.079 Â±0.124 100 %
(Ours) Î´= 0.76.981Â±0.283 100 % 4.562 Â±0.193 100 % 3.957 Â±0.117 100 %
Î´= 1 6.787Â±0.321 100 % 4.291 Â±0.281 100 % 3.672 Â±0.176 100 %
GCÎ¸= 5 7.221Â±0.254 100 % 4.765 Â±0.349 100 % 4.172 Â±0.274 100 %
Î¸= 10 7.301Â±0.495 60 % 4.834 Â±0.592 50 % 4.222 Â±0.570 50 %
Î¸= 15 7.331Â±1.141 20 % N/A 0 % N/A 0 %
Î¸= 20 N/A 0 % N/A 0 % N/A 0 %
8 Conclusion
This paper introduces the GIN for representation learning in high-dimensional SSMs. The data
flow is managed by Bayesian filtering-smoothing, and the use of GRU-based KG and SG networks
addresses computational issues, resulting in an efficient and numerically stable model. The GIN learns
system dynamics end-to-end, making it a high-performance model with strong system identification
capabilities. It also provides insightful uncertainty representations for predictions and outperforms
various counterparts, including generative models with variational inference, autoregressive models,
and other baselines.
9 Acknowledgments
We thank Yasin Abbasi-Yadkori for useful discussions and suggestions that contributed to this work.
Bibliography
[1]C. M. Bishop and N. M. Nasrabadi, Pattern recognition and machine learning . Springer, 2006,
vol. 4, no. 4.
[2]R. M. Neal et al. , â€œMcmc using hamiltonian dynamics,â€ Handbook of markov chain monte
carlo , vol. 2, no. 11, p. 2, 2011.
[3]D. P. Kingma and M. Welling, â€œAuto-encoding variational bayes,â€ arXiv preprint
arXiv:1312.6114 , 2013.
[4] D. Koller and N. Friedman, Probabilistic graphical models: principles and techniques . MIT
press, 2009.
[5] R. E. Kalman, â€œA new approach to linear filtering and prediction problems,â€ 1960.
10[6]H. E. Rauch, F. Tung, and C. T. Striebel, â€œMaximum likelihood estimates of linear dynamic
systems,â€ AIAA journal , vol. 3, no. 8, pp. 1445â€“1450, 1965.
[7]E. A. Wan and R. Van Der Merwe, â€œThe unscented kalman filter for nonlinear estimation,â€ in
Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and
Control Symposium (Cat. No. 00EX373) . Ieee, 2000, pp. 153â€“158.
[8]L. Ljung, â€œAsymptotic behavior of the extended kalman filter as a parameter estimator for linear
systems,â€ IEEE Transactions on Automatic Control , vol. 24, no. 1, pp. 36â€“50, 1979.
[9]S. Linderman, M. Johnson, A. Miller, R. Adams, D. Blei, and L. Paninski, â€œBayesian learning
and inference in recurrent switching linear dynamical systems,â€ in Artificial Intelligence and
Statistics . PMLR, 2017, pp. 914â€“922.
[10] R. Pascanu, T. Mikolov, and Y . Bengio, â€œOn the difficulty of training recurrent neural networks,â€
inInternational conference on machine learning . Pmlr, 2013, pp. 1310â€“1318.
[11] K. Doya et al. , â€œBifurcations in the learning of recurrent neural networks 3,â€ learning (RTRL) ,
vol. 3, p. 17, 1992.
[12] T. Haarnoja, A. Ajay, S. Levine, and P. Abbeel, â€œBackprop kf: Learning discriminative de-
terministic state estimators,â€ in Advances in neural information processing systems , 2016, pp.
4376â€“4384.
[13] R. Krishnan, U. Shalit, and D. Sontag, â€œStructured inference networks for nonlinear state space
models,â€ in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 31, no. 1, 2017.
[14] P. G. Chang, K. P. Murphy, and M. Jones, â€œOn diagonal approximations to the extended kalman
filter for online training of bayesian neural networks,â€ in Continual Lifelong Learning Workshop
at ACML 2022 , 2022.
[15] M. Jones, T. R. Scott, M. Ren, G. F. Elsayed, K. Hermann, D. Mayo, and M. C. Mozer,
â€œLearning in temporally structured environments,â€ in The Eleventh International Conference on
Learning Representations , 2022.
[16] M. Watter, J. T. Springenberg, J. Boedecker, and M. Riedmiller, â€œEmbed to control: A locally
linear latent dynamics model for control from raw images,â€ arXiv preprint arXiv:1506.07365 ,
2015.
[17] Y . Burda, R. Grosse, and R. Salakhutdinov, â€œImportance weighted autoencoders,â€ arXiv preprint
arXiv:1509.00519 , 2015.
[18] M. J. Johnson, D. K. Duvenaud, A. Wiltschko, R. P. Adams, and S. R. Datta, â€œComposing graph-
ical models with neural networks for structured representations and fast inference,â€ Advances in
neural information processing systems , vol. 29, 2016.
[19] M. Fraccaro, S. Kamronn, U. Paquet, and O. Winther, â€œA disentangled recognition and nonlinear
dynamics model for unsupervised learning,â€ arXiv preprint arXiv:1710.05741 , 2017.
[20] Y . Li and S. Mandt, â€œDisentangled sequential autoencoder,â€ arXiv preprint arXiv:1803.02991 ,
2018.
[21] A. Klushyn, R. Kurle, M. Soelch, B. Cseke, and P. van der Smagt, â€œLatent matters: Learning
deep state-space models,â€ Advances in Neural Information Processing Systems , vol. 34, 2021.
[22] F. Tonolini, N. Aletras, Y . Jiao, and G. Kazai, â€œRobust weak supervision with variational
auto-encoders,â€ in International Conference on Machine Learning . PMLR, 2023, pp. 34 394â€“
34 408.
[23] H. Zhu, C. Balsells-Rodas, and Y . Li, â€œMarkovian gaussian process variational autoencoders,â€
inInternational Conference on Machine Learning . PMLR, 2023, pp. 42 938â€“42 961.
[24] P. Becker, H. Pandya, G. Gebhardt, C. Zhao, C. J. Taylor, and G. Neumann, â€œRecurrent kalman
networks: Factorized inference in high-dimensional deep feature spaces,â€ in International
Conference on Machine Learning . PMLR, 2019, pp. 544â€“552.
11[25] M. Schirmer, M. Eltayeb, S. Lessmann, and M. Rudolph, â€œModeling irregular time series with
continuous recurrent units,â€ in International Conference on Machine Learning . PMLR, 2022,
pp. 19 388â€“19 405.
[26] S. Hochreiter and J. Schmidhuber, â€œLong short-term memory,â€ Neural computation , vol. 9,
no. 8, pp. 1735â€“1780, 1997.
[27] K. Cho, B. Van MerriÃ«nboer, D. Bahdanau, and Y . Bengio, â€œOn the properties of neural machine
translation: Encoder-decoder approaches,â€ arXiv preprint arXiv:1409.1259 , 2014.
[28] R. Wilson and L. Finkel, â€œA neural implementation of the kalman filter,â€ Advances in neural
information processing systems , vol. 22, pp. 2062â€“2070, 2009.
[29] I. Buchnik, G. Revach, D. Steger, R. J. Van Sloun, T. Routtenberg, and N. Shlezinger, â€œLatent-
kalmannet: Learned kalman filtering for tracking from high-dimensional signals,â€ IEEE Trans-
actions on Signal Processing , 2023.
[30] G. Revach, N. Shlezinger, X. Ni, A. L. Escoriza, R. J. van Sloun, and Y . C. Eldar, â€œKalman-
net: Neural network aided kalman filtering for partially known dynamics,â€ arXiv preprint
arXiv:2107.10043 , 2021.
[31] D. Ruhe and P. ForrÃ©, â€œSelf-supervised inference in state-space models,â€ arXiv preprint
arXiv:2107.13349 , 2021.
[32] T. Liu, K. A. Lee, Q. Wang, and H. Li, â€œDisentangling voice and content with self-supervision
for speaker recognition,â€ Advances in Neural Information Processing Systems , vol. 36, pp.
50 221â€“50 236, 2023.
[33] M. P. Deisenroth and H. Ohlsson, â€œA general perspective on gaussian filtering and smoothing:
Explaining current and deriving new algorithms,â€ in Proceedings of the 2011 American Control
Conference . IEEE, 2011, pp. 1807â€“1812.
[34] P. Gilabert, G. Montoro, and E. Bertran, â€œOn the wiener and hammerstein models for power
amplifier predistortion,â€ in 2005 Asia-Pacific Microwave Conference Proceedings , vol. 2. IEEE,
2005, pp. 4â€“pp.
[35] J. Chung, C. Gulcehre, K. Cho, and Y . Bengio, â€œEmpirical evaluation of gated recurrent neural
networks on sequence modeling,â€ arXiv preprint arXiv:1412.3555 , 2014.
[36] N. Srivastava, E. Mansimov, and R. Salakhudinov, â€œUnsupervised learning of video represen-
tations using lstms,â€ in International conference on machine learning . PMLR, 2015, pp.
843â€“852.
[37] H. Li, S. Yu, and J. Principe, â€œCausal recurrent variational autoencoder for medical time series
generation,â€ in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 37, no. 7,
2023, pp. 8562â€“8570.
[38] J. Chung, K. Kastner, L. Dinh, K. Goel, A. C. Courville, and Y . Bengio, â€œA recurrent latent
variable model for sequential data,â€ Advances in neural information processing systems , vol. 28,
2015.
[39] D. Salinas, V . Flunkert, J. Gasthaus, and T. Januschowski, â€œDeepar: Probabilistic forecasting
with autoregressive recurrent networks,â€ International Journal of Forecasting , vol. 36, no. 3, pp.
1181â€“1191, 2020.
[40] A. Geiger, P. Lenz, and R. Urtasun, â€œAre we ready for autonomous driving? the kitti vision
benchmark suite,â€ in 2012 IEEE conference on computer vision and pattern recognition . IEEE,
2012, pp. 3354â€“3361.
[41] T. Zhou, M. Brown, N. Snavely, and D. G. Lowe, â€œUnsupervised learning of depth and ego-
motion from video,â€ in Proceedings of the IEEE conference on computer vision and pattern
recognition , 2017, pp. 1851â€“1858.
12[42] S. Wang, R. Clark, H. Wen, and N. Trigoni, â€œDeepvo: Towards end-to-end visual odometry
with deep recurrent convolutional neural networks,â€ in 2017 IEEE international conference on
robotics and automation (ICRA) . IEEE, 2017, pp. 2043â€“2050.
[43] K. Sohn, H. Lee, and X. Yan, â€œLearning structured output representation using deep conditional
generative models,â€ Advances in neural information processing systems , vol. 28, 2015.
[44] D. Angeli, E. D. Sontag, and Y . Wang, â€œA characterization of integral input-to-state stability,â€
IEEE Transactions on Automatic Control , vol. 45, no. 6, pp. 1082â€“1097, 2000.
[45] R. A. Horn and C. R. Johnson, Matrix analysis . Cambridge university press, 2012.
[46] D. P. Kingma and J. Ba, â€œAdam: A method for stochastic optimization,â€ arXiv preprint
arXiv:1412.6980 , 2014.
[47] P. J. Werbos, â€œBackpropagation through time: what it does and how to do it,â€ Proceedings of
the IEEE , vol. 78, no. 10, pp. 1550â€“1560, 1990.
[48] J. L. Ba, J. R. Kiros, and G. E. Hinton, â€œLayer normalization,â€ arXiv preprint arXiv:1607.06450 ,
2016.
[49] J. M. Wang, D. J. Fleet, and A. Hertzmann, â€œGaussian process dynamical models for human
motion,â€ IEEE transactions on pattern analysis and machine intelligence , vol. 30, no. 2, pp.
283â€“298, 2007.
[50] J. Ko and D. Fox, â€œLearning gp-bayesfilters via gaussian process latent variable models,â€
Autonomous Robots , vol. 30, no. 1, pp. 3â€“23, 2011.
[51] R. Frigola, F. Lindsten, T. B. SchÃ¶n, and C. E. Rasmussen, â€œBayesian inference and learning
in gaussian process state-space models with particle mcmc,â€ Advances in neural information
processing systems , vol. 26, 2013.
[52] M. Schoukens and K. Tiels, â€œIdentification of block-oriented nonlinear systems starting from
linear approximations: A survey,â€ Automatica , vol. 85, pp. 272â€“292, 2017.
[53] R. Li, S. John, and A. Solin, â€œImproving hyperparameter learning under approximate inference
in gaussian process models,â€ in International Conference on Machine Learning . PMLR, 2023,
pp. 19 595â€“19 615.
[54] N. WahlstrÃ¶m, T. B. SchÃ¶n, and M. P. Deisenroth, â€œFrom pixels to torques: Policy learning with
deep dynamical models,â€ arXiv preprint arXiv:1502.02251 , 2015.
[55] E. Archer, I. M. Park, L. Buesing, J. Cunningham, and L. Paninski, â€œBlack box variational
inference for state space models,â€ arXiv preprint arXiv:1511.07367 , 2015.
[56] M. Karl, M. Soelch, J. Bayer, and P. Van der Smagt, â€œDeep variational bayes filters: Unsu-
pervised learning of state space models from raw data,â€ arXiv preprint arXiv:1605.06432 ,
2016.
[57] C. Naesseth, S. Linderman, R. Ranganath, and D. Blei, â€œVariational sequential monte carlo,â€ in
International conference on artificial intelligence and statistics . PMLR, 2018, pp. 968â€“977.
[58] S. S. Rangapuram, M. W. Seeger, J. Gasthaus, L. Stella, Y . Wang, and T. Januschowski, â€œDeep
state space models for time series forecasting,â€ Advances in neural information processing
systems , vol. 31, 2018.
[59] V . Garcia Satorras, Z. Akata, and M. Welling, â€œCombining generative and discriminative models
for hybrid inference,â€ Advances in Neural Information Processing Systems , vol. 32, 2019.
13A Appendix
A.1 Filtering and Smoothing Parameterization
The Kalman filter operates through two iterative steps: prediction and update. In the prediction step,
the filter uses prior state information to make an estimate, while in the update step, it adjusts this
estimate based on new observations. Assuming normally distributed additive process and observation
noise, the filter can effectively perform these steps. During the prediction step, the filter employs
the transition matrix Ft+1to estimate the next priors pÎ³1:t+1(xt+1|w1:t) = (Âµt+1|t,Î£t+1|t), which
represent the next state estimates without incorporating any new observations.
Âµt+1|t=Ft+1Âµt|t,and Î£t+1|t=Ft+1Î£t|tFT
t+1+Qt+1,and Qt+1=Ïƒ2
t+1I (13)
When a new observation is available, the Kalman filter proceeds to the second step, where it updates
the predicted prior using the new observation and the emission matrix Ht+1. This results in the next
posterior, (Âµt+1|t+1,Î£t+1|t+1).
Kt+1=Î£t+1|tHT
t+1 
Ht+1Î£t+1|tHT
t+1+Rt+1âˆ’1, (14)
Âµt+1|t+1=Âµt+1|t+Kt+1(wtâˆ’Ht+1Âµt+1|t),Î£t+1|t+1=Î£t+1|tâˆ’Kt+1 
Ht+1Î£t+1|tHT
t+1+Rt+1
Kt+1.
(15)
The entire observation update procedure can be viewed as a weighted mean between the next prior,
derived from the state update, and the new observation. This weighting is influenced by Qand
R, reflecting their inherent uncertainties. We derive the smoothing parameterization by leveraging
the Markov property, which states that xtis independent of future observations wt+1:Tgiven
xt+1. Although xt+1is unknown, there is a distribution over it. By conditioning on xt+1and then
marginalizing out, we can obtain xtconditioned on w1:T.
pÎ³1:T(xt|w1:T) =Z
pÎ³1:T(xt|xt+1,w1:T)pÎ³1:T(xt+1|w1:T)dxt+1
=Z
pÎ³1:t(xt|xt+1,w1:t,wt+1:T)pÎ³1:T(xt+1|w1:T)dxt+1(16)
By using induction and and smoothed distribution for t+ 1:
pÎ³1:T(xt+1|w1:T) =N(Âµt+1|T,Î£t+1|T) (17)
we calculate the filtered two-slice distribution as follows:
.pÎ³1:t(xt,xt+1|w1:t) =N
Âµt|t
Âµt+1|t
,
Î£t|tÎ£t|tFT
t+1
Ft+1Î£t|tÎ£t+1|t
(18)
by using Gaussian conditioning we have:
pÎ³1:t(xt|xt+1,w1:t) =N(Âµt|t+Jt 
xt+1âˆ’Ft+1Âµt|t
,Î£t|tâˆ’JtÎ£t+1|tJT
t) (19)
where Jt=Î£t|tFt+1[Î£t+1|t]âˆ’1. We calculate the smoothed distribution for tusing the rules of
iterated expectation and covariance:
Âµt|T=E
E[xt|xt+1,w1:T]|w1:T
=E
E[xt|xt+1,w1:t]|w1:T
=E
Âµt|t+Jt(xt+1âˆ’Ft+1Âµt|t)|w1:T
=Âµt|t+Jt(Âµt+1|Tâˆ’Ft+1Âµt|t)(20)
14Î£t|T=cov
E[xt|xt+1,w1:T]|w1:T
+E
cov[xt|xt+1,w1:T]|w1:T
=cov
E[xt|xt+1,w1:t]|w1:T
+E
cov[xt|xt+1,w1:t]|w1:T
=cov
Âµt|t+Jt(xt+1âˆ’Ft+1Âµt|t)|w1:T
+E
Î£t|tâˆ’JtÎ£t+1|tJT
t|w1:T
=Jtcov
xt+1âˆ’Ft+1Âµt|t|w1:T
JT
t+Î£t|tâˆ’JtÎ£t+1|tJT
t
=JtÎ£t+1|TJT
t+Î£t|tâˆ’JtÎ£t+1|tJT
t
=Î£t|t+Jt 
Î£t+1|Tâˆ’Î£t+1|t
JT
t.(21)
A.2 Process Noise Matrix
As stated in (13), we can elaborate the process noise matrix at time tin more details
Qt=Î£t|tâˆ’1âˆ’FtÎ£tâˆ’1|tâˆ’1FT
t=Î£t|tâˆ’1âˆ’Ft
Î£tâˆ’1|tâˆ’2âˆ’Ktâˆ’1[Htâˆ’1Î£tâˆ’1|tâˆ’2HT
tâˆ’1+Rtâˆ’1]âˆ’1KT
tâˆ’1
FT
t
(22)
combining (13) into (22) results in
Qt=Î£t|tâˆ’1âˆ’Ft
[Ftâˆ’1Î£tâˆ’2|tâˆ’2FT
tâˆ’1+Qtâˆ’1]
âˆ’Ktâˆ’1[Htâˆ’1[Ftâˆ’1Î£tâˆ’2|tâˆ’2FT
tâˆ’1+Qtâˆ’1]HT
tâˆ’1+Rtâˆ’1]âˆ’1KT
tâˆ’1
FT
t(23)
which is a function of Ft,Qtâˆ’1,Ftâˆ’1andHtâˆ’1. In the GIN, Ë†FtandË†Htare learned by the Dynamic
Network with the input of xtâˆ’1. From (15), Âµtâˆ’1|tâˆ’1is derived as a function of both Ftâˆ’1and
Htâˆ’1, meaning the learned Ë†Ftcarries the information of both Htâˆ’1andFtâˆ’1. Therefore, one can
rewrite the equation (23) as
Qt=g
Ë†Ft 
Âµtâˆ’1|tâˆ’1
,Qtâˆ’1
,where Ë†Ft=Dynamic Net
Âµtâˆ’1|tâˆ’1 
Htâˆ’1,Ftâˆ’1
(24)
where gis a nonlinear function mapping Âµtâˆ’1|tâˆ’1andQtâˆ’1toQtand the graphical model for such
choice of structure is in appendix figure 8b. It is possible to go one step further and simplify Âµtâˆ’1|tâˆ’1
more, as it has Î£tâˆ’1|tâˆ’1term in (15), combining it with (13) results in:
Âµtâˆ’1|tâˆ’1=Âµtâˆ’1|tâˆ’2+ [Ftâˆ’1Î£tâˆ’2|tâˆ’2FT
tâˆ’1+Qtâˆ’1]
HT
tâˆ’1 
Htâˆ’1[Ftâˆ’1Î£tâˆ’2|tâˆ’2FT
tâˆ’1+Qtâˆ’1]HT
tâˆ’1+Rtâˆ’1âˆ’1(wtâˆ’Htâˆ’1Âµtâˆ’1|tâˆ’2)
(25)
indicating that not only Ftâˆ’1andHtâˆ’1, but also Qtâˆ’1is included in Âµtâˆ’1|tâˆ’1, meaning that Qtcan
be written solely as a function of Âµtâˆ’1|tâˆ’1and the graphical model for such choice is in figure 8a.
Qt=g
Ë†Ft 
Âµtâˆ’1|tâˆ’1
,where Ë†Ft=Dynamic Net
Âµtâˆ’1|tâˆ’1 
Htâˆ’1,Ftâˆ’1,Qtâˆ’1
.(26)
We refer to gas the Q Network , which can be modeled either by an MLP, as shown in (26), or by a
recurrent network, as detailed in (24).
A.3 Output Distribution
In the case of grayscale images, each pixel yis either one or zero with the probability por1âˆ’p,
respectively, meaning that P(Y=y) =py(1âˆ’p)1âˆ’y. This probability equation can be rewritten in
the form of an exponential family as follows:
15ð‘žð‘¡âˆ’1
xð‘¡âˆ’1
wð‘¡âˆ’1ð‘žð‘¡
xð‘¡
wð‘¡ð‘žð‘¡+1
xð‘¡+1
wð‘¡+1â€¦
â€¦
â€¦â€¦
â€¦
â€¦
oð‘¡âˆ’1sð‘¡âˆ’1 oð‘¡ sð‘¡oð‘¡+1sð‘¡+1(a) Without recurrent dependency on qtmodeled with
(26).
ð‘žð‘¡âˆ’1
xð‘¡âˆ’1
wð‘¡âˆ’1ð‘žð‘¡
xð‘¡
wð‘¡ð‘žð‘¡+1
xð‘¡+1
wð‘¡+1â€¦
â€¦
â€¦â€¦
â€¦
â€¦
oð‘¡âˆ’1sð‘¡âˆ’1 oð‘¡ sð‘¡oð‘¡+1sð‘¡+1(b) With recurrent dependency on qtmodeled with
(24).
Figure 8: Graphical models for different parameterizations of the process noise.
fÎ¸(y) =h(y).exp 
Î¸.yâˆ’Ïˆ(Î¸)
â†’elog(py(1âˆ’p)1âˆ’y)=ey log (p
1âˆ’p)+log(1âˆ’p). (27)
By choosing Î¸=log(p
1âˆ’p)andÏˆ(Î¸) =log(1âˆ’p)andh(y) = 1 , we can obtain p=1
1+eâˆ’Î¸. This
means that by considering Î¸as the last layer of the decoder and applying a sigmoid layer, pis obtained
and one can optimize psuch that the likelihood is maximized as we did in in (11).
Similarly, consider xas the ground truth state, Ë†xÎ¸as the estimated state, and Î¸as the model variables.
The residual follows a Gaussian distribution: x= Ë†xÎ¸+Ïµâˆ¼ N(Ë†xÎ¸,Ë†ÏƒÎ¸), where Ë†ÏƒÎ¸is the estimated
variance. Then, the negative log likelihood is given by (28) as we obtained it in(10).
âˆ’log(L)âˆ1
2log(Ë†ÏƒÎ¸) +(xâˆ’Ë†xÎ¸)2
2Ë†ÏƒÎ¸(28)
A.4 Proof of theorems
We restate the theorems for the ease of readability and then provide the proofs.
A.4.1 Proof of theorem 1
Theorem. The log likelihood of the states given the original observations is determined as:
L(s1:T|o1:T) =1
NNX
i=1logp(s1:T|x(i)
1:T,w(i)
1:T,o1:T) =1
NNX
i=1TX
t=1logN
stdm(Ë†Âµ(i)
t|T), dc(Ë†Î£(i)
t|T)
where the dm(.)anddc(.)determines those parts of the decoder that obtain the state mean and
variance, respectively. Nsequences of (x(i)
1:T,w(i)
1:T)âˆ¼qÎ³1:T(x1:T,w1:T|o1:T)are sampled for
Monte Carlo integration estimation.
16Proof.
logpÎ³1:T(s1:T|o1:T)
=Z
qÏ•(x1:T,w1:T|o1:T,s1:T) logpÎ³1:T(s1:T,w1:T,x1:T|o1:T)
pÎ³1:T(x1:T,w1:T|s1:T,o1:T)dx1:Tdw1:T (29)
=Z
qÏ•(x1:T,w1:T|o1:T,s1:T) logqÏ•(x1:T,w1:T|o1:T,s1:T)
âˆ’qÏ•(x1:T,w1:T|o1:T,s1:T) logqÏ•(x1:T,w1:T|o1:T,s1:T)
+qÏ•(x1:T,w1:T|o1:T,s1:T) logpÎ³1:T(s1:T,w1:T,x1:T|o1:T)
pÎ³1:T(x1:T,w1:T|s1:T,o1:T)dx1:Tdw1:T (30)
= KL 
qÏ•(x1:T,w1:T|o1:T,s1:T)||pÎ³1:T(x1:T,w1:T|s1:T,o1:T)
+Z
qÏ•(x1:T,w1:T|o1:T,s1:T) logpÎ³1:T(s1:T,w1:T,x1:T|o1:T)
qÏ•(x1:T,w1:T|o1:T,s1:T)dx1:Tw1:T (31)
â‰¥EqÏ•(x1:T,w1:T|o1:T,s1:T)
logpÎ³1:T(s1:T,w1:T,x1:T|o1:T)
qÏ•(x1:T,w1:T|o1:T,s1:T)
(32)
=EqÏ•(x1:T,w1:T|o1:T,s1:T)
logpÎ³1:T(s1:T|w1:T,x1:T,o1:T).pÎ³1:T(w1:T,x1:T|o1:T)
qÏ•(x1:T,w1:T|o1:T,s1:T)
(33)
â‰ˆEqÏ•(x1:T,w1:T|o1:T,s1:T)
logpÎ³1:T(s1:T|w1:T,x1:T,o1:T)
(34)
â‰ˆEqÎ³1:T(x1:T,w1:T|o1:T)
logpÎ³1:T(s1:T|w1:T,x1:T,o1:T)
(35)
=EqÎ³1:T(x1:T|w1:T).p(w1:T|o1:T)
logpÎ³1:T(s1:T|w1:T,x1:T,o1:T)
(36)
â‰ˆ1
NNX
i=1logp(s1:T|x(i)
1:T,w(i)
1:T,o1:T),x(i)
1:Tâˆ¼qÎ³1:T(x1:T|w(i)
1:T),w(i)
1:Tâˆ¼p(w1:T|o1:T)(37)
=1
NNX
i=1TX
t=1logN
stdm(Ë†Âµ(i)
t|T), dc(Ë†Î£(i)
t|T)
(38)
=L(s1:T|o1:T). (39)
The inequality in (32) arises from the positivity of the Kullback-Leibler (KL) term. The approx-
imation in (34) results from assuming equality between the prior and the approximated posterior,
i.e.,pÎ³1:T(w1:T,x1:T|o1:T) =qÏ•(x1:T,w1:T|o1:T,s1:T). This assumption is not very restrictive
as explained further in [ 43]. The approximation in (35) is coming from the equality assumption
ofqÏ•(x1:T,w1:T|o1:T,s1:T)andqÎ³1:T(x1:T,w1:T|o1:T). This assumption implies that given the
original observation o1:T, our latent representation (x1:T,w1:T)is independent of the ground truth
states s1:T. In simpler terms, s1:Tis concealed within o1:T, allowing us to disregard s1:T. The
approximation in (37) is because of Monte Carlo integration estimation.
A.4.2 Proof of theorem 2
Theorem. The (lower bound of) log likelihood of the original images is:
L(o1:T) =1
NNX
i=1logp(o1:T|x(i)
1:T,w(i)
1:T) =1
NNX
i=1TX
t=1DoX
k=1o(k)
tlog 
dk(Ë†Âµ(i)
t|T)
+ 
1âˆ’o(k)
t
log(1âˆ’dk(Ë†Âµ(i)
t|T))
(40)
withNsequences of (x(i)
1:T,w(i)
1:T)âˆ¼qÎ³1:T(x1:T,w1:T|o1:T)for Monte Carlo integration estimation. dk(.)
defines the corresponding part of the decoder that maps the k-th pixel of otimage.
17Proof.
logpÎ³1:T(o1:T)
=Z
qÎ³1:T(x1:T,w1:T|o1:T) logpÎ³1:T(w1:T,x1:T,o1:T)
pÎ³1:T(x1:T,w1:T|o1:T)dx1:Tdw1:T (41)
=Z
qÎ³1:T(x1:T,w1:T|o1:T) logqÎ³1:T(x1:T,w1:T|o1:T)
âˆ’qÎ³1:T(x1:T,w1:T|o1:T) logqÎ³1:T(x1:T,w1:T|o1:T)
+qÎ³1:T(x1:T,w1:T|o1:T) logpÎ³1:T(w1:T,x1:T,o1:T)
pÎ³1:T(x1:T,w1:T|o1:T)dx1:Tdw1:T (42)
= KL 
qÎ³1:T(x1:T,w1:T|o1:T)||pÎ³1:T(x1:T,w1:T|o1:T)
+Z
qÎ³1:T(x1:T,w1:T|o1:T) logpÎ³1:T(w1:T,x1:T,o1:T)
qÎ³1:T(x1:T,w1:T|o1:Tdx1:Tw1:T (43)
â‰¥EqÎ³1:T(x1:T,w1:T|o1:T)
logpÎ³1:T(w1:T,x1:T,o1:T)
qÎ³1:T(x1:T,w1:T|o1:T)
(44)
=EqÎ³1:T(x1:T,w1:T|o1:T)
logpÎ³1:T(o1:T|w1:T,x1:T).pÎ³1:T(w1:T,x1:T)
qÎ³1:T(x1:T,w1:T|o1:T)
(45)
â‰ˆEqÎ³1:T(x1:T,w1:T|o1:T)
logpÎ³1:T(o1:T|w1:T,x1:T)
(46)
=EqÎ³1:T(x1:T|w1:T).p(w1:T|o1:T)
logpÎ³1:T(o1:T|w1:T,x1:T)
(47)
â‰ˆ1
NNX
i=1logp(o1:T|x(i)
1:T,w(i)
1:T),x(i)
1:Tâˆ¼qÎ³1:T(x1:T|w(i)
1:T),w(i)
1:Tâˆ¼p(w1:T|o1:T) (48)
=1
NNX
i=1TX
t=1DoX
k=1o(k)
tlog 
dk(Ë†Âµ(i)
t|T)
+ 
1âˆ’o(k)
t
log(1âˆ’dk(Ë†Âµ(i)
t|T)) (49)
=L(o1:T). (50)
The inequality in (44) arises from the positivity of the Kullback-Leibler (KL) term. The approxima-
tion in (46) results from assuming equality between the prior and the approximated posterior, i.e.,
pÎ³1:T(w1:T,x1:T) =qÏ•(x1:T,w1:T|o1:T). Although it is feasible to optimize (44) directly, we found
out that by setting prior pÎ³1:T(x1:T,w1:T)equal to approximated posterior qÎ³1:T(x1:T,w1:T|o1:T),
more stable results with concise improvement are achieved from the numerical results (similar to
[19, 21, 43]). The approximation in (48) is because of Monte Carlo integration estimation.
A.4.3 Proof of theorem 3
First we provide a brief review on the GRU cell equations from [ 35]. Then we introduce two lemmas,
by which we can proof theorem 2.
GRU Cell Review. The GRU cell holds the following equations:
zt=Sigmoid (Uxzxt+Uzhtâˆ’1), (51)
rt=Sigmoid (Uxrxt+Urhtâˆ’1), (52)
ht=ztâŠ™htâˆ’1+ (1âˆ’zt)âŠ™Ë†ht, (53)
Ë†ht=tanh(Uxhxt+Uh(rtâŠ™htâˆ’1)) (54)
where xtandhtare the input and the hidden state vectors, respectively. Uxz,Uz,Uxr,Ur,Uxh
andUhare all weight matrices.
Lemma 1. A GRU cell has a fixed point at hâˆ—=0, if the input variable xt=0.
Proof. After substituting xt=0andhtâˆ’1=0into (51) and (52), the update gate ztand reset gate
rtare both1
2. Substituting these values along with x=0andhtâˆ’1=0into (54) gives the candidate
18state Ë†ht=0. Finally, substituting htâˆ’1=0,zt=1
2, and Ë†ht=0into (53) results in the new state
ht=0. Thus, ht=htâˆ’1=0, indicating that GRU has a fixed point hâˆ—=0.
Lemma 2. LetIbe an hÃ—hidentity matrix, Î»i(.)shows the i-th largest absolute eigenvalue,
andA=1
4Uh+1
2I. When the spectral radius |Î»1(A)|<1, a GRU cell with input xt=0. can be
approximated by the following linearized GRU near ht=0:
ht=Ahtâˆ’1 (55)
and the fixed point hâˆ—=0is locally stable.
Proof. By employing Taylor series expansion and linearizing htwith respect to htâˆ’1athtâˆ’1=
xt=0,Ain (55) is obtain as1
4Uh+1
2I. Then, from (55) we get that ht=Ath0. Since At
is dependent on the t-th powers of the eigenvalues of A, the behavior of the linearized GRU is
determined by the eigenvalues of A. According to the Hartman-Grobman theorem, the behavior of a
dynamical system near a hyperbolic fixed point is homeomorphic to the behavior of the linearized
system. Therefore, when |Î»1(A)|<1, the fixed point hâˆ—=0becomes a hyperbolic fixed point.
Thus, a GRU cell can be approximated as ht=Ath0. Then, local stability is determined by the
spectral radius |Î»1(A)|<1and then we have |htâˆ’h0|tâ†’âˆž=0and the fixed point hâˆ—=0is
locally stable.
Theorem 3. When Ïƒ1(Uh)<2, a GRU cell is locally stable at a fix point hâˆ—=0.
Proof. Relying on Lemma1 andLemma2 , we need to satisfy |Î»1(1
4Uh+1
2I)|<1.|Î»1(1
4Uh+
1
2I)|=|1
4Î»1(Uh) +1
2|due to the properties of eigenvalues. From the triangle inequality we also
have|1
4Î»1(Uh) +1
2| â‰¤1
4|Î»1(Uh)|+1
2. Using Weylâ€™s inequality for its singular and eigenvalues, we
have|Î»1(Uh)| â‰¤Ïƒ1(Uh)and therefore1
4|Î»1(Uh)|+1
2â‰¤1
4|Ïƒ1(Uh)|+1
2. Thus, we need to satisfy
1
4|Ïƒ1(Uh)|+1
2<1condition and conclude1
4|Î»1(Uh)|+1
2â‰¤1
4|Ïƒ1(Uh)|+1
2<1. This can be
achieved by Ïƒ1(Uh)<2.
The GRU cell is considered as a nonlinear dynamical system with Ë™ht=f(ht,xt)model, where one
can drive ffrom (51)-(54). We have shown the conditions for local stability of Ë™h=f(h,0)in the
last paragraph. Now we show Ë™h=f(h,x)is locally stable if xtâ†’0astâ†’ âˆž .
As we have the stability condition for Ë™h=f(h,0), there exists V(h)that is a Lyapunov function for
this system such that:
V(h)â‰¥0,and Ë™V(h) =dV
dh.f(h,0)â‰¤ âˆ’W(h) (56)
for a positive definite W(h). When the input variable xis not zero, the system equation becomes
Ë™h=f(h,x)and the derivative of V(h)becomes
Ë™V(h) =dV
dh.f(h,x) (57)
but for a small xt, we can write:
Ë™V(h)â‰¤ âˆ’W(h) +Ïµ, (58)
Ïµ=|dV
dh.(f(h,x)âˆ’f(h,0))| (59)
andÏµâ†’0asxtâ†’0, utilizing Taylor series expansion of f(h,x)nearx=0[44]. Then, as xtâ†’0,
for any Ïµâ‰¥0, there exists a Tsuch that for all tâ‰¥T,|xt|< Ïµand therefore we have:
Ë™V(h)â‰¤ âˆ’W(h) +Ïµ, (60)
for sufficiently small Ïµ,Ë™V(h)remains negative.
Therefore, we need to demonstrate that the inputs of the GRU cells in (6) and (8) approach 0as
tâ†’ âˆž . As discussed in the main script, we apply a Wishart prior distribution on the covariance
matrices, guiding them towards a scaled identity matrix. Over time, this scale diminishes towards
zero, causing the covariance matricesâ€”and consequently, the zero bias Conv( .)operators in (6) and
19(8)â€”to converge to 0astâ†’ âˆž . This implies that the system tends to behave deterministically
after prolonged observation, while the stability of the GRU cell is guaranteed. Informally, Theorem
3 requires us to asymptotically shrink the input covariance matrices of our GRU cells toward zero.
While this shrinkage is reasonable as we expect the system to behave deterministically in the long run,
it imposes a limitation on posterior inference. We acknowledge this as an open problem for future
research.
A.4.4 Proof of theorem 4
Theorem. The modified weight matrix Uhobtained from (iii) step above, is a solution of the following
optimization problem: minUh||Ë†Uhâˆ’Uh||2
F, s.t. Ïƒ1(Uh)<2âˆ’Î´.
Proof. Relying on [45], due to the matrices properties we have:
hX
i=1
Ïƒi(Ë†Uh)âˆ’Ïƒi(Uh)2â‰¤ ||Ë†Uhâˆ’Uh||2
F. (61)
Assuming that the first ssingular values of Ë†Uhare greater than 2, we havePh
i=1
Ïƒi(Ë†Uh)âˆ’
Ïƒi(Uh)
=Ps
i=1
Ïƒi(Ë†Uh)âˆ’(2âˆ’Î´)
. According to (61), we need to show thatPs
i=1
Ïƒi(Ë†Uh)âˆ’
(2âˆ’Î´)2is equal to its upper bound ||Ë†Uhâˆ’Uh||2
F, i.e. the optimum solution.
Using the singular value decomposition properties, we have ||Ë†Uhâˆ’Uh||2
F=||WÎ›V âˆ’WÎ›V||2
F=
||W(Î›âˆ’Î›)V||2
F=tr(Vâˆ—(Î›âˆ’Î›)Wâˆ—W(Î›âˆ’Î›)V) =tr(Vâˆ—(Î›âˆ’Î›)(Î›âˆ’Î›)V) =tr(VVâˆ—(Î›âˆ’
Î›)(Î›âˆ’Î›)) =tr((Î›âˆ’Î›)(Î›âˆ’Î›)) =Ps
i=1
Ïƒi(Ë†Uh)âˆ’(2âˆ’Î´)2.
A.4.5 Proof of theorem 5
Theorem. We can satisfy the constraint introduced in Theorem 3 by applying the Gershgorin circle
theorem as follows.
(i) In the i-th row of Ë†Uh, sum up the non diagonal elements as id=Ph
j=1,jÌ¸=i|Ë†Uh(i, j)|. Do (i) for
the all rows.
(ii) For each Ë†Uh(i, i)assign a circle cluster centered at Ë†Uh(i, i)withidradius in the complex plane.
(iii) Merge the clusters which have intersection and repeat step (iii) until no cluster can be merged
any more. Finally the set of clusters C={C1, ...,Ck}with length of kâ‰¤his obtained.
(iv) Define the radius of Cjcluster as dCj=max(Ë†Uh(i, i)+id|âˆ€Ë†Uh(i, i)âˆˆ Cj). Calculate the radius
of all kclusters in step (iv).
(v) For each cluster Cj, if(Ë†Uh(i, i) +dCj|âˆ€Ë†Uh(i, i)âˆˆ Cj)>2, shift Ë†Uh(i, i)â†(2âˆ’dCjâˆ’Î´)for
a small Î´. Otherwise, keep Ë†Uh(i, i)unchanged. Do step (v) for all clusters and their elements, i.e.
Ë†Uh(i, i).
These five steps, ensures the new Ë†Uhfollows the constraint introduced in Theorem 3 .
Proof. The five steps elaborated above are direct results of the generalized Gershgorin circle theorem.
This approach is faster than SVD method introduced in the paper, while it is not the best solution of
the optimization problem introduced in the Theorem 4 .
A.5 Discussion About KL Term of Mode Collapse
The term introduced in the mode collapse handling section is:
âˆ’KL 
pi(Ë‡F)||pj(Ë‡F).prij(Ë‡F)
+KL 
pi(Ë‡F)||prii(Ë‡F)
. (62)
Here pi(Ë‡F)âˆ¼ MN nÃ—n(Ë‡Fi,I,I)andpj(Ë‡F)âˆ¼ MN nÃ—n(Ë‡Fj,I,I), are matrix normal distribu-
tions with priors prii(Ë‡F)âˆ¼ MN nÃ—n(Diag(mi),I,I)andprij(Ë‡F)âˆ¼ MN nÃ—n(Diag(mj),I,I),
respectively. We can expand (62) as:
20=Z
pi(Ë‡F)
logpj(Ë‡F).prij(Ë‡F)
pi(Ë‡F)+ logpi(Ë‡F)
prii(Ë‡F)
dË‡F (63)
=Z
pi(Ë‡F)
logpj(Ë‡F).prij(Ë‡F)
prii(Ë‡F)
dË‡F (64)
=Z
pi(Ë‡F)
logpj(Ë‡F)
dË‡F+Z
pi(Ë‡F)
logprij(Ë‡F)
dË‡Fâˆ’Z
pi(Ë‡F)
logprii(Ë‡F)
dË‡F
(65)
Relying on [45], we can simplify each term in (65) as:
Z
pi(Ë‡F)
logpj(Ë‡F)
dË‡F=âˆ’1
2h 
vec(Ë‡Fi)âˆ’vec(Ë‡Fj)T 
vec(Ë‡Fi)âˆ’vec(Ë‡Fj)
+tr(I)i
+const
(66)
=âˆ’1
2||Ë‡Fiâˆ’Ë‡Fj||2
Fâˆ’1
2tr(I) +const (67)
Z
pi(Ë‡F)
logprij(Ë‡F)
dË‡F=âˆ’1
2h 
vec(Ë‡Fi)âˆ’vec(Diag(mj))T 
vec(Ë‡Fi)âˆ’vec(Diag(mj))
+tr(I)i
+const
(68)
=âˆ’1
2||Ë‡Fiâˆ’Diag(mj)||2
Fâˆ’1
2tr(I) +const (69)
Z
pi(Ë‡F)
logprij(Ë‡F)
dË‡F=âˆ’1
2h 
vec(Ë‡Fi)âˆ’vec(Diag(mi))T 
vec(Ë‡Fi)âˆ’vec(Diag(mi))
+tr(I)i
+const
(70)
=âˆ’1
2||Ë‡Fiâˆ’Diag(mi)||2
Fâˆ’1
2tr(I). (71)
Thus, we can rewrite (62) as:
1
2||Ë‡Fiâˆ’Diag(mi)||2
Fâˆ’1
2||Ë‡Fiâˆ’Diag(mj)||2
Fâˆ’1
2||Ë‡Fiâˆ’Ë‡Fj||2
Fâˆ’1
2tr(I) +const (72)
which is half of (12) plus a constant.
A.6 Noise Generation Process
In our experiments, we use a time-correlated noise generation scheme to demonstrate the systemâ€™s
noise robustness. This method introduces a sequence of factors, ft, of the same length as the
data sequence, making the noise factors correlated over time. Let f0âˆ¼ U(0,1)andft+1=
min(max(0, ft+rt),1)withrtâˆ¼ U(âˆ’0.2,0.2), where f0is the initialized factor and Uis the
uniform distribution. Two thresholds, t1âˆ¼ U(0,0.25)andt2âˆ¼ U(0.75,1), are defined. Values of ft
less than t1are set to 0, values greater than t2are set to 1, and the remaining values are linearly scaled
within the range [0,1]. The original observation at time t,ot, is then given by ot=ftit+(1âˆ’ft)ipn
t,
where itis the true image at time tandipn
tis the pure noise generated for time t.
A.7 Hyperparameters and training
In all experiments, we used the Adam optimizer [ 46] on an NVIDIA GeForce GTX 1050 Ti with
16GB RAM. To ensure optimal hyperparameters, we conducted a grid search. We searched for the
initial learning rate in the range of 0.001to0.2with increments of 0.005, selecting the one that
yielded the highest log-likelihood. We chose an initial learning rate of 0.006with an exponential
decay rate of 0.9every 10 epochs. Backpropagation through time [ 47] was employed to compute
gradients, given the use of GRU cells in our structure. The gradients are applied to GRU cells with
the constraint explained in theorem 3, where we use the spectral theorem mentioned in the main script
. We applied the layer normalization technique [ 48] to stabilize the dynamics within the recurrent
structure and normalize the filter response. The Elu + 1 activation function was used to ensure the
positivity of the diagonal elements of the process noise and covariance matrices.
21Dynamics 
Network
ð±0:ð‘‡âˆ’1|0:ð‘‡âˆ’1 Prediction(à· ð…1:ð‘‡,à·¡ð‡1:ð‘‡)
(à·ð1:ð‘‡|0:ð‘‡âˆ’1 ,à·¡ðšº1:ð‘‡|0:ð‘‡âˆ’1 )ðºð‘…ð‘ˆð¾ðºFiltering Stepð’“1:ð‘‡ ðŒ1:ð‘‡
ð’˜1:ð‘‡
(à·ð1:ð‘‡|1:ð‘‡ ,à·¡ðšº1:ð‘‡|1:ð‘‡ )Smoothing Step
ðºð‘…ð‘ˆð‘†ðº
(à·ð0:ð‘‡âˆ’1|0:ð‘‡âˆ’1 ,à·¡ðšº0:ð‘‡âˆ’1|0:ð‘‡âˆ’1 )ð1:ð‘‡
à·¡ð‡1:ð‘‡à· ð…1:ð‘‡(à·ð1:ð‘‡|ð‘‡ ,à·¡ðšº1:ð‘‡|ð‘‡ )
Encoderð’1:ð‘‡ PredictionFiltering
(ð’“1:ð‘‡,ð’˜1:ð‘‡)(à·ð1:ð‘‡|1:ð‘‡ ,à·¡ðšº1:ð‘‡|1:ð‘‡ )
Decoder{ð’1:ð‘‡ ,ð’”1:ð‘‡ }
Smoothing(à·ð1:ð‘‡|ð‘‡ ,à·¡ðšº1:ð‘‡|ð‘‡ )GIN Cell
Conv
2Dà·¡ðšº1:ð‘‡|0:ð‘‡âˆ’1 Conv
2D
(à·ð1:ð‘‡|0:ð‘‡âˆ’1 ,à·¡ðšº1:ð‘‡|0:ð‘‡âˆ’1 )à·¡ðšº1:ð‘‡|0:ð‘‡âˆ’1 
(à·ð1:ð‘‡|1:ð‘‡ ,à·¡ðšº1:ð‘‡|1:ð‘‡ )
(à·ð1:ð‘‡|0:ð‘‡âˆ’1 ,à·¡ðšº1:ð‘‡|0:ð‘‡âˆ’1 )Figure 9: Proposed detailed architecture.
To prevent the model from getting stuck in poor local minima, such as focusing excessively on
reconstruction rather than learning the dynamics obtained through filtering-smoothing, we find it
beneficial to employ two training techniques for end-to-end learning:
1-Generating time correlated noisy sequences as consecutive observations, forces the model to
learn the dynamics instead of focusing on reconstruction, e.g. figures 11 and 13 in appendix.
2-During the initial epochs, the system focuses on learning the auto-encoder and globally
learned parameters, such as Ë‡FkandË‡Hk, while excluding the Dynamic Net parameters
Î±t(xtâˆ’1). Afterwards, all parameters are jointly learned. This approach enables the system
to initially acquire good embeddings and meaningful latent vectors before integrating the
learning of Kdifferent dynamics variables.
In our experiments, we set K= 15 to accommodate the complexity of the latent space, with each
latent representing a unique dynamical scenario. Generally, parameter tuning is not challenging when
the GIN is sufficiently flexible, as it can learn to prune unused elements through the Dynamic Net .
A.8 Proposed architecture, qualitative comparison with the SOTA and empirical complexity
analysis
A.8.1 Architectures
The proposed detailed structure is shown in figure 9. To design the dynamic network, we use an MLP
with 60 hidden units and a ReLU activation function, and a softmax activation in the last layer. The
state mean, with a size of n, is the input to the dynamic network, which outputs kcoefficients. The
structures of the encoder and decoder are shown in Table 5. In this table, mrepresents the transferred
observation dimension, with various values considered in the results. For state estimation tasks, the
output size ( out) is 4, 4, 8 and 12 for the single-pendulum, bouncing ball, double-pendulum and
KITTI visual odometry experiments, respectively. For the imputation task, the number of hidden
units in the KG and SG networks is set to 40 and 30, respectively. The convolutional layer applied
over the covariance matrix has 8 filters with a kernel size of 5 and zero bias.
22Table 5: The structure of the encoder and decoder.
Encoder Decoder
ifstate estimation task :
6Ã—6Conv, 12, max pooling 2Ã—2, stride 2Ã—2 sÂµ: fully connected: out, linear activation
LayerNormalizer() sÎ£: fully connected, Elu + 1 zero bised
4Ã—4Conv, 12, max pooling 2Ã—2, stride 2Ã—2 ifimputation task :
LayerNormalizer() fully connected: 144
fully connected: 40 6Ã—6Trns Conv, 16, stride 4Ã—4
w: fully connected: m, linear activation LayerNormalizer()
r: fully connected, Elu + 1 activation 4Ã—4Trns Conv, 12, stride 2Ã—2
LayerNormalizer()
oi:1Ã—1Trns Conv, stride 1Ã—1, softmax
Gradient Explosion Experiment.
Referring to table 4, higher values of Î´deteriorate performance because the convergence speed of the
linearized GRU hidden state depends on Ïƒ1(Uh)(see Eq. (55) in the appendix), which is projected to
2âˆ’Î´. Therefore, longer time dependencies in the data are eliminated for high Î´. On the other hand,
smaller values of Î´close to zero make the model more prone to noise [ 10]. Therefore, it is necessary
to tune an appropriate Î´within the range 0< Î´ < 2, which is much easier than tuning the unbounded
Î¸.
A.8.2 Empirical running times and parameters
We present the number of parameters for the utilized cell structures in our experiments and their
corresponding empirical running times for 1 epoch in Table 6. In the first row of each model structure,
we set the number of parameters approximately equal to our GIN to demonstrate the GINâ€™s superior
performance with the same parameter count. The extra running time of EM-variational approaches,
like KV AE, is due to the use of classic Bayesian equations, which significantly increase running
time for higher-dimensional observations. However, the GIN avoids this issue. The number of
parameters in the GIN is noticeably lower than in other memory cells, such as LSTM and GRU,
and EM-variational methods. This efficiency is achieved by converting high-dimensional sparse
covariance matrices into lower-dimensional covariance matrices using a convolutional operator.
A.8.3 Qualitative comparison of the GIN to recent related work.
Switching Linear Dynamical System models (SLDS) decompose complex, nonlinear time series
data into sequences of simpler, reusable dynamical modes. Fitting an SLDS to data enables us to
learn a flexible nonlinear generative model and parse data sequences into coherent discrete units.
[9] is a SLDS model that incorporates additional latent variables to switch among different linear
dynamics. However, this approach relies on Gibbs sampling for inferring the parameters, rendering it
impractical for large datasets due to scalability issues.
Auto-regressive state space models (ARSSMs) are a class of dynamic models commonly used in time
series analysis and forecasting. In these models, the evolution of a system over time is described by
a set of states, by observing all data. Auto-Regressive (AR) Hidden Markov Models (AR-HMM)
explain time series structures by defining a mapping from past observations to the current observation.
[39] presents an ARHMM approach where target values are used directly as inputs. However, this
reliance on target values makes the model more susceptible to noise.
Toward learning state space (system identification), a number of works including those by [ 49â€“
53] have proposed algorithms for learning Gaussian Process SSMs (GPSSMs) through maximum
likelihood estimation using the iterative EM algorithm. where filtering-smoothing with a set of fixed
parameters Î³is conducted (E step), and then updating the set of parameters Î³is performed such that
the obtained likelihood is maximized (M step). Frigola et al. [ 51] obtain sample trajectories from the
smoothing distribution and then, conditioned on this trajectory, conduct the M step for the modelâ€™s
parameters. In the context of System Identification (SI), the GIN is akin to a Hammerstein-Wiener
(HW) model [ 34], as it estimates system parameters directly from observations while transferring the
observations through nonlinear functions.
23Table 6: Empirical running times and parameters of experiments.
CellSingle Pend Double Pend Bouncing Ball Visual Odometry
Param T/E Param T/E Param T/E Param T/E
LSTM ( n=25) âˆ¼18k âˆ¼56s âˆ¼18k âˆ¼56s âˆ¼18k âˆ¼53s âˆ¼45k âˆ¼83s
LSTM ( n=50) âˆ¼36k âˆ¼70s âˆ¼36k âˆ¼71s âˆ¼36k âˆ¼68s âˆ¼70k âˆ¼95s
LSTM ( n=100) âˆ¼76k âˆ¼98s âˆ¼76k âˆ¼96s âˆ¼76k âˆ¼93s âˆ¼120k âˆ¼131s
GRU ( n=30) âˆ¼18k âˆ¼61s âˆ¼18k âˆ¼62s âˆ¼18k âˆ¼59s âˆ¼42k âˆ¼79s
GRU ( n=50) âˆ¼27k âˆ¼65s âˆ¼27k âˆ¼67s âˆ¼27k âˆ¼64s âˆ¼53k âˆ¼84s
GRU ( n=100) âˆ¼57k âˆ¼86s âˆ¼57k âˆ¼85s âˆ¼57k âˆ¼84s âˆ¼90k âˆ¼111s
V AE ( n=40) âˆ¼12k âˆ¼50s âˆ¼13k âˆ¼52s âˆ¼12k âˆ¼49s âˆ¼29k âˆ¼70s
IWV AE ( n=40) âˆ¼13k âˆ¼50s âˆ¼13k âˆ¼54s âˆ¼11k âˆ¼47s âˆ¼30k âˆ¼75s
V AE-RNN ( n=40) âˆ¼24k âˆ¼59s âˆ¼25k âˆ¼61s âˆ¼24k âˆ¼57s âˆ¼49k âˆ¼89s
SV AE ( n=40) âˆ¼27k âˆ¼67s âˆ¼27k âˆ¼69s âˆ¼26k âˆ¼65s âˆ¼68k âˆ¼149s
KV AE ( n=40) âˆ¼25k âˆ¼95s âˆ¼25k âˆ¼97s âˆ¼25k âˆ¼94s âˆ¼62k âˆ¼141s
KV AE ( n=60) âˆ¼36k âˆ¼114s âˆ¼36k âˆ¼111s âˆ¼36k âˆ¼115s âˆ¼80k âˆ¼165s
EKV AE ( n=40) âˆ¼26k âˆ¼98s âˆ¼26k âˆ¼99s âˆ¼26k âˆ¼94s âˆ¼65k âˆ¼145s
EKV AE ( n=60) âˆ¼37k âˆ¼116s âˆ¼38k âˆ¼113s âˆ¼35k âˆ¼112s âˆ¼83k âˆ¼170s
MKV AE ( n=40) âˆ¼34k âˆ¼112s âˆ¼34k âˆ¼110s âˆ¼33k âˆ¼105s âˆ¼77k âˆ¼153s
RKN ( n=100) âˆ¼25k âˆ¼57s âˆ¼25k âˆ¼58s âˆ¼25k âˆ¼56s âˆ¼45k âˆ¼79s
CRU ( n=100) âˆ¼24k âˆ¼55s âˆ¼24k âˆ¼55s âˆ¼23k âˆ¼54s âˆ¼46k âˆ¼78s
Encode-Decoder ( n=30) âˆ¼10k âˆ¼45s âˆ¼10k âˆ¼44s âˆ¼9k âˆ¼44s âˆ¼21k âˆ¼63s
LGSSM ( n=30) âˆ¼12k âˆ¼82s âˆ¼12k âˆ¼84s âˆ¼12k âˆ¼80s âˆ¼30k âˆ¼117s
LGSSM ( n=45) âˆ¼15k âˆ¼98s âˆ¼15k âˆ¼97s âˆ¼15k âˆ¼97s âˆ¼36k âˆ¼136s
GIN ( n=30) âˆ¼18k âˆ¼55s âˆ¼18k âˆ¼55s âˆ¼18k âˆ¼54s âˆ¼42k âˆ¼80s
GIN ( n=45) âˆ¼25k âˆ¼59s âˆ¼25k âˆ¼58s âˆ¼25k âˆ¼57s âˆ¼48k âˆ¼83s
In Table 7, we compare various algorithms to evaluate their ability to handle high-dimensional
observations, learn dynamics, estimate state accurately, provide uncertainty estimates while handling
noisy data, manage missing data, and perform direct optimization. Classic LGSSMs, such as the EKF
and UKF, rely on the linearization of transition and emission equations and apply classic Bayesian
updates over the linearized system with respect to the states. In other words, classic LGSSMs are
model-based. In contrast, the GIN uses a data-driven network to learn parameters, offering a different
approach from the traditional model-based methods.
Table 7: Learning the parameters in LGSSM is shown with Ã—/âœ“because general LGSSMs, e.g.
UKF and EKF, are not able to learn the parameters. However, in our setting and parameterization we
use a data driven-based network for obtaining (F,H)to make LGSSMs comparable with the GIN
for high dimensional observation experiments.
Model high-d learn dynamics missing-imputation state est uncertainty noise handling dir opt
LSTM [26] âœ“ âœ“ âœ“ âœ“ Ã— âœ“ âœ“
GRU [27] âœ“ âœ“ âœ“ âœ“ Ã— âœ“ âœ“
P2T [54] âœ“ âœ“ Ã— âœ“ Ã— Ã— âœ“
E2C [16] âœ“ âœ“ Ã— Ã— âœ“ Ã— Ã—
BB-VI [55] Ã— âœ“ âœ“ Ã— âœ“ âœ“ Ã—
SIN [13] âœ“ âœ“ âœ“ Ã— âœ“ âœ“ Ã—
DVBF [56] âœ“ âœ“ âœ“ Ã— âœ“ âœ“ Ã—
VSMC [57] âœ“ âœ“ âœ“ Ã— âœ“ âœ“ Ã—
DSA [20] âœ“ âœ“ Ã— Ã— âœ“ Ã— Ã—
KV AE [19] Ã— âœ“ âœ“ âœ“ âœ“ âœ“ Ã—
EKV AE [21] Ã— âœ“ âœ“ âœ“ âœ“ âœ“ Ã—
MV AE [23] Ã— âœ“ âœ“ âœ“ âœ“ âœ“ Ã—
rSLSD [9] Ã— Ã— Ã— âœ“ âœ“ Ã— Ã—
DeepAR [39] Ã— âœ“ Ã— âœ“ âœ“ Ã— âœ“
DSSM [58] Ã— âœ“ Ã— âœ“ âœ“ Ã— âœ“
HybridGNN [59] Ã— Ã— âœ“ âœ“ Ã— âœ“ âœ“
KalmanNet [30] Ã— Ã— âœ“ âœ“ Ã— âœ“ âœ“
SSI [31] Ã— Ã— âœ“ âœ“ âœ“ âœ“ âœ“
LGSSM Ã— Ã— /âœ“ âœ“ âœ“ âœ“ âœ“ âœ“
GIN âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“
24A.9 Visualization and The Imputation
Graphical results of informed, uninformed and noisy observations for image imputation task for both
single and double pendulum experiments can be found in 10, 11, 12 and 13 figures. Inference for the
trained smoothing distribution of all experiments are in 14, 15, 16, , 17, 18, 19, 20, 21, 22, 23 and
24 figures, where we generated samples from the smoothing estimated states distribution, (st|o1:T).
Then we fit density on the generated samples. This visualization shows the effectiveness of the GIN
in reducing the uncertainty of the estimates compare to LGSSM and KV AE.
25Ground Truth
Observed Sequence
LGSSM(filter)
LGSSM(smooth)
GIN(filter)
GIN(smooth)
Ground Truth
Observed Sequence
LGSSM(filter)
LGSSM(smooth)
GIN(filter)
GIN(smooth)
Figure 10: Informed(left column) and uninformed(right column) image imputation task for the single
pendulum experiments.
Figure 11: Image imputation task for the single pendulum experiment exposed to the noisy observa-
tions, where the generated noise has correlation with the time. Each figure, beginning from top to
bottom, indicates the ground truth, noisy observation and the imputation results of the GIN.
26Ground Truth
Observed Sequence
LGSSM(filter)
LGSSM(smooth)
GIN(filter)
GIN(smooth)
Ground Truth
Observed Sequence
LGSSM(filter)
LGSSM(smooth)
GIN(filter)
GIN(smooth)
Figure 12: Informed(left column) and uninformed(right column) image imputation task for the double
pendulum experiments.
Figure 13: Image imputation task for the double pendulum experiment exposed to the noisy observa-
tions, where the generated noise has correlation with the time. Each figure, beginning from top to
bottom, indicates the ground truth, noisy observation and the imputation results of the GIN.
27GIN LGSSM KVAE0.20.40.60.81.01.2s1p(gt1100)=(s10.7)
mean=0.69
mean=0.93
mean=0.53
Figure 14: Inference for the single pendulum s1position at 100-th time step. Generated samples from
smoothened distribution, (s1100|o1:150), trained by the GIN, LGSSM and KV AE, respectively. The
dashed red line p(gt1100)is the ground truth state with distribution of Î´(s1100âˆ’0.7). We calculate the
sample mean and fit a distribution on the samples for further visualization and comparison purpose.
GIN LGSSM KVAE0.20.40.60.81.01.2s2p(gt2100)=(s20.7)
mean=0.73
mean=0.91
mean=0.42
Figure 15: Inference for the single pendulum s2position at 100-th time step. Generated samples
from smoothened distribution, (s2100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
à¬µà¬´à¬´ à¬µà¬´à¬´
(a) GIN
à¬µà¬´à¬´ à¬µà¬´à¬´ (b) LGSSM
à¬µà¬´à¬´ à¬µà¬´à¬´ (c) KV AE
Figure 16: Generated samples from the trained smoothened joint distribution of the single pendulum
position, (s1, s2), at 100-th time step for the GIN, LGSSM and KV AE, respectively. The ground
truth is shown with a black point.
28GIN LGSSM KVAE0.2
0.00.20.40.60.8s1p(gt1100)=(s10.35)
mean=0.36
mean=0.38
mean=0.44
Figure 17: Inference for the double pendulum s1position at 100-th time step. Generated samples
from smoothened distribution, (s1100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
The dashed red line p(gt1100)is the ground truth state with distribution of Î´(s1100âˆ’0.35).
GIN LGSSM KVAE0.2
0.00.20.40.60.8s2p(gt2100)=(s20.35)
mean=0.38
mean=0.28
mean=0.29
Figure 18: Inference for the double pendulum s2position at 100-th time step. Generated samples
from smoothened distribution, (s2100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
The dashed red line p(gt2100)is the ground truth state with distribution of Î´(s2100âˆ’0.35).
à¬µà¬´à¬´ à¬µà¬´à¬´
(a) GIN
à¬µà¬´à¬´ à¬µà¬´à¬´ (b) LGSSM
à¬µà¬´à¬´ à¬µà¬´à¬´ (c) KV AE
Figure 19: Generated samples from the trained smoothened joint distribution of the double pendulum
first joint position, (s1, s2), at 100-th time step for the GIN, LGSSM and KV AE, respectively. The
ground truth is shown with a black point.
29GIN LGSSM KVAE0.60.81.01.21.4s3p(gt3100)=(s31)
mean=1.0
mean=0.94
mean=0.96
Figure 20: Inference for the double pendulum s3position at 100-th time step. Generated samples
from smoothened distribution, (s3100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
The dashed red line p(gt3100)is the ground truth state with distribution of Î´(s3100âˆ’1).
GIN LGSSM KVAE0.4
0.2
0.00.20.4s4p(gt4100)=(s4)
mean=-0.01
mean=0.08
mean=0.1
Figure 21: Inference for the double pendulum s4position at 100-th time step. Generated samples
from smoothened distribution, (s4100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
à¬µà¬´à¬´ à¬µà¬´à¬´
(a) GIN
à¬µà¬´à¬´ à¬µà¬´à¬´ (b) LGSSM
à¬µà¬´à¬´ à¬µà¬´à¬´ (c) KV AE
Figure 22: Generated samples from the trained smoothened joint distribution of the double pendulum
second joint position, (s3, s4), at 100-th time step for the GIN, LGSSM and KV AE, respectively.
The ground truth is shown with a black point.
3060.0
57.5
55.0
52.5
50.0
47.5
45.0
42.5
40.0
s1p(gt1100)=(s1+50)
100|500=-50.12
100|500=-52.25
100|500=-43.99
GIN LGSSM KVAE0.02.55.07.510.012.515.017.520.0s2
p(gt1100)=(s110)
100|500=10.08
100|500=12.86
100|500=8.46
Figure 23: Inference for the visual odometry s1ands2positions at 100-th time step. Generated
samples from smoothened distribution, (s1100, s2100|o1:500), trained by the GIN, LGSSM and
KV AE, respectively. The dashed red line p(gt1100, gt2100)is the ground truth state with distribution
of(Î´(s1100+ 50) , Î´(s2100âˆ’10)).
A.10 MSE Results for The State Estimation and Estimated KG-SG
The MSE results for the single pendulum, double pendulum, and bouncing ball experiments are
shown in Tables 8 and 9 and 10. In addition to the dynamics equation (5), where the Ë†Fmatrix includes
the effects of the process noise, two other solutions introduced in Section 5 are included in the MSE
results. Parameterizing the process noise as in (24) with a GRU cell is indicated by GRU( Q), while
another parameterization, shown as MLP( Q), is done using (26).
31à¬µà¬´à¬´ à¬µà¬´à¬´(a) GIN
à¬µà¬´à¬´ à¬µà¬´à¬´ (b) LGSSM
à¬µà¬´à¬´ à¬µà¬´à¬´ (c) KV AE
Figure 24: Generated samples from the trained smoothened joint distribution of the visual odometry
joint position, (s1, s2), at 100-th time step for the GIN, LGSSM and KV AE, respectively. The ground
truth is shown with a black point.
A.11 Algorithms and python inference code
Algorithm Training the GIN
Input: Observations o1:T, last posteriors (Ë†Âµ0:Tâˆ’1|0:Tâˆ’1,Ë†Î£0:Tâˆ’1|0:Tâˆ’1)
(x0:Tâˆ’1|0:Tâˆ’1)=Sample ((Ë†Âµ0:Tâˆ’1|0:Tâˆ’1,Ë†Î£0:Tâˆ’1|0:Tâˆ’1))
Î±1:T=Dynamic Net (x0:Tâˆ’1|0:Tâˆ’1)
Obtain Ë†F1:TandË†H1:Tby (5)
(Ë†Âµ1:T|0:Tâˆ’1,Ë†Î£1:T|0:Tâˆ’1)=Prediction (Ë†Âµ0:Tâˆ’1|0:Tâˆ’1,Ë†Î£0:Tâˆ’1|0:Tâˆ’1,Ë†F1:T)
(w1:T,r1:T)=encoder (o1:T)
Ë†K1:T=Ë†Î£1:T|0:Tâˆ’1Ë†H1:TM1:TMT
1:T,M1:T=GRUKG(Conv(Ë†Î£1:T|0:Tâˆ’1),r1:T)
Ë†J1:T=Ë†Î£1:T|1:TË†FT
1:TN1:TNT
1:T,N1:T=GRUSG(Conv(Ë†Î£1:T|0:Tâˆ’1))
(Ë†Âµ1:T|1:T,Ë†Î£1:T|1:T)=Filtering (Ë†Âµ1:T|0:Tâˆ’1,Ë†Î£1:T|0:Tâˆ’1,Ë†K1:T,w1:T,Ë†H1:T)
(Ë†Âµ1:T|T,Ë†Î£1:T|T)=Smoothing (Ë†Âµ1:T|1:T,Ë†Î£1:T|1:T,Ë†J1:T,Ë†F1:T)
if(image imputation) then
o1:T=decoder (Ë†Âµ1:T|T,Ë†Î£1:T|T)
L(o1:T)= Lower bound likelihood (o1:T)by using (10)
end if
if(state estimation) then
s1:T=decoder (Ë†Âµ1:T|T,Ë†Î£1:T|T)
L(s1:T|o1:T)= Lower bound likelihood (s1:T)by using (11)
end if
Backward Propagation by updating GRU cells with the steps in Theorem 3 orTheorem 4 .
32Table 8: MSE for single pendulum experiment.
Model MSE
LSTM (units = 25, m= 15 ) 0.092 Â±0.003
LSTM (units = 25, m= 20 ) 0.092 Â±0.005
LSTM (units = 25, m= 40 ) 0.090 Â±0.005
LSTM (units = 100, m= 15 ) 0.089 Â±0.002
LSTM (units = 100, m= 20 ) 0.089 Â±0.005
LSTM (units = 100, m= 40 ) 0.090 Â±0.004
GRU (units = 30, m= 15 ) 0.095 Â±0.006
GRU (units = 30, m= 20 ) 0.093 Â±0.002
GRU (units = 30, m= 40 ) 0.094 Â±0.005
GRU (units = 100, m= 15 ) 0.091 Â±0.002
GRU (units = 100, m= 20 ) 0.092 Â±0.004
GRU (units = 100, m= 40 ) 0.091 Â±0.008
Model Ë†F(Q) MLP(Q) GRU( Q)
LGSSM filter( m= 15 ,n= 30 ,K= 10 ) 0.089 Â±0.009 0.088 Â±0.005 0.088 Â±0.006
LGSSM filter( m= 15 ,n= 30 ,K= 15 ) 0.088 Â±0.011 0.087 Â±0.007 0.086 Â±0.004
LGSSM filter( m= 15 ,n= 45 ,K= 10 ) 0.085 Â±0.004 0.084 Â±0.007 0.084 Â±0.009
LGSSM filter( m= 15 ,n= 45 ,K= 15 ) 0.084 Â±0.005 0.083 Â±0.004 0.082 Â±0.004
LGSSM filter( m= 20 ,n= 40 ,K= 10 ) 0.084 Â±0.009 0.082 Â±0.014 0.082 Â±0.011
LGSSM filter( m= 20 ,n= 40 ,K= 15 ) 0.083 Â±0.012 0.081 Â±0.005 0.080 Â±0.014
LGSSM filter( m= 20 ,n= 60 ,K= 10 ) 0.079 Â±0.005 0.078 Â±0.012 0.076 Â±0.009
LGSSM filter( m= 20 ,n= 60 ,K= 15 ) 0.077 Â±0.006 0.075 Â±0.011 0.074 Â±0.008
LGSSM smooth( m= 15 ,n= 30 ,K= 10 ) 0.086 Â±0.011 0.083 Â±0.004 0.084 Â±0.007
LGSSM smooth( m= 15 ,n= 30 ,K= 15 ) 0.085 Â±0.012 0.084 Â±0.008 0.083 Â±0.012
LGSSM smooth( m= 15 ,n= 45 ,K= 10 ) 0.081 Â±0.008 0.080 Â±0.009 0.079 Â±0.003
LGSSM smooth( m= 15 ,n= 45 ,K= 15 ) 0.081 Â±0.014 0.078 Â±0.007 0.077 Â±0.011
LGSSM smooth( m= 20 ,n= 40 ,K= 10 ) 0.082 Â±0.005 0.078 Â±0.004 0.076 Â±0.013
LGSSM smooth( m= 20 ,n= 40 ,K= 15 ) 0.080 Â±0.003 0.076 Â±0.006 0.074 Â±0.010
LGSSM smooth( m= 20 ,n= 60 ,K= 10 ) 0.076 Â±0.008 0.073 Â±0.002 0.070 Â±0.009
LGSSM smooth( m= 20 ,n= 60 ,K= 15 ) 0.073 Â±0.013 0.071 Â±0.011 0.068 Â±0.013
GIN filter( m= 15 ,n= 30 ,K= 10 ) 0.078 Â±0.013 0.076 Â±0.005 0.075 Â±0.004
GIN filter( m= 15 ,n= 30 ,K= 15 ) 0.078 Â±0.014 0.075 Â±0.009 0.074 Â±0.012
GIN filter( m= 15 ,n= 45 ,K= 10 ) 0.074 Â±0.010 0.073 Â±0.008 0.072 Â±0.009
GIN filter( m= 15 ,n= 45 ,K= 15 ) 0.073 Â±0.015 0.074 Â±0.011 0.071 Â±0.005
GIN filter( m= 20 ,n= 40 ,K= 10 ) 0.072 Â±0.005 0.072 Â±0.008 0.070 Â±0.002
GIN filter( m= 20 ,n= 40 ,K= 15 ) 0.071 Â±0.007 0.071 Â±0.004 0.071 Â±0.009
GIN filter( m= 20 ,n= 60 ,K= 10 ) 0.067 Â±0.009 0.066 Â±0.005 0.065 Â±0.006
GIN filter( m= 20 ,n= 60 ,K= 15 ) 0.065 Â±0.013 0.064 Â±0.009 0.063 Â±0.010
GIN smooth( m= 15 ,n= 30 ,K= 10 ) 0.071 Â±0.007 0.070 Â±0.003 0.068 Â±0.009
GIN smooth( m= 15 ,n= 30 ,K= 15 ) 0.070 Â±0.008 0.068 Â±0.011 0.068 Â±0.007
GIN smooth( m= 15 ,n= 45 ,K= 10 ) 0.065 Â±0.011 0.065 Â±0.009 0.064 Â±0.012
GIN smooth( m= 15 ,n= 45 ,K= 15 ) 0.064 Â±0.008 0.066 Â±0.007 0.063 Â±0.009
GIN smooth( m= 20 ,n= 40 ,K= 10 ) 0.064 Â±0.005 0.065 Â±0.003 0.062 Â±0.008
GIN smooth( m= 20 ,n= 40 ,K= 15 ) 0.063 Â±0.004 0.064 Â±0.011 0.063 Â±0.007
GIN smooth( m= 20 ,n= 60 ,K= 10 ) 0.059 Â±0.009 0.061 Â±0.012 0.057 Â±0.006
GIN smooth( m= 20 ,n= 60 ,K= 15 ) 0.058 Â±0.005 0.057 Â±0.009 0.056 Â±0.004
33Table 9: MSE for double pendulum experiment.
Model MSE
LSTM (units = 50, m= 15 ) 0.172 Â±0.012
LSTM (units = 50, m= 20 ) 0.166 Â±0.009
LSTM (units = 50, m= 40 ) 0.167 Â±0.011
LSTM (units = 100, m= 15 ) 0.164 Â±0.006
LSTM (units = 100, m= 20 ) 0.162 Â±0.009
LSTM (units = 100, m= 40 ) 0.159 Â±0.010
GRU (units = 50, m= 15 ) 0.194 Â±0.014
GRU (units = 50, m= 20 ) 0.189 Â±0.013
GRU (units = 50, m= 40 ) 0.188 Â±0.015
GRU (units = 100, m= 15 ) 0.173 Â±0.009
GRU (units = 100, m= 20 ) 0.169 Â±0.014
GRU (units = 100, m= 40 ) 0.166 Â±0.018
Model Ë†F(Q) MLP(Q) GRU( Q)
LGSSM filter( m= 15 ,n= 30 ,K= 10 ) 0.154 Â±0.013 0.159 Â±0.021 0.153 Â±0.009
LGSSM filter( m= 15 ,n= 30 ,K= 15 ) 0.152 Â±0.008 0.153 Â±0.010 0.152 Â±0.012
LGSSM filter( m= 15 ,n= 45 ,K= 10 ) 0.144 Â±0.011 0.141 Â±0.015 0.139 Â±0.013
LGSSM filter( m= 15 ,n= 45 ,K= 15 ) 0.142 Â±0.007 0.138 Â±0.012 0.137 Â±0.017
LGSSM filter( m= 20 ,n= 40 ,K= 10 ) 0.144 Â±0.012 0.137 Â±0.009 0.138 Â±0.013
LGSSM filter( m= 20 ,n= 40 ,K= 15 ) 0.141 Â±0.007 0.137 Â±0.008 0.136 Â±0.016
LGSSM filter( m= 20 ,n= 60 ,K= 10 ) 0.129 Â±0.009 0.126 Â±0.014 0.122 Â±0.015
LGSSM filter( m= 20 ,n= 60 ,K= 15 ) 0.127 Â±0.012 0.124 Â±0.013 0.119 Â±0.009
LGSSM smooth( m= 15 ,n= 30 ,K= 10 ) 0.147 Â±0.009 0.148 Â±0.014 0.144 Â±0.015
LGSSM smooth( m= 15 ,n= 30 ,K= 15 ) 0.146 Â±0.014 0.146 Â±0.013 0.142 Â±0.017
LGSSM smooth( m= 15 ,n= 45 ,K= 10 ) 0.139 Â±0.017 0.136 Â±0.009 0.133 Â±0.017
LGSSM smooth( m= 15 ,n= 45 ,K= 15 ) 0.137 Â±0.009 0.135 Â±0.017 0.133 Â±0.012
LGSSM smooth( m= 20 ,n= 40 ,K= 10 ) 0.136 Â±0.014 0.131 Â±0.022 0.132 Â±0.011
LGSSM smooth( m= 20 ,n= 40 ,K= 15 ) 0.134 Â±0.011 0.129 Â±0.014 0.129 Â±0.022
LGSSM smooth( m= 20 ,n= 60 ,K= 10 ) 0.123 Â±0.019 0.116 Â±0.016 0.115 Â±0.013
LGSSM smooth( m= 20 ,n= 60 ,K= 15 ) 0.120 Â±0.010 0.112 Â±0.009 0.108 Â±0.014
GIN filter( m= 15 ,n= 30 ,K= 10 ) 0.126 Â±0.014 0.125 Â±0.012 0.125 Â±0.011
GIN filter( m= 15 ,n= 30 ,K= 15 ) 0.124 Â±0.015 0.124 Â±0.019 0.121 Â±0.009
GIN filter( m= 15 ,n= 45 ,K= 10 ) 0.115 Â±0.011 0.114 Â±0.015 0.110 Â±0.017
GIN filter( m= 15 ,n= 45 ,K= 15 ) 0.114 Â±0.019 0.112 Â±0.020 0.110 Â±0.011
GIN filter( m= 20 ,n= 40 ,K= 10 ) 0.113 Â±0.013 0.111 Â±0.009 0.111 Â±0.013
GIN filter( m= 20 ,n= 40 ,K= 15 ) 0.111 Â±0.009 0.109 Â±0.018 0.108 Â±0.009
GIN filter( m= 20 ,n= 60 ,K= 10 ) 0.099 Â±0.018 0.094 Â±0.017 0.095 Â±0.021
GIN filter( m= 20 ,n= 60 ,K= 15 ) 0.097 Â±0.009 0.093 Â±0.009 0.091 Â±0.008
GIN smooth( m= 15 ,n= 30 ,K= 10 ) 0.115 Â±0.011 0.116 Â±0.009 0.113 Â±0.017
GIN smooth( m= 15 ,n= 30 ,K= 15 ) 0.113 Â±0.015 0.113 Â±0.018 0.112 Â±0.014
GIN smooth( m= 15 ,n= 45 ,K= 10 ) 0.105 Â±0.009 0.101 Â±0.014 0.101 Â±0.015
GIN smooth( m= 15 ,n= 45 ,K= 15 ) 0.102 Â±0.013 0.100 Â±0.011 0.098 Â±0.008
GIN smooth( m= 20 ,n= 40 ,K= 10 ) 0.101 Â±0.008 0.098 Â±0.010 0.094 Â±0.015
GIN smooth( m= 20 ,n= 40 ,K= 15 ) 0.098 Â±0.017 0.095 Â±0.014 0.092 Â±0.007
GIN smooth( m= 20 ,n= 60 ,K= 10 ) 0.086 Â±0.013 0.081 Â±0.008 0.079 Â±0.009
GIN smooth( m= 20 ,n= 60 ,K= 15 ) 0.083 Â±0.009 0.079 Â±0.006 0.076 Â±0.013
34Table 10: MSE for bouncing ball experiment.
Model MSE
LSTM (units = 50, m= 15 ) 3.724 Â±0.195
LSTM (units = 50, m= 20 ) 3.698 Â±0.127
LSTM (units = 50, m= 40 ) 3.684 Â±0.152
LSTM (units = 100, m= 15 ) 3.476 Â±0.191
LSTM (units = 100, m= 20 ) 3.39 Â±0.282
LSTM (units = 100, m= 40 ) 3.28 Â±0.249
GRU (units = 50, m= 15 ) 3.941 Â±0.378
GRU (units = 50, m= 20 ) 3.725 Â±0.491
GRU (units = 50, m= 40 ) 3.65 Â±0.454
GRU (units = 100, m= 15 ) 3.631 Â±0.392
GRU (units = 100, m= 20 ) 3.512 Â±0.466
GRU (units = 100, m= 40 ) 3.389 Â±0.286
Model Ë†F(Q) MLP(Q) GRU( Q)
LGSSM filter( m= 15 ,n= 30 ,K= 10 ) 0.559 Â±0.057 0.557 Â±0.039 0.543 Â±0.049
LGSSM filter( m= 15 ,n= 30 ,K= 15 ) 0.552 Â±0.051 0.547 Â±0.019 0.531 Â±0.047
LGSSM filter( m= 15 ,n= 45 ,K= 10 ) 0.541 Â±0.044 0.543 Â±0.042 0.524 Â±0.061
LGSSM filter( m= 15 ,n= 45 ,K= 15 ) 0.539 Â±0.051 0.538 Â±0.042 0.519 Â±0.039
LGSSM filter( m= 20 ,n= 40 ,K= 10 ) 0.542 Â±0.072 0.536 Â±0.029 0.518 Â±0.050
LGSSM filter( m= 20 ,n= 40 ,K= 15 ) 0.524 Â±0.049 0.537 Â±0.061 0.522 Â±0.037
LGSSM filter( m= 20 ,n= 60 ,K= 10 ) 0.517 Â±0.047 0.524 Â±0.029 0.514 Â±0.060
LGSSM filter( m= 20 ,n= 60 ,K= 15 ) 0.529 Â±0.034 0.517 Â±0.039 0.512 Â±0.024
LGSSM smooth( m= 15 ,n= 30 ,K= 10 ) 0.485 Â±0.029 0.483 Â±0.019 0.475 Â±0.028
LGSSM smooth( m= 15 ,n= 30 ,K= 15 ) 0.476 Â±0.036 0.479 Â±0.051 0.458 Â±0.026
LGSSM smooth( m= 15 ,n= 45 ,K= 10 ) 0.479 Â±0.042 0.471 Â±0.045 0.468 Â±0.058
LGSSM smooth( m= 15 ,n= 45 ,K= 15 ) 0.462 Â±0.039 0.473 Â±0.041 0.471 Â±0.024
LGSSM smooth( m= 20 ,n= 40 ,K= 10 ) 0.469 Â±0.021 0.475 Â±0.043 0.451 Â±0.034
LGSSM smooth( m= 20 ,n= 40 ,K= 15 ) 0.461 Â±0.029 0.465 Â±0.037 0.455 Â±0.027
LGSSM smooth( m= 20 ,n= 60 ,K= 10 ) 0.460 Â±0.038 0.452 Â±0.014 0.442 Â±0.058
LGSSM smooth( m= 20 ,n= 60 ,K= 15 ) 0.448 Â±0.027 0.452 Â±0.020 0.444 Â±0.019
GIN filter( m= 15 ,n= 30 ,K= 10 ) 0.267 Â±0.028 0.264 Â±0.027 0.258 Â±0.034
GIN filter( m= 15 ,n= 30 ,K= 15 ) 0.265 Â±0.021 0.260 Â±0.020 0.251 Â±0.014
GIN filter( m= 15 ,n= 45 ,K= 10 ) 0.264 Â±0.024 0.259 Â±0.023 0.244 Â±0.019
GIN filter( m= 15 ,n= 45 ,K= 15 ) 0.259 Â±0.019 0.260 Â±0.029 0.245 Â±0.018
GIN filter( m= 20 ,n= 40 ,K= 10 ) 0.255 Â±0.011 0.250 Â±0.018 0.239 Â±0.051
GIN filter( m= 20 ,n= 40 ,K= 15 ) 0.256 Â±0.029 0.243 Â±0.034 0.237 Â±0.016
GIN filter( m= 20 ,n= 60 ,K= 10 ) 0.247 Â±0.043 0.240 Â±0.018 0.231 Â±0.028
GIN filter( m= 20 ,n= 60 ,K= 15 ) 0.244 Â±0.050 0.241 Â±0.031 0.231 Â±0.037
GIN smooth( m= 15 ,n= 30 ,K= 10 ) 0.148 Â±0.011 0.146 Â±0.012 0.139 Â±0.014
GIN smooth( m= 15 ,n= 30 ,K= 15 ) 0.145 Â±0.008 0.145 Â±0.031 0.133 Â±0.017
GIN smooth( m= 15 ,n= 45 ,K= 10 ) 0.140 Â±0.015 0.139 Â±0.008 0.130 Â±0.028
GIN smooth( m= 15 ,n= 45 ,K= 15 ) 0.133 Â±0.011 0.134 Â±0.024 0.129 Â±0.015
GIN smooth( m= 20 ,n= 40 ,K= 10 ) 0.121 Â±0.014 0.118 Â±0.008 0.110 Â±0.016
GIN smooth( m= 20 ,n= 40 ,K= 15 ) 0.115 Â±0.012 0.117 Â±0.009 0.106 Â±0.014
GIN smooth( m= 20 ,n= 60 ,K= 10 ) 0.115 Â±0.013 0.110 Â±0.018 0.099 Â±0.008
GIN smooth( m= 20 ,n= 60 ,K= 15 ) 0.112 Â±0.010 0.106 Â±0.012 0.094 Â±0.011
35To demonstrate the simplicity of our proposed GIN, we include intuitive inference code with Ten-
sorflow library. The code runs with Python 3.6+. The entire code to reproduce the experiments are
available in Github repository.
A.11.1 Python intuitive code.
1# Inference with !
2
3import tensorflow . keras as k
4import Prediction
5import Filtering
6import Smoothing
7import DynamicsNetwork
8import Encoder
9import Decoder
10import DataGen
11
12class GIN_CELL (k. layers . Layer ):
13 def __init__ (self , initial_states ):
14 self . mu_tm1_filt , self . Sigma_tm1_filt = initial_states
15 self . filter_states = [[ self . mu_tm1_filt , self . Sigma_tm1_filt ]]
16 def call (self , inputs ):
17 w_1 :T, r_1:T = inputs
18 for w_t , r_t in (w_1:T, r_1:T):
19 x_tm1_filt = sample ( self . mu_tm1_filt , self . Sigma_tm1_filt )
20 F_hat_t , H_hat_t = DynamicsNetwork ( x_tm1_filt )
21 mu_t_pri , Sigma_t_pri = Prediction ( F_hat_t , H_hat_t ,...
22 self . mu_tm1_filt , self . Sigma_tm1_filt )
23 mu_t_filt , Sigma_t_filt = Filtering ( mu_t_pri ,...
24 Sigma_t_pri , w_t , r_t , H_hat_t )
25 self . filter_states . append ([ mu_t_filt , Sigma_t_filt ])
26 self . mu_tm1_filt = x_t_filt
27 self . Sigma_tm1_filt = Sigma_t_filt
28 mu_1 : T_smooth , Sigma_1 : T_smooth = Smoothing ( F_hat_1 :T ,...
29 self . filter_states , Sigma_1 :T_pri ,)
30 return mu_1 : T_smooth , Sigma_1 : T_smooth
31
32class GIN (k. models . Model ):
33 def __init__ (self , initial_states ):
34 self . mu_0_filt , self . Sigma_0_filt = initial_states
35 self . GIN_CELL_OBJ = self . GIN_CELL ( self . x_0_filt , self .
Sigma_0_filt )
36 self . Encoder = Encoder
37 self . Decoder = Decoder
38
39 def call (self , o_1 :T):
40 w_1 :T, r_1:T = self . Encoder (o_1:T)
41 mu_1 : T_smooth , Sigma_1 : T_smooth = self . GIN_CELL_OBJ (w_1 :T, r_1
:T)
42 o_1 :T, s_1:T = self . Decoder ( mu_1 : T_smooth , Sigma_1 : T_smooth )
43 return o_1:T, s_1:T
44
45initial_states = mu_0_filt , Sigma_0_filt
46GIN_OBJ =GIN( initial_states )
47
48Data = DataGen ()
49o_1 :T, s_1:T = GIN_OBJ ( Data )
36NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: The claims we have made in abstract and introduction are elaborated and
achieved in the main paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss the limitations and assumptions necessary for Theorems 3 and
4. In the appendix, where we provide the proofs, we reiterate the requirements that the
algorithm must meet.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: The proofs of the mentioned theorems and mathematical claims are all provided
in appendix section. In the main text, we refer the readers to the proofs after introducing
each theorem-claim.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: All the required information for running the experiments are provided in the
supplementary materials and anonymous github repository.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide instructions to synthesis the data and run the experiments. All
details are provided in anonymous github repository.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We provide a detailed section in appendix to argue about network architecture,
hyper parameter optimization, experiment setting, etc.. This addresses the question you
asked.
Guidelines:
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
37Justification: We include confidence interval in our numerical experiments to show the
reliability of the results. Initialization approaches are explained with details in the main
script.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We provide detailed configuration of our machines for running the experiments.
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We are following all the ethics provided by NeurIPS.
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: We believe this work does not have negative impact on the social communities.
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: The paper does not use existing assets.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification:
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
38