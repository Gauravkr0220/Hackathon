An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side
Pre-trained Generator to Clients in Heterogeneous Federated Learning
Jianqing Zhang1*, Yang Liu2,3â€ , Yang Hua4, Jian Cao1,5â€ 
1Shanghai Jiao Tong University2Institute for AI Industry Research (AIR), Tsinghua University
3Shanghai Artificial Intelligence Laboratory4Queenâ€™s University Belfast
5Shanghai Key Laboratory of Trusted Data Circulation and Governance in Web3
tsingz@sjtu.edu.cn, liuy03@air.tsinghua.edu.cn, y.hua@qub.ac.uk, cao-jian@sjtu.edu.cn
Abstract
Heterogeneous Federated Learning (HtFL) enables col-
laborative learning on multiple clients with different model
architectures while preserving privacy. Despite recent re-
search progress, knowledge sharing in HtFL is still difficult
due to data and model heterogeneity. To tackle this issue, we
leverage the knowledge stored in public pre-trained genera-
tors and propose a new upload-efficient knowledge transfer
scheme called Federated Knowledge-Transfer Loop ( Fed-
KTL ). Our FedKTL can produce client-task-related proto-
typical image-vector pairs via the generatorâ€™s inference on
the server. With these pairs, each client can transfer pre-
existing knowledge from the generator to its local model
through an additional supervised local task. We conduct
extensive experiments on four datasets under two types of
data heterogeneity with 14 kinds of models including CNNs
and ViTs. Results show that our upload-efficient FedKTL
surpasses seven state-of-the-art methods by up to 7.31%
in accuracy. Moreover, our knowledge transfer scheme is
applicable in scenarios with only one edge client. Code:
https://github.com/TsingZ0/FedKTL
1. Introduction
Recently, there has been a growing trend for companies to
develop custom models tailored to their specific needs [3,
11, 15, 18, 50]. However, the problem of insufficient data
has persistently plagued model training in specific fields,
such as medicine [1, 4, 43]. Federated Learning (FL) is a
popular approach to tackle this problem by training models
collaboratively among multiple clients ( e.g., companies or
edge devices) while preserving privacy on clients [19, 28].
Traditional FL (tFL) focuses on training a global model for
all clients and is unable to fulfill clientsâ€™ personalized needs
due to data heterogeneity among clients [20, 29]. Conse-
quently, personalized FL (pFL) has emerged as a solution
to train customized models for each client [30, 58, 67, 69].
*Work done during internship at AIR.
â€ Corresponding authors.However, most pFL methods still assume homogeneous
client models [30, 67, 69], which may not adequately cater
to the specific needs of companies and individuals [61].
Besides, as the size of the model increases, both tFL and
pFL incur significant communication costs when transmit-
ting model parameters [76]. Furthermore, exposing clientsâ€™
model parameters also raises privacy and intellectual prop-
erty (IP) concerns [27, 55, 63, 70]. Recently, Heterogeneous
Federated Learning (HtFL) frameworks have been proposed
to consider both data and model heterogeneity [52, 61]. It
explores novel knowledge-sharing schemes that go beyond
sharing the entire client models.
Most existing HtFL methods adopt knowledge distilla-
tion (KD) techniques [13] and design various knowledge-
sharing frameworks based on a global dataset [36, 64], a
global auxiliary model [57, 71], or global class-wise pro-
totypes [52, 53, 70]. However, global datasetsâ€™ availabil-
ity and quality as well as their relevance to clientsâ€™ tasks
significantly impact the effectiveness of KD [65]. Directly
replacing the global dataset with a pre-trained generator
has a minimal impact since most generators are pre-trained
to generate unlabeled data within the domain of their pre-
training data [21, 22]. As for the global auxiliary model,
it introduces a substantial communication overhead due to
the need to transmit it in each communication iteration.
Although sharing class-wise prototypes is communication-
efficient, they can only carry limited global knowledge to
clients, which is insufficient for clientsâ€™ model training
needs. Furthermore, the prototypes extracted by heteroge-
neous models are biased, hindering the attainment of uni-
formly separated global prototypes on the server [70].
Thus, we propose an upload-efficient knowledge transfer
scheme called Federated Knowledge-Transfer Loop ( Fed-
KTL ), which takes advantage of the compactness of pro-
totypes and the pre-existing knowledge from a server-side
public pre-trained generator. FedKTL can (1) use the gen-
erator on the server to produce a handful of global proto-
typical image-vector pairs tailored to clientsâ€™ tasks, and (2)
transfer pre-existing common knowledge from the genera-
tor to each client model via an additional supervised local
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
12109
(a) Valid vecs
 (b) Random vecs
 (c) Prototypes
 (d) Aligned vecs
Figure 1. The images ( 64Ã—64) generated by StyleGAN-XL [48]
with different kinds of inputs. â€œvecsâ€ is short for vectors.
task using these image-vector pairs. We develop FedKTL
by addressing the following three questions. Q1:How to
upload unbiased prototypes while maintaining upload effi-
ciency? Q2 (the core challenge) :How to adapt any given
pre-trained generator to clientsâ€™ tasks without fine-tuning
it?Q3:How to transfer the generatorâ€™s knowledge to client
models regardless of the semantics of the generated images?
For Q1, inspired by FedETF [33], we replace each
clientâ€™s classifier with an ETF (equiangular tight frame)
classifier [33, 59] to let clients generate unbiased proto-
types. Then, we upload these unbiased prototypes to the
server for efficiency. For Q2, we align the domain formed
by prototypes with the generatorâ€™s inherent valid latent do-
main to generate informative images, as these two domains
are not naturally aligned . As shown in Fig. 1, the generator
can generate clear images given valid vectors. However, it
tends to generate blurry and uninformative images given in-
valid latent vectors (such as random vectors or prototypes).
To generate prototype-induced clear images, we propose a
lightweight trainable feature transformer on the server to
convert prototypes to aligned vectors within the valid input
domain, while preserving the class-wise discrimination rel-
evant to clientsâ€™ classification tasks. For Q3, we first aggre-
gate aligned vectors for each class to obtain latent centroids
and generate corresponding images to form image-vector
pairs. Then we conduct an additional supervised local task
to only enhance the client modelâ€™s feature extraction ability
using these pairs, thereby reducing the semantic relevance
requirements between the generated images and local data.
We evaluate our FedKTL via extensive experiments on
four datasets with two types of data heterogeneity and 14
model architectures using a StyleGAN [21â€“23, 48] or a Sta-
ble Diffusion [45] on the server. Our FedKTL can outper-
form seven state-of-the-art methods by at most 7.31% in ac-
curacy. We also show that FedKTL is upload-efficient and
one prototypical image-vector pair per class is sufficient for
knowledge transfer, which only demands minimal inference
of the generator on the server in each iteration.
2. Related Work
2.1. Heterogeneous Federated Learning (HtFL)
HtFL offers the advantage of preserving both privacy and
model IP while catering to personalized model architecturerequirements [10, 52, 61]. In terms of the level of model
heterogeneity, we classify existing HtFL methods into three
categories: group heterogeneity, partial heterogeneity, and
full heterogeneity.
Group-heterogeneity-based HtFL methods distribute
multiple groups of homogeneous models to clients, consid-
ering their diverse communication and computing capabil-
ities [8, 36]. They typically form groups by sampling sub-
models from a server model [8, 14, 56]. In this paper, we
do not consider this kind of model heterogeneity due to IP
protection concerns and client customization limitations.
Partial-heterogeneity-based HtFL methods ,e.g., LG-
FedAvg [35], FedGen [75], and FedGH [61], allow the main
parts of the clientsâ€™ models to be heterogeneous but assume
the remaining (small) parts to be homogeneous. However,
clients can only access limited global knowledge through
the small global part. Despite training a global represen-
tation generator, FedGen primarily utilizes it to introduce
global knowledge for the small classifier rather than the re-
maining main part ( i.e., the feature extractor). Therefore,
the data insufficiency problem still exists for the main part.
Full-heterogeneity-based HtFL methods do not impose
restrictions on the architectures of client models. Classic
KD-based HtFL approaches [26, 62] share model outputs
on a global dataset. However, obtaining such a dataset can
be difficult in practice [65]. Instead of relying on a global
dataset, FML [49] and FedKD [57] utilize mutual distilla-
tion [73] between a small auxiliary global model and client
models. However, in the early iterations when both the aux-
iliary model and client models have poor performance, there
is a risk of transferring uninformative knowledge between
each other [34]. Another approach is to share class proto-
types, like FedDistill [17], FedProto [52], and FedPCL [53].
However, the phenomenon of classifier bias has been ex-
tensively observed in FL when dealing with heterogeneous
data [33, 38]. The bias becomes more pronounced when
both the models and the data exhibit heterogeneity, leading
to biased prototypes, thereby posing challenges in aggregat-
ing class-wise global knowledge [70].
2.2. ETF Classifier
When training a model on balanced data reaches its termi-
nal stage, the neural collapse [42] phenomenon occurs. In
this phenomenon, prototypes and the classifier vectors con-
verge to form a simplex ETF, where the vectors are normal-
ized, and the pairwise angles between them are maximized
and identical (balanced). Since a simplex ETF represents
an ideal classifier, some centralized methods [59, 60] pro-
pose generating a random simplex ETF matrix to replace
the original classifier and guiding the feature extractor train-
ing using the fixed ETF classifier in imbalanced scenarios.
To address the data heterogeneity issue in FL, FedETF [33]
also proposes to replace the original classifier for each client
12110
with a fixed ETF classifier. However, FedETF assumes
the presence of homogeneous models and follows FedAvg
to transfer global knowledge. Inspired by these methods,
we utilize the ETF classifier to enable heterogeneous client
models to generate unbiased prototypes and facilitate class-
wise global knowledge aggregation on the server.
3. Method
3.1. Preliminaries
Several concepts in various generators, such as Style-
GAN [21] and Stable Diffusion [45], share similarities
when generating contents, despite potential differences in
their nomenclature. Without loss of generality, we primar-
ily focus on introducing the generator components based on
StyleGANâ€™s architecture here for convenience. Most ex-
isting StyleGANs contain two components: a mapping net-
work Gmand a synthesis network Gs. The space formed by
the latent vectors between GmandGsis called â€œ Wspaceâ€.
Page 6ğºğºğ‘ ğ‘ 
ğ’˜ğ’˜âˆˆğ’²ğ’²ğğâˆ¼ğ’©ğ’©(0,1) ğºğºğ‘šğ‘š
ğºğºğ‘šğ‘š
Figure 2. An illustration of the generating process (from right to
left) when utilizing StyleGAN-XL as an example. The solid bor-
der ofGsandGmmeans â€œwith frozen parametersâ€.
In Fig. 2, we show an example of the StyleGAN-XL [48]
employed in our FedKTL. Given a vector Ïµ(typically a
normally distributed noise vector) as the input, it trans-
forms Ïµto a latent vector wâˆˆRHthrough Gm,i.e.,
w=Gm(Ïµ)âˆˆ W . Then, it generates an image Iby further
transforming wwithGs,i.e.,I=Gs(w).wis the only
factor that controls the content of I. While the valid vec-
tors in Wcan produce clear and informative images, not all
vectors in RHare valid and possess the same capability.
3.2. Problem Statement
In HtFL, one server and Nclients collaborate to train client
models for a multi-classification task of Cclasses. Client i
owns private data Diand builds its model gi(parameterized
byWi) with a customized architecture. Formally, the objec-
tive is min{Wi}N
i=1PN
i=1ni
nLi(Wi,Di), where ni=|Di|,
n=PN
i=1ni, and Liis the local loss function.
3.3. Our FedKTL
3.3.1 Overview
In Fig. 3a, we illustrate six key steps of the knowledge-
transfer loop in our proposed FedKTL framework. 1After
local training, each client generates class-wise prototypes.
2Each client uploads prototypes to the server. 3Theserver trains a feature transformer (denoted by Fwith pa-
rameter WF) to transform and align client prototypes to la-
tent vectors. 4With the trained F, the server first obtains
the class-wise latent centroid Â¯Q, which is the averaged la-
tent vectors within each class, and then generates images
DIby inputting Â¯QintoGs.5Each client downloads the
prototypical image-vector pairs {DI,Â¯Q}from the server.
6Each client locally trains giandhâ€²
iusingDi,DI, and
Â¯Q, where hâ€²
iis an additional linear projection layer (param-
eterized by Whâ€²
i) used to change the dimension of feature
representations. Notice that |Â¯Q|=|DI|=Câ‰ª |D i|.
3.3.2 ETF Classifier and Prototype Generation
The local loss Liconsists of two components: LA
i, which is
the loss corresponding to Di, and LM
i, which is the loss for
knowledge transfer using DIandÂ¯Q. For clarity, we only
describe LA
ihere and leave the details of LM
ito Sec. 3.3.4.
To address the biased prototype issue, inspired by
FedETF [33], we replace the original classifiers of given
model architectures with identical ETF classifiers and add
a linear projection layer (one Fully Connected (FC) layer)
hito the feature extractor fi. In this way, we encourage
each local model gito generate unbiased prototypes that are
aligned with the globally identical ETF classifier vectors. fi
andhihave parameters WfiandWhi, respectively. Thus,
we have gi=hiâ—¦fiandWi={Wfi,Whi}.
Specifically, we first synthesize a simplex ETF V=
[v1, . . . ,vC], where V=q
C
Câˆ’1U(ICâˆ’1
C1C1T
C)âˆˆ
RKÃ—Cand the dimension of the ETF space Kâ‰¥Câˆ’1.
âˆ€câˆˆ[C],vcâˆˆRKand the L2-norm ||vc||2= 1.Uallows
a rotation, UâˆˆRKÃ—C,UTU=IC,ICis an identity ma-
trix, and 1Cis a vector with all ones. Besides, âˆ€c1, c2âˆˆ[C]
andc1Ì¸=c2, we have cosÎ¸=âˆ’1
Câˆ’1, where Î¸is the angle
between vc1andvc2. Furthermore, Î¸is also the maximum
angle to equally separate Cvectors [33, 42, 59]. Then, we
distribute Vto all clients.
Next, for a given input xon client i, we compute logits
by measuring the cosine similarity [40] between gi(x)and
each vector in V. As the ArcFace loss [7] is popular for
enhancing supervised learning when using cosine similarity
for classification, we apply it during local training:
LA
i=E(x,y)âˆ¼Diâˆ’loges(cos ( Î¸y+m))
es(cos ( Î¸y+m))+PC
c=1,cÌ¸=yescosÎ¸c,
(1)
where Î¸yis the angle between gi(x)andvy,sandmare
the re-scale and additive hyperparameters [7], respectively.
After local training, we fix giand collect prototypes
Pi={Pc
i}câˆˆCiin the ETF space, where Ciis a set of class
labels on client i. Formally, Pc
i=E(x,c)âˆ¼Dc
igi(x)âˆˆRK,
where Dc
irefers to the subset of Dicontaining data points
12111
ğ¿ğ¿MMDğ¿ğ¿MSE â‘£Image Generation (inference)â‘¢Domain Alignment
ğºğºğ‘ ğ‘ Server
ğ‘“ğ‘“ğ‘–ğ‘–ğ¿ğ¿ğ‘–ğ‘–ğ‘€ğ‘€
ğ¿ğ¿ğ‘–ğ‘–ğ´ğ´
ğ‘“ğ‘“ğ‘–ğ‘–â‘¥Local Training
â‘ Prototype Calculation (inference)Client ğ’Šğ’Šğ’˜ğ’˜
ğğâˆ¼ğ’©ğ’©(0,1)
ğ‘“ğ‘“ğ‘—ğ‘—ğ¿ğ¿ğ‘—ğ‘—ğ‘€ğ‘€
ğ¿ğ¿ğ‘—ğ‘—ğ´ğ´
ğ‘“ğ‘“ğ‘—ğ‘—â‘¥Local Training
â‘ Prototype Calculation (inference)Client ğ’‹ğ’‹
â€¦â‘¡Upload â‘¤Downloadğºğºğ‘šğ‘š ğ¹ğ¹ğ¹ğ¹
â„ğ‘–ğ‘–â€²
â„ğ‘–ğ‘–
â„ğ‘–ğ‘–â„ğ‘—ğ‘—â€²
â„ğ‘—ğ‘—
â„ğ‘—ğ‘—ğ’Ÿğ’Ÿğ‘–ğ‘–
ğ’Ÿğ’Ÿğ‘–ğ‘–ğ’Ÿğ’Ÿğ‘—ğ‘—
ğ’Ÿğ’Ÿğ‘—ğ‘—ğ’Ÿğ’Ÿğ¼ğ¼ğ’Ÿğ’Ÿğ¼ğ¼
ğ’Ÿğ’Ÿğ¼ğ¼Recall 
ğ’¬ğ’¬
ğ’«ğ’«ï¿½ğ’¬ğ’¬
ğ’«ğ’« ï¿½ğ’¬ğ’¬
ğ’Ÿğ’Ÿğ¼ğ¼
â‘¤Downloadğ’Ÿğ’Ÿğ¼ğ¼
â‘¡Upload(a) The framework of our FedKTL in one communication iteration for HtFL.
Page 7Recall 
FC
BN
FCReLU(b) The feature transformer ( F).
Page 7
ğ¾ğ¾=2
ğ»ğ»=3ğ‘„ğ‘„ğ‘–ğ‘–ğ‘ğ‘=ğ¹ğ¹(ğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘ğ‘)ğ‘ƒğ‘ƒğ‘˜ğ‘˜1
ğ’²ğ’²ğ‘ƒğ‘ƒğ‘—ğ‘—1
ğ‘ƒğ‘ƒğ‘–ğ‘–1 ğ‘ƒğ‘ƒğ‘—ğ‘—3ğ‘ƒğ‘ƒğ‘–ğ‘–3
ğ‘ƒğ‘ƒğ‘˜ğ‘˜3ğ‘ƒğ‘ƒğ‘˜ğ‘˜2ğ‘ƒğ‘ƒğ‘–ğ‘–2
ğ‘„ğ‘„ğ‘˜ğ‘˜1ğ‘„ğ‘„ğ‘—ğ‘—1
ğ‘„ğ‘„ğ‘–ğ‘–1
ğ‘„ğ‘„ğ‘˜ğ‘˜3ğ‘„ğ‘„ğ‘–ğ‘–3
ğ‘„ğ‘„ğ‘—ğ‘—3ğ‘„ğ‘„ğ‘–ğ‘–2
ğ‘„ğ‘„ğ‘˜ğ‘˜2
(c) A domain alignment example.
Figure 3. An example of our FedKTL for a 3-class classification task. (a) Rounded and slender rectangles denote models and represen-
tations, respectively; dash-dotted and solid borders denote updating and frozen components, respectively; the segmented circle represents
the ETF classifier. (b) The feature transformer ( F) contains two FC layers and one Batch Normalization [16] (BN) layer. (c) An example
of the domain alignment step with K= 2andH= 3; one cluster represents one class. Best viewed in color.
belonging to class c. Uploading Pito the server only re-
quires |Ci| Ã—Kelements to communicate, where |Ci| â‰¤C.
3.3.3 Domain Alignment and Image Generation
For simplicity, we assume full client participation here, al-
though FedKTL supports partial participation. With clientsâ€™
prototypes P={Pc
i}iâˆˆ[N],câˆˆCion the server, we devise
a trainable feature transformer F(see Fig. 3b) to convert
Pinto valid latent vectors Q={Qc
i}iâˆˆ[N],câˆˆCi, where
Qc
i=F(Pc
i)âˆˆRH, inWspace. To maintain Qâ€™s rela-
tionship with clientsâ€™ classification tasks, we first preserve
Qâ€™s class-wise discrimination by training Fwith
LMSE=1
CCX
c=11
|Mc|X
iâˆˆMcâ„“(F(Pc
i),Qc), (2)
where Mcis the client set owning class c, the global
class-wise centroid Qc=1
|Mc|P
jâˆˆMcF(Pc
j), and â„“is
the Mean Squared Error (MSE) [54] between two vectors.
Then, we use the Maximum Mean Discrepancy (MMD)
loss [31] to align the domain formed by Qwith the valid
input domain of GsinW:
LMMD=||EQâˆ¼QÏ•(Q)âˆ’Ewâˆ¼WÏ•(w)||2
H. (3)
wis randomly sampled using Gm,Ï•is a feature map in-
duced by a kernel function Îº,i.e.,Îº(a,b) =âŸ¨Ï•(a), Ï•(b)âŸ©,
andHis a reproducing kernel Hilbert space [31, 37]. Wecombine these two losses to form the server loss L=
LMMD+Î»LMSE, where Î»is a hyper-parameter. We show
a domain alignment example in Fig. 3c.
After training Fon the server, we generate one image
per class by inputting global centroids Â¯Q={Qc}C
c=1into
Gs, so only Ctimes of inference for Gsis required in each
iteration. Formally, we generate DI={Ic}C
c=1, where
Ic=Gs(Qc), and distribute paired class-wise DIandÂ¯Q
to clients for additional local supervised learning.
3.3.4 Transferring Pre-existing Global Knowledge
Then, client iconducts local training with the integrated lo-
cal loss Li=LA
i+ÂµLM
i, where Âµis a hyper-parameter.
LM
iis the additional supervised task to transfer pre-existing
knowledge from the generator and inject common and
shared information into the feature extractor. Formally,
LM
i=1
CCX
c=1â„“(hâ€²
i(fi(Ic)),Qc), (4)
where hâ€²
iis a linear projection layer that outputs vectors
with dimension H. Since DIandÂ¯Qare the output-input
pairs of Gsand serve as the input-output pairs for hâ€²
iâ—¦fi, we
can transfer common knowledge from Gstohâ€²
iâ—¦fi. Since
hâ€²
iis mainly used for dimension transformation rather than
knowledge learning, we initialize Whâ€²
iin an identical way
for all clients in each iteration, which does not introduce ad-
ditional communication costs. This approach minimizes the
12112
biased knowledge acquired by hâ€²
iand facilitates the transfer
of common knowledge from Gstofi.
3.3.5 Privacy-Preserving Discussion
Our FedKTL preserves privacy in three folds. (1) We in-
troduce an identical ETF classifier for all clients to generate
unbiased prototypes, which contain little private informa-
tion. (2) The generated images belong to the generatorâ€™s
inherent output domain, so they are much different from the
clientâ€™s local data (see Fig. 4). (3) We keep all the model
parameters locally on clients without sharing. See the Ap-
pendix for further analysis and experimental results.
4. Experiments
4.1. Setup
Datasets and baseline methods. In this paper, we evalu-
ate our FedKTL on four image datasets, i.e., Cifar10 [25],
Cifar100 [25], Tiny-ImageNet [5], and Flowers102 [41]
(8K images with 102 classes). Besides, we compare Fed-
KTL with seven state-of-the-art HtFL methods, including
LG-FedAvg [35], FedGen [75], FedGH [61], FML [49],
FedKD [57], FedDistill [17], and FedProto [52].
Model heterogeneity scenarios. LG-FedAvg, FedGen,
and FedGH assume the classifier to be homogeneous. Un-
less explicitly specified, we consider model heterogeneity
for the main model part, i.e., using Heterogeneous Fea-
ture Extractors (HtFE), for a fair comparison. Specifically,
we denote the model heterogeneity scenarios by â€œHtFE Xâ€,
where the suffix number Xrepresents the degree of model
heterogeneity, and we utilize a total of Xmodel architec-
tures in HtFL. The larger the Xis, the more heteroge-
neous the scenario is. Given Nclients, we distribute the
(imod X)th model architecture to client i, iâˆˆ[N]and
reinitialize its parameters. For instance, we use HtFE 8by
default, which includes eight model architectures: 4-layer
CNN [39], GoogleNet [51], MobileNet v2 [47], ResNet18,
ResNet34, ResNet50, ResNet101, and ResNet152 [12].
The model architectures in HtFE 8cover both small and
large models. The feature dimensions Kâ€²before classi-
fiers are different in these model architectures, which cannot
meet the assumptions of FedGH, FedKD, and FedProto, so
we add an average pooling layer [51] before classifiers and
setKâ€²= 512 by default for all model architectures.
Data heterogeneity. Following prior arts [39, 67, 75] in
the FL field, we consider two data heterogeneity scenarios,
including the pathological setting [52, 68, 70] and the prac-
tical setting [53, 66, 69]. In the pathological setting, follow-
ing FedALA [69], we assign unbalanced data of 2/10/10/20
classes to each client from a total of 10/100/102/200
classes from Cifar10/Cifar100/Flowers102/Tiny-ImageNet
datasets without overlap. As for the practical setting, fol-lowing GPFL [67], we assign a proportion qc,iof data from
a subset that contains all the data belonging to class cin a
public dataset to client i, where qc,iâˆ¼Dir(Î²),Dir(Î²)is
Dirichlet distribution and Î²is typically set to 0.1 [36].
General Implementation Details. We combine the above
model and data heterogeneity to simulate HtFL scenarios.
Besides, we split the local data into a training set and a test
set with a ratio of 3:1 following [68, 69]. The performance
of clientsâ€™ models is assessed using their respective test sets,
and these results ( e.g., test accuracy) are then averaged to
gauge the performance of an HtFL method. Following Fe-
dAvg, we set the client batch size to 10 and run one training
epoch with SGD [72], i.e.,âŒŠni
10âŒ‹SGD steps, on the client
in each iteration. Besides, we set the client learning rate
Î·c= 0.01and the total communication iterations to 1000.
We run three trials and report the mean and standard devi-
ation of the numerical results. We simulate HtFL scenarios
on 20 clients with a client participation ratio Ï= 1, and we
experiment on 50, 100, and 200 clients with Ï= 0.5.
Implementation Details for Our FedKTL. We set Âµ=
50,Î»= 1,K=C,Î·S= 0.01,BS= 100 , and ES= 100
by default on all tasks, where Î·S,BS, andESrepresent the
learning rate, batch size, and number of epochs for training
Fon the server. Besides, we use Adam [24] for Ftraining
following FedGen and set s= 64 andm= 0.5following
ArcFace loss [7]. By default, we use a public pre-trained
StyleGAN-XL [48] as the server-side generator (not used
during clientsâ€™ inference), which is one of the latest Style-
GANs. It has approximately 0.13 billion model parameters
and is trained on a large-scale ImageNet dataset [6] to gen-
erate images with a resolution of 64Ã—64. To ensure compat-
ibility with clientsâ€™ models, we rescale the generated images
on the server to match the resolution of clientsâ€™ data before
downloading them. See the Appendix for the experiments
using Stable Diffusion or only one edge client.
4.2. Performance Comparison
We show the test accuracy of all the methods on four
datasets in Tab. 1, where FedKTL achieves superior per-
formance than baselines in HtFL scenarios. Specifically,
our FedKTL outperforms counterparts by up to 5.40% in
test accuracy on Cifar100 in the practical setting. Be-
sides, our FedKTL demonstrates greater superiority in
the practical setting compared to the pathological set-
ting. The number of generated images in DIequals
the number of classes C, so|DI|is 10/100/102/200 for
Cifar10/Cifar100/Flowers102/Tiny-ImageNet. Even with
only 10 images in DI, our FedKTL can still perform ex-
cellently on Cifar10 in two data heterogeneous settings.
4.3. Impact of Model Heterogeneity
We further assess FedKTL on the other five scenarios with
incremental model heterogeneity. Specifically, we con-
12113
Settings Pathological Setting Practical Setting
Datasets Cifar10 Cifar100 Flowers102 Tiny-ImageNet Cifar10 Cifar100 Flowers102 Tiny-ImageNet
LG-FedAvg 86.82Â±0.26 57.01 Â±0.66 58.88 Â±0.28 32.04 Â±0.17 84.55Â±0.51 40.65 Â±0.07 45.93 Â±0.48 24.06 Â±0.10
FedGen 82.83Â±0.65 58.26 Â±0.36 59.90 Â±0.15 29.80 Â±1.11 82.55Â±0.49 38.73 Â±0.14 45.30 Â±0.17 19.60 Â±0.08
FedGH 86.59Â±0.23 57.19 Â±0.20 59.27 Â±0.33 32.55 Â±0.37 84.43Â±0.31 40.99 Â±0.51 46.13 Â±0.17 24.01 Â±0.11
FML 87.06Â±0.24 55.15 Â±0.14 57.79 Â±0.31 31.38 Â±0.15 85.88Â±0.08 39.86 Â±0.25 46.08 Â±0.53 24.25 Â±0.14
FedKD 87.32Â±0.31 56.56 Â±0.27 54.82 Â±0.35 32.64 Â±0.36 86.45Â±0.10 40.56 Â±0.31 48.52 Â±0.28 25.51 Â±0.35
FedDistill 87.24Â±0.06 56.99 Â±0.27 58.51 Â±0.34 31.49 Â±0.38 86.01Â±0.31 41.54 Â±0.08 49.13 Â±0.85 24.87 Â±0.31
FedProto 83.39Â±0.15 53.59 Â±0.29 55.13 Â±0.17 29.28 Â±0.36 82.07Â±1.64 36.34 Â±0.28 41.21 Â±0.22 19.01 Â±0.10
FedKTL 88.43Â±0.13 62.01 Â±0.28 64.72 Â±0.62 34.74 Â±0.17 87.63Â±0.07 46.94 Â±0.23 53.16 Â±0.08 28.17 Â±0.18
Table 1. The test accuracy (%) on four datasets in the pathological and practical settings using HtFE 8.
Settings Different Degrees of Model Heterogeneity Large Client Amount ( Ï= 0.5)
HtFE 2 HtFE 3 HtFE 4 HtFE 9 HtM 10 50 Clients 100 Clients 200 Clients
LG-FedAvg 46.61Â±0.24 45.56 Â±0.37 43.91 Â±0.16 42.04 Â±0.26 â€” 37.81Â±0.12 35.14 Â±0.47 27.93 Â±0.04
FedGen 43.92Â±0.11 43.65 Â±0.43 40.47 Â±1.09 40.28 Â±0.54 â€” 37.95Â±0.25 34.52 Â±0.31 28.01 Â±0.24
FedGH 46.70Â±0.35 45.24 Â±0.23 43.29 Â±0.17 43.02 Â±0.86 â€” 37.30Â±0.44 34.32 Â±0.16 29.27 Â±0.39
FML 45.94Â±0.16 43.05 Â±0.06 43.00 Â±0.08 42.41 Â±0.28 39.87 Â±0.09 38.47Â±0.14 36.09 Â±0.28 30.55 Â±0.52
FedKD 46.33Â±0.24 43.16 Â±0.49 43.21 Â±0.37 42.15 Â±0.36 40.36 Â±0.12 38.25Â±0.41 35.62 Â±0.55 31.82 Â±0.50
FedDistill 46.88Â±0.13 43.53 Â±0.21 43.56 Â±0.14 42.09 Â±0.20 40.95 Â±0.04 38.51Â±0.36 36.06 Â±0.24 31.26 Â±0.13
FedProto 43.97Â±0.18 38.14 Â±0.64 34.67 Â±0.55 32.74 Â±0.82 36.06 Â±0.10 33.03Â±0.42 28.95 Â±0.51 24.28 Â±0.46
FedKTL 48.06Â±0.19 49.83 Â±0.44 47.06 Â±0.21 50.33 Â±0.35 45.84 Â±0.15 43.16Â±0.82 39.73 Â±0.87 34.24 Â±0.45
Table 2. The test accuracy (%) on Cifar100 in the practical setting with different degrees of model heterogeneity or large client amounts.
sider HtFE 2, HtFE 3, HtFE 4, HtFE 9, and HtM 10. HtFE 2
includes 4-layer CNN and ResNet18. HtFE 3includes
ResNet10 [74], ResNet18, and ResNet34. HtFE 4includes
4-layer CNN, GoogleNet, MobileNet v2, and ResNet18.
HtFE 9includes ResNet4, ResNet6, and ResNet8 [74],
ResNet10, ResNet18, ResNet34, ResNet50, ResNet101,
and ResNet152. HtM 10contains all the model architectures
in HtFE 8plus another two architectures ViT-B/16 [9] and
ViT-B/32 [9]. â€œHtMâ€ is short for heterogeneous models,
where classifiers are also heterogeneous. LG-FedAvg, Fed-
Gen, and FedGH are not applicable for HtM 10due to the
different classifier architectures of ResNets and ViTs. We
allocate model architectures in HtM 10to clients using the
method introduced for HtFE X. We show the test accuracy
in Tab. 2. For almost all the baselines, their performance de-
teriorates as model heterogeneity increases, resulting in an
accuracy drop of at least 3.53% from HtFE 2to HtFE 9. In
contrast, FedKTL attains its best performance with HtFE 9,
outperforming baselines by 7.31% .
4.4. Partial Participation with More Clients
To study the scalability of our FedKTL in HtFL settings
with more clients, we introduce three scenarios with 50,
100, and 200 clients on HtFE 8, respectively, by splitting the
Cifar100 dataset differently. With 200 participating clients,
each class has an average of only eight samples for training.We consider partial client participation and set Ï= 0.5in
each iteration in these three scenarios. Notice that compar-
ing the accuracy between these scenarios is unreasonable
because both the number of clients and the amount of client
data change when splitting Cifar100 into different numbers
of clientsâ€™ datasets. As shown in Tab. 2, our FedKTL main-
tains its superiority even with a large number of clients and
partial client participation.
4.5. Impact of Number of Client Training Epochs
E= 5 E= 10 E= 20
LG-FedAvg 40.33Â±0.15 40.46 Â±0.08 40.93 Â±0.23
FedGen 40.00Â±0.41 39.66 Â±0.31 40.07 Â±0.12
FedGH 41.09Â±0.25 39.87 Â±0.27 40.22 Â±0.41
FML 39.08Â±0.27 37.97 Â±0.19 36.02 Â±0.22
FedKD 41.06Â±0.13 40.36 Â±0.20 39.08 Â±0.33
FedDistill 41.02Â±0.30 41.29 Â±0.23 41.13 Â±0.41
FedProto 38.04Â±0.52 38.13 Â±0.42 38.74 Â±0.51
FedKTL 46.18Â±0.34 45.70 Â±0.27 45.57 Â±0.23
Table 3. The test accuracy (%) on Cifar100 in the practical setting
using HtFE 8with large E.
Training more epochs on clients before uploading can save
12114
communication resources [39]. Here, we increase the num-
ber of client training epochs and study its effects. From
Tab. 3, we observe that most of the methods, except for
FML and FedKD, can maintain their performance even with
a large value of E. Notably, our FedKTL maintains its supe-
rior performance across different values of E. Since FML
and FedKD learn an auxiliary model following the scheme
of FedAvg, the auxiliary model tends to learn more biased
information during local training with a larger value of E,
which may deteriorate the auxiliary model aggregation [44].
4.6. Impact of Feature Dimensions
Kâ€²= 64 Kâ€²= 256 Kâ€²= 1024
LG-FedAvg 39.69Â±0.25 40.21 Â±0.11 40.46 Â±0.01
FedGen 39.78Â±0.36 40.38 Â±0.36 40.83 Â±0.25
FedGH 39.93Â±0.45 40.80 Â±0.40 40.19 Â±0.37
FML 39.89Â±0.34 40.95 Â±0.09 40.26 Â±0.16
FedKD 41.06Â±0.18 41.14 Â±0.35 40.72 Â±0.25
FedDistill 41.69Â±0.10 41.66 Â±0.15 40.09 Â±0.27
FedProto 30.71Â±0.65 37.16 Â±0.42 31.21 Â±0.27
FedKTL 46.46Â±0.41 47.81 Â±0.43 45.91 Â±0.54
Table 4. The test accuracy (%) on Cifar100 in the practical setting
using HtFE 8with different Kâ€².
Here, we study the impact of Kâ€²on the test accuracy. Most
of the methods achieve their best performance when setting
Kâ€²= 256 , except for the methods that share classifiers,
such as LG-FedAvg and FedGen. Using a larger value of
Kâ€², FedProto can generate prototypes with dimension Kâ€²
and upload more client information to the server. In con-
trast, our FedKTL generates prototypes after the projection
layer ( hi, iâˆˆ[N]) with another dimension of K=C <
Kâ€². This dimension is fixed, i.e.,K= 100 , for the 100-
classification problem on Cifar100.
4.7. Communication Cost
Our FedKTL exhibits excellent performance while main-
taining an affordable communication cost, as shown in
Tab. 5. Specifically, FedKTL exhibits lower upload and
download costs compared to FedGen, FML, and FedKD.
Notably, the upload cost of our approach is the lowest
among all the baselines, since we set K=Cfor our Fed-
KTL. Besides, the upload overhead required by FedKTL is
much less than the download one, which is suitable for real-
world scenarios, where the uplink speed is typically lower
than the downlink speed [32]. The upload-efficient charac-
teristic of FedKTL highlights its practicality for knowledge
transfer in HtFL.Upload Download Accuracy
LG-FedAvg 1.03M 1.03M 40.65Â±0.07
FedGen 1.03M 7.66M 38.73Â±0.14
FedGH 0.46M 1.03M 40.99Â±0.51
FML 18.50M 18.50M 39.86Â±0.25
FedKD 16.52M 16.52M 40.56Â±0.31
FedDistill 0.09M 0.20M 41.54Â±0.08
FedProto 0.46M 1.02M 36.34Â±0.28
FedKTL 0.09M 7.17M 46.94Â±0.23
Table 5. The upload and download overhead per iteration using
HtFE 8on Cifar100 with 20 clients in the practical setting. â€œMâ€ is
short for million. The accuracy column is referred from Tab. 1.
Î»= 0.05 Î»= 0.1 Î»= 0.5
AFHQv2 26.82Â±0.32 27.05Â±0.26 26.32Â±0.52
Bench 27.71Â±0.25 28.36Â±0.42 27.56Â±0.50
FFHQ-U 27.28Â±0.23 27.21Â±0.35 26.59 Â±0.47
WikiArt 27.37Â±0.51 27.48Â±0.33 27.30Â±0.15
Table 6. The test accuracy (%) on Tiny-ImageNet in the practical
setting using HtFE 8with different pre-trained StyleGAN3s, which
are represented by the names of the pre-training datasets.
4.8. Adapting to Various Pre-Trained StyleGAN3s
Although we adopt the pre-trained StyleGAN-XL by de-
fault as the server generator, our FedKTL is also applicable
to other StyleGANs due to the adaptable ability of our fea-
ture transformer ( F). Here we consider utilizing the pop-
ular StyleGAN3 [23], which has nearly1
3of the parameter
count compared to StyleGAN-XL. Specifically, we use sev-
eral public StyleGAN3s pre-trained on four datasets with
different resolutions: AFHQv2 ( 512Ã—512) [23], Benches
(512Ã—512) [2], FFHQ-U ( 256Ã—256) [23], and WikiArt
(1024Ã—1024 ) [46]. To adapt to different pre-trained gener-
ators, we re-tune the hyperparameter Î». According to Tab. 1
and Tab. 6, our FedKTL maintains excellent performance
even when using other generators with different pre-training
datasets. In FedKTL, we prioritize the class-wise discrimi-
nation of the generated images over their semantic content.
Thus, the knowledge-transfer loop remains valuable when
generated images are distinguishable by classes but do not
share semantic relevance with clientsâ€™ data (see Fig. 4).
4.9. Iterative Domain Alignment Process
The training process in HtFL is iterative, so the domain
alignment in our FedKTL is also an iterative process. Here
we demonstrate the generated images throughout HtFLâ€™s
training process in Fig. 5 to show the iterative domain align-
ment process. In the early iterations, as shown in Fig. 5a and
12115
(a) Client #1
 (b) AFHQv2
 (c) Benches
 (d) FFHQ-U
 (e) WikiArt
Figure 4. (a): Four images (one image per class) on client #1. (b),
(c), (d), and (e): The images generated by different StyleGAN3s
corresponding to the aforementioned four classes.
(a) Iter. 0
 (b) Iter. 1
 (c) Iter. 10
 (d) Iter. 20
 (e) Iter. 30
(f) Iter. 50
 (g) Iter. 100
 (h) Iter. 110
 (i) Iter. 120
 (j) Iter. 130
Figure 5. The images generated by StyleGAN-XL corresponding
to four classes at different iterations.
Fig. 5b, the generated images ( DI) corresponding to class-
wise latent centroids ( Â¯Q) appear similar, since clients can-
not generate discriminative prototypes. As HtFLâ€™s training
process continues, the generated images become increas-
ingly class-discriminative and clear. The generated images
in iterations 110, 120, and 130 hardly change for each class,
showing the convergence of Fand client modelsâ€™ training.
4.10. Ablation Study
FedKTL -LM
i -LMSE-LMMD-ETF - Â¯Q +CS
28.17 24.39 21.70 20.14 21.02 20.69 24.13
Table 7. The test accuracy (%) of our FedKTLâ€™s variants on Tiny-
ImageNet in the practical setting using HtFE 8.
(a)-LM
i
(b)-LMSE
(c)-LMMD
(d)-ETF
 (e)-Â¯Q
Figure 6. The images generated by StyleGAN-XL corresponding
to four classes in our FedKTLâ€™s variants when variants converge.
Here, we remove LM
i,LMMD, and LMSEfrom FedKTL
and denote these variants â€œ -LM
iâ€, â€œ-LMMDâ€, and â€œ -LMSEâ€,
respectively. Moreover, we create the following three vari-
ants. (1) â€œ -ETF â€: we remove hiand replace the ETF clas-
sifier with the original classifier of each model architec-ture. (2) â€œ -Â¯Qâ€: we remove LM
iand mix the generated
class-discriminative data DIwith local data Di. (3) Be-
sides the common practice of using noise Ïµto generate im-
ages, StyleGAN-XL offers a conditional version that can
generate images belonging to any class from the ImageNet
dataset. Using the Conditional StyleGAN-XL (CS), we cre-
ate a variant â€œ +CSâ€ by disabling step 2Upload and step 3
Domain Alignment, and directly generating Cimage-vector
pairs for Crandomly selected ImageNet classes.
The poor results of these variants in Tab. 7 and Fig. 6
demonstrate the effectiveness of each key component in our
FedKTL. Below, we analyze them one by one. (1) -LM
i: re-
moving LM
imeans training solely on the local dataset Di
without collaboration, leading to a 3.78% accuracy drop
and distorted generated images (unused). (2) -LMSE: re-
moving LMSEcauses the generated images to become indis-
criminative, thus misleading the local extractor and causing
an accuracy drop of 6.47% . (3) -LMMD: without the MMD
loss for domain alignment, it is hard for Â¯Qto be valid la-
tent input vectors for the generator, leading to blurry images
and a notable accuracy decrease. (4) -ETF : biased classi-
fiers make prototypes of different classes overlap, resulting
in a loss of class-wise discrimination of the generated im-
ages. In Fig. 6d, three out of the four images depict dogs
and grass. (5) -Â¯Q: without Â¯Q, only using DIon clients can-
not transfer knowledge from the generator and mixing DI
andDiperturb the semantics of local data, thus achieving
poor performance and generating images with strange con-
tents. (6) +CS: using a conditional generator to produce
class-wise image-vector pairs without adapting to clientsâ€™
tasks can harm local training, as evidenced by a 0.26% de-
crease in accuracy compared to - LM
i(no collaboration). (7)
Interestingly, the variants - LMSE, -LMMD, -ETF, and - Â¯Q
perform worse than - LM
i, which indicates that all key com-
ponents are crucial and assist each other in FedKTL.
5. Conclusion
We propose FedKTL to promote client training in HtFL by
(1) producing image-vector pairs that are related to clientsâ€™
tasks through a pre-trained generatorâ€™s inference on the
server, and (2) transferring pre-existing knowledge from the
generator to clientsâ€™ heterogeneous models. Extensive ex-
periments show the effectiveness, efficiency, and practical-
ity of our FedKTL in various scenarios.
Acknowledgements
This work was supported by the National Key R&D Pro-
gram of China under Grant No.2022ZD0160504, the Pro-
gram of Technology Innovation of the Science and Technol-
ogy Commission of Shanghai Municipality (Granted No.
21511104700), and Tsinghua University(AIR)-Asiainfo
Technologies (China) Inc. Joint Research Center.
12116
References
[1] Enes Ayan and Halil Murat Â¨Unver. Data augmentation im-
portance for classification of skin lesions via deep learning.
In2018 Electric Electronics, Computer Science, Biomedical
Engineeringsâ€™ Meeting (EBBT) , pages 1â€“4. IEEE, 2018. 1
[2] Marion Bowman. Trees, benches and contemporary com-
memoration: When the ordinary becomes extraordinary.
Journal for the Study of Religious Experience , 7(3):33â€“49,
2021. 7
[3] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-
biah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakan-
tan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Lan-
guage models are few-shot learners. Advances in Neural In-
formation Processing Systems (NeurIPS) , 2020. 1
[4] Sema Candemir, Xuan V Nguyen, Les R Folio, and Lu-
ciano M Prevedello. Training strategies for radiology deep
learning models in data-limited scenarios. Radiology: Artifi-
cial Intelligence , 3(6):e210014, 2021. 1
[5] Patryk Chrabaszcz, Ilya Loshchilov, and Frank Hutter. A
Downsampled Variant of Imagenet as an Alternative to the
Cifar Datasets. arXiv preprint arXiv:1707.08819 , 2017. 5
[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and
Li Fei-Fei. Imagenet: A Large-Scale Hierarchical Image
Database. In IEEE Conference on Computer Vision and Pat-
tern Recognition (CVPR) , 2009. 5
[7] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos
Zafeiriou. Arcface: Additive angular margin loss for deep
face recognition. In IEEE Conference on Computer Vision
and Pattern Recognition (CVPR) , 2019. 3, 5
[8] Enmao Diao, Jie Ding, and Vahid Tarokh. Heterofl: Com-
putation and communication efficient federated learning
for heterogeneous clients. In International Conference on
Learning Representations (ICLR) , 2020. 2
[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, et al. An image is worth 16x16 words: Trans-
formers for image recognition at scale. In International Con-
ference on Learning Representations (ICLR) , 2020. 6
[10] Xiuwen Fang, Mang Ye, and Xiyuan Yang. Robust hetero-
geneous federated learning under data corruption. In IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR) , 2023. 2
[11] Zhida Feng, Zhenyu Zhang, Xintong Yu, Yewei Fang,
Lanxin Li, Xuyi Chen, Yuxiang Lu, Jiaxiang Liu, Weichong
Yin, Shikun Feng, et al. Ernie-vilg 2.0: Improving text-to-
image diffusion model with knowledge-enhanced mixture-
of-denoising-experts. In IEEE Conference on Computer Vi-
sion and Pattern Recognition (CVPR) , 2023. 1
[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep Residual Learning for Image Recognition. In IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR) , 2016. 5
[13] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distill-
ing the knowledge in a neural network. arXiv preprint
arXiv:1503.02531 , 2015. 1[14] Samuel Horvath, Stefanos Laskaridis, Mario Almeida, Ilias
Leontiadis, Stylianos Venieris, and Nicholas Lane. Fjord:
Fair and accurate federated learning under heterogeneous tar-
gets with ordered dropout. Advances in Neural Information
Processing Systems (NeurIPS) , 2021. 2
[15] Linmei Hu, Zeyi Liu, Ziwang Zhao, Lei Hou, Liqiang Nie,
and Juanzi Li. A survey of knowledge enhanced pre-trained
language models. IEEE Transactions on Knowledge and
Data Engineering , 2023. 1
[16] Sergey Ioffe and Christian Szegedy. Batch Normalization:
Accelerating Deep Network Training by Reducing Internal
Covariate Shift. In International Conference on Machine
Learning (ICML) , 2015. 4
[17] Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park,
Mehdi Bennis, and Seong-Lyun Kim. Communication-
efficient on-device machine learning: Federated distillation
and augmentation under non-iid private data. arXiv preprint
arXiv:1811.11479 , 2018. 2, 5
[18] Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao
Chen, Linlin Li, Fang Wang, and Qun Liu. Tinybert: Dis-
tilling bert for natural language understanding. In Findings
of the Association for Computational Linguistics: EMNLP
2020 , pages 4163â€“4174, 2020. 1
[19] Peter Kairouz, H Brendan McMahan, Brendan Avent,
AurÂ´elien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista
Bonawitz, Zachary Charles, Graham Cormode, Rachel Cum-
mings, et al. Advances and Open Problems in Federated
Learning. arXiv preprint arXiv:1912.04977 , 2019. 1
[20] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri,
Sashank Reddi, Sebastian Stich, and Ananda Theertha
Suresh. Scaffold: Stochastic Controlled Averaging for Fed-
erated Learning. In International Conference on Machine
Learning (ICML) , 2020. 1
[21] Tero Karras, Samuli Laine, and Timo Aila. A style-based
generator architecture for generative adversarial networks. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR) , 2019. 1, 2, 3
[22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,
Jaakko Lehtinen, and Timo Aila. Analyzing and improving
the image quality of stylegan. In IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR) , 2020. 1
[23] Tero Karras, Miika Aittala, Samuli Laine, Erik H Â¨arkÂ¨onen,
Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Alias-free
generative adversarial networks. Advances in Neural Infor-
mation Processing Systems (NeurIPS) , 2021. 2, 7
[24] Diederik P Kingma and Jimmy Ba. Adam: A Method for
Stochastic Optimization. In International Conference on
Learning Representations (ICLR) , 2015. 5
[25] Alex Krizhevsky and Hinton Geoffrey. Learning Multiple
Layers of Features From Tiny Images. Technical Report ,
2009. 5
[26] Daliang Li and Junpu Wang. Fedmd: Heterogenous
federated learning via model distillation. arXiv preprint
arXiv:1910.03581 , 2019. 2
[27] Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang,
Yuan Li, Xu Liu, and Bingsheng He. A Survey on Federated
Learning Systems: Vision, Hype and Reality for Data Pri-
12117
vacy and Protection. IEEE Transactions on Knowledge and
Data Engineering , 2021. 1
[28] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia
Smith. Federated Learning: Challenges, Methods, and Fu-
ture Directions. IEEE Signal Processing Magazine , 37(3):
50â€“60, 2020. 1
[29] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith. Federated Optimiza-
tion in Heterogeneous Networks. In Conference on Machine
Learning and Systems (MLSys) , 2020. 1
[30] Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia
Smith. Ditto: Fair and Robust Federated Learning Through
Personalization. In International Conference on Machine
Learning (ICML) , 2021. 1
[31] Xin-Chun Li, De-Chuan Zhan, Yunfeng Shao, Bingshuai Li,
and Shaoming Song. FedPHP: Federated Personalization
with Inherited Private Models. In European Conference on
Machine Learning and Principles and Practice of Knowl-
edge Discovery in Databases (ECML) , 2021. 4
[32] Zhenhua Li, Xingyao Li, Xinlei Yang, Xianlong Wang, Feng
Qian, and Yunhao Liu. Fast uplink bandwidth testing for in-
ternet users. IEEE/ACM Transactions on Networking , 2023.
7
[33] Zexi Li, Xinyi Shang, Rui He, Tao Lin, and Chao Wu. No
fear of classifier biases: Neural collapse inspired federated
learning with synthetic and fixed classifier. In IEEE Inter-
national Conference on Computer Vision (ICCV) , 2023. 2,
3
[34] Ziyun Li, Xinshao Wang, Neil M Robertson, David A
Clifton, Christoph Meinel, and Haojin Yang. Smkd: Se-
lective mutual knowledge distillation. In International Joint
Conference on Neural Networks (IJCNN) , 2023. 2
[35] Paul Pu Liang, Terrance Liu, Liu Ziyin, Nicholas B Allen,
Randy P Auerbach, David Brent, Ruslan Salakhutdinov, and
Louis-Philippe Morency. Think locally, act globally: Fed-
erated learning with local and global representations. arXiv
preprint arXiv:2001.01523 , 2020. 2, 5
[36] Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin
Jaggi. Ensemble distillation for robust model fusion in fed-
erated learning. Advances in Neural Information Processing
Systems (NeurIPS) , 33:2351â€“2363, 2020. 1, 2, 5
[37] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jor-
dan. Learning transferable features with deep adaptation net-
works. In International Conference on Machine Learning
(ICML) , 2015. 4
[38] Mi Luo, Fei Chen, Dapeng Hu, Yifan Zhang, Jian Liang, and
Jiashi Feng. No Fear of Heterogeneity: Classifier Calibration
for Federated Learning with Non-IID data. In Advances in
Neural Information Processing Systems (NeurIPS) , 2021. 2
[39] Brendan McMahan, Eider Moore, Daniel Ramage, Seth
Hampson, and Blaise Aguera y Arcas. Communication-
Efficient Learning of Deep Networks from Decentralized
Data. In International Conference on Artificial Intelligence
and Statistics (AISTATS) , 2017. 5, 7
[40] Hieu V Nguyen and Li Bai. Cosine similarity metric learn-
ing for face verification. In Asian Conference on Computer
Vision (ACCV) , 2010. 3[41] Maria-Elena Nilsback and Andrew Zisserman. Automated
flower classification over a large number of classes. In 2008
Sixth Indian conference on computer vision, graphics & im-
age processing , pages 722â€“729. IEEE, 2008. 5
[42] Vardan Papyan, XY Han, and David L Donoho. Prevalence
of neural collapse during the terminal phase of deep learning
training. Proceedings of the National Academy of Sciences ,
117(40):24652â€“24663, 2020. 2, 3
[43] Francesco Ponzio, Gianvito Urgese, Elisa Ficarra, and Santa
Di Cataldo. Dealing with lack of training data for convolu-
tional neural networks: the case of digital pathology. Elec-
tronics , 8(3):256, 2019. 1
[44] Liangqiong Qu, Yuyin Zhou, Paul Pu Liang, Yingda Xia,
Feifei Wang, Ehsan Adeli, Li Fei-Fei, and Daniel Rubin. Re-
thinking architecture design for tackling data heterogeneity
in federated learning. In IEEE Conference on Computer Vi-
sion and Pattern Recognition (CVPR) , 2022. 7
[45] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bj Â¨orn Ommer. High-resolution image syn-
thesis with latent diffusion models. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR) , 2022. 2,
3
[46] Babak Saleh and Ahmed Elgammal. Large-scale classifica-
tion of fine-art paintings: Learning the right metric on the
right feature. arXiv preprint arXiv:1505.00855 , 2015. 7
[47] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zh-
moginov, and Liang-Chieh Chen. Mobilenetv2: Inverted
residuals and linear bottlenecks. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR) , 2018. 5
[48] Axel Sauer, Katja Schwarz, and Andreas Geiger. Stylegan-
xl: Scaling stylegan to large diverse datasets. In ACM SIG-
GRAPH 2022 conference proceedings , pages 1â€“10, 2022. 2,
3, 5
[49] Tao Shen, Jie Zhang, Xinkang Jia, Fengda Zhang, Gang
Huang, Pan Zhou, Kun Kuang, Fei Wu, and Chao Wu. Fed-
erated mutual learning. arXiv preprint arXiv:2006.16765 ,
2020. 2, 5
[50] Kaili Sun, Xudong Luo, and Michael Y Luo. A survey of
pretrained language models. In International Conference on
Knowledge Science, Engineering and Management , 2022. 1
[51] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,
Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent
Vanhoucke, and Andrew Rabinovich. Going deeper with
convolutions. In IEEE Conference on Computer Vision and
Pattern Recognition (CVPR) , 2015. 5
[52] Yue Tan, Guodong Long, Lu Liu, Tianyi Zhou, Qinghua Lu,
Jing Jiang, and Chengqi Zhang. Fedproto: Federated Proto-
type Learning across Heterogeneous Clients. In AAAI Con-
ference on Artificial Intelligence (AAAI) , 2022. 1, 2, 5
[53] Yue Tan, Guodong Long, Jie Ma, Lu Liu, Tianyi Zhou, and
Jing Jiang. Federated learning from pre-trained models: A
contrastive learning approach. Advances in Neural Informa-
tion Processing Systems (NeurIPS) , 2022. 1, 2, 5
[54] Michael Tuchler, Andrew C Singer, and Ralf Koetter. Min-
imum Mean Squared Error Equalization using A Priori In-
formation. IEEE Transactions on Signal Processing , 50(3):
673â€“683, 2002. 4
12118
[55] Lianyu Wang, Meng Wang, Daoqiang Zhang, and Huazhu
Fu. Model barrier: A compact un-transferable isolation do-
main for model intellectual property protection. In IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR) , 2023. 1
[56] Dingzhu Wen, Ki-Jun Jeon, and Kaibin Huang. Federated
dropoutâ€”a simple approach for enabling federated learning
on resource constrained devices. IEEE wireless communica-
tions letters , 11(5):923â€“927, 2022. 2
[57] Chuhan Wu, Fangzhao Wu, Lingjuan Lyu, Yongfeng Huang,
and Xing Xie. Communication-efficient federated learning
via knowledge distillation. Nature communications , 13(1):
2032, 2022. 1, 2, 5
[58] Xiyuan Yang, Wenke Huang, and Mang Ye. Dynamic per-
sonalized federated learning with adaptive differential pri-
vacy. Advances in Neural Information Processing Systems
(NeurIPS) , 2023. 1
[59] Yibo Yang, Shixiang Chen, Xiangtai Li, Liang Xie,
Zhouchen Lin, and Dacheng Tao. Inducing neural collapse
in imbalanced learning: Do we really need a learnable clas-
sifier at the end of deep neural network? Advances in Neural
Information Processing Systems (NeurIPS) , 2022. 2, 3
[60] Yibo Yang, Haobo Yuan, Xiangtai Li, Zhouchen Lin, Philip
Torr, and Dacheng Tao. Neural collapse inspired feature-
classifier alignment for few-shot class-incremental learning.
InInternational Conference on Learning Representations
(ICLR) , 2022. 2
[61] Liping Yi, Gang Wang, Xiaoguang Liu, Zhuan Shi, and Han
Yu. Fedgh: Heterogeneous federated learning with general-
ized global header. In Proceedings of the 31st ACM Interna-
tional Conference on Multimedia , 2023. 1, 2, 5
[62] Qiying Yu, Yang Liu, Yimu Wang, Ke Xu, and Jingjing Liu.
Multimodal federated learning via contrastive representation
ensemble. In International Conference on Learning Repre-
sentations (ICLR) , 2022. 2
[63] Jialong Zhang, Zhongshu Gu, Jiyong Jang, Hui Wu, Marc Ph
Stoecklin, Heqing Huang, and Ian Molloy. Protecting intel-
lectual property of deep neural networks with watermarking.
InProceedings of the 2018 on Asia conference on computer
and communications security , pages 159â€“172, 2018. 1
[64] Jie Zhang, Song Guo, Xiaosong Ma, Haozhao Wang, Wen-
chao Xu, and Feijie Wu. Parameterized Knowledge Transfer
for Personalized Federated Learning. In Advances in Neural
Information Processing Systems (NeurIPS) , 2021. 1
[65] Jie Zhang, Song Guo, Jingcai Guo, Deze Zeng, Jingren
Zhou, and Albert Zomaya. Towards data-independent
knowledge transfer in model-heterogeneous federated learn-
ing. IEEE Transactions on Computers , 2023. 1, 2
[66] Jianqing Zhang, Yang Hua, Jian Cao, Hao Wang, Tao Song,
Zhengui Xue, Ruhui Ma, and Haibing Guan. Eliminating do-
main bias for federated learning in representation space. Ad-
vances in Neural Information Processing Systems (NeurIPS) ,
2023. 5
[67] Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui
Xue, Ruhui Ma, Jian Cao, and Haibing Guan. Gpfl: Simulta-
neously learning global and personalized feature information
for personalized federated learning. In IEEE International
Conference on Computer Vision (ICCV) , 2023. 1, 5[68] Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui
Xue, Ruhui Ma, and Haibing Guan. Fedcp: Separating fea-
ture information for personalized federated learning via con-
ditional policy. In Proceedings of ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Min-
ing, 2023. 5
[69] Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhen-
gui Xue, Ruhui Ma, and Haibing Guan. FedALA: Adaptive
Local Aggregation for Personalized Federated Learning. In
AAAI Conference on Artificial Intelligence (AAAI) , 2023. 1,
5
[70] Jianqing Zhang, Yang Liu, Yang Hua, and Jian Cao. Fedtgp:
Trainable global prototypes with adaptive-margin-enhanced
contrastive learning for data and model heterogeneity in fed-
erated learning. arXiv preprint arXiv:2401.03230 , 2024. 1,
2, 5
[71] Lin Zhang, Li Shen, Liang Ding, Dacheng Tao, and Ling-
Yu Duan. Fine-Tuning Global Model Via Data-Free Knowl-
edge Distillation for Non-IID Federated Learning. In IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR) , 2022. 1
[72] Sixin Zhang, Anna E Choromanska, and Yann LeCun. Deep
Learning with Elastic Averaging SGD. Advances in Neural
Information Processing Systems (NeurIPS) , 2015. 5
[73] Ying Zhang, Tao Xiang, Timothy M Hospedales, and
Huchuan Lu. Deep mutual learning. In IEEE Conference
on Computer Vision and Pattern Recognition (CVPR) , 2018.
2
[74] Zilong Zhong, Jonathan Li, Lingfei Ma, Han Jiang, and
He Zhao. Deep residual networks for hyperspectral image
classification. In 2017 IEEE International Geoscience and
Remote Sensing Symposium (IGARSS) , pages 1824â€“1827.
IEEE, 2017. 6
[75] Zhuangdi Zhu, Junyuan Hong, and Jiayu Zhou. Data-Free
Knowledge Distillation for Heterogeneous Federated Learn-
ing. In International Conference on Machine Learning
(ICML) , 2021. 2, 5
[76] Weiming Zhuang, Chen Chen, and Lingjuan Lyu. When
foundation model meets federated learning: Motiva-
tions, challenges, and future directions. arXiv preprint
arXiv:2306.15546 , 2023. 1
12119
