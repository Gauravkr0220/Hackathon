Think Twice Before Selection: Federated Evidential Active Learning for Medical
Image Analysis with Domain Shifts
Jiayi Chen1âˆ—Benteng Ma2âˆ—Hengfei Cui1Yong Xia1,3â€ 
1School of Computer Science and Engineering, Northwestern Polytechnical University, China
2Hong Kong University of Science and Technology, Hong Kong SAR, China
3Research & Development Institute of Northwestern Polytechnical University in Shenzhen, China
jiayichen@mail.nwpu.edu.cn, bentengma@ust.hk, hfcui@nwpu.edu.cn, yxia@nwpu.edu.cn
Abstract
Federated learning facilitates the collaborative learning
of a global model across multiple distributed medical in-
stitutions without centralizing data. Nevertheless, the ex-
pensive cost of annotation on local clients remains an ob-
stacle to effectively utilizing local data. To mitigate this
issue, federated active learning methods suggest leverag-
ing local and global model predictions to select a rela-
tively small amount of informative local data for annota-
tion. However, existing methods mainly focus on all lo-
cal data sampled from the same domain, making them un-
reliable in realistic medical scenarios with domain shifts
among different clients. In this paper, we make the first at-
tempt to assess the informativeness of local data derived
from diverse domains and propose a novel methodology
termed Federated Evidential ActiveLearning (FEAL) to
calibrate the data evaluation under domain shift. Specif-
ically, we introduce a Dirichlet prior distribution in both
local and global models to treat the prediction as a distribu-
tion over the probability simplex and capture both aleatoric
and epistemic uncertainties by using the Dirichlet-based
evidential model. Then we employ the epistemic uncer-
tainty to calibrate the aleatoric uncertainty. Afterward, we
design a diversity relaxation strategy to reduce data re-
dundancy and maintain data diversity. Extensive experi-
ments and analysis on five real multi-center medical im-
age datasets demonstrate the superiority of FEAL over the
state-of-the-art active learning methods in federated sce-
narios with domain shifts. The code will be available at
https://github.com/JiayiChen815/FEAL .
âˆ—Equal contribution.â€ Yong Xia is the corresponding author. This
work was supported in part by Shenzhen Science and Technology Pro-
gram under Grants JCYJ20220530161616036, National Natural Science
Foundation of China under Grants 62171377 and 62271405, Ningbo Clin-
ical Research Center for Medical Imaging under Grant 2021L003 (Open
Project: 2022LYKFZD06), and Foshan HKUST Projects under Grants
FSUST21-HKUST10E and FSUST21-HKUST11E.
?ğ‘ˆ!ğ¿!
?
ğ‘ˆ"ğ¿"
ğ‘ˆ#ğ¿#
AnnotateDistributeAggregateâ‹¯Client KServerClient 1Client 2Train
(a) FAL scheme
0.0 2.5 5.0 7.5 10.0 12.5
Energy score0.000.050.100.150.200.25DensityClient 1
Client 2
Client 3
Client 4
(b) KDE of energy score
1 2 3 4
Client1 2 3 4Client1.0000 0.0001 0.0001 0.0001
0.0001 1.0000 0.0130 0.0001
0.0001 0.0130 1.0000 0.0031
0.0001 0.0001 0.0031 1.0000
0.00.20.40.60.81.0
 (c)p-value
Figure 1. Illustration of federated active learning (FAL) in the
presence of domain shift. (a) FAL comprises model distribution,
local training, model aggregation, and data annotation. (b) The
KDE of energy scores depicts domain shifts across clients. (c)
The low p-values in cross-client KDE of energy scores indicate
the existence of significant domain shifts between all client pairs.
1. Introduction
Federated learning enables collaborative learning across
multiple clinical institutions ( i.e., clients) to learn a uni-
fied model on the central server through model aggregation
while preserving the data privacy at each client [21, 36, 57]
(see Fig. 1 (a)). Unfortunately, such a learning pipeline re-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
11439
quires each client to prepare its own labeled data, whose
scale is constrained by the available expertise, time, and
budget for data annotation.
One possible solution to alleviate the annotation cost is
to select a part of highly informative data to annotate. Ac-
tive learning (AL) has shown great potential in guiding the
data selection process [1, 3, 20, 61], leading to the federated
AL (FAL) framework. Such a pipeline [4, 14, 37, 41, 46, 65]
allows each client to assess the informativeness of unla-
beled data using either the local model at each client or the
global model from the server, greatly alleviating the heavy
annotation costs while retaining great performance. Nev-
ertheless, when using a local model to select data, there
is a bias toward prioritizing the data that improves the lo-
cal updates while disregarding the overall generalizability
of the global model. Client models trained on diverse do-
mains may exhibit significant divergence within the param-
eter space, making the use of a global model aggregated
from these models for data selection unreliable.
Recent advances in FAL, e.g., LoGo [20] and
KAFAL [3], tend to harness the knowledge of both local and
global models to identify informative samples. Although
this strategy has been proven to be more effective than em-
ploying a single model, these methods focus mainly on the
class imbalance issue while assuming that the data at mul-
tiple clients is from the same domain. However, the do-
main shift across clients is commonly seen in real-world
applications, which is evidenced by the extremely low p-
values of the kernel density estimation (KDE) of energy
scores [31] (see Fig. 1 (b) and (c)). The existence of domain
shift renders two major challenges for FAL. (1) Overcon-
fidence; Existing FAL methods evaluate data uncertainty
based on the softmax prediction made by a deterministic
model, which is essentially a point estimate and can be mis-
calibrated easily on data with domain shifts [31, 33, 42],
resulting in unreliable uncertainty evaluation. (2) Limited
uncertainty representation. Uncertainty can be divided
into aleatoric uncertainty (or data uncertainty) and epis-
temic uncertainty (or knowledge uncertainty) [43]. The for-
mer reflects the inherent complexity of data, such as class
overlap and instance noise [54]. The latter captures the re-
stricted knowledge of a model caused by insufficient data
or domain shifts. The softmax prediction can represent
the aleatoric uncertainty but fails to capture the epistemic
uncertainty, resulting in incomplete evaluations, which are
particularly noticeable in the presence of domain shift.
To address both challenges, we propose the Federated
Evidential Active Learning (FEAL) method. Built upon
the Dirichlet-based evidential model [47, 62], FEAL treats
the categorical prediction of a sample as following a Dirich-
let distribution, thus allowing multiple potential predictions
for a sample. FEAL comprises two key modules, i.e.,
calibrated evidential sampling (CES) and evidential modellearning (EML). CES is a novel FAL sampling strategy that
incorporates both uncertainty and diversity measures. It uti-
lizes the expected entropy of potential predictions to quan-
tify aleatoric uncertainty and aggregates the aleatoric un-
certainty in both global and local models. Further, CES em-
ploys the differential entropy of the Dirichlet distribution to
characterize the epistemic uncertainty [51] and utilizes the
epistemic uncertainty in the global model to calibrate the
aggregated aleatoric uncertainty. To enhance data selection,
diversity relaxation is also employed with the local model
to reduce redundancy and maintain diversity among the se-
lected samples. In addition to active sampling, we introduce
evidence regularization in EML for accurate evidence rep-
resentation and data assessment. The main contributions of
this work are summarized as follows:
â€¢ We explore a rarely studied problem, FAL with domain
shifts, which aims to attain a global model with a limited
annotation budget for local clients amidst domain shifts.
â€¢ We propose the FEAL method, with a sampling strategy
CES and a local training scheme EML, to tackle the chal-
lenges in FAL with domain shifts. CES is designed to se-
lect informative samples by leveraging aleatoric and epis-
temic uncertainty with both global and local models and
retaining sample diversity. EML is developed to regular-
ize the evidence for improved data evaluation.
â€¢ We conduct extensive experiments on five real multi-
center medical image datasets, comprising two datasets
for classification and three datasets for segmentation. The
results suggest the superiority of our FEAL method over
its AL and FAL counterparts.
2. Related Work
2.1. Federated Learning with Domain Shifts
Domain shift is a long-standing challenge for feder-
ated learning. Previous approaches can be divided into
regularization-based, aggregation-based, and personalized
ones. Regularization-based methods implemented regu-
larization on model parameters [19, 27, 52] or feature em-
beddings [12, 15, 26, 60] to address the objective inconsis-
tency induced by domain shift. Aggregation-based meth-
odsdynamically adjust aggregation weights based on data
quality [32], estimated client contribution [17], general-
ization gap between global and local models [67], layer-
wise divergence [44] or performance on proxy dataset [29].
Personalized methods aggregated domain-agnostic layers,
while customizing domain-specific layers for local clients,
including batch normalization (BN) [28], high-frequency
convolution [6] and prediction layers [57]. Additionally,
several methods enhanced data diversity [30, 68] to refine
data distribution and mitigate statistical heterogeneity [64].
These approaches strive to mitigate the impact of domain
shifts across clients in supervised scenarios with fully an-
11440
notated training samples. Unfortunately, they ignore the
substantial annotation costs for each client. In contrast, we
further leverage active learning to reduce annotation costs
by selecting the most informative data and propose a label-
efficient method for federated learning with domain shifts.
2.2. AL Methods
Conventional AL methods can be categorized into
uncertainty-based, diversity-based, and hybrid ones.
Uncertainty-based AL methods aim to select the most
ambiguous unlabeled samples for annotation. Classical ap-
proaches such as least confidence sampling [49], margin-
based sampling [37], and entropy-based sampling [50] eval-
uate the data uncertainty based on categorical probabilities.
Yoo et al. [65] and Huang et al. [14] estimated the loss for
uncertainty assessment. Moreover, several approaches as-
sess the data uncertainty by analyzing the prediction incon-
sistency among multiple augmented samples [11], standard
and dropout inferences [9, 10], or original and disturbed
features [41]. Diversity-based AL methods aim to iden-
tify a subset of samples that captures the distribution of the
complete dataset. A variety of approaches have been pro-
posed that exploit core-set techniques [4, 46] or clustering
methods [23, 38, 55] in the latent feature space, incorporate
a diversity constraint in the optimization process [8, 63], or
model the distribution discrepancy between labeled and un-
labeled samples [24] in order to identify a diverse collection
of samples. Hybrid AL methods exploit both uncertainty
and diversity in their sampling strategies. Ash et al. [2] clus-
tered the gradient embeddings to guarantee both uncertainty
and diversity. A two-stage sampling strategy has also been
implemented [41, 56, 66]. However, these methods primar-
ily focus on data selection driven by aleatoric uncertainty,
often neglecting its sufficiency and reliability in practical
scenarios. In this work, we developed a Dirichlet-based ev-
idential model to capture both aleatoric and epistemic un-
certainties. We further leveraged the epistemic uncertainty
to calibrate uncertainty estimates, enhancing their reliability
in the context of domain shifts.
2.3. FAL Methods
FAL aims to enhance the annotation efficacy of each local
client in decentralized learning. In contrast to the central-
ized scenarios, there exist two potential query-selector mod-
els in FAL [20], including the global model and the local
model. Both Wu et al. [61] and Ahn et al. [1] exclusively
utilized a singular model for data evaluation. Specifically,
Wuet al. [61] introduced a hybrid metric that considers both
the locally predicted loss and the local feature distances be-
tween unlabeled and labeled samples. By contrast, Ahn
et al. [1] argued that evaluating samples with the global
model contributes to the objectives of federated learning
and recommended applying sampling strategies solely withthe global model. Nevertheless, as demonstrated in [20],
the superiority of the two query-selector models depends
on the global and local heterogeneous levels, and it is nec-
essary to leverage the knowledge of both global and local
models. Kim et al. [20] proposed a hybrid metric called
LoGo, which applies k-means clustering technique [34] on
the gradient space of the local model and subsequently con-
ducts cluster-wise sampling using the global model. Cao et
al.[3] proposed a knowledge-specialized sampling strategy,
which leverages the discrepancy between the global model
and local model to assess data uncertainty. However, these
methods focus on the local data from a singular domain,
which is less realistic. Though partial approaches [3, 20]
account for heterogeneity caused by class imbalance, they
often neglect another heterogeneous property known as do-
main shifts. In this work, we propose the uncertainty cal-
ibration method to achieve reliable uncertainty evaluation
with domain shifts across multiple clients.
3. Methodology
3.1. Problem Formulation
The overview of our FEAL framework is displayed in Fig. 2
and Appendix A. Under this framework, we maintain K
local models {Î¸k}K
k=1on clients and a global model Î¸on
the central server. The k-th local client contains a labeled
setLkand an unlabeled set Uk. FAL comprises two iterative
phases: federated model training and local data annotation.
Federated model training involves model distribution, local
training, and model aggregation. In the first round, the k-th
client randomly selects Bkunlabeled samples and annotates
them to form the initial labeled set L1
k={(xi,yi)}Bk
i=1, and
the unlabeled set is updated to U1
k=Uk\L1
k. In the r-th
FAL round, the k-th client constructs the query set Qr
k=
{(xj,yj)}Bk
j=1for annotation using the sampling strategy
and updates the labeled set to Lr
k=Lrâˆ’1
kâˆªQr
k, whereas the
unlabeled set is updated to Ur
k=Urâˆ’1
k\Qr
k. Subsequent
federated model training proceeds with the updated labeled
setLr
k. The FAL process is repeated for Rtimes as required.
3.2. Dirichlet-based Evidential Model in FAL
For federated active learning, we employ a Dirichlet-based
evidential model to effectively capture aleatoric and epis-
temic uncertainties in both global and local models. In this
section, we begin by presenting the foundational formula-
tion of the Dirichlet-based evidential model.
We start with the general C-class classification task.
Given an input sample xfrom the k-th client, a model f
parameterized with Î¸projects xinto a C-dimensional log-
itsf(x,Î¸). The classical CNN utilizes the softmax operator
to transform the logits f(x,Î¸)into the prediction of class
probabilities Ï. However, this approach essentially provides
a single-point estimate of Ïand can be easily miscalibrated
11441
(a) Federated Evidential Active Learning (FEAL)
DistributeAggregate
â‹¯
Server
ğ‘ˆ!ğ¿!
â‹®ğœ½â‹®ğœ½!Query with
Client 1Train
ğ‘ˆ"ğ¿"
Query withâ‹®ğœ½â‹®ğœ½"Annotate
(b) Calibrated Evidential Sampling (CES)
ğ‘ˆ!ğ¿!ğ’™
LowHighSortğ‘ˆ(ğ’™,ğœ½,ğœ½#)
LowHighSelectğ‘ˆ(ğ’™,ğœ½,ğœ½#)ğ‘ˆ(ğ’™,ğœ½,ğœ½#)
ğ‘ˆ"#$(ğ’™,ğœ½)ğ‘ˆ%&"(ğ’™,ğœ½)
ğ‘ˆ%&"(ğ’™,ğœ½!)Local model ğœ½!Global model ğœ½Evidential head
FeatureextractorFeatureextractorâ‹®
Evidential headğ¶"ğ¶!ğ¶$ğœ¶â‹®
ğ¶"ğ¶!ğ¶$ğœ¶
Uncertainty Calibration
Diversity RelaxationMin neighbor size ğ‘›=5
ğ‘„!Query set
Oracle
Labeled neighborUnlabeled neighborCadidate sample ğ’™% (Select)Cadidate sample ğ’™% (Ignore)
ğ‘ˆ&ğ¿&
Query withâ‹®ğœ½â‹®ğœ½#Unlabeled setLabeled set
Client 2
Client KFigure 2. Illustration of the proposed FEAL method. (a) Overview of FEAL. (b) Illustration of CES module, including uncertainty
calibration and diversity relaxation.
on local data from diverse domains. The Dirichlet-based ev-
idential model, on the other hand, views the categorical pre-
diction Ïas a random variable with a Dirichlet distribution
Dir(Ï|Î±). The probability density function of Ï[47, 62],
givenxandÎ¸, is formulated as:
p(Ï|x,Î¸) =ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³Î“(PC
c=1Î±c)QC
c=1Î“(Î±c)CY
c=1ÏÎ±câˆ’1
c,(Ïâˆˆâˆ†C)
0 ,(otherwise )(1)
where Î±denotes the parameters of the Dirichlet distri-
bution for sample x,Î“(Â·)is the Gamma function, and
âˆ†C={Ï|PC
c=1Ïc=1and0<Ïc<1}represents the C-
dimensional unit simplex.
The posterior probability P(y=c|x,Î¸)for class c,
a.k.a. , the expected categorical prediction Ïc, is given by:
P(y=c|x,Î¸) =Z
p(y=c|Ï)Â·p(Ï|x,Î¸)dÏ=Î±c
S,(2)
where S=PC
c=1Î±crepresents the Dirichlet strength. The
derivation of Eq. 2 is provided in Appendix B.1.
Drawing on concepts from Dempster-Shafer theory [48]
and subjective logic [18], the parameter Î±is linked to the
accumulated evidence ewhich quantifies the degree of sup-
port for the prediction on sample x. The parameter Î±is
derived as Î±=e+ 1 = A(f(x,Î¸)) + 1 , where A(Â·)is
a non-negative activation function that transforms the logits
f(x,Î¸)into evidence e.
In our study, all local models adopt the same Dirichlet-
based evidential architecture with the global model to com-
municate between local clients and the central server.
3.3. Calibrated Evidential Sampling
In the context of FAL with domain shifts, we integrate both
uncertainty and diversity measures to identify the most in-
formative samples for annotation (see Fig. 2(b)). As for un-
certainty evaluation, we leverage the epistemic uncertaintyin the global model to calibrate the aleatoric uncertainty in
both global and local models. We now delve into its details.
Aleatoric uncertainty. Dirichlet-based evidential models
interpret the categorical prediction Ïas a distribution rather
than a singular point estimate, which acknowledges a range
of possible predictions. We use the expected entropy of all
possible predictions to deliver the aleatoric uncertainty [62]
to quantify the inherent complexity or ambiguity present in
local data. Given a sample xand the global model Î¸, the
aleatoric uncertainty of the sample xin the global model Î¸
is represented as:
Uale(x,Î¸) =Ep(Ï|x,Î¸)[H[P(y|Ï)]]
=âˆ’CX
c=1Ep(Ïc|x,Î¸)[ÏcÂ·logÏc]
=CX
c=1Î±c
SÂ·[Ïˆ(S+ 1)âˆ’Ïˆ(Î±c+ 1)],(3)
where H(Â·)denotes the Shannon entropy [50]. Similarly,
the aleatoric uncertainty in the local model kisUale(x,Î¸k).
The derivation of Eq. 3 is in Appendix B.2.
Epistemic uncertainty. In the Dirichlet distribution, the
differential entropy quantifies how dispersed the probabil-
ities are across different categories [35]. We employ the
differential entropy of the Dirichlet distribution to quantify
the epistemic uncertainty linked to domain shifts between
the global model and local data. Specifically, given a sam-
plexand the global model Î¸, the epistemic uncertainty of
the sample xin the global model Î¸is represented as:
Uepi(x,Î¸) =H[p(Ï|x,Î¸)]
=âˆ’Z
p(Ï|x,Î¸)Â·logp(Ï|x,Î¸)dÏ
=CX
c=1logÎ“(Î±c)
Î“(S)âˆ’(Î±câˆ’1)Â·[Ïˆ(Î±c)âˆ’Ïˆ(S)].(4)
The derivation of Eq. 4 is in Appendix B.2.
11442
Uncertainty calibration. Given a sample x, the global
model Î¸, and the local model Î¸k, we calculate the aleatoric
uncertainty (Eq. 3) in both global and local models and sub-
sequently calibrate the aleatoric uncertainty by incorporat-
ing the epistemic uncertainty (Eq. 4) from the global model.
The overall calibrated uncertainty for sample xis
U(x,Î¸,Î¸k) = [Uale(x,Î¸) +Uale(x,Î¸k)]Â·Uepi(x,Î¸). (5)
Diversity relaxation. We adopt local constraints to ensure
diversity among selected samples, contrasting with core-set
techniques that impose global diversity constraints. As out-
lined in Alg. 1, we initially sort the unlabeled set Urâˆ’1
kby
descending calibrated uncertainty U(x,Î¸,Î¸k), and then ex-
tract feature embeddings with local model Î¸k. During the it-
eration over the unlabeled set Urâˆ’1
k, we compute the cosine
similarity s(xi,xj)for each candidate sample xiagainst
all other samples xjâˆˆUrâˆ’1
k\xiand form a neighbor set
N(xi)based on the similarity threshold Ï„. A sample xi
is selected if its neighbor counts |N(xi)|are less than the
minimum neighbor size nor if these neighbors remain un-
labeled. Following this criterion, Bkunlabeled samples are
chosen to constitute the final set Qr
kfor annotation, effec-
tively balancing diversity and uncertainty in data selection.
Algorithm 1 Diversity Relaxation for Local Client k
Input: unlabeled set Urâˆ’1
k, local model Î¸k, annotation budget
Bk, similarity threshold Ï„, minimum neighbor size n
Output: query set Qr
k
1:SortUrâˆ’1
kby descending calibrated uncertainty.
2:Initialize index i= 1and query set Qr
k=âˆ….
3:while|Qr
k|< B kandiâ‰¤ |Urâˆ’1
k|do
4: Select a candidate sample xifromUrâˆ’1
k.
5: Compute feature similarity s(xi,xj)using Î¸k, where
xjâˆˆUrâˆ’1
k\xi.
6: Form neighbor set N(xi), including xjwiths(xi,xj)â‰¥Ï„.
7: if|N(xi)|< n orN(xi)âˆ©Qr
k=âˆ…then
8: AddxitoQr
k.
9: end if
10: Increment i.
11:end while
12:return Qr
k
3.4. Evidential Model Learning
Dirichlet-based evidential models treat the categorical pre-
diction of a sample as a distribution, enabling multiple po-
tential predictions to occur with specific probabilities. Con-
sidering all possible predictions, we adopt the Bayes risk
of cross-entropy loss [47] as the task loss for classification
tasks, formulated as follows:
Ltask(x,Î¸k,y) =Z
(CX
c=1âˆ’yclogÏc)Â·p(Ï|x,Î¸k)dÏ
=CX
c=1ycÂ·[Ïˆ(S)âˆ’Ïˆ(Î±c)],(6)where Ïˆ(Â·)is the digamma function and ycis the label indi-
cator for class c. Similarly, the Bayes risk of Dice loss [25]
for segmentation tasks is:
Ltask(x,Î¸k,y) =Z
(1âˆ’2
CCX
c=1âˆ¥ycâ—¦Ïcâˆ¥1
âˆ¥y2
câˆ¥1+âˆ¥Ï2
câˆ¥1)Â·p(Ï|x,Î¸k)dÏ
= 1âˆ’2
CCX
c=1âˆ¥ycâ—¦Ïcâˆ¥1
âˆ¥y2
câˆ¥1+âˆ¥Ï2
câˆ¥1+âˆ¥Ïcâ—¦(1âˆ’Ïc)
S+1âˆ¥1,
(7)
where â—¦is the Hadamard product and the expected categor-
ical probability of xisÏc=Î±c
S. The derivation of Eq. 6
and Eq. 7 are in Appendix B.3.
We incorporate evidence regularization to further reduce
incorrect evidence [47] and improve correct evidence [40].
Lreg(x,Î¸k,y)=KL[Dir(Ï|ËœÎ±)âˆ¥Dir(Ï|1)]âˆ’C
SÂ·f(x,Î¸k),(8)
where ËœÎ±=y+ (1âˆ’y)âŠ™Î±andKL(Â·)denotes the
Kullback-Leibler divergence [22]. Notably, we calculate
the average pixel-wise Lregin segmentation.
The overall training objective, combining task loss Ltask
and evidence regularization Lreg, is formulated as:
L(x,Î¸k,y) =Ltask(x,Î¸k,y) +Î»Â· Lreg(x,Î¸k,y),(9)
where Î»is the trade-off weight. between the task loss and
the regularization term.
4. Experiments
4.1. Experimental Settings
Datasets. We evaluated FEAL on five real multi-center
medical image datasets, comprising two classification and
three segmentation datasets. The classification datasets in-
cluded
â€¢Fed-ISIC : A skin lesion dataset from 4 data sources [39]
containing {12413, 3954, 3363, 2259 }images.
â€¢Fed-Camelyon : A breast cancer histology dataset from 5
centers [16] comprising {59436, 34904, 85054, 129838,
146722 }patches.
The segmentation datasets included
â€¢Fed-Polyp : A endoscopic polyp dataset from 4 cen-
ters [57] with {1000, 196, 379, 612 }samples.
â€¢Fed-Prostate : A prostate MRI dataset from 6 data
sources [30] with {261, 384, 158, 468, 421, 175 }slices.
â€¢Fed-Fundus : A retinal fundus dataset from 4 centers [30]
with{101, 159, 400, 400 }samples.
In our study, each dataset was divided using an 8:2 train-to-
test split ratio at the patient level. Details of these datasets
are provided in Appendix C.1.
Evaluation metrics. For classification, we utilized the Bal-
anced Multi-class Accuracy (BMA) for skin lesion classi-
fication [5] and measured accuracy (ACC) for breast can-
cer histology classification. In the context of segmentation,
11443
1 2 3 4 5
AL round525456586062646668BMA (%)
Full
Random
Entropy (G)
TOD (G)Gradnorm (G)
CoreSet (G)
BADGE (G)
Ours+ 1.98+ 1.04+ 2.08 + 2.84(a) Fed-ISIC ( G)
1 2 3 4 5
AL round525456586062646668BMA (%)
Full
Random
Entropy (L)
TOD (L)Gradnorm (L)
CoreSet (L)
BADGE (L)
Ours+ 2.02+ 0.92+ 1.48 + 2.06 (b) Fed-ISIC ( L)
1 2 3 4 5
AL round525456586062646668BMA (%)
Full
Random
Entroopy (E)
TOD (E)
Gradnorm (E)CoreSet (E)
BADGE (E)
LoGo
KAFAL
Ours+ 1.95+ 1.21+ 1.39 + 1.62 (c) Fed-ISIC ( E)
1 2 3 4 5
AL round939495969798ACC (%)
Full
Random
Entropy (G)
TOD (G)Gradnorm (G)
CoreSet (G)
BADGE (G)
Ours+ 0.88+ 0.57+ 0.51+ 0.44
(d) Fed-Camelyon ( G)
1 2 3 4 5
AL round939495969798ACC (%)
Full
Random
Entropy (L)
TOD (L)Gradnorm (L)
CoreSet (L)
BADGE (L)
Ours+ 0.69+ 0.51+ 0.35+ 0.44 (e) Fed-Camelyon ( L)
1 2 3 4 5
AL round939495969798ACC (%)
Full
Random
Entropy (E)
TOD (E)
Gradnorm (E)CoreSet (E)
BADGE (E)
LoGo
KAFAL
Ours+ 0.73+ 0.46+ 0.32+ 0.37 (f) Fed-Camelyon ( E)
Figure 3. Comparison of FAL methods in medical image classification. (a)-(c) and (d)-(f) depict the results of the Fed-ISIC and Fed-
Camelyon datasets, respectively. Performance enhancements over the second-best method in each FAL round are emphasized in red text.
we used the Dice score and the 95% Hausdorff Distance
(HD95) to assess segmentation results.
Implementation details. We conducted R= 5 rounds of
FAL involving federated model training and data annota-
tion. The annotation budget Bkis500for Fed-ISIC and
Fed-Camelyon, 50for Fed-Polyp, and 20for Fed-Prostate
and Fed-Fundus. During model training, we followed the
previous work [16, 57, 59] to utilize EfficientNet-B0 [53]
for Fed-ISIC, DenseNet-121 [13] for Fed-Camelyon, and
U-Net [30, 45] for segmentation datasets. Notably, both
EfficientNet-B0 and DenseNet-121 were pre-trained on Im-
ageNet [7]. Each experiment was conducted three times us-
ing different random seeds, and the average results were re-
ported. More details are in Appendix C.1.
Comparison methods. We compared FEAL with eight
FAL methods, including random sampling (Random),
entropy-based sampling (Entropy) [50], TOD [14], Grad-
norm [58], CoreSet [46], BADGE [2], LoGo [20], and
KAFAL [3]. The first six strategies are primarily developed
for standard active learning, whereas LoGo and KAFAL
are specifically tailored for decentralized scenarios. To in-
corporate these standard AL strategies into the FAL frame-
work, we implemented them in three distinct manners: us-
ing only the global model (referred to as G), depending
solely on the local model ( L), or employing a simple en-
semble method with both models ( E). It guarantees a com-
prehensive evaluation of these strategies in FAL. Details of
comparison methods are summarized in Appendix C.1.4.2. Results
Image classification. The comparative analysis of image
classification results in Fig. 3 indicates that FEAL achieves
superior results on both Fed-ISIC and Fed-Camelyon
datasets. As depicted in Fig. 3, the performance of all meth-
ods exhibits a general trend of improvement with the incre-
mental inclusion of labeled samples. However, an exception
to this trend is observed in the Fed-ISIC dataset as shown
in Fig. 3(a). As observed, the exclusive use of Entropy,
Gradnorm, and CoreSet with a single model, whether it is a
global (see Fig. 3(a)) or local model (see Fig. 3(b)), results
in suboptimal performance, leading to a notable decrease in
effectiveness beginning from the third round. The global
model delivers unreliable uncertainty evaluations, which
may result in suboptimal data selection and adversely affect
the ability of the model to generalize effectively. Moreover,
selecting data based on evaluations from the local model can
cause overfitting to its specific client, negatively impacting
the performance. Conversely, methods like Gradnorm ( E)
and TOD ( E) that combine both global and local models
often outperform those relying solely on the global model,
benefiting from the additional domain-specific knowledge
of the local model. However, it is important to note that
without proper calibration of the global model, the com-
bined use of both models does not always guarantee better
performance than solely using the local model.
Remarkably, FEAL consistently outperforms state-of-
the-art FAL methods on Fed-ISIC, as shown in Fig. 3(a)-
(c). This superiority is especially noticeable in the fifth FAL
round, where FEAL achieves a substantial performance
11444
Table 1. Comparison of FAL methods in medical image segmentation. Dice scores for three segmentation datasets are reported. For
Fed-Fundus, Dice scores for both optic disc and optic cup segmentation and their average are presented. GandLstand for sampling solely
with the global or local model, while Erepresents sampling with both models. Red and blue highlight the Top-1 and Top-2 results.
Model MethodFed-Polyp (%) Fed-Prostate (%) Fed-Fundus (%)
R2 R3 R4 R5 R2 R3 R4 R5 R2 R3 R4 R5
- Full 78.18 88.02 94.32 / 85.70 (90.01)
- Random 67.70 72.16 75.58 76.32 80.29 82.70 83.94 84.77 92.30 / 81.41 (86.85) 93.33 / 84.45 (88.89) 94.29 / 84.80 (89.54) 94.46 / 85.05 (89.76)
GEntropy [50] 67.45 74.65 75.30 76.69 82.17 82.53 84.05 86.10 93.19 / 82.61 (87.90) 93.84 / 84.35 (89.10) 94.27 / 85.34 (89.80) 94.47 / 85.29 (89.88)
TOD [14] 64.99 74.61 76.24 78.26 80.75 83.48 84.31 85.82 92.70 / 82.49 (87.60) 93.95 / 85.01 (89.48) 94.27 / 85.63 (89.95) 94.71 / 85.58 (90.14)
Gradnorm [58] 69.14 74.58 75.79 78.51 82.10 83.01 84.85 86.02 93.20 / 82.01 (87.60) 94.12 / 84.71 (89.41) 94.33 / 85.38 (89.85) 94.56 / 85.43 (89.99)
CoreSet [46] 69.50 73.37 76.71 78.18 82.11 83.68 84.56 85.86 93.00 / 83.07 (88.03) 93.90 / 84.75 (89.32) 94.16 / 85.35 (89.75) 94.51 / 85.63 (90.07)
BADGE [2] 70.09 74.11 76.38 76.55 82.78 83.91 85.39 85.97 93.17 / 82.54 (87.85) 94.07 / 84.46 (89.26) 94.40 / 85.37 (89.89) 94.58 / 85.19 (89.89)
LEntropy 67.48 73.41 75.07 78.63 81.08 82.22 84.36 85.19 93.19 / 83.22 (88.21) 93.83 / 84.49 (89.16) 94.36 / 84.97 (89.66) 94.63 / 85.68 (90.15)
TOD [14] 65.95 72.92 75.19 77.97 79.59 83.74 85.50 86.03 92.82 / 82.34 (87.58) 93.98 / 85.00 (89.49) 94.37 / 85.28 (89.83) 94.65 / 85.56 (90.10)
Gradnorm [58] 70.06 74.69 77.25 78.84 80.52 83.43 84.94 86.04 93.29 / 83.04 (88.16) 94.13 / 84.69 (89.41) 94.33 / 85.60 (89.97) 94.42 / 85.53 (89.98)
CoreSet [46] 68.92 74.06 75.59 77.75 81.49 83.49 84.65 86.19 92.80 / 83.20 (88.00) 93.87 / 84.70 (89.28) 94.28 / 85.42 (89.85) 94.47 / 85.54 (90.00)
BADGE [2] 70.28 73.96 76.21 77.63 82.07 83.54 85.30 86.06 93.06 / 82.65 (87.85) 93.95 / 84.44 (89.19) 94.34 / 85.02 (89.68) 94.54 / 85.52 (90.03)
EEntropy [50] 67.85 75.10 76.80 77.20 80.95 83.66 84.81 85.42 93.26 / 82.77 (88.01) 94.04 / 84.69 (89.36) 94.33 / 85.31 (89.82) 94.38 / 85.10 (89.74)
TOD [14] 67.25 70.43 74.84 77.53 81.45 84.46 84.51 85.65 93.13 / 82.70 (87.92) 93.63 / 84.64 (89.14) 94.31 / 85.30 (89.81) 94.54 / 85.82 (90.18)
Gradnorm [58] 68.01 75.75 77.73 75.67 81.21 83.43 85.30 85.13 93.36 / 83.09 (88.23) 93.83 / 84.91 (89.37) 94.33 / 85.59 (89.96) 94.65 / 85.52 (90.08)
CoreSet [46] 67.77 74.28 77.69 75.87 81.30 84.52 84.75 86.50 93.24 / 82.55 (87.89) 93.63 / 84.86 (89.24) 94.20 / 85.50 (89.85) 94.62 / 85.89 (90.25)
BADGE [2] 69.12 75.45 77.37 76.24 81.31 84.34 85.92 85.55 93.37 / 82.95 (88.16) 93.99 / 85.00 (89.50) 94.50 / 85.22 (89.86) 94.62 / 85.44 (90.03)
LoGo [20] 69.07 75.76 74.63 77.24 82.35 84.56 85.53 85.97 93.14 / 83.01 (88.08) 93.93 / 84.55 (89.24) 94.18 / 85.68 (89.93) 94.61 / 85.64 (90.12)
KAFAL [3] 69.69 73.83 75.38 77.97 82.65 83.49 85.58 85.96 93.11 / 82.75 (87.93) 94.01 / 84.12 (89.06) 94.37 / 85.16 (89.77) 94.46 / 85.02 (89.74)
FEAL (Ours) 72.06 76.39 78.62 80.18 82.94 85.29 86.77 87.42 93.53 / 83.72 (88.63) 94.25 / 85.19 (89.72) 94.60 / 85.96 (90.28) 94.89 / 86.27 (90.58)
gain of 1.62% over the second-best method, CoreSet ( E),
as demonstrated in Fig. 3(c). Additionally, it is noteworthy
that FEAL achieves a performance comparable to training
with the fully annotated dataset in the third round and even
exceeds the fully supervised performance by 0.84% in the
fifth round. These advancements are primarily attributable
to the effective uncertainty calibration and demonstrate the
efficacy of FEAL. It is noteworthy that the baseline meth-
ods KAFAL and LoGo, designed for FAL underperform in
real-world federated scenarios. Despite showing impressive
results in simulated federated datasets, they fail to repli-
cate this success in actual multi-center federated scenarios.
This is mainly due to the inherent domain shift characteris-
tics of multi-center medical data. As depicted in Fig. 3(d)-
(f), FEAL also achieves superior performance on the large-
scale dataset Fed-Camelyon, where each local client con-
tains tens of thousands of patches. By employing a low-
data regime, where merely about 3.43% of the total train-
ing samples are annotated in the active learning process,
FEAL attains 99.40% of fully supervised performance af-
ter five rounds of FAL. This achievement represents a sig-
nificant improvement compared to the second-best method,
KAFAL, which reaches 98.93% of the fully supervised per-
formance, demonstrating the effectiveness of uncertainty
calibration in FEAL. Additional results with different an-
notation budgets/ratios are available in Appendix C.2.
Image segmentation. To further evaluate the effective-
ness of FEAL in segmentation tasks, we conducted experi-
ments on three real multi-center datasets: Fed-Polyp, Fed-
Prostate, and Fed-Fundus, with the results summarized in
Tab. 1. As can be seen, FEAL exhibits superior perfor-
mance on three multi-center segmentation datasets, as ev-
idenced by its higher Dice scores. Specifically, for Fed-
Polyp, FEAL yields a Dice score of 80.18% in the fifthround, outperforming the second-best method Gradnorm
(L) by1.34% and surpassing fully-supervised training by
2.00%. For Fed-Prostate, FEAL demonstrates improve-
ments of 0.85% and0.92% over the second-best method
in the fourth and fifth FAL rounds, respectively. For Fed-
Fundus, FEAL not only surpasses other methods in seg-
menting both the optic disc and optic cup but also outper-
forms fully supervised training in the fourth and fifth rounds
of FAL. Complete results including HD95 and standard de-
viation are available in Appendix C.2.
4.3. Discussion
Effect of uncertainty calibration. We conducted exper-
iments on Fed-ISIC to evaluate the effects of different un-
certainty combinations: UG
epi,UG
ale, andUL
ale. As summarized
in Tab. 2, combining aleatoric uncertainty from both global
and local models proves more effective than relying on just
one model. The best results are obtained with UG
epi,UG
ale, and
UL
ale, showcasing the effectiveness of the proposed uncer-
tainty calibration. The ablation results on Fed-Polyp are in
Appendix C.3. Moreover, we visualize the aleatoric uncer-
tainty in both models on Fed-Polyp in Fig. 4. It is noticeable
thatUG
aleandUL
alehighlight different regions, underscoring
the importance of combining aleatoric uncertainty in both
models for a more comprehensive assessment.
Table 2. Ablation study of uncertainty calibration on Fed-ISIC.
UG
epiUG
aleUL
aleRound 2 Round 3 Round 4 Round 5
-âœ“ -60.61Â±1.5766.60Â±0.3367.09Â±1.0266.57Â±1.21
- - âœ“ 62.20Â±3.5666.84Â±1.9966.13Â±1.5267.45Â±0.69
-âœ“ âœ“ 63.43Â±1.1167.18Â±0.5566.58Â±1.0266.70Â±0.28
âœ“ - - 61.97Â±1.2565.87Â±0.5967.09Â±1.2466.41Â±1.10
âœ“ âœ“ -61.95Â±2.1266.08Â±0.4067.19Â±1.0266.85Â±0.84
âœ“ -âœ“ 61.07Â±1.2465.17Â±1.5867.16Â±0.7365.92Â±1.95
âœ“âœ“âœ“ 65.18Â±0.4167.77Â±1.3168.41Â±1.0168.46Â±0.37
11445
InputGround truthğ‘ˆ!"#$ğ‘ˆ!"#%ğ‘ˆ!"#$+ğ‘ˆ!"#%Figure 4. Visualization of aleatoric uncertainty on Fed-Polyp. UG
ale
andUL
aledenote the aleatoric uncertainty in the global and local
models, respectively.
Effect of diversity relaxation. We analyzed the impact of
hyperparameters, i.e.minimum neighbor size nand sim-
ilarity threshold Ï„, on Fed-ISIC. As depicted in Fig. 5(a),
eliminating diversity relaxation (â€˜w/o relaxationâ€™) results in
a notable reduction in BMA in the fifth round, and the best
performance is achieved with n=5andÏ„=0.85. The abla-
tion results on Fed-Polyp are reported in Appendix C.3.
1 2 3 4 5
AL round52.555.057.560.062.565.067.5BMA (%)
w/o relaxation
3 neighbors
5 neighbors (Ours)
7 neighbors
9 neighbors
(a) Minimum neighbor size n
1 2 3 4 5
AL round52.555.057.560.062.565.067.5BMA (%)
=0.75
=0.80
=0.85 (Ours)
=0.90
 (b) Similarity threshold Ï„
Figure 5. Ablation study of diversity relaxation on Fed-ISIC.
Effect of evidential model training. We performed exper-
iments to compare the evidential loss ( Lin Eq. 9) against
cross-entropy loss (CE) on Fed-ISIC and against dice loss
(Dice) on Fed-Polyp. The results are detailed in Tab. 3. As
can be seen, training with evidential loss results in an aver-
age performance gain of 1.03% on Fed-ISIC and 1.16% on
Fed-Polyp, respectively. This improvement can be primar-
ily attributed to evidence regularization, demonstrating the
efficacy of evidential model training. The ablation results
on the other three datasets are available in Appendix C.3.
Table 3. Ablation study of loss function.
Dataset Loss Round 2 Round 3 Round 4 Round 5
Fed-ISICCE 64.28Â±1.6466.69Â±0.9567.32Â±1.1667.40Â±0.22
L 65.18Â±0.4167.77Â±1.3168.41Â±1.0168.46Â±0.37
Fed-PolypDice 70.14Â±0.1075.77Â±0.6777.23Â±0.2179.48Â±0.62
L 72.06Â±0.7276.39Â±0.6678.62Â±1.4480.18Â±0.10
Effect of trade-off weight Î». We further de-
termined the optimal setting for the hyperparame-
terÎ»on Fed-ISIC, choosing from the candidate set
{1eâˆ’3,5eâˆ’3,1eâˆ’2,5eâˆ’2,1eâˆ’1}, the results are detailed
in Tab. 4. As can be seen, the best performance is achieved
when Î»= 1eâˆ’2. The ablation results on Fed-Polyp are
reported in Appendix C.3.
Analysis of Dirichlet simplex. We analyze the Dirich-
let simplex on a subset of Fed-ISIC encompassing threeTable 4. Ablation study of trade-off weight Î»on Fed-ISIC.
Î» Round 2 Round 3 Round 4 Round 5
1eâˆ’3 63.49Â±3.00 64.57Â±2.70 66.25Â±1.17 65.45Â±1.06
5eâˆ’3 63.10Â±2.07 65.79Â±2.57 66.00Â±2.09 66.48Â±0.86
1eâˆ’2 65.18Â±0.41 67.77Â±1.31 68.41Â±1.01 68.46Â±0.37
5eâˆ’2 62.12Â±0.99 67.21Â±1.42 66.92Â±0.70 66.90Â±0.93
1eâˆ’1 63.53Â±2.03 66.21Â±0.35 66.03Â±2.34 67.78Â±1.17
classes. As illustrated in Fig. 6, when selecting samples
with FEAL, the Dirichlet distribution becomes more con-
centrated at the simplexâ€™s corner for unlabeled samples, in-
dicating reduced epistemic uncertainty in the global model.
This trend verifies the effectiveness of CES in addressing
domain shifts. Additionally, starting with an identical set
of labeled samples, we tracked the selection of samples in
the second FAL round utilizing various FAL methods. The
Dirichlet simplexes of different methods are visualized in
Fig. 7. As can be seen, the Dirichlet distribution of sam-
ples selected by FEAL showcases a broader spread across
the simplex, indicating that FEAL effectively models the
global modelâ€™s knowledge of local data and prioritizes se-
lecting samples characterized by high epistemic uncertainty.
More details and results are available in Appendix C.3.
ğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’4.03
MELBCCBKLRound 1
ğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’4.42
MELBCCBKLRound 2
ğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’5.03
MELBCCBKLRound 3
MELBCCBKLğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’5.55Round 4
MELBCCBKLğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’6.22Round 5
MELBCCBKLEntropy
MELBCCBKLCoreSet
MELBCCBKLLoGo
MELBCCBKLKAFAL
MELBCCBKLOurs
MELBCCBKL
MELBCCBKLBKLBKLBKLMELBCCMELBCCMELBCC
BKLMELBCCBKLMELBCCBKLMELBCCBKLMELBCCBKLMELBCC
Figure 6. Visualization of the Dirichlet simplex for unlabeled sam-
ples across five FAL rounds using FEAL.
MELBCCBKLEntropy
MELBCCBKLCoreSet
MELBCCBKLLoGo
MELBCCBKLKAFAL
MELBCCBKLOursğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’4.03
MELBCCBKLRound 1
ğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’4.42
MELBCCBKLRound 2
ğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’5.03
MELBCCBKLRound 3
MELBCCBKLğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’5.55Round 4
MELBCCBKLğ‘ˆ!"#(ğ’™,ğœ½)=âˆ’6.22Round 5
Figure 7. Visualization of the Dirichlet simplex for samples se-
lected in the second FAL round using various sampling strategies.
5. Conclusion and Social Impact
To address the challenge of unreliable data assessment us-
ing the global model under domain shifts, we proposed a
method FEAL, which places a Dirichlet prior over categori-
cal probabilities to treat the prediction as a distribution over
the probability simplex and leverages both aleatoric uncer-
tainty and epistemic uncertainty to calibrate the uncertainty
evaluation, enhancing the reliability of data assessment and
incorporating diversity relaxation to maintain sample diver-
sity. Extensive results verify the effectiveness. This work
holds the potential to advance healthcare by preserving data
privacy and facilitating collaborative research, ultimately
leading to more accessible and effective patient care.
11446
References
[1] Jin-Hyun Ahn, Kyungsang Kim, Jeongwan Koh, and
Quanzheng Li. Federated active learning (f-al): an efficient
annotation strategy for federated learning. arXiv preprint
arXiv:2202.00195 , 2022. 2, 3
[2] Jordan T Ash, Chicheng Zhang, Akshay Krishnamurthy,
John Langford, and Alekh Agarwal. Deep batch active learn-
ing by diverse, uncertain gradient lower bounds. In ICLR ,
2020. 3, 6, 7
[3] Yu-Tong Cao, Ye Shi, Baosheng Yu, Jingya Wang, and
Dacheng Tao. Knowledge-aware federated active learning
with non-iid data. In ICCV , pages 22279â€“22289, 2023. 2, 3,
6, 7
[4] Razvan Caramalau, Binod Bhattarai, and Tae-Kyun Kim. Se-
quential graph convolutional network for active learning. In
CVPR , pages 9583â€“9592, 2021. 2, 3
[5] Bill Cassidy, Connah Kendrick, Andrzej Brodzicki, Joanna
Jaworek-Korjakowska, and Moi Hoon Yap. Analysis of the
isic image datasets: Usage, benchmarks and recommenda-
tions. Med. Image. Anal. , 75:102305, 2022. 5
[6] Zhen Chen, Meilu Zhu, Chen Yang, and Yixuan Yuan. Per-
sonalized retrogress-resilient framework for real-world med-
ical federated learning. In MICCAI , pages 347â€“356, 2021.
2
[7] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In CVPR , pages 248â€“255. IEEE, 2009. 6
[8] Ehsan Elhamifar, Guillermo Sapiro, Allen Yang, and
S Shankar Sasrty. A convex optimization framework for ac-
tive learning. In ICCV , pages 209â€“216, 2013. 3
[9] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian
approximation: representing model uncertainty in deep
learning. In ICML , 2016. 3
[10] Yarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep
bayesian active learning with image data. In ICML , 2017. 3
[11] Mingfei Gao, Zizhao Zhang, Guo Yu, Sercan Â¨O ArÄ±k,
Larry S Davis, and Tomas Pfister. Consistency-based semi-
supervised active learning: Towards minimizing labeling
cost. In ECCV , pages 510â€“526, 2020. 3
[12] Yongxin Guo, Xiaoying Tang, and Tao Lin. Fedbr: improv-
ing federated learning on heterogeneous data via local learn-
ing bias reduction. In ICML , pages 12034â€“12054, 2023. 2
[13] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil-
ian Q Weinberger. Densely connected convolutional net-
works. In CVPR , pages 4700â€“4708, 2017. 6
[14] Siyu Huang, Tianyang Wang, Haoyi Xiong, Jun Huan, and
Dejing Dou. Semi-supervised active learning with temporal
output discrepancy. In ICCV , pages 3447â€“3456, 2021. 2, 3,
6, 7
[15] Wenke Huang, Mang Ye, Zekun Shi, He Li, and Bo Du. Re-
thinking federated learning with domain shift: A prototype
view. In CVPR , pages 16312â€“16322. IEEE, 2023. 2
[16] Meirui Jiang, Zirui Wang, and Qi Dou. Harmofl: Harmoniz-
ing local and global drifts in federated learning on heteroge-
neous medical images. In AAAI , pages 1087â€“1095, 2022. 5,
6[17] Meirui Jiang, Holger R Roth, Wenqi Li, Dong Yang, Can
Zhao, Vishwesh Nath, Daguang Xu, Qi Dou, and Ziyue Xu.
Fair federated medical image segmentation via client contri-
bution estimation. In CVPR , pages 16302â€“16311, 2023. 2
[18] Audun JÃ¸sang. Subjective logic . 2016. 4
[19] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri,
Sashank Reddi, Sebastian Stich, and Ananda Theertha
Suresh. Scaffold: Stochastic controlled averaging for fed-
erated learning. In ICML , pages 5132â€“5143, 2020. 2
[20] SangMook Kim, Sangmin Bae, Hwanjun Song, and Se-
Young Yun. Re-thinking federated active learning based on
inter-class diversity. In CVPR , pages 3944â€“3953, 2023. 2, 3,
6, 7
[21] Jakub Kone Ë‡cn`y, H Brendan McMahan, Daniel Ramage, and
Peter Richt Â´arik. Federated optimization: Distributed ma-
chine learning for on-device intelligence. arXiv preprint
arXiv:1610.02527 , 2016. 1
[22] Solomon Kullback and Richard A Leibler. On information
and sufficiency. The annals of mathematical statistics , 22(1):
79â€“86, 1951. 5
[23] Natsumaro Kutsuna, Takumi Higaki, Sachihiro Matsunaga,
Tomoshi Otsuki, Masayuki Yamaguchi, Hirofumi Fujii, and
Seiichiro Hasezawa. Active learning framework with itera-
tive clustering for bioimage classification. Nat. Commun. , 3
(1):1032, 2012. 3
[24] Haohan Li and Zhaozheng Yin. Attention, suggestion and
annotation: a deep active learning framework for biomedical
image segmentation. In MICCAI , pages 3â€“13, 2020. 3
[25] Hao Li, Yang Nan, Javier Del Ser, and Guang Yang. Region-
based evidential deep learning to quantify uncertainty and
improve robustness of brain tumor segmentation. Neural
Comput. Appl. , pages 1â€“15, 2022. 5
[26] Qinbin Li, Bingsheng He, and Dawn Song. Model-
contrastive federated learning. In CVPR , pages 10713â€“
10722, 2021. 2
[27] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith. Federated optimiza-
tion in heterogeneous networks. MLSys , 2:429â€“450, 2020.
2
[28] Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp,
and Qi Dou. Fedbn: Federated learning on non-iid
features via local batch normalization. arXiv preprint
arXiv:2102.07623 , 2021. 2
[29] Zexi Li, Tao Lin, Xinyi Shang, and Chao Wu. Revisiting
weighted aggregation in federated learning with neural net-
works. arXiv preprint arXiv:2302.10911 , 2023. 2
[30] Quande Liu, Cheng Chen, Jing Qin, Qi Dou, and Pheng-Ann
Heng. Feddg: Federated domain generalization on medical
image segmentation via episodic learning in continuous fre-
quency space. In CVPR , pages 1013â€“1023, 2021. 2, 5, 6
[31] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li.
Energy-based out-of-distribution detection. NeurIPS , 33:
21464â€“21475, 2020. 2
[32] Benteng Ma, Yu Feng, Geng Chen, Changyang Li, and Yong
Xia. Federated adaptive reweighting for medical image clas-
sification. Pattern Recogn. , 144:109880, 2023. 2
11447
[33] Benteng Ma, Jing Zhang, Yong Xia, and Dacheng Tao. Vnas:
Variational neural architecture search. Int. J. Comput. Vis. ,
2024. 2
[34] James MacQueen et al. Some methods for classification
and analysis of multivariate observations. In Proceedings of
the fifth Berkeley symposium on mathematical statistics and
probability , pages 281â€“297, 1967. 3
[35] Andrey Malinin and Mark Gales. Predictive uncertainty es-
timation via prior networks. NeurIPS , 31, 2018. 4
[36] Brendan McMahan, Eider Moore, Daniel Ramage, Seth
Hampson, and Blaise Aguera y Arcas. Communication-
efficient learning of deep networks from decentralized data.
InAISTATS , pages 1273â€“1282, 2017. 1
[37] Robert Munro Monarch. Human-in-the-Loop Machine
Learning: Active learning and annotation for human-
centered AI . Simon and Schuster, 2021. 2, 3
[38] Hieu T Nguyen and Arnold Smeulders. Active learning using
pre-clustering. In ICML , page 79, 2004. 3
[39] Jean Ogier du Terrail, Samy-Safwan Ayed, Edwige Cyffers,
Felix Grimberg, Chaoyang He, Regis Loeb, Paul Mangold,
Tanguy Marchand, Othmane Marfoq, Erum Mushtaq, et al.
Flamby: Datasets and benchmarks for cross-silo federated
learning in realistic healthcare settings. NeurIPS , 35:5315â€“
5334, 2022. 5
[40] Deep Shankar Pandey and Qi Yu. Learn to accumulate ev-
idence from all training samples: Theory and practice. In
ICML , pages 26963â€“26989, 2023. 5
[41] Amin Parvaneh, Ehsan Abbasnejad, Damien Teney, Gholam-
reza Reza Haffari, Anton van den Hengel, and Javen Qinfeng
Shi. Active learning by feature mixing. In CVPR , pages
12237â€“12246, 2022. 2, 3
[42] Tim Pearce. Uncertainty in neural networks; bayesian en-
sembles, priors & prediction intervals . PhD thesis, Univer-
sity of Cambridge, 2020. 2
[43] Tim Pearce, Alexandra Brintrup, and Jun Zhu. Under-
standing softmax confidence and uncertainty. arXiv preprint
arXiv:2106.04972 , 2021. 2
[44] Yasar Abbas Ur Rehman, Yan Gao, Pedro Porto Buarque
De Gusm Ëœao, Mina Alibeigi, Jiajun Shen, and Nicholas D
Lane. L-dawa: Layer-wise divergence aware weight ag-
gregation in federated self-supervised visual representation
learning. In ICCV , pages 16464â€“16473, 2023. 2
[45] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net:
Convolutional networks for biomedical image segmentation.
InMICCAI , pages 234â€“241, 2015. 6
[46] Ozan Sener and Silvio Savarese. Active learning for convolu-
tional neural networks: A core-set approach. arXiv preprint
arXiv:1708.00489 , 2017. 2, 3, 6, 7
[47] Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evi-
dential deep learning to quantify classification uncertainty.
NeurIPS , 31, 2018. 2, 4, 5
[48] Kari Sentz and Scott Ferson. Combination of evidence in
dempster-shafer theory. 2002. 4
[49] Burr Settles. Active learning literature survey. 2009. 3
[50] Claude Elwood Shannon. A mathematical theory of commu-
nication. Bell Syst. Tech. J. , 27(3):379â€“423, 1948. 3, 4, 6,
7[51] Maohao Shen, Yuheng Bu, Prasanna Sattigeri, Soumya
Ghosh, Subhro Das, and Gregory Wornell. Post-hoc uncer-
tainty learning using a dirichlet meta-model. In AAAI , pages
9772â€“9781, 2023. 2
[52] Neta Shoham, Tomer Avidor, Aviv Keren, Nadav Israel,
Daniel Benditkis, Liron Mor-Yosef, and Itai Zeitak. Over-
coming forgetting in federated learning on non-iid data.
arXiv preprint arXiv:1910.07796 , 2019. 2
[53] Mingxing Tan and Quoc Le. Efficientnet: Rethinking model
scaling for convolutional neural networks. In ICML , pages
6105â€“6114, 2019. 6
[54] Dennis Ulmer, Christian Hardmeier, and Jes Frellsen. Prior
and posterior networks: A survey on evidential deep learning
methods for uncertainty estimation. TMLR , 2023. 2
[55] Ruth Urner, Sharon Wulff, and Shai Ben-David. Plal:
Cluster-based active learning. In COLT , pages 376â€“397,
2013. 3
[56] Fan Wang, Zhongyi Han, Zhiyan Zhang, Rundong He, and
Yilong Yin. Mhpl: Minimum happy points learning for ac-
tive source free domain adaptation. In CVPR , pages 20008â€“
20018, 2023. 3
[57] Jiacheng Wang, Yueming Jin, and Liansheng Wang. Per-
sonalizing federated medical image segmentation via local
calibration. In ECCV , pages 456â€“472, 2022. 1, 2, 5, 6
[58] Tianyang Wang, Xingjian Li, Pengkun Yang, Guosheng Hu,
Xiangrui Zeng, Siyu Huang, Cheng-Zhong Xu, and Min Xu.
Boosting active learning via improving test performance. In
AAAI , pages 8566â€“8574, 2022. 6, 7
[59] Jeffry Wicaksana, Zengqiang Yan, and Kwang-Ting
Cheng. Fca: Taming long-tailed federated medical im-
age classification by classifier anchoring. arXiv preprint
arXiv:2305.00738 , 2023. 6
[60] Nannan Wu, Li Yu, Xin Yang, Kwang-Ting Cheng, and
Zengqiang Yan. Fediic: Towards robust federated learning
for class-imbalanced medical image classification. In MIC-
CAI, pages 692â€“702, 2023. 2
[61] Xing Wu, Jie Pei, Cheng Chen, Yimin Zhu, Jianjia Wang,
Quan Qian, Jian Zhang, Qun Sun, and Yike Guo. Federated
active learning for multicenter collaborative disease diagno-
sis.IEEE Trans. Med. Imaging. , 2022. 2, 3
[62] Mixue Xie, Shuang Li, Rui Zhang, and Chi Harold Liu.
Dirichlet-based uncertainty calibration for active domain
adaptation. arXiv preprint arXiv:2302.13824 , 2023. 2, 4
[63] Yi Yang, Zhigang Ma, Feiping Nie, Xiaojun Chang, and
Alexander G Hauptmann. Multi-class active learning by un-
certainty sampling with diversity maximization. Int. J. Com-
put. Vis. , 113:113â€“127, 2015. 3
[64] Mang Ye, Xiuwen Fang, Bo Du, Pong C Yuen, and Dacheng
Tao. Heterogeneous federated learning: State-of-the-art and
research challenges. ACM Comput. Surv. , 56(3):1â€“44, 2023.
2
[65] Donggeun Yoo and In So Kweon. Learning loss for active
learning. In CVPR , 2019. 2, 3
[66] Jiakang Yuan, Bo Zhang, Xiangchao Yan, Tao Chen, Botian
Shi, Yikang Li, and Yu Qiao. Bi3d: Bi-domain active learn-
ing for cross-domain 3d object detection. In CVPR , pages
15599â€“15608, 2023. 3
11448
[67] Ruipeng Zhang, Qinwei Xu, Jiangchao Yao, Ya Zhang, Qi
Tian, and Yanfeng Wang. Federated domain generalization
with generalization adjustment. In CVPR , pages 3954â€“3963,
2023. 2
[68] Tianfei Zhou and Ender Konukoglu. Fedfa: Federated fea-
ture augmentation. arXiv preprint arXiv:2301.12995 , 2023.
2
11449
