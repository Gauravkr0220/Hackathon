Diffusion-Based Cloud-Edge-Device Collaborative Learning for
Next POI Recommendations
Jing Long
jing.long@uq.edu.au
The University of Queensland
Brisbane, AustraliaGuanhua Ye
g.ye@bupt.edu.cn
Beijing University of Posts and
Telecommunications
Beijing, ChinaTong Chen
tong.chen@uq.edu.au
The University of Queensland
Brisbane, Australia
Yang Wang
yangwang@hfut.edu.cn
Hefei University of Technology
Hefei, ChinaMeng Wang
eric.mengwang@gmail.com
Hefei University of Technology
Hefei, ChinaHongzhi Yin*
h.yin1@uq.edu.au
The University of Queensland
Brisbane, Australia
Abstract
The rapid expansion of Location-Based Social Networks (LBSNs)
has highlighted the importance of effective next Point-of-Interest
(POI) recommendations, which leverage historical check-in data
to predict users‚Äô next POIs to visit. Traditional centralized deep
neural networks (DNNs) offer impressive POI recommendation
performance but face challenges due to privacy concerns and lim-
ited timeliness. In response, on-device POI recommendations have
been introduced, utilizing federated learning (FL) and decentral-
ized approaches to ensure privacy and recommendation timeliness.
However, these methods often suffer from computational strain on
devices and struggle to adapt to new users and regions. This paper
introduces a novel collaborative learning framework, Diffusion-
Based Cloud-Edge-Device Collaborative Learning for Next POI
Recommendations (DCPR), leveraging the diffusion model known
for its success across various domains. DCPR operates with a cloud-
edge-device architecture to offer region-specific and highly person-
alized POI recommendations while reducing on-device computa-
tional burdens. DCPR minimizes on-device computational demands
through a unique blend of global and local learning processes. Our
evaluation with two real-world datasets demonstrates DCPR‚Äôs su-
perior performance in recommendation accuracy, efficiency, and
adaptability to new users and regions, marking a significant step
forward in on-device POI recommendation technology.
CCS Concepts
‚Ä¢Information systems ‚ÜíRecommender systems.
*Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671743Keywords
Point-of-Interest Recommendations; On-Device POI Recommenda-
tions; Diffusion Models
ACM Reference Format:
Jing Long, Guanhua Ye, Tong Chen, Yang Wang, Meng Wang, and Hongzhi
Yin*. 2024. Diffusion-Based Cloud-Edge-Device Collaborative Learning
for Next POI Recommendations. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ‚Äô24), August
25‚Äì29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages. https:
//doi.org/10.1145/3637528.3671743
1 Introduction
The emergence of Location-Based Social Networks (LBSNs), such as
Foursquare and Weeplace, has improved the way we interact with
our surroundings. These platforms, accumulating vast amounts of
historical check-in data, have become fertile ground for developing
Point-of-Interest (POI) recommendation systems. Given the power-
ful computational capabilities of servers, centralized deep neural
networks (DNNs) based on graph embedding [ 18,41,48] and atten-
tion mechanisms [ 20,26] demonstrate impressive performance in
POI recommendations. Unfortunately, due to increasing concerns
regarding privacy and the location-sensitive nature of POI recom-
mendations, users are becoming increasingly cautious and even
reluctant to upload their check-in data, thereby impacting the rec-
ommendation quality [ 25,52]. Apart from this, recommendations in
centralized services are computed upon request and then transmit-
ted to user devices, making the service timeliness highly dependent
on network quality [ 24]. Thus, on-device POI recommendations
have emerged, aimed at mitigating the limitations of centralized
paradigms [ 50]. That is, each user locally hosts a lightweight rec-
ommendation model that generates personalized recommendations
without sharing sensitive data, which also warrants responsiveness.
Being a widely recognized approach under this paradigm, feder-
ated learning (FL) based POI recommendations (e.g., [ 10]) centrally
collect and aggregate locally trained models, as well as redistribut-
ing the aggregated model to all users. However, all users sharing
the same model may hurt the minority groups and impair the rec-
ommendation quality of these users. To achieve a higher degree
of personalization, instead of aggregating all user models, some
federated POI recommenders [ 13,33,36,43] group similar users
 
2026
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jing Long et al.
and perform aggregation within groups. Further remedy is pro-
posed in decentralized POI recommenders [ 23,24], where users can
directly engage in collaborative learning with their neighbors in a
device-to-device manner, allowing more personalization of learned
on-device models. Unfortunately, the aforementioned federated and
decentralized frameworks suffer from two major limitations. On the
one hand, they require full device engagement during training or
updating, whether in collaboration with the cloud or other devices,
which heavily burdens on-device computational resources. On the
other hand, they face challenges in transferability, as they must
learn patterns for new users and regions from the ground up.
To this end, we propose a fast-adapting on-device POI recommen-
dation framework, namely Diffusion-Based Cloud-Edge-Device Col-
laborative Learning for Next POI Recommendations (DCPR). DCPR
adopts the diffusion model as its primary building block, which
has drawn significant attention due to its substantial success in
various fields like computer vision (CV), natural language process-
ing (NLP), sequential recommendations, and others [ 1,17,32,45].
Leveraging its advantages in distributed generation and diverse
representations, we believe the diffusion model is highly suitable
to bridge the above gap. More intuitively, the proposed framework
consists of three layers, including cloud server, edge server, and
device. Initially, a centrally hosted global diffusion model is trained
to learn category-level movement patterns. Since the training data
(i.e., category sequences) does not involve sensitive geographical
locations, it is easily collected in LBSNs.
Subsequently, the well-trained global model is sent to all region-
specific edge servers, and endowed with the ability to capture
region-specific preferences. This is achieved by each region-specific
edge server modifying the global model with POI sequences in this
region. The training data for each region comes from published de-
identified check-in sequences. Finally, each edge server distributes
the region-specific model to all users within this region, which is
further fine-tuned locally by personal data. To avoid impairing the
inherent generation capabilities of the region-specific model, an
additional patch model is inserted and updated with personal data
to reflect the user‚Äôs personal preferences. An acceleration is further
adopted to speed up the inference process, which is a significant
drawback of the standard diffusion model. With the cloud-edge-
device architecture, DCPR significantly reduces the burden of the
on-device computational resource, having capabilities to provide
POI recommendations effectively and efficiently. Meanwhile, such
progressively personalized architecture is highly transferable as it
can rapidly adapt to new regions and new users. In a nutshell, we
summarize our contributions as follows:
‚Ä¢To the best of our knowledge, we are the first to bridge
the gap between the diffusion model and on-device POI
recommendations and propose a fast-adapting on-device
POI recommendation framework, namely DCPR, aimed at
providing personalized POI recommendations efficiently.
‚Ä¢DCPR consists of three layers including cloud server, edge
server, and device, where the latter is progressively built
on the former, and thus, it can fit new regions and users
quickly. To speed up the on-device inference process, we fur-
ther design an acceleration strategy, significantly reducing
inference time.‚Ä¢We evaluate DCPR with two real-world datasets, and demon-
strate its effectiveness. The experimental results highlight
superior accuracy, efficiency, and transferability.
2 Preliminaries
In this section, we list key notations used throughout this paper,
outline our primary task, and introduce the standard diffusion
model.
2.1 Notations
We denote the sets of users ùë¢, POIsùëùand categories ùëêasU,P,C,
respectively. Each POI ùëù‚ààP is associated with a category tag (e.g.,
entertainment or restaurant) ùëêùëù‚ààCand coordinates(ùëôùëúùëõùëù,ùëôùëéùë°ùëù).
Definition 1: Check-in Sequence. A check-in activity of a
user indicates a user ùë¢‚àà U has visited POI ùëù‚àà P at times-
tampùë°. By sorting a user‚Äôs check-ins chronologically, a check-in
sequence contains ùëÄùë¢consecutive POIs visited by a user ùë¢, denoted
byX(ùë¢)={ùëù1,ùëù2,...,ùëùùëÄùë¢}. Each personal check-in sequence X(ùë¢)
is stored on the corresponding personal device.
Definition 2: Category Sequence. A category sequence substi-
tutes all POIs in the check-in sequence X(ùë¢)with their associated
category tags, indicated as Xùëê(ùë¢)={ùëê1,ùëê2,...,ùëêùëÄùë¢}.
Definition 3: Global POI Category Sequence Dataset. The
global semantic dataset Dùëî={Xùëêùëß}ùëç
ùëß=1consists ofùëçanonymized
categorical sequences. The global POI category sequence dataset is
stored on the cloud server.
Definition 4: Region. A region ùëürefers to a geographic seg-
ment providing additional context about the POIs it encompasses.
We do not assume specific region division methods, although we
adoptùëò-means clustering [ 27] to derive a set of regions Rfollowing
[23]. Other predefined functional regions, such as city districts or
suburbs, can also work in our proposed framework.
Definition 5: Region-Specific Dataset. The region-specific
datasetDùëü={Xùë£}ùëâùëü
ùë£=1for a region ùëüincludesùëâùëüanonymized check-
in sequences. Each region possesses its unique dataset, encompass-
ing check-in activities exclusively within region ùëü. Each region-
specific datasetDùëüis stored on a region-based edge server.
2.2 Task: On-Device Next POI Recommendation
With the cloud-edge-device architecture, DCPR owns a cloud server
and multiple edge servers where each region is assigned an edge
server. Then, the functions of cloud server, edge server, and user
device are as follows:
‚Ä¢Cloud Server. The cloud server initially develops a global
diffusion network Œòùëîwith the global dataset Dùëî. Subse-
quently, Œòùëîis sent to all region-specific edge servers.
‚Ä¢Edge Server. After receiving the global network Œòùëî, each
region-specific edge server modifies it with the region‚Äôs
check-in sequences Dùëü. The edge server then distributes
the customized region-specific model Œòùëüto all users within
the region.
‚Ä¢User Device. Each userùë¢receive the region-specific model
Œòùëüand further refine it to create a personalized model Œòùë¢
with personal data Xùë¢.
 
2027Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Global Data
Personal DataSent to each region-
specific edge server
and initialize
trainable parameters
Region-
Specifc Data
Patch Model
Distributed to each user in the region
and initialize the patch modelCloud Server
User DeviceModel Parameters Category Embeddings POI Embeddings
Edge Server
Figure 1: The overview of our proposed DCPR.
Under this construction, we aim to develop a performant local
model for each user, capable of providing a ranked list of potential
POIs for the next visit.
2.3 Standard Diffusion Model
Before introducing our model, we briefly describe the standard dif-
fusion model as the preliminary knowledge. The Diffusion Phase
progressively transforms the initial representation ùë•0into pure
Gaussian noise via a Markov Chain (ùë•0‚Üíùë•1‚Üíùë•2‚Üí...‚Üí
ùë•ùë°‚àí1‚Üíùë•ùë°‚Üí...‚Üíùë•ùëá‚àí1‚Üíùë•ùëá), whereùëádenotes the maximum
diffusion step. More specifically, the relationship between ùë•ùë°and
ùë•ùë°‚àí1is formulated as:
ùë•ùë°=‚àöÔ∏Å
1‚àíùõΩùë°ùë•ùë°‚àí1+ùõΩùë°ùúñ, (1)
whereùúñ‚àºN( 0,ùêº)which is a standard normal distribution, and ùõΩùë°
controls noise level at the diffusion step ùë°. Recall that the diffusion
process aims to make ùë•0converge towards a standard normal distri-
bution,ùõΩùë°increases with the growth of ùë°. Normally, the value of ùõΩùë°
is generated from a pre-defined noise schedule, while common noise
schedules include square-root schedule [ 17], cosine schedule [ 11],
and linear schedule [ 29]. In this paper, we adopt the square-root
schedule, and ùõΩùë°is defined as:
ùõΩùë°=‚àöÔ∏Å
ùë°/ùëá+ùë§, (2)
whereùë§is a small constant corresponding to the starting noise
level. Inspired by [ 11],ùë•ùë°can also be derived directly from the
original target category embedding ùë•0, where the relationship is
defined as:
ùë•ùë°=‚àöÔ∏Å
ùõºùë°ùë•0+‚àöÔ∏Å
1‚àíùõºùë°ùúñ, (3)whereùúñ‚àºN( 0,ùêº)and
‚àöÔ∏Å
ùõºùë°=ùë°√ñ
ùë†=1ùõºùë†, (4)
whereùõºùë†=1‚àíùõΩùë†. In this way, a vast amount of training samples
are obtained to train a network Œò, having the capability to estimate
the original presentation ùë•0given its noised version ùë•ùë°.
TheReverse Phase denoises the pure Gaussian noise ùë•ùëáto
approximate the initial representation ùë•0in an iterative manner
(ùë•ùëá‚Üíùë•ùëá‚àí1‚Üí...‚Üíùë•ùë°‚Üíùë•ùë°‚àí1‚Üí...‚Üíùë•1‚Üíùë•0), which
is precisely opposite to the diffusion process. Formally, ùë•ùë°‚àí1is
obtained from ùë•ùë°by:
ùë•ùë°‚àí1=‚àöùõºùë°(1‚àíùõºùë°‚àí1)ùë•ùë°+‚àöùõºùë°‚àí1(1‚àíùõºùë°)ÀÜùë•0+(1‚àíùõºùë°)(1‚àíùõºùë°‚àí1)ùúñ
1‚àíùõºùë°,
(5)
where ÀÜùë•0=Œò(ùë•ùë°), andùúñ‚àºN( 0,ùêº).
3 Methodology
In this section, we formally introduce the design of DCPR, with an
overview provided in Figure 1. The framework consists of three
stages: (1) Development of a Global Diffusion Model: This
stage involves creating a model adept at encapsulating category-
level inclinations on the cloud server. (2) Training of Region-
Specific Models: The global model is tailored to each region by
incorporating check-in sequences pertinent to that region on the
region-specific edge server, thereby creating models attuned to
regional dynamics. (3) Local Finetuning for Personalization: In
the final stage, the region-specific models undergo local refinement
 
2028KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jing Long et al.
to generate personalized models. This ensures highly accurate and
tailored on-device POI recommendations for individual users.
Selecting the diffusion model as the backbone in our proposed
framework for on-device POI recommendations is driven by two
key considerations. Firstly, the diffusion model‚Äôs architecture excels
at managing complex data [ 11], an essential feature for POI rec-
ommendations that demand a thorough grasp of the nuanced and
dynamic aspects of POI sequences. This alignment greatly enhances
the model‚Äôs generalization capabilities across different scenarios,
leading to precise recommendations. Secondly, the diffusion model‚Äôs
strengths in distributed generation and its capability to effectively
capture a wide range of representations make it uniquely suited
to swiftly and accurately adapt to new regions and user profiles,
benefiting its transferability.
3.1 Global Diffusion Model
The proposed framework begins with the training of a global diffu-
sion model on the cloud server, aimed at learning the patterns of
category-level movements.
3.1.1 Diffusion Phase. Formally, the global diffusion model is de-
signed to construct the next category embedding eùëê
ùëÄ+1from Pure
Gaussian noise ùë•ùëá, whereùë•ùëá‚àºN( 0,ùêº), conditional on the histori-
cal category sequence Xùëê={ùëê1,ùëê2,...,ùëêùëÄ}. Here, the next category
embedding eùëê
ùëÄ+1is also known as the initial target representation
ùë•0. Following the standard diffusion algorithm, we progressively
add noise into the target category embedding ùë•0through the dif-
fusion phase, and represent the noise-altered target category at
stepùë°asùë•ùë°. This process is leveraged to generate samples for train-
ing a network Œòùëî, which takes as input the noised target category
representation ùë•ùë°and the category sequence Xùëê. The output is the
estimated target category representation ÀÜùë•0, aiming to approximate
the true target category embedding ùë•0. The comprehensive design
of the network Œòùëîwill be introduced in the following section. Since
the task of the proposed DCPR is to offer on-device POI recommen-
dations, the global network Œòùëîserves merely as a semi-finished
model and does not engage in the reverse phase (inference) solely.
We will describe the personal inference process later.
3.1.2 Attention-based Network. As previously mentioned, the core
objective of the network is to reconstruct the target category em-
beddingùë•0given its noised representation ùë•ùë°and the historical
category sequence Xùëê, denoted as:
ÀÜùë•0=Œòùëî(ùë•ùë°,Xùëê), (6)
where ÀÜùë•0denotes the estimated representation of ùë•0. Here, we
employ an attention-based neural network as the core mechanism
for the proposed network. This approach has been proven effective
in centralized POI recommendation frameworks [ 26,40], capturing
connections between consecutive check-in activities. Specifically,
we useùëãùëê=[eùëê1,eùëê2,...,eùëêùëÄ]‚ààRùëÄ√óùëëto denote the embedding
of the category sequence. Then, we combine the noised target
representation with each category embedding eùëêùëö‚ààùëãùëê:
ùëßùëêùëö=eùëêùëö+ùúÜ(ùë•ùë°+eùë°), (7)where eùë°represents the embedding of the corresponding diffu-
sion/reverse step created by following [ 35], andùúÜis a hyperpa-
rameter, indicating the level of noise incorporation. Then, the self-
attention mechanism is adopted to enhance the revised sequence
embeddingùëçùëê=[ùëßùëê1,ùëßùëê2,...,ùëßùëêùëÄ]‚ààRùëÄ√óùëë. Given three parameters
ùëäùëÑ,ùëäùêæ,ùëäùëâ‚ààRùëë√óùëë, the final embedded sequence ùê∏‚ààRùëÄ√óùëëis
defined as follows:
ùê∏=ùëÜùëúùëìùë°ùëöùëéùë•(ùëÑùêæùëá
‚àö
ùëë)¬∑ùëâ, (8)
whereùëÑ=ùëçùëêùëäùëÑ,ùêæ=ùëçùëêùëäùêæ,ùëâ=ùëçùëêùëäùëâ. To this end, the estimated
representation is defined as:
ÀÜùë•0=ùëÜùë¢ùëö(ùê∏ùëá), (9)
whereùëÜùë¢ùëö(¬∑)is the sum of the last dimension. Then, we utilize the
cross-entropy loss for model optimization:
Lùê∂ùê∏(ÀÜùë•0,ùë•0)=‚àí¬©¬≠
¬´ùëôùëúùëîùúé(ÀÜùë•ùëá
0¬∑ùë•0)‚àí1
|ùëå‚àí|‚àëÔ∏Å
ùëíùëõ‚ààùëå‚àíùëôùëúùëîùúé(ÀÜùë•ùëá
0¬∑eùëõ)¬™¬Æ
¬¨,
(10)
where the symbol¬∑denotes the inner product, ùëå‚àíconsists of mul-
tiple negative embeddings for each positive sample where eùëõ‚â†ùë•0,
andùúé(¬∑)is the sigmoid function.
3.2 Region-Specific Models
As of now, we have developed a proficiently trained global network
Œòùëî. This model is set to undergo further modifications to cater to
POI recommendations. A tailored model is established for each
region on the corresponding edge server, driven by two key factors.
Firstly, region-specific attributes, such as POI-level details and pre-
cise geographical data, are potentially redundant or even disruptive
when applied outside their respective regions. Secondly, consider-
ing that the region-specific model is intended for deployment on
user devices, the storage of embeddings for all POIs, rather than
just those within a specific region, poses an unnecessary load on
the device‚Äôs resources.
For each region ùëü, after receiving the pre-trained global network
Œòùëî, the edge server freezes its parameters and injects trainable
parameters, mainly containing the yet-to-be-trained embeddings
of all POIs within the region ùëü. We use Œòùëüto indicate the combined
network and Œò‚Ä≤
ùëüto denote the trainable parameters. Given that each
POI is linked to a specific category and representative category em-
beddings are already established, we initialize each POI embedding
with its corresponding category embedding. This strategy infuses
category-level insights and contributes to a more efficient training
process. The novel structure ensures that the frozen parameters
maintain the integrity and performance of the global model, which
has been trained on a vast dataset. Simultaneously, the trainable
parameters leverage this robust foundation to adapt flexibly to the
unique characteristics and requirements of different regions.
The network Œòùëü, similar to the global model, undergoes training
via a diffusion process. Specifically, given a POI sequence X=
{ùëù1,ùëù2,...,ùëùùëÄ}and the target POI ùëùùëÄ+1, the diffusion algorithm
add noise to the target POI embedding eùëÄ+1, also denoted as ùë•0,
referring to the original representation. This process results in the
creation of a noised POI representation ùë•ùë°, whereùë°denotes the
specific step in the diffusion process. In this way, valuable samples
 
2029Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
can be obtained to train the region-specific network Œòùëü, which
takes the noised target POI representation ùë•ùë°and the POI sequence
X. The output is the estimated target POI representation ÀÜùë•0, aiming
to approximate the true target POI embedding ùë•0.
The approach utilized by the region-specific network Œòùëüexhibits
a nuanced divergence from the global network Œòùëî, as detailed in
3.1.2. This variation stems from adaptations in both the underlying
task requirements and the architectural design of the network. A
pivotal element in this modified approach is the integration of
both category and POI embeddings for each POI in the check-in
sequence, rather than relying exclusively on category embeddings.
This integration is operationalized by revising Equation 7 as follows:
ùëßùëö=ùëíùëùùëö+ùõæùëíùëêùëö+ùúÜ(ùë•ùë°+ùëëùë°). (11)
Similar toùúÜ,ùõæserves as a hyperparameter, modulating the influence
of category embeddings. This alteration ensures a more compre-
hensive representation by amalgamating the distinct yet comple-
mentary information from both category and POI embeddings.
An additional modification is to introduce the spatiotemporal
correlations of the check-in sequence in its final embedding ùê∏ob-
tained by Equation 8. Capturing spatiotemporal correlations in POI
sequences is essential for delivering personalized and contextu-
ally relevant POI recommendations, enabling systems to accurately
predict user preferences based on the intricate patterns of their
movements and timings. Specifically, we encode the spatiotemporal
gaps between two check-ins ùëùùëéandùëùùëèviaeŒî
ùëéùëè‚ààRùëë:
eŒî
ùëéùëè=Œîùë†
ùëéùëè√óeŒîùë†+Œîùë°
ùëéùëè√óeŒîùë° (12)
where eŒîùë†andeŒîùë°are two unit embeddings to represent a specific
amount of spatial (e.g., one kilometer) or time (e.g., one hour) differ-
ence,Œîùë†
ùëéùëèandŒîùë°
ùëéùëèare the true spatiotemporal differences of ùëùùëéand
ùëùùëè(e.g., 10 kilometers and 5 hours). On this basis, the embedding
of the trajectory spatiotemporal relation matrix is Œî‚ààRùëÄ√óùëÄ:
Œî=Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞ùëíŒî‚Ä≤
11ùëíŒî‚Ä≤
12... ùëíŒî‚Ä≤
1ùëÄ
ùëíŒî‚Ä≤
21ùëíŒî‚Ä≤
22... ùëíŒî‚Ä≤
2ùëÄ
... ... ... ...
ùëíŒî‚Ä≤
ùëÄ1ùëíŒî‚Ä≤
ùëÄ2... ùëíŒî‚Ä≤
ùëÄùëÄÔ£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª(13)
whereùëíŒî‚Ä≤
ùëéùëèis the element-wise sum of eŒî
ùëéùëè. To this end, we com-
bine the embedded sequence and spatiotemporal differences by
modifying Equation 8:
ùê∏=ùëÜùëúùëìùë°ùëöùëéùë•(ùëÑùêæùëá+Œî‚àö
ùëë)¬∑ùëâ. (14)
Recall that partial parameters of Œòùëüare frozen, its updates are
defined as:
Œò‚Ä≤
ùëü=Œò‚Ä≤
ùëü‚àíùúáùúïLùê∂ùê∏(Œòùëü(ùë•ùë°,X),ùë•0)
ùúïŒò‚Ä≤
ùëü, (15)
whereùúádenotes the learning rate. Please note that we do not per-
form the reverse phase (inference) on the edge server and Œòùëüis
directly distributed to all users within this region.
3.3 Local Finetuning and Inference
Although the region-specific model can provide POI recommenda-
tions for all users within this region, a limitation arises from the
model‚Äôs bias toward active users within the same region, which
can compromise overall performance. To mitigate this, there isan initiative to fine-tune the region-specific model locally using
personal data. The most straightforward method would involve
updating the entire network with local data. Nevertheless, consid-
ering the vast number of parameters in the region-specific model,
adapting the entire network is not a feasible option. An alternative
approach proposes fine-tuning only a subset of parameters. This
method, however, has its limitations, as it leads to a performance
bottleneck due to the problematic interplay between stable and
variable vectors, which disrupts the original feature representation.
Hence, inspired by [ 47], we adopt patch-learning for on-device fine-
tuning. This involves integrating an additional patch model into the
region-specific network. This patch model undergoes modifications
during the local diffusion phase, enabling it to effectively capture
user-specific preferences.
Formally, for each user ùë¢, we introduce a Multi-Layer Perceptron
Œòùë¢, aimed to modify the reconstructed ÀÜùë•0presentation returned by
Œòùëü:
ÀÜùë•0‚ÜêŒòùë¢(Œòùëü(ùë•ùë°,X)). (16)
Then, we repeat the region-specific diffusion phase locally with
personal data to train the user-specific MLP while freezing all pa-
rameters of Œòùëü:
Œòùë¢=Œòùë¢‚àíùúáùúïLùê∂ùê∏(ÀÜùë•0,ùë•0)
ùúïŒòùë¢, (17)
whereùúádenotes the learning rate. Note that the design of MLP can
be adapted to the capacity of the user device. In this work, the MLP
with 3hidden layers, all having ùëëunits, is utilized. To this end, we
have described the whole design of DCPR and its optimization is
summarized in Algorithm 1.
With the region-specific model Œòùëüand personal patch model
Œòùë¢, the reverse algorithm, as detailed in Section 2.3, is capable
of producing a ranked list of POIs for the next movement of the
userùë¢. Intuitively, the reverse phase begins with sampling the
fully noised target item ùë•ùëáfrom a standard Gaussian distribution
N(0,ùêº). The denoising process then proceeds iteratively, where
ùë•ùë°‚àí1is obtained from ùë•ùë°under the guidance of ÀÜùë•0which is returned
byŒòùë¢(Œòùëü(ùë•ùë°,Xùëê)). Once the final target POI representation ùë•0
is reached, we map it into the discrete POI index space for final
recommendations. To accomplish this, we first compute the score
of each ofùêªcandidate POIs by:
ùõº(ùëù‚Ñé)=ùë•ùëá
0¬∑ùëíùëù‚Ñé. (18)
Then, we rank all scores in descending for final recommendations.
A primary limitation of the standard diffusion model lies in its
sluggish generation speed, attributed to the iterative processing
required in the reverse phase from ùë•ùëátoùë•0to produce the final rep-
resentation. This issue is further exacerbated when this processing
is executed on-device, due to the restricted computational resources
available. To address this challenge, we adopt and adapt the novel
sampling technique introduced by [ 34]. This technique significantly
reduces the number of sampling steps, thereby markedly improv-
ing the efficiency of the generation process. Specifically, instead of
performing the reverse process on all steps from ùë•ùëátoùë•0, we only
perform it on{ùë•TùëÜ,ùë•TùëÜ‚àí1,...,ùë•T1,ùë•T0}, where[TùëÜ,TùëÜ‚àí1,...,T1,T0]is
an arithmetic and decreasing sub-sequence of [ùëá,ùëá‚àí1,...,1,0]. On
this basis, the relationship between ùë•Tùë†andùë•Tùë†‚àí1is changed, which
 
2030KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jing Long et al.
Algorithm 1 Cloud-Edge-Device Collaborative Training of DCPR.
/*Global model - on the cloud server*/
1:Initialize Œòùëî;
2:for(ùëêùëÄ+1,Xùëê)‚ààDùëîdo
3:repeat
4:ùë•0‚ÜêeùëêùëÄ+1;
5:ùë°‚àºùëà(0,ùëá);
6:ùë•ùë°‚Üê‚àöùõºùë°ùë•0+‚àö1‚àíùõºùë°ùúñ,ùúñ‚àºN( 0,ùêº);
7: ÀÜùë•0‚ÜêŒòùëî(ùë•ùë°,Xùëê);
8: Œòùëî‚ÜêŒòùëî‚àíùúáùúïLùê∂ùê∏(ÀÜùë•0,ùë•0)
ùúïŒòùëî;
9:until convergence
10:end for
/*Region-specific model - on the edge server*/
11:forùëü‚ààRdo{in parallel} ‚ä≤Each region has an edge server
12: Receive Œòùëîand initialize Œò‚Ä≤
ùëü;
13: Obtain Œòùëüby combining ŒòùëîandŒò‚Ä≤
ùëü;
14: for(ùëùùëÄ+1,X)‚ààDùëüdo
15: repeat
16:ùë•0‚ÜêeùëùùëÄ+1;
17:ùë°‚àºùëà(0,ùëá);
18:ùë•ùë°‚Üê‚àöùõºùë°ùë•0+‚àö1‚àíùõºùë°ùúñ,ùúñ‚àºN( 0,ùêº);
19: ÀÜùë•0‚ÜêŒòùëü(ùë•ùë°,X);
20: Œò‚Ä≤
ùëü=Œò‚Ä≤
ùëü‚àíùúáùúïLùê∂ùê∏(ÀÜùë•0,ùë•0)
ùúïŒò‚Ä≤
ùëü;
21: until convergence
22: end for
23:end for
/*Personal model - on the user side*/
24:forùë¢‚ààUdo{in parallel}
25: Receive Œòùëüand initialize Œòùë¢;
26: for(ùëùùëÄ+1,X)‚ààXùë¢do
27: repeat
28:ùë•0‚ÜêeùëùùëÄ+1;
29:ùë°‚àºùëà(0,ùëá);
30:ùë•ùë°‚Üê‚àöùõºùë°ùë•0+‚àö1‚àíùõºùë°ùúñ,ùúñ‚àºN( 0,ùêº);
31: ÀÜùë•0‚ÜêŒòùë¢(Œòùëü(ùë•ùë°,X));
32: Œòùë¢‚ÜêŒòùë¢‚àíùúáùúïLùê∂ùê∏(ÀÜùë•0,ùë•0)
ùúïŒòùë¢;
33: until convergence
34: end for
35:end for
is defined as:
ùë•Tùë†‚àí1=‚àöÔ∏É
ùõºTùë†‚àí1(ùë•Tùë†‚àí‚àö1‚àíùõºùë°ÀÜùë•0‚àö
ùõºTùë†)+‚àöÔ∏É
1‚àíùõºTùë†‚àí1ÀÜùë•0. (19)
To this end, the reverse step ùëáùëÖcan be set to any positive integer
which is less than the maximum diffusion step ùëá.
4 Experiments
In this section, we perform comprehensive experiments with two
real-world datasets to evaluate the effectiveness and efficiency of
the proposed DCPR. The comparative analysis includes two cate-
gories of baselines: centralized POI recommendation systems and
on-device POI recommenders. Specifically, our investigation seeks
to address the following research questions:RQ1: How does the DCPR perform compared with state-of-the-art
POI recommendation methods?
RQ2: How efficient (i.e., model size and time complexity) is the pro-
posed DCPR compared with other on-device POI recommenders?
RQ3: Is the proposed DCPR efficiently transferable to new regions
and new users?
RQ4: What is the impact of DCPR‚Äôs key hyperparameters?
Table 1: Dataset statistics.
Foursquare Weeplace
#users 7,507 4,560
#POIs 80,962 44,194
#categories 436 625
#check-ins 1,214,631 923,600
#check-ins per user 161.80 202.54
4.1 Datasets and Evaluation Protocols
We adopt two real-world datasets to evaluate our proposed DCPR,
namely Foursquare [ 6] and Weeplace [ 22]. Both datasets include
users‚Äô check-in histories in the cities of New York, Los Angeles,
and Chicago. Additionally, in this work, each city is divided into
5regions by applying k-means clustering which is discussed in
Section 2. Following [ 2,16], users and POIs with less than 10 in-
teractions are removed. Table 1 summarizes the statistics of the
two datasets. For each dataset, we derive all category sequences
from check-in activities and regard those category sequences as
the global training data Dùëî. Then, 50%of the POI sequences within
each region ùëüacts as the corresponding region-specific training
dataDùëü, while the rest is employed for the training, testing and
validation of on-device models.
For evaluation, we adopt the leave-one-out protocol which is
widely used in previous works [ 38,39,53]. That is, for each of the
on-device check-in sequences, the last check-in POI is for testing,
the second last POI is for validation, and all others are for train-
ing. It is worth noting that, for each category sequence in Dùëî, we
remove the last two check-in activities for rigorous experiments.
In addition, the maximum sequence length is set to 200. For each
ground truth, instead of ranking all e-commerce products [ 15], we
only pair it with 200 unvisited and nearest POIs within the same
region of the sequence as the candidates for ranking. The rationale
is, different from e-commerce products [ 15,31], in the scenario
of POI recommendations that are location-sensitive, users seldom
travel between two POIs consecutively that are far away from each
other [18, 24, 51].
On this basis, we leverage two ranking metrics, namely Hit Ratio
at Rankùëò(HR@ùëò) and Normalized Discounted Cumulative Gain
at Rankùëò(NDCG@ùëò) [42] where HR@ ùëòonly measures the times
that the ground truth is present on the top- ùëòlist, while NDCG@ ùëò
cares whether the ground truth can be ranked as highly as possible.
For hyperparameters, we set the maximum diffusion step ùëáto
1024, the reverse inference step ùëáùëÖto16,ùõæto0.7,ùúÜto0.003, the
learning rate ùúáto0.002, the dimension size to 64, the dropout to 0.2,
the batch size to 16, and the maximum training epoch is set to 200.
 
2031Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Table 2: Recommendation performance comparison with baselines.
Foursquare Weeplace
HR@5 NDCG@5 HR@10 NDCG@10 HR@5 NDCG@5 HR@10 NDCG@10
MF 0.0847 0.0607 0.0965 0.0661 0.1042 0.0599 0.1316 0.0889
LSTM 0.1939 0.1195 0.2782 0.1668 0.2156 0.1322 0.3251 0.1549
STAN 0.2987 0.1776 0.4327 0.2598 0.3141 0.1819 0.4663 0.2876
DRAN 0.3114 0.1802 0.4345 0.2655 0.3165 0.1843 0.4775 0.2974
Diff-POI 0.3228 0.1840 0.4585 0.2838 0.3281 0.1921 0.4933 0.2994
LLRec 0.2648 0.1447 0.3549 0.1884 0.3008 0.1839 0.3751 0.2329
DCCL 0.2679 0.1486 0.3723 0.1969 0.3118 0.1868 0.3925 0.2353
PREFER 0.2858 0.1746 0.3723 0.2251 0.3009 0.1783 0.3914 0.2367
DCLR 0.3136 0.1887 0.4406 0.2740 0.3124 0.1857 0.4357 0.2797
MAC 0.3030 0.1826 0.4520 0.2780 0.3187 0.1974 0.4852 0.2829
DCPR 0.3272 0.1922 0.4623 0.2913 0.3337 0.1978 0.5082 0.3063
4.2 Baselines
We compare DCPR with both the centralized and on-device POI
recommenders:
Centralized POI Recommenders:
‚Ä¢MF[21]: It is a classic centralized POI recommendation sys-
tem based on user-item matrix factorization.
‚Ä¢LSTM [12]: This recurrent neural network can capture short-
term and long-term dependencies in sequential data.
‚Ä¢STAN [26]: It learns explicit spatiotemporal correlations of
check-in trajectories via a bi-attention approach.
‚Ä¢DRAN [40]: It is a GNN-based method that leverages a dis-
entangled representation-enhanced attention network for
next POI recommendation
‚Ä¢Diff-POI [30]: It is a diffusion-based model that samples
from the posterior distribution that reflects the user‚Äôs geo-
graphical preference.
On-Device POI Recommenders:
‚Ä¢LLRec [37]: It utilizes the teacher-student training strategy
to obtain the compressed model that can be deployed locally.
‚Ä¢DCCL [47]: It compresses and deployes a well-trained model
on-device, which is further finetuned locally with personal
data.
‚Ä¢PREFER [10]: This federated POI recommendation par-
adigm allows the server to collect and aggregate locally
trained models, as well as redistribute the federated model.
‚Ä¢DCLR [24]: This decentralized collaborative learning frame-
work allows locally trained models to share knowledge be-
tween homogeneous neighbors by model aggregation.
‚Ä¢MAC [23]: It is designed to collaboratively train local mod-
els with heterogeneous neighbors by comparing their soft
decisions on a public reference dataset.
4.3 Recommendation Effectiveness (RQ1)
The performance comparison among all the POI recommenders is
summarized in Table 2, where we observe the following findings.
LSTM outshines MF on both datasets, owing to its adept handling
of sequential check-in activities‚Äô short-term and long-term depen-
dencies. Furthermore, STAN, which leverages spatiotemporal cor-
relations in check-in activities with the attention mechanism, bothconsecutive and non-consecutive, surpasses LSTM in accuracy. Ad-
vancing further, DRAN melds a Graph Neural Network (GNN) with
an attention mechanism, leading to more refined POI embeddings
and thus outperforming STAN in terms of accuracy.
Most notably, Diff-POI, employing the robust generality of the
diffusion model, sets a new benchmark for state-of-the-art accuracy
in this domain. While these centralized models show prowess, our
method remains highly competitive. The centralized models, trained
across multiple cities, often grapple with the noise in knowledge
transfer between cities, which can detract from their performance.
In contrast, our approach excels in personalization in regions and
personals to learn more expressive models, thereby offering tailored
and efficient recommendations.
In the meantime, DCPR outperforms all on-device POI recom-
menders on both datasets in terms of all metrics. It begins by point-
ing out the shortcomings of LLRec, which ranks lowest in terms
of performance. This is primarily due to its training process that
omits all personal data, leading to a disregard for individual user
preferences. In contrast, DCCL attempts to enhance its model by
incorporating personal data. However, it still does not reach the
pinnacle of accuracy, primarily due to its suboptimal model design.
The analysis then shifts focus to collaborative learning frameworks
such as PREFER, DCLR, and MAC, acknowledging their notable
improvements in accuracy. The proposed DCPR stands out for more
accurate recommendations. Furthermore, it surpasses other models
in recommendation efficiency, demonstrated through its compact
on-device model size and reduced computational time complexity.
These aspects, along with their implications, are set to be elaborated
and explored in greater detail in the subsequent section.
4.4 Recommendation Efficiency (RQ2)
To assess the recommendation efficiency of the proposed DCPR,
concerning all on-device POI recommenders, we record recommen-
dation accuracy (HR@10 on Weeplace), on-device model size (in
megabytes), on-device training time (in seconds), and on-device
inference time (in milliseconds), for the latent dimensions ùëë‚àà
{8,16,32,64,128,256,512}. Please note personal models in LLRec
are not trained or updated locally, leading to the lack of on-device
training time. The summarized results are shown in Figure 2.
 
2032KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jing Long et al.
8 16 32 64 128 256 512
d0.200.250.300.350.400.450.50HR@10LLRec
DCCL
PREFER
DCLR
MAC
DCPR
8 16 32 64 128 256 512
d01020304050607080Model Size (mb)LLRec
DCCL
PREFER
DCLR
MAC
DCPR
8 16 32 64 128 256 512
d05001000150020002500300035004000Training Time (s)DCCL
PREFER
DCLR
MAC
DCPR
8 16 32 64 128 256 512
d0102030405060Inference Time (ms)LLRec
DCCL
PREFER
DCLR
MAC
DCPR
Figure 2: Recommendation Efficiency.
8 16 32 64 128 256 512 1024
TR0100200300400500Inference Time (ms)Foursquare
Weepalce
8 16 32 64 128 256 512 1024
TR0.450.460.470.480.490.500.51HR@10
Foursquare
Weepalce
Figure 3: Effectiveness of Acceleration Strategy.
4.4.1 On-Device Memory Efficiency. Here, it is noticeable that the
average model sizes of both MAC and DCPR are significantly
smaller compared to other on-device recommendation systems.
This efficiency is attributed to their design, which allows the user
device to store only those POI embeddings that are pertinent.
4.4.2 On-Device Time Efficiency. DCPR‚Äôs efficiency is further high-
lighted by its minimal reliance on the computational capabilities
of local devices, proved by the least on-device training time of
DCPR. Regarding inference time, DCPR effectively overcomes the
constraints of the standard reverse algorithm, resulting in similar
inference time compared with other on-device models. To further
prove the effectiveness of the acceleration strategy, we fix the di-
mension size to 64, and record the recommendation accuracy and
inference time for various ùëáùëÖ‚àà{8,16,32,64,128,256,512,1024},
whereùëáùëÖ=1024 means no acceleration is employed. The results
are shown in Figure 3, where we can observe that the acceler-
ation mechanism significantly reduces the inference time while
maintaining the recommendation accuracy. More specifically, as ùëáùëÖ
increases, there is a generally upward trend in both inference time
and accuracy. However, the accuracy converges when ùëáùëÖexceeds
16. Meanwhile, the inference time keeps rising with more reverse
steps. Thus, ùëáùëÖis set to 16, offering high accuracy without exces-
sively prolonging inference time. To conclude, considering the factTable 3: Recommendation Transferability.
Foursquare Weeplace
Time (s) HR@10 Time (s) HR@10
DCPR 4143 0.4487 2824 0.4916
DCPR-T 5708 0.4252 4685 0.4709
that DCPR surpasses all other on-device frameworks in recommen-
dation accuracy, it is a more effective and efficient solution in the
landscape of on-device POI recommenders.
4.5 Recommendation Transferability (RQ3)
As indicated in Section 4.4.2, the on-device training time for DCPR
is significantly shorter compared to other on-device POI recommen-
dation frameworks, while still maintaining high recommendation
accuracy. More importantly, the training and updating process for
individual user models within DCPR does not interfere with other
user models, region-specific models, or the global model, under-
scoring DCPR‚Äôs effective adaptability to new users.
To evaluate DCPR‚Äôs transferability to new regions, we record the
averaged training time (in seconds) of all region-specific models,
and recommendation accuracy (HR@10 on Weeplace) after directly
applying each of them to personal check-in sequences in the region
without local fine-tuning. For comparison, we introduced DCPR-T, a
variant where each region-specific model is retrained from scratch,
not leveraging the well-trained global model. Similar to DCPR, we
record the averaged training time and recommendation accuracy of
DCPR-T. The results, shown in Table 3, reveal that DCPR, with the
support of the global model, achieves faster convergence and supe-
rior recommendation accuracy compared to DCPR-T. Furthermore,
the training of region-specific models does not impact each other or
the global model, affirming DCPR‚Äôs capacity for efficient adaption
to new regions. In summary, DCPR‚Äôs unique cloud-edge-device ar-
chitecture enables efficient transferability to new users and regions,
a feature that distinguishes it from other POI recommendation
systems.
4.6 Hyperparameter Sensitivity (RQ4)
In this section, we first illustrate the effect of three hyperparameters
on the recommendation accuracy of DCPR including ùõæthat controls
the injection level of category embedding to POI embedding in
Equation 11, ùúÜthat controls the noise level added to POI embedding
in Equation 11, and the averaged check-in numbers ùëÅùê∂on the
region. The results are shown in Figure 4.
Impact ofùõæ.We experiment on ùõæ‚àà{0,0.1,0.3,0.5,0.7,0.9,1}.
The lowest accuracy is obtained if all region-specific model is
trained solely without well-trained category embeddings in the
global model ( ùõæ=0), showing the significance of the cloud-edge-
device architecture. Therefore, the recommendation accuracy in-
creases with the increase of ùõæ. However, the accuracy will decline
if knowledge from the frozen category embedding in the global
model has an excessive proportion ( ùõæ>0.7).
Impact of ùúÜ.Recommendation accuracy is recorded for ùúÜ‚àà
{0,0.001,0.003,0.005,0.007,0.009,0.01}. The best performance is
observed when ùúÜ=0.003for both datasets, highlighting a delicate
 
2033Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
00.1 0.3 0.5 0.7 0.9 1
0.440.450.460.470.480.490.500.51HR@10
Foursquare
Weepalce
00.001 0.003 0.005 0.007 0.009 0.01
0.440.460.480.50
Foursquare
Weepalce
100 500 1000 1500 2000 2500
NC0.250.300.350.400.450.50
Foursquare
Weepalce
Figure 4: Hyperparameter Sensitivity.
balance. Excessive noise compromises POI embeddings, while in-
sufficient noise fails to introduce the necessary diversity into POI
recommendations.
Impact ofùëÅùê∂.ùëÅùê∂is evaluated in{100,500,1000,1500,2000,2500}.
Usually, the recommendation accuracy benefits from higher check-
in numbers. In this study, accuracy stabilizes once ùëÅùê∂exceeds
1000, indicating that the proposed DCPR is capable of delivering
high-performance recommendations without requiring an exten-
sive volume of check-ins.
5 Related Work
This section reviews recent literature on related areas including
centralized models for POI recommendation, on-device frameworks
for POI recommendation, and diffusion models.
5.1 Next POI Recommendation
To help people discover attractive places by analyzing user-POI in-
teractions, early works mainly focused on matrix factorization [ 21]
and Markov chains [ 7,53]. The introduction of recurrent neural
network (RNN) models marked a significant advancement, show-
casing their ability to understand the spatiotemporal dynamics in
POI sequences [ 4,5,14,18,49]. Additionally, models employing
attentive neural networks [ 3,26,46,49] have adopted self-attention
mechanisms to meticulously analyze the spatiotemporal context of
sequential check-in behaviors. Then, graph neural networks (GNN)
based models [ 8,9,18,40] took a step further by integrating graph-
augmented POI sequences, which capitalized on collaborative sig-
nals from semantically similar POIs and unveiled sequential trends,
thereby outperforming RNN-based approaches in terms of accuracy.
Then, Diff-POI [ 30], by leveraging the powerful generality of the
diffusion model, establishes a new standard for cutting-edge accu-
racy in the field. These approaches, however, predominantly rely on
cloud-based infrastructure, which brings the need for substantial
cloud computing capabilities. In contrast, DCPR introduces a fast-
adapting on-device POI recommendation framework, emphasizing,
recommendation accuracy, efficiency, and model transferability.
5.2 On-Device POI Recommendation
On-device frameworks effectively address many limitations of cloud-
based learning in POI recommendations. Federated learning [ 10],
a key approach in this context, aggregates locally trained models
and shares a unified model with users. However, this can result
in the long-tail problem, where less active users get subpar rec-
ommendations. Some federated POI recommenders [ 33,43] tackle
this by grouping users with similar interests, and decentralizedsystems [ 23,24] allow nearby devices to collaborate, enhancing
personalization. Despite this, these methods demand extensive de-
vice engagement and intra-device communication, raising concerns
about privacy and Transferability. An alternative approach [37] is
using pre-trained, compressed models on devices with anonymized
data for privacy, but this compromises accuracy due to the lack of
personalized data and limited model adaptability. Some systems
[28,44] try to fine-tune with local data, yet they underperform com-
pared to centralized systems. Although this method can quickly
adapt to new users, it compromises recommendation quality and
struggles to adjust to new regions. Our work introduces a diffusion
model-based system, deploying a well-trained model to users for
local fine-tuning and achieving high-quality recommendations.
5.3 Diffusion Models
Diffusion models have revolutionized generative tasks across fields
like computer vision (CV), natural language processing (NLP), and
others [ 1,17,32,45], with Denoising Diffusion Probabilistic Mod-
els (DDPMs) [ 11] excelling in creating high-quality images. To
improve efficiency, Denoising Diffusion Implicit Models (DDIMs)
[34] reduce sampling steps with minimal impact on diversity. De-
spite their ability to generate diverse images, controlling the output
remains a challenge. Addressing this, text-conditional diffusion
models [ 1,32] have emerged, using text encoders to guide image
generation by integrating textual and image representations dur-
ing the diffusion process. These works [ 17,19,30] also extend the
diffusion model to sequence-to-sequence tasks, including NLP and
sequential recommendations, by training networks to reconstruct
targets from noised inputs. Yet, their application in on-device POI
recommendation systems is novel. This study pioneers the use of
diffusion models for on-device POI recommendations, harnessing
their generative capabilities to deliver transferable, accurate, and
efficient recommendations, marking a significant advancement in
personalized and location-based services.
6 Conclusion
In conclusion, this work has successfully developed and evaluated
the Diffusion-Based Cloud-Edge-Device Collaborative Learning
(DCPR) framework, a pioneering approach to on-device POI rec-
ommendations. By integrating the diffusion model‚Äôs strengths in
generating diverse and distributed representations, DCPR effec-
tively addresses the limitations of existing centralized and collab-
orative learning systems, particularly in terms of computational
efficiency, and the capacity for personalization. Furthermore, the
novel cloud-edge-device architecture ensures DCPR‚Äôs transferabil-
ity to new regions and users. Experimental results with two real-
world datasets have validated DCPR‚Äôs effectiveness, showcasing its
potential to significantly enhance the quality and accessibility of
POI recommendations.
Acknowledgments
This work is supported by Australian Research Council under the
streams of Future Fellowship (Grant No. FT210100624), Discovery
Early Career Researcher Award (Grants No. DE230101033), Discov-
ery Project (Grants No.DP240101108 and No.DP240101814).
 
2034KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jing Long et al.
References
[1]Omri Avrahami, Dani Lischinski, and Ohad Fried. 2022. Blended diffusion for
text-driven editing of natural images. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition. 18208‚Äì18218.
[2]B. Chang, Y. Park, D. Park, S. Kim, and J. Kang. 2018. Content-Aware Hierarchical
Point-of-Interest Embedding Model for Successive POI Recommendation. In
Twenty-Seventh International Joint Conference on Artificial Intelligence IJCAI-18.
[3]Tong Chen, Hongzhi Yin, Hongxu Chen, Rui Yan, Quoc Viet Hung Nguyen, and
Xue Li. 2019. Air: Attentional intention-aware recommender systems. In 2019
IEEE 35th International Conference on Data Engineering (ICDE). IEEE, 304‚Äì315.
[4]Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen, Wen-Chih Peng, Xue Li, and
Xiaofang Zhou. 2020. Sequence-aware factorization machines for temporal pre-
dictive analytics. In 2020 IEEE 36th International Conference on Data Engineering
(ICDE). IEEE, 1405‚Äì1416.
[5]Tong Chen, Hongzhi Yin, Guanhua Ye, Zi Huang, Yang Wang, and Meng Wang.
2020. Try this instead: Personalized and interpretable substitute recommendation.
InProceedings of the 43rd international ACM SIGIR conference on research and
development in information retrieval. 891‚Äì900.
[6]Z. Chen, H. Cao, H. Wang, F. Xu, and Y. Li. 2020. Will You Come Back / Check-in
Again? Understanding Characteristics Leading to Urban Revisitation and Re-
check-in. Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous
Technologies (2020).
[7]C. Cheng, H. Yang, M. R. Lyu, and I. King. 2013. Where You Like to Go Next:
Successive Point-of-Interest Recommendation.. In International Joint Conference
on Artificial Intelligence.
[8]Xinyi Gao, Tong Chen, Yilong Zang, Wentao Zhang, Quoc Viet Hung Nguyen,
Kai Zheng, and Hongzhi Yin. 2023. Graph condensation for inductive node
representation learning. arXiv preprint arXiv:2307.15967 (2023).
[9]Xinyi Gao, Wentao Zhang, Tong Chen, Junliang Yu, Hung Quoc Viet Nguyen, and
Hongzhi Yin. 2023. Semantic-aware node synthesis for imbalanced heterogeneous
information networks. In Proceedings of the 32nd ACM International Conference
on Information and Knowledge Management. 545‚Äì555.
[10] Y. Guo, F. Liu, Z. Cai, H. Zeng, and N. Xiao. 2021. PREFER: Point-of-interest
REcommendation with efficiency and privacy-preservation via Federated Edge
leaRning. Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous
Technologies 5, 1 (2021), 1‚Äì25.
[11] Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising diffusion probabilistic
models. Advances in neural information processing systems 33 (2020), 6840‚Äì6851.
[12] S. Hochreiter and J. Schmidhuber. 1997. Long Short-Term Memory. Neural
Computation 9, 8 (1997), 1735‚Äì1780.
[13] Mubashir Imran, Hongzhi Yin, Tong Chen, Quoc Viet Hung Nguyen, Alexander
Zhou, and Kai Zheng. 2023. ReFRS: Resource-efficient federated recommender
system for dynamic and diversified user preferences. ACM Transactions on
Information Systems 41, 3 (2023), 1‚Äì30.
[14] F. Jie, L. Yong, Z. Chao, F. Sun, and D. Jin. 2018. DeepMove: Predicting Human
Mobility with Attentional Recurrent Networks. In the 2018 World Wide Web
Conference.
[15] W. Krichene and S. Rendle. 2020. On Sampled Metrics for Item Recommendation.
InKDD ‚Äô20: The 26th ACM SIGKDD Conference on Knowledge Discovery and Data
Mining.
[16] Ranzhen Li, Yanyan Shen, and Yanmin Zhu. 2018. Next Point-of-Interest Rec-
ommendation with Temporal and Multi-level Context Attention. 2018 IEEE
International Conference on Data Mining (ICDM) (2018), 1110‚Äì1115.
[17] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang, and Tatsunori B
Hashimoto. 2022. Diffusion-lm improves controllable text generation. Advances
in Neural Information Processing Systems 35 (2022), 4328‚Äì4343.
[18] Yang Li, Tong Chen, Yadan Luo, Hongzhi Yin, and Zi Huang. 2021. Discovering
collaborative signals for next POI recommendation with iterative Seq2Graph
augmentation. In IJCAI. 1491‚Äì1497.
[19] Zihao Li, Aixin Sun, and Chenliang Li. 2023. DiffuRec: A Diffusion Model for
Sequential Recommendation. arXiv preprint arXiv:2304.00686 (2023).
[20] D. Lian, Y. Wu, Y. Ge, X. Xie, and E. Chen. 2020. Geography-Aware Sequential
Location Recommendation. In KDD ‚Äô20: The 26th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining.
[21] D. Lian, C. Zhao, X. Xie, G. Sun, E. Chen, and Y. Rui. 2014. GeoMF: joint geo-
graphical modeling and matrix factorization for point-of-interest recommendation.
ACM.
[22] X. Liu, Y. Liu, K. Aberer, and C. Miao. 2013. Personalized point-of-interest
recommendation by mining users‚Äô preference transition. In Acm International
Conference on Conference on Information & Knowledge Management.
[23] Jing Long, Tong Chen, Quoc Viet Hung Nguyen, Guandong Xu, Kai Zheng, and
Hongzhi Yin. 2023. Model-Agnostic Decentralized Collaborative Learning for
On-Device POI Recommendation. In Proceedings of the 46th International ACM
SIGIR Conference on Research and Development in Information Retrieval. 423‚Äì432.
[24] Jing Long, Tong Chen, Quoc Viet Hung Nguyen, and Hongzhi Yin. 2023. Decen-
tralized collaborative learning framework for next POI recommendation. ACM
Transactions on Information Systems 41, 3 (2023), 1‚Äì25.[25] Jing Long, Tong Chen, Guanhua Ye, Kai Zheng, Nguyen Quoc Viet Hung, and
Hongzhi Yin. 2024. Physical Trajectory Inference Attack and Defense in Decen-
tralized POI Recommendation. arXiv preprint arXiv:2401.14583 (2024).
[26] Y. Luo, Q. Liu, and Z. Liu. 2021. STAN: Spatio-Temporal Attention Network for
Next Location Recommendation.
[27] J. Macqueen. 1967. Some methods for classification and analysis of multivariate
observations. Proc. Symp. Math. Statist. and Probability, 5th 1 (1967).
[28] Nattaya Mairittha, Tittaya Mairittha, and Sozo Inoue. 2020. Improving activity
data collection with on-device personalization using fine-tuning. In Adjunct
Proceedings of the 2020 ACM International Joint Conference on Pervasive and
Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium
on Wearable Computers. 255‚Äì260.
[29] Alexander Quinn Nichol and Prafulla Dhariwal. 2021. Improved denoising diffu-
sion probabilistic models. In International Conference on Machine Learning. PMLR,
8162‚Äì8171.
[30] Yifang Qin, Hongjun Wu, Wei Ju, Xiao Luo, and Ming Zhang. 2023. A Diffusion
Model for POI Recommendation. ACM Transactions on Information Systems 42, 2
(Nov. 2023), 1‚Äì27. https://doi.org/10.1145/3624475
[31] Liang Qu, Huaisheng Zhu, Ruiqi Zheng, Yuhui Shi, and Hongzhi Yin. 2021. Im-
gagn: Imbalanced network embedding via generative adversarial graph networks.
InProceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &
Data Mining. 1390‚Äì1398.
[32] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
2022. Hierarchical text-conditional image generation with clip latents, 2022. URL
https://arxiv. org/abs/2204.06125 7 (2022).
[33] J. Rao, S. Gao, M. Li, and Q. Huang. 2021. A privacy-preserving framework for
location recommendation using decentralized collaborative machine learning.
Transactions in GIS (2021).
[34] Jiaming Song, Chenlin Meng, and Stefano Ermon. 2020. Denoising diffusion
implicit models. arXiv preprint arXiv:2010.02502 (2020).
[35] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[36] Hao Wang, Yanmei Fu, Qinyong Wang, Hongzhi Yin, Changying Du, and Hui
Xiong. 2017. A location-sentiment-aware recommender system for both home-
town and out-of-town users. In Proceedings of the 23rd ACM SIGKDD international
conference on knowledge discovery and data mining. 1135‚Äì1143.
[37] Q. Wang, H. Yin, T. Chen, Z. Huang, and Nqv Hung. 2020. Next Point-of-Interest
Recommendation on Resource-Constrained Mobile Devices. In WWW ‚Äô20: The
Web Conference 2020.
[38] Q. Wang, H. Yin, Z. Hu, D. Lian, H. Wang, and Z. Huang. 2018. Neural Memory
Streaming Recommender Networks with Adversarial Training. (2018), 2467‚Äì
2475.
[39] Q. Wang, H. Yin, H. Wang, Qvh Nguyen, and L. Cui. 2019. Enhancing Col-
laborative Filtering with Generative Augmentation. In the 25th ACM SIGKDD
International Conference.
[40] Zhaobo Wang, Yanmin Zhu, Haobing Liu, and Chunyang Wang. 2022. Learning
Graph-based Disentangled Representations for Next POI Recommendation. In
Proceedings of the 45th International ACM SIGIR Conference on Research and
Development in Information Retrieval (, Madrid, Spain,) (SIGIR ‚Äô22). Association
for Computing Machinery, New York, NY, USA, 1154‚Äì1163. https://doi.org/10.
1145/3477495.3532012
[41] Zhaobo Wang, Yanmin Zhu, Qiaomei Zhang, Haobing Liu, Chunyang Wang,
and Tong Liu. 2021. Graph-enhanced Spatial-temporal Network for Next POI
Recommendation. ACM Transactions on Knowledge Discovery from Data (TKDD)
(2021).
[42] M. Weimer, A. Karatzoglou, Q. V. Le, and A. J. Smola. 2007. CoFiRank - Maximum
Margin Matrix Factorization for Collaborative Ranking. In Neural Information
Processing Systems.
[43] A Xw, A Mn, A Jc, B Lc, and C Kl. 2020. A group preference-based privacy-
preserving POI recommender system. ICT Express 6, 3 (2020), 204‚Äì208.
[44] Yikai Yan, Chaoyue Niu, Renjie Gu, Fan Wu, Shaojie Tang, Lifeng Hua, Chengfei
Lyu, and Guihai Chen. 2022. On-Device Learning for Model Personalization
with Large-Scale Cloud-Coordinated Domain Adaption. In Proceedings of the 28th
ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2180‚Äì2190.
[45] Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao,
Wentao Zhang, Bin Cui, and Ming-Hsuan Yang. 2023. Diffusion models: A
comprehensive survey of methods and applications. Comput. Surveys 56, 4 (2023),
1‚Äì39.
[46] Song Yang, Jiamou Liu, and Kaiqi Zhao. 2022. GETNext: Trajectory Flow Map
Enhanced Transformer for Next POI Recommendation. In Proceedings of the 45th
International ACM SIGIR Conference on Research and Development in Information
Retrieval (Madrid, Spain) (SIGIR ‚Äô22). Association for Computing Machinery, New
York, NY, USA, 1144‚Äì1153. https://doi.org/10.1145/3477495.3531983
[47] Jiangchao Yao, Feng Wang, Kunyang Jia, Bo Han, Jingren Zhou, and Hongxia
Yang. 2021. Device-Cloud Collaborative Learning for Recommendation (KDD
‚Äô21). Association for Computing Machinery, New York, NY, USA, 3865‚Äì3874.
https://doi.org/10.1145/3447548.3467097
 
2035Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
[48] Hongzhi Yin and Bin Cui. 2016. Spatio-temporal recommendation in social media.
Springer.
[49] Hongzhi Yin, Bin Cui, Zi Huang, Weiqing Wang, Xian Wu, and Xiaofang Zhou.
2015. Joint modeling of users‚Äô interests and mobility patterns for point-of-interest
recommendation. In Proceedings of the 23rd ACM international conference on
Multimedia. 819‚Äì822.
[50] Hongzhi Yin, Liang Qu, Tong Chen, Wei Yuan, Ruiqi Zheng, Jing Long, Xin
Xia, Yuhui Shi, and Chengqi Zhang. 2024. On-Device Recommender Systems: A
Comprehensive Survey. arXiv preprint arXiv:2401.11441 (2024).
[51] Wei Yuan, Hongzhi Yin, Fangzhao Wu, Shijie Zhang, Tieke He, and Hao Wang.
2023. Federated unlearning for on-device recommendation. In Proceedings of theSixteenth ACM International Conference on Web Search and Data Mining. 393‚Äì401.
[52] Shijie Zhang, Hongzhi Yin, Tong Chen, Zi Huang, Quoc Viet Hung Nguyen,
and Lizhen Cui. 2022. Pipattack: Poisoning federated recommender systems for
manipulating item promotion. In Proceedings of the Fifteenth ACM International
Conference on Web Search and Data Mining. 1415‚Äì1423.
[53] Bolong Zheng, Kai Zheng, Xiaokui Xiao, Han Su, Hongzhi Yin, Xiaofang Zhou,
and Guohui Li. 2016. Keyword-aware continuous knn query on road networks.
In2016 IEEE 32Nd international conference on data engineering (ICDE). IEEE,
871‚Äì882.
 
2036