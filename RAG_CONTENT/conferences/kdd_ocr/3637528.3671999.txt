Learning Causal Networks from Episodic Data
Osman Mianâ—¦
osman.mian@cispa.de
CISPA Helmholtz Center for
Information Security
SaarbrÃ¼cken, GermanySarah Mamecheâ—¦
sarah.mameche@cispa.de
CISPA Helmholtz Center for
Information Security
SaarbrÃ¼cken, GermanyJilles Vreeken
vreeken@cispa.de
CISPA Helmholtz Center for
Information Security
SaarbrÃ¼cken, Germany
ABSTRACT
In numerous real-world domains, spanning from environmental
monitoring to long-term medical studies, observations do not arrive
in a single batch but rather over time in episodes. This challenges the
traditional assumption in causal discovery of a single, observational
dataset, not only because each episode may be a biased sample
of the population but also because multiple episodes could differ
in the causal interactions underlying the observed variables. We
address these issues using notions of context switches and episodic
selection bias, and introduce a framework for causal modeling
of episodic data. We show under which conditions we can apply
information-theoretic scoring criteria for causal discovery while
preserving consistency. To in practice discover the causal model
progressively over time, we propose the Continent algorithm
which, taking inspiration from continual learning, discovers the
causal model in an online fashion without having to re-learn the
model upon arrival of each new episode. Our experiments over a
variety of settings including selection bias, unknown interventions,
and network changes showcase that Continent works well in
practice and outperforms the baselines by a clear margin.
CCS CONCEPTS
â€¢Mathematics of computing â†’Causal networks; Informa-
tion theory; â€¢Theory of computation â†’Online algorithms .
KEYWORDS
Causal Discovery, Continual Learning, Selection Bias
ACM Reference Format:
Osman Mian, Sarah Mameche, and Jilles Vreeken. 2024. Learning Causal
Networks from Episodic Data. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD â€™24), August
25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3637528.3671999
1 INTRODUCTION
Determining causality is of fundamental interest throughout the
sciences [ 30]. As controlled experiments are often not feasible, the
â—¦Both authors contributed equally to this research.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671999ğ‘†+:
warm
ğ‘†âˆ’:
cold
0 50 100 1500102030
ğ‘‹2: ozone (ğœ‡ğ‘”
ğ‘š3)ğ‘‹1:
temperature (â—¦ğ¶)ğ¸1: November
ğ¸2: February
ğ¸3: June
ğ¸4: October
Figure 1: Cause ğ‘‹1and effect ğ‘‹2[29] measured in episodes
over time(ğ¸1-ğ¸4). Each episode comes from an underlying
season(ğ‘†+,ğ‘†âˆ’), and an unknown context, here Switzerland.
question of how to do so given observational data alone is gaining
increased attention. Classical algorithms for discovering causal
networks assume as their starting point a single, homogeneous
dataset sampled from a single, stationary distribution [6, 30, 39].
However, a more realistic setting is one where we obtain obser-
vations in batches over time. Not only does this mean that we need
to learn and update our causal hypothesis over time, but each batch
likely contains samples from a specific time period or subpopulation,
resulting in a biased distribution. Even the collective data distribu-
tion over allsuch episodes is often not identically distributed since
the causal interactions could differ across domains.
To motivate the episodic setting and illustrate its challenges, con-
sider an example in environmental monitoring where we measure
two markers ğ‘‹1:temperature andğ‘‹2:ozone concentration at differ-
ent times of the year. Suppose we obtain monthly measurements,
resulting in episodes {ğ¸1,...ğ¸ 4}at timepoints{ğ‘¡1,...ğ‘¡4}as shown
in Fig. 1. In our example taken from the TÃ¼bingen cause-effect
pairs [ 29],ğ‘‹1is considered the cause of ğ‘‹2and the overall data
suggest a roughly linear trend of the causal mechanism relating
them. Considering a winter month such as ğ¸1(blue) on its own
would however suggest that both variables are uncorrelated. Only
when including the summer month ğ¸3(yellow) do we obtain a com-
plete picture. In this example, there is a high-temperature season ğ‘†+
(circle) as well as a low-temperature season ğ‘†âˆ’(star), and episodes
coming from only one such season offer a biased picture.
This simplistic example suggests that combining all episodes is
a good practice to remove seasonal bias. This however can lead to
its own set of issues. Consider a dataset that stems from a differ-
ent geographical region or context, where due to local measuring
devices noise levels are different, or even the underlying causal
relationship changes. For instance, a phenomenon known as ozone
suppression [ 42] creates a situation where ozone levels are no longer
 
2224
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
positively correlated with temperature. As ozone suppression only
occurs above a certain temperature threshold, it is not visible in
the data obtained in Switzerland shown in Fig. 1 but could affect
a datasetğ¸5from a region with exceptionally high temperatures.
Overall, whereas episodes ğ¸1âˆ’ğ¸4should be combined to remove
seasonal bias, combining samples from different contexts ğ¸1âˆ’ğ¸5
obscures context-specific causal relationships [44].
While recent work in causal discovery considers different con-
texts [ 28,40,44], it neither addresses episodes nor allows for struc-
tural changes in the causal model across contexts. In contrast, we
propose a causal modeling framework for episodes with selection
bias where an unknown number of causal networks underlie the
data-generating process. We show that in principle, we can use a
consistent scoring criterion for causal discovery in this setting so
long as we observe sufficiently many episodes.
From a practical perspective, existing algorithms for causal dis-
covery [ 6,27,30] start from a single batch of data and hence would
need to relearn the causal model whenever a new episode arrives.
This is clearly computationally impractical; rather, it would be de-
sirable for a domain expert to gain preliminary insights into the
causal relationships based on some earlier episodes and perenially
update these as new data becomes available.
Given these limitations, we develop the Continent algorithm
for discovering causal models over episodic data, more specifi-
cally multiple fully directed causal networks over a set of contexts.
Taking inspiration from continual learning, we hereby avoid fully
re-learning the causal model upon the arrival of each episode but
learn it in an online fashion. We propose a strategy to update
the causal hypothesis as new episodes arrive, using distribution
matching and an information-theoretic perspective of causality,
and show that our updating strategy is consistent. We show in
experiments that Continent discovers causal networks reliably
from data with episodic selection bias, under interventions, as well
as with structural changes in causal networks. Not only does it
compare favorably to its competitors, but only Continent is able
to learn the causal model adaptively over time. It can also address
an experimental setting where we assign a new, unseen episode to
one of the causal networks inferred from previous episodes.
Contributions. To summarize our main contributions, we
â€¢introduce a causal modeling framework for episodic data,
â€¢show under which conditions we can use an information-
theoretic consistent scoring criterion to identify a set of
causal networks underlying such data,
â€¢develop the practical approach Continent to learn such
causal networks in a continual fashion,
â€¢confirm in experiments that Continent works in practice.
We structure our exposition according to the above, first introduc-
ing notation and preliminaries, then introducing our causal model
and practical algorithm, and concluding with an experimental eval-
uation and discussion.
2 PRELIMINARIES
First, we outline our problem setting and review causal modeling
techniques for independent and identically distributed (i.i.d.) data.2.1 Notation and Problem Setting
Throughout our work, we consider a batch setting where we ob-
tain observations as a sequence of datasets {ğ¸0,...,ğ¸ğ‘}at time-
points{ğ‘¡0,...,ğ‘¡ğ‘}, and refer to dataset ğ¸ğ‘–at timeğ‘¡ğ‘–as an episode.
We denote the dataset that combines all episodes up to time ğ‘¡ğ‘–as
ğ·ğ‘=âˆªğ‘
ğ‘–=1ğ¸ğ‘–.In each episode, we observe a fixed set of continuous
random variables ğ‘‹={ğ‘‹1,...,ğ‘‹ğ‘€}with distribution ğ‘ƒ(ğ‘‹).
Episodes can belong to different domains or environments, which
we call contexts denoted by{ğ¶0,...,ğ¶ğ‘…}. Each episode ğ¸ğ‘–is a mem-
ber of a unique context ğ¶ğ‘Ÿ, which we write as ğ¶(ğ¸ğ‘–), and we write
ğ‘‹ğ‘Ÿ,ğ‘ƒğ‘Ÿto refer to variables, resp. distributions, in the ğ‘Ÿth context.
Novel to our work is that we neither know how many contexts ğ‘…
exist nor which context ğ¶(ğ¸ğ‘–)each episode comes from.
In addition to coming from different contexts, episodes are not
necessarily i.i.d. but rather could preferentially include samples
from a certain subpopulation ğ‘†. To illustrate, consider the warm
seasonğ‘†+in Fig. 1. Episode ğ¸3exhibits selection bias in that it
only includes i.i.d. samples from this season. We can represent ğ‘†+
through a binary variable ğ‘†with values ğ‘†=â—¦,ğ‘†=âˆ—, with the
interpretation that samples ğ‘†=â—¦are observed, ğ‘†=âˆ—are missing
fromğ¸3, so that it follows a biased distribution. In general, we
consider a categorical variable ğ‘†with values{ğ‘ 1,...,ğ‘ ğ¾}modeling
subpopulations of ğ‘ƒ(ğ‘‹), so that each episode results from selecting
an unknown population ğ‘ ğ‘˜and sampling from ğ‘ƒ(ğ‘‹|ğ‘†=ğ‘ ğ‘˜). As
we could obtain multiple episodes from the same subpopulation,
for example repeated monthly episodes over multiple years, we do
not assume the number ğ¾â‰¤ğ‘to be known a priori.
In this episodic setting, we want to discover how many and
which causal models there are.
Problem Statement (Informal). Given datasets{ğ¸0,...,ğ¸ğ‘}
where each episode ğ¸ğ‘–is generated from the causal model in an un-
known context ğ¶ğ‘Ÿand by conditioning on an unknown value ğ‘ ğ‘˜ofğ‘†,
we want to discover the set of causal models over ğ‘‹.
Before we address this problem, we take a step back to address
causal discovery in an i.i.d. setting and introduce the concepts and
assumptions that we build on.
2.2 Causal Discovery
For now, consider the case of a single context without selection bias.
We can specify a causal model over the variables ğ‘‹by a directed
acyclic graph (DAG) ğº=(ğ‘‹,ğ¸)with node set ğ‘‹and edges(ğ‘–,ğ‘—)âˆˆğ¸
whenever the variable ğ‘‹ğ‘–is a cause of ğ‘‹ğ‘—[30]. To denote the set
of direct causes of ğ‘‹ğ‘—we write pağ‘—where we leave ğºimplicit.
Together with the network structure in ğº, we assume a structural
causal model over the variables, where each effect is generated from
its causes through a causal function or mechanism ğ‘“ğ‘—,
ğ‘‹ğ‘—=ğ‘“ğ‘—(pağ‘—,ğ‘ğ‘—)
whereğ‘ğ‘—is a noise variable implicit in ğºwithğ‘ğ‘—âŠ¥âŠ¥ğ‘‹ğ‘—.
A causal model is identifiable when we can determine it uniquely
from an observational distribution [ 30]. In general, identifiability
of the causal DAG ğºis only possible under additional assumptions.
Hence, we assume causal sufficiency, which states that no latent
variable jointly causes any of the observed variables, as well as the
causal Markov andfaithfulness conditions, which together imply
 
2225Learning Causal Networks from Episodic Data KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
that edge separations in the graphical model ğºcorrespond to inde-
pendence constraints in the observed distribution ğ‘ƒ. Under these
assumptions, it is well known that identifiability holds up to the
Markov Equivalence Class (MEC) of ğº[10].
Identification of causal directions beyond the MEC is possible
using additional information about how the system reacts to inter-
ventions [ 11,22,44]. In the absence of such information, we need to
make additional assumptions, such as restricting the functional de-
pendencies ğ‘“to nonlinear functions with additive noise [ 5,12,25].
As an example of this approach, a family of methods build on the
algorithmic framework of causation [ 14] and derive consistent scor-
ing criteria that can be used for causal discovery within a given
class of functional models. This is the approach we will follow here.
2.3 Information-theoretic Causal Discovery
The algorithmic model of causation [ 14] reasons about the complex-
ity of causal mechanisms in describing the observed data. To this
end, it uses the concept of Kolmogorov complexity. Kolmogorov
complexity defines, for binary strings ğ‘¥âˆˆ{0,1}âˆ—, the length ğ¾(ğ‘¥)
of the shortest binary program ğ‘¥âˆ—that outputs ğ‘¥and halts. The Kol-
mogorov complexity ğ¾(ğ‘ƒ)over a distribution ğ‘ƒdefines the length
of the shortest program ğ‘âˆ—that approximates ğ‘ƒup to precision ğ‘
on a universal Turing machine Ugiven inputâŸ¨ğ‘¥,ğ‘âŸ©[18],
ğ¾(ğ‘ƒ)=min
ğ‘âˆ—âˆˆ{0,1}âˆ—{|ğ‘âˆ—|:UâŸ¨ğ‘¥,ğ‘âŸ©âˆ’ğ‘ƒ(ğ‘¥)|â‰¤1
ğ‘}.
Using Kolmogorov complexity, we can state the centerpiece of
the algorithmic view of causal networks, namely the Algorithmic
Markov Condition (AMC) [14].
Algorithmic Markov Condition. The AMC postulates that causal
mechanisms correspond to programs that encode the observed
distributions most concisely in terms of Kolmogorov complexity.
More precisely, it assumes that each causal mechanism ğ‘“ğ‘—for a
givenğ‘‹ğ‘—can be described by a program ğ‘ğ‘—that independently
generates the distribution ğ‘ƒ(ğ‘‹ğ‘—|pağ‘—). The AMC posits that the
complexity of the overall distribution ğ‘ƒ(ğ‘‹)corresponds to the
summed complexities over these independent programs,
ğ¾(ğ‘ƒ(ğ‘‹))+=ğ‘€âˆ‘ï¸
ğ‘—=1ğ¾ ğ‘ƒ(ğ‘‹ğ‘—|pağ‘—)(1)
which holds up to a constant, i.e. the complexities can differ by that
of a program with constant length.
Causal Discovery using the AMC. Kolmogorov complexity cannot
be computed for arbitrary programs [ 18], but can be approximated
from above via Minimum Description Length (MDL) [ 9] for a fixed
model class. Eq. (1)is therefore commonly stated for a flexible class
of functions, such as non-parametric regression models.
In detail, MDL defines a description length ğ¿ofğ‘‹together with
its optimal causal model ğºâˆ—, given by
ğ¿(ğ‘‹;ğºâˆ—)=ğ¿(ğºâˆ—)+âˆ‘ï¸
ğ‘‹ğ‘—âˆˆğºâˆ—(ğ‘‹ğ‘—|pağ‘—,ğºâˆ—). (2)
The scoreğ¿(ğ‘‹;ğº)is given by the length, in bits, of first encoding
the model itself and then encoding the data under the model. Specif-
ically,ğ¿(ğº)encodes the network structure of ğºand the functional
relationships ğ‘“ğ‘—using a model class of choice with MDL score ğ¿(ğ‘“ğ‘—).The remaining term poses according to the causal factorization
and describes each variable ğ‘‹ğ‘—from its causal parents pağ‘—. Usingğ¿,
Eq.(1)suggests estimating the causal model as the one minimizing
the overall description length ğ¿(ğ‘‹;ğº).
Various instantiations of ğ¿exist, addressing, for example, the
bivariate [ 24] and multivariate case [ 27], latent confounding [ 16],
and interventional data [ 21,22,26]. Throughout this work, we
assume a given score ğ¿that decomposes as in Eq. 2 and is consistent
in the sense that it allows estimating a DAG ğºâˆ¼ğºâˆ—that is Markov
equivalent to ğºâˆ—in the limit, limğ‘›â†’âˆğ‘ƒ(Ë†ğºâˆ¼ğºâˆ—)=1for i.i.d. data
with sample size ğ‘›. We refer to Mian et al . [27] for definitions of ğ¿
in a multivariate setting and a consistent algorithm for discovering
ğºin from an i.i.d. data distribution. As consistency results and
practical algorithms have only been explored in the i.i.d. case [ 27]
or interventional data [22, 26], we turn to episodic data here.
3 THEORY
In this section, we introduce our causal model for episodic data.
3.1 Causal Model
Our causal model comprises a set of causal DAGs G={ğº1,...,ğºğ‘…}
over a common set of variables ğ‘‹âˆª{ğ‘†}, whereğ‘‹are measured,
continuous random variables of interest, and ğ‘†is an unmeasured
categorical variable with values ğ‘†={ğ‘ 1,...,ğ‘ ğ¾}. Each DAG ğºğ‘Ÿis
a causal model over ğ‘‹ğ‘Ÿ, i.e., it describes the causal relationships
in all episodes from a given context ğ¶ğ‘Ÿ. The additional variable ğ‘†
models that certain observations may be missing in each episode.
To do so, we extend upon a missingness framework commonly
used to handle selection bias [ 2,35]. To explain, consider the ğ‘›th
observation, where we represent ğ‘†using a one-hot encoding,
 ğ‘‹(ğ‘›)
1,...,ğ‘‹(ğ‘›)
ğ‘€,ğ‘ (ğ‘›)
1,...,ğ‘ (ğ‘›)
ğ¾
where we suppress the dependency on the context to avoid clutter.
Above,ğ‘‹(ğ‘›)is associated to indicators ğ‘ ğ‘˜whereğ‘ ğ‘˜=1ifğ‘‹(ğ‘›)is
observed, else ğ‘ ğ‘˜=0if it is missing in a distribution ğ‘˜. We obtainğ¾
biased distributions ğ‘ƒ(ğ‘‹|ğ‘†=ğ‘ ğ‘˜)of which episodes are subsamples.
Exactly which samples are observed could depend on ğ‘‹; in Fig. 1,
for instance, ğ‘†+=â—¦holds for the temperature range ğ‘‹1â‰¥10. In
general, we assume that any unknown mechanism assigns ğ‘†,
ğ‘†=ğ‘”(ğ‘‹,ğ‘ğ‘ ), ğ‘ğ‘ âŠ¥âŠ¥ğ‘† ,
whereğ‘”maps each sample to an assignment of ğ‘†using input ğ‘‹,
which is noisy through ğ‘ğ‘ . We therefore include ğ‘†in the causal
model together with edges ğ‘‹ğ‘—â†’ğ‘†for allğ‘‹ğ‘—, and assume that ğ‘†is
a sink node. We include a node ğ‘†ğ‘Ÿinğºğ‘Ÿin eachğ¶ğ‘Ÿwith the same ğ¾
for simplicity, although our framework can be extended to include
a dependency ğ¾ğ‘Ÿ. We assume causal sufficiency over ğ‘‹ğ‘Ÿâˆª{ğ‘†}.
To summarize, our causal model is the following.
Assumption 3.1 (Causal model with contexts and selection). Our
causal model is given by a set of DAGs G={ğº1,...,ğºğ‘…}over
ğ‘‹âˆª{ğ‘†}from a finite number of contexts ğ‘…such that in context ğ¶ğ‘Ÿ,
each observed variable ğ‘‹ğ‘—is generated as
ğ‘‹ğ‘Ÿ
ğ‘—=ğ‘“ğ‘Ÿ
ğ‘—(pağ‘Ÿ
ğ‘—,ğ‘ğ‘Ÿ
ğ‘—), ğ‘ğ‘Ÿ
ğ‘—âŠ¥âŠ¥ğ‘‹ğ‘Ÿ
ğ‘—,
 
2226KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
where pağ‘Ÿ
ğ‘—denote the causal parents of ğ‘‹ğ‘Ÿ
ğ‘—inğºğ‘Ÿandğ‘ğ‘Ÿ
ğ‘—is an
independent noise term. The latent variable ğ‘†is generated as
ğ‘†ğ‘Ÿ=ğ‘”ğ‘Ÿ(ğ‘‹ğ‘Ÿ
ğ‘—,ğ‘ğ‘Ÿ
ğ‘ ), ğ‘ğ‘Ÿ
ğ‘ âŠ¥âŠ¥ğ‘†ğ‘Ÿ.
The above describes an unbiased generating process where each
variableğ‘‹ğ‘—is a function of its causal parents pağ‘—and noiseğ‘ğ‘—.
In addition, the mechanism ğ‘”with noiseğ‘ğ‘ generatesğ‘†. This
generating process happens independently in each context.
We assume that episodes result from conditioning on a specific
value of the unobserved selection variable.
Assumption 3.2 (Episodic data). Under the causal model in As-
sumption 3.1, after generating an unbiased distribution ğ‘ƒğ‘Ÿ(ğ‘‹,ğ‘†)
from the DAG ğºğ‘Ÿin each context ğ¶ğ‘Ÿ, all episodes ğ¸coming from
contextğ¶(ğ¸)=ğ¶ğ‘Ÿhave distribution ğ‘ƒğ‘Ÿ(ğ‘‹|ğ‘†=ğ‘ ğ‘˜)for some
specificğ‘ ğ‘˜âˆˆ{ğ‘ 1,...,ğ‘ ğ¾}.
With no assumption on the selection mechanism ğ‘”, number of
contextsğ‘…, or number of selection regions ğ¾, our model can en-
compass general cases of episodic data. This invariably also makes
it more challenging to discover the causal model from data. To do
so, we first state the algorithmic Markov condition for our model.
Postulate 3.3 (Algorithmic Markov Condition). Under Assump-
tions 3.1 and 3.2, a set of causal DAGs G={ğº1,...,ğºğ‘…}is only
admissible as the causal hypothesis over ğ‘‹andğ‘†if
ğ¾ ğ‘ƒ ğ‘‹âˆª{ğ‘†}+=ğ‘…âˆ‘ï¸
ğ‘Ÿ=1ğ‘€âˆ‘ï¸
ğ‘—=1ğ¾ ğ‘ƒğ‘Ÿ(ğ‘‹ğ‘—|pağ‘—)+ğ¾(ğ‘ƒğ‘Ÿ(ğ‘†|ğ‘‹))
+=ğ¾ ğ‘ƒ(ğ‘‹)+ğ¾ ğ‘ƒ(ğ‘†|ğ‘‹)
where+=holds up to an additive constant.
Asğ‘†is not included in any parent set, we can in principle consider
the complexity of, and hence causal structure over, ğ‘‹independently
of the complexity of ğ‘†. This motivates the idea of using a consistent
scoring criterion to find the causal structure over ğ‘‹in each context.
As a complication, we hereby need to discover the number of
contexts. Suppose we obtained data ğ·ğ‘›accumulated over ğ‘›episodes.
There could be any number ğ‘…of different causal models, with 1â‰¤
ğ‘…â‰¤ğ‘›. Thus, we need to consider any partition of our samples into
ğ‘…disjoint sets, which we write as Î (ğ·ğ‘›)={ğ‘‹1,...ğ‘‹ğ‘…}. In each
set, we propose discovering the causal DAG using the consistent
scoreğ¿(ğ‘‹ğ‘Ÿ;ğº), and overall find the partition minimizing this score.
To summarize, our objective is as follows.
Problem Statement. Given variables ğ‘‹and datağ·ğ‘›overğ‘›
episodes, we aim to discover the partition Î (ğ·ğ‘›)ofğ·ğ‘›into contexts
and the causal model Ë†ğºğ‘Ÿin each context minimizing
min
Î (ğ·)|Î (ğ·)|âˆ‘ï¸
ğ‘Ÿ=1min
ğºğ‘Ÿğ¿(ğ‘‹ğ‘Ÿ;ğºğ‘Ÿ). (3)
where we write ğ‘‹ğ‘Ÿfor the data in the ğ‘Ÿ-th set of Î (ğ·).
This leaves us with two questions; first, ensuring that the above
is a consistent way of identifying the causal model, and second,
how to efficiently minimize it in practice.3.2 Asymptotic Guarantees
We first want to establish conditions under which ğ¿can be used in
a consistent way to discover the causal DAGs in all contexts.
This revolves around whether the biased distributions in each
episode eventually allow us to estimate the relevant distributions
in Postulate 3.3 in an unbiased way so that we can apply Eq. (3).
That is, estimation of each causal mechanism should not depend on
the selection variable. We hence make the following assumption.
Assumption 3.4 (Ignorability). Under the causal model in As-
sumption 3.1 and given ğ·ğ‘overğ‘episodes, in each context ğ¶ğ‘Ÿ,
we assume the following ignorability of selection bias,
ğ‘‹ğ‘Ÿ
ğ‘—âŠ¥âŠ¥ğ‘†ğ‘Ÿ|Zğ‘Ÿ
for eachğ‘‹ğ‘Ÿ
ğ‘—and conditioning set Zğ‘ŸâŠ†ğ‘‹ğ‘Ÿ\{ğ‘‹,
ğ‘—ğ‘†ğ‘Ÿ}.
Examples of when the above holds are cases known as Missing
At Random (MAR) or Missing Completely At Random (MCAR)
[2,3,35], for example, when a biased ğ‘ƒ(ğ‘‹|ğ‘†=ğ‘ ğ‘˜)is a uniform
sample from the population ğ‘ƒ(ğ‘‹). A more realistic case is the one
in Fig. 1 where the selection mechanism depends on temperature
ğ‘‹1. We can see that episodes from the cold season ğ‘ƒ(ğ‘‹|ğ‘†=âˆ—)
indeed do not allow an unbiased view of the causal mechanism,
however once we obtain enough episodes from both ğ‘†âˆ’,ğ‘†+then
ignorability holds. More generally, we ensure via Assumption 3.4
that we eventually obtain enough samples from the support of ğ‘‹.
With this, we can show that an MDL-based score ğ¿can be used
for causal discovery with unknown contexts.
Theorem 3.5 (Consistency of ğ¿in the episodic setting). For the
causal model in Assumption 3.1 and given data ğ·ğ‘›overğ‘›episodes as
in Assumption 3.2, under Assumption 3.4, a consistent scoring criterion
ğ¿that decomposes as in Eq. 2 remains consistent,
lim
|ğ·ğ‘›|â†’âˆğ‘ƒ(Ë†ğºğ‘Ÿâˆ¼ğºâˆ—
ğ‘Ÿ)=1 for allğ‘Ÿâˆˆ{1,...,ğ‘…}.
However, this does not make it obvious how to apply ğ¿in practice.
First, note that the result relies on enough episodes being observed
so that selection is ignorable, that is, we did not yet address how
to deal with non-ignorable selection at each time point when we
only observed a subset of episodes. Second, even when observing
enough episodes, searching over the space of DAGs to minimize ğ¿
as in Eq. 3 is prohibitive even for a single causal model due to the
super-exponential search space over DAGs [ 6]. While there exist
greedy algorithms to do so, such as the MDL-based Globe , applying
such methods to any partition of the data with an unknown number
of contexts is not favorable as it could violate the i.i.d. assumption
required for these methods. To address these issues, we propose an
algorithm for causal discovery over episodic data in the following.
4 ALGORITHM
In this section, we introduce our algorithm Continent.
4.1 Overview
To motivate our algorithm setup, let us revisit our motivating ex-
ample in Fig. 1 showing episodes obtained in winter ğ¸1, springğ¸2,
summerğ¸3, and autumn ğ¸4. We consider a fixed number of seasons,
hereğ‘†+,ğ‘†âˆ’. All episodes ğ¸1-ğ¸4shown come from a context ğ¶1but
any number of future episodes could arrive from a different ğ¶2.
 
2227Learning Causal Networks from Episodic Data KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Algorithm 1: Continent(ğ¸,A,T)
input : episodesğ¸arriving over time, residual test T,
causal discovery algorithm Awith scoreğ¿
output: causal model G={ğº1,...ğºğ‘…}
1Gâ†{}
2ğœâ†0
3while a new episode ğ¸ğ‘–arrives do
4 Gâ†Update(G,ğ¸ğ‘–,A,T)
5ğœâ†ğœ+1
6 ifğœâ‰¥ğœmaxthen
7 Gâ†Merge(G,A,T)
8ğœâ†0
9 end
10end
11Gâ†Merge(G,A)
12return G
Given a learnerAfor greedy DAG search with a consistent scor-
ing criterion ğ¿, we aim to discover the underlying causal DAG ğº1
overğ¸1-ğ¸4, and possibly add a causal model ğº2if future episodes
from a different ğ¶2arrive. ApplyingAto all episodes at each time
point is not only impractical, but may also not be consistent given
that selection bias is not ignorable until all episodes arrive. In-
stead, we propose an algorithm Continent that maintains plau-
sible causal models G={ğº1,...,ğºğ‘…}at each time ğ‘¡ğ‘–and uses a
strategy for updating Gwhen a new episode ğ¸ğ‘–+1arrives.
Model Updating. In our example, say that we obtained episodes
ğ¸1-ğ¸3and the current causal model is G={ğº1}. As we already
observed episodes from both seasons ğ‘†+resp.ğ‘†âˆ’we likely already
learned an unbiased model ğº1. As the autumn episode ğ¸4arrives,
we want to assign it to ğº1without re-learning the causal model
from scratch. To this end, we propose using a two-sample testing
procedureTto decide whether a given episode matches an existing
causal model. Here, after checking with Tthatğ¸1-ğ¸4can be stacked
we combine the data ğ¸1-ğ¸4and keep the model ğº1as is.
On the other hand, say episode ğ¸5from a different context ğ¶2
arrives1andTdecides that it does not match any current causal
model. Then we apply the learner Ato learn a new model ğº2over
ğ¸5and add it to our set of models, G={ğº1,ğº2}.
Note that the above assumes that we already learned an unbiased
causal model over the available episodes. We also need to consider
the case where a causal model is biased, such that we need to update
it after merging data from multiple episodes.
Model Merging. Say that we observed episodes ğ¸1-ğ¸2to learn
a causal model ğº0. From the winter seasons ğ‘†âˆ’alone, it appears
thatğ‘‹1,ğ‘‹2are uncorrelated, hence ğº0is biased. When ğ¸3from
summer season ğ‘†+arrives, we need to merge the data to the previous
episodes and learn a new model ğº1.
To do this, we attempt merging data over multiple episodes at
regular time intervals. We again apply Tto check whether a merge
is possible, and if so, check whether merging any two causal models
1This could be e.g. readings obtained from a different geographical region where causal
mechanism between ğ‘‹1andğ‘‹2is different/non-existent.Algorithm 2: TestResidualEq(ğºğ‘Ÿ,ğ¸ğ‘–,ğ·,T)
input : causal model ğº, episodeğ¸ğ‘–, datağ·, residual testT
output: test result
1foreachğ‘‹ğ‘—with parent set Zinğºdo
2ğ‘ğ‘—â†T.Test(ğ»0:ğ‘ƒğ·(ğ‘‹ğ‘—|Z)â‰¡ğ‘ƒğ‘–(ğ‘‹ğ‘—|Z);ğ›¼)
3end
4pâ†T.Correct({ğ‘1,...ğ‘ğ‘€})
5ifT.Significant(p)return True else return False
results in an improved model, judging by our score ğ¿. As stacking
may be sufficient when we already gained sufficient evidence for a
candidate model, in practice, we attempt merging at regular time
intervals using a pre-specified tolerance parameter ğœmax.
Combining the model updating and model merging described
above, we have our proposed approach, Continent .
Continent .We show the pseudocode of Continent in Alg. 1.
We maintain a set of models Gthroughout, where we associate
eachğºâˆˆGto a dataset ğ·of episodes, initially empty (Line 1).
As new episodes arrive, we update Gat each time step using
theUpdate function (Line 4). In short, it checks using hypothesis
testing whether a new episode ğ¸ğ‘–matches the data ğ·under an
existing model, in which case we stack the datasets ğ¸ğ‘–andğ·; else
we applyAtoğ¸ğ‘–to discover a new model ğºğ‘–which we add to G.
We show our hypothesis test in Alg. 2, and Update in the appendix.
After a pre-specified number of episodes, we attempt merging
existing models (Line 7), with a tolerance parameter ğœkeeping
track of the time since a merge last happened (Line 8). In essence,
Merge performs pairwise comparison of models ğº,ğºâ€². If appro-
priate, it learns a new model ğºâˆªafter pooling the resp. datasets
ğ·,ğ·â€²of the pair. During the algorithm, we only allow such a merge
ifTmarks the residual distributions of ğ·,ğ·â€²as compatible, for
which we again apply our hypothesis test in Alg. 2. We include the
pseudocode for Merge in Appendix B.
Our alternation of updating and merging continues as long as
new episodes arrive. We conclude with a final merge (Line 11).
Compared to merge steps throughout our algorithm which we
protect byT, we consider all remaining possible merges of model
pairsğº,ğºâ€²in this step given that no more episodes arrive (Line 11).
4.2 Consistency
Naturally, we want to make sure that our adaptive strategy is con-
sistent. At any time point ğ‘¡ğ‘–, however, we only have access to a
subset of the episodes so that ignorability in Assumption 3.4 un-
likely holds, and hence any causal model inferred using Amay be
incorrect. Nevertheless, we need to avoid merging episodes with
different underlying models. We now show that we can do so with-
out knowing the true models. To do so, we assume a hypothesis
testTtesting
ğ»0:ğ‘ƒ1(ğ‘‹ğ‘—|Z)â‰¡ğ‘ƒ2(ğ‘‹ğ‘—|Z)
for a given variable ğ‘‹ğ‘—, conditioning set Zand two datasets ğ‘ƒ1,ğ‘ƒ2.
Given any causal DAG, we test ğ»0for each variable given its es-
timated parent set and include a multiple testing correction, as
 
2228KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
shown in Alg. 2. We can show that our updating strategy protected
by this test is consistent under the following condition.
Assumption 4.1 (Detectable selection) .We assume that selection
detectable for a variable ğ‘‹ğ‘—and pair of contexts ğ¶ğ‘Ÿ,ğ¶â€²ğ‘Ÿmeaning
ğ‘ƒğ‘Ÿ(ğ‘‹ğ‘—|pağ‘—)â‰ ğ‘ƒğ‘Ÿâ€²(ğ‘‹ğ‘—|pağ‘—)
â‡’ğ‘ƒğ‘Ÿ(ğ‘‹ğ‘—|pağ‘—,ğ‘†=ğ‘ ğ‘˜)â‰ ğ‘ƒğ‘Ÿâ€²(ğ‘‹ğ‘—|pağ‘—,ğ‘†=ğ‘ ğ‘˜)
holds for each value ğ‘ ğ‘˜ofğ‘†.
Unlike ignorability in Assumption 3.4 which requires full inde-
pendence of the causal mechanism and selection mechanism, that
is, ensures that we can estimate the causal mechanism for each
variable in a fully unbiased way, Assumption 4.1 only requires that
distribution differences of ğ‘ƒ(ğ‘‹)hold also in the biased distribution
ğ‘ƒ(ğ‘‹|ğ‘†=ğ‘ ğ‘˜). Given that the latter are subsamples of the overall
distribution, this is reasonable in practice. With this, we can show
that our updating strategy is consistent.
Theorem 4.2 (Consistency of updating using T).With discrepancy
testTwe will never merge a new episode ğ¸ğ‘–+1with a set Ë†ğ‘‹ğ‘Ÿfrom an
incorrect context where ğ¶(ğ¸ğ‘–+1)â‰ ğ¶(ğ¸)for someğ¸âˆˆË†ğ‘‹ğ‘Ÿ.
This shows that our updating step is safe in the sense that we
always discover subsets of the correct contexts. When we observed
all episodes, we can also recover the exact sets of contexts if ignor-
ability holds, based on Thm. 3.5.
Corollary 4.3 (Consistency of Continent ).Given a consistent
DAG search algorithm Aand scoreğ¿, under assumption 3.4 our
algorithm is consistent, so that
lim
|ğ·ğ‘›|â†’âˆğ‘ƒ(Ë†ğºğ‘Ÿâˆ¼ğºğ‘Ÿâˆ—)=1 for allğ‘Ÿâˆˆ{1...,ğ‘…}
holds after we obtain ğ‘›episodesğ·ğ‘›and perform the merge step.
As the final step in this section, we address practical considera-
tions around our algorithm.
4.3 Instantiation
We conclude this section by giving details on the components of
Continent .
Causal Discovery Algorithm A.We assume a score-based causal
discovery algorithm Athat allows discovering a causal DAG ğº
from an i.i.d. dataset ğ·. While in principle, this could be any score-
based method with a consistent scoring criterion ğ¿decomposing
according to Eq. (2), we use an MDL-based approach in our practical
instantiation as it allows for a principled way for model comparison.
We instantiateAwith Globe [27] which is an efficient algorithm
for discovering causal networks. It models causal functions through
non-parametric multivariate regression with additive noise.
Residual TestT.Our method can also work together with any
hypothesis testTfor differences in conditional distributions under
a causal model. As Globe models causal functions through non-
parametric spline regression, a natural choice is testing residual
distributions under a given model for equality. As we apply a test
per each variable, we perform Bonferroni correction to obtain a
ğ‘-value from the test results {ğ‘1,...,ğ‘ğ‘€}. Unless otherwise stated,
we apply the non-parametric Kolmogorov-Smirnov [ 1,38] test in
our evaluations.5 RELATED WORK
Discovering causal models that faithfully describe the interactions
between variables of interest given observational data alone is an
actively studied problem and finds applications in almost all areas of
science. Approaches to do so typically fall into the categorizations
of constraint-based methods, such as PC [ 30], or score-based meth-
ods, such as GES [ 6,34]. As these approaches discover a Markov
Equivalence Class (MEC) of the causal DAG [ 10], recent approaches
study under which assumptions we can determine causal directions
beyond the MEC. One line of work does so by constraining the
functional model [ 5,33], such as LiNGAM [ 37] which assumes lin-
ear non-Gaussian models. Another branch of work builds on the
algorithmic model of causality [ 14], such as Globe [27]. However,
the examples given up to this point assume an i.i.d. data distribution
where a single causal network can capture the causal interactions,
and where neither selection bias nor contexts exist.
Selection Bias. Missingness is a well-studied problem in statistical
inference and in particular, many approaches exist for correcting
for missingness and selection bias [ 4,8,43]; see Little and Rubin
[19] for an overview. Only very recent work studies assumptions
foridentifying whether selection bias holds in a given dataset [ 17].
Our perspective is different as we are interested in adapting causal
discovery to the presence of missingness. An important line of work
studies recoverability [3,31] from selection bias in causal discovery,
modeled through unobserved sink node ğ‘†in the causal graph. We
also adopt this model here using multiple missingness regions, and
in addition consider the presence of multiple contexts in the form
of varying causal mechanisms.
Different Contexts. A wealth of recent literature studies causal
discovery from different environments, experimental regimes, or
contexts [ 13,20,40,44]; prominent examples include the constraint-
based JCI framework [ 28], additive noise model based multi-group
Lingam [36], and score-based approaches [ 7,21,22,26] for discov-
ering causal DAGs from multi-context data. While studies of latent
confounding in such data exist [ 23], latent selection remains under-
explored. In particular, existing work assumes that each context is
an identically distributed (i.i.d.) sample with fixed causal model. We
make this setting more general in that we obtain biased samples
from each context, which need to be combined to result in i.i.d. data.
To our knowledge, we are the first to allow a different causal model
with episodical bias in different contexts, and also address the algo-
rithmic challenges associated with discovering causal networks in
an online fashion.
To demonstrate how classical and environment-based causal
discovery approaches fare with episodical selection bias in practice,
we next compare them against Continent.
6 EVALUATION
Since to the best of our knowledge, there is no specific algorithm
designed for causal discovery from continually arriving episodic
data, we look at the nearest possible modifications of existing al-
gorithms for comparison. As baseline we compare to Globe [27],
Resit [33] and Ges[6,34]. We modify these algorithms as follows
â€” we first learn a causal network over each individual incoming
 
2229Learning Causal Networks from Episodic Data KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
00.20.40.60.8100.20.40.60.81
Ã—Ã—Ã—
Ã—Ã—Ã—
ShdSid Continent
Globe
Ges
Lingam
Resit
Jci-P
c
00.20.40.60.81F1Continent Globe Ges
Resit Lingam Jci-P
c
Figur e2:Normalize dShd andSid[Left, Closer toorigin
isbetter ]and Orientation F1[Right, Higher isbetter ]for
netw orks learne doverepiso dicdata with selection bias.
00.20.40.60.8100.20.40.60.81
Ã—Ã—Ã—Ã—Ã—Ã—
ShdSid Continent
Globe
Ges
Resit
Lingam
Jci-P
c
00.20.40.60.81F1Continent Globe Ges
Resit Lingam Jci-P
c
Figur e3:Normalize dShd andSid[Left, Closer toorigin isbet-
ter]andOrientation F1[Right, Higher isbetter ]fornetw orks
learne doverepiso dicdata with unkno wninter ventions.
episo deofdata, andthen take aunion overtheedges. This iscor-
rect,under theassumption underlying each ofthese appr oaches,
that each episo decomes fromthesame causal netw ork[26].We
also compar etomulti-envir onment causal disco veryappr oaches
such astheJCI-frame work[28]using thePcalgorithm [39],aswell
asMulti-Gr oupLingam (Lingam )[36].Thelatter twoapproaches,
however,requirethatallepiso desareavailable tolearn acausal net-
work.Hence ,weprovide allepiso desinonegotothese approaches.
This constitutes anadvantage astheycanlearn fromcomplete data.
Tomeasur ethequality ofthepredicte dcausal structur eswe
usetheStructural Hamming Distance (Shd)[15],theStructural
Inter vention Distance (Sid)[32],aswellastheOrientation- F1score
overlearne dnetw orks. Shd counts thenumb erofedges wher ethe
predicte dcausal netw orkdiffers fromthetrue causal netw ork,Sid
counts pairs ofvariables forwhich inter vention estimation differs
acrosspredicte dresp.true causal netw orkandtheF1scoreallows
ustoseehowaccurately edges areoriente dinthelearne dnetw ork.
Next,wediscuss results overbothsynthetic andreal-w orld data.
6.1 Synthetic Data
Foreach oftheproposedexperiment setups, wegenerate random
graphs using ErdÅ‘s-RÃ©nyi modelfornetw orksizesğ‘‘={5,10,15},
andgenerate data foreffectsusing functions ofthefollowing form,
ğ‘‹ğ‘–=Ã
ğ‘¥âˆˆğ‘ğ‘ğ‘–ğ‘“(ğ‘¥)+Nğ‘–,wher eğ‘“(ğ‘¥)iseither apolynomial function
oracombination ofsine andcosine functions define dovereach
parentğ‘¥âˆˆğ‘ğ‘ğ‘–ofğ‘‹ğ‘–,andNğ‘–iseither Gaussian orUniform. For
each graph/function combination, wegenerate atotal of10,00012345678910010203040
ğ‘’Shdğ‘‘=5ğ‘‘=10
ğ‘‘=15
12345678910010203040
ğ‘’Shd
Figur e4:[Lowerisbetter ]Change inShd overincreasing
numb erofepiso desğ‘’fordata with selection bias (left) and
unkno wninter ventions (right) forgraph sizesğ‘‘={5,10,15}.
123456789100123456
ğ‘’Mo
delCountğ‘‘=5ğ‘‘=10
ğ‘‘=15
123456789100123456
ğ‘’Mo
delCount
Figur e5:ModelCount overincreasing episo desğ‘’fordata
with selection bias (left) anddata with (unkno wn)inter ven-
tions (right) forgraphs ofsizeğ‘‘={5,10,15}.Ther eare1resp.
3true underlying models for bias resp. intervention cases.
samples andthen split them into 10episo desofsize1000 each.
Wetransmit these episo destoeach algorithm oneatatime.After
each episo de,wenote theupdatedcausal netw orkforeach ofthe
metho ds.AsJci-P candLingam areprovidedallepiso destogether ,
weonly measur eperformance overthefinal netw ork.
Primarily ,weinvestigate thefollowing questions.
Q1CanContinent reliably disco vercausal netw orks when the
incoming episo descome fromthesame underlying causal
netw ork?
Q2HowwelldoesContinent perform when episo descontain
unkno wninter ventions?
Q3CanContinent identify causal netw orks fromepiso dicdata
containing different causal mechanisms?
Q4HowdoesContinent â€™sperformance change overtime as
episo desarriv e?
AsContinent isdesigne dwithout theassumption that each
data comes fromthesame underlying causal netw ork,ittherefore
maintains alistofcandidate netw orks forgroups ofepiso des.For
comparability toother approaches, weforceContinent topredict
asingle causal netw orkforcasesğ‘„1andğ‘„2bytaking aunion over
theedges incandidate models[26].Wefurther provide ananalysis
oftheindividually learne dcausal netw orks forevaluation inğ‘„3.
Werelease allourcodeanddata forresear chpurp oses2.Next,we
showresults foreach ofthefour questions.
2https://eda.rg.cispa.io/prj/continent/
 
2230KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
Experiment Nodes Shd Sid F1
Interventions5 0.23 0.15 0.68
10 0.25 0.34 0.54
15 0.29 0.50 0.43
Mechanism
Changes5 0.21 0.15 0.74
10 0.26 0.38 0.64
15 0.36 0.65 0.41
Table 1: Normalized Shd [Lower is better], normalized Sid
[Lower is better] and Orientation F1[Higher is better] for
networks predicted by Continent for held-out episodes for
interventional data as well as mechanism changes.
Q1. Identical Networks. We first test all methods on the cases
where each incoming episode comes from the same underlying
causal network, both for i.i.d. as well as selection bias. Interesting
for us is the latter where episodes can contain selection bias. We
generate this case by choosing a variable at random from our dataset
and sorting the entire data over that variable before splitting the
data into episodes and transmitting it. We show the results for this
in Fig 2 where we see that Continent shows superior performance
to the competition. Continent not only discovers causal network
structurally closer to the ground truth, but also clearly performs
well when orienting the edges as can be seen by the F1score in
Fig. 2. This shows that Continent performs well under selection
bias. We provide the results for i.i.d. data in the appendix.
Q2. Interventions. After our sanity check using i.i.d. data and
dominant performance over data with selection bias, we level up
the difficulty by introducing episodes that contain interventions.
To do so, we generate 3datasets. The first dataset is observational,
whereas for the other two, we select a subset of at most log2(ğ‘‘)
variables and perform a ğ‘‘ğ‘œ-intervention [ 30] on that subset, before
generating the data. This gives us data sampled from three different
distributions. We further split each of these datasets into episodes
before transmitting them. We never provide information about
these interventions to any of the methods beforehand.
We show the results of this experiment in Fig. 3, where we see
that while Globe degrades slightly, Continentâ€™s performance
does not degrade compared to the setup in ğ‘„1.Continent , in fact,
continues to clearly outperform the competition.
Q3. Changing Mechanisms. As the next challenging step, we in-
troduce episodes containing different causal networks/mechanisms
over the same variables. This rules out using any of our competitors
as they can not handle such data. To evaluate Continent in this
setting, we additionally generate a hold-out set of episodes that we
do not learn over. Once Continent has learned over the training
episodes, we try to predict the causal network for hold-out episodes,
without learning it explicitly, using the existing learned models.
We do so by simply taking the model that compresses this hold-out
episode best (Eq. (1)) and comparing the predicted network to the
ground truth. We show the results in Table. 1 where we observe
thatContinent continues to perform well overall for ğ‘‘=5,10,
and at least structurally for ğ‘‘=15. We see that for this challenging00.20.40.60.8100.20.40.60.81
Ã—Ã—Ã—Ã—
Ã—Ã—
ShdSidContinent
Globe
Ges
Resit
Lingam
Jci-P
c
00.20.40.60.81F1Continent Globe
Ges Resit
Lingam Jci-P
c
Figur e6:Normalize dShd andSid[Left, Closer toorigin is
better ]andOrientation F1[Right, Higher isbetter ]fornet-
works learne dReged Lung cancer gene expression dataset.
setting with changing mechanisms, Continent canfindareason-
able skeleton (lowerShd)butconflicting mechanisms cause itto
getedgedirections wrongmoreoften (higher Sid).Nevertheless,
weseethatContinentâ€™s performance doesnotdegrade massiv ely
compar edtoprevious settings, eveninthischallenging case.
Q4.Performance overtime.Wemeasur ehowtheindividual mod-
elspresent inside Continent evolveovertime.Tothat end, we
showhowtheShd (Fig. 4)aswellasthemodelcount (Fig. 5)pro-
gresses aswereceivenewepiso des.Forthecase ofShd,wefindthat
Continent always ends upwith alowerShd atthefinal episo de,
than theoneitstarts with, thiseffectismoreprofound fornetw orks
ofsizeğ‘‘=15thanğ‘‘=5asitmight behardertoidentify thecorrect
netw orkoveralarger numb erofvariables inthebeginning. We
seethatContinent isable toimpr oveasthenumb erofepiso des
increase.Fordata with selection bias, weseethatContinent keeps
onaverage 2models throughout thelearning asshowninFig.5.
Moreinter estingly Continent ends upconv erging toalmost 3
modelsforinter ventional data asshowninFig.5,which isexactly
theactual numb erofdiffer entnetw orks present acrossepiso des.
6.2 Lung cancer gene expression data
After measuring theefficacy ofourapproach using synthetic data,
weturn to(pseudo) real-w orldReged dataset [41]containing 20,000
samples over500variables forlung cancer gene-e xpressions. We
split thesamples into tennon-o verlapping episo desandconsider
twonon-o verlapping netw orks ofsizesğ‘‘=5,15within theground
truth networkandrunatotal of10experiments asfollows.First, we
randomly chooseasubset of5episo des,merge them andintroduce
selection bias overthestacke ddata akin toğ‘„2,beforesplitting
itback. Weshowtheresults forReged 5intheappendix andfor
Reged 15inFig.6wher eonce again Continent comes outontop.
7DISCUSSION AND CONCLUSION
Ourinter estinthisworkisdetermining causality when data arriv es
progressiv elyovertime inmultiple episo des,each representing sub-
samples ofthepopulation orsubregions ofthedata that needto
bepooledtogether toavoidbias. Atthesame time,weaddressthat
thecausal relationships may notbestationar yovertime,andtreat
episo desfromdiffer entconte xtsunder aseparate causal model.
Toaddressthissetting, weproposeacausal modeloverasetof
latent conte xtsleading toasetofdiffer entcausal netw orks, aswell
 
2231Learning Causal Networks from Episodic Data KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
as model episodic bias through a hidden selection variable. We
show that information-theoretic scoring criteria remain consistent
for this model in the limit if we obtain sufficiently many episodes
so that selection bias becomes ignorable. To address the more re-
alistic setting where episodes arrive one by one over time with
non-ignorable selection bias, we propose the Continent algorithm
to learn the causal model adaptively over time. It maintains a set of
causal networks over all episodes and incorporates new episodes
into the model, using a residual testing strategy to avoid combining
episodes from different contexts.
Our experimental results show that our method performs reliably
in the presence of selection bias, under unknown interventions, and
even when different causal models underlie the data-generating
process, which to our knowledge no existing methods can address.
Future directions of our work include addressing non-ignorability
further by using correction or extrapolation techniques, and ad-
dressing practical considerations such as the instantiation choices.
REFERENCES
[1]KOLMOGOROV AN. 1933. Sulla determinazione empirica di una legge didis-
tribuzione. Giorn Dellâ€™inst Ital Degli Att 4 (1933), 89â€“91.
[2]Elias Bareinboim and Judea Pearl. 2012. Controlling Selection Bias in Causal
Inference. In AISTATS, Vol. 22. PMLR, 100â€“108.
[3]Elias Bareinboim, Jin Tian, and Judea Pearl. 2014. Recovering from Selection Bias
in Causal and Statistical Inference. AAAI 28, 1 (2014).
[4]P Boeken, Noud de Kroon, Mathijs de Jong, Joris M. Mooij, and Onno Zoeter.
2023. Correcting for selection bias and missing response in regression using
privileged information. In UAI. PMLR, 195â€“205.
[5]Peter BÃ¼hlmann, Jonas Peters, Jan Ernest, et al .2014. CAM: Causal additive
models, high-dimensional order search and penalized regression. Annals Stat. 42,
6 (2014), 2526â€“2556.
[6]David Maxwell Chickering. 2002. Optimal structure identification with greedy
search. JMLR 3 (2002), 507â€“554.
[7]Daniel Eaton and Kevin Murphy. 2007. Exact Bayesian structure learning from
uncertain interventions. In AISTATS. PMLR, 107â€“114.
[8]Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borg-
wardt, and Bernhard SchÃ¶lkopf. 2008. Covariate Shift by Kernel Mean Matching.
InDataset Shift in Machine Learning. The MIT Press.
[9] Peter GrÃ¼nwald. 2007. The Minimum Description Length Principle. MIT Press.
[10] Alain Hauser and Peter BÃ¼hlmann. 2013. Jointly interventional and observational
data: Estimation of interventional Markov equivalence classes of directed acyclic
graphs. J. R. Statist. Soc. B 77 (03 2013).
[11] Alain Hauser and Peter BÃ¼hlmann. 2014. Two optimal strategies for active
learning of causal models from interventional data. International Journal of
Approximate Reasoning 55, 4 (jun 2014), 926â€“939.
[12] Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard
SchÃ¶lkopf. 2009. Nonlinear causal discovery with additive noise models. In
NeurIPS, Vol. 21. Curran.
[13] Amin Jaber, Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim.
2020. Causal discovery from soft interventions with unknown targets: Charac-
terization and learning. Advances in neural information processing systems 33
(2020).
[14] D. Janzing and B. SchÃ¶lkopf. 2010. Causal Inference Using the Algorithmic
Markov Condition. IEEE TIT 56, 10 (2010), 5168â€“5194.
[15] Markus Kalisch and Peter BÃ¼hlmann. 2007. Estimating high-dimensional directed
acyclic graphs with the PC-algorithm. JMLR 8, Mar (2007), 613â€“636.
[16] David Kaltenpoth and Jilles Vreeken. 2019. We Are Not Your Real Parents: Telling
Causal from Confounded using MDL. In SDM. SIAM, 199â€“207.
[17] David Kaltenpoth and Jilles Vreeken. 2023. Identifying Selection Bias from
Observational Data. AAAI (2023), 8177â€“8185.[18] M. Li and P. VitÃ¡nyi. 2009. An Introduction to Kolmogorov Complexity and its
Applications. Springer.
[19] Roderick Little and Donald Rubin. 2019. Statistical Analysis with Missing Data,
Third Edition. (04 2019). https://doi.org/10.1002/9781119482260
[20] Sara Magliacane, Thijs van Ommen, Tom Claassen, Stephan Bongers, Philip
Versteeg, and Joris M Mooij. 2018. Domain Adaptation by Using Causal Inference
to Predict Invariant Conditional Distributions. In NIPS, Vol. 31.
[21] Sarah Mameche, David Kaltenpoth, and Jilles Vreeken. 2022. Discovering Invari-
ant and Changing Mechanisms from Data. In KDD. ACM, 1242â€“1252.
[22] Sarah Mameche, David Kaltenpoth, and Jilles Vreeken. 2023. Learning Causal
Mechanisms under Independent Changes. In NeurIPS.
[23] Sarah Mameche, Jilles Vreeken, and David Kaltenpoth. 2024. Identifying Con-
founding from Causal Mechanism Shifts. In International Conference on Artificial
Intelligence and Statistics. PMLR, 4897â€“4905.
[24] Alexander Marx and Jilles Vreeken. 2019. Identifiability of Cause and Effect using
Regularized Regression. In KDD. ACM.
[25] Alexander Marx and Jilles Vreeken. 2021. Formally Justifying MDL-based Infer-
ence of Cause and Effect. arXiv preprint arXiv:2105.01902 (2021).
[26] Osman Mian, Michael Kamp, and Jilles Vreeken. 2023. Information-theoretic
causal discovery and intervention detection over multiple environments. In
AAAI-23.
[27] Osman Mian, Alexander Marx, and Jilles Vreeken. 2021. Discovering fully ori-
ented causal networks. In AAAI.
[28] Joris M Mooij, Sara Magliacane, and Tom Claassen. 2016. Joint causal inference
from multiple contexts. JMLR 21 (2016).
[29] Joris M. Mooij, J. Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard
Scholkopf. 2014. Distinguishing Cause from Effect Using Observational Data:
Methods and Benchmarks. ArXiv abs/1412.3773 (2014).
[30] Judea Pearl. 2009. Causality: Models, Reasoning and Inference (2nd ed.). Cambridge
University Press.
[31] Judea Pearl. 2012. A solution to a class of selection bias problems. (2012).
[32] Jonas Peters and Peter BÃ¼hlmann. 2015. Structural intervention distance for
evaluating causal graphs. Neural computation 27, 3 (2015), 771â€“799.
[33] Jonas Peters, Joris M. Mooij, Dominik Janzing, and Bernhard SchÃ¶lkopf. 2014.
Causal Discovery with Continuous Additive Noise Models. JMLR 15 (2014).
[34] Joseph Ramsey, Madelyn Glymour, Ruben Sanchez-Romero, and Clark Glymour.
2017. A million variables and more: the Fast Greedy Equivalence Search algorithm
for learning high-dimensional graphical causal models, with an application to
functional magnetic resonance images. J. Data Sci. Anal. (2017).
[35] Donald B. Rubin. 1976. Inference and missing data. Biometrika 63, 3 (1976),
581â€“592.
[36] Shohei Shimizu. 2012. Joint estimation of linear non-Gaussian acyclic models.
Neurocomputing 81 (2012).
[37] Shohei Shimizu, Patrik O. Hoyer, Aapo HyvÃ¤rinen, and Antti Kerminen. 2006. A
Linear Non-Gaussian Acyclic Model for Causal Discovery. JMLR 7 (2006).
[38] Nickolay Smirnov. 1948. Table for estimating the goodness of fit of empirical
distributions. The annals of mathematical statistics 19, 2 (1948), 279â€“281.
[39] Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. 2000.
Causation, prediction, and search. MIT Press.
[40] Chandler Squires, Yuhao Wang, and Caroline Uhler. 2020. Permutation-based
causal structure learning with unknown intervention targets. In UAI. PMLR,
1039â€“1048.
[41] Alexander Statnikov, Sisi Ma, Mikael Henaff, Nikita Lytkin, Efstratios Efstathiadis,
Eric R. Peskin, and Constantin F. Aliferis. 2015. Ultra-Scalable and Efficient
Methods for Hybrid Observational and Experimental Local Causal Pathway
Discovery. JMLR 16 (2015), 3219â€“3267.
[42] Allison L. Steiner, Adam J. Davis, Sanford Sillman, Robert C. Owen, Anna M.
Michalak, and Arlene M. Fiore. [n. d.]. Observed suppression of ozone forma-
tion at extremely high temperatures due to chemical and biophysical feedbacks.
Proceedings of the National Academy of Sciences ([n. d.]).
[43] Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert MÃ¼ller. 2007. Covariate
Shift Adaptation by Importance Weighted Cross Validation. J. Mach. Learn. Res.
8 (dec 2007), 985â€“1005.
[44] Kun Zhang, Biwei Huang, Jiji Zhang, Clark Glymour, and Bernhard SchÃ¶lkopf.
2017. Causal discovery from nonstationary/heterogeneous data: Skeleton estima-
tion and orientation determination. In IJCAI.
 
2232KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
A THEORY
We provide the technical details of our results in the following.
For ease of exposition, we separate out the case of a single context with one causal model in Thm. 3.5 and show it first.
Lemma A.1 (Consistency of ğ¿for a single causal model). Assume a causal model in Assumption 3.1 with one context ğ¶,ğ‘…=1, and true causal
DAGğºâˆ—inğ¶. Given data ğ·ğ‘›overğ‘›episodes from ğ¶as in Assumption 3.2, under Assumption 3.4, a consistent scoring criterion ğ¿that decomposes
as in Eq. 2 remains consistent,
limğ‘›â†’âˆğ‘ƒ(Ë†ğºâˆ¼ğºâˆ—)=1.
Proof.
In the underlying causal model in assumption 3.1 with ğ‘…=1, consider data ğ·âˆ—ğ‘›from the true causal DAG ğºâˆ—overğ‘‹âˆª{ğ‘†}whereğ‘†is
observed. By consistency of ğ¿, we know that
lim
|ğ·âˆ—ğ‘›|â†’âˆğ‘ƒ(ğºâˆ—âˆ¼arg min
ğºğ¿(ğ‘‹âˆª{ğ‘†};ğº))=1.
Using thatğ¿is decomposable as in Eq. 2, we can write
min
ğºğ¿(ğ‘‹âˆª{ğ‘†};ğº)=min
ğº(ğ‘‹,ğ‘†)
ğ¿(ğº(ğ‘‹,ğ‘†))+ğ‘€âˆ‘ï¸
ğ‘—=1ğ¿(ğ‘‹ğ‘—|pağ‘—(ğº))+ğ¿(ğ‘†|ğ‘‹)
=min
ğº(ğ‘‹)
ğ¿(ğº(ğ‘‹))+ğ‘€âˆ‘ï¸
ğ‘—=1ğ¿(ğ‘‹ğ‘—|pağ‘—(ğº))
+min
ğº(ğ‘†|ğ‘‹)
ğ¿(ğº(ğ‘†|ğ‘‹))+ğ¿(ğ‘†|ğ‘‹)
= min
ğº(ğ‘‹)ğ¿(ğ‘‹;ğº(ğ‘‹))+ min
ğº(ğ‘†|ğ‘‹)ğ¿(ğ‘†;ğº(ğ‘†|ğ‘‹))).
Above, we separated the graph structure ğºinto two subgraphs: ğº(ğ‘‹)overğ‘‹, andğº(ğ‘†|ğ‘‹)which includes ğ‘†as well as all edges towards it.
We can do so as ğ‘†is a sink node and ğ¿is decomposable. Hence, when ğ‘†is observed, the subgraph ğº(ğ‘‹)can be identified with our objective
by construction. As ğ‘†is unobserved, however, we only access data ğ·ğ‘›overğ‘›episodes inducing a biased distribution Ëœğ‘‹. In that case, assume
we obtain a different minimiser Ëœğº=minğº(Ëœğ‘‹)ğ¿(Ëœğ‘‹;ğº)with Ëœğºâ‰ğºâˆ—andğ¿(Ëœğ‘‹;Ëœğº)<ğ¿(ğ‘‹;ğºâˆ—). Then for at least one ğ‘‹ğ‘—,pağ‘—(Ëœğº)â‰ pağ‘—(ğºâˆ—).
Due to ignorabiliy in Assumption 3.4, Ëœğ‘‹ğ‘—âŠ¥âŠ¥ğ‘†|Zholds for the conditioning sets Z1=Ëœpağ‘—(Ëœğº)andZ2=Ëœpağ‘—(ğºâˆ—), thereforeğ‘†does not affect
the local score for Ëœğ‘‹ğ‘—given either conditioning set. That is, ğ¿(Ëœğ‘‹ğ‘—|Ëœpağ‘—(ğºâˆ—))=ğ¿(ğ‘‹ğ‘—|pağ‘—(ğºâˆ—))<ğ¿(ğ‘‹ğ‘—|pağ‘—(Ëœğº))=ğ¿(Ëœğ‘‹ğ‘—|Ëœpağ‘—(Ëœğº)), which
contradicts that Ëœğºis a minimizer. Therefore, we also have
lim
|ğ·ğ‘›|â†’âˆğ‘ƒ(ğºâˆ—âˆ¼arg min
ğºğ¿(ğ‘‹;ğº))=1.
â–¡
With this, we move to our full causal model with multiple contexts. For ease of access, we restate our objective in Eq. (3),
 Ë†Î (ğ·),Ë†ğº=min
Î (ğ·)|Î (ğ·)|âˆ‘ï¸
ğ‘Ÿ=1min
ğºğ‘Ÿğ¿(ğ‘‹ğ‘Ÿ;ğºğ‘Ÿ).
Theorem A.2 (Consistency of ğ¿for multiple causal models). For the causal model in Assumption 3.1 and given data ğ·ğ‘›overğ‘›episodes as in
Assumption 3.2, under Assumption 3.4, a consistent scoring criterion ğ¿that decomposes as in Eq. 2 remains consistent,
lim
|ğ·ğ‘›|â†’âˆğ‘ƒ(Ë†ğºğ‘Ÿâˆ¼ğºâˆ—
ğ‘Ÿ)=1 for allğ‘Ÿâˆˆ{1,...,ğ‘…}.
Proof. First, assume the number of contexts ğ‘…and the context ğ¶(ğ¸)that each episode ğ¸belongs to is known. That is, for the data ğ·=ğ·ğ‘
over all episodes, we know the true partitioning Î (ğ·)={ğ‘‹1,...,ğ‘‹ğ‘…}into disjoint, non-empty subsets ğ‘‹ğ‘ŸâŠ†ğ·such thatâˆªğ‘Ÿğ‘‹ğ‘Ÿ=ğ·and
eachğ‘‹ğ‘Ÿis generated from a fixed causal model ğºğ‘Ÿin theğ‘Ÿth context. Due to independent data generation from each ğºğ‘Ÿ, we can apply
Lemma A.1 separately in each context and obtain
lim
|ğ·|â†’âˆğ‘ƒ(ğºâˆ—
1,...ğºâˆ—
ğ‘…âˆ¼min
ğº1,...ğºğ‘…ğ‘…âˆ‘ï¸
ğ‘Ÿ=1ğ¿(ğ‘‹ğ‘Ÿ;ğºğ‘Ÿ(ğ‘‹)))=lim
|ğ·|â†’âˆğ‘ƒ(ğºâˆ—
1,...ğºâˆ—
ğ‘…âˆ¼min
ğº1,...ğºğ‘…ğ‘…âˆ‘ï¸
ğ‘Ÿ=1ğ¿(ğ‘‹ğ‘Ÿ,ğ‘†ğ‘Ÿ;ğºğ‘Ÿ(ğ‘‹)))=1.
Left to show is the case where ğ‘…andÎ (ğ·)are unknown. We compare
â€¢the true model Gâˆ—={ğºâˆ—
1,...,ğºâˆ—
ğ‘…âˆ—}and subsets Î âˆ—(ğ·)={ğ‘‹âˆ—1,...,ğ‘‹âˆ—ğ‘…âˆ—}, and
â€¢the estimated model Ë†G={Ë†ğº1,..., Ë†ğºË†ğ‘…}and subsets Ë†Î (ğ·)={Ë†ğ‘‹1,..., Ë†ğ‘‹Ë†ğ‘…}minimizing Eq. 3 with score ğ¿(Ë†G)=ÃË†ğ‘…
ğ‘Ÿ=1ğ¿(Ë†ğ‘‹ğ‘Ÿ;Ë†ğºğ‘Ÿ(Ë†ğ‘‹ğ‘Ÿ)).
For contradiction, assume that there is no exact correspondence between the true and estimated models, more precisely, that for at least one
contextğ‘Ÿwith true model ğ‘‹âˆ—ğ‘Ÿandğºâˆ—ğ‘Ÿthere is no other ğ‘Ÿâ€²so that Ë†ğ‘‹ğ‘Ÿâ€²=ğ‘‹âˆ—ğ‘Ÿand Ë†ğºğ‘Ÿâ€²âˆ¼ğºâˆ—ğ‘Ÿ. We can distinguish the following cases,
 
2233Learning Causal Networks from Episodic Data KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
(1)Caseğ‘‹âˆ—ğ‘Ÿ=Ë†ğ‘‹ğ‘Ÿâ€²for someğ‘Ÿâ€²â‰ ğ‘Ÿ: then also Ë†ğºğ‘Ÿâ€²âˆ¼ğºâˆ—ğ‘Ÿby Lemma A.1 as ğ‘‹âˆ—ğ‘Ÿis a dataset from a single context ğ‘Ÿ, which however
contradicts the above assumption.
(2)Caseğ‘‹âˆ—ğ‘ŸâŠ‚Ë†ğ‘‹ğ‘Ÿâ€²for someğ‘Ÿâ€²â‰ ğ‘Ÿ: Then the set ğ‘‹âˆ—ğ‘Ÿis wrongly included under the incorrect model Ë†ğºğ‘Ÿâ€². Then the decomposition of
Eq. 3 will contain a suboptimal likelihood term
ğ¿(ğ‘‹âˆ—ğ‘Ÿ|Ë†ğºğ‘Ÿâ€²)=ğ‘€âˆ‘ï¸
ğ‘—=1ğ¿(ğ‘‹âˆ—ğ‘Ÿ
ğ‘—|pağ‘Ÿ
ğ‘—(Ë†ğºğ‘Ÿâ€²)).
Using thatğ¿is decomposable, we can replace the above term in the decomposition of ğ¿as follows (keeping all other terms the same),
(a) ifğºâˆ—ğ‘ŸâˆˆË†G, we can replace ğ¿(ğ‘‹âˆ—ğ‘Ÿ|Ë†ğºğ‘Ÿâ€²)withğ¿(ğ‘‹âˆ—ğ‘Ÿ|ğºâˆ—ğ‘Ÿ).
(b)ifğºâˆ—ğ‘Ÿâˆ‰Ë†G, we can replace ğ¿(ğ‘‹âˆ—ğ‘Ÿ|Ë†ğºğ‘Ÿâ€²)with the full cost ğ¿(ğ‘‹âˆ—ğ‘Ÿ;ğºâˆ—ğ‘Ÿ)as the likelihood component dominates over ğ¿(ğºâˆ—ğ‘Ÿ)in the limit
of samples, as shown in Mian et al. [27].
In both cases, we can replace Ë†GbyË†Gâˆª{ğºâˆ—ğ‘Ÿ}and Ë†Î (ğ·)by{Ë†ğ‘‹1,..,ğ‘‹âˆ—ğ‘Ÿ,Ë†ğ‘‹ğ‘Ÿâ€²,..,Ë†ğ‘‹Ë†ğ‘…}where we separate ğ‘‹âˆ—ğ‘Ÿand Ë†ğ‘‹ğ‘Ÿâ€²and keep all other
parts the same, resulting in a favorable model, contradicting that it is the minimizer of Eq. 3.
(3)Caseğ‘‹âŠ‚Ë†ğ‘‹ğ‘Ÿâ€²for someğ‘Ÿâ€²â‰ ğ‘Ÿand for a set ğ‘‹âŠ‚ğ‘‹âˆ—ğ‘Ÿ,ğ‘‹â‰ âˆ…: This means that a non-empty subset of ğ‘‹âˆ—ğ‘Ÿis included under the incorrect
DAG, in which case we can apply the same argument as in case (2).
We can disregard the case ğ‘‹âˆ—ğ‘Ÿâˆ©Ë†ğ‘‹ğ‘Ÿâ€²=âˆ…for allğ‘Ÿâ€²as thenğ‘‹âˆ—ğ‘Ÿis not covered by the partition.
Thus, Ë†ğ‘…=ğ‘…âˆ—and each Ë†ğ‘‹ğ‘Ÿ=ğ‘‹âˆ—ğ‘Ÿandğºğ‘Ÿâˆ¼Ë†ğºğ‘Ÿ(up to permuting the indices). â–¡
Next, we justify our updating and merging strategy in the presence of selection bias.
Theorem A.3 (Consistency of model updating using T).Given a set of causal DAGs Ë†G={Ë†ğº1,..., Ë†ğºË†ğ‘…}and subsets Ë†Î (ğ·)={Ë†ğ‘‹1,..., Ë†ğ‘‹Ë†ğ‘…}
over episodesâˆªğ‘ŸË†ğ‘‹ğ‘Ÿ={ğ¸1,...,ğ¸ğ‘–}. With discrepancy test Twe will never merge a new episode ğ¸ğ‘–+1with a set Ë†ğ‘‹ğ‘Ÿfrom an incorrect context.
Proof. We need to show that with a merge protected by T, a merge of ğ¸ğ‘–+1with any set Ë†ğ‘‹ğ‘Ÿcan only occur if ğ¶(ğ¸ğ‘–â€²)=ğ¶(ğ¸ğ‘–+1)for all
ğ‘–â€²â‰¤ğ‘–. For induction on the time step ğ‘–, consider the following cases,
(1)For the base case is ğ‘–=2, assumeğ¶(ğ¸1)â‰ ğ¶(ğ¸2). We need to show that Tnever merges ğ¸1,ğ¸2fromğ¶1,ğ¶2From our causal model,
we know there is at least one variable in ğºâˆ—
1,ğºâˆ—
2s.t.
ğ‘ƒ(ğ‘‹1
ğ‘—|pa1
ğ‘—)â‰ ğ‘ƒ(ğ‘‹2
ğ‘—|pa2
ğ‘—)
From Cor. 4.5 in MSS, this implies that also for any conditioning set Z,
ğ‘ƒ(ğ‘‹1
ğ‘—|Z1)â‰ ğ‘ƒ(ğ‘‹2
ğ‘—|Z2)
that is, we have a distribution shift even when Adiscovers an incorrect DAG Ë†ğº1. Left to show is that it holds also for the biased
distributions
ğ‘ƒ(ğ‘‹1
ğ‘—|Z1,ğ‘†=ğ‘ ğ‘˜)â‰ ğ‘ƒ(ğ‘‹2
ğ‘—|Z2,ğ‘†=ğ‘ ğ‘˜â€²)
which holds under detectable selection. Hence, our test ğ‘‡will detect the difference for ğ‘‹ğ‘—given enough data from ğ¸1,ğ¸2and reject
merging.
(2)For the induction step, we can assume that ğ¶(ğ¸ğ‘–â€²)=ğ¶(ğ¸ğ‘–â€²â€²)for allğ‘–â€²,ğ‘–â€²â€², and apply the above pairwise argument to ğ¸ğ‘–+1and eachğ¸ğ‘–â€².
Corollary A.4 (Consistency of model merging). Given a consistent DAG search algorithm Aand scoreğ¿,Continent is consistent under
Assumption 3.4, so that
lim
|ğ·ğ‘›|â†’âˆğ‘ƒ(Ë†ğºğ‘Ÿâˆ¼ğºğ‘Ÿâˆ—)=1 for allğ‘Ÿâˆˆ{1,...,ğ‘…}.
Proof. Consider the estimated model Ë†G={Ë†ğº1,..., Ë†ğºË†ğ‘…}and subsets Ë†Î (ğ·)={Ë†ğ‘‹1,..., Ë†ğ‘‹Ë†ğ‘…}that we obtain with Continent at time step ğ‘›.
By the previous theorem, we know that episodes from different contexts were not merged incorrectly, Ë†ğ‘‹ğ‘ŸâŠ†ğ‘‹âˆ—ğ‘Ÿâ€²for someğ‘Ÿâ€²for eachğ‘Ÿ
where Ë†ğ‘…â‰¤ğ‘…, which we write shorthand as Ë†Î (ğ·)âŠ†Î âˆ—(ğ·). In case Ë†ğ‘…<ğ‘…, we need to consider any remaining merges among sets in Ë†ğ‘‹ğ‘Ÿ. If
the assumptions of Thm. 3.5 hold, then we can use
min
Î (ğ·),Ë†Î (ğ·)âŠ†Î (ğ·)|Î (ğ·)|âˆ‘ï¸
ğ‘Ÿ=1min
ğºğ‘Ÿğ¿(ğ‘‹ğ‘Ÿ;ğºğ‘Ÿ).
The above will be minimized for Î âˆ—(ğ·)and Ë†ğºğ‘Ÿâˆ¼ğºğ‘Ÿâˆ—for eachğ‘Ÿas it considers a subset of the partitions that Thm. 3.5 considers. Hence
minimizing ğ¿is a consistent way to discover the remaining merges. â–¡
 
2234KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
B ALGORITHM
In this section, we include the pseudocode of the components of Continent .
Algorithm 3: Update(G,ğ¸,A,T)
input : episodeğ¸,
causal model G,
causal discovery algorithm Awith scoreğ¿,
residual testT
output: updated causal model G
1acceptedâ†False
2foreachğºğ‘Ÿover datağ·inGdo
3 ifTestResidualEq(ğºğ‘Ÿ,ğ¸,ğ·,T)then
4 acceptedâ†True
5ğ·â†ğ·.stackData(ğ¸)
6 end
7end
8ifnotaccepted then
9ğºâ†A .Learn(ğ¸)
10 G=Gâˆª{ğº}
11end
12return G
Algorithm 4: Merge(G,A,T)
input : causal model G,
causal discovery algorithm Awith scoreğ¿,
residual testT
output: updated causal model G
1repeat
2 foreachğºover datağ·inGdo
3ğ·â˜…â†ğ·
4ğºâ˜…â†ğº
5ğ¿â˜…â†ğº.Score(ğ·)
6 foreachğºâ€²over datağ·â€²inGnot seen yet do
7 ifnotTestResidualEq(ğºâ€²,ğ·,ğ·â€²,T)continue;
8 ğ·âˆª=ğ·âˆªğ·â€²
9 ğºâˆªâ†A .Learn(ğ·âˆª)
10 ğ¿âˆªâ†ğºâˆª.Score(ğ·âˆª)
11 ifTestScoreDiff (ğ¿âˆª,ğ¿â˜…)then
12 ğ·â˜…â†ğ·âˆª
13 ğ¿â˜…â†ğ¿âˆª
14 ğºâ˜…â†ğºâˆª
15 end
16 end
17 ifğºâ˜…is notğºthen
18 replace corresponding ğº,ğºâ€²withğºâˆªinG
19 end
20 end
21until convergence ;
22return G
 
2235