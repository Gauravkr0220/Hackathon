Distributed Thresholded Counting with Limited Interaction
Xiaoyi Zhu
22110980022@m.fudan.edu.cn
Fudan University
School of Data Science
Shanghai, ChinaYuxiang Tian
tianyx22@m.fudan.edu.cn
Fudan University
School of Data Science
Shanghai, ChinaZengfeng Huangâˆ—
huangzf@fudan.edu.cn
Fudan University
School of Data Science
Shanghai, China
Abstract
Problems in the area of distributed computing have been extensively
studied. In this paper, we focus on the Distributed Thresholded
Counting problem in the coordinator model. In this problem, we
haveğ‘˜sites holding their input and communicating with a central
coordinator. The coordinatorâ€™s task is to determine whether the
sum of inputs is larger than a threshold.
While the communication complexity of this basic problem has
been studied for decades, it is still not well understood. Our work
considers the worst-case communication cost for an algorithm
that uses limited interaction â€” i.e. a bounded number of rounds
of communication. Algorithms in previous research usually need
ğ‘‚(log logğ‘)orğ‘‚(ğ‘˜)rounds. In comparison, in the deterministic
case, our algorithm achieves optimal communication complexity in
onlyğ›¼(ğ‘˜)rounds, where ğ›¼(ğ‘˜)denotes the inverse Ackermann func-
tion and is nearly constant. We also give a randomized algorithm
that balances communication, rounds, and error probability.
CCS Concepts
â€¢Theory of computation â†’Distributed algorithms.
Keywords
communication complexity; distributed counting; algorithm
ACM Reference Format:
Xiaoyi Zhu, Yuxiang Tian, and Zengfeng Huang. 2024. Distributed Thresh-
olded Counting with Limited Interaction. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD â€™24),
August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages.
https://doi.org/10.1145/3637528.3671868
1 Introduction
In many practical applications, massive data is collected and stored
on a large number of nodes possibly deployed at different locations,
while we want to learn properties of the union of the data. For
example, user data generated by edge devices [ 8], measurements
collected from large-scale sensor networks [ 19], application data
from location based services [ 22]. In such distributed systems and
âˆ—Corresponding Author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671868applications, communication costs is often the major concern, since
communication is much slower than local computation. Another
reason is that communication is the biggest source of battery drain
on smartphones and sensors [ 16], and it is always desirable to save
energy on such devices.
In this paper, we consider distributed thresholded counting. In
this problem, each distributed node holds a private value ğ‘›ğ‘–, and
the goal is to determine whether the sum of the values surpasses a
given threshold ğ‘. This is a ubiquitous query and a basic task for
many applications including network traffic monitoring, anomaly,
and attack detection [ 17]. For example, in a network monitoring
system, we want to know whether a destination receives more than
20GB of traffic in an hour. We aim to understand the communication
complexity of this problem in a multi-party distributed model.
To formalize the theoretical study, we consider the number-in-
hand coordinator model introduced in [ 12]. In this model, there are
ğ‘˜sites each holding his private input ğ‘›ğ‘–, and an additional site called
coordinator that receives no input. Sites can only communicate with
the coordinator. The task of the coordinator is to collaborate with
all the sites to correctly output the value of a joint function of
their inputs. Our goal is to minimize the worst-case communication
costs, i.e., the total number of bits exchanged, and the number of
communication rounds. This model has received increased attention
and become a standard model for studying the communication
complexity of distributed computing [4â€“6, 24].
In the thresholded counting problem, the coordinator needs to
determine whether the sum of the inputsÃğ‘˜
ğ‘–=1ğ‘›ğ‘–is larger than a
given threshold ğ‘. Perhaps surprisingly, the communication com-
plexity of this basic problem, although has been studied in the
computational complexity community for decades [ 20], is still not
well understood. Due to motivations from circuit complexity, the
complexity community mainly focuses on the case where ğ‘is expo-
nentially larger than ğ‘˜. However, there is still a large gap between
the best upper and lower bounds [ 23] for this case, and closing
this gap was posed as an extremely challenging open problem.
Specifically, assuming ğ‘˜=(logğ‘)ğ‘œ(1), [23] provides a random-
ized algorithm with ğ‘‚(ğ‘˜logğ‘˜log logğ‘)bits of communication
andğ‘‚(log logğ‘)rounds, while the current best randomized lower
bound on communication is Î©(max{ğ‘˜,log logğ‘})[13, 18, 23].
In this paper, we focus on the regime where ğ‘=ğ‘˜ğ‘‚(1), which
is arguably more practical. In this regime, the naive one-round
algorithm in which all sites send their inputs incurs ğ‘‚(ğ‘˜logğ‘)bits
of communication. There is another straightforward determinis-
tic algorithm (see Section 4) that uses ğ‘‚
ğ‘˜log
ğ‘
ğ‘˜
bits, which
matches the deterministic lower bound proved in [ 10] and is better
whenğ‘=ğ‘‚(ğ‘˜). However, it requires ğ‘˜rounds in the worst case.
4664
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Xiaoyi Zhu, Yuxiang Tian, & Zengfeng Huang.
The main question we try to answer in this paper is whether there
is an algorithm with optimal communication cost and ğ‘‚(1)rounds.
We make significant progress on this question. First, we provide
three deterministic algorithms with ğ‘‚
ğ‘˜log
ğ‘
ğ‘˜
bits of commu-
nication cost, and their round complexity is ğ‘‚(logğ‘˜),logâˆ—(ğ‘˜)and
ğ‘‚(ğ›¼(ğ‘˜))respectively. Here ğ›¼(ğ‘˜)is the inverse Ackermann function,
which grows extremely slowly and practically ğ‘‚(1). Moreover, we
present a randomized algorithm with error probability at most 2âˆ’âˆš
ğ‘˜.
It has the same communication cost and uses at most 3 rounds.
1.1 Problem Definition and Our Results
In this paper, we study the Distributed Thresholded Counting (DTC)
problem and consider both exact and approximate versions, which
are defined next.
Definition 1.1 (Exact DTC). Each siteğ‘›ğ‘–holds a private integer
ğ‘›ğ‘–âˆˆ[0,ğ‘), the job of the coordinator is to output YES ifÃğ‘˜
ğ‘–=1ğ‘›ğ‘–>
ğ‘and output NO ifÃğ‘˜
ğ‘–=1ğ‘›ğ‘–â‰¤ğ‘.
Definition 1.2 (Approximate DTC). Each siteğ‘›ğ‘–holds a private
integerğ‘›ğ‘–âˆˆ[0,ğ‘), the job of the coordinator is to output YES ifÃğ‘˜
ğ‘–=1ğ‘›ğ‘–>ğ‘and output NO ifÃğ‘˜
ğ‘–=1ğ‘›ğ‘–â‰¤(1âˆ’ğœ€)ğ‘. The coordinator
can output anything if (1âˆ’ğœ€)ğ‘<Ãğ‘˜
ğ‘–=1ğ‘›ğ‘–â‰¤ğ‘.
Here we assume ğ‘,ğœ€,ğ‘˜ are public information.
Reduction of the problems. As will be discussed in Section 3,
both problems of interest can be reduced to a special case of exact
DTC, in which ğ‘=ğ‘‚(ğ‘˜). Moreover, this special case is of great
interest in its own right, since the gap of communication costs
between the naive algorithm and the best algorithm is the largest.
Thus, we mainly focus on analyzing algorithms for ğ‘=ğ‘‚(ğ‘˜)and
provide a discussion on how to extend to general ğ‘and approxi-
mate algorithm in Section 3.
Deterministic algorithms. We develop three deterministic algo-
rithms with progressively intricate designs. Our final algorithm
achieves the following result that has the strongest guarantees on
both communication cost and rounds. ğ›¼(ğ‘˜)is the inverse Acker-
mann function defined in Section 2, which is a small constant in
practice.
Theorem 1.3 (Deterministic algorithm). The exact DTC with
ğ‘=ğ‘‚(ğ‘˜)can be solved deterministically with ğ‘‚(ğ‘˜)communication
andğ‘‚(ğ›¼(ğ‘˜))rounds.
Randomized Algorithm. With the power of randomization, we
propose an algorithm making use of a sampling approach that
balances communication, rounds, and error probability.
Theorem 1.4 (Randomized Algorithm). The exact DTC with
ğ‘=ğ‘‚(ğ‘˜)can be solved in ğ‘Ÿrounds with randomized communication
costğ‘‚
ğ¸ğ‘˜1
ğ‘Ÿâˆ’1+ğ‘˜ğ‘Ÿ
and failure probability at most ğ›¿=2âˆ’ğ¸.
1.2 Related Work
Distributed Sum-Equal. In the Sum-Equal problem, the coordina-
tor needs to decide whether the sum of the inputs equals a specific
value. Several works [ 2,20,23] have considered this problem and
current best upper bound is ğ‘‚(ğ‘˜log(ğ‘˜/ğ›¿))[23]. It is worth not-
ing that adapting their method to the DTC problem usually needs
ğ‘‚(logğ‘)for performing dichotomy on log(ğ‘)length bits.Distributed Tracking. A setting similar to the DTC problem is
distributed tracking [ 9,10,15], where the input of each site is given
gradually over time instead of directly. [ 10] provides a tight de-
terministic algorithm with communication cost of Î˜(ğ‘˜log(ğ‘/ğ‘˜))
bits. Under the assumption that the data follows a certain distri-
bution, [ 25] improves the results to ğ‘‚(ğ‘˜log logğ‘)words. While
distributed tracking enjoys many similarities with our problems,
directly translating their algorithms to our setting will incur an
unacceptable round complexity of ğ‘˜.
Rounds and Communication Tradeoff. Plenty of works study
the tradeoff between communication rounds and the communica-
tion cost. Under the blackboard model, [ 3,5] study the tradeoff
between the number of interaction rounds and the bits needed to
solve the problem of set disjointness and maximal independent set
respectively. For the problems of set intersection and equality test-
ing, [ 7,21] studies tradeoff between rounds, communication cost,
and [ 14] further studies tradeoff among two mentioned parameters
and probability of error.
2 Preliminary
For brevity, we use the notation log(ğ‘¥)=log2(ğ‘¥)andexp(ğ‘¥)=2ğ‘¥
throughout the paper. Let logâˆ—(ğ‘¥)denote the iterated logarithm of
ğ‘¥, which is defined as the number of times the logarithm function
must be applied before the result is less than or equal to 1. That is
logâˆ—(ğ‘¥)=min{ğ‘§|ğ‘§times
z      }|      {
log(Â·Â·Â·log(ğ‘¥))â‰¤ 1}.
The iterated logarithm is useful with its application in algorithms
and computational complexity [ 1,11] and grows at a slow rate.
Moreover, based on this definition, We can define logâˆ—âˆ—(Â·)in a sim-
ilar way that it denotes the number of times the iterated logarithm
function must be applied before the result is less than or equal to 1:
logâˆ—âˆ—(ğ‘¥)=min{ğ‘§|ğ‘§times
z         }|         {
logâˆ—(Â·Â·Â·logâˆ—(ğ‘¥))â‰¤1}.
It is clear that logâˆ—âˆ—(Â·)grows even more slowly than logâˆ—(Â·). Gen-
eralizing the definitions to higher degrees, we have the form of
logğ‘£timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘¥)=min{ğ‘§|logğ‘£âˆ’1timesz}|{
âˆ—Â·Â·Â·âˆ—(Â·Â·Â·logğ‘£âˆ’1timesz}|{
âˆ—Â·Â·Â·âˆ—
|                         {z                         }
ğ‘§times(ğ‘¥))â‰¤1},
where we let log0timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘¥)=log(ğ‘¥). The growth rate of the func-
tion declines for higher degrees and we are finally ready to define
the inverse Ackermann function as
ğ›¼(ğ‘¥)=min{ğ‘§|logğ‘§timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘¥)â‰¤3}.
The inverse Ackermann function grows at an extremely slow rate
that for example, ğ›¼
22265536
=2. Based on these definitions, for
any integer ğ‘£,ğ‘¤â‰¥0, we useğ‘“(ğ‘£,ğ‘¤)to denote the function that
ğ‘“(ğ‘£,ğ‘¤)=logğ‘£timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘“(ğ‘£,ğ‘¤+1)),
4665Distributed Thresholded Counting with Limited Interaction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
whereğ‘“(ğ‘£,0)=1for non-negative integer ğ‘£. This function de-
notes how the inverse of the iterated functions grows. For exam-
ple, when we take ğ‘£=0, byğ‘“(0,ğ‘¤)=log(ğ‘“(0,ğ‘¤+1)),ğ‘“(0,ğ‘¤)
shows the growth of the inverse of iterated logarithm. To be more
clearly, we have that logâˆ—(1)=0,ğ‘“(0,0)=1; logâˆ—(2)=1,ğ‘“(0,1)=
2;logâˆ—(4)=2,ğ‘“(0,2)=4;logâˆ—(16)=3,ğ‘“(0,3)=16;generally we
have thatğ‘“(0,logâˆ—(ğ‘˜))=ğ‘˜.
3 Reduction of the problems
In this section, we will reduce the problems defined in Definition 1.1
and 1.2 to the exact DTC with ğ‘=ğ‘‚(ğ‘˜). Firstly, for the problem
with general ğ‘, we have
Lemma 3.1 (Reduction of Exact DTC). An algorithm for the
Exact DTC with threshold Ëœğ‘=ğ‘‚(ğ‘˜)that communicates ğ¶ğ¶bits inğ‘Ÿ
rounds implies an algorithm for the Exact DTC with general ğ‘that
communicates ğ¶ğ¶+ğ‘‚
ğ‘˜log
ğ‘
ğ‘˜
bits in(ğ‘Ÿ+1)rounds.
Proof. The proof of Lemma 3.1 can be found in Section A. The
idea is to interpret the counter of each site ğ‘›ğ‘–asğ‘›ğ‘–=ğ‘ğ‘–Â·ğ‘
ğ‘˜+ğ‘ğ‘–.
Sinceğ‘ğ‘–can be encoded within ğ‘‚
log
ğ‘
ğ‘˜
bits, we only need to
consider whetherÃ
ğ‘–ğ‘ğ‘–is larger than ğ‘‚(ğ‘˜). â–¡
[10] has shown that the deterministic lower bound of this prob-
lem is Î©
ğ‘˜log
ğ‘
ğ‘˜
. Therefore, this term is tight and we only need
to consider the communication used for solving the problem when
ğ‘=ğ‘‚(ğ‘˜). For the relaxed version of the problem, we have
Lemma 3.2 (Reduction of Approximate DTC). An algorithm
for the Exact DTC with threshold Ëœğ‘=ğ‘‚(ğ‘˜)that communicates ğ¶ğ¶
bits inğ‘Ÿrounds implies an algorithm for the Approximate DTC with
ğ‘that communicates ğ¶ğ¶+ğ‘‚
ğ‘˜log
1
ğœ€
bits in(ğ‘Ÿ+1)rounds.
Proof. The proof of Lemma 3.2 can be found in Section A. The
idea is to interpret the counter of each site ğ‘›ğ‘–as
ğ‘›ğ‘–=ğ‘0
ğ‘–Â·ğ‘
ğ‘˜+ğ‘1
ğ‘–Â·ğ‘
2ğ‘˜+Â·Â·Â·+ğ‘ğ‘™
ğ‘–ğ‘
2ğ‘™ğ‘˜+ğ‘ğ‘–.
Choosingğ‘™=ğ‘‚
1
ğœ€
, we must haveÃ
ğ‘–ğ‘ğ‘–<ğœ€ğ‘and will not affect
the value of the problem. Moreover, we can use ğ‘‚
log
1
ğœ€
bits
to encodeğ‘1
ğ‘–,Â·Â·Â·,ğ‘ğ‘™
ğ‘–. We only need to whetherÃ
ğ‘–ğ‘ğ‘–is larger than
ğ‘‚(ğ‘˜). â–¡
The deterministic communication lower bound of the relaxed
problem is Î©
ğ‘˜log
1
ğœ€ğ‘˜
. Our reduction is almost optimal and
matches the state-of-the-art algorithm that uses ğ‘‚
ğ‘˜log
1
ğœ€
bits
[10]. It is worth noting that their algorithm needs ğ‘‚(ğ‘˜)rounds.
4 Deterministic Algorithms
One naive solution is that all site directly send their value to the
coordinator, which is a one-round algorithm. However, since the
value of each site can be as large as ğ‘‚(ğ‘˜), this leads to a total com-
munication complexity of ğ‘‚(ğ‘˜logğ‘˜)bits rather than the optimal
ğ‘‚(ğ‘˜). Another simple algorithm is that the coordinator asks for
the value of one site in each round, and stops immediately if the
current total sum becomes larger than the threshold. Let ğ‘›1,Â·Â·Â·,ğ‘›ğ‘ Algorithm 1: Siteğ‘–: One-Layer Deterministic DTC
Input: Counterğ‘›ğ‘–, Number of Rounds ğ‘Ÿ
Initialize: SetËœğ‘›ğ‘–,0=ğ‘›ğ‘–,{ğ‘¡ğ‘—}ğ‘Ÿ
ğ‘—=1,ğ‘™=1
1When siteğ‘–receives the signal of the new round :
2 ifËœğ‘›ğ‘–,ğ‘™âˆ’1>ğ‘¡ğ‘™then
3 Send to the server a signal that 1Ëœğ‘›ğ‘–,ğ‘™âˆ’1>ğ‘¡ğ‘™=1.
4 Ëœğ‘›ğ‘–,ğ‘™â†Ëœğ‘›ğ‘–,ğ‘™âˆ’1âˆ’ğ‘¡ğ‘™.
5 else
6 Send to the server a signal that 1Ëœğ‘›ğ‘–,ğ‘™âˆ’1>ğ‘¡ğ‘™=0
7 Send to the server the value of Ëœğ‘›ğ‘–,ğ‘™âˆ’1.
8ğ‘™â†ğ‘™+1.
be the values sent during the algorithm. We haveÃğ‘ 
ğ‘–=1ğ‘›ğ‘–â‰¤2ğ‘˜, and
thus the communication costÃğ‘ 
ğ‘–=1logğ‘›ğ‘–â‰¤ğ‘‚(ğ‘˜)by concavity of
thelogfunction. However, the number of rounds can be ğ‘˜in the
worst case due to the sequential nature of the algorithm.
Thus, one intriguing question is: Is there a deterministic algorithm,
which achieves both ğ‘‚(ğ‘˜)communication cost and ğ‘‚(1)rounds?
This section investigates the above question comprehensively.
We provide three algorithms that use ğ‘‚(ğ‘˜)bits withğ‘‚(logğ‘˜),
ğ‘‚(logâˆ—(ğ‘˜))andğ‘‚(ğ›¼(ğ‘˜))rounds, respectively. These algorithms are
built successively, incorporating several new ideas along the way.
Furthermore, the first ğ‘‚(log(ğ‘˜))algorithm can be seen as a warm-
up to other algorithms and provides some intuition. Building upon
this, we propose our second ğ‘‚(logâˆ—(ğ‘˜))algorithm. This algorithm
is not only straightforward to implement but also achieves near-
optimal performance in many practical scenarios. For cases where
ğ‘˜is extremely large and interaction is limited, our third algorithm
becomes particularly useful. Although it may be more challenging
to implement compared to the previous two algorithms, it offers
high theoretical interest with a round complexity of only ğ‘‚(ğ›¼(ğ‘˜)).
We remark that the last algorithm with ğ›¼(ğ‘˜)rounds is practically
anğ‘‚(1)-round algorithm as the inverse Ackermann function grows
extremely slowly. However, whether it can be further reduced to
truly constant remains a major open question.
Overall, our three algorithms provide a smooth tradeoff between
implementation difficulty and efficiency in terms of round complex-
ity. The third algorithm can be employed if the scenario allows only
limited interaction. In many other practical settings, the ease of im-
plementation and good performance make the first two algorithms
viable choices.
4.1 Anğ‘‚(logğ‘˜)Rounds Algorithm
We start by introducing the algorithm that uses ğ‘‚(ğ‘˜)communi-
cation andğ‘‚(logğ‘˜)rounds. Actually, the algorithm can achieve a
smooth tradeoff between communication and round complexities.
Overview. The algorithm receives an integer ğ‘Ÿas input and pro-
ceeds inğ‘Ÿrounds. In the ğ‘™-th round, there is a predefined threshold
â„ğ‘™and each site ğ‘–notifies the coordinator whether ğ‘›ğ‘–>â„ğ‘™or not.
If not, the site ğ‘–sendsğ‘›ğ‘–âˆ’â„ğ‘™âˆ’1and will not participate in the
algorithm since then. In the first round, all sites are active. The
algorithm stops if all sites become inactive or the current sum main-
tained at the coordinator exceeds ğ‘. Clearly, the key is how to set
the grid of thresholds, and it turns out that the equidistant grid is
4666KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Xiaoyi Zhu, Yuxiang Tian, & Zengfeng Huang.
Algorithm 2: Coordinator: One-Layer Deterministic DTC
Input: Thresholdğ‘, Number of Rounds ğ‘Ÿ
Initialize: Setğ‘š0=0,ğ‘Ÿğ‘–,0=1for eachğ‘–âˆˆ[ğ‘˜],{ğ‘¡ğ‘—}ğ‘Ÿ
ğ‘—=1
1ForRoundğ‘™from 1toğ‘Ÿ:
2 ForSiteğ‘–from 1toğ‘˜:
3 ifğ‘Ÿğ‘–,ğ‘™âˆ’1=1then
4 Send to site ğ‘–a signal of the new round.
5ğ‘Ÿğ‘–,ğ‘™â†0.
6ğ‘šğ‘™â†ğ‘šğ‘™âˆ’1.
7 When coordinator receives a signal from some site ğ‘–:
8 if1Ëœğ‘›ğ‘–,ğ‘™âˆ’1>ğ‘¡ğ‘™=1then
9 ğ‘šğ‘™â†ğ‘šğ‘™+ğ‘¡ğ‘™.
10 ğ‘Ÿğ‘–,ğ‘™â†1.
11 else
12 ğ‘šğ‘™â†ğ‘šğ‘™+Ëœğ‘›ğ‘–,ğ‘™âˆ’1.
13 ifğ‘šğ‘™â‰¥ğ‘then
14 Output YES.
15Output NO.
not a good choice. Observing that the communication cost of each
site in round ğ‘™is at most log(â„ğ‘™âˆ’â„ğ‘™âˆ’1)bits, which increases slowly
as the gap gets large. On the other hand, the number of active
sites decreases over rounds. Thus a natural choice is to double the
distance between two consecutive thresholds, i.e., â„ğ‘™âˆ’â„ğ‘™âˆ’1, after
each round, and we still expect the overall communication cost
decreases over rounds.
To implement the above idea we set ğ‘¢1=2log(ğ‘)âˆ’ğ‘Ÿ+1,ğ‘¢ğ‘™=2ğ‘¢ğ‘™âˆ’1,
ğ‘™=2,Â·Â·Â·,ğ‘Ÿandğ‘¡ğ‘™=âŒˆğ‘¢ğ‘™âŒ‰for allğ‘™âˆˆ[ğ‘Ÿ]. The algorithm is shown in
Algorithm 1 and 2. The threshold in round ğ‘™isâ„ğ‘™=Ãğ‘™
ğ‘–=1ğ‘¡ğ‘–.
Theorem 4.1 (Upper Bound of log(ğ‘˜)rounds algorithm).
The Exact DTC with ğ‘=ğ‘‚(ğ‘˜)can be solved deterministically with ğ‘Ÿ
rounds and communication ğ‘‚(ğ‘˜(log(ğ‘˜)âˆ’ğ‘Ÿ)+ğ‘˜)bits.
Proof. Observe that at the point when site ğ‘–becomes inactive,
the coordinator knows the exact value of ğ‘›ğ‘–. Then, the correctness
of the algorithm is straightforward. For the NO case, the coordi-
nator will eventually get the exact values of all sites and thus the
output must be correct. For the YES case, the algorithm will either
(1) output YES (which is correct) or (2) run until all sites become
inactive. When (2) happens, the coordinator gets the exact values
of all sites and the output must be correct. Next, we focus on the
communication cost.
The First Round. Since each site can send a value smaller than
ğ‘¡1â‰¤ğ‘¢1+1=2log(ğ‘)âˆ’ğ‘Ÿ+1+1, the communication cost is at most
ğ‘˜log(ğ‘¡1+1)â‰¤ğ‘˜log
2log(ğ‘)âˆ’ğ‘Ÿ+1+2
â‰¤ğ‘˜(log(ğ‘)âˆ’ğ‘Ÿ+2)
â‰¤ğ‘‚(ğ‘˜(log(ğ‘˜)âˆ’ğ‘Ÿ)+ğ‘˜).
Theğ‘™-th Round. Letğ‘…ğ‘™=Ãğ‘˜
ğ‘–=1ğ‘Ÿğ‘–,ğ‘™denote the number of active
sites in theğ‘™-th round. Note, for any active site in the ğ‘™-th round,
its value must be larger than ğ‘¡ğ‘™âˆ’1=âŒˆ2log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1âŒ‰. Therefore,
ğ‘…ğ‘™â‰¤ğ‘
âŒˆ2log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1âŒ‰.Otherwise, we must have that ğ‘šğ‘™â‰¥ğ‘andstop the iteration. In the ğ‘™-th round, the communication cost of
each site is bound by
log(ğ‘¡ğ‘™+1)â‰¤log
2log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™+2
â‰¤2(log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™).
Therefore, the total cost for the ğ‘™-th round is bound by
ğ‘…ğ‘™+ğ‘…ğ‘™Â·log(ğ‘¡ğ‘™+1)â‰¤ğ‘
âŒˆ2log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1âŒ‰+2ğ‘(log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™)
âŒˆ2log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1âŒ‰
â‰¤6ğ‘(log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™)
2log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™,
where the first ğ‘…ğ‘™denotes the cost of sending the signals.
Total Communication Cost. Letğ¶ğ¶denote the cost of the algo-
rithm. Combining the costs for the first and all the other rounds,
the total cost is less than
ğ¶ğ¶â‰¤ğ‘˜(log(ğ‘)âˆ’ğ‘Ÿ+2)+ğ‘Ÿâˆ‘ï¸
ğ‘™=16ğ‘(log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™)
2log(ğ‘)âˆ’ğ‘Ÿ+ğ‘™
=ğ‘˜(log(ğ‘)âˆ’ğ‘Ÿ+2)+6ğ‘log(ğ‘)âˆ‘ï¸
ğ‘™=log(ğ‘)âˆ’ğ‘Ÿ+1ğ‘™
2ğ‘™.
Now for the second part, denote ğ‘¥=Ãlog(ğ‘)
ğ‘™=log(ğ‘)âˆ’ğ‘Ÿ+1ğ‘™
2ğ‘™, we
should have
ğ‘¥âˆ’1
2ğ‘¥=log(ğ‘)âˆ’ğ‘Ÿ+1
2log(ğ‘)âˆ’ğ‘Ÿ+1+log(ğ‘)âˆ‘ï¸
ğ‘™=log(ğ‘)âˆ’ğ‘Ÿ+21
2ğ‘™âˆ’log(ğ‘)
2log(ğ‘)+1
â‰¤log(ğ‘)âˆ’ğ‘Ÿ+1
2log(ğ‘)âˆ’ğ‘Ÿ+1+1
2log(ğ‘)âˆ’ğ‘Ÿ+1
=log(ğ‘)âˆ’ğ‘Ÿ+2
2log(ğ‘)âˆ’ğ‘Ÿ+1,
where the first inequation holds by the upper bound of the sum
of geometric progression. Therefore,
ğ¶ğ¶â‰¤ğ‘˜(log(ğ‘)âˆ’ğ‘Ÿ+2)+6ğ‘log(ğ‘)âˆ‘ï¸
ğ‘™=log(ğ‘)âˆ’ğ‘Ÿ+1ğ‘™
2ğ‘™
â‰¤ğ‘˜(log(ğ‘)âˆ’ğ‘Ÿ+2)+6ğ‘2(log(ğ‘)âˆ’ğ‘Ÿ+2)
2log(ğ‘)âˆ’ğ‘Ÿ+1
=ğ‘˜(log(ğ‘)âˆ’ğ‘Ÿ+2)+6Â·2ğ‘Ÿ(log(ğ‘)âˆ’ğ‘Ÿ+2)
=ğ‘‚(ğ‘˜(log(ğ‘˜)âˆ’ğ‘Ÿ)+ğ‘˜),
where the last equality holds because 2ğ‘Ÿâ‰¤2log(ğ‘)=ğ‘‚(ğ‘˜).â–¡
Takingğ‘Ÿ=log(ğ‘)=ğ‘‚(log(ğ‘˜)), we directly get
Corollary 4.2. The Exact DTC with ğ‘=ğ‘‚(ğ‘˜)can be solved
deterministically with ğ‘‚(ğ‘˜)bits andğ‘‚(log(ğ‘˜))rounds.
4.2 Anğ‘‚(logâˆ—ğ‘˜)Rounds Algorithm
The logğ‘˜-round algorithm is already a significant improvement
over the naive ğ‘˜-round algorithm. Next we refine the idea further
to get an logâˆ—ğ‘˜-round algorithm. Compared to the logğ‘˜-round
algorithm, the only difference is a better choice of threshold grid,
where the increase rate is doubly exponential:
ğ‘¢â€²
1=ğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+1), ğ‘¢â€²
ğ‘™=exp
ğ‘¢â€²
ğ‘™âˆ’1
, ğ‘™=2,Â·Â·Â·,ğ‘Ÿ,
4667Distributed Thresholded Counting with Limited Interaction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
andğ‘¡â€²
ğ‘™=l
ğ‘¢â€²
ğ‘™m
for allğ‘™âˆˆ[ğ‘Ÿ]. See Section 2 for the definition of ğ‘“.
The idea behind the design of new grids is to maximize the size
of the grids under the constraint that the communication in each
round does not exceed ğ‘‚(ğ‘˜). Moreover, we utilize a more careful
analysis to control the total communication up to ğ‘Ÿrounds.
Theorem 4.3 (Upper Bound of logâˆ—(ğ‘˜)rounds algorithm).
The Exact DTC with ğ‘=ğ‘‚(ğ‘˜)can be solved deterministically with ğ‘Ÿ
rounds and communication ğ‘‚(ğ‘˜ğ‘“(0,logâˆ—(ğ‘˜)âˆ’ğ‘Ÿ)+ğ‘˜)bits.
Proof. By the same argument as above, the correctness is straight-
forward, and thus we focus on analyzing communication cost. Re-
call that by the definition of ğ‘“(0,ğ‘¤), we have that
ğ‘“(0,ğ‘¤)=log(ğ‘“(0,ğ‘¤+1)),andğ‘“(0,0)=1.
We useğ¶ğ¶ğ‘—to denote the communication for the ğ‘—-th round. For the
communication cost, the worst case happens when the algorithm
stops after one round. As long as the algorithm goes to the second
round, the communication cost is bounded by ğ‘‚(ğ‘˜)regardless of
the actual number of rounds in the execution. Next, we analyze the
two cases separately.
Case 1: stop after one round. Each site can send a value smaller
thanğ‘¡â€²
1â‰¤ğ‘¢â€²
1+1=ğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+1)+1, the cost is at most
ğ‘˜log(ğ‘¡1+1)â‰¤ğ‘˜log ğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+1)+2
â‰¤ğ‘‚(ğ‘˜ğ‘“(0,logâˆ—(ğ‘˜)âˆ’ğ‘Ÿ)+ğ‘˜).
Case 2: stops after ğ‘™rounds with ğ‘™â‰¥2.The communication cost
is divided into two parts: the cost for round 1toğ‘™âˆ’1and the cost
for theğ‘™-th round. For the first ğ‘™âˆ’1rounds, the communication is
ğ‘™âˆ’1âˆ‘ï¸
ğ‘—=1ğ¶ğ¶ğ‘—=ğ‘™âˆ’1âˆ‘ï¸
ğ‘—=1ğ‘˜âˆ‘ï¸
ğ‘–=1
1ğ‘Ÿğ‘–,ğ‘—âˆ’1=1log min
ğ‘¡ğ‘—,Ëœğ‘›ğ‘–,ğ‘—âˆ’1	
+1+ğ‘Ÿğ‘–,ğ‘—âˆ’1
â‰¤ğ‘™âˆ’1âˆ‘ï¸
ğ‘—=1ğ‘˜âˆ‘ï¸
ğ‘–=1
1ğ‘Ÿğ‘–,ğ‘—âˆ’1=1min
ğ‘¡ğ‘—,Ëœğ‘›ğ‘–,ğ‘—âˆ’1	
+2ğ‘Ÿğ‘–,ğ‘—âˆ’1
â‰¤3ğ‘™âˆ’1âˆ‘ï¸
ğ‘—=1ğ‘˜âˆ‘ï¸
ğ‘–=1min
ğ‘¡ğ‘—,Ëœğ‘›ğ‘–,ğ‘—âˆ’1	
â‰¤3ğ‘šğ‘™âˆ’1,
where the second inequality holds because
ğ‘Ÿğ‘–,ğ‘—âˆ’1=1Ëœğ‘›ğ‘–,ğ‘—âˆ’1>0â‰¤min
ğ‘¡ğ‘—,Ëœğ‘›ğ‘–,ğ‘—âˆ’1	
.
Moreover, since we can pass to the ğ‘™-th round, we must have that
ğ‘šğ‘™âˆ’1â‰¤ğ‘.This implies the communication for the first ğ‘™âˆ’1rounds
is at mostğ‘‚(ğ‘)=ğ‘‚(ğ‘˜)bits.
For theğ‘™-th round, let ğ‘…ğ‘™=Ãğ‘˜
ğ‘–=1ğ‘Ÿğ‘–,ğ‘™denote the number of active
sites in theğ‘™-th round. For any active site in ğ‘™-th round, its value
is larger than ğ‘¡ğ‘™âˆ’1=âŒˆğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1)âŒ‰. Therefore, ğ‘…ğ‘™â‰¤
ğ‘
âŒˆğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1)âŒ‰, since otherwise, we must have that ğ‘šğ‘™â‰¥ğ‘
and stop the iteration. In the ğ‘™-th round, the communication cost of
each active site is bound by
log(ğ‘¡ğ‘™+1)â‰¤log ğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+ğ‘™)+2
â‰¤ğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1)+2.Algorithm 3: Siteğ‘–: Multi-Layer Deterministic DTC
Input: Counterğ‘›ğ‘–, Number of Rounds ğ‘Ÿ
Initialize: SetËœğ‘›ğ‘–=ğ‘›ğ‘–,ğ‘™=1
1Compute the thresholds ğ‘›ğ‘–belongs to and get ğ‘—ğ‘–
ğ‘™such that
â„ğ‘Ÿâˆ’ğ‘™,0
ğ‘—ğ‘–
ğ‘™â‰¤ğ‘›ğ‘–<â„ğ‘Ÿâˆ’ğ‘™,0
ğ‘—ğ‘–
ğ‘™+1for allğ‘™âˆˆ[0,ğ‘Ÿâˆ’1]. (Note that ğ‘—ğ‘–ğ‘Ÿ=ğ‘›ğ‘–.)
2When siteğ‘–receives the signal of the new round :
3 ifğ‘›ğ‘–â‰¤ğ‘“(0,ğ‘Ÿ)then
4 Send to the server a signal that 1ğ‘›ğ‘–â‰¤ğ‘“(0,ğ‘Ÿ)=1.
5 ifËœğ‘›ğ‘–>ğ‘“(0,ğ‘™)then
6 Send to the server a signal that 1Ëœğ‘›ğ‘–>ğ‘“(0,ğ‘™)=1.
7 Ëœğ‘›ğ‘–â†Ëœğ‘›ğ‘–âˆ’ğ‘“(0,ğ‘™).
8 else
9 Send to the server a signal that 1Ëœğ‘›ğ‘–>ğ‘“(0,ğ‘™)=0.
10 Send to the server the value of Ëœğ‘›ğ‘–.
11 else
12 Send to the server a signal that 1ğ‘›ğ‘–â‰¤ğ‘“(0,ğ‘Ÿ)=0.
13 ifğ‘™>1then
14 Send to the server ğ‘—ğ‘–
ğ‘™âˆ’â„ğ‘Ÿâˆ’ğ‘™+1,ğ‘Ÿâˆ’ğ‘™
ğ‘—ğ‘–
ğ‘™âˆ’1.
15 else
16 Send to the server ğ‘—ğ‘–
ğ‘™.
17ğ‘™â†ğ‘™+1.
Therefore, the communication for ğ‘™rounds each round is less than
ğ‘™âˆ‘ï¸
ğ‘—=1ğ¶ğ¶ğ‘—=ğ‘™âˆ’1âˆ‘ï¸
ğ‘—=1ğ¶ğ¶ğ‘—+ğ¶ğ¶ğ‘™â‰¤3ğ‘+ğ‘…ğ‘™+ğ‘…ğ‘™Â·log(ğ‘¡ğ‘™+1)
â‰¤3ğ‘+ğ‘(ğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1)+3)
âŒˆğ‘“(0,logâˆ—(ğ‘)âˆ’ğ‘Ÿ+ğ‘™âˆ’1)âŒ‰â‰¤7ğ‘=ğ‘‚(ğ‘˜).
This bound holds for any ğ‘™â‰¥2. â–¡
Takingğ‘Ÿ=logâˆ—(ğ‘)âˆ’1=ğ‘‚(logâˆ—(ğ‘˜)), we get
Corollary 4.4. The Exact DTC with ğ‘=ğ‘‚(ğ‘˜)can be solved
deterministically with ğ‘‚(ğ‘˜)bits andğ‘‚(logâˆ—(ğ‘˜))rounds.
4.3 Anğ‘‚(ğ›¼(ğ‘˜))Rounds Algorithm
Whileğ‘‚(logâˆ—(ğ‘˜))is already very small for any reasonable ğ‘˜, in this
section, we show that the round complexity can be further reduced
toğ‘‚(ğ›¼(ğ‘˜)). As is introduced in Section 2, function ğ›¼(ğ‘˜)grows at
an extremely slow rate and is less than 3even ifğ‘˜=22265536
. The
algorithms are shown in Algorithm 3 and 4. We will first introduce
the idea that brings us to our final algorithm.
Overview. Imagine that we place [0,ğ‘]on a straight line as the
bottom layer 0. Our previous algorithms effectively divide this line
into multiple grids. Their job is first to determine the grid to which
each siteâ€™s value belongs by systematically testing from the smallest
grid to the largest one and then obtaining the exact value in this grid.
The grids are designed so that the number of them (corresponding
to the number of rounds) and communication of each round are
bounded.
4668KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Xiaoyi Zhu, Yuxiang Tian, & Zengfeng Huang.
Algorithm 4: Coordinator: Multi-Layer Deterministic DTC
Input: Thresholdğ‘, Number of Rounds ğ‘Ÿ
Initialize: Setğ‘š0=0,ğ‘Ÿğ‘–,0=1for eachğ‘–âˆˆ[ğ‘˜]
1ForRoundğ‘™from 1toğ‘Ÿ:
2 ForSiteğ‘–from 1toğ‘˜:
3 ifğ‘Ÿğ‘–,ğ‘™âˆ’1=1then
4 Send to site ğ‘–a signal of the new round.
5ğ‘Ÿğ‘–,ğ‘™â†0.
6ğ‘šğ‘™â†ğ‘šğ‘™âˆ’1
7 When coordinator receives a signal from some site ğ‘–:
8 if1ğ‘›ğ‘–â‰¤ğ‘“(0,ğ‘Ÿ)=1then
9 ifËœğ‘›ğ‘–>ğ‘“(0,ğ‘™)then
10 ğ‘šğ‘™â†ğ‘šğ‘™+ğ‘“(0,ğ‘™),ğ‘Ÿğ‘–,ğ‘™â†1.
11 else
12 ğ‘šğ‘™â†ğ‘šğ‘™+Ëœğ‘›ğ‘–.
13 else
14 ifğ‘™>1then
15 Computeğ‘—ğ‘–
ğ‘™by adding back â„ğ‘Ÿâˆ’ğ‘™+1,ğ‘Ÿâˆ’ğ‘™
ğ‘—ğ‘–
ğ‘™âˆ’1.
16 ğ‘šğ‘™â†ğ‘šğ‘™+â„ğ‘Ÿâˆ’ğ‘™,0
ğ‘—ğ‘–
ğ‘™âˆ’â„ğ‘Ÿâˆ’ğ‘™+1,0
ğ‘—ğ‘–
ğ‘™âˆ’1,ğ‘Ÿğ‘–,ğ‘™â†1.
17 else
18 ğ‘šğ‘™â†ğ‘šğ‘™+â„ğ‘Ÿâˆ’ğ‘™,0
ğ‘—ğ‘–
ğ‘™,ğ‘Ÿğ‘–,ğ‘™â†1.
19 ifğ‘›â‰¥ğ‘then
20 Output Yes.
21Output No.
Compared to that, a more effective way is to lift the grids to layer
1and let them act as an "express lane" for the layer below. That is,
in the first round, we directly get the value in layer 1, which helps
us to know which grid the value belongs to, and then in the next
round, we get the exact value in this grid at layer 0. This gives us an
algorithm that runs in 2 rounds and uses ğ‘‚(ğ‘˜log(logâˆ—(ğ‘)))bits.
This idea can be generalized to get higher layers. That is, we
build higher layers to determine the grids that the value belongs
to in lower layers quickly. The main hardness of the method is to
construct such multiple-layer grids while satisfying the constraints
of communication complexity, which is our focus in the next part.
Construction of Grids. We useğ‘‘ğ‘™to denote the number of grids
at theğ‘™th layer. Initially, at the bottom layer 0, we have ğ‘¡0
0=0,ğ‘¡0
1=
1,Â·Â·Â·,ğ‘¡0
ğ‘‘0=ğ‘,ğ‘‘ 0=ğ‘.The construction of the first layer is similar
to the grids we use in Section4.2. We let ğ‘¡1
0=0,ğ‘¡1
1=1and
ğ‘¡1
ğ‘—+1=ğ‘¡1
ğ‘—+exp
ğ‘¡0
ğ‘¡1
ğ‘—
=ğ‘¡1
ğ‘—+exp
ğ‘¡1
ğ‘—
.
Those points[ğ‘¡1
ğ‘—,ğ‘¡1
ğ‘—+1]in layer 0 belongs to grid ğ‘—in layer 1. Now
for higher layers, assume that we already have grids at layer ğ‘™being
ğ‘¡ğ‘™
0,Â·Â·Â·,ğ‘¡ğ‘™
ğ‘‘ğ‘™and we would like to build the grids at the (ğ‘™+1)th layer.
Start withğ‘¡ğ‘™+1
0=0,ğ‘¡ğ‘™+1
1=1. Forğ‘¡ğ‘™+1
ğ‘—+1, We will firstly compute
â„ğ‘™+1,ğ‘™+1
ğ‘—=ğ‘¡ğ‘™+1
ğ‘—,â„ğ‘™+1,ğ‘ 
ğ‘—=ğ‘¡ğ‘ 
â„ğ‘™+1,ğ‘ +1
ğ‘—,ğ‘ =ğ‘™,Â·Â·Â·,0.Specifically, â„ğ‘™+1,ğ‘ 
ğ‘—is the minimum value in the ğ‘ th level that will
be assigned to the corresponding grid ğ‘¡ğ‘™+1
ğ‘—. For example, assume
that[4,16]in layer 0 belongs to [3,5]in layer 1 and finally ğ‘¡2
ğ‘—=2
in layer 2, then we have that â„ğ‘™+1,1
ğ‘—=3andâ„ğ‘™+1,0
ğ‘—=4.
We letğ‘¡ğ‘™+1
ğ‘—+1=ğ‘¡ğ‘™+1
ğ‘—+exp
â„ğ‘™+1,0
ğ‘—
and keep computing until ğ‘¡ğ‘™+1
ğ‘—>
ğ‘‘ğ‘™, andğ‘‘ğ‘™+1=minn
ğ‘—|ğ‘¡ğ‘™+1
ğ‘—>ğ‘‘ğ‘™o
.We have the upper bound of the
number of grids of each layer and the property of the grids that
Lemma 4.5 (Upper Bound of Number of grids). For the grids
constructed in Section 4.3, we have
ğ‘‘ğ‘™â‰¤logğ‘™timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘)+1,âˆ€ğ‘™âˆˆ[1,ğ‘Ÿâˆ’1].
Proof. The proof of Lemma 4.5 can be found in Section B. The
idea is to first prove
ğ‘¡ğ‘™
ğ‘—â‰¥ğ‘“(ğ‘™âˆ’1,ğ‘—),âˆ€ğ‘™âˆˆ[1,ğ‘Ÿâˆ’1]
by induction and then gives the upper bound of the number of
thresholds. â–¡
Lemma 4.6 (Property of grids). For the grids constructed in
Section 4.3, any 0â‰¤ğ‘™â‰¤ğ›¼(ğ‘˜),ğ›¼in the layer ğ‘™,ğ›½in the layer ğ‘™+1
andğ›¼belongs to grid ğ›½,we haveğ›¼âˆ’â„ğ‘™+1,ğ‘™
ğ›½â‰¤â„ğ‘™,0
ğ›¼âˆ’â„ğ‘™+1,0
ğ›½.
Proof. The proof of Lemma 4.6 can be found in Section B. â–¡
Algorithm. With the above construction of grids, we can now
introduce our algorithms in Algorithm 3 and 4. For sites with a
value less than ğ‘“(0,ğ‘Ÿ), we just perform the Algorithm 1 and 2 with
grids being ğ‘“(0,1),Â·Â·Â·,ğ‘“(0,ğ‘Ÿ). For sites with large values, firstly,
we assign the value of grids on each layer based on our construction.
Then in each round ğ‘™, sites send their value of grids in ğ‘Ÿâˆ’ğ‘™layers
to the coordinator. (Note that when ğ‘™=ğ‘Ÿ, we are sending the value
in the bottom layer, which is also the exact value.) Using this value,
the coordinator updates the minimum value each site can be and
compares the sum to ğ‘. We have the guarantee that
Theorem 4.7 (Upper Bound of ğ›¼(ğ‘˜)Rounds Algorithm). The
Exact DTC with ğ‘=ğ‘‚(ğ‘˜)can be solved deterministically with ğ‘Ÿ
rounds and communication ğ‘‚(ğ‘˜log(logğ‘Ÿâˆ’1timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘˜))+ğ‘˜)bits.
Proof. The correctness holds again due to our exact computa-
tion that in the last round, all sites will eventually send their exact
value. Next, We focus on the communication cost. For sites with a
value less than ğ‘“(0,ğ‘Ÿ), their protocol is similar to Algorithms 1and 2
with gridsğ‘“(0,ğ‘™)for each round. Therefore, their communication
can be bounded by ğ‘‚(ğ‘˜)with the same arguments in proof of The-
orem 4.1. We then consider sites with a value more than ğ‘“(0,ğ‘Ÿ). We
useğ¶ğ¶ğ‘—to denote the communication for the ğ‘—-th round.
4669Distributed Thresholded Counting with Limited Interaction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Case 1: stop after one round. In the first round each site can send
a value in[0,ğ‘‘ğ‘Ÿâˆ’1]. By Lemma 4.5, we have the cost is at most
ğ‘˜log(ğ‘‘ğ‘Ÿâˆ’1+1)â‰¤ğ‘˜log(logğ‘Ÿâˆ’1timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘)+2)
â‰¤ğ‘‚(ğ‘˜log(logğ‘Ÿâˆ’1timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘˜))+ğ‘˜).
Case 1: stop after ğ‘rounds with ğ‘â‰¥2.The communication cost
forğ‘rounds can be divided into two parts. The cost for 1toğ‘âˆ’1
rounds and the cost for the ğ‘-th round. For ğ‘â‰¥2, since we can
pass the first round, each survival site must have a value larger
thanğ‘“(0,ğ‘Ÿ), and the number of them is less thanğ‘
ğ‘“(0,ğ‘Ÿ). Therefore,
sending signals to them for ğ‘Ÿrounds needs bitsğ‘
ğ‘“(0,ğ‘Ÿ)Â·ğ‘Ÿâ‰¤ğ‘=
ğ‘‚(ğ‘˜).For the first ğ‘âˆ’1rounds, the bits we have sent are
ğ‘âˆ’1âˆ‘ï¸
ğ‘™=1ğ¶ğ¶ğ‘™=ğ¶ğ¶1+ğ‘âˆ’1âˆ‘ï¸
ğ‘™=2ğ¶ğ¶ğ‘™
=âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ)log
ğ‘—ğ‘–
1+1
+ğ‘âˆ’1âˆ‘ï¸
ğ‘™=2âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ)log
ğ‘—ğ‘–
ğ‘™âˆ’â„ğ‘Ÿâˆ’ğ‘™+1,ğ‘Ÿâˆ’ğ‘™
ğ‘—ğ‘–
ğ‘™âˆ’1+1
.
Since logğ‘¥â‰¤ğ‘¥forğ‘¥â‰¥1, we have the communication is upper
bound by
âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ) 
ğ‘—ğ‘–
1+ğ‘âˆ’1âˆ‘ï¸
ğ‘™=2
ğ‘—ğ‘–
ğ‘™âˆ’â„ğ‘Ÿâˆ’ğ‘™+1,ğ‘Ÿâˆ’ğ‘™
ğ‘—ğ‘–
ğ‘™âˆ’1!
+ğ‘âˆ’1âˆ‘ï¸
ğ‘™=1âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ)2.
Now for the first part, applying Lemma 4.6 gives us
âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ) 
ğ‘—ğ‘–
1+ğ‘âˆ’1âˆ‘ï¸
ğ‘™=2
ğ‘—ğ‘–
ğ‘™âˆ’â„ğ‘Ÿâˆ’ğ‘™+1,ğ‘Ÿâˆ’ğ‘™
ğ‘—ğ‘–
ğ‘™âˆ’1!
â‰¤âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ) 
â„ğ‘Ÿâˆ’1,0
ğ‘—ğ‘–
1+ğ‘âˆ’1âˆ‘ï¸
ğ‘™=2
â„ğ‘Ÿâˆ’ğ‘™,0
ğ‘—ğ‘–
ğ‘™âˆ’â„ğ‘Ÿâˆ’ğ‘™+1,0
ğ‘—ğ‘–
ğ‘™âˆ’1!
â‰¤âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ)â„ğ‘Ÿâˆ’ğ‘+1,0
ğ‘—ğ‘–
ğ‘âˆ’1â‰¤ğ‘.
The last ineqation holds due to the condition to pass to the ğ‘-th
round. For the second part, we have
ğ‘âˆ’1âˆ‘ï¸
ğ‘™=1âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ)2â‰¤ğ‘âˆ’1âˆ‘ï¸
ğ‘™=12ğ‘
ğ‘“(0,ğ‘Ÿ)â‰¤2ğ‘ŸÂ·ğ‘
ğ‘“(0,ğ‘Ÿ)â‰¤2ğ‘,
where the first and second inequation holds by direct counting and
the final inequation holds since function ğ‘“(0,ğ‘Ÿ)grows significantly
faster thanğ‘Ÿ. Combining the results, we have that the communica-
tion in the first ğ‘âˆ’1rounds is bound by
ğ‘âˆ’1âˆ‘ï¸
ğ‘™=1ğ¶ğ¶ğ‘™â‰¤âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ)â„ğ‘Ÿâˆ’ğ‘+1,0
ğ‘—ğ‘–
ğ‘âˆ’1+2ğ‘,Algorithm 5: Siteğ‘–: Sampling-Procedure
Input: Counterğ‘›ğ‘–, Sum Parameter ğ‘, Communication
parameterğ¶ğ¶, Error probability ğ›¿
1ifğ¶ğ¶â‰¥ğ‘Â·log
2
ğ›¿
then
2 Setğ‘â†log(2
ğ›¿)
ğ‘.
3else
4 Setğ‘â†ğ¶ğ¶
ğ‘ğ‘.
5Generate Ëœğ‘›ğ‘–âˆ¼Binomial(ğ‘›ğ‘–,ğ‘).
6Send Ëœğ‘›ğ‘–to the coordinator.
Algorithm 6: Coordinator: Sampling-Procedure
Input: Thresholdğ‘, Sum Parameter ğ‘, Communication
parameterğ¶ğ¶, Error probability ğ›¿
Initialize: SetËœğ‘›=0.
1ifğ¶ğ¶â‰¥ğ‘Â·log
2
ğ›¿
then
2 Setğ‘‡â†4 log
6ğ‘Ÿ
ğ›¿
.
3else
4 Setğ‘‡â†ğ¶ğ¶
ğ‘+3 log
2
ğ›¿
.
5When coordinator receives signals from some site ğ‘–:
6 Ëœğ‘›â†Ëœğ‘›+Ëœğ‘›ğ‘–.
7ifËœğ‘›â‰¥ğ‘‡then
8 Return Yes.
9Return No.
In theğ‘-th round, the communication of each site is bound by
log
â„ğ‘Ÿâˆ’ğ‘,0
ğ‘—ğ‘–
ğ‘âˆ’â„ğ‘Ÿâˆ’ğ‘+1,0
ğ‘—ğ‘–
ğ‘âˆ’1+1
â‰¤log
exp
â„ğ‘Ÿâˆ’ğ‘+1,0
ğ‘—ğ‘–
ğ‘âˆ’1
+1
â‰¤â„ğ‘Ÿâˆ’ğ‘+1,0
ğ‘—ğ‘–
ğ‘âˆ’1+1,
where the first inequality holds due to our construction of grids.
Therefore, the communication for ğ‘rounds each round is less than
ğ‘âˆ‘ï¸
ğ‘™=1ğ¶ğ¶ğ‘™=ğ‘âˆ’1âˆ‘ï¸
ğ‘™=1ğ¶ğ¶ğ‘—+ğ¶ğ¶ğ‘
â‰¤âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ)â„ğ‘Ÿâˆ’ğ‘+1,0
ğ‘—ğ‘–
ğ‘âˆ’1+2ğ‘+âˆ‘ï¸
ğ‘–:ğ‘›ğ‘–>ğ‘“(0,ğ‘Ÿ)
â„ğ‘Ÿâˆ’ğ‘+1,0
ğ‘—ğ‘–
ğ‘âˆ’1+1
â‰¤4ğ‘+ğ‘
ğ‘“(0,ğ‘Ÿ)â‰¤5ğ‘.
This holds for any ğ‘â‰¥2. The proof completes by taking ğ‘=ğ‘‚(ğ‘˜).
â–¡
Takingğ‘Ÿ=ğ›¼(ğ‘)=ğ‘‚(ğ›¼(ğ‘˜)), we have the following corollary.
Corollary 4.8 (Theorem 1.3 restatement). The Exact DTC
withğ‘=ğ‘‚(ğ‘˜)can be solved deterministically with ğ‘‚(ğ‘˜)bits com-
munication and ğ‘‚(ğ›¼(ğ‘˜))rounds.
4670KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Xiaoyi Zhu, Yuxiang Tian, & Zengfeng Huang.
5 Randomized Algorithms
We have shown that there is a deterministic algorithm with optimal
communication cost and ğ›¼(ğ‘˜)rounds, but whether there is an ğ‘‚(1)-
round deterministic algorithm with similar communication cost
is unclear. On the other hand, we show that such an algorithm
exists if we allow randomization and a tiny probability of error. The
algorithms are shown in Algorithm 7 and Algorithm 8.
Overview. The key challenge in our problem is that there may
be many sites with large values. Even if their sum exceeds the
threshold by a significant margin, sending these values can cause
substantial communication costs. To address this challenge, instead
of constructing grids as in our deterministic algorithm, we utilize a
sampling approach to gradually narrow down the possible range
of our sum. To avoid significant communication, we start with a
lower sampling probability to filter out larger values in the sum and
increase this probability over rounds. The sampling procedure is
shown in algorithm 5 and 6. Here we use an extra input parameter
ğ‘which would influence this procedure. We have the following
property of this process summarized in Lemma 5.1.
Lemma 5.1 (Property of Sampling Procedure). For the sam-
pling procedure shown in algorithm 5 and 6, if the sum ğ‘›=Ãğ‘˜
ğ‘–=1ğ‘›ğ‘–â‰¤
12ğ‘ğ‘, with probability at least 1âˆ’2ğ›¿, the procedure will output 0 when
ğ‘›â‰¤ğ‘and use less than 24ğ¶ğ¶bits for communication. Moreover,
â€¢Forlog
2
ğ›¿
<ğ¶ğ¶<ğ‘Â·log
2
ğ›¿
, with probability at least 1âˆ’ğ›¿,
the procedure will output 1 when ğ‘›>12ğ‘ğ‘Â·log(2
ğ›¿)
ğ¶ğ¶>12ğ‘.
â€¢Forğ¶ğ¶â‰¥ğ‘Â·log
2
ğ›¿
, with probability at least 1âˆ’ğ›¿, the
procedure will output 1 when ğ‘›>12ğ‘.
Proof. The proof of Lemma 5.1 can be found in Section C. The
idea is to apply Chernoff bound to control the probability of the
sampling procedure outputting 1whenğ‘›is small and the probability
of outputting 0whenğ‘›is large. â–¡
With Lemma 5.1, we have the guarantee of our algorithm 7 and 8.
Theorem 5.2 (Theorem 1.4 restatement). The Exact DTC with
ğ‘=ğ‘‚(ğ‘˜)can be solved in ğ‘Ÿrounds with randomized communication
costğ‘‚
ğ¸ğ‘˜1
ğ‘Ÿâˆ’1+ğ‘˜ğ‘Ÿ
bits with failure probability at most ğ›¿=2âˆ’ğ¸.
This shows that we can achieve the optimal ğ‘‚(ğ‘˜)in a constant
number of rounds and small failure probability. For example, we
only need 3 rounds and have failure probability ğ›¿=2âˆ’âˆš
ğ‘˜.
Proof. We set the error probability for the sampling procedure
toğ›¿
3ğ‘Ÿ. By union bound, the property in Lemma 5.1 holds for ğ‘Ÿâˆ’1
rounds invocation with probability at least 1âˆ’ğ‘Ÿâˆ’1
ğ‘Ÿğ›¿. Moreover, we
will choose ğ¶ğ¶=ğ‘˜1
ğ‘Ÿâˆ’1log
6ğ‘Ÿ
ğ›¿
in our algorithm.
Correctness. Initially, the total sum is upper bounded by ğ‘˜ğ‘and
corresponding ğ‘1=ğ‘˜
12. Using Lemma 5.1, if the sum is guaranteed
to be less than 12ğ‘ğ‘ğ‘™after roundğ‘™, we have that for the ğ‘™+1rounds,
â€¢either the sampling procedure outputs 1, which means that
ğ‘›>12ğ‘and we can stop the iteration;
â€¢or the sampling procedure outputs 0, and we have the new
guaranteeğ‘›â‰¤12ğ‘ğ‘ğ‘™+1withğ‘ğ‘™+1=ğ‘ğ‘™Â·log(6ğ‘Ÿ
ğ›¿)
ğ¶ğ¶.Therefore, with probability at least 1âˆ’ğ›¿, when the sampling proce-
dure outputs 1, we are confirmed thatÃğ‘˜
ğ‘–=1ğ‘›ğ‘–>ğ‘for the firstğ‘Ÿâˆ’1
rounds. In the last round, we let each site send its value directly.
The correctness holds for exact computation.
Communication Cost. If the algorithm passes the ğ‘™th round for
ğ‘™â‰¤ğ‘Ÿâˆ’2, the sum is smaller than 12ğ‘ğ‘ğ‘™=ğ‘˜ğ‘
log
6ğ‘Ÿ
ğ›¿
/ğ¶ğ¶ğ‘™
.
Therefore, considering all ğ‘™+1rounds we need to sample it, let Ëœğ‘
be the total sum of sampled value, the expectation is at most
E[Ëœğ‘]â‰¤ğ‘˜ğ‘Â©Â­Â­
Â«log
6ğ‘Ÿ
ğ›¿
ğ¶ğ¶ÂªÂ®Â®
Â¬ğ‘™
ğ‘™+1âˆ‘ï¸
ğ‘—=112ğ¶ğ¶
ğ‘˜ğ‘
log(6ğ‘Ÿ
ğ›¿)
ğ¶ğ¶ğ‘—âˆ’1+12ğ‘ğ‘ğ‘Ÿâˆ’2log
6ğ‘Ÿ
ğ›¿
ğ‘
â‰¤12ğ¶ğ¶Â©Â­Â­Â­
Â«ğ‘™+1âˆ‘ï¸
ğ‘—=1Â©Â­Â­
Â«log
6ğ‘Ÿ
ğ›¿
ğ¶ğ¶ÂªÂ®Â®
Â¬ğ‘™âˆ’ğ‘—+1
+1ÂªÂ®Â®Â®
Â¬â‰¤12ğ¶ğ¶
1âˆ’log(6ğ‘Ÿ
ğ›¿)
ğ¶ğ¶+12ğ¶ğ¶
=12ğ¶ğ¶
1âˆ’1
ğ‘˜1
ğ‘Ÿâˆ’1+12ğ¶ğ¶â‰¤36ğ¶ğ¶,
where the last inequality holds for ğ‘˜â‰¥2ğ‘Ÿ(Otherwise, we can do
it deterministically with ğ‘Ÿ=ğ‘‚(ğ›¼(ğ‘˜))). We can now compute the
total number of samples we may take. By Chernoff Bound, we have
Pr[Ëœğ‘â‰¥72ğ¶ğ¶]<Pr[|ğ‘âˆ’ğ¸[ğ‘]|â‰¥36ğ¶ğ¶]<2 exp
âˆ’36ğ¶ğ¶
3
<2 exp
âˆ’12 log6ğ‘Ÿ
ğ›¿
=2ğ›¿
6ğ‘Ÿ12
<ğ›¿
ğ‘Ÿ.
With probability at least 1âˆ’ğ›¿
ğ‘Ÿ, The number of samples we take
is upper bounded by ğ‘‚(ğ¶ğ¶)=ğ‘‚
ğ‘˜1
ğ‘Ÿâˆ’1log
6ğ‘Ÿ
ğ›¿
. Moreover, our
choice ofğ¶ğ¶=ğ‘˜1
ğ‘Ÿâˆ’1log
6ğ‘Ÿ
ğ›¿
guarantees that after at most ğ‘Ÿâˆ’2
rounds, we have ğ‘›<12ğ‘ğ‘ğ‘Ÿâˆ’1with
ğ‘ğ‘Ÿâˆ’1Â·log6ğ‘Ÿ
ğ›¿
=1
12ğ‘˜Â©Â­Â­
Â«log
6ğ‘Ÿ
ğ›¿
ğ¶ğ¶ÂªÂ®Â®
Â¬ğ‘Ÿâˆ’2
log6ğ‘Ÿ
ğ›¿
=1
12ğ‘˜1
ğ‘Ÿâˆ’1log6ğ‘Ÿ
ğ›¿
â‰¤ğ¶ğ¶.
With the second part of Lemma 5.1, we will have that ğ‘›â‰¤12ğ‘if
the sampling procedure in the ğ‘Ÿâˆ’1round outputs 0. Therefore,
the communication for the last round is at most ğ‘‚(ğ‘)=ğ‘‚(ğ‘˜)by
concavity of the log function. The extra ğ‘‚(ğ‘˜ğ‘Ÿ)is used for alerting
the new rounds. Taking ğ›¿=2âˆ’ğ¸completes the proof.
â–¡
6 Experimental Evaluation
In this section, we evaluate the proposed algorithms on a machine
running Intel(R) Xeon(R)CPU E5-2678 v3 @ 2.50GHZ. The four algo-
rithms are compared under the synthetic datasets that we construct.
For brevity, we use the names: log,star ,alpha andrandomize to
denote the deterministic algorithms with round complexity log(ğ‘˜),
logâˆ—(ğ‘˜),ğ›¼(ğ‘˜)and the randomized algorithm respectively. We set
the error probability of the randomized algorithm being 10âˆ’8.
4671Distributed Thresholded Counting with Limited Interaction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Algorithm 7: Siteğ‘–: Randomized DTC
Input: Counterğ‘›ğ‘–, Number of Rounds ğ‘Ÿ, Communication
parameterğ¶ğ¶, Error probability ğ›¿
Initialize: Setğ‘™=1,ğ¶ğ¶=ğ‘˜1
ğ‘Ÿâˆ’1log
6ğ‘Ÿ
ğ›¿
,ğ‘1=ğ‘˜
12.
1When siteğ‘–receives the signal of the new round :
2ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘–ğ‘›ğ‘”âˆ’ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘’ğ‘‘ğ‘¢ğ‘Ÿğ‘’
ğ‘›ğ‘–,ğ‘ğ‘™,ğ¶ğ¶,ğ›¿
3ğ‘Ÿ
.
3ğ‘™â†ğ‘™+1,ğ‘ğ‘™â†ğ‘ğ‘™âˆ’1
log(6ğ‘Ÿ
ğ›¿)
ğ¶ğ¶
.
4When siteğ‘–receives the special signal :
5 Send to the coordinator the value of counter ğ‘›ğ‘–.
Algorithm 8: Coordinator: Randomized DTC
Input: Thresholdğ‘, Number of Rounds ğ‘Ÿ, Communication
parameterğ¶ğ¶, Error probability ğ›¿
Initialize: Setğ‘›=0,ğ¶ğ¶=ğ‘˜1
ğ‘Ÿâˆ’1log
6ğ‘Ÿ
ğ›¿
,ğ‘1=ğ‘˜
12.
1ForRoundğ‘™from 1to(ğ‘Ÿâˆ’1):
2 ForSiteğ‘–from 1toğ‘˜:
3 Send to site ğ‘–a signal of the new round
4ğ‘šğ‘™â†ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘–ğ‘›ğ‘”âˆ’ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘’ğ‘‘ğ‘¢ğ‘Ÿğ‘’
ğ‘,ğ‘ğ‘™,ğ¶ğ¶,ğ›¿
3ğ‘Ÿ
.
5 ifğ‘šğ‘™=Yes then
6 Output Yes.
7ğ‘ğ‘™â†ğ‘ğ‘™âˆ’1
log(6ğ‘Ÿ
ğ›¿)
ğ¶ğ¶
.
8ForSiteğ‘–from 1toğ‘˜:
9 Send to site ğ‘–a special signal
10When coordinator receives ğ‘›ğ‘–from some site ğ‘–:
11ğ‘›â†ğ‘›+ğ‘›ğ‘–
12ifğ‘›>ğ‘then
13 Output Yes.
14Output No.
In the synthetic datasets, the number of the sites ğ‘˜ranges from
1,000,000to100,000,000and the threshold ğ‘=2ğ‘˜. For each gen-
erated value ğ‘¥, if it is not an integer, we take âŒˆğ‘¥âŒ‰. For1
10fraction
of the sites, we generate random value from a uniform distribution
on[0,ğ‘), and for the rest of the sites, we simply assign 0.
It is important to note that our algorithms perform well with
worst-case communication and round upper bounds regardless of
the inputs received. The choice of specific inputs in our evaluation
aims to demonstrate the worst-case capabilities of our algorithms.
In this particular scenario, directly transmitting all the inputs would
result in suboptimal communication complexity of ğ‘‚(ğ‘˜logğ‘˜), while
employing the algorithm described in [ 10] requiresğ‘‚(ğ‘˜)rounds if
the sites with values are the last ones to be inquired. In comparison,
our algorithms achieve better communication-round trade-offs in
this setting.
The main parameters in our algorithm are the number of sites ğ‘˜
and the round complexity ğ‘Ÿand we will fix them respectively.Fix Round Complexity. The first row of Figure 1 illustrates the
result of the algorithms when the number of rounds is fixed to be 2
or3. While the communication of all the algorithms grows nearly
linearly over ğ‘˜, our final deterministic algorithm alpha and ran-
domized algorithm randomize perform the best with a significantly
lower slope, which is consistent with theoretical results.
Moreover, Algorithm alpha performs better with 2 rounds while
algorithm randomize is superior with 3 rounds. This is expected as
our 2-round randomized algorithm has a complexity of ğ‘‚(ğ‘˜log
1
ğ›¿
+
ğ‘˜), where the first term dominates. For 3 rounds, the first term drops
to onlyğ‘‚âˆš
ğ‘˜log
1
ğ›¿
, leading to better performance.
Finally, there are discontinuous parts appearing on the both
lines. This can be attributed to the discontinuous nature of the grid
construction. The grids constructed based on the inputs remain
unchanged until the size of ğ‘˜is doubled. However, from an asymp-
totic perspective, the lines still exhibit a linear relationship with ğ‘˜,
which aligns with our analysis.
Fix Number of Sites. We fix the number of sites ğ‘˜and compute
the minimum communication that algorithms need within different
round complexity ğ‘Ÿ. The results are shown in the second row of
Figure 1. The convergence of the algorithms illustrates the number
of rounds required to attain optimal communication. Compared
tolog,alpha andrandomize exhibit a better performance with
lower communication complexity and fewer rounds to converge.
This shows that our algorithms successfully balance the round
complexity and communication cost.
0.0 0.2 0.4 0.6 0.8 1.0
number of sites1e80.00.51.01.52.02.5comunication complexity (bits)1e8 2 rounds
log
star
alpha
randomize
0.0 0.2 0.4 0.6 0.8 1.0
number of sites1e80.00.51.01.52.02.5comunication complexity (bits)1e8 3 rounds
log
star
alpha
randomize
0 5 10 15 20 25
number of rounds0.00.51.01.52.02.5comunication complexity (bits)1e7 k=10,000,000
log
star
alpha
randomize
0 5 10 15 20 25
number of rounds0.00.51.01.52.02.5comunication complexity (bits)1e8 k=100,000,000
log
star
alpha
randomize
Figure 1: First Row: The communication complexity v.s. num-
ber of sites under a fixed number of rounds
Second Row: The communication complexity v.s. number of
rounds under a fixed number of sites
7 Acknowledgements
This work is supported by National Natural Science Foundation of
China No. 62276066, No. U2241212
4672KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Xiaoyi Zhu, Yuxiang Tian, & Zengfeng Huang.
References
[1]Noga Alon and Yossi Azar. 1989. Finding an approximate maximum. SIAM J.
Comput. 18, 2 (1989), 258â€“267.
[2]Daniel Apon, Jonathan Katz, and Alex J Malozemoff. 2013. One-round multi-party
communication complexity of distinguishing sums. Theoretical Computer Science
501 (2013), 101â€“108.
[3]Sepehr Assadi, Gillat Kol, and Zhijun Zhang. 2022. Rounds vs communication
tradeoffs for maximal independent sets. In 2022 IEEE 63rd Annual Symposium on
Foundations of Computer Science (FOCS). IEEE, 1193â€“1204.
[4]Mark Braverman and Rotem Oshman. 2015. On information complexity in the
broadcast model. In Proceedings of the 2015 ACM Symposium on Principles of
Distributed Computing. 355â€“364.
[5]Mark Braverman and Rotem Oshman. 2017. A rounds vs. communication trade-
off for multi-party set disjointness. In 2017 IEEE 58th Annual Symposium on
Foundations of Computer Science (FOCS). IEEE, 144â€“155.
[6]Joshua Brody, Amit Chakrabarti, Ranganath Kondapally, David P Woodruff,
and Grigory Yaroslavtsev. 2014. Beyond set disjointness: the communication
complexity of finding the intersection. In Proceedings of the 2014 ACM symposium
on Principles of distributed computing. 106â€“113.
[7]Joshua Brody, Amit Chakrabarti, Ranganath Kondapally, David P Woodruff,
and Grigory Yaroslavtsev. 2014. Certifying equality with limited interaction. In
Approximation, Randomization, and Combinatorial Optimization. Algorithms and
Techniques (APPROX/RANDOM 2014). Schloss Dagstuhl-Leibniz-Zentrum fuer
Informatik.
[8]Badrish Chandramouli, Suman Nath, and Wenchao Zhou. 2013. Supporting
distributed feed-following apps over edge devices. Proceedings of the VLDB
Endowment 6, 13 (2013), 1570â€“1581.
[9]Graham Cormode. 2013. The continuous distributed monitoring model. ACM
SIGMOD Record 42, 1 (2013), 5â€“14.
[10] Graham Cormode, Shanmugavelayutham Muthukrishnan, and Ke Yi. 2011. Algo-
rithms for distributed functional monitoring. ACM Transactions on Algorithms
(TALG) 7, 2 (2011), 1â€“20.
[11] Olivier Devillers. 1992. Randomization yields simple ğ‘œ(ğ‘›logâˆ—ğ‘›)algorithms
for difficultğœ”(n) problems. International Journal of Computational Geometry &
Applications 2, 01 (1992), 97â€“111.
[12] Danny Dolev and TomÃ¡s Feder. 1989. Multiparty communication complexity. IBM
Thomas J. Watson Research Division.
[13] JÃ¼rgen Forster, Niels Schmitt, Hans Ulrich Simon, and Thorsten Suttorp. 2003.
Estimating the optimal margins of embeddings in euclidean half spaces. Machine
Learning 51 (2003), 263â€“281.
[14] Dawei Huang, Seth Pettie, Yixiang Zhang, and Zhijun Zhang. 2021. The com-
munication complexity of set intersection and multiple equality testing. SIAM J.
Comput. 50, 2 (2021), 674â€“717.
[15] Zengfeng Huang, Ke Yi, and Qin Zhang. 2019. Randomized algorithms for
tracking distributed count, frequencies, and ranks. Algorithmica 81, 6 (2019),
2222â€“2243.
[16] Philo Juang, Hidekazu Oki, Yong Wang, Margaret Martonosi, Li Shiuan Peh,
and Daniel Rubenstein. 2002. Energy-efficient computing for wildlife tracking:
Design tradeoffs and early experiences with ZebraNet. In Proceedings of the 10th
international conference on Architectural support for programming languages and
operating systems. 96â€“107.
[17] Ram Keralapura, Graham Cormode, and Jeyashankher Ramamirtham. 2006.
Communication-efficient distributed monitoring of thresholded counts. In Pro-
ceedings of the 2006 ACM SIGMOD international conference on Management of
data. 289â€“300.
[18] Nati Linial and Adi Shraibman. 2009. Learning complexity vs communication
complexity. Combinatorics, Probability and Computing 18, 1-2 (2009), 227â€“245.
[19] Samuel R Madden, Michael J Franklin, Joseph M Hellerstein, and Wei Hong. 2005.
TinyDB: an acquisitional query processing system for sensor networks. ACM
Transactions on database systems (TODS) 30, 1 (2005), 122â€“173.
[20] Noam Nisan. 1993. The communication complexity of threshold gates. Combina-
torics, Paul Erdos is Eighty 1 (1993), 301â€“315.
[21] Mert Saglam and GÃ¡bor Tardos. 2013. On the communication complexity of sparse
set disjointness and exists-equal problems. In 2013 IEEE 54th Annual Symposium
on Foundations of Computer Science. IEEE, 678â€“687.
[22] Jochen Schiller and AgnÃ¨s Voisard. 2004. Location-based services. Elsevier.
[23] Emanuele Viola. 2015. The communication complexity of addition. Combinatorica
35 (2015), 703â€“747.
[24] David P Woodruff and Qin Zhang. 2013. When distributed computation does not
help. CoRR, abs/1304.4636 5 (2013).
[25] Hao Wu, Junhao Gan, and Rui Zhang. 2020. Learning based distributed tracking.
InProceedings of the 26th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining. 2040â€“2050.A Proof in Section 3
Lemma A.1 (Lemma 3.1 Restatement). An algorithm for the
Exact DTC with threshold Ëœğ‘=ğ‘‚(ğ‘˜)that communicates ğ¶ğ¶bits inğ‘Ÿ
rounds implies an algorithm for the Exact DTC with general ğ‘that
communicates ğ¶ğ¶+ğ‘‚
ğ‘˜log
ğ‘
ğ‘˜
bits in(ğ‘Ÿ+1)rounds.
Proof. We assume thatğ‘
ğ‘˜is an integer without loss of general-
ity, otherwise replacing it by âŒŠğ‘
ğ‘˜âŒ‹we can get the same result up to
a constant. By Euclidâ€™s division lemma, the counter of each site ğ‘›ğ‘–
can be interpreted as ğ‘›ğ‘–=ğ‘ğ‘–Â·ğ‘
ğ‘˜+ğ‘ğ‘–for someğ‘ğ‘–âˆˆ
0,ğ‘
ğ‘˜
. Thus
we can encode each ğ‘ğ‘–withinğ‘‚
log
ğ‘
ğ‘˜
bits.
To solve the problem for general ğ‘, we first run the algorithm
forğ‘=ğ‘‚(ğ‘˜)when each site holds their ğ‘ğ‘–and the threshold is ğ‘˜.
If the algorithm outputs 1, we must have that
ğ‘˜âˆ‘ï¸
ğ‘–=1ğ‘›ğ‘–>ğ‘
ğ‘˜ğ‘˜âˆ‘ï¸
ğ‘–=1ğ‘ğ‘–>ğ‘.
If the algorithm outputs 0, we let each site send their ğ‘ğ‘–andğ‘ğ‘–to
the coordinator. The correctness comes from the exact computation
and the communication is bound by
ğ‘˜âˆ‘ï¸
ğ‘–=1(log(ğ‘ğ‘–+1)+log(ğ‘ğ‘–+1))â‰¤ğ‘˜âˆ‘ï¸
ğ‘–=1ğ‘ğ‘–+ğ‘˜âˆ‘ï¸
ğ‘–=1logğ‘
ğ‘˜
+2ğ‘˜
â‰¤ğ‘‚
ğ‘˜logğ‘
ğ‘˜
.
â–¡
Lemma A.2 (Lemma 3.2 Restatement). An algorithm for the
Exact DTC with threshold Ëœğ‘=ğ‘‚(ğ‘˜)that communicates ğ¶ğ¶bits inğ‘Ÿ
rounds implies an algorithm for the Approximate DTC with general
ğ‘that communicates ğ¶ğ¶+ğ‘‚
ğ‘˜log
1
ğœ€
bits in(ğ‘Ÿ+1)rounds.
Proof. We assume thatğ‘
ğ‘˜is an integer without loss of general-
ity, otherwise replacing it by âŒŠğ‘
ğ‘˜âŒ‹we can get the same result up to
a constant. By Euclidâ€™s division lemma, the counter of each site ğ‘›ğ‘–
can be interpreted as
ğ‘›ğ‘–=ğ‘0
ğ‘–Â·ğ‘
ğ‘˜+ğ‘1
ğ‘–Â·ğ‘
2ğ‘˜+Â·Â·Â·+ğ‘ğ‘™
ğ‘–ğ‘
2ğ‘™ğ‘˜+ğ‘ğ‘–.
Notice that we have for all ğ‘—âˆˆ[1,ğ‘™],ğ‘ğ‘—
ğ‘–âˆˆ{0,1}. This is because if
ğ‘ğ‘—
ğ‘–â‰¥2, we can subtract 2 from ğ‘ğ‘—
ğ‘–and add 1 to ğ‘ğ‘—âˆ’1
ğ‘–. We choose ğ‘™
to be the smallest number such that1
2ğ‘™<ğœ€. It is easy to verify that
ğ‘™=ğ‘‚
1
ğœ€
andğ‘ğ‘–<ğœ€ğ‘
ğ‘˜.
To solve the problem for the relaxed problem, we first run the
algorithm for ğ‘=ğ‘‚(ğ‘˜)when each site holds their ğ‘0
ğ‘–and the
threshold is ğ‘˜. If the algorithm outputs 1, we must have that
ğ‘˜âˆ‘ï¸
ğ‘–=1ğ‘›ğ‘–>ğ‘
ğ‘˜ğ‘˜âˆ‘ï¸
ğ‘–=1ğ‘0
ğ‘–>ğ‘.
4673Distributed Thresholded Counting with Limited Interaction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
If the algorithm outputs 0, we let each site send their ğ‘ğ‘—
ğ‘–,ğ‘—âˆˆ[0,ğ‘™]
to the coordinator and then compute the value of
ğ‘˜âˆ‘ï¸
ğ‘–=1
ğ‘0
ğ‘–Â·ğ‘
ğ‘˜+ğ‘1
ğ‘–Â·ğ‘
2ğ‘˜+Â·Â·Â·+ğ‘ğ‘™
ğ‘–ğ‘
2ğ‘—ğ‘˜
.
If this value is less than (1âˆ’ğœ€)ğ‘, we output 0 and we output
1 otherwise. This is correct because: If the true sum is less than
(1âˆ’ğœ€)ğ‘, we must have that this value is also less than (1âˆ’ğœ€)ğ‘
and output correctly. Moreover, if the true sum is larger than ğ‘,
we must have that this value is larger than (1âˆ’ğœ€)ğ‘and we output
1 correctly:
ğ‘˜âˆ‘ï¸
ğ‘–=1
ğ‘0
ğ‘–Â·ğ‘
ğ‘˜+ğ‘1
ğ‘–Â·ğ‘
2ğ‘˜+Â·Â·Â·+ğ‘ğ‘™
ğ‘–ğ‘
2ğ‘—ğ‘˜
=ğ‘›âˆ‘ï¸
ğ‘–=1ğ‘›ğ‘–âˆ’ğ‘˜âˆ‘ï¸
ğ‘–=1ğ‘ğ‘–
>ğ‘âˆ’ğ‘˜âˆ‘ï¸
ğ‘–=1ğœ€ğ‘
ğ‘˜=(1âˆ’ğœ€)ğ‘.
For the communication complexity, in the last round, we send
ğ‘˜âˆ‘ï¸
ğ‘–=1Â©Â­
Â«ğ‘™âˆ‘ï¸
ğ‘—=0log(ğ‘ğ‘—
ğ‘–+1)ÂªÂ®
Â¬â‰¤ğ‘˜âˆ‘ï¸
ğ‘–=1
ğ‘0
ğ‘–+1
+ğ‘˜âˆ‘ï¸
ğ‘–=1Â©Â­
Â«ğ‘™âˆ‘ï¸
ğ‘—=1log(ğ‘ğ‘—
ğ‘–+1)ÂªÂ®
Â¬
â‰¤2ğ‘˜+ğ‘˜âˆ‘ï¸
ğ‘–=1Â©Â­
Â«ğ‘™âˆ‘ï¸
ğ‘—=11ÂªÂ®
Â¬â‰¤ğ‘‚
ğ‘˜log1
ğœ€
.
â–¡
B Proof in Section 4.3
We will first prove the lower bound of the value of the threshold by
induction. By the definition of the ğ‘“(ğ‘£,ğ‘¤)function, we can prove
the following lemma.
Lemma B.1 (Property of ğ‘“(ğ‘£,ğ‘¤)).For the function ğ‘“(ğ‘£,ğ‘¤)de-
fined in Section 2, we have ğ‘“(ğ‘£,ğ‘¤)=ğ‘“(ğ‘£âˆ’1,ğ‘“(ğ‘£,ğ‘¤âˆ’1)).
Proof. By the definition,
ğ‘“(ğ‘£,ğ‘¤)=logğ‘£timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘“(ğ‘£,ğ‘¤+1)),ğ‘“(ğ‘£,0)=1
logğ‘£timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘¥)=min{ğ‘§|ğ‘§times
z                               }|                               {
logğ‘£âˆ’1timesz}|{
âˆ—Â·Â·Â·âˆ—(Â·Â·Â·logğ‘£âˆ’1timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘¥))â‰¤1},
For valueğ‘¥, we must have that
ğ‘¥=ğ‘“(ğ‘£,logğ‘£+1timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘¥)).
Therefore,
ğ‘“(ğ‘£,ğ‘¤)=ğ‘“(ğ‘£âˆ’1,logğ‘£timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘“(ğ‘£,ğ‘¤)))=ğ‘“(ğ‘£âˆ’1,ğ‘“(ğ‘£,ğ‘¤âˆ’1)).
â–¡
Lemma B.2 (Lower Bound of Value of Thresholds). For the
grids constructed in 4.3, we have
ğ‘¡ğ‘™
ğ‘—â‰¥ğ‘“(ğ‘™âˆ’1,ğ‘—),âˆ€ğ‘™âˆˆ[1,ğ‘Ÿâˆ’1].Proof. Level 1:ğ‘¡1
ğ‘—â‰¥ğ‘“(0,ğ‘—)
Note that this clearly holds for ğ‘¡1
1. Assume this holds for ğ‘¡1
ğ‘—. Then
forğ‘¡1
ğ‘—+1, we shall have â„1,0
ğ‘—=ğ‘¡0
ğ‘¡1
ğ‘—=ğ‘¡1
ğ‘—and thus
ğ‘¡1
ğ‘—+1=ğ‘¡1
ğ‘—+exp
ğ‘¡1
ğ‘—
â‰¥exp
ğ‘¡1
ğ‘—
â‰¥exp(ğ‘“(0,ğ‘—))=ğ‘“(0,ğ‘—+1).
We then consider the induction. Assume that we already have
that at Level l:ğ‘¡ğ‘™
ğ‘—â‰¥ğ‘“(ğ‘™âˆ’1,ğ‘—), then we would like to prove that
atLevel i+1:ğ‘¡ğ‘™+1
ğ‘—â‰¥ğ‘“(ğ‘™,ğ‘—).
It is again easy to show that this holds for ğ‘¡ğ‘™+1
1. Assume this holds
forğ‘¡ğ‘™+1
ğ‘—. Then forğ‘¡ğ‘™+1
ğ‘—+1, we shall have â„ğ‘™+1,0
ğ‘—=â„ğ‘™,0
ğ‘¡ğ‘™+1
ğ‘—and thus
ğ‘¡ğ‘™+1
ğ‘—+1=ğ‘¡ğ‘™+1
ğ‘—+exp
â„ğ‘™+1,0
ğ‘—
â‰¥ğ‘¡ğ‘™+1
ğ‘—+exp
â„ğ‘™,0
ğ‘¡ğ‘™+1
ğ‘—
â‰¥1
2ğ‘¡ğ‘™
ğ‘¡ğ‘™+1
ğ‘—+1
â‰¥1
2ğ‘“
ğ‘™âˆ’1,ğ‘¡ğ‘™+1
ğ‘—+1
â‰¥ğ‘“
ğ‘™âˆ’1,ğ‘¡ğ‘™+1
ğ‘—
â‰¥ğ‘“(ğ‘™âˆ’1,ğ‘“(ğ‘™,ğ‘—))=ğ‘“(ğ‘™,ğ‘—+1).
â–¡
With Lemma B.2, we prove by induction and get the final lemma.
Lemma B.3 (Lemma 4.5 Restatement). For the grids constructed
in Section 4.3, we have
ğ‘‘ğ‘™â‰¤logğ‘™timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘)+1,âˆ€ğ‘™âˆˆ[1,ğ‘Ÿâˆ’1].
Proof. Note that we have ğ‘‘0=ğ‘˜andğ‘‘ğ‘™+1=minn
ğ‘—|ğ‘¡ğ‘™+1
ğ‘—>ğ‘‘ğ‘™o
.
AtLevel 1:ğ‘‘1â‰¤logâˆ—(ğ‘)+1.We have that ğ‘=ğ‘‘0â‰¥ğ‘¡1
ğ‘‘1âˆ’1â‰¥
ğ‘“(0,ğ‘‘1âˆ’1),ğ‘‘1â‰¤logâˆ—(ğ‘)+1.
We then consider the induction. Assume that we already have
that at Levelğ‘™:ğ‘‘ğ‘™â‰¤logğ‘™timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘)+1. We would like to prove that
atLevelğ‘™+1:ğ‘‘ğ‘™+1â‰¤logğ‘™+1timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘)+1.
We have that
logğ‘™timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘)+1â‰¥ğ‘‘ğ‘™â‰¥ğ‘¡ğ‘™+1
ğ‘‘ğ‘™+1âˆ’1â‰¥ğ‘“(ğ‘™,ğ‘‘ğ‘™+1âˆ’1),
ğ‘‘ğ‘™+1â‰¤logğ‘™+1timesz}|{
âˆ—Â·Â·Â·âˆ—Â©Â­Â­Â­
Â«logğ‘™timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘)+1ÂªÂ®Â®Â®
Â¬+1â‰¤logğ‘™+1timesz}|{
âˆ—Â·Â·Â·âˆ—(ğ‘)+1.
â–¡
We then prove the property of the grids.
Lemma B.4 (Lemma 4.6 Restatement). For the grids constructed
in Section 4.3, any 0â‰¤ğ‘™â‰¤ğ›¼(ğ‘˜),ğ›¼in the layerğ‘™,ğ›½in the layerğ‘™+1
andğ›¼belongs to grid ğ›½,we have
ğ›¼âˆ’â„ğ‘™+1,ğ‘™
ğ›½â‰¤â„ğ‘™,0
ğ›¼âˆ’â„ğ‘™+1,0
ğ›½.
Proof. By definition, we have that ğ›¼=â„ğ‘™,ğ‘™
ğ›¼. Therefore, it is
sufficient for us to prove
â„ğ‘™,ğ‘—
ğ›¼âˆ’â„ğ‘™+1,ğ‘—
ğ›½â‰¤â„ğ‘™,ğ‘—âˆ’1
ğ›¼âˆ’â„ğ‘™+1,ğ‘—âˆ’1
ğ›½,âˆ€1â‰¤ğ‘—â‰¤ğ‘™.
4674KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Xiaoyi Zhu, Yuxiang Tian, & Zengfeng Huang.
Ifâ„ğ‘™,ğ‘—
ğ›¼âˆ’â„ğ‘™+1,ğ‘—
ğ›½=0, the bound holds trivially. Therefore, we consider
the case when â„ğ‘™,ğ‘—
ğ›¼âˆ’â„ğ‘™+1,ğ‘—
ğ›½â‰¥1. Sinceğ›¼belongs to grid ğ›½, we must
have that
â„ğ‘™,ğ‘—
ğ›¼âˆ’â„ğ‘™+1,ğ‘—
ğ›½â‰¤exp 
â„ğ‘—,0
â„ğ‘™+1,ğ‘—
ğ›½!
=exp
â„ğ‘™+1,0
ğ›½
.
On the other hand, we have that
â„ğ‘™,ğ‘—âˆ’1
ğ›¼âˆ’â„ğ‘™+1,ğ‘—âˆ’1
ğ›½=ğ‘¡ğ‘—âˆ’1
â„ğ‘™,ğ‘—âˆ’1
ğ›¼âˆ’ğ‘¡ğ‘—âˆ’1
â„ğ‘™+1,ğ‘—âˆ’1
ğ›½â‰¥ğ‘¡ğ‘—âˆ’1
â„ğ‘™+1,ğ‘—âˆ’1
ğ›½+1âˆ’ğ‘¡ğ‘—âˆ’1
â„ğ‘™+1,ğ‘—âˆ’1
ğ›½
â‰¥exp 
â„ğ‘—âˆ’1,0
â„ğ‘™+1,ğ‘—âˆ’1
ğ›½!
=exp
â„ğ‘™+1,0
ğ›½
.
â–¡
C Proof in Section 5
Lemma C.1 (Lemma 5.1 Restatement). For the sampling proce-
dure shown in algorithm 5 and 6, if the sum ğ‘›=Ãğ‘˜
ğ‘–=1ğ‘›ğ‘–â‰¤12ğ‘ğ‘,
with probability at least 1âˆ’2ğ›¿, the procedure will output 0 when
ğ‘›â‰¤ğ‘and uses less than 24ğ¶ğ¶bits for communication. Moreover,
â€¢Forlog
2
ğ›¿
<ğ¶ğ¶<ğ‘Â·log
2
ğ›¿
, with probability at least 1âˆ’ğ›¿,
the procedure will output 1 when ğ‘›>12ğ‘ğ‘Â·log(2
ğ›¿)
ğ¶ğ¶.
â€¢Forğ¶ğ¶â‰¥ğ‘Â·log
2
ğ›¿
, with probability at least 1âˆ’ğ›¿, the
procedure will output 1 when ğ‘›>12ğ‘.
We prove the two parts of the Lemma 5.1 separately.
Proof of Lemma 5.1(first part). Forlog
2
ğ›¿
<ğ¶ğ¶<ğ‘Â·log
2
ğ›¿
,
we set the sampling probability being ğ‘=ğ¶ğ¶
ğ‘ğ‘and the threshold
ğ‘‡=ğ¶ğ¶
ğ‘+3 log
2
ğ›¿
.
Communication Cost. Since the actual sum is ğ‘›â‰¤12ğ‘ğ‘, we
shall have that the sampled number Ëœğ‘›âˆ¼Binomial
ğ‘›,ğ¶ğ¶
ğ‘ğ‘
. Thus,
the expectation of Ëœğ‘›is less than 12ğ¶ğ¶. Applying the Chernoff Bound
gives us
Pr[Ëœğ‘›â‰¥24ğ¶ğ¶]<Pr[|Ëœğ‘›âˆ’ğ¸[Ëœğ‘›]|â‰¥12ğ¶ğ¶]<2 exp(âˆ’4ğ¶ğ¶)
<2 exp
âˆ’4 log2
ğ›¿
=2ğ›¿
24
<ğ›¿.
This shows that our sampled value will not exceed 24ğ¶ğ¶with
high probability, which controls our communication cost.
Whenğ‘›â‰¤ğ‘.Since the sum is less than or equal to ğ‘, we shall
have expectation of Ëœğ‘›is less thanğ¶ğ¶
ğ‘. By Chernoff bound,
Pr[Ëœğ‘›â‰¥ğ‘‡]<Pr
|Ëœğ‘›âˆ’ğ¸[Ëœğ‘›]|â‰¥3 log2
ğ›¿
<2 expÂ©Â­Â­
Â«âˆ’Â©Â­Â­
Â«3ğ‘log
2
ğ›¿
ğ¶ğ¶ÂªÂ®Â®
Â¬2
ğ¶ğ¶
3ğ‘ÂªÂ®Â®
Â¬.
Forğ¶ğ¶<ğ‘Â·log
2
ğ›¿
, we have that
Pr[Ëœğ‘›â‰¥ğ‘‡ğ‘–]<2 expÂ©Â­Â­
Â«âˆ’Â©Â­Â­
Â«9ğ‘log
2
ğ›¿
ğ¶ğ¶ÂªÂ®Â®
Â¬ğ¶ğ¶
ğ‘ÂªÂ®Â®
Â¬<ğ›¿.This shows that with probability at least 1âˆ’ğ›¿, we will not screen
out the sum which is less than ğ‘.
Whenğ‘›>3ğ‘‡Â·ğ‘ğ‘
ğ¶ğ¶.We now have the expectation of Ëœğ‘›is larger
than 3ğ‘‡. By Chernoff Bound,
Pr[Ëœğ‘›â‰¤ğ‘‡]<Pr[|Ëœğ‘›âˆ’ğ¸[Ëœğ‘›]|â‰¥2ğ‘‡]<2 exp 
âˆ’2
32
ğ‘‡!
<2 exp
âˆ’4
3Â·log2
ğ›¿
<ğ›¿,
This shows that with probability at least 1âˆ’ğ›¿, cases where the
sum is larger than 3ğ‘‡Â·ğ‘ğ‘
ğ¶ğ¶will be filtered out. Note that
3ğ‘‡Â·ğ‘ğ‘
ğ¶ğ¶=3ğ‘+9ğ‘ğ‘Â·log
2
ğ›¿
ğ¶ğ¶<12ğ‘ğ‘Â·log
2
ğ›¿
ğ¶ğ¶.
â–¡
For the second part, we have
Proof of Lemma 5.1(second part). The proof is the same ex-
cept that now we have the sampling probability ğ‘=log(2
ğ›¿)
ğ‘, and
ğ‘‡=4 log
2
ğ›¿
.
Communication Cost. Since the actual sum is ğ‘›â‰¤12ğ‘ğ‘, we
shall have that the sampled number Ëœğ‘›âˆ¼Binomial
ğ‘›,log(2
ğ›¿)
ğ‘
. Thus,
the expectation of Ëœğ‘›is less than 12ğ‘Â·log
2
ğ›¿
â‰¤12ğ¶ğ¶. Applying
the Chernoff Bound gives us
Pr[Ëœğ‘›â‰¥24ğ¶ğ¶]<Pr[|Ëœğ‘›âˆ’ğ¸[Ëœğ‘›]|â‰¥12ğ¶ğ¶]<2 exp(âˆ’4ğ¶ğ¶)
<2 exp
âˆ’12 log2
ğ›¿
=2ğ›¿
212
<ğ›¿.
This shows that our sampled value will not exceed 24ğ¶ğ¶with
high probability, which controls our communication cost.
Whenğ‘›â‰¤ğ‘.Since the sum is less than or equal to ğ‘, we shall
have expectation of Ëœğ‘›is less than log
2
ğ›¿
. By Chernoff bound,
Pr[Ëœğ‘›â‰¥ğ‘‡]<Pr
|Ëœğ‘›âˆ’ğ¸[Ëœğ‘›]|â‰¥3 log2
ğ›¿
<2 expÂ©Â­Â­
Â«âˆ’32log
2
ğ›¿
3ÂªÂ®Â®
Â¬<ğ›¿.
This shows that with probability at least 1âˆ’ğ›¿, we will not screen
out the sum which is less than or equal to ğ‘.
Whenğ‘›>3ğ‘‡Â·ğ‘
log(2
ğ›¿)=12ğ‘.We now have the expectation of
Ëœğ‘›is larger than 3ğ‘‡. By Chernoff Bound,
Pr[Ëœğ‘›â‰¤ğ‘‡]<Pr[|Ëœğ‘›âˆ’ğ¸[Ëœğ‘›]|â‰¥2ğ‘‡]<2 exp 
âˆ’2
32
ğ‘‡!
<2 exp
âˆ’4
3Â·log2
ğ›¿
<ğ›¿,
This shows that with probability at least 1âˆ’ğ›¿, cases where the
sum is larger than 12ğ‘will be filtered out.
â–¡
4675