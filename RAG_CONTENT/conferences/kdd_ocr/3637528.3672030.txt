MulSTE: A Multi-view Spatio-temporal Learning Framework with
Heterogeneous Event Fusion for Demand-supply Prediction
Li Lin
Southeast University
Nanjing, China
linli321@seu.edu.cnZhiqiang Lu
Southeast University
Nanjing, China
lu_zhiqiang@seu.edu.cnShuai Wangâˆ—
Southeast University
Nanjing, China
shuaiwang@seu.edu.cnYunhuai Liu
Peking University
Beijing, China
yunhuai.liu@pku.edu.cn
Zhiqing Hong
Rutgers University
Piscataway, USA
zhiqing.hong@rutgers.eduHaotian Wang
JD Logistics
Beijing, China
wanghaotian18@jd.comShuai Wang
Southeast University
Nanjing, China
shuaiwang_iot@seu.edu.cn
Abstract
Recently, integrated warehouse and distribution logistics systems
are widely used in E-commerce industries to adjust to constantly
changing customer demands. It makes the prediction of purchase
demand and delivery supply capacity a crucial problem to stream-
line operations and improve efficiency. The interaction between
such demand and supply not only relies on their economic relation-
ships but also on consumer psychology caused by daily events, such
as epidemics, promotions, and festivals. Although existing studies
have made great efforts in the joint prediction of demand and supply
considering modeling the demand-supply interactions, they seldom
refer to the impacts of diverse events. In this work, we propose
MulSTE, a Multi-view Spatio-Temporal learning framework with
heterogeneous Event fusion. Firstly, an Event Fusion Representa-
tion (EFR) module is designed to fuse the textual, numerical, and
categorical heterogeneous information for emergent and periodic
events. Secondly, a Multi-graph Adaptive Convolution Recurrent
Network (MGACRN) is developed as the spatio-temporal encoder
(ST-Encoder) to capture the evolutional features of demand, supply,
and events. Thirdly, the Event Gated Demand-Supply Interaction
Attention (EGIA) module is designed to model the demand-supply
interactions during events. The evaluations are conducted on two
real-world datasets collected from JD Logistics and public web-
sites. The experimental results show that our method outperforms
state-of-the-art baselines in various metrics.
CCS Concepts
â€¢Information systems â†’Spatial-temporal systems.
âˆ—Shuai Wang is the corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672030Keywords
Demand-supply Prediction, Event Representation, Graph Neural
Network, Spatio-temporal Graphs
ACM Reference Format:
Li Lin, Zhiqiang Lu, Shuai Wang, Yunhuai Liu, Zhiqing Hong, Haotian Wang,
and Shuai Wang. 2024. MulSTE: A Multi-view Spatio-temporal Learning
Framework with Heterogeneous Event Fusion for Demand-supply Predic-
tion. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain.
ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3672030
1 Introduction
Recently, warehouse-distribution integration (WDI) [ 14] is a new
logistics mode. It provides a combination of capabilities, speed,
accountability, and accuracy in warehouse and distribution op-
erations, which requires the ability to predict future demand for
logistics resources and the flexible adjustment of supply capacity.
The demand-supply balance is the goal many enterprises strive to
achieve, while the complicated interactions between demand and
supply make it a hard issue. In real-world scenarios, the relationship
between demand and supply is vulnerable to diverse daily events
(such as epidemics, promotions, festivals., etc.).
Fig. 1 shows how the purchase demand and delivery supply in-
teract with each other in a WDI system considering the impacts of
events with heterogeneous data, which can be divided into emer-
gent events and periodic events. Specifically, the WDI system di-
vides a city into various service regions and establishes a delivery
station for each region. Each delivery station is responsible to guar-
antee the packages arrive on time, where each package corresponds
to a userâ€™s order in the E-commerce platform. This process exhibits
a dynamic balance between demand and supply. However, during
daily events, consumersâ€™ purchase demand grows when their hoard-
ing intent is stimulated by emergent events or when the prices are
attractive during promotions. And when the delivery supply capac-
ity is far behind the demand, the increasing delay of distribution
would prevent consumers buy more goods on the platform. Be-
sides, the spatial relations of different regions vary a lot, e.g. the
transportation distance, connectivity, economic functions and user
profiles. Therefore, it is critical to predict the purchase demand and
delivery supply for each region to guide the resource distribution
of WDI systems under diverse events.
 
1781
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Li Lin et al.
Emergent Events Periodic Events
Textual Type
 Numerical Type Categorical Type
&
Events with Heterogeneous Data 
Users
Region iE-commerce 
WDI Delivery Station Warehouse
Distance -aware
 Neighbor -aware
 Type -similarity
 Crowd -similarityRegional Relations 
Online Purchase Demand Offline Delivery Supply
Orders Packages
Impact Direction
Purchase Demand
 Delivery Supply
Figure 1: Demand-supply-event relations across regions in
E-commerce WDI scenario.
The prediction of demand and supply has attracted attention
from researchers in many fields, such as traffics [ 5,26], labor mar-
kets [ 10], and e-commerce [ 23,31]. These studies deal with the
auto-regressive demand and supply sequences independently, fo-
cus on supply-demand gap prediction, or jointly predict demand
and supply as a multi-task problem without considering the change-
able interaction between demand and supply caused by daily events.
There are also several studies investigating the impacts of events
on demand prediction. They focus on demand prediction during a
specific event [ 21] or leverage the daily embedding based on world
events to forecast usersâ€™ behavior on e-commerce platforms [ 15].
However, how to understand the interaction between demand and
supply during diverse events is still an open issue.
To fill in the gap, we aim to design a joint prediction framework
of purchase demand and delivery supply for E-commerce goods
considering the event impacts. Due to diverse events consisting of
heterogeneous data, i.e. text, numeric, and categories, which affect
the evolution of demand and supply separately, and the spatio-
temporal interactions between them. Thus, solving the problem of
demand-supply prediction under events faces the following chal-
lenges: (i) Unified representation learning for events with het-
erogeneous data. Heterogeneous event data describe varied daily
events, including semantics, severity, trigger time, and frequency
of events. It is challenging to capture the unified representation of
all events and further adapt the information to the demand-supply
prediction task. (ii) Extracting the spatio-temporal relations
of demand, supply, and events. Different temporal dependency
patterns are exhibited by both demand and supply at various time
periods, i.e. emergent, periodic, and normal periods. Additionally,
inter-regional relations may have varying degrees of relative im-
portance when modeling demand, supply, and event data.
To address these challenges, we propose MulSTE1, a multi-view
spatio-temporal learning framework with heterogeneous event fu-
sion for demand-supply prediction. It follows the Encoder-Decoder
framework for sequential forecasting, which consists of two key
components: (i) Event Fusion Representation. It is designed
to conduct a unified representation learning fusing heterogeneous
event data (EFR). For textual events, we first fine-tune a pre-trained
language model and then apply it to produce semantic embeddings
1Our implementation is available at https://github.com/mulste-kdd2024/MulSTE.of daily events. For numerical and categorical events, we straightly
use a linear embedding layer to capture the information about
the severity, trigger time, and frequency. (ii) Multiple Spatio-
temporal Encoders. To construct the spatio-temporal relationship
of purchase demand, delivery supply, and events, we design three
parallel encoders following the gated recurrent units (GRU) form.
We name the basic cell with Multi-graph Adaptive Convolution Re-
current Unit (MGACRU). In MGACRU, we adopt the Multi-graph
Adaptive Convolution (MGAC) module to the gating mechanism,
acting as the update and reset gates by capturing the spatial features
in each time step of history sequences. While the temporal features
can be recurrently modeled by connected MGACRUs. Besides, to
further model the demand-supply interactions, we design an Event
Gated Demand-Supply Interaction Attention (EGIA) module com-
posed of a self-attention to model the demand-supply correlations
and a cross-attention to model the event-related interactions of
demand and supply. Finally, for the decoders, we use two fully
connected layers to transmit the interacted demand and supply
representations from spatio-temporal encoders into multi-step pre-
dictions concurrently. In summary, our key contributions are as
follows:
â€¢To the best of our knowledge, we are the first to jointly
predict demand and supply under events. It considers the
influence of heterogeneous events on the joint prediction of
demand and supply, especially the effects on the demand-
supply interactions.
â€¢A novel multi-graph adaptive convolution recurrent net-
work is designed to capture the spatio-temporal relations of
demand, supply, and events, with the multi-graph adaptive
convolution module acting as the update and reset gates. The
Event Gated Demand-Supply Interaction Attention module
is introduced to handle the diversified influence of events
on demand-supply interactions.
â€¢We evaluate MulSTE on two real-world datasets in Shanghai
and Zhengzhou from JD Logistics, including 353 delivery
stations, 25.7 million users, 339.24 million orders, and 31
periodic event categories. For emergent events, 13.13 thou-
sand news titles are collected from public webs. Experiments
show that the performance of MulSTE outperforms the state-
of-the-art methods by 24.50%and12.68%improvement in
demand and supply on average.
2 Related Work
2.1 Demand and Supply Prediction
The prediction of demand and supply is a widely studied problem
that has various applications. Some studies have made concerns
about user-level purchase behavior predictions [ 12,13], platform-
level [ 23] and city-level purchase demand prediction [ 31]. Besides E-
commerce applications, demand prediction is also an important task
in many other fields, such as talent market [ 10], bike-sharing [ 19],
ride-hailing [ 5,26,35], multi-transportation [ 34,44], and first-
aid [28]. We noticed that there are only a few demand-supply joint
prediction works [ 5,10,26] and the study [ 10] is the only one using
the interactive information of demand and supply to realize simul-
taneously prediction of demand and supply, but it cannot cope with
 
1782MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
2021-01 2021-022021-03 2021-04 2021-05 2021-06 2021-07 2021-08 2021-09
Date0102030405060Emergent Event IndicatorsIndicator1
Indicator2
0200040006000800010000
Demand/Supply VolumeDemand
Supply
spring festivalmid-year promotion
(a) Normal+Periodic
2022-01 2022-022022-03 2022-04 2022-05 2022-06 2022-07 2022-08 2022-09
Date0102030405060Emergent Event IndicatorsIndicator1
Indicator2
0200040006000800010000
Demand/Supply VolumeDemand
Supply
spring festivalmid-year promotion (b) Normal+Periodic+Emergent
Figure 2: The purchase demand and delivery supply over time
when periodic events occur (a), and when periodic and emergent
events occur (b)2.
0
100020003000400050006000700080009000
Demand0500100015002000250030003500SupplyEmergent
Periodic
Normal(a) Event types
0
10002000300040005000600070008000900010000
Demand0200040006000800010000SupplyRegion 0
Region 1
Region 2 (b) Regions
Figure 3: The demand-supply distribution for different
event types (a), and for different regions (b).
the occurrence of events and the spatio-temporal information. Re-
cently, some works in traffic scenarios have combined graph neural
networks (e.g., GCN [ 16], GAT [ 25], etc.) with sequential meth-
ods to capture spatio-temporal relationship. Graph WaveNet [ 33],
MTGNN [ 32] combine the GNN with temporal convolutional net-
work structure, while DCRNN [ 18], AGCRN [ 1], DGCRN [ 17], T-
GCN [ 41] combine the GCN with recurrent neural networks, only a
few works exploit fixed/static multi-view graph structures [ 9,38] to
model diverse spatial relationships. However, we aim to make the
joint prediction of both demand and supply, where the interactions
of demand and supply become a critical challenge.
2.2 Time Series Prediction under Events
Research on time series prediction under events is diverse corre-
sponding to varied event data types. Some studies focus on mod-
eling time series without incorporating external event data. They
apply the Bayesian meta-learning techniques to capture traffic flow
dynamics [ 39,40]. In many scenarios, external knowledge about
events would prompt the understanding of time-series forecasting.
Some researchers leverage textual event data from Tweets or Wiki
to apply the semantic information to assist in predicting urban
traffic flow and E-commerce consumer demand [ 8,15]. Besides,
daily event statistics, like the infectivity index during Covid-19
can be employed to aid in predicting E-commerce consumer de-
mand [ 36]. The categorical event data are also commonly used to
capture abnormal patterns of the time series and facilitate predic-
tion [ 6,21,27] by leveraging the effects of different types of events.
However, the studies considering only a single data type of event
have some limitations, such as the lack of spatial granularity in tex-
tual data, the lack of semantics in numerical data, and the inability
of categorical data to reflect event evolution. Therefore, it is crucial
to make a fusion of heterogeneous event data to better understand
the influence of such events.
3 Preliminaries and Definitions
3.1 Data Investigation
We collect demand and supply data in Shanghai and Zhengzhou
from JDL, one of the most popular E-commerce and logistics com-
panies in WDI mode. A total of 339.24 million orders in 353 delivery
stations and 25.7 million users are covered in the datasets. Three
types of events are considered in this work: public health emergen-
cies (Covid-19), festivals, and promotions. For textual events, we
extracted the descriptions of from news websites3and obtained
13.13 thousand news text titles. Besides the textual data, we alsogather the numerical emergent event data from the statistical webs4.
For periodic events, we collect 31 events including 20 festivals and
11 promotions recorded by the JD public webs5.
As shown in Fig. 2, there are demand-supply time series in Shang-
hai from 1/1 to 8/31 in 2021 and 2022. Fig. 2a shows that demand
and supply are usually consistent during normal scenarios. Even
when periodic events happen, there is a slight delay in the sup-
ply curve compared to the demand, it is still acceptable to learn
the subtle demand-supply fluctuation. However, when considering
the emergent events, as shown in Fig. 2b, we find the temporary
increase of supply cannot satisfy the surging demand and would
result in a decrease in purchase demand. We further analyze the dis-
tributions of demand-supply values under different event types and
regions, as shown in Fig. 3. We find that during emergencies, the
demand-supply values more easily exceed expectations and the val-
ues vary in different regions. It motivates us to construct multi-view
graphs to describe the relations of regions from the perspectives of
distance, connectivity, type-similarity, and crowd-similarity.
3.2 Definitions
Definition 1 (Multi-view Graph). Given a city, which is di-
vided intoğ‘service regions (delivery stations), we define the multi-
view graph set ğºâˆ—=âˆªn
ğº(ğ‘™)o
. Each graph ğº(ğ‘™)=(ğ‘‰,ğ‘ˆ(ğ‘™),ğ´(ğ‘™)),ğ‘™âˆˆ
{1,...,ğ¿}, whereğ‘‰is the set of regions and ğ´(ğ‘™)âˆˆğ‘…|ğ‘‰|Ã—|ğ‘‰|is the ad-
jacency matrix of ğ‘™ğ‘¡â„graph,ğ¿is the total number of views to represent
the static spatial relationships of different regions.
Definition 2 (Demand and Supply Seqence). In the time step
ğ‘¡, the purchase demand ğ‘‘ğ‘¡and delivery supply ğ‘ ğ‘¡are defined as the
order counts of requests and deliveries respectively. Then the demand
sequenceğ·and supply sequence ğ‘†overğ‘regions can be represented
asğ·={ğ‘‘1,ğ‘‘2,...,ğ‘‘ğ‘‡}andğ‘†={ğ‘ 1,ğ‘ 2,...,ğ‘ ğ‘‡}, whereğ‘‘ğ‘¡,ğ‘ ğ‘¡âˆˆğ‘…ğ‘,
ğ‘‡is the length of the sequence.
Definition 3 (Event Seqence). The heterogeneous event se-
quence is defined as textual type ğ¸ğ‘¢=
ğ‘’ğ‘¢
1,ğ‘’ğ‘¢
2,...,ğ‘’ğ‘¢
ğ‘‡	, numerical
typeğ¸ğ‘›=
ğ‘’ğ‘›
1,ğ‘’ğ‘›
2,...,ğ‘’ğ‘›
ğ‘‡	, categorical type ğ¸ğ‘=
ğ‘’ğ‘
1,ğ‘’ğ‘
2,...,ğ‘’ğ‘
ğ‘‡	,
whereğ‘’ğ‘¢
ğ‘¡âˆˆSğ‘€represents the ğ‘€pieces of text containing emergent
event in time step ğ‘¡,ğ‘’ğ‘›
ğ‘¡âˆˆRğ‘represents the number of emergent
2Indicators are the number of outbreak locations (Indicator1, Ã—100), risk locations
(Indicator2,Ã—10) of Covid-19.
3https://www.shanghai.gov.cn/, https://www.zhengzhou.gov.cn/
4https://wsjkw.sh.gov.cn/, https://wjw.zhengzhou.gov.cn/
5https://www.jd.com/
 
1783KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Li Lin et al.
event locations over ğ‘regions in time step ğ‘¡,ğ‘’ğ‘
ğ‘¡âˆˆZğ¶represents the
periodic event category with ğ¶dimensions in time step ğ‘¡.
Definition 4 (Problem: Joint Prediction of Future Demandâ€“
Supply Seqence under Events). Given the previous sequences
of demand, supply: ğ·ğ‘={ğ‘‘1,ğ‘‘2,...,ğ‘‘ğ‘‡},ğ‘†ğ‘={ğ‘ 1,ğ‘ 2,...,ğ‘ ğ‘‡},
and events: ğ¸ğ‘¢ğ‘=
ğ‘’ğ‘¢
1,ğ‘’ğ‘¢
2,...,ğ‘’ğ‘¢
ğ‘‡	,ğ¸ğ‘›ğ‘=
ğ‘’ğ‘›
1,ğ‘’ğ‘›
2,...,ğ‘’ğ‘›
ğ‘‡	,ğ¸ğ‘ğ‘=
ğ‘’ğ‘
1,ğ‘’ğ‘
2,...,ğ‘’ğ‘
ğ‘‡	
, as well as the multi-view graph: ğºâˆ—=ğº(ğ‘–|ğ‘–âˆˆ[1,ğ‘š]).
The target of joint prediction of the future demand-supply sequence un-
der events is to train a parametric model Fğœƒto produce future demand
and supply sequences with length ğ‘™â€²,ğ·ğ‘“={ğ‘‘ğ‘‡+1,ğ‘‘ğ‘‡+2,...,ğ‘‘ğ‘‡+ğ‘™â€²},
ğ‘†ğ‘“={ğ‘ ğ‘‡+1,ğ‘ ğ‘‡+2,...,ğ‘ ğ‘‡+ğ‘™â€²}:
(ğ·ğ‘“;ğ‘†ğ‘“)=Fğœƒ
ğ·ğ‘;ğ‘†ğ‘;ğ¸(ğ‘¢,ğ‘›,ğ‘)
ğ‘ ;ğºâˆ—
(1)
whereğœƒis the parameter set of F.
4 Methodology
The framework of MulSTE is given in Fig. 4. Our model follows
the Encoder-Decoder framework for sequence learning, which con-
tains three key components: (i) Event Fusion Representation
(Sec. 4.2) to conduct a unified fusing representation for hetero-
geneous event data. (ii) Multiple Spatio-temporal Encoders
(Sec. 4.3) to construct the complex spatio-temporal relationship of
demand, supply, and events, also their interactions. (iii) Multi-step
Demand-Supply Decoder (Sec. 4.4) to produce future demand
and supply sequences based on the spatio-temporal representations.
4.1 Data Preprocessing
4.1.1 Multi-view Graph Construction. We construct multi-view
graphs to describe the static regional relations following the method
in [35], which can be divided into the following four parts.
Distance-aware graph. By calculating the distance between
two regions, we build a distance-aware graph ğº(ğ‘‘)=(ğ‘‰,ğ‘ˆ(ğ‘‘),ğ´(ğ‘‘)).
Each edgeğ‘¢(ğ‘‘)
ğ‘–ğ‘—âˆˆğ‘ˆ(ğ‘‘)represents the spatial distance between re-
gionsğ‘Ÿğ‘–andğ‘Ÿğ‘—.
Neighbor-aware graph. To account for the neighboring corre-
lation between regions, we build a neighbor-aware graph ğº(ğ‘›)=
(ğ‘‰,ğ‘ˆ(ğ‘›),ğ´(ğ‘›)), Inğº(ğ‘›), the edgeğ‘¢(ğ‘›)
ğ‘–ğ‘—âˆˆğ‘ˆ(ğ‘›)indicates whether
ğ‘Ÿğ‘–andğ‘Ÿğ‘—are neighboring regions with boolean value.
Type-similarity graph. To capture function similarity among
regions, a fully connected undirected graph ğº(ğ‘¡)=(ğ‘‰,ğ‘ˆ(ğ‘¡),ğ´(ğ‘¡))
is built, named type-similarity graph. Its edge ğ‘¢(ğ‘¡)
ğ‘–ğ‘—âˆˆğ‘ˆ(ğ‘¡)is com-
puted with ğ‘ğ‘œğ‘ (T(ğ‘Ÿğ‘–),T(ğ‘Ÿğ‘—)). Here,ğ‘ğ‘œğ‘ ()is the cosine function,
and the functionT(Â·) denotes the function-type properties of
a given region, which refers to the number, size, distance of 9
type zones (industrial, office building, residential, professional mar-
ket, commercial-residential mixed (mainly residential), mixed area
(mainly commercial), school, township, and commercial).
Crowd-similarity graph. We utilize region-level aggregated
user profiles, named crowd properties, to build the fully connected
undirected graph ğº(ğ‘)=(ğ‘‰,ğ‘ˆ(ğ‘),ğ´(ğ‘)), named crowd-similarity
graph. Its edge ğ‘¢(ğ‘)
ğ‘–ğ‘—âˆˆğ‘ˆ(ğ‘)is computed with ğ‘ğ‘œğ‘ (C(ğ‘Ÿğ‘–),C(ğ‘Ÿğ‘—)).
Here,ğ‘ğ‘œğ‘ ()is the cosine function, and the function C(Â·) denotes
the crowd properties of a given region, such as the statistics of
gender, age, education, registration time, and so on.4.1.2 Demand, Supply, and Event Sequences Processing. We use
a sliding window with a size of ğ‘‡+ğ‘™â€², whereğ‘‡denotes the his-
tory length, and ğ‘™â€²denotes the future length for targets. For each
timestep in event sequences, it is a set of heterogeneous event data
(ğ‘’ğ‘¢
ğ‘¡,ğ‘’ğ‘›
ğ‘¡,ğ‘’ğ‘
ğ‘¡). Specifically, the textual type ğ‘’ğ‘¢
ğ‘¡âˆˆSğ‘€represents the ğ‘€
pieces of text describing emergent events, numerical type ğ‘’ğ‘›
ğ‘¡âˆˆRğ‘
represents the counts of emergent events in ğ‘different regions,
categorical type ğ‘’ğ‘
ğ‘¡âˆˆZğ¶represents the periodic event category
withğ¶dimensions.
4.2 Event Fusion Representation
The Event Fusion Representation (EFR) module as shown in Fig. 5
aims to provide a unified representation for heterogeneous event
data, containing textual, numerical, and categorical data.
4.2.1 Textual Events Learning. For textual emergent events, the
pre-trained language model, MacBERT [ 3], is to capture the seman-
tic information by fine-tuning it on event descriptions in earlier
days (textual data details are provided in Appendix A.2). For each
sentence, we use the tokenizer combined in MacBERT from Hug-
gingFace6to generate the tokens. Then a ğ‘€ğ¿ğ‘ƒ layer makes a binary
classification of whether the news is emergent event-related based
on the semantic embedding. After that, a fine-tuned MacBERT
with the ability to recognize emergent event-related news is ob-
tained. Then the model parameters are frozen and conveyed to the
demand-supply prediction work for multiple cities. We take the
last hidden state corresponding to the special token [CLS] for each
piece of news in textual input ğ‘’ğ‘¢
ğ‘¡âˆˆSğ‘€to represent the semantic
information of each whole news title at time step ğ‘¡as follows:
ğ¸ğ‘
ğ‘¡â†ğµğ¸ğ‘…ğ‘‡ğ‘“[CLS](ğ‘‡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ ğ‘’ğ‘¢
ğ‘¡) (2)
whereğ¸ğ‘
ğ‘¡is the piece-level textual semantic embedding at time
stepğ‘¡,ğµğ¸ğ‘…ğ‘‡ğ‘“is the frozen BERT initialized by fine-tuned parame-
ters,ğ‘‡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ ğ‘’ğ‘¢
ğ‘¡is the tokens converted from predicting-task news
titlesğ‘’ğ‘¢
ğ‘¡at time step ğ‘¡. Then, we use the ğ‘†ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ to calculate the
weighted sum of time-step level semantic representation:
ğ›½ğ‘™ğ‘ğ‘ğ‘’ğ‘™ =1â†âˆ’ğ‘†ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘€ğ¿ğ‘ƒ(ğ¸ğ‘
ğ‘¡))
ğ¸ğ‘¢
ğ‘¡=ğ‘€âˆ‘ï¸
ğ‘–=1ğ›½ğ‘–âŠ™(ğ¸ğ‘
ğ‘¡)ğ‘–(3)
whereğ›½is the weights of ğ¸ğ‘
ğ‘¡,ğ‘€ğ¿ğ‘ƒ is the classification head in fine-
tuned MacBERT, ğ‘€is the max number of news pieces in one time
step,ğ¸ğ‘¢
ğ‘¡âˆˆğ‘…ğ‘‘â„is the time-step level textual semantic embedding.
4.2.2 Numerical and Categorical Events Learning. For numerical
type data which exhibit spatio-temporal characteristics and reflect
the severity of emergent events in different regions, we introduce a
simple fully connected layer to expand the raw input ğ‘’ğ‘›
ğ‘¡to match
the dimension of the hidden state ğ¸ğ‘›
ğ‘¡âˆˆğ‘…ğ‘Ã—ğ‘‘â„. For categorical type
data (day of week, day of month, day of year, festival type) which
reveal the time and frequency of demand-supply changes triggered
by periodic events, we convert them to the same dimension as the
hidden state using the linear Embedding layer. Then, we performed
6https://huggingface.co/hfl/chinese-bert-wwm-ext
 
1784MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Timeğ·1
ğ‘’2ğ‘¢ğ‘’2ğ‘›ğ‘’2ğ‘EGIA
FC
ğ‘‘2ğ·2MGACRU
FC
ğ‘ 2ğ‘†2MGACRU
EFRMGACRU
ğ¸2ğ¹ğ‘ ğ‘›ğ·ğ‘‡
ğ‘’1ğ‘¢ğ‘’1ğ‘›ğ‘’1ğ‘EGIA
ğ‘‘1MGACRU
FC
ğ‘ 1ğ‘†1MGACRU
EFRMGACRU
ğ¸1ğ¹ğ‘ ğ‘›
ğ‘’ğ‘‡ğ‘¢ğ‘’ğ‘‡ğ‘›ğ‘’ğ‘‡ğ‘EGIA
FC
ğ‘‘ğ‘‡MGACRU
FC
ğ‘ ğ‘‡ğ‘†ğ‘‡MGACRU
EFRMGACRU
ğ¸ğ‘‡ğ¹ğ‘ ğ‘›â€¦
â€¦
â€¦
â€¦FC
Crowd -similarity graph Constr. 
ğº(ğ‘)
Demand Data 
ğ·=ğ‘‘1,ğ‘‘2,â‹¯,ğ‘‘ğ‘‡Demand Sequence: 
Supply Data 
ğ‘†=ğ‘ 1,ğ‘ 2,â‹¯,ğ‘ ğ‘‡Supply Sequence: 
Numerical type Textual Type
Emergent Event Data Textual Event Sequence: 
ğ¸ğ‘¢=ğ‘’1ğ‘¢,ğ‘’2ğ‘¢,â‹¯,ğ‘’ğ‘‡ğ‘¢
Numerical Event Sequence: 
ğ¸ğ‘›=ğ‘’1ğ‘›,ğ‘’2ğ‘›,â‹¯,ğ‘’ğ‘‡ğ‘›Categorical Type
Periodic Event Data
& Periodic Event Sequence: 
ğ¸ğ‘=ğ‘’1ğ‘,ğ‘’2ğ‘,â‹¯,ğ‘’ğ‘‡ğ‘Supply ST Encoder
Event ST Encoder
ğº(ğ‘‘)Distance -aware graph Constr.
ğº(ğ‘›)Neighbor -aware graph Constr.Demand ST Encoder
â„0ğ·ğ¼ â„1ğ·â„1ğ·ğ¼â„ğ‘‡âˆ’1ğ·ğ¼â„2ğ·â„2ğ·ğ¼â„ğ‘‡ğ·
â„ğ‘‡ğ·ğ¼
â„1ğ‘†â„1ğ‘†ğ¼â„ğ‘‡âˆ’1ğ‘†ğ¼ â„2ğ‘†â„2ğ‘†ğ¼â„ğ‘‡ğ‘†â„ğ‘‡ğ‘†ğ¼
â„0ğ‘†ğ¼
â„0ğ¸â„1ğ¸â„2ğ¸â„ğ‘‡ğ¸
Type -similarity graph Constr.
ğº(ğ‘¡)Multi -view Graph Construction (Sec. 4.1.1)
Demand, Supply, and Event Sequences Processing (Sec. 4.1.2)Multiple Spatio -temporal Encoders (Sec. 4.3)
Event Fusion 
Representation  
(Sec. 4.2)
Multi -step Demand -Supply Decoder (Sec. 4.4)Demand Predictions
ğ‘‘ğ‘‡+1ğ‘‘ğ‘‡+2ğ‘‘ğ‘‡+ğ‘™â€¦
FC
FCDemand FC Output layerSupply Predictions
ğ‘ ğ‘‡+1ğ‘ ğ‘‡+2ğ‘ ğ‘‡+ğ‘™â€¦
Supply FC Output layer
â„ğ‘‡ğ·ğ¸
â„ğ‘‡ğ‘†ğ¸ğ»ğ‘‡ğ·
ğ»ğ‘‡ğ‘†
Concat Concat
Figure 4: The framework of our work, consisting of four main components: 1) data preprocessing, 2) event fusion representation,
3) multiple spatio-temporal encoders for representation learning, and 4) the multi-step demand-supply decoder for predictions.
element-wise addition of the four type embeddings to obtain ğ¸ğ‘
ğ‘¡âˆˆ
ğ‘…ğ‘‘â„at time step ğ‘¡.
Finally, we execute spatio-temporal alignment through element-
wise addition to get the event fusion representation:
ğ¸ğ¹ğ‘ ğ‘›
ğ‘¡=ğ¸ğ‘¢
ğ‘¡+ğ¸ğ‘›
ğ‘¡+ğ¸ğ‘
ğ‘¡ (4)
4.3 Multiple Spatio-temporal Encoders
We design three parallel encoders for demand, supply, and events
separately to capture their complex spatio-temporal relations. Each
encoder incorporates a unified graph-based recurrent network
based on MGACRU as shown in Fig. 6, which is a GRU-based cell
that integrates the Multi-Graph Adaptive Convolution (MGAC), to
recurrently aggregate historical demand or supply representation
and historical event representation from the EFR module.
4.3.1 Multi-Graph Adaptive Convolution.
(i) Predefined multi-view graph convolution adaptive weight-
ing. For the pre-defined multi-view graph ğºâˆ—, which ensembles ğ¿
graph views, we design ğ¿independent GCN layers correspondingly:
ğ‘(ğ‘™)
ğ‘¡=
ğ¼ğ‘+ğ·âˆ’1
2ğ´(ğ‘™)ğ·âˆ’1
2
ğ‘‹ğ‘§
ğ‘¡Î˜(ğ‘™)+ğ‘(ğ‘™),ğ‘™âˆˆ{1,...,ğ¿}(5)
Single news titleC â€¦
â€¦
â€¦ğ‘‡ğ‘‡1ğ‘‡ğ‘‡2 ğ‘‡ğ‘‡N
E[CLS]E1 E2 EN
[CLS] Tok1 Tok2 TokNFine- tuning
EFR
EFR EFRAdapting to prediction tasks
Single news titleC â€¦
â€¦
â€¦Bertğ‘‡ğ‘‡1ğ‘‡ğ‘‡2 ğ‘‡ğ‘‡N
E[CLS]E1 E2 EN
[CLS] Tok1 Tok2 TokN
Classification
HeadSpace- temporal Alignment
Emergent Events Rep. Periodic Events Rep.
Embedding 
Layerâ€¦ â€¦
Numerical type Textual Type Categorical Type
Time Emergent Event Data Periodic Event Data
& ğ‘’ğ‘’ğ‘¡ğ‘¡ğ‘¢ğ‘¢ğ‘’ğ‘’ğ‘¡ğ‘¡ğ‘›ğ‘›ğ‘’ğ‘’ğ‘¡ğ‘¡ğ‘ğ‘
ğ‘“ğ‘“Fine -tuning 
News
Emergent Event Data ğ‘’ğ‘’1ğ‘¢ğ‘¢ğ‘’ğ‘’1ğ‘›ğ‘›ğ‘’ğ‘’1ğ‘ğ‘ğ‘’ğ‘’ğ‘‡ğ‘‡ğ‘¢ğ‘¢ğ‘’ğ‘’ğ‘‡ğ‘‡ğ‘›ğ‘›ğ‘’ğ‘’ğ‘‡ğ‘‡ğ‘ğ‘ğ¸ğ¸ğ‘¡ğ‘¡ğ¹ğ¹ğ¹ğ¹ğ‘›ğ‘›ğ¸ğ¸ğ‘‡ğ‘‡ğ¹ğ¹ğ¹ğ¹ğ‘›ğ‘›ğ¸ğ¸1ğ¹ğ¹ğ¹ğ¹ğ‘›ğ‘›
ğ¸ğ¸ğ‘¡ğ‘¡ğ‘ğ‘ğ¸ğ¸ğ‘¡ğ‘¡ğ‘¢ğ‘¢
ğ¸ğ¸ğ‘¡ğ‘¡ğ‘›ğ‘›ğ¸ğ¸ğ‘¡ğ‘¡ğ‘ğ‘
ğ¸ğ¸ğ‘¡ğ‘¡ğ‘¤ğ‘¤ğ¸ğ¸ğ‘¡ğ‘¡ğ‘šğ‘š
ğ¸ğ¸ğ‘¡ğ‘¡ğ‘¦ğ‘¦ğ¸ğ¸ğ‘¡ğ‘¡ğ‘“ğ‘“ ğ¸ğ¸ğ‘“ğ‘“
Initialization
TransferFrozen BERT BERT
FCMLP 
Layers
Softmax
ClassificationHeadLoss
Figure 5: Process of Event Fusion Representation.whereğ´(ğ‘™)is the adjacent matrix, ğ·is the degree matrix, ğ¼ğ‘is the
identity matrix, Î˜(ğ‘™)andğ‘(ğ‘™)are learnable parameters.
Then adaptive weighting is designed to measure different de-
grees of relative importance to demand, supply, and events for
predefined relationships. The attention weights of ğ‘™ğ‘¡â„view graph
can be formulated as:
ğ›¼(ğ‘™)=ğ‘’ğ‘¥ğ‘(ğ‘Šğ‘[ğ‘(ğ‘™)
ğ‘¡]+ğ‘ğ‘)
Ãğ¿
ğ‘–=1ğ‘’ğ‘¥ğ‘(ğ‘Šğ‘[ğ‘(ğ‘–)
ğ‘¡]+ğ‘ğ‘)(6)
whereğ›¼(ğ‘™)âˆˆğ‘…ğ‘represents the ğ‘regionsâ€™ attention weights of
ğ‘™ğ‘¡â„view graph, ğ‘Šğ‘,ğ‘ğ‘are learnable parameters.
Further, we incorporate all the ğ¿graph views by the adaptive
weighting of the graph convolution results as ğ‘ğ‘
ğ‘¡=Ãğ¿
ğ‘™=1ğ›¼(ğ‘™)âŠ™
ğ‘(ğ‘™),ğ‘™âˆˆ{1,...,ğ¿}, whereâŠ™is element-wise multiplication.
(ii) Adaptive node aggregation graph-structured learning.
To adaptively capture the graph information that the predefined
multi-view graph cannot contain, we construct an adaptive graph
ğºğ‘“=(ğ‘‰,ğ‘ˆğ‘“,eğ´ğ‘“). The normalized adjacent matrix eğ´ğ‘“is data-
adaptive to discover the hidden spatial relationships, requiring no
prior knowledge, and can be learned through stochastic gradient
descent. We first randomly initialize a learnable parameter ğ‘€ğ‘“âˆˆ
ğ‘…ğ‘Ã—ğ‘‘â„for all nodes, where each row of ğ‘€ğ‘“represents the structure
embedding of a node, ğ‘‘â„represents the dimension of node structure
embedding. According to the nodesâ€™ similarity, we can define the
normalized adjacent matrix eğ´ğ‘“as:
eğ´ğ‘“=Softmax(Relu(ğ‘€ğ‘“ğ‘€ğ‘“ğ‘‡)) (7)
where theğ‘…ğ‘’ğ‘™ğ‘¢ is used to eliminate weak connections, and the
ğ‘†ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ is utilized to normalize the adaptive graph. Then the
adaptive graph node embedding aggregation can be formulated as:
ğ‘ğ‘“
ğ‘¡=eğ´ğ‘“ğ‘‹ğ‘§
ğ‘¡ğ‘Šğ‘“+ğ‘ğ‘“ (8)
whereğ‘ğ‘“
ğ‘¡âˆˆğ‘…ğ‘Ã—ğ‘‘â„is the adaptive graph node embedding at time
stepğ‘¡,ğ‘is the nodes number, ğ‘‘â„is the dimension of graph node
embedding, and ğ‘Šğ‘“,ğ‘ğ‘“are the learnable parameters.
 
1785KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Li Lin et al.
â„ğ‘‡ğ‘‡
Timeâ€¦ â€¦
â€¦ â€¦â„1
MGACRUâ„0
ğ‘‹ğ‘‹1MGACRUâ„ğ‘‡ğ‘‡âˆ’1
ğ‘‹ğ‘‹ğ‘‡ğ‘‡â„ğ‘¡ğ‘¡âˆ’1MGACRU â„ğ‘¡ğ‘¡
ğ‘Ÿğ‘Ÿğ‘¡ğ‘¡ğ‘¢ğ‘¢ğ‘¡ğ‘¡
ğ‘ğ‘ğ‘¡ğ‘¡ğ‘¢ğ‘¢
Concat
Concatğœğœğœğœ
tanh1-
u-MGAC
r-MGACğ‘ğ‘ğ‘¡ğ‘¡ğ‘Ÿğ‘Ÿ
ğ‘‹ğ‘‹ğ‘¡ğ‘¡
Adaptive 
Weighting
MLP
MLPPre-definedConcat ğ‘ğ‘ğ‘¡ğ‘¡ğ‘”ğ‘”
ğ‘ğ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘ğ‘ğ‘¡ğ‘¡ğ‘ğ‘
ğ»ğ»ğ‘¡ğ‘¡ğ‘ğ‘MGAC (ii) Adaptive Node Aggregation Graph- structured Learning
(i) Predefined Multi- view Graph 
Convolution Adaptive WeightingConcat
ğ‘ğ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘¡ğ‘¡ğ‘”ğ‘”
ğ‘ğ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘ğ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘ğ‘ğ‘¡ğ‘¡ğ‘“ğ‘“
ConcatFC ğ‘‹ğ‘‹ğ‘¡ğ‘¡ğ‘§ğ‘§
MLP
MLPğ»ğ»ğ‘¡ğ‘¡ğ‘ğ‘ (iii) Non -graph- structured Bias Learning
Figure 6: Illustration of MGACRU.
(iii) Non-graph-structured bias learning. We concat the pre-
defined multi-view graph convolution adaptive weighting output
ğ‘ğ‘
ğ‘¡and the adaptive node aggregation output ğ‘ğ‘“
ğ‘¡to generate the
graph-structured relationship embedding ğ‘ğ‘”
ğ‘¡.
However, the graph-structured relationship captured may not
cover all the inter-regional relations. Inspired by D2STGNN [ 22], we
useğ‘ğ‘”
ğ‘¡passed back to an MLP branch to obtain ğ»ğ‘
ğ‘¡, then compute
the differential matrix between ğ‘‹ğ‘§
ğ‘¡andğ»ğ‘
ğ‘¡, passing forward to the
other MLP branch to achieve non-graph-structured bias learning.
ğ»ğ‘
ğ‘¡=ğœ(ğ‘ğ‘”
ğ‘¡ğ‘Šğ‘1+ğ‘ğ‘1)
ğ‘ğ‘
ğ‘¡=ğœ((ğ‘‹ğ‘§
ğ‘¡âˆ’ğ»ğ‘
ğ‘¡)ğ‘Šğ‘2+ğ‘ğ‘2)(9)
whereğ»ğ‘
ğ‘¡âˆˆğ‘…ğ‘Ã—ğ‘‘â„,ğ‘ğ‘
ğ‘¡âˆˆğ‘…ğ‘Ã—ğ‘‘â„represent the embedding trans-
formed into the input space and the bias information. ğ‘Šğ‘1,ğ‘ğ‘1,ğ‘Šğ‘2,
ğ‘ğ‘2are the learnable parameters.
Finally, we get the output of MGAC as: ğ‘ğ‘¡=[ğ‘ğ‘”
ğ‘¡||ğ‘ğ‘
ğ‘¡]ğ‘Š+ğ‘
whereğ‘ğ‘¡âˆˆğ‘…ğ‘Ã—ğ‘‘â„,ğ‘Šandğ‘are learnable parameters, and each
row inğ‘ğ‘¡is the sequence embedding of one region at time ğ‘¡.
4.3.2 Multi-Graph Adaptive Convolution Recurrent Network. We
use GRU [ 2] as the basic structure in MGACRU by adjusting the
update and reset gates with u-MGAC and r-MGAC as follows:
ğ‘ğ‘¢
ğ‘¡=u-MGAC([ğ‘‹ğ‘¡||â„ğ‘¡âˆ’1],ğºâˆ—)
ğ‘¢ğ‘¡=ğœ(ğ‘ğ‘¢
ğ‘¡ğ‘Šğ‘¢+ğ‘ğ‘¢)
ğ‘Ÿğ‘¡=ğœ(ğ‘ğ‘¢
ğ‘¡ğ‘Šğ‘Ÿ+ğ‘ğ‘Ÿ)
ğ‘ğ‘Ÿ
ğ‘¡=r-MGAC([ğ‘‹ğ‘¡||(ğ‘Ÿğ‘¡âŠ™â„ğ‘¡âˆ’1)],ğºâˆ—)
ğ‘ğ‘¡=ğ‘¡ğ‘ğ‘›â„(ğ‘ğ‘Ÿ
ğ‘¡ğ‘Šğ‘+ğ‘ğ‘)
â„ğ‘¡=ğ‘¢ğ‘¡âŠ™â„ğ‘¡âˆ’1+(1âˆ’ğ‘¢ğ‘¡)âŠ™ğ‘ğ‘¡(10)
EGIA
ğœğœ1-
â„ğ‘¡ğ‘¡ğ·ğ·ğ¼ğ¼
â„ğ‘¡ğ‘¡ğ‘†ğ‘†ğ¼ğ¼ï¿½â„ğ‘¡ğ‘¡ğ·ğ·
ï¿½â„ğ‘¡ğ‘¡ğ‘†ğ‘†
ï¿½â„ğ‘¡ğ‘¡ğ¸ğ¸
Time
ğ‘¬ğ‘¬ğ‘®ğ‘®ğ‘®ğ‘®ğ‘®ğ‘®ğŸğŸEGIA EGIAâ€¦
â€¦
ğ‘¬ğ‘¬ğ‘®ğ‘®ğ‘®ğ‘®ğ‘®ğ‘®ğ’•ğ’• ğ‘¬ğ‘¬ğ‘®ğ‘®ğ‘®ğ‘®ğ‘®ğ‘®ğ‘»ğ‘»â„ğ‘¡ğ‘¡ğ·ğ·
â„ğ‘¡ğ‘¡ğ‘†ğ‘†â„ğ‘¡ğ‘¡ğ¸ğ¸â„ğ‘¡ğ‘¡ğ·ğ·ğ¼ğ¼
â„ğ‘¡ğ‘¡ğ‘†ğ‘†ğ¼ğ¼QKV
QKVâ„1ğ¸ğ¸â„1ğ·ğ·â„1ğ·ğ·ğ¼ğ¼
â„1ğ‘†ğ‘†â„1ğ‘†ğ‘†ğ¼ğ¼â„ğ‘‡ğ‘‡ğ¸ğ¸â„ğ‘‡ğ‘‡ğ·ğ·â„ğ‘‡ğ‘‡ğ·ğ·ğ¼ğ¼
â„ğ‘‡ğ‘‡ğ‘†ğ‘†â„ğ‘‡ğ‘‡ğ‘†ğ‘†ğ¼ğ¼â€¦
â€¦
â€¦ â€¦
ConcatSplitSelf-
Attention
Cross -
Attention
Figure 7: Illustration of EGIA structure.whereğ‘‹ğ‘¡âˆˆğ‘…ğ‘Ã—ğ¹,â„ğ‘¡âˆˆğ‘…ğ‘Ã—ğ‘‘â„are the sequence input and hidden
state output of MGACRU at time step ğ‘¡,||denotes the concatenation
operation,ğ‘¢ğ‘¡andğ‘Ÿğ‘¡are hidden states of update gate and reset gate
at time step ğ‘¡.ğ‘Šğ‘¢,ğ‘Šğ‘Ÿ,ğ‘Šğ‘,ğ‘ğ‘¢,ğ‘ğ‘Ÿ,ğ‘ğ‘are trainable parameters.
4.3.3 Event Gated Demand-Supply Interaction Attention. To model
the interrelation between demand and supply under event impact,
we design the Event Gated Demand-Supply Interaction Attention
module (EGIA). The detailed structure is shown in Fig.7. Firstly, we
compute the self-attention of demand-supply as follows:
Ë†â„ğ·
ğ‘¡||Ë†â„ğ‘†
ğ‘¡=Softmax([â„ğ·
ğ‘¡||â„ğ‘†
ğ‘¡]ğ‘Šğ‘„
1([â„ğ·
ğ‘¡||â„ğ‘†
ğ‘¡]ğ‘Šğ¾
1)ğ‘‡
âˆšï¸
ğ‘‘ğ‘˜)[â„ğ·
ğ‘¡||â„ğ‘†
ğ‘¡]ğ‘Šğ‘‰
1(11)
where Ë†â„ğ·
ğ‘¡and Ë†â„ğ‘†
ğ‘¡are interacted representations for demand and
supply respectively. Secondly, we compute the event impacts via
cross-attention as follows:
Ë†â„ğ¸
ğ‘¡=Softmax(â„ğ¸
ğ‘¡ğ‘Šğ‘„
2([â„ğ·
ğ‘¡||â„ğ‘†
ğ‘¡]ğ‘Šğ¾
2)ğ‘‡
âˆšï¸
ğ‘‘ğ‘˜)[â„ğ·
ğ‘¡||â„ğ‘†
ğ‘¡]ğ‘Šğ‘‰
2(12)
Ë†â„ğ¸
ğ‘¡is calculated to fuse demand and supply depending on both
responses to the event. Finally, we utilize the event gate to control
the proportion of the above two attention:
â„ğ·ğ¼
ğ‘¡=ğœ(â„ğ¸
ğ‘¡)âŠ™Ë†â„ğ¸
ğ‘¡+(1âˆ’ğœ(â„ğ¸
ğ‘¡))âŠ™ Ë†â„ğ·
ğ‘¡
â„ğ‘†ğ¼
ğ‘¡=ğœ(â„ğ¸
ğ‘¡)âŠ™Ë†â„ğ¸
ğ‘¡+(1âˆ’ğœ(â„ğ¸
ğ‘¡))âŠ™ Ë†â„ğ‘†
ğ‘¡(13)
Then we get the demand-supply interaction enhanced demand,
supply, and event Encoders as shown in Fig. 4 formulated as:
â„ğ·
ğ‘¡=MGACRU(ğ·ğ‘¡,â„ğ·ğ¼
ğ‘¡âˆ’1,ğºâˆ—)
â„ğ‘†
ğ‘¡=MGACRU(ğ‘†ğ‘¡,â„ğ‘†ğ¼
ğ‘¡âˆ’1,ğºâˆ—)
â„ğ¸
ğ‘¡=MGACRU(ğ¸ğ¹ğ‘ ğ‘›
ğ‘¡,â„ğ¸
ğ‘¡âˆ’1,ğºâˆ—)(14)
And EGIA can be formulated as:
â„ğ·ğ¼
ğ‘¡,â„ğ‘†ğ¼
ğ‘¡=EGIA(â„ğ·
ğ‘¡âŠ•ğ·ğ‘¡,â„ğ‘†
ğ‘¡âŠ•ğ‘†ğ‘¡,â„ğ¸
ğ‘¡âŠ•ğ¸ğ¹ğ‘ ğ‘›
ğ‘¡) (15)
whereğ·ğ‘¡andğ‘†ğ‘¡are the demand and supply representations ob-
tained from the parallel Spatio-temporal encoders. ğ¸ğ¹ğ‘ ğ‘›
ğ‘¡represents
the event fusion representation obtained from the EFR module at
time stepğ‘¡.âŠ•represents the residual connection [11].
4.4 Multi-step Demand-Supply Decoder
Finally, we concatenate the interacted demand output â„ğ·ğ¼
ğ‘‡and sup-
ply outputâ„ğ‘†ğ¼
ğ‘‡from the last EGIA in Equation (15), respectively
along with the demand-related event representation â„ğ·ğ¸
ğ‘‡=â„ğ¸
ğ‘‡ğ‘Šğ‘’1+
ğ‘ğ‘’1and supply-related event representation â„ğ‘†ğ¸
ğ‘‡=â„ğ¸
ğ‘‡ğ‘Šğ‘’2+ğ‘ğ‘’2
transformed from the last output â„ğ¸
ğ‘‡of the Event Encoder in Equa-
tion (14), to get the final demand representation ğ»ğ·
ğ‘‡=[â„ğ·ğ¼
ğ‘‡||â„ğ·ğ¸
ğ‘‡]
and supply representation ğ»ğ‘†
ğ‘‡=[â„ğ‘†ğ¼
ğ‘‡||â„ğ‘†ğ¸
ğ‘‡]for multi-step predic-
tion. We can directly obtain the demand and supply prediction for
the nextğ‘™â€²steps of all nodes by applying two linear transformations.
Then the L1 loss is chosen as our training objective:
Lğœƒ=LD+LS=Ãğ‘‡+ğ‘™â€²
ğ‘¡=ğ‘‡+1ğ·ğ‘¡âˆ’ğ·ğ‘¡â€²+Ãğ‘‡+ğ‘™â€²
ğ‘¡=ğ‘‡+1ğ‘†ğ‘¡âˆ’ğ‘†ğ‘¡â€²(16)
whereğ·ğ‘¡andğ‘†ğ‘¡are the ground truth of demand and supply. And
ğ·ğ‘¡â€²,ğ‘†ğ‘¡â€²are the predicted ones.
 
1786MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 1: Dataset statistics, â€œ#â€ represents the COUNT operation.
City Time span # Orders # Stations # Users # Emerg. Event # News titles # Periodic event categories
SH 2021/1/1â€“2022/8/31 273.02M 282 19.19M 180,302 8,067 31 (20 festivals + 11 promotions)
ZZ 2021/1/1â€“2022/12/31 66.22M 71 6.51M 30,399 5,060 31 (20 festivals + 11 promotions)
Table 2: Overall comparison in two various-scale cities. Bold: Best, underline : Second best (Same in below table).
ModelsShanghai (SH) Zhengzhou (ZZ)
Demand Supply Demand Supply
MAE RMSE sMAPE MAE RMSE sMAPE MAE RMSE sMAPE MAE RMSE sMAPE
HI 418.61 762.14 23.93% 423.84 687.77 31.07% 354.63 769.31 24.54% 387.33 696.21 29.92%
ARIMA 370.32 771.25 21.59% 362.07 646.82 25.80% 337.13 637.30 24.86% 326.13 628.30 26.40%
SVR 401.52 785.01 23.91% 408.10 699.79 26.27% 279.01 507.79 22.14% 301.25 516.86 25.24%
GWN 303.46 538.42 17.42% 303.33 499.04 22.16% 185.68 349.02 15.59% 195.84 347.10 18.96%
MTGNN 317.39 560.10 18.44% 304.33 506.04 21.47% 202.78 380.90 16.41% 216.92 389.94 21.11%
DCRNN 330.32 579.67 19.33% 343.88 546.18 22.97% 216.42 384.27 18.56% 252.83 447.91 22.67%
AGCRN 204.19 375.08 12.05% 201.62 337.21 16.20% 158.10 306.61 13.39% 163.66 289.22 17.41%
Transformer 461.18 684.76 29.11% 486.80 678.28 31.05% 378.16 556.32 32.36% 408.15 590.70 34.86%
Informer 270.53 497.47 15.36% 202.67 352.96 17.30% 156.73 314.15 12.60% 151.79 282.10 16.12%
Fedformer 267.84 471.66 16.64% 319.09 541.63 23.95% 240.53 420.31 20.98% 254.06 422.59 23.01%
PatchTST 331.57 576.78 19.43% 342.60 564.20 24.85% 229.12 406.25 19.24% 273.35 492.53 24.08%
GRU 312.73 555.34 18.20% 326.56 532.29 22.42% 195.93 361.53 16.44% 229.61 410.97 21.62%
DLinear 348.39 602.69 20.25% 339.17 552.63 23.77% 267.40 455.59 22.27% 294.24 512.46 25.34%
TimesNet 323.30 580.34 19.04% 317.72 539.26 23.62% 233.50 407.47 19.71% 274.71 495.64 23.91%
DeepSD (-e) 321.50 562.79 18.94% 308.99 499.60 20.88% 239.27 408.89 19.78% 240.63 430.54 20.82%
DeepSD (e) 328.78 569.32 19.34% 307.14 497.18 20.82% 243.75 411.64 20.17% 238.81 427.52 21.25%
DH-GEM (r) 460.50 683.60 29.07% 472.43 661.88 30.36% 378.57 558.77 32.37% 385.89 564.01 33.81%
DH-GEM (s) 453.18 673.60 28.75% 468.88 658.03 30.21% 377.97 554.15 32.33% 385.09 560.31 33.68%
MulSTE 160.11 279.27 10.64% 197.84 334.97 15.36% 105.46 190.06 10.59% 111.75 199.74 14.06%
Table 3: Model performance evaluation across event types.
Models TypeDemand Supply
MAE RMSE sMAPE MAE RMSE sMAPE
SHAGCRNemergent 245.13 600.32 13.73% 258.05 453.10 21.91%
periodic 176.57 349.87 10.64% 179.64 313.79 11.75%
normal 128.12 215.15 9.00% 123.48 194.47 8.55%
Informeremergent 330.41 783.72 17.88% 259.43 482.03 23.71%
periodic 219.54 488.45 12.73% 174.36 319.48 11.44%
normal 181.50 339.59 11.75% 128.16 209.46 8.85%
MulSTEemergent 195.75 389.92 12.76% 259.05 441.69 20.76%
periodic 136.49 237.82 9.15% 158.95 283.30 10.65%
normal 111.72 200.13 7.95% 123.11 198.33 8.62%
ZZAGCRNemergent 186.17 446.21 16.29% 243.62 480.81 34.57%
periodic 176.79 397.09 13.51% 150.44 282.33 11.81%
normal 115.01 206.26 11.13% 123.02 205.52 10.96%
Informeremergent 183.79 457.54 14.80% 220.30 478.52 32.69%
periodic 178.65 420.01 13.06% 148.49 305.10 11.13%
normal 107.41 196.04 10.24% 103.22 179.47 9.03%
MulSTEemergent 126.84 228.48 13.53% 157.87 271.73 28.79%
periodic 103.37 199.06 9.34% 104.33 197.33 8.95%
normal 91.56 166.80 9.67% 89.32 159.00 8.82%
5 Evaluations
5.1 Experimental Setup
5.1.1 Datasets. We conduct experiments on real-world datasets
from two cities, Shanghai (SH) and Zhengzhou (ZZ), containingregional relation data, demand-supply data, and event data. The
dataset statistics are shown in Table 1 (details in Appendix A.2).
Each time step is set as one day. We use the history ğ‘‡=7time steps
to predict the next future ğ‘™â€²=7time steps. We split the dataset into
training, validation, and test sets randomly with 7:2:1 split ratio.
5.1.2 Parameter Settings. We implement MulSTE and baselines
with Pytorch 1.10.1 in Python 3.7.12 environment and train the
model with 24 GB memory and a Tesla P40 GPU. The max number
of training epochs is 300, the number of early stop epochs is 50, and
the batch size is 4. We use the Adam optimizer to accelerate the
training process, and the learning rate is initialized as 0.001 with
150 steps, then decayed to 0.0001. The hidden dimension is set to
64, and the number of MGACRU layers in MulSTE is set to 1.
5.1.3 Metrics. We deploy Mean Absolute Error (MAE), Root Mean
Square Error (RMSE), and Symmetric Mean Absolute Percentage
Error (sMAPE). Detailed metrics are provided in Appendix A.3.
5.1.4 Baselines. For extensive experiments, we compare MulSTE
with the following baselines. (i) Classic time series prediction
models (i.e., HI [ 4], ARIMA [ 29], SVR [ 7]) are the traditional
models based on statistics or machine learning. (ii) Graph-based
spatio-temporal prediction models (i.e., Graph WaveNet [ 33],
MTGNN [ 32], DCRNN [ 18], AGCRN [ 1]) combine graph neural
networks with sequential methods to capture the spatio-temporal
relationship. (iii) Transformer-based prediction models (i.e.,
Transformer [ 24], Informer [ 42], Fedformer [ 43], PatchTST [ 20])
 
1787KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Li Lin et al.
Demand Supply0255075100125150175200225250275MAE
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten
(a) MAE
Demand Supply050100150200250300350400450RMSE
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten (b) RMSE
Demand Supply0.02.55.07.510.012.515.017.520.022.5sMAPE(%)
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten (c) sMAPE
Figure 8: Ablation study in Shanghai.
Demand Supply0255075100125150175200MAE
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten
(a) MAE
Demand Supply050100150200250300350RMSE
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten (b) RMSE
Demand Supply0.02.55.07.510.012.515.017.520.022.5sMAPE(%)
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten (c) sMAPE
Figure 9: Ablation study in Zhengzhou.
utilize Transformer to model sequential dependency. (iv) Other
well-known Seq2Seq models (i.e., GRU [ 2], DLinear [ 37], Times-
Net [ 30]) use recurrent unit, linear transformation, or 2D-variations
to model temporal sequences. (v) Demand-supply jointly pre-
diction models (i.e., DeepSD(-e), DeepSD(e) [ 26], DH-GEM (-s),
DH-GEM (-r) [ 10]) are to predict supply-demand gap or predict
demand and supply simultaneously. We study DeepSD (-e) which
omits the event block, DeepSD (e) which maintains the event block,
to verify the effectiveness of the DeepSD in demand-supply predic-
tion under events. Meanwhile, DH-GEM (-s) which substitutes the
heterogeneous graph to homogeneous graph, DH-GEM (-r) which
removes the graph structures, are adapted to our scenario to predict
demand and supply concurrently.
5.2 Overall Performance
5.2.1 Overall Comparison. The average results of MAE, RMSE,
sMAPE of demand and supply in two cities are shown in Table 2.
We observe that our model has the best overall performance com-
pared with all baselines. We found that AGCRN, MTGNN, and
Graph WaveNet perform better than DCRNN, which proves the ef-
fectiveness of adaptive graph learning. AGCRN has the second-best
performance on the Shanghai dataset, on which the performance
of MulSTE achieves 19.61% and 2.57% improvement in demand
and supply compared with AGCRN. Informer performs slightly
worse than our model on the Zhengzhou dataset, on which the
performance of MulSTE achieves 29.39% and 22.79% improvement
in demand and supply compared with Informer. Compared to the
baselines solving the demand-supply joint prediction. We find that
MulSTE can efficiently capture the event effects on demand-supply
interactions, with a significant superiority over DeepSD(e), which
also models the event impacts on demand and supply. In addition,
DH-GEM performs better than Transformer even if the graph struc-
ture is removed in DH-GEM (-r). It demonstrates the necessity of
demand-supply interaction design. However, due to DH-GEM ne-
glecting the spatio-temporal characteristics of demand and supply,
even if we replace the original heterogeneous graph with an adap-
tive spatio-temporal homograph, the effect of DH-GEM (-s) is stillworse than MulSTE. It further reflects that the interaction module
of MulSTE can extract better demand and supply representation.
5.2.2 Event Types Comparison. To evaluate the model performance
under different event types, we conducted tests on samples with
emergent events, samples with periodic events, and samples with
no events. The results are presented in Table 3. Notably, our model
outperformed baselines significantly in the Zhengzhou dataset, ir-
respective of the event type. In the Shanghai dataset, our modelâ€™s
demand prediction performance outperformed all baselines signifi-
cantly. However, in supply prediction, the MAE for emergent events
and the sMAPE for normal events are slightly weaker compared to
the best baseline. It is mainly attributed to that emergent events like
Covid-19 would cause supply paralysis and then result in a decrease
in purchase demand, while MulSTE prefers to balance out the error
rate of demand and supply prediction tasks. The minor gap can be
effectively compensated by adjusting the supply-demand loss ratio
as in Sec. 5.4. We further verify the generalizability of our model in
various event-related scenarios. More results are in Appendix A.4.
5.3 Ablation Study
Fig. 8 and Fig. 9 show the results of the ablation study in Shanghai
and Zhengzhou datasets. When removing textual emergent or cate-
gorical periodic event representations, the performance decreases
significantly. It confirms the effectiveness of event fusion represen-
tations. We further compare MulSTE with other three variants: w/o
Bias (removing the bias learning), w/o Ada (removing the adaptive
graph node aggregation), and w/o Mul (removing the predefined
multi-view graph adaptive weighting). The results demonstrate that
the design of multi-view graphs effectively represents the actual
prior knowledge of regional relations. Moreover, adaptive graph
learning can also capture hidden regional information as a comple-
ment to empirical graphs, while bias learning also has the ability to
8 16 32 64 128
Dimension150170190210230250270290310MAE
1011121314151617181920
sMAPE (%)
Demand MAE
Supply MAEDemand sMAPE
Supply sMAPE
(a) Shanghai
8 16 32 64 128
Dimension100110120130140150160170180190200210MAE
1011121314151617181920
sMAPE (%)
Demand MAE
Supply MAEDemand sMAPE
Supply sMAPE (b) Zhengzhou
Figure 10: Effect of different embedding sizes.
1:9 3:7 5:5 7:3 9:1
Loss Ratio130150170190210230250270290310MAE
91011121314151617181920
sMAPE (%)
Demand MAE
Supply MAEDemand sMAPE
Supply sMAPE
(a) Shanghai
1:9 3:7 5:5 7:3 9:1
Loss Ratio90100110120130140150160170MAE
91011121314151617181920
sMAPE (%)
Demand MAE
Supply MAEDemand sMAPE
Supply sMAPE (b) Zhengzhou
Figure 11: Effect of different demand and supply loss ratios.
 
1788MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
capture non-graph relationships to a certain extent. Moreover, we
analyze the contribution of EGIA by (i) removing it from encoders
(w/o Inter) and (ii) concatenating the demand and supply hidden
state as interaction information (w/o Atten). It can be seen that
the performances of w/o EGIA and w/o Atten drop significantly,
which demonstrates the effectiveness of the design of event-related
interaction modeling in MulSTE.
5.4 Parameter Sensitivity
Fig. 10 shows the results when adjusting the hidden size ğ‘‘â„. The
performance improved and then decreased with the increase in
hidden size, and the best size is 64. Fig. 11 shows the performance
comparison under different loss ratios. It confirms that the joint
prediction of demand and supply still has to face the multi-task
trade-off issue. We simply set it to 1 : 1 in our experiments.
5.5 Effect of Attention Weights
To investigate how important is each view of graphs to learn the
spatial relations, we visualize the attention weights ğ›¼(ğ‘™)among
multi-view graphs in u-MGAC and r-MGAC by KDE density curves
on the Shanghai dataset. Fig. 12 shows the weight distributions of
regional graphs for learning representations of demand, supply, and
event separately. r-MGAC determines how much of the previous
hidden state should be forgotten, while u-MGAC determines how
much of the new input should be used to update the hidden state.
We can find that (i) for supply representation, the crowd-similarity
graph gets a significantly high weight when learning long-term
information while the type-similarity graph wins a relatively high
weight in short-term learning, (ii) for demand representation, the
weight distributions are nearly contrary between u-MGAC and
r-MGAC, which reveals that multi-view regional graphs contribute
oppositely in long-short term encoding. (iii) for event representa-
tion, the type-similarity graph is important in both u-MGAC and
r-MGAC. It is interesting to observe that the impact of events on
regions is strongly correlated to their function properties.
5.6 Effect of Adaptive Graph
To demonstrate the effectiveness of the adaptive adjacent matrix
ğ‘€ğ‘“ğ‘€ğ‘“ğ‘‡in the adaptive graph of MGAC, we draw the heat map
of the adaptive adjacency matrix in Fig. 13 on Shanghai dataset,
consisting of 282 regions. Although multi-view graphs describe
regional relations from different aspects, the adaptive adjacency
matrix can further reflect the statistical correlation of regions auto-
matically. We select the key regions with high weights in Fig. 13b
and map them to the delivery stations in Fig. 13a with the blue heat
map. It is interesting to find that the key regions in the adaptive
matrix are in strong agreement with high-risk areas (red heat map
in Fig. 13a) to the emergent event (Covid-19). It reveals that the
adaptive graph can learn the event-related information of regions.
6 Conclusion
In this work, we study the problem of joint prediction of purchase
demand and delivery supply under events with heterogeneous data.
To address the challenges of complex spatio-temporal interaction of
demand and supply under the diverse impacts of events with hetero-
geneous data, we propose MulSTE. Evaluation results on real-world
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0510152025KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph(a) u-MGAC for demand
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0102030405060708090KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph (b) u-MGAC for supply
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights051015202530KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph
(c) u-MGAC for event
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0510152025KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph (d) r-MGAC for demand
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0102030405060KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph
(e) r-MGAC for supply
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0102030405060708090KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph (f) r-MGAC for event
Figure 12: Attention weight distribution of Shanghai.
(a) Shanghai Map
070140 210 280
Region_no070140210280Region_no
0.00.20.40.60.8 (b) Adaptive Adjacent Matrix
Figure 13: Important region discovery for events in Shanghai.
datasets show that our model outperforms other state-of-the-art
models significantly, achieving at least 24.50%, 12.68%improvement
in demand and supply on average. In the future, we further expect
to extend our model to address event-aware forecasting problems
in various fields beyond E-commerce.
Acknowledgments
This work was supported in part by National Science and Technol-
ogy Major Project 2021ZD0114200, Natural Science Foundation of
Jiangsu Province under Grant BK20230815, National Natural Sci-
ence Foundation of China under Grant 61925202, Jiangsu Provincial
Key Research and Development Program under Grant BE2022065-1,
BE2022065-3.
 
1789KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Li Lin et al.
References
[1]Lei Bai, Lina Yao, Can Li, Xianzhi Wang, and Can Wang. 2020. Adaptive graph
convolutional recurrent network for traffic forecasting. Advances in neural
information processing systems 33 (2020), 17804â€“17815.
[2]Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. 2014.
Empirical evaluation of gated recurrent neural networks on sequence modeling.
InNIPS 2014 Workshop on Deep Learning, December 2014.
[3]Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin Wang, and Guoping Hu.
2020. Revisiting Pre-Trained Models for Chinese Natural Language Processing. In
Findings of the Association for Computational Linguistics: EMNLP 2020. 657â€“668.
[4]Yue Cui, Jiandong Xie, and Kai Zheng. 2021. Historical inertia: A neglected but
powerful baseline for long sequence time-series forecasting. In Proceedings of
the 30th ACM International Conference on Information & Knowledge Management.
2965â€“2969.
[5]Neema Davis, Gaurav Raina, and Krishna Jagannathan. 2020. Grids versus graphs:
Partitioning space for improved taxi demand-supply forecasts. IEEE Transactions
on Intelligent Transportation Systems 22, 10 (2020), 6526â€“6535.
[6]Daizong Ding, Mi Zhang, Xudong Pan, Min Yang, and Xiangnan He. 2019. Mod-
eling extreme events in time series prediction. In Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discovery & Data Mining. 1114â€“
1122.
[7]Harris Drucker, Christopher J Burges, Linda Kaufman, Alex Smola, and Vladimir
Vapnik. 1996. Support vector regression machines. Advances in neural information
processing systems 9 (1996).
[8]Aniekan Essien, Ilias Petrounias, Pedro Sampaio, and Sandra Sampaio. 2021. A
deep-learning model for urban traffic flow prediction with traffic events mined
from twitter. World Wide Web 24, 4 (2021), 1345â€“1368.
[9]Xu Geng, Yaguang Li, Leye Wang, Lingyu Zhang, Qiang Yang, Jieping Ye, and
Yan Liu. 2019. Spatiotemporal multi-graph convolution network for ride-hailing
demand forecasting. In Proceedings of the AAAI conference on artificial intelligence,
Vol. 33. 3656â€“3663.
[10] Zhuoning Guo, Hao Liu, Le Zhang, Qi Zhang, Hengshu Zhu, and Hui Xiong. 2022.
Talent Demand-Supply Joint Prediction with Dynamic Heterogeneous Graph
Enhanced Meta-Learning. In Proceedings of the 28th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining. 2957â€“2967.
[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770â€“778.
[12] Chao Huang, Jiashu Zhao, and Dawei Yin. 2021. Purchase intent forecasting with
convolutional hierarchical transformer networks. In 2021 IEEE 37th International
Conference on Data Engineering (ICDE). IEEE, 2488â€“2498.
[13] Xuanwen Huang, Yang Yang, Ziqiang Cheng, Shen Fan, Zhongyao Wang, Juren
Li, Jun Zhang, and Jingmin Chen. 2021. How Powerful are Interest Diffusion
on Purchasing Prediction: A Case Study of Taocode. In Proceedings of the 44th
International ACM SIGIR Conference on Research and Development in Information
Retrieval. 1308â€“1317.
[14] Huiling Jian, Chuanlei Wang, and Xiaocheng Jiang. 2021. Integrated Operation
Mode of Warehousing and Distribution in the O2O Environment. In The Inter-
national Conference on Artificial Intelligence and Logistics Engineering. Springer,
161â€“170.
[15] Dan Kalifa, Uriel Singer, Ido Guy, Guy D Rosin, and Kira Radinsky. 2022. Lever-
aging World Events to Predict E-Commerce Consumer Demand under Anomaly.
InProceedings of the Fifteenth ACM International Conference on Web Search and
Data Mining. 430â€“438.
[16] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In International Conference on Learning Repre-
sentations. https://openreview.net/forum?id=SJU4ayYgl
[17] Fuxian Li, Jie Feng, Huan Yan, Guangyin Jin, Fan Yang, Funing Sun, Depeng Jin,
and Yong Li. 2021. Dynamic graph convolutional recurrent network for traffic
prediction: Benchmark and solution. ACM Transactions on Knowledge Discovery
from Data (TKDD) (2021).
[18] Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion Convolutional
Recurrent Neural Network: Data-Driven Traffic Forecasting. In International
Conference on Learning Representations.
[19] Junming Liu, Leilei Sun, Qiao Li, Jingci Ming, Yanchi Liu, and Hui Xiong. 2017.
Functional zone based hierarchical demand prediction for bike system expansion.
InProceedings of the 23rd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining. 957â€“966.
[20] Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2022.
A Time Series is Worth 64 Words: Long-term Forecasting with Transformers. In
The Eleventh International Conference on Learning Representations.
[21] Huiling Qin, Songyu Ke, Xiaodu Yang, Haoran Xu, Xianyuan Zhan, and Yu Zheng.
2021. Robust spatio-temporal purchase prediction via deep meta learning. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 4312â€“4319.
[22] Zezhi Shao, Zhao Zhang, Wei Wei, Fei Wang, Yongjun Xu, Xin Cao, and Chris-
tian S Jensen. 2022. Decoupled dynamic spatial-temporal graph neural network
for traffic forecasting. arXiv preprint arXiv:2206.09112 (2022).[23] Jiatu Shi, Huaxiu Yao, Xian Wu, Tong Li, Zedong Lin, Tengfei Wang, and Binqiang
Zhao. 2021. Relation-aware meta-learning for e-commerce market segment de-
mand prediction with limited records. In Proceedings of the 14th ACM International
Conference on Web Search and Data Mining. 220â€“228.
[24] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[25] Petar VeliÄkoviÄ‡, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
LiÃ², and Yoshua Bengio. 2018. Graph Attention Networks. In International Confer-
ence on Learning Representations. https://openreview.net/forum?id=rJXMpikCZ
[26] Dong Wang, Wei Cao, Jian Li, and Jieping Ye. 2017. DeepSD: Supply-demand
prediction for online car-hailing services using deep neural networks. In 2017
IEEE 33rd international conference on data engineering (ICDE). IEEE, 243â€“254.
[27] Zhaonan Wang, Renhe Jiang, Hao Xue, Flora D Salim, Xuan Song, and Ryosuke
Shibasaki. 2022. Event-aware multimodal mobility nowcasting. In Proceedings of
the AAAI Conference on Artificial Intelligence, Vol. 36. 4228â€“4236.
[28] Zhaonan Wang, Tianqi Xia, Renhe Jiang, Xin Liu, Kyoung-Sook Kim, Xuan Song,
and Ryosuke Shibasaki. 2021. Forecasting Ambulance Demand with Profiled
Human Mobility via Heterogeneous Multi-Graph Neural Networks. In 2021 IEEE
37th International Conference on Data Engineering (ICDE). IEEE, 1751â€“1762.
[29] Billy M Williams and Lester A Hoel. 2003. Modeling and forecasting vehicular
traffic flow as a seasonal ARIMA process: Theoretical basis and empirical results.
Journal of transportation engineering 129, 6 (2003), 664â€“672.
[30] Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng
Long. 2022. TimesNet: Temporal 2D-Variation Modeling for General Time Series
Analysis. In The Eleventh International Conference on Learning Representations.
[31] Tongwen Wu, Yu Yang, Yanzhi Li, Huiqiang Mao, Liming Li, Xiaoqing Wang, and
Yuming Deng. 2021. Representation Learning for Predicting Customer Orders.
InProceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &
Data Mining. 3735â€“3744.
[32] Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang, and Chengqi
Zhang. 2020. Connecting the dots: Multivariate time series forecasting with graph
neural networks. In Proceedings of the 26th ACM SIGKDD international conference
on knowledge discovery & data mining. 753â€“763.
[33] Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019.
Graph wavenet for deep spatial-temporal graph modeling. In Proceedings of the
28th International Joint Conference on Artificial Intelligence. 1907â€“1913.
[34] Junchen Ye, Leilei Sun, Bowen Du, Yanjie Fu, Xinran Tong, and Hui Xiong. 2019.
Co-prediction of multiple transportation demands based on deep spatio-temporal
neural network. In Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining. 305â€“313.
[35] Haitao Yuan, Guoliang Li, Zhifeng Bao, and Ling Feng. 2021. An effective joint pre-
diction model for travel demands and traffic flows. In 2021 IEEE 37th International
Conference on Data Engineering (ICDE). IEEE, 348â€“359.
[36] Yuan Yuan, Muzhi Guan, Zhilun Zhou, Sundong Kim, Meeyoung Cha, Depeng Jin,
and Yong Li. 2021. Disruption in chinese e-commerce during covid-19. Frontiers
in Computer Science 3 (2021), 668711.
[37] Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. 2023. Are transformers
effective for time series forecasting?. In Proceedings of the AAAI conference on
artificial intelligence, Vol. 37. 11121â€“11128.
[38] Mingyang Zhang, Tong Li, Yong Li, and Pan Hui. 2021. Multi-view joint graph
representation learning for urban region embedding. In Proceedings of the Twenty-
Ninth International Conference on International Joint Conferences on Artificial
Intelligence. 4431â€“4437.
[39] Xin Zhang, Yanhua Li, Xun Zhou, Oren Mangoubi, Ziming Zhang, Vincent Filardi,
and Jun Luo. 2021. DAC-ML: Domain Adaptable Continuous Meta-Learning
for Urban Dynamics Prediction. In 2021 IEEE International Conference on Data
Mining (ICDM). IEEE, 906â€“915.
[40] Yingxue Zhang, Yanhua Li, Xun Zhou, and Jun Luo. 2020. cST-ML: Continuous
spatial-temporal meta-learning for traffic dynamics prediction. In 2020 IEEE
International Conference on Data Mining (ICDM). IEEE, 1418â€“1423.
[41] Ling Zhao, Yujiao Song, Chao Zhang, Yu Liu, Pu Wang, Tao Lin, Min Deng, and
Haifeng Li. 2019. T-gcn: A temporal graph convolutional network for traffic
prediction. IEEE transactions on intelligent transportation systems 21, 9 (2019),
3848â€“3858.
[42] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong,
and Wancai Zhang. 2021. Informer: Beyond efficient transformer for long se-
quence time-series forecasting. In Proceedings of the AAAI conference on artificial
intelligence, Vol. 35. 11106â€“11115.
[43] Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin.
2022. Fedformer: Frequency enhanced decomposed transformer for long-term
series forecasting. In International Conference on Machine Learning. PMLR, 27268â€“
27286.
[44] Xian Zhou, Yanyan Shen, Yanmin Zhu, and Linpeng Huang. 2018. Predicting
multi-step citywide passenger demands using attention-based neural networks.
InProceedings of the Eleventh ACM international conference on web search and
data mining. 736â€“744.
 
1790MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
A APPENDIX
A.1 Mathematical Notations
The key mathematical notations are listed in Table 4.
A.2 Data Details
Taking Shanghai as an example, we provide specific examples of
original data, as shown in Table 5, categorized into five types: order
data, delivery station data, user data, emergent event data, news
data, and periodic event data.
For the news data, we crawled the dates, news sources, and news
titles from the important news website of the Shanghai Municipal
Peopleâ€™s Government, as illustrated in Fig. 14. For the Fine-tuning
stage (2020/1/1-2020/12/31), we labeled the news using a keyword
filtering and manual review approach. The chosen base keywords
were epidemic, lockdown, resumption, masks, etc., and itâ€™s worth
noting that these keywords can be replaced based on different
events. A label of 1 indicates that the news title is related to this
emergent event, while a label of 0 indicates no relevance to this
emergent event. Consequently, we obtained the limited labeled
news titles during the Fine-tuning stage as depicted in Fig. 5. Miss-
ing news filling tricks are also applied in the Adapting to prediction
tasks stage to cope with the different number of news at each time
step and facilitate conversion into tensors.
A.3 Metrics
We deploy three metrics Mean Absolute Error (MAE), Root Mean
Square Error (RMSE), and Symmetric Mean Absolute Percentage Er-
ror (sMAPE) suitable to measure the performance of the predictive
model.
ğ‘€ğ´ğ¸ =1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1|ğ‘¦ğ‘–âˆ’Ë†ğ‘¦ğ‘–|
ğ‘…ğ‘€ğ‘†ğ¸ =vt
1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1(ğ‘¦ğ‘–âˆ’Ë†ğ‘¦ğ‘–)2
ğ‘ ğ‘€ğ´ğ‘ƒğ¸ =1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1|ğ‘¦ğ‘–âˆ’Ë†ğ‘¦ğ‘–|
(|ğ‘¦ğ‘–|+|Ë†ğ‘¦ğ‘–|)/2(17)A.4 Additional Experimental Results
To further verify the generalizability of our model in various sce-
narios, we evaluate MulSTE on a filtered sub-dataset named NE by
omitting all samples that happen under emergent events, aiming to
know whether MulSTE can accurately predict the demand-supply
sequences when no emergent events happen. Similarly, we filtered
all samples related to emergent events to construct the sub-dataset
PE. We adopt two different evaluating approaches: retraining (RT)
and direct inference (DI) where RT needs to train another MulSTE
model on the given sub-dataset and DI directly use the trained Mul-
STE on the raw dataset to make inference on the two sub-datasets.
The experimental results are shown in Table 6. It demonstrates that
on NE sub-datasets, MulSTE outperforms all baselines with a signif-
icant margin whenever we use the re-trained model or directly infer
on the pre-trained one. However, when evaluating the models on
PE sub-datasets, a few metrics show a slight weakness of MulSTE
compared with Informer and AGCRN. For example, when predict-
ing the supply volume on the Shanghai PE sub-dataset, AGCRN has
a comparable performance compared with MulSTE either through
RT or DI. Whether the spatial or temporal information makes more
contributions to the overall performance is also a question hard to
answer. Factually, although MulSTE may not achieve the best per-
formance in some specific evaluation settings, it still wins second
place compared with others. It confirms that our proposed MulSTE
is competent in generalized situations, even using direct inference
without further training.
Figure 14: News Web of Shanghai Municipal Peopleâ€™s Gov-
ernment.
Table 4: Key mathematical notations.
Notation Definition Notation Definition
ğºâˆ—The multi-view graph â„ğ·
ğ‘¡The hidden state of demand at time step ğ‘¡
ğ‘ The number of regions â„ğ‘†
ğ‘¡ The hidden state of supply at time step ğ‘¡
ğ‘‘ğ‘¡ The purchase demand at time step ğ‘¡ â„ğ¸
ğ‘¡ The hidden state of event at time step ğ‘¡
ğ‘ ğ‘¡ The delivery supply at time step ğ‘¡ â„ğ·ğ¼
ğ‘¡The hidden state of interacted demand at time step ğ‘¡
ğ‘’ğ‘¢
ğ‘¡ The textual type events at time step ğ‘¡â„ğ‘†ğ¼
ğ‘¡The hidden state of interacted supply at time step ğ‘¡
ğ‘’ğ‘›
ğ‘¡ The numerical type events at time step ğ‘¡â„ğ·ğ¸
ğ‘‡The final demand-related event representation
ğ‘’ğ‘
ğ‘¡The categorical type events at time step ğ‘¡â„ğ‘†ğ¸
ğ‘‡The final supply-related event representation
ğ·ğ‘¡ The demand representation at time step ğ‘¡ğ»ğ·
ğ‘‡The final demand representation
ğ‘†ğ‘¡ The supply representation at time step ğ‘¡ğ»ğ‘†
ğ‘‡The final supply representation
ğ¸ğ¹ğ‘ ğ‘›
ğ‘¡The event fusion representation at time step ğ‘¡LD The loss of demand prediction task
ğœƒ The model parameter set of MulSTE LS The loss of supply prediction task
ğ‘‡ The length of previous sequence Lğœƒ The loss of joint prediction task
ğ‘™ The length of future sequence ğ‘‘â„ The dimension of hidden state
 
1791KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Li Lin et al.
Table 5: Data Details.
Original Data Attribute Example
Order DataOrder_ID JD*********9544
Purchase timestamp 2022/3/7 22:25
Delivery timestamp 2022/3/8 9:15
Region ID 26
User ID User_0
Delivery Station DataRegion ID 26
Name Shanghai Guchuan Delivery Station
Location 121.3921â—¦ğ¸,31.2523â—¦ğ‘
Scope POLYGON ((121.3844 31.2604, ...., 121.3844 31.2604))
Types (counts, areas, distances) Type0: 2, 0.2924, 0.1518; ... ; Type8: 5, 0.2345, 0.1976
User DataUser ID User_0
Region ID 26
Gender ****
Age ****
. . . . . . . . . . . .
Purchasing power ****
Promotion sensitivity ****
Emergent Event DataDate 2022/3/7
Outbreak location Addressä¸Šæµ·å¸‚/å¾æ±‡åŒº/æ¼•æºªåŒ—è·¯/1200å·
(No. 1200, Caoxi North Road, Xuhui District, Shanghai)
coordinates 121.4356â—¦ğ¸,31.1818â—¦ğ‘
Risk area location Addressä¸Šæµ·å¸‚/å˜‰å®šåŒº/é©¬é™†é•‡/å®å®‰å…¬è·¯/3705å¼„/1å·
(No. 1, Lane 3705, Baoâ€™an Road, Malu Town, Jiading District, Shanghai)
coordinates 121.2680â—¦ğ¸,31.3248â—¦ğ‘
News DataDate 2022/3/13
News Source è§£æ”¾æ—¥æŠ¥ (JIEFANG DAILY)
News titleä¸Šæµ·è¿›ä¸€æ­¥å¼ºåŒ–ç–«æƒ…é˜²æ§æªæ–½å¸‚æ°‘éå¿…è¦ä¸ç¦»æ²ª
(Shanghai further strengthens epidemic prevention and control measures;
citizens do not leave Shanghai unless necessary.)
Label 1 - emergent event related
Periodic Event DataDate 2022/6/18
Day of Week Saturday
Festival Type Mid-year Promotion
Table 6: Model effectiveness validation in the simulation of non-emergent and prolonged-emergent scenarios.
Type ModelsRT DI
Demand Supply Demand Supply
MAE RMSE sMAPE MAE RMSE sMAPE MAE RMSE sMAPE MAE RMSE sMAPE
SHNEAGCRN 203.59 420.70 12.22% 136.52 208.98 9.03% 150.65 298.10 9.86% 127.83 201.04 8.64%
Informer 211.53 415.00 12.63% 135.18 206.65 9.04% 192.22 411.38 12.07% 128.46 206.83 8.68%
MulSTE 139.19 265.06 8.78% 112.17 178.76 7.54% 113.50 204.07 7.86% 117.79 188.08 8.13%
PEAGCRN 190.69 284.16 13.10% 277.11 465.13 23.80% 245.13 600.32 13.73% 258.05 453.10 21.91%
Informer 182.11 281.47 12.37% 276.99 483.69 25.31% 330.41 783.72 17.88% 259.43 482.03 23.71%
MulSTE 181.17 262.78 13.61% 278.28 462.67 23.90% 195.75 389.92 12.76% 259.05 441.69 20.76%
ZZNEAGCRN 187.36 423.56 13.78% 148.60 279.44 11.71% 148.03 332.71 12.34% 134.99 248.57 11.10%
Informer 200.57 440.16 13.93% 128.64 240.11 10.54% 147.04 345.92 11.80% 127.24 255.75 10.04%
MulSTE 109.87 199.40 10.71% 107.81 202.46 9.27% 97.80 184.26 9.52% 95.21 175.92 8.61%
PEAGCRN 316.59 624.98 23.63% 281.36 463.60 34.45% 186.17 446.21 16.29% 243.62 480.81 34.57%
Informer 307.85 632.21 22.39% 264.02 442.96 34.76% 183.79 457.54 14.80% 220.30 478.52 32.69%
MulSTE 250.51 496.86 21.77% 282.38 438.00 34.77% 126.84 228.48 13.53% 157.87 271.73 28.79%
 
1792