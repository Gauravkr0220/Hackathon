Propagation Structure-Aware Graph Transformer for Robust and
Interpretable Fake News Detection
Junyou Zhu
School of Artificial Intelligence,
Optics and Electronics
Northwestern Polytechnical
University
Xiâ€™an, China
Potsdam Institute for Climate Impact
Research
Potsdam, Germany
Junyou.Zhu@pik-potsdam.deChao Gao
School of Artificial Intelligence,
Optics and Electronics
Northwestern Polytechnical
University
Xiâ€™an, China
cgao@nwpu.edu.cnZe Yin
Hunan University
College of Computer Science and
Electronic Engineering
Changsha, China
zyin@hnu.edu.cn
Xianghua Liâˆ—
School of Artificial Intelligence,
Optics and Electronics
Northwestern Polytechnical
University
Xiâ€™an, China
li_xianghua@nwpu.edu.cnJuergen Kurths
Potsdam Institute for Climate Impact
Research
Potsdam, Germany
Department of Physics
Humboldt-UniversitÃ¤t zu Berlin
Berlin, Germany
kurths@pik-potsdam.de
Abstract
The rise of social media has intensified fake news risks, prompting
a growing focus on leveraging graph learning methods such as
graph neural networks (GNNs) to understand post-spread patterns
of news. However, existing methods often produce less robust and
interpretable results as they assume that all information within
the propagation graph is relevant to the news item, without ade-
quately eliminating noise from engaged users. Furthermore, they
inadequately capture intricate patterns inherent in long-sequence
dependencies of news propagation due to their use of shallow GNNs
aimed at avoiding the over-smoothing issue, consequently dimin-
ishing their overall accuracy. In this paper, we address these issues
by proposing the Propagation Structure-aware Graph Transformer
(PSGT). Specifically, to filter out noise from users within propa-
gation graphs, PSGT first designs a noise-reduction self-attention
mechanism based on the information bottleneck principle, aiming
to minimize or completely remove the noise attention links among
task-irrelevant users. Moreover, to capture multi-scale propagation
structures while considering long-sequence features, we present a
novel relational propagation graph as a position encoding for the
graph Transformer, enabling the model to capture both propagation
âˆ—Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672024depth and distance relationships of users. Extensive experiments
demonstrate the effectiveness, interpretability, and robustness of
our PSGT.
CCS Concepts
â€¢Computing methodologies â†’Knowledge representation
and reasoning; â€¢Information systems â†’Data mining.
Keywords
Fake News Detection; Graph Transformer; Social Networks
ACM Reference Format:
Junyou Zhu, Chao Gao, Ze Yin, Xianghua Li, and Juergen Kurths. 2024.
Propagation Structure-Aware Graph Transformer for Robust and Inter-
pretable Fake News Detection. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD â€™24), August
25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3637528.3672024
1 Introduction
In the current digital age, the rapid growth of the Internet has
provided unprecedented opportunities for the production, dissemi-
nation, and consumption of fake news [ 56]. Such deceptive news
disrupts public opinion [ 46] and social harmony [ 47], but also under-
mines trust in institutions [ 13]. Hence, effective fake news detection
methods are crucial for public access to reliable information.
Graph Neural Networks (GNNs) [ 68,69] have recently demon-
strated their efficacy in identifying user propagation patterns, offer-
ing vital insights for fake news detection [ 4,11,11,49,51]. While
these methods have improved detection accuracy, they have not
mitigated crucial public concerns regarding the fairness and trans-
parency of such automated systems. This public skepticism has
4652
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Junyou Zhu, Chao Gao, Ze Yin, Xianghua Li, & Juergen Kurths
p1
p8 p7p5s
p2 p3
p10p6p4
p9Relevant topic Noise topicSource News
(a) (a) A Simplified Illustration of Fake News Propagation Graph
(b) 
p1
p8 p7p5s
p2 p3
p10p6p4
p9On-Topic 
but FalseOff-Topic 
but True
(a) 
A major hurricane is expected to 
make landfall on the US West Coast 
tomorrowâ€¦
Has the government 
declared an 
emergency ?
Speaking of the US, 
has anyone tried that 
new NY burger ?
Looks bad. Stock up !
Yep, loved their burgers !
A major hurricane is expected to 
make landfall on the US West Coast 
tomorrowâ€¦
Speaking of the US, 
has anyone tried that 
new NY burger ?
Yep, loved their burgers !
Has the government 
declared an 
emergency ?
Looks bad. Stock up !(b) 
p1
p8 p7p5s
p2 p3
p10p6p4
p9On-Topic 
but FalseOff-Topic 
but True
(a) 
A major hurricane is expected to 
make landfall on the US West Coast 
tomorrowâ€¦
Speaking of the US, 
has anyone tried that 
new NY burger ?
Yep, loved their burgers !
Has the government 
declared an 
emergency ?
Looks bad. Stock up !
A Bot or M alicious User
A Normal  User
(a) (b) 
Figure 1: (a) Illustrates noise patterns in news propagation
graphs. (b) Empirically observes noise information in two
news propagation graphs and the average observation across
all graphs in the Politifact dataset [ 45]. Using k-means [ 14],
users are divided into two groups (A and B) based on their
features. Gaussian noise, defined by a Gaussian distribution
ğœ€âˆ¼ğ‘(0,1), is then injected to observe its effects. After 50 runs,
successful classifications are counted. Some groups show
minimal effects, possibly due to task-irrelevant participants
like bots or malicious users.
led many organizations to continue relying on human interven-
tion to address fake news, as it provides a clear explanation for
classifying news as either true or false. Thus, enhancing the ro-
bustness, transparency, and interpretability of fake news detection
models is essential for their final application in real-world scenar-
ios. Nonetheless, enhancing model interpretability to improve user
trust remains challenging by two critical issues. Firstly , real-world
scenarios often involve noise, such as malicious content from users
or AI, misleading models to make false predictions and explana-
tions [ 51]. Ensuring that models can eliminate this noise to provide
clear, transparent explanations without sacrificing accuracy is essen-
tial for their wider acceptance and practical application. Secondly ,
existing GNN-based detection models, including those designed
for interpretability, often struggle to balance capturing news long-
sequence propagation structures with avoiding over-smoothing,
inherent in their design to learn local patterns [ 27,60,71]. An over-
reliance on local propagation structures fails to capture key shifts in
news propagation, which can compromise detection accuracy, even
if some models provide explanations, contradicting the objectives
of practitioners.
Regarding the noisy information in propagation graphs, as il-
lustrated in Figure 1 (a), malicious users are frequently engaged
in introducing noise to news comments. Such interactions from
adversarial entities often introduce task-irrelevant noise such as
disruptive comments, negatively impacting or at best not aiding
the model interpretability and prediction [ 24,50]. Figure 1 (b) em-
pirically validates this through a case study on news propagation
graphs in Political dataset [ 45]. Intriguingly, specific user groups
within propagation graphs, such as group A, display resilience tonoise injection, possibly due to the involvement of irrelevant partic-
ipants such as bots. This resilience implies that group A is primarily
composed of noise information, as the presence of substantial task-
relevant content would have resulted in a marked decrease in model
accuracy following noise injection. In contrast, others, like group B,
show pronounced susceptibility, likely because these users featured
useful task-relevant information. Such empirical insights provide
guidelines for us to enhance both the reliability and accuracy of
fake news detection, particularly by mitigating noise impact in
news propagation graphs. Despite methods like UPFD [ 11] use
self-attention to focus on key features, recent studies [ 34,40,61]
question the efficacy of attention mechanisms in prioritizing im-
pactful features, challenging their utility in enhancing the reliable
interpretability in fake news detection.
As for tracking the long-sequence propagation dependencies in
news propagation graphs, they remain a critical yet under-explored
aspect. These dependencies capture subtle and vital shifts in user
engagements, such as comment topic changes and community evo-
lution, during information dissemination. As news diffuses, its cas-
cade depth increases, as evidenced in Appendix D.2 (Figure 6), indi-
cating a substantial propagation distance between some engaged
users and the source news. This could explain why existing fake
news detection methods [ 4,11,51] based on shallow GNNs often
merge features from the original news source into subsequent user
nodes. However, such a strategy dilutes a certain task-irrelevant
noise signal of users by mixing it with task-relevant information of
source news, thereby undermining the capability of models for effec-
tive noise filtration, as we demonstrated in Appendix D.2 (Figure 7).
While the adoption of vanilla Transformers [ 54] could intuitively
address long-sequence dependencies, recent insights [ 34,40,61]
have found that their attention mechanisms do not inherently pri-
oritize features that most significantly impact the output and fail
to adequately model the structural relationships within propaga-
tion graphs. Although some recent graph-based Transformers have
shown being promising in domains like protein prediction [ 37,67],
their architecture is not well-suited to the information diffusion-
based structure characteristic of news propagation graphs, as il-
lustrated in Appendix D.2, restricting their direct applicability in
robust and interpretable fake news detection.
In this work, we aim to address the above issues by proposing
thePropagation Structure-aware Graph Transformer (PSGT), a
novel propagation structure-aware graph Transformer designed
with innate interpretability and robustness for fake news detection.
Building on the information bottleneck (IB) principle [ 2,52], PSGT
integrates a noise-reduction mechanism within the Transformer
architecture, aiming to selectively guide task-relevant information
flow across the propagation graph while systematically eliminating
extraneous noise. This mechanism initially treats user relationships
as a fully connected attention graph, subsequently removing atten-
tion links between task-irrelevant graph components to prevent
noise transmission. The graph components, such as nodes with
abundant connected attention links in the learned noise-reduction
attention graph, are eventually identified as task-relevant, and their
propagation structure provides interpretability. The model is also
expected to be more robust due to its adept noise-filtering capa-
bilities. Furthermore, to model the long-sequence dependencies
and the distinctive structural characteristics of news propagation
4653Propagation Structure-Aware Graph Transformer for Robust and Interpretable Fake News Detection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
graphs, we introduce a new positional encoding strategy for the
graph Transformer. This strategy models the depth and relational
distances among users in the propagation graph, enabling the Trans-
former architecture to be aware of the propagation structure.
In summary, our contributions are as follows:
â€¢We design a novel noise-reduction mechanism for the graph
Transformer based on the IB principle. This mechanism ef-
fectively removes task-irrelevant attention links within the
self-attention module, yielding interpretable and robust re-
sults. To the best of our knowledge, PSGT is the first to
propose a unified graph-based IB method for interpretable
fake news detection.
â€¢We present a new positional encoding approach rooted in the
propagation structure, enabling the model to capture both
the propagation structure and long-sequence dependencies,
further enhancing both the accuracy and reliability of fake
news detection.
2 Related Work
2.1 Fake News Detection
Fake news detection is generally framed as a binary classification
problem, aiming to determine the verity or falsity of a specific
news article. There are two category methods highly related to our
work: Content-based andpropagation-network-based methods.
Content-based methods have employed an array of advanced deep
learning models such as recurrent neural networks (RNNs) [ 36]
and pre-trained language models to extract semantic signatures
from the news articles [ 26,64]. In addition to news content, vari-
ous complementary features have also been explored to enhance
prediction accuracy. These supplementary inputs encompass in-
formation drawn from knowledge graphs [ 8,12,17], corroborative
evidence from external repositories [ 7,43], visual cues from associ-
ated images [ 6,41], and environmental metadata surrounding the
news ecosystem [ 42]. Acknowledging that the spread of fake news
is inherently a social phenomenon, propagation-network-based
methods incorporate various social attributes into their frame-
works [ 4,28,44,48,51,57,60,70]. These social indicators include,
but are not limited to, user interaction metrics [ 62], social net-
work connectivity patterns [ 15,32,72], historical posting activity
of users [ 11] and provenance of the news source. Although existing
methods have proven being effective in modeling social information,
they have overlooked the critical aspect of long-sequence depen-
dencies inherent in news propagation structures. Moreover, these
approaches often suffer from low interpretability and increased sus-
ceptibility to noise within the propagation graphs, primarily due to
their inadequacy in effectively filtering out malicious information.
2.2 Graph Transformer
The Transformer architecture [ 54], a category of neural networks,
has influenced a wide array of tasks, from text to visual data process-
ing [ 53]. However, pure Transformers lack intrinsic relationships
between tokens, thus requiring additional positional encodings for
structural understanding. To address this shortcoming, recent stud-
ies have explored specialized Transformer adaptations for graph-
structured tasks [ 29,31]. These adaptations fall into two categoriesrelevant to our study: the first utilizes absolute positional en-
codings (APE) through techniques like Laplacian vectors [ 23] or
random walks [ 25] to convey nodal structure; the second employs
relative positional encodings (RPE) to enrich the attention mech-
anism with structural information derived from graph distances or
features generated by GNNs [ 67]. Additionally, some frameworks
incorporate Transformers as modular components in more com-
plex architectures [ 38]. Despite the progress, these approaches are
primarily configured for generic graph-related tasks or specific
applications such as recommendation systems [ 33]. Designing a
specialized graph Transformer to tackle fake news detection, par-
ticularly by utilizing distinct structural characteristics inherent to
news propagation graphs, remains an unsolved challenge.
3 Preliminaries
As preliminaries, we define the problem formulation and concepts.
3.1 Problem Formulation
Fake news detection can be defined as a task of binary classification.
The main objective is to train a classifier utilizing a dataset of
labeled news and subsequently employ this classifier to determine
the veracity of a given test news article.
To provide clarity in our formulation, let us denote our dataset
of news articles as C={ğ‘1,ğ‘2,...ğ‘ğ‘š}, whereğ‘ğ‘–denotes the ğ‘–-th
news article and ğ‘šrepresents the total count of articles in the
dataset. Each news article ğ‘ğ‘–can be described as a tuple ( ğ‘¦,G).
Here,ğ‘¦indicates the ground truth label belonging to either ğ¹orğ‘…,
symbolizing whether the news is Fake or Real respectively. Mean-
while,G=(V,E)represents the propagation structure associated
with the news article ğ‘ğ‘–. Specifically,V={ğ‘£0,ğ‘£1,...ğ‘£ğ‘}, where
ğ‘£0represents the source news, and ğ‘£ğ‘–denotes an engaged user of
the news. The set of edges Eis defined asE=
ğ‘’ğ‘–ğ‘—|ğ´ğ‘–ğ‘—â‰ 0, for
ğ‘–,ğ‘—=0,...,ğ‘}, whereğ´ğ‘–ğ‘—is an element of the adjacency matrix
Athat indicates a direct reply or comment relationship from user
ğ‘£ğ‘–to userğ‘£ğ‘—. In this work, we follow prior work [ 11] to generate
the initial features ğ‘¥ğ‘–of each node by using pre-trained BERT [ 10]
embeddings to encode the news content and users who comment
on the news.
To encapsulate the described framework: Given a news collection
Cand a set of training labels ğ‘Œğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› , our goal is to train a classifier
ğ‘“ğœ™. This function, when presented with unseen test news, should
proficiently assign the corresponding veracity labels ğ‘Œğ‘¡ğ‘’ğ‘ ğ‘¡.
3.2 Transformers on Graphs
3.2.1 Original Transformers. The Transformer architecture is com-
posed of several Transformer layers. Each layer comprises two pri-
mary modules: a multi-head self-attention mechanism (MSA) and
a feed-forward network (FFN). The head self-attention mechanism
is crucial for identifying and comprehending the intrinsic semantic
relationships among input tokens. Given an input XâˆˆRğ‘›Ã—ğ‘‘for
theğ»head self-attention mechanism, where ğ‘›is the number of
tokens andğ‘‘denotes the hidden dimension, the mechanism maps
Xinto three separate spaces: Qâ„,Kâ„, and Vâ„. More formally, the
projections can be described as Qâ„=XWâ„
Q,Kâ„=XWâ„
K, and
Vâ„=XWâ„
Vrespectively. For each head â„, the self-attention can
4654KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Junyou Zhu, Chao Gao, Ze Yin, Xianghua Li, & Juergen Kurths
then be computed by
Attnâ„(X)=softmax 
Qâ„Kâ„ğ‘‡
âˆšï¸
ğ‘‘ğ»!
(1)
where Wâ„
QâˆˆRğ‘‘Ã—ğ‘‘ğ»,Wâ„
KâˆˆRğ‘‘Ã—ğ‘‘ğ», and Wâ„
VâˆˆRğ‘‘Ã—ğ‘‘ğ»are trainable
matrices for each head â„.ğ»means the total number of heads. ğ‘‘ğ»
denotes the dimension of each head. Subsequently, the output of
the self-attention mechanism is combined with a skip-connection,
followed by a feed-forward network. Together, these components
constitute a Transformer layer, as illustrated below:
Xâ€²=X+ğ»âˆ‘ï¸
â„=1Attnâ„(X)Vâ„Wâ„
ğ‘‚(2)
Z=FFN(Xâ€²)=ReLU(Xâ€²W1)W2 (3)
where Wâ„
ğ‘‚âˆˆRğ‘‘ğ»Ã—ğ‘‘,W1âˆˆRğ‘‘Ã—ğ‘ŸandW2âˆˆRğ‘ŸÃ—ğ‘‘are trainable
matrices.
3.2.2 Graph Transformers. Owing to the inherent equivariance of
self-attention to input node permutations, the Transformer consis-
tently produces identical node representations for nodes with the
same attributes, regardless of their positions or graph structures.
Addressing this, recent studies have introduced positional encoding
strategies, i.e., APE and RPE. Our work aligns more closely with
RPE, for which we subsequently provide a mathematical formula-
tion. For APE insights, readers are referred to [ 31]. RPE-based graph
Transformer emphasizes relative structural relationships between
node pairs. Building on this, most preceding research has adjusted
the attention computation described in Equation (1), as follows:
Attnâ„
ğ‘…ğ‘ƒğ¸(X)=softmax 
Qâ„Kâ„ğ‘‡
âˆšï¸
ğ‘‘ğ»+B!
(4)
where Bis anğ‘›Ã—ğ‘›matrix. The entry ğ‘ğ‘–ğ‘—inBrepresents the inter-
action between nodes ğ‘£ğ‘–andğ‘£ğ‘—. Different parameterizations of B
yield distinct model architectures. However, prevalent RPE-based
graph Transformer methods exhibit two limitations. Firstly, they in-
terpret the network as a fully connected graph within the attention
mechanism, lacking the precision to highlight task-relevant fea-
tures and exclude noise, our method solves these issues, as detailed
in Section 4.2. Secondly, these methods, such as GraphGPS [ 37],
are only generic structure-aware, in contrast to our specifically tai-
lored propagation structures-aware RPE strategy, detailed further
in Section 4.3.
3.3 Information Bottleneck
Various techniques, including feature selection-based [ 5] and motif-
based methods [ 65], have been explored to mitigate noise in graphs.
However, these methods often impose inherent biased constraints,
notably setting constraints on the size and connectivity of task-
relevant subgraphs. For instance, in the domain of protein graphs [ 18],
functionally similar group structures exhibit consistency in size. In
contrast, domains like news propagation graphs lack this unifor-
mity, with task-relevant substructures displaying variations in size
and connectivity.
Informed by the information bottleneck (IB) principle [ 63], we
exclude the task-irrelevant noise by compressing the propagationgraphGwithout imposing any structural constraints, i.e., solving
max
Gğ‘ ğ¼(Gğ‘ ;ğ‘Œ), s.t.ğ¼(Gğ‘ ;ğº)â‰¤ğ›¾,Gğ‘ âˆˆGğ‘ ğ‘¢ğ‘(G) (5)
whereğ›¾is a compression parameter and Gğ‘ ğ‘¢ğ‘(G)represents the set
of subgraphs derived from G.ğ¼(ğ‘;ğ‘)â‰œÃ
ğ‘,ğ‘P(ğ‘,ğ‘)logP(ğ‘,ğ‘)
P(ğ‘)P(ğ‘)
represents the mutual information (MI) between variables ğ‘andğ‘.
Specifically, when handling irregular graph data, the IB framework
applies the constraint ğ¼(Gğ‘ ;ğº)â‰¤ğ›¾. This guides the selection of
Gğ‘ to absorb only pivotal information from Gto predict the label
ğ‘Œ, thereby maximizing ğ¼(Gğ‘ ;ğ‘Œ). Consequently,Gğ‘ plays a crucial
role in the interpretability of the model.
Recent studies have also leveraged the IB principle for graph
learning [30, 69], primarily focusing on local structures via GNNs.
However, as we mentioned before, these methods are not well-
suited for fake news detection since news propagation graphs ex-
hibit long-sequence dependencies. To our knowledge, PSGT is the
first to utilize graph IB for fake news detection, effectively eliminat-
ing noise from propagation graphs while producing interpretable
subgraphs that capture both local and long-sequence dependencies.
4 PSGT: Propagation Structure-aware Graph
Transformer
In this section, we introduce a novel graph Transformer designed
for fake news detection. We begin by providing an overview of the
proposed graph Transformer and then present a formal definition
of a feasible information bottleneck intended for noise filtration.
Next, we detail a unique positional encoding strategy for modeling
propagation structures within the graph Transformer. Finally, we
discuss the optimization techniques applied to PSGT.
4.1 Overview of the Proposed Graph
Transformer
We propose an innovative graph Transformer specifically designed
for fake news detection. Notably, this model has the capability to
eliminate noise while capturing the long-sequence dependencies
characteristic inherent in propagation structures. The main differ-
ence between our proposed graph Transformer and the existing
graph Transformer architecture lies in the MSA. Within a standard
MSA layer, there are ğ»attention heads, each implicitly focusing
on different representational subspaces of various nodes. In con-
trast, our model employs a graph-masking mechanism, compelling
these heads to explicitly focus on different subspaces through graph
masks.
As illustrated in Figure 2, our approach begins with the integra-
tion of a feasible information bottleneck. This mechanism learns a
noise-filtered mask graph, Gğ‘ (as detailed in Section 4.2), rooted in
a fully connected attention graph. This guides the attention mech-
anism of graph Transformer to emphasize task-relevant features.
To further enhance the ability of the Transformer to capture news
propagation patterns, we introduce a new propagation structure
modeling strategy. This strategy is tailored for the explicit con-
struction of a structural positional encoding mask, Gğ‘(as detailed
in Section 4.3), grounded in real-world news propagation princi-
ples. Based on this, we modify the self-attention score computation
4655Propagation Structure-Aware Graph Transformer for Robust and Interpretable Fake News Detection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Transformer
D
epth
D
istance
Propagation 
Structure
MLP+Sigmoid
a 
~ Bern(  )
Propagation Graph
z
1
, 
z
2
, ... , 
z
n
ï«
ï«
Transformer
Propagation Graph
z
1
, 
z
2
, ... , 
z
n
D
epth
D
istance
Propagation 
Structure
MLP+Sigmoid
ï«
a
s
ï‡
a 
~ Bern(  )
ï«
p
ï‡
KL
ïŒ
F
eed
-
F
orward 
N
etwork
Graph
-
Masked Transformer (
N
 
Layers)
Graph
-
Masked Multi
-
head Self
-
Attention
Complete Graphs
s
ï‡
f
ï‡
p
ï‡
Graph
-
Level Representatons
MLP+Softmax
Y
cls
ïŒ
Figure 2: The architecture of PSGT. From a given news propa-
gation graph, we first learn a noise-reduced subgraph Gğ‘ and
subsequently construct a more realistic propagation graph
Gğ‘. TheGğ‘ primarily retains task-relevant attention links
between users for enhanced interpretability, while Gğ‘cap-
tures both the propagation depth and distance relationships
among users. Then, using Gğ‘ andGğ‘as graph masks, the
graph Transformer effectively captures propagation struc-
tures and long-sequence dependencies, while filtering out su-
perfluous noise. For label prediction, a binary cross-entropy
loss is applied, and a Kullback-Leibler (KL) loss is employed
for noise-reduced subgraph learning. Both losses are com-
bined for optimal model training.
described in Equation (4) as:
Attnâ„
ğ‘‚ğ‘¢ğ‘Ÿ(X)=softmax 
M(Qâ„Kâ„ğ‘‡
âˆšï¸
ğ‘‘ğ»,Ağ‘–)!
(6)
where Ağ‘–belongs to the set{Ağ‘ ,Ağ‘,Ağ‘“}. Here, Ağ‘ ,Ağ‘andAğ‘“=
1|V|Ã—|V| represent the adjacency matrices for Gğ‘ ,Gğ‘, and a fully-
connected graphGğ‘“respectively. The masking function, M, is
defined as:
M(ğ‘¥,ğœ†)=ğ‘¥+ğœğœ† (7)
whereğœis a sufficiently large value. This approach, while simple,
effectively ensures the attention mechanism recognizes structuralcharacteristics and excludes noise information. Given the three
types of graph masks Gğ‘ ,Gğ‘, andGğ‘“, we divide heads into four
groups. The first two are masked using Ağ‘ andAğ‘, whereas the
latter two utilize Ağ‘“. Note that within Ağ‘“, we avoid imposing any
structural bias, granting the model the most freedom to learn latent
node interrelations. Subsequently, the node representations in ğ‘™-th
Transformer layer, Zğ‘™={z1,z2,...,zğ‘›}, are obtained by the FFN
described in Equation (2).
4.2 A Feasible Graph Information Bottleneck
for Noise Filtration
The inherent attention mechanism within the Transformer does
not selectively prioritize key features that predominantly influence
the output. Consequently, we develop a strategy to learn a noise-
filtered graph mask Gğ‘ for the self-attention mechanism in graph
Transformer. This aims to enhance the ability of the model to em-
phasize task-relevant features and simultaneously filter out noise
information.
4.2.1 A Feasible Graph IB Objective . LetAâ„denote the self-attention
matrix derived from the first head in Transformer layer ğ‘™viaAttnâ„(X).
This can be viewed as a fully-connected attention graph, Gâ„=
(V,Eğ‘“ğ‘¢ğ‘™ğ‘™,Zğ‘™âˆ’1), where Zğ‘™âˆ’1is the output of previous Transformer
layer and Z0=X. Building on this, PSGT first aims to train an
extractorğ‘’Î¦with parameter Î¦to construct task-relevant attention
subgraphGğ‘ âˆˆGğ‘ ğ‘¢ğ‘(Gâ„). By design, ğ‘’Î¦encourages the attention
mechanism to eliminate task-irrelevant information by removing
the noise attention links in Gâ„, ensuring only task-relevant infor-
mation is retained in Gğ‘ . In essence, ğ‘’Î¦(Gâ„)offers a distribution
overGğ‘ ğ‘¢ğ‘(Gâ„), expressed as PÎ¦(Gğ‘ |Gâ„).
Integrating this into Equation (5), we formulate the optimization
criterion for ğ‘’Î¦leveraging the IB principle:
min
Î¦âˆ’ğ¼(Gğ‘ ;ğ‘Œ)+ğ›½ğ¼(Gğ‘ ;Gâ„), ğ‘ .ğ‘¡.Gğ‘ âˆ¼ğ‘’Î¦(Gâ„), ğ›½>0 (8)
We then follow previous works [ 2,35,63] to derive a feasible varia-
tional upper bound for terms present in Equation (8). For the term
ğ¼(Gğ‘ ;ğ‘Œ), a parameterized variational approximation Pğœ™(ğ‘Œ|Gğ‘ )
replaces P(ğ‘Œ|Gğ‘ ), yielding the lower bound:
ğ¼(Gğ‘ ;ğ‘Œ)â‰¥EGğ‘ ,ğ‘Œ[logPğœ™(ğ‘Œ|Gğ‘ )]+ğ»(ğ‘Œ) (9)
Considering ğ»(ğ‘Œ)is a constant, it is extraneous during optimization.
Notably, in our context, Pğœ™(ğ‘Œ|Gğ‘ )functions as the predictor or
the binary classifier ğ‘“ğœ™, which predicts the label ğ‘ŒofGbased onGğ‘ .
For the other term ğ¼(Gğ‘ ;Gâ„), a variational approximation Q(Gğ‘ )is
introduced for the distribution P(Gğ‘ )=Ã
GPÎ¦(Gğ‘ |Gâ„)PGâ„(Gâ„),
resulting in the upper bound:
ğ¼(Gğ‘ ;Gâ„)â‰¤EG[KL(PÎ¦(Gğ‘ |Gâ„)âˆ¥Q(Gğ‘ ))] (10)
Combining these bounds for Equation (8), PSGT objective becomes:
min
Î¦,ğœ™âˆ’E
logPğœ™(ğ‘Œ|Gğ‘ )
+ğ›½E[KL(PÎ¦(Gğ‘ |Gâ„)âˆ¥Q(Gğ‘ ))](11)
In Equation (11), the first term Pğœ™serves as a classifier ğ‘“ğœ™. Conse-
quently, only the terms PÎ¦andQneed further specification, which
we will describe in Section 4.2.2 and Section 4.2.3, respectively.
4656KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Junyou Zhu, Chao Gao, Ze Yin, Xianghua Li, & Juergen Kurths
4.2.2 Noise-Reduction Self-Attention Mechanism via PÎ¦.The func-
tionPÎ¦(Gğ‘ |Gâ„)essentially serves as the extractor ğ‘’Î¦, designed to
extract the task-relevant attention subgraph Gğ‘ fromGâ„. Notably,
due to the densely connected nature of Gâ„, it contains superflu-
ous and noise attention connections that remain unaddressed by
standard self-attention mechanisms.
To address this, we model all attention links as a collection of
independent Bernoulli random variables, each parameterized by its
respective learned weight ğœ…:
As=Ã˜
ğ‘¢,ğ‘£âˆˆEğ‘“ğ‘¢ğ‘™ğ‘™
ğ‘ğ‘¢,ğ‘£âˆ¼Bernoulli ğœ…ğ‘¢,ğ‘£	
(12)
The probability ğœ…, governing the sampling of attention links, is
optimized within the Transformer architecture. Specifically, the
graphGâ„is first encoded by the Transformer, yielding a set of
node representations {zğ‘£|ğ‘£âˆˆ V} . Subsequently, for each node
pair(ğ‘¢,ğ‘£), an multi-layer perceptron (MLP) layer combined with
a sigmoid activation functions as the extractor ğ‘’Î¦, transforming
the concatenated pair (zğ‘¢,zğ‘£)into a probability value ğœ…ğ‘¢,ğ‘£âˆˆ[0,1].
Here, a lower ğœ…ğ‘¢,ğ‘£indicates a more noise-prone relationship, thus
suggesting a reduced weight or exclusion of the attention link.
However, a challenge arises with Ağ‘ , given its non-differentiability
with respect to ğœ…due to its Bernoulli nature. To solve this, we employ
the concrete relaxation technique [ 19] for the Bernoulli distribution:
Bernoulli ğœ…ğ‘¢,ğ‘£â‰ˆsigmoid1
ğ‘¡
logğœ…ğ‘¢,ğ‘£
1âˆ’ğœ…ğ‘¢,ğ‘£+logğœ–
1âˆ’ğœ–
(13)
whereğœ–âˆ¼Bernoulli(0,1)andğ‘¡acts as the temperature for this con-
crete distribution. Thus, the distribution of Gğ‘ givenGâ„,PÎ¦(Gğ‘ |Gâ„),
can be defined as PÎ¦(Gğ‘ |Gâ„)=Ã
ğ‘¢,ğ‘£âˆˆEğ‘“ğ‘¢ğ‘™ğ‘™P ğ‘ğ‘¢,ğ‘£|ğœ…ğ‘¢,ğ‘£.
4.2.3 Variational Approximation via Q.The bound presented in
Equation (10) holds universally for any Q(Gğ‘ ). For optimization
efficiency, we also define it as another Bernoulli distribution. Given
a graphGsampled from PG, we can get the only Gâ„from the
first attention head in Transformer. For every node pair ( ğ‘¢,ğ‘£)
within the fully connected attention graph Gâ„, we sample Ëœğ‘ğ‘¢ğ‘£from
Bernoulli(ğœŒ), whereğœŒis a hyperparameter in [0, 1]. We subsequently
remove all existing attention links in Gâ„and adds links ( ğ‘¢,ğ‘£) when
Ëœğ‘ğ‘¢ğ‘£=1. Suppose the obtained task-relevant attention subgraph is Gğ‘ ,
we have Q(Gğ‘ )=Ã
GP(Ëœğ‘|Gâ„)PG(Gâ„). Thus, taking into account
two Bernoulli distributions, P(Gğ‘ |Gâ„)andQ(Gğ‘ ), and omitting
constants, the second term of Equation (11) can be described as:
KL(PÎ¦(Gğ‘ |Gâ„)âˆ¥Q(Gğ‘ ))=
âˆ‘ï¸
(ğ‘¢,ğ‘£)âˆˆEğ‘“ğ‘¢ğ‘™ğ‘™ğœ…ğ‘¢,ğ‘£logğœ…ğ‘¢,ğ‘£
ğœŒ+ 1âˆ’ğœ…ğ‘¢,ğ‘£log1âˆ’ğœ…ğ‘¢,ğ‘£
1âˆ’ğœŒ(14)
After extracting subgraph Gğ‘ , the classifier ğ‘“ğœ™employs the masked
Transformer, which shares the same parameters as before, to map
Gğ‘ into a graph representation using an averaging readout function.
This representation is then passed through an MLP layer followed
by a softmax function to model the distribution of ğ‘Œ, yielding the
distribution Pğœ™(ğ‘Œ|Gğ‘ ).
4.2.4 Guaranteed Noise Reduction in Attention Graph Gâ„.PSGT,
following the IB principle, enhances graph Transformerâ€™s focus
on task-relevant features while effectively eliminating superfluous
attention links in the self-attention graph Gâ„. This strategy not onlyprovides model interpretability for the model but also reinforces the
robustness. LetGğœ–be a graph solely comprised of those superfluous
attention links inGâ„. We then give the following theorem, which
suggests that minimizing the objective in Equation (8) inherently
minimizes the relevance between Gğ‘ andGğœ–:
Theorem 4.1. Letğ‘Œbe determined solely by the optimal task-
relevant attention graph ËœGğ‘ extracted by ğ‘’Î¦, and withGğœ–defined as
the noise attention graph satisfying ËœGğ‘ âˆªGğœ–=Gâ„. When we select
Gğ‘ equivalent to ËœGğ‘ , it essentially leads to maximizing the objective
ğ¼(Gğ‘ ;ğ‘Œ)âˆ’ğ›½ğ¼(Gğ‘ ;Gâ„).
Proof of this theorem is detailed in the Appendix A. In essence,
Theorem 4.1 suggests that optimizing the objective in Equation (8)
forcesGğ‘ to become increasingly unrelated to extraneous attention
links inGğœ–.
4.3 Propagation Structure Modeling
Up to now, we do not explicitly leverage structural information
from observed propagation graphs, which is often recognized as
important for modeling propagation behavior. While many exist-
ing strategies [ 4,51] primarily use adjacency matrices, focusing
mainly the first-order propagation relationships among users, our
method offers a more realistic view by examining real-world news
propagation patterns.
We define the propagation relationship between users in terms of
both distance and depth. The distance aspect quantifies the shortest
path length between two nodes in the propagation graph, mim-
icking the fact [ 3] that if two users are distantly connected in the
propagation structure, they might engage in different topics even
under the same news, hence sharing less correlation. On the other
hand, the depth relationship measures the shortest path from a user
to the source news, effectively simulating the prevalent phenome-
non of information decay [ 9] during propagation. As discussions
around news deepen, users might veer into topics deviating from
the original news theme. These users who participate in such off-
topic discussions are less valuable for news classification. Therefore,
for any node pair ( ğ‘¢,ğ‘£) inG, our proposed propagation structure
modeling module explicitly captures these phenomena, as follows:
ğ‘ğ‘¢ğ‘£=ğ‘’1
ğ‘‘ğ‘¢ğ‘£Â·ğ‘’âˆ’ğ‘‘ğ‘¢+ğ‘‘ğ‘£
2 (15)
In Equation (15), the first and second terms denote the distance
and depth relationships, respectively. Here, ğ‘‘ğ‘¢ğ‘£defines the shortest
path length between node ğ‘¢andğ‘£, whileğ‘‘ğ‘¢indicates the shortest
path length from node ğ‘¢to the source news. For computational
efficiency, we only calculate the shortest path for node pairs whose
shortest path is not longer 2, i.e., ğ‘‘ğ‘¢ğ‘£â‰¤2. Moreover, by setting the
shortest path length to 2, this strategy more intuitively reflects the
local structural features of the propagation graph. When combined
with the Transformerâ€™s ability to characterize long sequence de-
pendencies, indicative of global structure characteristics, the model
achieves a more comprehensive understanding of the propagation
structures at both local and global levels. This approach yields
the graphGğ‘, with its adjacency matrix Ağ‘constructed by Equa-
tion (15). As we mentioned in Section 4.1, by incorporating Gğ‘as a
graph mask within the graph Transformer, PSGT adeptly captures
both the propagation depth and distance relationships among users.
4657Propagation Structure-Aware Graph Transformer for Robust and Interpretable Fake News Detection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
4.4 Optimization and News Classification
The overall optimization objective of PSGT comprises two loss
terms: the binary classification loss Lğ‘ğ‘™ğ‘ defined in Equation (9) and
KL lossLğ¾ğ¿defined in Equation (14). For the binary classification
lossLğ‘ğ‘™ğ‘ , we utilize the standard cross-entropy loss. To specify this,
we first extract graph-level representations of the news using a
readout function:
s=Readout(A)=1
|V|âˆ‘ï¸
ğ‘£ğ‘–âˆˆVzğ‘– (16)
Subsequently, this representation is processed through an MLP
followed by a softmax function to predict the news label Ë†ğ‘Œfor a
given snews itemğ‘ğ‘–. Hence,Lğ‘ğ‘™ğ‘ is expressed as:
Lğ‘ğ‘™ğ‘ (ğ‘Œ,Ë†ğ‘Œ)=âˆ’(ğ‘ŒlogË†ğ‘Œ+(1âˆ’ğ‘Œ)log(1âˆ’Ë†ğ‘Œ)) (17)
whereğ‘Œâˆˆ{0,1}means the label for each piece of unverified news.
Finally, the total optimization objective is then L=Lğ‘ğ‘™ğ‘ +Lğ¾ğ¿.
4.5 Comparison with Existing Related Methods
Recent studies applying the IB principle to graph learning have
primarily focused on local structures through GNNs [ 30,69]. How-
ever, in PSGT, the application of IB fundamentally differs from
existing approaches, and we have adopted this powerful concept to
tackle the specific challenges of interpretable fake news detection.
Unlike existing graph IB methods that modify the original graph
structure, PSGT leverages the IB principle to filter noisy attention
connections within the self-attention layer of Transformers. This
is critical because, even if we remove the noise propagation edge
between nodes and in the original news propagation graph, the
self-attention mechanisms can still naturally and inadvertently rely
on toxic correlations between these nodes, giving a higher atten-
tion weight to them [ 40,61]. Furthermore, GNN-based methods
often fall short in capturing the extended sequence dependencies in
news propagation, limiting their effectiveness in practical scenarios.
PSGT stands out as the first method to employ graph IB for Trans-
former in fake news detection, successfully filtering noise while
generating interpretable subgraphs that comprehensively capture
local and long-sequence dependencies.
Additionally, while several graph Transformer methods [ 31], e.g.,
GraphGPS [ 37], have been proposed for applications like protein
design, they are not ideally suited for fake news detection, failing to
account for unique news propagation features, such as information
decay [ 9]. Our novel graph Transformer model addresses this gap
by considering propagation depth and user distance relationships,
enhancing both the accuracy and interpretability of fake news de-
tection. Notably, our model excels in using propagation graphs for
this purpose. However, the core principles of our model, particularly
the propagation structure-based positional encoding strategy, have
broader applicability. They can potentially be adapted to various
propagation-based graphs, including social, information, and infec-
tious disease networks [ 58]. We aim to explore these applications
in future work.5 Experiments
5.1 Experimental Setup
5.1.1 Datasets. Our study focuses on the impact of news propaga-
tion structure and user engagement in fake news detection, utilizing
the FakeNewsNet dataset, which includes PolitiFact and GossipCop
sub-datasets. Each entry comprises a news piece, related Twitter
posts, user interactions, and a "Real" or "Fake" label assigned by
experts. We preprocess the data following the methods in [ 11], us-
ing 75% of the articles for training and the remainder for testing.
Detailed dataset statistics are available in Appendix C.1.
5.1.2 Comparison Methods. To explore the impact of news prop-
agation structures, we benchmark our PSGT algorithm1against
various known methods, which span both content-based meth-
ods (M1) and propagation-structure-based methods (M2). In the
content-based category, we consider CSI[39], which employs an
LSTM network to learn sequential retweet features, as well as Bert-
MLP andSpacy-MLP, which classify news using MLPs based
on 768-dimensional and 300-dimensional features encoded by pre-
trained BERT [ 10] and spaCy [ 16] word2vec models, respectively.
We also consider UniPF [59], which develops a semantic-clustering
strategy for fake news detection. For propagation-network-based
methods, we include GCN [22], a well-known graph neural network
(GNN) that uses a message propagation mechanism to learn repre-
sentations for users and news items; GAT [55], which distinguishes
node importance through an attention mechanism; GraphGPS [37],
a graph Transformer approach incorporating positional encod-
ing;BiGCN [4], which employs two separate GCNs for model-
ing both the propagation-directed and dispersion-directed graphs;
UPFD [11], which integrates the social history of users and news
features into a GNN architecture; GACL [51], introducing an adver-
sarial contrastive learning strategy into rumor detection; EBGCN [60],
a probabilistic model that captures propagation uncertainty by en-
coding propagation trees with edge-enhanced Bayesian networks;
andGSAT [30], which employs a graph information bottleneck
technique for optimization purposes; DECOR [62], which refines
social graph structures by applying a degree-correction mecha-
nism to better align with real-world social dynamics; HGFND [20],
which uses hypergraph neural networks to capture complex rela-
tional data in news propagation networks, enhancing the detection
of fake news through higher-order relationship modeling; and Fin-
erFact [21], which employs a fine-grained reasoning framework
and dual-channel graph network for subtle evidence differentiation,
enhancing detection capabilities and explainability.
Detailed information on evaluation metrics, experimental set-
tings, and implementation is provided in Appendix C.
5.2 Overall Performance
Tables 1 and 2 demonstrate that PSGT consistently outperforms
competing baseline methods across both datasets. Several key ob-
servations can be informed from these results: (1) Advantage of
Propagation-Structure-Based Methods: Methods based on prop-
agation structure yield a marked improvement in performance over
those relying solely on content. This aligns well with expectations,
1The implementation code is available at https://github.com/JYZHU03/PSGT.
4658KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Junyou Zhu, Chao Gao, Ze Yin, Xianghua Li, & Juergen Kurths
Table 1: Comparison of PSGT and baselines (M1: Content-
based, M2: Propagation-structure-based) on PolitiFact .
Methods ACC Pre Rec F1
M1CSI 0.734 0.672 0.550 0.688
Bert-MLP 0.853 0.892 0.833 0.825
SpaCy-MLP 0.375 0.124 0.136 0.272
UniPF 0.760 0.783 0.800 0.754
M2GCN 0.833 0.958 0.766 0.831
GAT 0.895 0.930 0.900 0.890
GraphGPS 0.903 0.900 0.818 0.857
BiGCN 0.854 0.960 0.800 0.851
UPFD 0.875 0.900 0.900 0.866
GACL 0.875 0.961 0.833 0.871
EBGCN 0.896 0.898 0.909 0.891
GSAT 0.854 0.947 0.750 0.852
DECOR 0.907 0.951 0.911 0.918
HGFND 0.911 0.947 0.907 0.911
FinerFact 0.909 0.919 0.904 0.917
Our PSGT 0.917 0.966 0.918 0.922
Table 2: Comparison of PSGT and baselines (M1: Content-
based, M2: Propagation-structure-based) on GossipCop .
Methods ACC Pre Rec F1
M1CSI 0.866 0.892 0.840 0.866
Bert-MLP 0.962 0.968 0.954 0.961
SpaCy-MLP 0.501 0.498 0.534 0.333
UniPF 0.933 0.932 0.933 0.932
M2GCN 0.957 0.931 0.984 0.957
GAT 0.961 0.945 0.971 0.960
GraphGPS 0.968 0.972 0.952 0.960
BiGCN 0.951 0.923 0.982 0.953
UPFD 0.965 0.972 0.957 0.965
GACL 0.976 0.971 0.972 0.976
EBGCN 0.964 0.966 0.962 0.963
GSAT 0.956 0.949 0.962 0.955
DECOR 0.972 0.962 0.961 0.956
HGFND 0.974 0.963 0.973 0.974
FinerFact 0.832 0.862 0.878 0.869
Our PSGT 0.980 0.974 0.987 0.980
as the former captures both the propagation structure and the fea-
tures of news into unified node representations, thereby amplifying
accuracy. (2) Superiority of PSGT: Among the techniques that
leverage propagation structure, our proposed PSGT outshines all
competitors. This highlights the effectiveness of PSGT to extract
both structural patterns and feature information. (3) Comparison
with Other GNN-Based Methods: Specifically, PSGT outperforms
GNN-based methods like BiGCN, UPFD, GACL, and EBGCN, whichare developed with the aim of detecting fake news. Their underper-
formance can be attributed to their reliance on shallow GNN archi-
tectures that are not capable of capturing long-sequence features.
(4) Comparison with Graph Transformer and IB Methods:
Interestingly, even methods such as GraphGPS, which accounts
for long-sequence features, and GSAT, which employs an infor-
mation bottleneck, do not surpass PSGT. This likely stems from
their inability to simultaneously capture the unique graph struc-
ture inherent to news propagation while filtering out extraneous
noise. These insights collectively validate the effectiveness of PSGT,
which thoughtfully considers both propagation structure and noise
filtration, in detecting fake news on real-world social media.
5.3 Robustness
In real-world fake news tasks, robustness is essential, especially
since fake news propagation graphs often face noise disruptions. To
test the robustness of our model, we incorporated Gaussian noise,
characterized by a Gaussian distribution ğœ€âˆ¼ğ‘(0,1), into node
features and removed 20% of the edges. When assessing accuracy
by introducing varying noise levels to node features, our results in
Figure 3 revealed that our PSGT consistently outperformed base-
lines, even when some, like GAST, employed strategies like IB for
key feature selection, or GACL used adversarial learning to elimi-
nate noise. Intriguingly, we found that a certain proportion of noise
could enhance performance. This finding aligns with previous re-
search [ 4] indicating a minimal influence from non-root nodes in
news propagation graphs, with optimal noise levels refocusing the
model on the root node, thereby improving its overall performance.
(b) 
Gossipcop
(a) 
Politifact
Figure 3: RobustnessRobustness test on Politifact and Gos-
sipcop. The x-axis represents the percentage of Gaussian
noise injected, while the y-axis denotes accuracy. PSGT con-
sistently surpasses baselines across various noise levels.
5.4 Interpretability
An interpretable result aids individuals in understanding which
parts of the data the model leverages, with minimal cognitive ef-
fort [ 66]. When the model exhibits high accuracy, its generated
explanations do not only clarify the modelâ€™s workings but also
shed light on the dataset. For instance, they can highlight which
users or propagation structures are pivotal for fake news detection.
We begin by visualizing a propagation graph from PolitiFact com-
prising 58 nodes. This graph size is optimal for visualization, and
4659Propagation Structure-Aware Graph Transformer for Robust and Interpretable Fake News Detection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
other graphs display similar patterns. As shown in Figure 4 (a), the
source news node ( ğ‘–ğ‘‘=0) and its immediate neighbors carry higher
attention weights, indicating the emphasis of the model on early
propagation. This aligns with prior research [ 32], highlighting that
initial engaged users often provide pertinent comments.
Building on the observation that the most interpretable aspects
often reside in the initial propagation structure, an intriguing ques-
tion arises: for a user with a limited cognitive resources, how ef-
fectively can they derive insights? To address this, we execute an
automatic quantitative experiment, wherein we extract small early
propagation subgraphs from PolitiFact at various cognitive loads.
Specifically, beginning with the root node, we employ a breadth-
first search algorithm to extract 5% to 35% of the nodes and their
associated edges. These subsets represent varying cognitive loads.
These subgraphs are then input into our models. Figure 4 (b) demon-
strates that PSGT surpasses the baselines across all cognitive loads
and performs exceptionally well, even at minimal cognitive de-
mands. Interestingly, the baselines also perform well at a mere 5%
cognitive load. This can be attributed to the limited noise in the
5%data subset, allowing these models to primarily depend on the
source news without disruptive interactions. However, in contrast
to the baselines, our PSGT approach incorporates a noise-filtering
mechanism. Hence, as cognitive load increases, the model can still
extract value without being overly affected by noise.
(a) Attention Weights (b) C ognitive Budget
Figure 4: Interpretability results from PolitiFact data. (a)
Heatmap of attention weights, highlighting the crucial part
of early propagation structure surrounding the source news
node (ğ‘–ğ‘‘=0). (b) PSGT and baseline performance across cog-
nitive loads, demonstrating PSGT can achieve competitive
performance even at minimal cognitive demands.
6 Conclusion
In this paper, we have introduced PSGT, a propagation structure-
aware graph Transformer, specifically designed for interpretable
fake news detection. By incorporating a graph Information Bottle-
neck strategy, PSGT inherently provides robust and interpretable
results. Guided by the IB principle, our proposed graph Transformer
effectively filters out task-irrelevant information through a noise-
reduction attention graph, enhancing the reliability in interpretabil-
ity. Additionally, we have presented a unique positional encoding
strategy tailored for the Transformer architecture, enabling PSGT
to capture both long-sequence dependencies and the propagation
structure effectively. Extensive evaluations comparing PSGT with
various known methods, including those based on GNNs, graphTransformers, and IB principles, demonstrate the effectiveness of
PSGT in providing robust and interpretable fake news detection
outcomes.
7 Acknowledgements
This work was supported by the National Natural Science Founda-
tion of China (Nos. 62271411, U22A2098, 62261136549 and 11931015),
the China Scholarship Council scholarship.
References
[1]Alessandro Achille and Stefano Soatto. 2018. Emergence of invariance and
disentanglement in deep representations. The Journal of Machine Learning
Research 19, 1 (2018), 1947â€“1980.
[2]Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, and Kevin Murphy. 2017.
Deep variational information bottleneck. In Proceedings of the 5th International
Conference on Learning Representations. OpenReview.net.
[3]Venkatesh Bala and Sanjeev Goyal. 2000. A noncooperative model of network
formation. Econometrica 68, 5 (2000), 1181â€“1229.
[4]Tian Bian, Xi Xiao, Tingyang Xu, Peilin Zhao, Wenbing Huang, Yu Rong, and
Junzhou Huang. 2020. Rumor detection on social media with Bi-directional graph
convolutional Networks. In Proceedings of the 34th AAAI Conference on Artificial
Intelligence. AAAI Press, 549â€“556.
[5]Jianbo Chen, Le Song, Martin J. Wainwright, and Michael I. Jordan. 2018. Learning
to explain: An information-theoretic perspective on model interpretation. In
Proceedings of the 35th International Conference on Machine Learning, Vol. 80.
PMLR, 882â€“891.
[6]Yixuan Chen, Dongsheng Li, Peng Zhang, Jie Sui, Qin Lv, Tun Lu, and Li Shang.
2022. Cross-modal ambiguity learning for multimodal fake news detection. In
Proceedings of the ACM Web Conference 2022. ACM, 2897â€“2905.
[7] Zhendong Chen, Siu Cheung Hui, Fuzhen Zhuang, Lejian Liao, Fei Li, Meihuizi
Jia, and Jiaqi Li. 2022. EvidenceNet: Evidence fusion network for fact verification.
InProceedings of the ACM Web Conference 2022. ACM, 2636â€“2645.
[8]Limeng Cui, Haeseung Seo, Maryam Tabar, Fenglong Ma, Suhang Wang, and
Dongwon Lee. 2020. DETERRENT: Knowledge guided graph attention network
for detecting healthcare misinformation. In Proceedings of the 26th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining. ACM, 492â€“502.
[9]Daryl J Daley and David G Kendall. 1964. Epidemics and rumours. Nature 204,
4963 (1964), 1118â€“1118.
[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:
Pre-training of deep bidirectional transformers for language Understanding. In
Proceedings of the 2019 Conference of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language Technologies, NAACL-HLT.
Association for Computational Linguistics, 4171â€“4186.
[11] Yingtong Dou, Kai Shu, Congying Xia, Philip S. Yu, and Lichao Sun. 2021. User
preference-aware fake news detection. In Proceedings of the 44th International
ACM SIGIR Conference on Research and Development in Information Retrieval.
ACM, 2051â€“2055.
[12] Yaqian Dun, Kefei Tu, Chen Chen, Chunyan Hou, and Xiaojie Yuan. 2021. KAN:
Knowledge-aware attention network for fake news detection. In Proceedings of
the 35th AAAI Conference on Artificial Intelligence. AAAI Press, 81â€“89.
[13] Shubham Gupta, Narendra Yadav, Suman Kundu, and Sainathreddy Sankepally.
2023. FakEDAMR: Fake News Detection Using Abstract Meaning Representation
Network. In International Conference on Complex Networks and Their Applications.
Springer, 308â€“319.
[14] Greg Hamerly and Charles Elkan. 2003. Learning the k in k-means. In Advances
in Neural Information Processing Systems. MIT Press, 281â€“288.
[15] Zhenyu He, Ce Li, Fan Zhou, and Yi Yang. 2021. Rumor detection on social media
with event augmentations. In Proceedings of the 44th international ACM SIGIR
conference on research and development in information retrieval. 2020â€“2024.
[16] Matthew Honnibal and Ines Montani. 2017. spaCy 2: Natural language under-
standing with bloom embeddings, convolutional neural networks and incremental
parsing. To appear 7, 1 (2017), 411â€“420.
[17] Linmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong, Duyu Tang, Chuan Shi,
Nan Duan, and Ming Zhou. 2021. Compare to The knowledge: graph neural
fake news detection with external knowledge. In Proceedings of the 59th Annual
Meeting of the Association for Computational Linguistics and the 11th International
Joint Conference on Natural Language Processing. Association for Computational
Linguistics, 754â€“763.
[18] Ylva Ivarsson and Per Jemth. 2019. Affinity and specificity of motif-based proteinâ€“
protein interactions. Current opinion in structural biology 54 (2019), 26â€“33.
[19] Eric Jang, Shixiang Gu, and Ben Poole. 2017. Categorical reparameterization with
gumbel-softmax. In Proceedings of the 5th International Conference on Learning
Representations. OpenReview.net.
4660KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Junyou Zhu, Chao Gao, Ze Yin, Xianghua Li, & Juergen Kurths
[20] Ujun Jeong, Kaize Ding, Lu Cheng, Ruocheng Guo, Kai Shu, and Huan Liu. 2022.
Nothing stands alone: Relational fake news detection with hypergraph neural
networks. In 2022 IEEE International Conference on Big Data (Big Data). IEEE,
596â€“605.
[21] Yiqiao Jin, Xiting Wang, Ruichao Yang, Yizhou Sun, Wei Wang, Hao Liao, and
Xing Xie. 2022. Towards fine-grained reasoning for fake news detection. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36. 5746â€“5754.
[22] Thomas N. Kipf and Max Welling. 2017. Semi-supervised classification with
graph convolutional networks. In 5th International Conference on Learning Repre-
sentations. OpenReview.net.
[23] Devin Kreuzer, Dominique Beaini, William L. Hamilton, Vincent LÃ©tourneau, and
Prudencio Tossou. 2021. Rethinking graph transformers with spectral attention.
InAdvances in Neural Information Processing Systems. 21618â€“21629.
[24] Thai Le, Suhang Wang, and Dongwon Lee. 2020. MALCOM: Generating malicious
comments to attack neural fake news detection models. In Proceedings of the 20th
IEEE International Conference on Data Mining. IEEE, 282â€“291.
[25] Pan Li, Yanbang Wang, Hongwei Wang, and Jure Leskovec. 2020. Distance encod-
ing: Design provably more powerful neural networks for graph representation
learning. In Advances in Neural Information Processing Systems.
[26] Qifei Li and Wangchunshu Zhou. 2020. Connecting the dots between fact verifi-
cation and fake news detection. In Proceedings of the 28th International Conference
on Computational Linguistics. 1820â€“1825.
[27] Leyuan Liu, Junyi Chen, Zhangtao Cheng, Wenxin Tai, and Fan Zhou. 2023.
Towards Trustworthy Rumor Detection with Interpretable Graph Structural
Learning. In Proceedings of the 32nd ACM International Conference on Information
and Knowledge Management. 4089â€“4093.
[28] Guanghui Ma, Chunming Hu, Ling Ge, Junfan Chen, Hong Zhang, and Richong
Zhang. 2022. Towards robust false information detection on social networks
with contrastive learning. In Proceedings of the 31st ACM International Conference
on Information & Knowledge Management. 1441â€“1450.
[29] Liheng Ma, Chen Lin, Derek Lim, Adriana Romero-Soriano, Puneet K. Dokania,
Mark Coates, Philip H. S. Torr, and Ser-Nam Lim. 2023. Graph inductive biases
in transformers without message passing. In Proceedings of the 40th International
Conference on Machine Learning, Vol. 202. PMLR, 23321â€“23337.
[30] Siqi Miao, Mia Liu, and Pan Li. 2022. Interpretable and generalizable graph learn-
ing via stochastic attention Mechanism. In Proceedings of the 39th International
Conference on Machine Learning, Vol. 162. PMLR, 15524â€“15543.
[31] Erxue Min, Runfa Chen, Yatao Bian, Tingyang Xu, Kangfei Zhao, Wenbing Huang,
Peilin Zhao, Junzhou Huang, Sophia Ananiadou, and Yu Rong. 2022. Trans-
former for graphs: An overview from architecture perspective. arXiv preprint
arXiv:2202.08455 (2022).
[32] Erxue Min, Yu Rong, Yatao Bian, Tingyang Xu, Peilin Zhao, Junzhou Huang, and
Sophia Ananiadou. 2022. Divide-and-conquer: Post-user interaction network for
fake news detection on Social Media. In Proceedings of the ACM Web Conference
2022. ACM, 1148â€“1158.
[33] Erxue Min, Yu Rong, Tingyang Xu, Yatao Bian, Da Luo, Kangyi Lin, Junzhou
Huang, Sophia Ananiadou, and Peilin Zhao. 2022. Neighbour interaction based
click-through rate prediction via graph-masked transformer. In Proceedings of
the 45th International ACM SIGIR Conference on Research and Development in
Information Retrieval. ACM, 353â€“362.
[34] Akash Kumar Mohankumar, Preksha Nema, Sharan Narasimhan, Mitesh M.
Khapra, Balaji Vasan Srinivasan, and Balaraman Ravindran. 2020. Towards trans-
parent and explainable attention models. In Proceedings of the 58th Annual Meeting
of the Association for Computational Linguistics. Association for Computational
Linguistics, 4206â€“4216.
[35] Ben Poole, Sherjil Ozair, AÃ¤ron van den Oord, Alexander A. Alemi, and George
Tucker. 2019. On variational bounds of mutual information. In Proceedings of the
36th International Conference on Machine Learning, Vol. 97. PMLR, 5171â€“5180.
[36] Piotr Przybyla. 2020. Capturing the style of fake news. In Proceedings of the 34th
AAAI Conference on Artificial Intelligence. AAAI Press, 490â€“497.
[37] Ladislav RampÃ¡sek, Michael Galkin, Vijay Prakash Dwivedi, Anh Tuan Luu, Guy
Wolf, and Dominique Beaini. 2022. Recipe for a general, powerful, scalable graph
transformer. In Proceedings of the Advances in Neural Information Processing
Systems. 14501â€“14515.
[38] Yu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang,
and Junzhou Huang. 2020. Self-supervised graph transformer on large-scale
molecular data. In Advances in Neural Information Processing Systems.
[39] Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017. CSI: A hybrid deep model for
fake news detection. In Proceedings of the 2017 ACM on Conference on Information
and Knowledge Management. ACM, 797â€“806.
[40] Sofia Serrano and Noah A. Smith. 2019. Is attention interpretable?. In Proceedings
of the 57th Conference of the Association for Computational Linguistics. Association
for Computational Linguistics, 2931â€“2951.
[41] Lanyu Shang, Ziyi Kou, Yang Zhang, and Dong Wang. 2022. A duo-generative
approach to explainable multimodal COVID-19 misinformation Detection. In
Proceedings of the ACM Web Conference 2022. ACM, 3623â€“3631.
[42] Qiang Sheng, Juan Cao, Xueyao Zhang, Rundong Li, Danding Wang, and
Yongchun Zhu. 2022. Zoom out and observe: News environment perception forfake news detection. In Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics. 4543â€“4556.
[43] Qiang Sheng, Xueyao Zhang, Juan Cao, and Lei Zhong. 2021. Integrating pattern-
and fact-based fake news detection via model preference learning. In Proceed-
ings of the 30th ACM International Conference on Information and Knowledge
Management. ACM, 1640â€“1650.
[44] Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, and Huan Liu. 2019. De-
fend: Explainable fake news detection. In Proceedings of the 25th ACM SIGKDD
international conference on knowledge discovery & data mining. 395â€“405.
[45] Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee, and Huan Liu.
2020. FakeNewsNet: A data repository with news content, social context, and
spatiotemporal information for studying fake news on social media. Big Data 8,
3 (2020), 171â€“188.
[46] Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake news
detection on social media: A data mining perspective. ACM SIGKDD explorations
newsletter 19, 1 (2017), 22â€“36.
[47] Kai Shu, Suhang Wang, and Huan Liu. 2019. Beyond news contents: The role of
social context for fake news detection. In Proceedings of the 12th ACM International
Conference on Web Search and Data Mining. ACM, 312â€“320.
[48] Amila Silva, Yi Han, Ling Luo, Shanika Karunasekera, and Christopher Leckie.
2021. Propagation2Vec: Embedding partial propagation networks for explainable
fake news early detection. Information Processing & Management 58, 5 (2021),
102618.
[49] Xing Su, Jian Yang, Jia Wu, and Yuchen Zhang. 2023. Mining user-aware multi-
relations for fake news detection in large scale online social networks. In Proceed-
ings of the 16th ACM International Conference on Web Search and Data Mining.
ACM, 51â€“59.
[50] Qingyun Sun, Jianxin Li, Hao Peng, Jia Wu, Xingcheng Fu, Cheng Ji, and Philip S.
Yu. 2022. Graph structure learning with variational information bottleneck. In
Proceedings of the 36th AAAI Conference on Artificial Intelligence. 4165â€“4174.
[51] Tiening Sun, Zhong Qian, Sujun Dong, Peifeng Li, and Qiaoming Zhu. 2022.
Rumor detection on social media with graph adversarial contrastive Learning. In
Proceedings of the ACM Web Conference 2022. ACM, 2789â€“2797.
[52] Naftali Tishby and Noga Zaslavsky. 2015. Deep learning and the information
bottleneck principle. In Proceedings of the 2015 IEEE Information Theory Workshop.
IEEE, 1â€“5.
[53] Hugo Touvron, Matthieu Cord, Alexandre Sablayrolles, Gabriel Synnaeve, and
HervÃ© JÃ©gou. 2021. Going deeper with image transformers. In Proceedings of the
2021 IEEE/CVF International Conference on Computer Vision. IEEE, 32â€“42.
[54] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Processing Systems. 5998â€“6008.
[55] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
LiÃ², and Yoshua Bengio. 2018. Graph attention networks. In Proceedings of the
6th International Conference on Learning Representations. OpenReview.net.
[56] Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false
news online. Science 359, 6380 (2018), 1146â€“1151.
[57] Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu
Su, and Jing Gao. 2018. Eann: Event adversarial neural networks for multi-modal
fake news detection. In Proceedings of the 24th acm sigkdd international conference
on knowledge discovery & data mining. 849â€“857.
[58] Zhen Wang, Dongpeng Hou, Chao Gao, Xiaoyu Li, and Xuelong Li. 2023. Light-
weight source localization for large-scale social networks. In Proceedings of the
ACM Web Conference 2023. 286â€“294.
[59] Lingwei Wei, Dou Hu, Yantong Lai, Wei Zhou, and Songlin Hu. 2022. A unified
propagation forest-based framework for fake news detection. In Proceedings of
the 29th International Conference on Computational Linguistics. 2769â€“2779.
[60] Lingwei Wei, Dou Hu, Wei Zhou, Zhaojuan Yue, and Songlin Hu. 2021. Towards
propagation uncertainty: Edge-enhanced bayesian graph convolutional Networks
for Rumor Detection. In Proceedings of the 59th Annual Meeting of the Associa-
tion for Computational Linguistics and the 11th International Joint Conference on
Natural Language Processing. 3845â€“3854.
[61] Sarah Wiegreffe and Yuval Pinter. 2019. Attention is not not explanation. In
Proceedings of the 2019 Conference on Empirical Methods in Natural Language Pro-
cessing and the 9th International Joint Conference on Natural Language Processing.
Association for Computational Linguistics, 11â€“20.
[62] Jiaying Wu and Bryan Hooi. 2023. DECOR: Degree-corrected social graph refine-
ment for fake news detection. In Proceedings of the 29th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining. ACM, 2582â€“2593.
[63] Tailin Wu, Hongyu Ren, Pan Li, and Jure Leskovec. 2020. Graph information
bottleneck. In Advances in Neural Information Processing Systems.
[64] Weizhi Xu, Junfei Wu, Qiang Liu, Shu Wu, and Liang Wang. 2022. Evidence-
aware fake news detection with graph neural networks. In Proceedings of the
ACM Web Conference 2022. ACM, 2501â€“2510.
[65] Carl Yang, Mengxiong Liu, Vincent W. Zheng, and Jiawei Han. 2018. Node,
motif and subgraph: Leveraging network functional blocks through structural
convolution. In Proceedings of the IEEE/ACM 2018 International Conference on
Advances in Social Networks Analysis and Mining. IEEE Computer Society, 47â€“52.
4661Propagation Structure-Aware Graph Transformer for Robust and Interpretable Fake News Detection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
[66] Ruichao Yang, Xiting Wang, Yiqiao Jin, Chaozhuo Li, Jianxun Lian, and Xing Xie.
2022. Reinforcement subgraph reasoning for fake news detection. In Proceedings
of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
ACM, 2253â€“2262.
[67] Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Yanming Shen, and
Tieyan Liu. 2021. Do transformers really perform badly for graph representation?.
InAdvances in Neural Information Processing Systems. 28877â€“28888.
[68] Junchi Yu, Jie Cao, and Ran He. 2022. Improving subgraph recognition with vari-
ational graph information bottleneck. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition. IEEE, 19374â€“19383.
[69] Junchi Yu, Tingyang Xu, Yu Rong, Yatao Bian, Junzhou Huang, and Ran He. 2021.
Graph information bottleneck for subgraph recognition. In Proceedings of the 9th
International Conference on Learning Representations. OpenReview.net.
[70] Kaiwei Zhang, Junchi Yu, Haichao Shi, Jian Liang, and Xiao-Yu Zhang. 2023.
Rumor detection with diverse counterfactual evidence. In Proceedings of the 29th
ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 3321â€“3331.
[71] Junyou Zhu, Xianghua Li, Chao Gao, Zhen Wang, and Jurgen Kurths. 2021.
Unsupervised community detection in attributed networks based on mutual
information maximization. New Journal of Physics 23, 11 (2021), 113016.
[72] Junyou Zhu, Chunyu Wang, Chao Gao, Fan Zhang, Zhen Wang, and Xuelong Li.
2021. Community detection in graph: an embedding method. IEEE Transactions
on Network Science and Engineering 9, 2 (2021), 689â€“702.
A Proof of Theorem 4.1
Proof. We adopt similar technicalities in [ 1] to prove Theo-
rem 4.1. Consider a fully connected attention graph, denoted as
Gâ„, which is determined by noise attention links Gğœ–and the au-
thenticity label ğ‘Œof the news ğ‘. Let the optimal task-relevant at-
tention graph,Gğ‘ , depend onGğœ–solely viaGâ„. This relationship
can be captured by the Markov Chain âŸ¨(ğ‘Œ,Gğœ–) â†’ Gâ„â†’ Gğ‘ âŸ©.
Given thatGğœ–represents noise attention links, and is therefore
unrelated and independent of ğ‘Œ, it follows that ğ»(ğ‘Œ|Gğœ–)=ğ»(ğ‘Œ)
andğ»(ğ‘Œ| Gğœ–;Gğ‘ ) â‰¤ğ»(ğ‘Œ| Gğ‘ ). Invoking the data processing
inequality, we deduce:
ğ¼(Gğ‘ ;Gâ„)â‰¥ğ¼(Gğ‘ ;ğ‘Œ,Gğœ–)
=ğ¼(Gğ‘ ;Gğœ–)+ğ¼(Gğ‘ ;ğ‘Œ|Gğœ–)
=ğ¼(Gğ‘ ;Gğœ–)+ğ»(ğ‘Œ|Gğœ–)âˆ’ğ»(ğ‘Œ|Gğœ–;Gğ‘ )
â‰¥ğ¼(Gğ‘ ;Gğœ–)+ğ»(ğ‘Œ)âˆ’ğ»(ğ‘Œ|Gğ‘ )
=ğ¼(Gğ‘ ;Gğœ–)+ğ¼(Gğ‘ ;ğ‘Œ)(18)
This concludes the proof. â–¡
B Complexity Analysis
The time complexity of PSGT is primarily influenced by the con-
struction of the propagation graph and the design of the Trans-
former architecture. Specifically, we employ the Dijkstra algorithm
to determine the depth relationships between the source news and
all users. This has a time complexity of O(|V| log|V|+|E| log|V|) .
Retrieving second-order neighbors for all nodes incurs a cost of
O(|E||V|) . Given that our Transformer architecture involves a cal-
culation of attention similar to standard Transformer designs, its
complexity stands at O(|V|2). Regarding the IB principle, the first
term has a complexity of O(|V|) , while the second term has a com-
plexity ofO(ğ‘‘|V|) . Consequently, for a training dataset comprising
ğ‘šnews articles, the overall time complexity of PSGT amounts to
O(ğ‘šğ‘‘|V|2).
C Implementation Details
C.1 Dataset and Graph Statistics
We present a detailed statistical analysis of the datasets utilized in
this study, as shown in Table 3. The dataset used has few nodes pergraph, so the average depth of news propagation graphs does not
exceed 4, though some reach higher depths, as Figure 6 illustrates.
C.2 Experimental Settings and Implementation
Following the prior work [ 11], we initialize word embeddings using
768-dimensional feature vectors that have been pre-trained via
BERT on extensive corpora. These settings are applied to both the
PolitiFact and GossipCop datasets. We stack two Transformer layers
with 128 hidden dimensions each. Training is conducted over 600
epochs, with model parameters updated using the Adam optimizer
at a learning rate of 0.001. ğ›½andğœare not tuned and are set to 1 and
103, respectively. Temperature parameter ğ‘¡used in Equation (13)
is also not tuned, and we set it as 1 for all datasets. The number
of Transformer layers is set to 2 for all datasets. To ensure the
robustness of our findings, we average the experimental outcomes
across ten independent runs. Experiments are performed using the
PyTorch framework on a Linux server equipped with Nvidia V100
GPUs.
C.3 Evaluation Metrics
In line with previous works [ 11,51], we employ a quartet of com-
monly utilized evaluation metrics to assess the effectiveness of
various fake news detection techniques. These metrics include Ac-
curacy (Acc.), Precision (Prec.), Recall (Rec.), and F1 Score (F1).
D More Experiment Results
(b) 
(a) 
Figure 5: Ablation study on Politifact and Gossipcop datasets.
Bars represent model accuracy for configurations: full
(PSGT), without news propagation structure (w/o P), with-
out information bottleneck (w/o I), and with GAT instead of
Transformer (w/o T). Error bars denote standard deviations.
D.1 Ablation Study
Our model comprises three essential modules: the News Propaga-
tion Structure, the Information Bottleneck (IB) Principle, and the
Transformer Architecture. These modules are responsible for sim-
ulating propagation behavior, eliminating irrelevant information,
and capturing long-range dependencies, respectively. To quantify
the contributions of each of these modules, we conducted an abla-
tion study. For this study, we created three model variants:
â€¢"w/o N" removes the News Propagation Structure module.
â€¢"w/o I" is a variant without the IB Principle
4662KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Junyou Zhu, Chao Gao, Ze Yin, Xianghua Li, & Juergen Kurths
Table 3: Statistic of the experimental datasets
DatasetGraphs Total Total Avg. Nodes
(Fake) Nodes Edges per Graph
Politifact 314 (157) 41,054 40,740 131
Gossipcop 5464 (2732) 314,262 308,798 58
â€¢"w/o T" replaces the Transformer Architecture with the
Graph Attention Networks (GAT) architecture, which is a
type of GNNs that also has a self-attention mechanism.
Results presented in Figure 5 clearly show that the omission of any
of these modules results in a decrease in model performance. This
leads us to several key observations: (1) Both news features and
propagation structures are essential for effective model learning. (2)
The IB Principle contributes to the model by effectively filtering out
noisy data, thereby enhancing accuracy. (3) The Transformer Archi-
tecture outperforms GAT, despite both having self-attention mech-
anisms, emphasizing the importance of long-sequence-dependent
features in news propagation graphs. For an extended compari-
son between GNNs and Transformer architectures, please refer to
Appendix D.2 (Figure 7).
D.2 Comparing PSGT and GNN-based Fake
News Detection with News Root
Concatenation
Source news
Neighbors below the 
f
ourth
-
order 
Fourth
-
order 
Fifth
-
order 
Sixth
-
order 
Seventh
-
order 
Figure 6: Visualization of a 141-node, information diffusion-
based news propagation graph from Politifact. The source
news node is labeled with ğ‘–ğ‘‘=0, with varying node colors rep-
resenting the different orders of propagation distance from
the source news node. Numerous nodes exhibit a propagation
distance exceeding three orders from the source news node.
In realistic information diffusion-based news propagation graphs,
the depth of the propagation cascade can be substantial, indicat-
ing a large propagation distance between some engaged users and
the source news. For instance, in a news propagation graph with
141 nodes as depicted in Figure 6, many nodes have a propagation
distance from the source news exceeding three orders. When em-
ploying shallow GNNs-based fake news detection methods in such
(b) 
Gossipcop
(a) 
Politifact
(b) 
Gossipcop
(a) 
PolitifactFigure 7: Performance comparison of several GNN-based
fake news detection methods in concatenation and non-
concatenation scenarios. Unlike existing GNN-based fake
news detection methods which benefit from concatenation,
PSGT demonstrates superior performance without concate-
nation, underlining its efficacy in handling long-sequence
dependencies in the propagation graph.
scenarios, the information from these nodes cannot be efficiently
passed to the source news, nor can it capture the source news infor-
mation adequately. This limitation explains why existing fake news
detection techniques relying on shallow GNNs often incorporate
features from the source news into subsequent user nodes.
However, this strategy has a disadvantage as it dilutes the noise
signal of user nodes by blending it with source news, thereby harm-
ing the ability of models for effective noise filtration. For example,
when concatenating the features of source news to a noisy user
node, the noise information gets diluted by the relevant features of
the source news, which negatively impacts model learning. Unlike
existing GNN-based fake news detection methods, our proposed
PSGT model has an inherent ability to capture long sequence depen-
dencies without the need for extra concatenation. This capability
allows non-noise but distant nodes to self-adapt and capture in-
formation from the source news efficiently, without the risk of
introducing noise to the source news. To empirically validate this,
we conducted an experiment comparing the performance between
our PSGT and GNN-based fake news detection methods, with and
without concatenation of source news features.
Figure 7 shows typical GNN-based methods improve perfor-
mance when concatenating source news features to user nodes,
whereas our PSGT exhibits the opposite behavior. This finding high-
lights the inefficacy of shallow GNNs in capturing long-sequence
features within the propagation graph effectively. As for the ob-
served decline in PSGT performance, a reasonable explanation
is that after injecting all nodes with root node information, the
noise node information is diluted by the features of task-relevant
news nodes, leading the model to misidentify these noise nodes as
non-noise nodes. Consequently, their original noise information is
transmitted to other nodes, deteriorating the quality of the learned
node representation and thereby reducing experimental accuracy.
4663