Hierarchical Knowledge Guided Fault Intensity Diagnosis of
Complex Industrial Systems
Yu Shaâˆ—
Xidian University, FIAS and XF-IJRC
Xian, Shaanxi, China
yusha@fias.uni-frankfurt.deShuiping Gouâ€¡
Xidian University
Xian, Shaanxi, China
shpgou@mail.xidian.edu.cnBo Liu
Xidian University
Xian, Shaanxi, China
Johannes Faber
FIAS
Frankfurt, Hessian, GermanyNingtao Liu
Xidian University
Xian, Shaanxi, ChinaStefan Schramm
FIAS
Frankfurt, Hessian, Germany
Horst Stoeckerâ€ 
FIAS, Goethe UniversitÃ¤t and GSI
Frankfurt, Hessian, GermanyThomas Steckenreiter
SAMSOM AG
Frankfurt, Hessian, GermanyDomagoj Vnucec
SAMSOM AG
Frankfurt, Hessian, Germany
Nadine Wetzstein
SAMSOM AG
Frankfurt, Hessian, GermanyAndreas Widl
SAMSOM AG
Frankfurt, Hessian, GermanyKai Zhouâ€¡
CUHK-SZ and FIAS
Shenzhen, Guangdong, China
zhoukai@cuhk.edu.cn
Abstract
Fault intensity diagnosis (FID) plays a pivotal role in monitoring
and maintaining mechanical devices within complex industrial
systems. As current FID methods are based on chain of thought
without considering dependencies among target classes. To capture
and explore dependencies, we propose a hierarchical knowledge
guided fault intensity diagnosis framework (HKG) inspired by the
tree of thought, which is amenable to any representation learning
methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set
of interdependent global hierarchical classifiers, where each node
is denoted by word embeddings of a class. These global hierar-
chical classifiers are applied to learned deep features extracted by
representation learning, allowing the entire model to be end-to-
end learnable. In addition, we develop a re-weighted hierarchical
knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical cor-
relation matrix (SCM) which effectively guides the information
sharing of nodes in graphical convolutional neural networks and
avoids over-smoothing issues. The Re-HKCM is derived from the
âˆ—FIAS: Frankfurt Institute for Advanced Studies
XF-IJRC: Xidian-FIAS International Joint Research Center
â€ GSI: GSI Helmholtzzentrum fÃ¼r Schwerionenforschung GmbH
â€¡Kai Zhou and Shuiping Gou are the corresponding authors
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671610SCM through a series of mathematical transformations. Extensive
experiments are performed on four real-world datasets from dif-
ferent industrial domains (three cavitation datasets from SAMSON
AG and one existing publicly) for FID, all showing superior results
and outperform recent state-of-the-art FID methods.
CCS Concepts
â€¢Computing methodologies â†’Machine learning; Machine
learning approaches ; Representation learning; Graph convolutional
network.
Keywords
Cavitation Intensity Diagnosis; Acoustic Signals; Hierarchical Knowl-
edge; Hierarchical classification; Representation Learning and Graph
Convolutional Network
ACM Reference Format:
Yu Sha, Shuiping Gouâ€¡, Bo Liu, Johannes Faber, Ningtao Liu, Stefan Schramm,
Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein,
Andreas Widl, and Kai Zhou. 2024. Hierarchical Knowledge Guided Fault
Intensity Diagnosis of Complex Industrial Systems. In Proceedings of the
30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3637528.3671610
1 INTRODUCTION
Deep learning has achieved impressive performance in numerous
signal processing applications, such as fault detection, fault location
and fault intensity diagnosis (FID) [ 12]. In this paper, we focus on
FID for cavitation or other faults in complex industrial mechanical
systems, which has been an active research topic in the industry
during recent years. The essence of FID is to pinpoint the finer fault
within the acoustic or vibration signals emitted by the target ma-
chine, which is regarded as a fundamental technology in the fourth
5657
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yu Sha et al.
Input
Output(a) ChainofThought(CoT)Input
Outputthought
(b) Treeof Thought(ToT)
Figure 1: Schematic diagrams for visualising different
thoughts. Each rectangular box represents a thought, which
is an intermediate step towards the problem. Different
coloured rectangular boxes of the same colour scheme indi-
cate their associations.
industrial revolution [ 27]. Monitoring the health of a machine can
make a huge contribution to the overall maintenance and efficiency
of industrial processes by â€™listeningâ€™ to signals emitted from the
machine [7].
Formally, FID data comprises multiple measurement signals, each
describing the whole physical process from the beginning to the
end of a particular fault state arising in a complex entity. Therefore,
there is a natural interdependency among each measurement event.
This interdependency is also referred to as hierarchical knowledge
between measurement events, which can be systematically orga-
nized into a hierarchical knowledge tree [ 17]. Disregarding this
interdependency may lead to degradation of fault intensity diag-
nosis performance. In order for the mechanical equipment health
monitoring system to work better in complex industrial systems, the
algorithm should take full account of interdependencies between
measurement events, i.e., hierarchical knowledge.
Recent FID methods can be broadly categorized into two classes
based on convolutional neural networks (CNN) and Transformer.
CNN-based methods [ 25,28,43] use filters (i.e., convolutional struc-
tures) to capture spatio-temporal features from vibration or acoustic
signals. Then, multiple-layer convolutional structures are imple-
mented to model complex patterns of signals to achieve accurate
fault diagnosis. For transformer-based approaches [ 4,42], they ex-
plore long-term dependencies across signal sequences through a
self-attention mechanism, allowing a better understanding of the
intrinsic correlations between the signals. This approach is good at
dealing with non-stationary signals and complex relationships.
However, CNN- or Transformers-based methods apart from their
own limitations, common drawback is that they are based on the
traditional input-output chain of thought (CoT) [ 38], as shown in
Figure 1a. CoT treats the problem as a direct mapping between
inputs and outputs and neglects implicit relationships (i.e., hier-
archical relationships) between target classes, which affects the
performance and generalisability of the model. To overcome this
limitation, we suggest a tree of thought (ToT) paradigm [ 40], i.e.,
embedding hierarchical knowledge between target classes into the
CoT, see Figure 1b. Each node of the ToT represents a specific fault
state and edges denote the hierarchical relationships among nodes.
The ToT paradigm is consistent with the inherent hierarchical na-
ture of fault data, which can capture hierarchical dependenciesacross fault classes and provide a richer representation of the rela-
tionships between various fault states to guide the model towards
a more nuanced understanding of fault classes.
Based on the above considerations, for industrial signals fault
intensity diagnosis, we propose to explicitly embed hierarchical
knowledge among target classes into the current deep learning
methods (i.e., CNNs and Transformers) to better enhance the ability
of the model to understand the complex inter-dependencies and
intrinsic structure across fault data. To convert CoT into ToT, in-
stead of previous structured FID models focusing on sophisticated
network design, we directly formulate FID as a feature multi-label
classification task. This allows hierarchical knowledge to be easily
embedded into any current representation learning (ML) meth-
ods and better guides learned deep features from ML. To make
feature classification consistent with the hierarchical structure of
classes, we use graph convolutional networks to map the hierarchi-
cal topology of class/label representations along with the learned
deep features from ML into interdependent target classifiers, i.e.,
hierarchical classifiers. Furthermore, the hierarchical classifier with
hierarchical constraints is not a set of independently trained param-
eter vectors, but it implements end-to-end learning with learned
deep features. The hierarchical classifier is also a global classifier
since its mapping parameters are common to all target classes. In
addition, we develop a re-weighted hierarchical knowledge correla-
tion matrix (Re-HKCM) paradigm by embedding the hierarchical
knowledge across classes into a data-driven statistical correlation
matrix (SCM), which can explicitly model inter-class dependen-
cies and alleviate the over-smoothing problem. The Re-HKCM is
derived from the SCM through a series of mathematical transforma-
tions. The above forms our proposed knowledge- and data-driven
approach, namely Hierarchical Knowledge Guided (HKG) fault in-
tensity diagnosis in complex industrial systems.
The contributions of this paper are summarized as follows:
â€¢A novel end-to-end hierarchical knowledge- guided fault in-
tensity diagnosis framework (HKG) is proposed, which can
be employed to any representation learning approaches.
â€¢We develop a global hierarchical classifier using graph con-
volutional neural networks which maps the hierarchical
topological graph of the label representation to the inter-
dependent target classifiers.
â€¢We design a re-weighted hierarchical knowledge correlation
matrix scheme by embedding inter-class hierarchical knowl-
edge into a data-driven statistical correlation matrix, which
efficiently constrains learned deep features and mitigates the
phenomenon of over-smoothing.
â€¢Our HKG outperforms state-of-the-art methods in experi-
ments conducted on four real-world datasets from different
industrial domains (three cavitation datasets provided by
SAMSON AG and one public dataset). Moreover, ablation
studies further demonstrate the effectiveness of our proposed
HKG for industrial fault intensity diagnosis.
2 PRELIMINARIES
2.1 Cavitation Event Intensity Recognition
Cavitation is defined as the phenomenon of the formation, growth
and collapse of local bubbles or vapor cavities in a liquid [ 31]. For
5658Hierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
piping systems, the acoustic signals of different flow conditions
(different levels of cavitation or non-cavitation) are recorded as
continuous waveforms using acoustic sensors, as shown in Figure 2.
Different intensities of cavitation are defined in the Appendix. Each
observed acoustic signal records the entire physical process from
the beginning to the end of the event of the corresponding flow
state. In our experiments, cavitation intensity recognition mainly
distinguishes incipient cavitation, constant cavitation, choked flow
cavitation and non-cavitation. Whether severe or subtle, any type
of cavitation would indicate a potential problem or failure in sys-
tem operation. Therefore, there is an urgent need for operators of
industrial systems to effectively and precisely recognize different
intensities of cavitation to take suitable countermeasures.
0 0.5 1.0 1.5 2.0 2.5 3
Time (sec)-800-600-400-2000200400600Amplitude in mV
(a) Choked Flow cavitation
0 0.5 1.0 1.5 2.0 2.5 3
Time (sec)-600-400-2000200400Amplitude in mV (b) Constant cavitation
0 0.5 1.0 1.5 2.0 2.5 3
Time (sec)-200-1000100200Amplitude in mV
(c) Incipient cavitation
0 0.5 1.0 1.5 2.0 2.5 3
Time (sec)-200-1000100200Amplitude in mV (d) Non cavitation
Figure 2: Different cavitation states of acoustic signals.
2.2 Acoustic Signals Augmentation
Formally, there is ğ‘¥âŠ†Rğ‘€Ã—ğ‘withğ‘€measurements for each acous-
tic signal. Considering the purposely maintained steady flow status
(i.e., itâ€™s always the same fluid status class within the individual
measurement duration with 3 sor25 s) in each recorded stream and
fine resolution for the sensor. One can split each stream into several
pieces, which still can hold enough essential information for detec-
tion. The given piece is also not too short due to the inherent ran-
domness of the noise emission and features of each piece are inde-
pendent. Therefore, we apply a sliding window (SW) with window
sizeğ‘ ğ‘¤and step size ğ‘ ğ‘ to divide the acoustic signal sequence into a
set of sub-sequences Xğ‘ ğ‘¤=
ğ’™ğ‘–,ğ‘—,ğ‘–=1,2,...,ğ‘ ;ğ‘—=1,2,...,ğ‘˜	
âŠ†
Rğ‘ ğ‘¤Ã—ğ‘˜ğ‘, whereğ‘˜=(ğ‘€âˆ’ğ‘ ğ‘¤)
ğ‘ ğ‘ is the number of sub-sequences and
ğ‘is stream. The SW is an important part of acoustic signal pre-
processing.
2.3 Graph Convolutional Network
Graph Convolutional Network (GCN) [ 14] is introduced to learn the
knowledge between the neighbourhood information propagation
labels of a node. The GCN can learn more complex representations
by stacking multiple graph convolutional layers. Each GCN layer
can be calculated using the following formula:
ğ‘¯ğ‘™+1=F(Ë†ğ‘¨ğ‘¯ğ‘™ğ‘¾ğ‘™) (1)where ğ‘¾ğ‘™âˆˆRğ‘‘Ã—ğ‘‘â€²represents a transformation matrix to be learned
(ğ‘‘andğ‘‘â€²denote the dimensions of node features); Ë†ğ‘¨ğ‘™âˆˆRğ‘›Ã—ğ‘›
indicates the normalised correlation matrix ğ‘¨(ğ‘›is the number of
nodes);F(Â·) represents a non-linear function, which is acted by
LeakyReLU in our experiments; ğ‘¯ğ‘™âˆˆRğ‘›Ã—ğ‘‘andğ‘¯ğ‘™+1âˆˆRğ‘›Ã—ğ‘‘â€²are
the node representation matrices for the ğ‘™-th and(ğ‘™+1)-th layers,
respectively, with each row corresponding to a node in the graph
and each column corresponding to the features of this node. In our
method, GCN is employed to learn hierarchical knowledge between
labels/classes in the hierarchical knowledge learning module.
3 Method
3.1 Architecture Overview
The key idea of hierarchical knowledge- guided fault intensity di-
agnosis (HKG) is to exploit the inherent hierarchical knowledge
of the cavitation classes learned by graph convolutional network
(GCN) to guide/constrain the deep features learned by CNN. This
integrated approach can capture subtle nuances in acoustic signals
and helps to improve the quantitative relationship between signal
features and fault intensity. In our design, one stream is employed
for fault feature learning and the other stream is used for hierarchi-
cal knowledge learning. The overall architecture of our model is
depicted in Figure 3 (see appendix for HKG algorithm).
Given a signal dataset ğ‘¿={ğ‘‹ğ‘–,ğ‘–=1,2,...,ğ‘}âŠ†Rğ‘€Ã—ğ‘and the
corresponding label ğ‘³âˆˆRğ¶Ã—ğ‘withğ‘streams,ğ‘€measurements
for each stream and ğ¶fault classes. For the fault feature learning
stream, the signal dataset ğ‘¿is input to the signal pre-processing
module and Ëœğ‘¿âˆˆRğ‘‡Ã—ğ¹Ã—3is the output after the sliding window
(SW) and STFT operations as follows:
Ëœğ‘¿=10Ã—log10(|STFT(SW(ğ‘¿))|
max(|STFT(SW(ğ‘¿))|))
:=10Ã—log10(|ğ‘¿ğ‘ ğ‘¤[ğ‘›,ğ‘š]|
max(|ğ‘¿ğ‘ ğ‘¤[ğ‘›,ğ‘š]|))(2)
where ğ‘¿ğ‘ ğ‘¤[ğ‘›,ğ‘š]indicates the ğ‘›-th row and ğ‘š-th column elements
of the results matrix of STFT and |ğ‘¿ğ‘ ğ‘¤[ğ‘›,ğ‘š]|denotes the elements
of the amplitude spectrum matrix. Then, Ëœğ‘¿is fed into the feature
representation learning module (FRL) to produce learned pooling
features ğ‘­â€²âˆˆRğ·withğ·denoting the dimension of the T-F domain
spectrogram. For hierarchical knowledge learning stream, the label
setğ‘³is first one-hot encoded and then hierarchical label tree Tâˆˆ
Rğ¶Ã—ğ»are created by manual or unsupervised learning, where ğ»is
the height of the tree. Next, the hierarchical label tree TâˆˆRğ¶Ã—ğ»is
used as input to the hierarchical knowledge learning module (HKL)
to generate a hierarchical knowledge classifier CâˆˆRğ¶Ã—ğ·. Finally,
the hierarchical knowledge guided predicted score Ë†ğ’€âˆˆRğ¶can be
computed by:
Ë†ğ’€=FRL(Ëœğ‘¿)Â·(HKL(T))âŠ¤:=ğ‘­â€²Â·CâŠ¤(3)
whereÂ·represents matrix multiplication operation and CâŠ¤denotes
the transpose matrix of C. Through the described process, our
HKG exploits hierarchical knowledge of target states to effectively
constrain the extracted deep features. The effect of hierarchical
classification is shown in the top right corner of Figure 3.
5659KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yu Sha et al.
TimeDomainAcoustic SignalsT-F Domain SpectrogramsFeatureLearnerGlobalMaxPoolingLearnedDeep FeaturesLearnedPooling Features
SCMHKCMB-HKCMRe-HKCMChoked FlowConstantIncipientCavitationNon-CavitationNon-CavitationHierarchical Edge Knowledge
Time Domain SubsequencesWord-Embedding Vector
NonCavitation
ChokedFlow
Constant
Incipient
BinaryConstraintRe-WeightedHierarchical classifierGCNAcoustic SignalsPre-processingFeature Representation Learning
Hierarchical Knowledge Learning
Hierarchical Classification
Multi-Label Loss
Hierarchical Knowledge Classifier Predicted ScoreHierarchicalLabelTreeIncipientConstantChoked FlowCavitationNonData0.70.70.30.20.5Hierarchical Classification ResultMatrix MultiplicationFeatures Guided Direction
Figure 3: Overall framework of the HKG. The T-F domain spectrograms are fed into feature representation learning module
for extracting deep features ğ‘­â€². Meanwhile, the target classes are used to generate word embeddings ğ‘¬ğ‘¤and re-weighted
hierarchical knowledge correlation matrix Ëœğ‘¨, which are input to a GCNs to generate a set of interdependent global hierarchical
knowledge classifiers C. Finally, the deep features ğ‘­â€²and the hierarchical knowledge classifier Care obtained predicted scores.
3.2 Feature Representation Learning
The feature representation learning uses deep learning methods
to extract deep features from T-F domain spectrograms and the
extracted features are acted on hierarchical classifiers.
In our experiments, we employ various deep learning methods as
feature learners, including convolutional neural networks (ResNet
[9], VGG [ 35] and DenseNet [ 11]), lightweight neural networks
(MobileNetv2/v3 [10, 32] and ShuffleNetv2 [22]) and transformers
(ViT [ 5] and Swin [ 20]). Given a T-F domain spectrogram Ëœğ‘¿as
an input to the feature learner FFL, we can obtain a learned deep
feature ğ‘­. Next, we perform a global max pooling layer FGMP to
obtain the learned pooling feature ğ‘­â€²âˆˆRğ·. The mathematical flow
of feature representation learning is described as follows:
ğ‘­â€²=FGMP(FFL(Ëœğ‘¿,ğœ½FL)):=FGMP(ğ‘­) (4)
where ğœ½FLis the parameter of the feature learner and ğ·=ğ‘‡Ã—ğ¹Ã—ğ¶â„
denotes the dimension of the T-F domain spectrogram ( ğ‘‡,ğ¹andğ¶â„
are the width, height and number of channels of the spectrogram.)
3.3 Hierarchical Knowledge Learning
The core of GCN is to propagate information between nodes based
on the correlation matrix. Therefore, how to construct the corre-
lation matrix is a key issue in GCN. In this paper, we construct
a correlation matrix in a data-driven and structured knowledge
way. In other words, we define the correlation between classes
by mining the co-occurrence patterns of classes from the dataset
and correcting the correlation based on the inherent hierarchical
knowledge in the hierarchical label tree.
Class Dependency. We represent class dependencies in terms of
conditional probability, i.e., ğ´ğ‘–â†’ğ‘—=ğ‘ƒ(ğ¿ğ‘—|ğ¿ğ‘–)denotes the impor-
tance of class ğ¿ğ‘–âˆˆğ¶for classğ¿ğ‘—âˆˆğ¶andğ´ğ‘—â†’ğ‘–=ğ‘ƒ(ğ¿ğ‘–|ğ¿ğ‘—)indicates
the importance of class ğ¿ğ‘—âˆˆğ¶for classğ¿ğ‘–âˆˆğ¶.
Statistical Correlation Matrix (SCM). To construct the statistical
correlation matrix, we first count the number of each class in thedataset to obtain ğ‘º={ğ‘†ğ‘–}ğ¶
ğ‘–=1. Then, we calculate the count of co-
occurrences of class ğ¿ğ‘–and classğ¿ğ‘—, i.e.ğ‘†(ğ‘–,ğ‘—)=ğ‘†(ğ‘—,ğ‘–)=ğ‘†ğ‘–+ğ‘†ğ‘—(ğ‘–â‰ 
ğ‘—). Finally, the SCM ğ‘¨âˆˆRğ¶Ã—ğ¶can be obtained as follows:
ğ‘¨=
ğ´ğ‘–ğ‘—
=ï£±ï£´ ï£²
ï£´ï£³ğ´ğ‘–ğ‘—=ğ‘†ğ‘–
ğ‘†ğ‘–+ğ‘†ğ‘—, ğ‘–â‰ ğ‘—
ğ´ğ‘–ğ‘–=ğ‘†ğ‘–
ğ‘†ğ‘–=ğ‘†ğ‘—
ğ‘†ğ‘—,ğ‘–=ğ‘—(5)
According to Equation 5, we can get ğ´ğ‘–â†’ğ‘—=ğ‘ƒ(ğ¿ğ‘—|ğ¿ğ‘–)=ğ‘†ğ‘–(ğ‘†ğ‘–+ğ‘†ğ‘—)
andğ´ğ‘—â†’ğ‘–=ğ‘ƒ(ğ¿ğ‘–|ğ¿ğ‘—)=ğ‘†ğ‘—(ğ‘†ğ‘–+ğ‘†ğ‘—). Therefore, the SCM is an
asymmetrical matrix with a diagonal of 1 since ğ´ğ‘–â†’ğ‘—=ğ‘ƒ(ğ¿ğ‘—|ğ¿ğ‘–)â‰ 
ğ´ğ‘—â†’ğ‘–=ğ‘ƒ(ğ¿ğ‘–|ğ¿ğ‘—)andğ´ğ‘–ğ‘–=ğ‘†ğ‘–/ğ‘†ğ‘–.
Hierarchical Knowledge Correlation Matrix (HKCM). The
basic SCM does not consider hierarchical knowledge among classes.
Therefore, we embed hierarchical edge knowledge based on hierar-
chical label treeT=(V,E)into the SCM to achieve the potential
dependencies between classes are considered. Each node ğ‘£âˆˆV
denotes a target class/concept and each edge (ğ‘¢,ğ‘£)âˆˆE encodes the
decomposition relationship between class ğ‘¢âˆˆV and classğ‘£âˆˆV,
where the parent node ğ‘¢is a broader conceptual superclass of the
child nodeğ‘£, such as(ğ‘¢,ğ‘£)=(cavitation,incipient cavitation) . In
addition, node ğ‘¢â€²âˆˆV and nodeğ‘¢is the same hierarchical classes
and are siblings of each other, i.e., ğ‘¢â€²is a cousin node of ğ‘£, such
as(ğ‘¢â€²,ğ‘£)=(non cavitation ,incipient cavitation) . We also assume
(ğ‘£,ğ‘£), i.e., each class is not only a subclass of itself, but also a super-
class of itself. Therefore, we have the following hierarchical edge
knowledge constraints:
ï£±ï£´ï£´ï£´ ï£²
ï£´ï£´ï£´ï£³Eğ‘£â†’ğ‘¢=(ğ‘£,ğ‘¢)=1
Eğ‘£â†’ğ‘¢â€²=(ğ‘£,ğ‘¢â€²)=0
Eğ‘¢â€²â†’ğ‘£=(ğ‘¢â€²,ğ‘£)=0(6)
Next, we create a transition matrix Î¦âˆˆRğ¶Ã—ğ¶with a diagonal of 1,
the elements corresponding to constraints Eğ‘£â†’ğ‘¢â€²andEğ‘¢â€²â†’ğ‘£as 0,
the element corresponding to the constraint Eğ‘£â†’ğ‘¢as1/ğ´ğ‘–ğ‘—(ğ‘–â‰ ğ‘—)
and the remaining elements as 1. Then, the HKCM Ë‡ğ‘¨âˆˆRğ¶Ã—ğ¶can
5660Hierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
be acquired as follows:
Ë‡ğ‘¨=ğ‘¨âŠ™Î¦ (7)
whereâŠ™is the Hadamard product. Since the ğ‘¨is an asymmetri-
cal matrix with diagonal 1 and |ğ‘¨|â‰ 0,ğ‘¨ğ‘¨âˆ’1=ğ‘°(ğ‘°âˆˆRğ¶Ã—ğ¶
is a unit matrix), so the ğ‘¨exists an inverse matrix ğ‘¨âˆ’1. Further-
more, we have Î¦=ğ‘¨âˆ’1Ë‡ğ‘¨, which indicates that hierarchical edge
knowledge is interpretable and equivalent to conventional matrix
transformations.
Binary HKCM (B-HKCM). The HKCM may face two drawbacks.
Firstly, the pattern of co-occurrence between class and other classes
may suffer from a long-tailed distribution [ 37]. Secondly, the ab-
solute number of training and testing datasets may not be exactly
equivalent. Therefore, we suggest to binarise the HKCM Ë‡ğ‘¨to filter
the edge noise. The B-HKCM Ë†ğ‘¨âˆˆRğ¶Ã—ğ¶is derived as follows:
Ë†ğ‘¨=(
0,ifË‡ğ‘¨ğ‘–ğ‘—<ğœ
1,ifË‡ğ‘¨ğ‘–ğ‘—â‰¥ğœ(8)
whereğœâˆˆ(0,1]is the threshold and Ë‡ğ‘¨ğ‘–ğ‘—denotes the element of
theğ‘–-th row and ğ‘—-th column of Ë‡ğ‘¨.
Re-weighted HKCM (Re-HKCM). The B-HKCM only considers
the connection relationship between nodes and ignores the strength
information of the connections. This can cause features to blend
too evenly across the graph as the GCN propagates information,
blurring the differences between nodes, i.e., over-smoothing [ 3,
19]. Our proposed re-weighting scheme considers the connection
strength of nodes and introduces more detailed information to
retain more differences in node features. This can more effectively
distinguish between nodes of various clusters and improve the
discriminative ability of the model. Specifically, the re-weighting
scheme is as follows:
Ëœğ‘¨=ï£±ï£´ï£´ ï£²
ï£´ï£´ï£³ğœ‚Ë†ğ‘¨Ãğ¶
ğ‘—=1Ë†ğ‘¨ğ‘–ğ‘—+ğ‘, ğ‘–â‰ ğ‘—
(1âˆ’ğœ‚)ğ‘°, ğ‘– =ğ‘—(9)
where Ëœğ‘¨âˆˆRğ¶Ã—ğ¶is Re-HKCM, Ë†ğ‘¨ğ‘–ğ‘—denotes the element of the
ğ‘–-th row and ğ‘—-th column of Ë†ğ‘¨,ğœ‚âˆˆ[0,1]is the scaling factor to
adjust the matrix elements, ğ‘denotes the smoothing factor to avoid
infinitely large values and ğ‘°represents the matrix of ğ¶Ã—ğ¶. When
ğœ‚â†’1, the neighborhood information is emphasized. When ğœ‚â†’0,
the nodeâ€™s features are considered.
Word Embedding. The word embedding represents the semantic
relationships between classes by mapping words into a continuous
vector space, which better models associations of classes. In our
model, the hierarchical label tree T âˆˆRğ¶Ã—ğ»is used as an input
to the global vectors for word representation (GloVe) [ 30] to a
generate word embedding vector ğ‘¬ğ‘¤âˆˆRğ¶Ã—ğ‘‘(ğ‘‘is the dimension
of the class-level word embedding), which is used as one of the
inputs to GCN.
Based on the above description, the global hierarchical knowl-
edge classifierCâˆˆRğ¶Ã—ğ·generated by the hierarchical knowledge
learning module is as follows:
C=FGCN((GloVe(T),Ëœğ‘¨),ğœ½GCN))
:=FGCN((ğ‘¬ğ‘¤,Ëœğ‘¨),ğœ½GCN)(10)
where ğœ½GCN is the parameter of the GCN.3.4 Hierarchical Classification
Hierarchical Knowledge Classifier Predicted Score. An inter-
dependent global hierarchical knowledge classifier, i.e., CâˆˆRğ¶Ã—ğ·
is learned from label representations based on the mapping func-
tion of GCN, where ğ¶is the number of classes and ğ·indicates
the dimension of the learned deep pooling features ğ‘­â€². We em-
ploy the learned global hierarchical knowledge classifier Con the
learned deep pooling features ğ‘­â€²to obtain the prediction scores Ë†ğ’€,
as follows:
Ë†ğ’€={Ë†ğ’šğ‘–}ğ¶
ğ‘–=1=ğ‘­â€²Â·CâŠ¤(11)
where Ë†ğ’šğ‘–âˆˆ[0,1]is the predicted score for each class.
Objective Function. In contrast to previous structured cavitation
intensity diagnoses focusing on complex network design, HKG
directly formulates it as a multi-label classification task. Therefore,
our method uses the traditional multi-label classification loss as
our modelâ€™s objective function, as follows:
L=âˆ’1
ğ¶ğ¶âˆ‘ï¸
ğ‘–=1ğ’ğ‘–log(1
1+ğ‘’âˆ’Ë†ğ’šğ‘–)+(1âˆ’ğ’ğ‘–)log(ğ‘’âˆ’Ë†ğ’šğ‘–
1+ğ‘’âˆ’Ë†ğ’šğ‘–) (12)
whereğ¶is the number of classes, ğ’denotes the ground truth label of
a T-F domain sub-spectrogram and Ë†ğ’šindicates the prediction score
of our model. The proposed HKG is summarized in the Algorithm
1.
Algorithm 1 HKG-based Fault Intensity Diagnosis
Input: original signal dataset ğ‘¿âŠ†Rğ‘€Ã—ğ‘, the corresponding label
ğ‘³âˆˆRğ¶Ã—ğ‘, thresholdğœâˆˆ(0,1]and scaling factor ğœ‚âˆˆ[0,1]
Output: hierarchical knowledge classifier predicted score Ë†ğ’šğ‘–
forepoch =0,1,...,ğ‘ do
Acoustic Signals Pre-processing:
ğ‘¿={ğ‘‹ğ‘–,ğ‘–=1,2,...,ğ‘}â‡’ Ëœğ‘¿âˆˆRğ‘‡Ã—ğ¹Ã—3â–·Equation 2
Feature Representation Learning:
FGMP(FFL(Ëœğ‘¿,ğœ½FL))â‡’ ğ‘­â€²âˆˆRğ·â–·e.g. CNNs, Transformer
Hierarchical Knowledge Learning:
Create hierarchical label tree:
ğ‘³âˆˆRğ¶Ã—ğ‘â‡’Tâˆˆ Rğ¶Ã—ğ»â–·Manual, Unsupervised Learning
Build correlation matrix:
T=(V,E)â‡’ ğ‘¨âˆˆRğ¶Ã—ğ¶â–·Equation 5
ğ‘¨âˆˆRğ¶Ã—ğ¶ğœ€â‡’Ë‡ğ‘¨âˆˆRğ¶Ã—ğ¶â–·Equations 6 and 7
Ë‡ğ‘¨âˆˆRğ¶Ã—ğ¶ğœâ‡’Ë†ğ‘¨âˆˆRğ¶Ã—ğ¶â–·Equation 8
Ë†ğ‘¨âˆˆRğ¶Ã—ğ¶ğœ‚â‡’Ëœğ‘¨âˆˆRğ¶Ã—ğ¶â–·Equation 9
Generate word-embedding vector:
Word2Vec(T)â‡’ ğ‘¬ğ‘¤âˆˆRğ¶Ã—ğ‘‘â–·e.g. GloVe, FastText
Hierarchical knowledge classifier:
FGCN((ğ‘¬ğ‘¤,Ëœğ‘¨),ğœ½GCN)â‡’Câˆˆ Rğ¶Ã—ğ·â–·Equation 10
Hierarchical Classification:
Obtain prediction score Ë†ğ’€:
ğ‘­â€²Â·CâŠ¤â‡’Ë†ğ’€={Ë†ğ’šğ‘–}ğ¶
ğ‘–=1â–·Equation 11
Update parameters of HKG by minimizing L:
minâˆ’1
ğ¶Ãğ¶
ğ‘–=1ğ’ğ‘–log(1
1+ğ‘’âˆ’Ë†ğ’šğ‘–)+(1âˆ’ğ’ğ‘–)log(ğ‘’âˆ’Ë†ğ’šğ‘–
1+ğ‘’âˆ’Ë†ğ’šğ‘–)
Save parameters ğœ½FLandğœ½GCN of HKG in current epoch.
end for
5661KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yu Sha et al.
4 Experiments
We conduct extensive experiments on four different datasets (three
cavitation datasets are provided by SAMSON AG and one public
dataset) to validate the effectiveness and scalability of the proposed
HKG. And detailed analysis of the performance and its comparison
with state-of-the-art methods are also reported. In addition, we
provide extensive discussions and ablation analysis to demonstrate
the stability and significance of the proposed HKG.
4.1 Evaluation Metrics
To achieve hierarchical knowledge-guided fault intensity diagnosis,
we technically treat it as a multi-label task. We still need to use
the same evaluation metrics as traditional fault intensity diagnosis
from the from the practical application for comparability and in-
terpretability. Therefore, we select Accuracy (Acc), Precision (Pre),
Recall (Rec) and F1-score (F1) as evaluation metrics following pre-
vious studies [ 8,34]. The threshold is determined by the Youden
index in ROC-AUC (more details see Appendix).
4.2 Implementation Details
The HKG contains a feature learning stream and a hierarchical
knowledge learning stream. For the feature learning stream, ResNet
[9], VGG [ 35], DeneseNet [ 11], MobNetv2/3 [ 10,32], ShuNetv2 [ 22],
ViT [ 5] and Swin [ 20] are used as feature learners, respectively. And
the input T-F domain spectrogram is flipped horizontally, flipped
vertically, rotated with 180â—¦and resized to 512Ã—512. For the hier-
archical knowledge learning stream, 2 layers of GCN are used with
output dimensions of 512 and 1024, respectively (not specified). In
addition, LeakyReLU non-linear function is applied across the two
GCN layers. For word embeddings, we use a 300-dim GloVe trained
on the Wikipedia corpus (the default word embedding method). For
the correlation matrix, the parameters ğœandğœ‚in Equation 8 and
Equation 9 are set to 0.3 and 0.4, respectively. During training, HKG
uses SGD as the optimizer with a momentum of 0.9 and a weight
decay of 10âˆ’4. The initial learning rate of the optimizer is set to
0.01 and dynamically adjusted by the Plateau Scheduler. The HKG
is trained for 100 epochs with a batch size of 16. Our source code is
released at https://github.com/CavitationDetection/HKG.
4.3 Datasets
Cavitation Datasets. This dataset is provided by SAMSON AG and
contains three sub-datasets, called Cavitation-Short, Cavitation-
Long andCavitation-Noise with real noise, respectively. The
cavitation acoustic signals are collected from different valves with
different upstream pressures and different valve opening rates in
a professional environment. The cavitation includes incipient cav-
itation, constant cavitation and choked flow cavitation. The non-
cavitation contains turbulent flow and no flow. Cavitation-Short
has a total of 356 acoustic signals and each acoustic signal with
time duration of 3 s. Cavitation-Long and Cavitation-Noise have
806 and 160 acoustic signals and each of them with time duration
of25 s, respectively. The sampling rate of all recording acoustic
signals is 1562.5 kHz (more details see Appendix).
PUB Dataset. This dataset [ 15] contains bearing vibration signals
provided by Paderborn University. The PUB contains three bearing
states named Inner Ring (IR) Damage, Outer Ring (OR) Damageand Healthy, with each fault state comprising artificial damage and
real damage. The vibration signals of the PUB are collected at a
sampling frequency of 64kHzwith a time duration of 4 s. The PUB is
organized into three hierarchies based on damage areas and damage
levels of the bearing: baring diagnosis (Hierarchy I), damage type
diagnosis (Hierarchy II) and IR/OR intensity diagnosis (Hierarchy
III-IR/III-OR). In our experiments, 80%of data is allocated to model
training and 20%of data is used for model testing (more details see
Appendix).
4.4 Experimental Results
Results on Cavitation datasets. Figure 4 shows examples of
cavitation deep feature distributions with and without the guidance
of hierarchical knowledge. It indicates that hierarchical knowledge
can better constrain and guide cavitation deep features. As seen in
Table 1, HKG shows superior results under different representation
learning methods across different cavitation datasets. The proposed
HKG achieves the best accuracy of 89.71%, 93.18% and99.63% in
three cavitation datasets, respectively. It shows that our proposed
HKG can be applied to any representation learning framework.
	

(a) ResNet34
	
 (b) HKG+ResNet34
Figure 4: Visualisation of the learned deep feature distribu-
tion of vanillia ResNet34 and HKG+ResNet34 via t-SNE [ 36]
on Cavitation-Short.
Detailedly, (1) Cavitation-Short: The accuracy of HKG is above
85% for each specific backbone, which outperforms the correspond-
ing baseline. The HKG improves the accuracy of ResNet34 by
1.14%. Specifically, the HKG achieves 92.35% precision on the Swin-
B. (2) Cavitation-Long: The accuracy of HKG under ResNet34,
DenseNet169, ViT-B (32) and Swin-B (4-12) as backbones all ex-
ceed 92%, which improves 0.56%, 0.61%, 0.44% and0.3% over the
corresponding backbone, respectively. The HKG achieves the best
precision, recall and F1-score on Swin-B with 89.58%, 93.40% and
91.27%, respectively. (3) Cavitation-Noise: Our method obtains
perfect performance in all backbones, which is better than all base-
lines.The HKG obtains an accuracy of 99.25%, 99.06%, 99.19% and
99.63% on backbone of ResNet18, ResNet34, DeneseNet169 and
Swin-B, respectively. And it has an improvement of 0.31%, 0.25%,
0.5% and0.44% over the corresponding backbone. In addition, the
best precision, recall and F1-score obtained by HKG+Swin-B are
99.63%, 99.63% and99.62%, respectively. The reasons why our
method gets superior results are as follows. First, although this
dataset has real background noise compared to other cavitation
5662Hierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
datasets, the time-frequency transform can filter most of the noise.
Second, this dataset is obtained with only one operating of valve
stroke and upstream pressure. Third, each class of data is balanced
for this dataset (see Appendix).
Table 1: Results of different evaluation metrics on three real-
world cavitation datasets. We compare different represen-
tation learning methods including CNNs, LNNs and Trans-
formers. According to our previous research [ 33], the slid-
ing window with a window size of 466944 and a step size of
466944.
Dataset Cavitation-Short Cavitation-Long Cavitation-Noise
MethodsImage
sizeAcc Pre Rec F1 Acc Pre Rec F1 Acc Pre Rec F1
ResNet18 [9] 256287.57 90.25 77.16 77.95 90.83 86.31 90.75 88.21 98.94 98.94 98.94 98.94
ResNet34 [9] 256288.57 91.47 76.22 74.00 91.88 87.60 91.86 89.42 98.81 98.82 98.81 98.81
ResNet50 [9] 256284.43 86.97 71.70 66.83 91.45 87.09 91.25 88.89 98.19 98.20 98.19 98.19
ResNet101 [9] 256282.14 59.88 68.75 63.73 89.49 84.54 89.43 86.56 97.56 97.57 97.56 97.56
VGG11 [35] 256284.29 62.31 70.10 65.95 80.78 74.46 81.11 76.69 97.81 97.82 97.81 97.81
VGG13 [35] 256280.71 58.96 66.85 62.60 81.56 75.21 82.00 77.50 98.19 98.19 98.19 98.19
VGG16 [35] 256279.86 57.77 66.53 61.25 83.38 77.30 83.14 79.44 98.44 98.44 98.44 98.44
VGG19 [35] 256273.29 64.40 59.76 59.03 82.80 76.52 82.42 78.63 98.69 98.69 98.69 98.69
DenseNet121 [11] 256284.86 87.36 72.01 67.21 91.16 86.73 91.24 88.66 97.94 97.94 97.94 97.94
DenseNet161 [11] 256285.00 89.49 71.96 71.14 91.84 87.84 92.07 89.67 98.25 98.25 98.25 98.25
DenseNet169 [11] 256287.00 64.39 73.04 68.28 92.08 87.78 92.14 89.65 98.69 98.69 98.69 98.69
DenseNet201 [11] 256284.14 86.59 72.13 69.37 90.40 85.66 90.79 87.76 98.56 98.57 98.56 98.56
HKG-ResNet18 256288.43 89.35 78.28 79.37 91.81 87.56 92.03 89.48 99.25 99.25 99.25 99.25
HKG-ResNet34 256289.71 90.54 78.02 76.74 92.44 88.55 92.21 90.16 99.06 99.06 99.06 99.06
HKG-VGG11 256285.71 88.21 75.78 76.19 82.86 76.67 83.06 78.89 98.63 98.63 98.63 98.63
HKG-DenseNet169 256288.14 90.07 75.27 72.31 92.69 88.85 92.48 90.46 99.19 99.19 99.19 99.19
MobNetv2 [32] 256284.00 62.15 69.98 65.82 88.30 82.99 88.08 85.04 94.13 94.13 94.13 94.13
MobNetv3-S [10] 256276.71 55.36 63.38 58.82 85.38 79.45 85.56 81.72 92.38 92.44 92.38 92.37
MobNetv3-L [10] 256277.43 59.02 61.39 58.10 86.87 81.14 86.43 83.24 93.44 93.49 93.44 93.44
ShuNetv2-0.5 [22] 256274.14 58.67 57.20 53.04 83.27 77.15 83.39 79.36 90.06 90.06 90.06 90.06
ShuNetv2-1.0 [22] 256274.86 63.13 57.98 55.51 83.00 76.85 83.06 79.04 90.56 90.60 90.56 90.57
ShuNetv2-1.5 [22] 256284.86 63.12 71.55 67.07 88.89 83.68 89.06 85.84 90.94 90.94 90.94 90.92
ShuNetv2-2.0 [22] 256273.29 64.63 58.35 55.91 82.53 76.11 81.94 78.17 89.94 89.95 89.94 89.94
HKG-MobNetv2 256285.29 87.87 75.41 75.57 89.70 85.00 89.73 86.98 96.25 96.25 96.25 96.25
HKG-ShuNetv2-1.5 256286.57 89.79 73.55 70.69 89.99 85.23 89.97 87.21 93.13 93.14 93.13 93.13
ViT-T-16 [5] 224286.86 89.32 76.81 77.77 91.23 86.85 91.09 88.69 96.19 96.19 96.19 96.19
ViT-S-16 [5] 224287.14 89.69 76.89 77.53 91.73 87.84 91.78 89.56 96.38 96.39 96.38 96.38
ViT-S-32 [5] 224287.43 90.08 77.02 77.79 91.93 87.84 92.08 89.68 96.50 96.50 96.50 96.50
ViT-B-16 [5] 224287.57 90.45 74.90 72.08 92.05 87.86 92.06 89.68 96.81 96.81 96.81 96.81
ViT-B-32 [5] 224287.86 90.81 75.17 72.39 92.65 88.77 92.46 90.40 97.25 97.25 97.25 97.25
Swin-T-4-7 [20] 224287.71 90.63 75.03 72.24 91.64 87.35 91.59 89.16 97.38 97.40 97.38 97.38
Swin-S-4-7 [20] 224287.86 90.81 75.17 72.39 91.90 87.72 91.43 89.35 97.63 97.63 97.63 97.63
Swin-B-4-7 [20] 224288.29 91.11 75.94 73.69 92.60 88.58 92.39 90.25 97.88 97.88 97.88 97.87
Swin-B-4-12 [20] 384288.43 91.39 75.90 73.41 92.88 88.91 93.09 90.73 99.19 99.19 99.19 99.19
HKG-ViT-B-32 224288.75 91.20 76.74 75.23 93.09 89.54 93.01 91.09 98.44 98.44 98.44 98.44
HKG-Swin-B-4-12 384289.57 92.35 77.88 76.66 93.18 89.58 93.40 91.27 99.63 99.63 99.63 99.62
In addition, we also report the accuracy of each cavitation state
on three real-world cavitation datasets, see Table 2. It can be found
that HKG can help different backbone networks to improve the
accuracy of each cavitation state. It is worth noting that HKG can
significantly improve the diagnosis results of incipient cavitation
states without basically degrading the performance of other cavi-
tation states. For example, the HKG assists ViT-B (32) to increase
the incipient cavitation accuracy by 6.25%, 0.6% and1.5% on three
cavitation datasets, respectively.
Furthermore, we also show the results of different compari-
son methods on three real-world cavitation datasets, see Table
A1. It is clear from the table that HKG+ResNet34, HKG+ResNet18,
HKG+DeneseNet169 and HKG+Swin-B-4-12 outperform the other
methods in several critical metrics, especially in accuracy and F1Table 2: Accuracy of various fine states on three real-world
cavitation datasets, encompassing non-cavitation (non),
choked flow cavitation (cho), constant cavitation (con), and
incipient cavitation (inc). We show different representation
learning methods including CNNs, LNNs and Transformers.
Dataset Cavitation-Short Cavitation-Long Cavitation-Noise
Methods cho con inc non cho con inc non cho con inc non
ResNet34 [9] 100.0 96.11 8.75 100.0 92.21 92.24 92.17 90.84 98.50 98.75 99.00 99.00
VGG11 [35] 85.71 95.00 0.00 99.67 81.04 80.33 81.93 81.14 97.75 98.00 97.25 98.25
DenseNet169 [11] 92.14 100.0 0.00 100.0 92.45 91.96 92.17 91.99 98.50 98.25 98.50 99.50
HKG-ResNet34 100.0 98.33 13.75 100.0 91.81 92.82 91.87 92.35 99.50 98.50 99.50 98.75
HKG-VGG11 93.57 87.22 25.00 97.33 83.25 82.78 83.73 82.47 98.25 98.50 99.00 98.75
HKG-DenseNet169 93.57 100.0 7.50 100.0 92.81 92.71 91.47 92.92 98.75 99.50 99.75 98.75
MobileNetv2 [32] 88.57 91.67 0.00 99.67 88.07 88.41 87.25 88.58 93.75 94.25 93.25 95.25
ShuNetv2-1.5 [22] 97.86 90.00 0.00 98.33 89.40 88.64 89.36 88.86 88.50 87.75 94.25 93.25
HKG-MobileNetv2 93.57 88.33 23.75 96.00 90.36 89.64 89.56 89.34 97.50 96.50 95.75 95.25
HKG-ShuNetv2-1.5 96.43 92.78 5.00 100.0 90.00 89.95 89.86 90.09 93.75 92.75 92.75 93.25
ViT-B-32 [5] 100.0 94.44 6.25 100.0 91.77 92.86 92.17 93.04 97.75 98.25 96.50 96.50
Swin-B-4-12 [20] 99.29 96.11 8.75 100.0 93.29 92.54 93.47 93.04 99.50 98.75 98.75 99.75
HKG-ViT-B-32 100.0 94.44 12.50 100.0 93.37 93.23 92.77 92.68 98.25 98.75 98.00 98.75
HKG-Swin-B-4-12 100.0 97.78 13.75 100.0 93.29 93.03 94.18 93.10 100.0 100.0 99.50 99.00
score, which show significant advantages. This suggests that the
HKG method provides significant advantages for various backbones
in cavitation intensity diagnosis, indicating the effective guidance
of hierarchical knowledge on deep learning features.
Table 3: Results of different evaluation metrics on three real-
world cavitation datasets. Non-hierarchical and hierarchical
methods from cavitation intensity recognition or fault diag-
nosis are used as comparative methods. The sliding window
with a window size of 466944 and a step size of 466944.
Dataset Cavitation-Short Cavitation-Long Cavitation-Noise
MethodsImage
sizeAcc Pre Rec F1 Acc Pre Rec F1 Acc Pre Rec F1
LiftingNet [28] 256285.29 82.75 75.89 73.95 88.43 86.31 87.97 87.05 95.86 94.62 95.84 95.20
MIPLCNet [29] 256286.57 83.38 77.71 75.00 89.14 87.06 88.18 87.55 96.57 95.78 96.61 96.18
ResNet-APReLU [43] 256286.86 84.04 77.89 75.56 90.71 88.83 90.91 89.70 97.29 96.77 97.49 97.12
LSTM-RDRN [25] 256287.71 85.42 78.50 76.72 91.14 89.36 91.55 90.32 98.71 98.40 98.53 98.46
BCNN [44] 256281.71 78.63 72.25 70.03 85.71 82.42 85.09 83.56 92.14 89.75 92.71 91.03
HKG-ResNet18 256288.43 89.35 78.28 79.37 91.81 87.56 92.03 89.48 99.25 99.25 99.25 99.25
HKG-ResNet34 256289.71 90.54 78.02 76.74 92.44 88.55 92.21 90.16 99.06 99.06 99.06 99.06
HKG-DeneseNet169 256288.14 90.07 75.27 72.31 92.69 88.85 92.48 90.46 99.19 99.19 99.19 99.19
HKG-Swin-B-4-12 384289.57 92.35 77.88 76.66 93.18 89.58 93.40 91.27 99.63 99.63 99.63 99.62
Results on PUB. Table 4 shows the experimental results of dif-
ferent evaluation metrics. In general, HKG can help improve the
diagnostic performance of various backbone networks. In particular,
the HKG+ViT-S achieves the best performance of 98.92% outper-
forming all SOAT methods and increasing average accuracy by
2.83%. And HKG also reaches the best precision, recall and F1-score
of98.3%, 99% and98.63%, respectively.
In detail, (1) Health: The diagnostic accuracy of HKG+ViT-S
for bearing health is 100%, with an average improvement of 3.69%
compared to all SOAT methods. (2) IR-1: Although HKG+ViT-S,
ResNet-APReLU, TDMSAE and SACL all obtain an accuracy of
98.21% for IR-1, the performance of HKG is more superior for other
states with ResNet18, ResNet34 and ViT-S. (3) IR-2: The results
of HKG based on ResNet18/34 and ViT are all over 97%, which is
better than all compared methods. In particular, HKG+ResNet34
5663KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yu Sha et al.
achieves 100% accuracy, which is on average 5.11% better than
comparison methods. (4) IR-3: HKG+ResNet18 and HKG+ViT-S
all perform 100%, which an average improvement of 2.27% over
all baselines. (5) OR-1: HKG+ResNet34 and HKG+ViT all attain a
performance of 99.11%. (6) OR-2: HKG+ResNet18, HKG+ResNet34
and HKG+ViT-S obtain 97.47%, 100% and98.73% diagnostic results,
which are 1.38%, 3.91% and2.65% improvement compared to SOAT
methods, respectively.
Table 4: Different evaluation metrics results on PUB dataset.
Methods BackbonesImage
sizeAccuracy of fine states Overall
Health IR-1 IR-2 IR-3 OR-1 OR-2 Acc Pre Rec F1
DATMMD [18] LeNet 256290.63 93.75 93.75 100.0 93.75 94.94 93.52 92.46 94.47 93.38
LiftingNet [28] AlexNet 256295.83 90.18 93.75 93.75 94.64 92.41 93.30 91.18 93.43 92.09
MIP-LCNet [29] AlexNet 256297.92 89.29 95.83 93.75 94.64 96.20 93.48 91.68 94.61 92.96
ResNet18 [9] ResNet18 256294.79 96.43 93.75 100.0 95.54 94.94 95.46 94.86 95.91 95.36
ResNet-APReLU [43] ResNet18 256297.92 98.21 91.67 100.0 96.43 96.20 96.76 95.07 96.74 95.78
ADMTL [16] ResNet18 256295.83 95.54 97.92 93.75 98.21 96.20 96.54 95.13 96.24 95.66
RDRN [25] ResNet18 256297.92 96.43 95.83 100.0 98.21 94.94 96.98 94.32 97.22 95.57
TDMSAE [41] ResNet50 256293.75 98.21 95.83 93.75 99.11 98.73 97.19 95.50 96.56 95.96
LRSADTLM [42] Transformer 224297.92 97.32 95.83 100.0 99.11 96.20 97.62 96.40 97.73 97.00
SACL [4] Transformer 224297.92 98.21 93.75 100.0 97.32 97.47 97.41 95.83 97.45 96.51
TS-TCC [6] Transformer 224298.96 97.32 95.83 100.0 97.32 98.73 97.84 96.56 98.03 97.23
ResNet18 256296.88 94.64 97.92 100.0 97.32 97.47 96.76 94.59 97.37 95.79
HKG ResNet34 256295.83 97.32 100.0 93.75 99.11 100.0 98.06 97.40 97.67 97.53
ViT-S (32) 2242100.0 98.21 97.92 100.0 99.11 98.73 98.92 98.30 99.00 98.63
Takeaways: The proposed HKG achieves significant improvements
in results for various backbone networks on four real-world datasets.
This is motivated by two following reasons. Firstly, the hierarchical
knowledge learning module of HKG explicitly learns the hierar-
chical relationships between target classes. Secondly, the global
hierarchical classifier effectively constrains and guides the learned
deep features from representation learning.
4.5 Ablation Analysis
Effects of correlation matrices. We report the results with differ-
ent correlation matrices for our method in Table 5. It can be found
that the Re-HEKCM for HKG significantly outperforms the other
correlation matrices (SCM, HEKCM and B-HEKCM), which shows
the Re-HEKCM effectively overcomes the issues mentioned in Sec-
tion 3.3. Meanwhile, the performance of HKG with Re-HEKCM,
B-HEKCM and HEKCM are superior to HKG with SCM. It demon-
strates that correlation matrices (i.e., Re-HEKCM, B-HEKCM and
HEKCM) obtained by embedding hierarchical knowledge between
classes in SCM are more conducive to guiding deep features.
Table 5: Effects of correlation matrices on Cavitation-Short.
HKG + ResNet-34 Evaluation Metrics
SCM HEKCM B-HEKCM Re-HEKCM Accuracy Precision Recall F1-score
âœ— âœ— âœ— âœ— 88.57â†‘0.00 91.47â†‘0.00 76.22â†‘0.00 74.00â†‘0.00
âœ“
âœ— âœ— âœ— 89.00â†‘0.43 91.80â†‘0.33 76.98â†‘0.76 75.27â†‘1.27
âœ—
âœ“ âœ— âœ— 89.29â†‘0.72 92.00â†‘0.53 77.43â†‘1.21 75.89â†‘1.89
âœ—
âœ— âœ“ âœ— 89.57â†‘1.00 92.25â†‘0.78 77.88â†‘1.66 76.56â†‘2.56
âœ— âœ— âœ— âœ“ 89.71â†‘1.14 90.54â†“0.93 78.02â†‘1.8076.74â†‘2.74
Analysis of GCN layer number. From Table 6, it can be found
that as the number of graph convolutional layers increases, theperformance of our model initially increases and then decreases.
When the number of layers is 0, our model is ResNet34. The possible
reason for the performance drop is the oversmoothing between
nodes when the GCN is deep.
Table 6: Effects of depth of GCN on Cavitation-Short.
GCN
LayersEvaluation
Metrics
A
ccuracy Precision Recall F1-score
0-lay
er 88.57â†‘0.00 91.47â†‘0.00 76.22â†‘0.00 74.00â†‘0.00
1-lay
er 89.00â†‘0.43 91.80â†‘0.33 76.98â†‘0.76 75.27â†‘1.27
2-lay
er 89.71â†‘1.14 90.54â†“0.93 78.02â†‘1.80 76.74â†‘2.74
3-lay
er 89.43â†‘0.86 92.17â†‘0.70 77.57â†‘1.35 76.02â†‘2.02
Impacts of word embeddings. We compare the performance of
our model using different word embedding methods on Cavitation-
Short. It is clear from Table 7 that the three different word em-
bedding methods have a negligible effect on the performance of
our model. It indicates that the performance of our methods does
not depend entirely on the semantic information of the word em-
beddings. In addition, the reason that powerful word embeddings
achieve higher performance is that learned word embeddings from
publicly available semantic repositories keep topological structure
between classes.
Table 7: Results of word embedding on Cavitation-Short.
T
ypesEvaluation
Metrics
A
ccuracy Precision Recall F1-score
FastT
ext [13] 88.57â†‘0.00 91.47â†‘0.00 76.22â†‘0.00 74.00â†‘0.00
Go
ogleNews [24] 89.00â†‘0.43 91.80â†‘0.33 76.98â†‘0.76 75.27â†‘1.27
Glo
Ve [30] 89.43â†‘0.86 92.17â†‘0.70 77.57â†‘1.35 76.02â†‘2.02
Parameters ( ğœ&ğœ‚) sensitivity. We analyze the impact of different
values of threshold ğœ(Equation 8) and scaling factor ğœ‚(Equation
9) on for the HKG on Cavitation-Short, see Figure 5a. For ğœ, HKG
accuracy is improved when a small amount of edge noise is filtered.
When a large amount of edge noise is filtered causing neighbor
information being lost, HKG accuracy decreases. Where, HKG does
not converge for ğœ=0. The optimal value of ğœis 0.3. Forğœ‚, HKG
achieves the best accuracy with ğœ‚=0.4. Whenğœ‚is set too small,
the node only considers its own features. Conversely, ğœ‚is set too
large, the node considers excessive neighbour information, which
occurs as an over-smoothing issue.
STFT parameter analysis. We consider the effect of the window
length of the STFT for the performance of HKG. In all experiments,
the step length is one-quarter of the window length. From Figure
5b, it can be seen that the window length has a very significant
impact on the results and the most appropriate window length is
2048.
Window size analysis. We compare the results of our method
with different window sizes on Cavitation-Short. It is clear from
Figure 5c that the window size is sensitive to the performance of
HKG and the best window size is 466944.
Downsampling effects. In practical applications, the ability to
recognize signals obtained from low-level sensors is very impor-
tant and challenging. Our method is evaluated under the origi-
nal sample frequency ( ğ¹ğ‘ =1 562 500 Hz), one-half, one-quarter,
5664Hierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
0.0 0.2 0.4 0.6 0.8 1.0
Parameters Ï„ and Î·767880828486889092Accuracy (%)
Î·
Ï„
87.590.092.5
Precision
75.077.5
Recall
0.0 0.2 0.4 0.6 0.8 1.072.575.077.5
F1-score
(a) Parameter sensitivity
128 256 512 1024 2048 4096
Window lengths5560657075808590Performance (%)
Accuracy
128 256 512 1024 2048 4096
Window lengths30405060708090Performance (%)Precision
Recall
F1-score (b) STFT parameter analysis
1167360 778240 583680 466944 389120 333531
Window sizes5560657075808590Performance (%)
Accuracy
1167360 778240 583680 466944 389120 333531
Window sizes30405060708090Performance (%)Precision
Recall
F1-score (c) Window size analysis
48000 195312 260416 390625 781250 1562500
Sample frequencies (Hz)30405060708090Performance (%)
Accuracy
48000 195312 260416 390625 781250 1562500
Sample frequencies (Hz)405060708090Performance (%)Precision
Recall
F1-score (d) Downsampling effects
Figure 5: Different evaluation metrics results of various ablation experiments on Cavitation-Short. (a)-(b) and (d) are all
performed with a window size of 466944 and a step size of 466944.
one-sixth, one-eighth of the original sample frequency (781 250 Hz,
390 625 Hz,260 416 Hz,195 312 Hz) and the maximum frequency
a mobile phone can withstand (48 000 Hzâ‰ˆğ¹ğ‘ /32). As shown in
Figure 5d, although the performance of HKG gradually reduces as
the sampling frequency decreases, the accuracy always remains
above 80%. Moreover, HKG also reaches 69% accuracy with the
maximum sample frequency of mobile phones.
5 Related Work
Fault Intensity Diagnosis. Fault intensity diagnosis (FID) is usu-
ally regarded as a specific recognition problem based on a fine-
grained fault classification in terms of signals. Signal-based FID
can be broadly organized into two classes: convolutional neural
networks (CNNs) and transformers. For CNN methods, Zhou et
al. in [ 18] proposed an intelligent fault diagnosis method based
on feature space distance extractor and feature domain mismatch
extractor. Pan et al. in [ 28] designed a novel CNN consisting of
split layers inspired by the second generation wavelet transform.
Pan et al. in [ 29] developed an intelligent fault detection method
using multiscale inner product and local feature connection. Li et
al. in [ 16] presented a novel attention-based deep meta-transfer
learning for fine-grained fault diagnosis. Arta et al. [ 25] recommend
a deep residual network modulated by a long- and short-term mem-
ory network for vehicle fault diagnosis. Yu et al. in [41] presented
a decoupled multi-scale autoencoder fault diagnosis model. For
transformer methods, Yu et al. in [ 42] proposed a deep transfer
method for fault diagnosis by combining time-frequency analysis,
residual networks and self-attention. Cui et al. in [ 4] introduced
the transformer as the backbone of a contrastive learning fault
diagnosis model. However, the above methods do not consider the
hierarchical structure information between target classes.
Hierarchical Classification. Considering the hierarchical infor-
mation of target classes is an active topic in machine learning appli-
cation domains [ 26]. According to the target class belonging to one
or more paths of hierarchical structure, hierarchical classification
can be viewed as a special kind of multi-label classification task.
[17]. For deep learning methods, existing hierarchical classifications
can be divided into three families: label embedding, hierarchical
losses and hierarchical structures. For label embedding methods
[1,3], the hierarchical information across labels is mapped into hier-
archical semantic vectors containing relative position information.
For hierarchical losses [ 2,17], which emphasizes the consistencybetween the prediction results and the class hierarchy that is often
employed in multi-label classification tasks. Hierarchical structures
[21,23,39] aim to better adapt specifically designed deep neural
network structures to the class hierarchy of a particular task. In this
work, our proposed HKG is one of the label embedding methods.
6 Conclusions
Fault intensity diagnosis FID is essential for monitoring complex in-
dustrial systems. In this paper, we propose HKG, a novel end-to-end
knowledge- and data-driven FID approach that uses graph convo-
lutional neural networks to map hierarchical topological graphs of
label representations together with learned deep features from rep-
resentation learning to a set of interdependent global hierarchical
classifiers. To explicitly model the hierarchical dependencies among
classes, we design a novel re-weighted hierarchical knowledge cor-
relation matrix scheme by embedding hierarchical knowledge in
a data-driven statistical correlation matrix. The scheme can effec-
tively mitigate over-fitting and over-smoothing issues by balancing
the weights between nodes and their neighborhoods. The HKG
outperforms the SOTA methods on four real-world datasets. The
ablation experiments clearly show that HKG successfully meets the
FID requirements of complex industrial systems in the real world,
providing insights for extending the method to other industrial
applications.
Acknowledgements
This research is supported by Xidian-FIAS International Joint Re-
search Center (Y. S.), by the AI grant at FIAS through SAMSON AG
(J. F., K. Z.), by the CUHK-Shenzhen university development fund
under grant No. UDF01003041 and the BMBF funded KISS consor-
tium (05D23RI1) in the ErUM-Data action plan (K. Z.), by SAM-
SON AG (D. V., T. S., A. W.), by the Walter GreinerGesellschaft zur
FÃ¶rderung der physikalischen Grundla - genforschung e.V. through
the Judah M. Eisenberg Lau-reatus Chair at Goethe UniversitÃ¤t
Frankfurt am Main (H. S.), by the NVIDIA GPU grant through
NVIDIA Corporation (K. Z.), by the National Natural Science Foun-
dation of China under No. 62372358 and No. 62301395 (S. G.), and
by the Shaanxi Province Postdoctoral Science Foundation under
NO. 2023BSHEDZZ177 (S. G.).
5665KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yu Sha et al.
References
[1]Samy Bengio, Jason Weston, and David Grangier. 2010. Label embedding trees
for large multi-class tasks. Advances in neural information processing systems 23
(2010).
[2]Luca Bertinetto, Romain Mueller, Konstantinos Tertikas, Sina Samangooei, and
Nicholas A Lord. 2020. Making better mistakes: Leveraging class hierarchies
with deep networks. In Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition. 12506â€“12515.
[3]Zhao-Min Chen, Xiu-Shen Wei, Peng Wang, and Yanwen Guo. 2019. Multi-label
image recognition with graph convolutional networks. In Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition. 5177â€“5186.
[4]Long Cui, Xincheng Tian, Qingzhe Wei, and Yan Liu. 2024. A self-attention based
contrastive learning method for bearing fault diagnosis. Expert Systems with
Applications 238 (2024), 121645.
[5]Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-
aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, et al .2020. An image is worth 16x16 words: Transformers
for image recognition at scale. arXiv preprint arXiv:2010.11929 (2020).
[6]Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee-Keong
Kwoh, Xiaoli Li, and Cuntai Guan. 2023. Self-supervised contrastive representa-
tion learning for semi-supervised time-series classification. IEEE Transactions on
Pattern Analysis and Machine Intelligence (2023).
[7]Charles R Farrar and Keith Worden. 2012. Structural health monitoring: a machine
learning perspective. John Wiley & Sons.
[8]Dennis Fedorishin, Justas Birgiolas, Deen Dayal Mohan, Livio Forte, Philip Schnei-
der, Srirangaraj Setlur, and Venu Govindaraju. 2022. Large-Scale Acoustic Au-
tomobile Fault Detection: Diagnosing Engines Through Sound. In Proceedings
of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
2871â€“2881.
[9]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770â€“778.
[10] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingx-
ing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et al .2019.
Searching for mobilenetv3. In Proceedings of the IEEE/CVF international conference
on computer vision. 1314â€“1324.
[11] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger.
2017. Densely connected convolutional networks. In Proceedings of the IEEE
conference on computer vision and pattern recognition. 4700â€“4708.
[12] Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and
Tom Soderstrom. 2018. Detecting spacecraft anomalies using lstms and nonpara-
metric dynamic thresholding. In Proceedings of the 24th ACM SIGKDD interna-
tional conference on knowledge discovery & data mining. 387â€“395.
[13] Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2016. Bag
of tricks for efficient text classification. arXiv preprint arXiv:1607.01759 (2016).
[14] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In International Conference on Learning Repre-
sentations.
[15] Christian Lessmeier, James Kuria Kimotho, Detmar Zimmer, and Walter Sextro.
2016. Condition monitoring of bearing damage in electromechanical drive sys-
tems by using motor current signals of electric motors: A benchmark data set for
data-driven classification. In PHM Society European Conference, Vol. 3.
[16] Chuanjiang Li, Shaobo Li, Huan Wang, Fengshou Gu, and Andrew D Ball. 2023.
Attention-based deep meta-transfer learning for few-shot fine-grained fault
diagnosis. Knowledge-Based Systems 264 (2023), 110345.
[17] Liulei Li, Tianfei Zhou, Wenguan Wang, Jianwu Li, and Yi Yang. 2022. Deep
hierarchical semantic segmentation. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition. 1246â€“1257.
[18] Yibin Li, Yan Song, Lei Jia, Shengyao Gao, Qiqiang Li, and Meikang Qiu. 2020.
Intelligent fault diagnosis by fusing domain adversarial training and maximum
mean discrepancy via ensemble learning. IEEE Transactions on Industrial Infor-
matics 17, 4 (2020), 2833â€“2841.
[19] Hua Liu, Haoyu Han, Wei Jin, Xiaorui Liu, and Hui Liu. 2023. Enhancing Graph
Representations Learning with Decorrelated Propagation. In Proceedings of the
29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 1466â€“
1476.
[20] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin,
and Baining Guo. 2021. Swin transformer: Hierarchical vision transformer us-
ing shifted windows. In Proceedings of the IEEE/CVF international conference on
computer vision. 10012â€“10022.
[21] Chen Ma, Peng Kang, and Xue Liu. 2019. Hierarchical gating networks for
sequential recommendation. In Proceedings of the 25th ACM SIGKDD international
conference on knowledge discovery & data mining. 825â€“833.
[22] Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun. 2018. Shufflenet
v2: Practical guidelines for efficient cnn architecture design. In Proceedings of the
European conference on computer vision (ECCV). 116â€“131.[23] Changping Meng, Jiasen Yang, Bruno Ribeiro, and Jennifer Neville. 2019. Hats: A
hierarchical sequence-attention framework for inductive set-of-sets embeddings.
InProceedings of the 25th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining. 783â€“792.
[24] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
estimation of word representations in vector space. arXiv preprint arXiv:1301.3781
(2013).
[25] Arta Mohammad-Alikhani, Babak Nahid-Mobarakeh, and Min-Fu Hsieh. 2023.
One-Dimensional LSTM-Regulated Deep Residual Network for Data-Driven Fault
Detection in Electric Machines. IEEE Transactions on Industrial Electronics (2023).
[26] Seyedeh Fatemeh Mousavi, Mehran Safayani, Abdolreza Mirzaei, and Hoda Ba-
honar. 2017. Hierarchical graph embedding in vector space by graph pyramid.
Pattern Recognition 61 (2017), 245â€“254.
[27] Sathyan Munirathinam. 2020. Industry 4.0: Industrial internet of things (IIOT).
InAdvances in computers. Vol. 117. Elsevier, 129â€“164.
[28] Jun Pan, Yanyang Zi, Jinglong Chen, Zitong Zhou, and Biao Wang. 2017. Lift-
ingNet: A novel deep learning network with layerwise feature learning from
noisy mechanical data for fault classification. IEEE Transactions on Industrial
Electronics 65, 6 (2017), 4973â€“4982.
[29] Tongyang Pan, Jinglong Chen, Zitong Zhou, Changlei Wang, and Shuilong He.
2019. A novel deep learning network via multiscale inner product with locally
connected feature extraction for intelligent fault detection. IEEE Transactions on
Industrial Informatics 15, 9 (2019), 5119â€“5128.
[30] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove:
Global vectors for word representation. In Proceedings of the 2014 conference on
empirical methods in natural language processing (EMNLP). 1532â€“1543.
[31] Milton S Plesset and Andrea Prosperetti. 1977. Bubble dynamics and cavitation.
Annual review of fluid mechanics 9, 1 (1977), 145â€“185.
[32] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-
Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In
Proceedings of the IEEE conference on computer vision and pattern recognition.
4510â€“4520.
[33] Yu Sha, Johannes Faber, Shuiping Gou, Bo Liu, Wei Li, Stefan Schramm, Horst
Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, et al .2022.
A multi-task learning for cavitation detection and cavitation intensity recognition
of valve acoustic signals. Engineering Applications of Artificial Intelligence 113
(2022), 104904.
[34] Yu Sha, Shuiping Gou, Johannes Faber, et al .2022. Regional-Local Adversarially
Learned One-Class Classifier Anomalous Sound Detection in Global Long-Term
Space. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining. 3858â€“3868.
[35] Karen Simonyan and Andrew Zisserman. 2014. Very deep convolutional networks
for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).
[36] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.
Journal of machine learning research 9, 11 (2008).
[37] Ya Wang, Dongliang He, Fu Li, Xiang Long, Zhichao Zhou, Jinwen Ma, and
Shilei Wen. 2020. Multi-label classification with label graph superimposing. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 12265â€“12272.
[38] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
Quoc V Le, Denny Zhou, et al .2022. Chain-of-thought prompting elicits reasoning
in large language models. Advances in Neural Information Processing Systems 35
(2022), 24824â€“24837.
[39] Ning Wu, Xin Wayne Zhao, Jingyuan Wang, and Dayan Pan. 2020. Learning
effective road network representation with hierarchical graph neural networks.
InProceedings of the 26th ACM SIGKDD international conference on knowledge
discovery & data mining. 6â€“14.
[40] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao,
and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate problem solving
with large language models. arXiv preprint arXiv:2305.10601 (2023).
[41] Shihang Yu, Min Wang, Shanchen Pang, Limei Song, Xue Zhai, and Yawu Zhao.
2023. TDMSAE: A transferable decoupling multi-scale autoencoder for me-
chanical fault diagnosis. Mechanical Systems and Signal Processing 185 (2023),
109789.
[42] Xiao Yu, Youjie Wang, Zhongting Liang, Haidong Shao, Kun Yu, and Wanli Yu.
2023. An Adaptive Domain Adaptation Method for Rolling Bearingsâ€™ Fault Diag-
nosis Fusing Deep Convolution and Self-Attention Networks. IEEE Transactions
on Instrumentation and Measurement 72 (2023), 1â€“14.
[43] Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Shaojiang Dong,
and Michael Pecht. 2020. Deep residual networks with adaptively parametric
rectifier linear units for fault diagnosis. IEEE Transactions on Industrial Electronics
68, 3 (2020), 2587â€“2597.
[44] Xinqi Zhu and Michael Bain. 2017. B-CNN: branch convolutional neural network
for hierarchical classification. arXiv preprint arXiv:1709.09890 (2017).
5666Hierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
A PRELIMINARIES
A.1 Definition of Cavitation Intensity
Figure A1 illustrates how the local pressure changes in a one-
dimensional flow. The valve would operate normally without cavi-
tation when the minimum pressure ğ‘ğ‘šğ‘–ğ‘›is higher than the vapor
pressureğ‘ğ‘£. In the case where ğ‘ğ‘£>ğ‘ğ‘šğ‘–ğ‘›cavitation begins. How-
ever, it cannot be measured directly as the minimum pressure occurs
downstream of the restriction. In practice, the cavitation coefficient
ğ‘‹ğ¹ğ‘is equal to the ratio of the external pressure difference to the
internal pressure difference. It can be determined empirically by
assuming that cavitation noise only begins when the minimum
pressureğ‘ğ‘šğ‘–ğ‘›is equal to the vapor pressure ğ‘ğ‘£. Therefore, the cavi-
tation coefficient ğ‘‹ğ¹ğ‘can be measured by the noise, which depends
on the load of the valve. The equations for the cavitation coefficient
ğ‘‹ğ¹ğ‘and the operating pressure ratio ğ‘‹ğ¹are given below:
ğ‘‹ğ¹ğ‘=ğ‘ğ‘¢âˆ’ğ‘ğ‘‘
ğ‘ğ‘¢âˆ’ğ‘ğ‘šğ‘–ğ‘›ğ‘‹ğ¹=ğ‘ğ‘¢âˆ’ğ‘ğ‘‘
ğ‘ğ‘¢âˆ’ğ‘ğ‘£(A.1)
whereğ‘ğ‘¢is the upstream pressure, ğ‘ğ‘‘is the downstream pressure,
ğ‘ğ‘šğ‘–ğ‘›is the minimum pressure in the valve and ğ‘ğ‘£is the vapor
pressure. When all coefficients are known over the full opening
range of the valve, the following statements can be made.
	
	

Figure A1: Pressure flow model in a valve. The solid black,
dotted orange, dotted green and dotted blue lines are repre-
sented by the upstream pressure ğ‘ğ‘¢, the downstream pressure
ğ‘ğ‘‘, the minimum pressure ğ‘ğ‘šğ‘–ğ‘›and the vapor pressure ğ‘ğ‘£,
respectively.
â€¢ğ‘‹ğ¹<ğ‘‹ğ¹ğ‘: The valve operates without cavitation and the
flow is only turbulent or laminar.
â€¢ğ‘‹ğ¹â‰¥ğ‘‹ğ¹ğ‘: Forğ‘‹ğ¹=ğ‘‹ğ¹ğ‘, the valve operates with incipient
cavitation. As the difference between ğ‘‹ğ¹ğ‘andğ‘‹ğ¹increases,
the cavitation zone grows as the pressure drops due to in-
creasing flow velocities.
â€¢ğ‘‹ğ¹>1: Here the bubbles do not implode in the valve but
rather continue to flow into the pipe because the down-
stream pressure ğ‘ğ‘‘is lower than the vapor pressure ğ‘ğ‘£. This
phenomenon is called flashing.
The cavitation coefficient ğ‘‹ğ¹ğ‘is only applied to the fluid, where it is
measured empirically. Its valve varies for different liquid mediums,
due to changes in viscosity, content of dissolved gas and so on.
TIFPIUpstream throttelingvalveTemperature measuring deviceFlow measuring devicePressureTap p1TestSpecimenPressureTap p2PIDownstream throttelingvalveTest sectionFlow
TankFigure A2: Schematic view of the test rack at SAMSON AG.
RootNode HierarchyIHealthDamageIRORIR-1IR-2IR-3OR-1OR-2HierarchyIIHierarchyIII
Figure A3: A hierarchical bearing tree from the PUB.
B Experiments
B.1 Evaluation Metrics
As discussed in the evaluation metrics, we use dynamic thresholds
to calculate the performance of fault intensity diagnosis for the pro-
posed HKG. Therefore, given a specific threshold, we can calculate
the TP (True Positives), FP (False Positives), TN (True Negatives),
and FN (False Negatives). Furthermore, we have:
Accuracy =TP+TN
TP+TN+FP+FNPrecision =TP
TP+FP
F1-score =2Ã—PrecisionÃ—Recall
Precision+RecallRecall =TP
TP+FN(A.2)
where under all possible thresholds, we can obtain a precision-recall
curve (with precision as the ğ‘¦-axis and recall as the ğ‘¥-axis) and
ğ´ğ‘ƒ=Ã
ğ‘›((ğ‘…ğ‘›âˆ’ğ‘ƒğ‘›âˆ’1)/ğ‘ƒğ‘›), whereğ‘ƒğ‘›andğ‘…ğ‘›are precision and
recall at the ğ‘›-th threshold.
B.2 Datasets
Cavitation Datasets. The cavitation datasets are provided by SAM-
SON AG in Frankfurt. The schematic of the experimental setup to
collect data is shown in Figure A2. And five flow statuses are in-
duced in acoustic signals by varying the differential pressure at
various constant upstream pressures of the control valve different
operation conditions: choked flow cavitation, constant cavitation,
incipient cavitation, turbulent flow and no flow (see Table A1 and
Table A2). For detailed dataset statistics shown in Table A3.
PUB Dataset. This dataset is used to validate the extensibility of
our approach. The bearing damage levels are listed in Table A4. The
bearing file codes and fault types utilized in our experiments are
shown in Table A5. The PUB is organized into three hierarchies:
bearing diagnosis (Hierarchy I), bearing damage type diagnosis
5667KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yu Sha et al.
Choked flow Constant Incipient Non
Predicted ClassChoked flow Constant Incipient NonTrue Class0.9929 0.0071 0.0000 0.0000
0.0389 0.9611 0.0000 0.0000
0.0000 0.5875 0.0875 0.3250
0.0000 0.0000 0.0000 1.0000
0.00.20.40.60.81.0
(a) Swin-B (Cavitation-Short)
Choked flow Constant Incipient Non
Predicted ClassChoked flow Constant Incipient NonTrue Class0.9329 0.0237 0.0265 0.0169
0.0271 0.9254 0.0241 0.0233
0.0201 0.0251 0.9347 0.0201
0.0226 0.0220 0.0250 0.9304
0.20.40.60.8 (b) Swin-B (Cavitation-Long)
Choked flow Constant Incipient Non
Predicted ClassChoked flow Constant Incipient NonTrue Class0.9950 0.0025 0.0025 0.0000
0.0000 0.9875 0.0025 0.0100
0.0025 0.0025 0.9875 0.0075
0.0025 0.0000 0.0000 0.9975
0.00.20.40.60.8 (c) Swin-B (Cavitation-Noise)
Health IR-1 IR-2 IR-3 OR-1 OR-2
Predicted ClassHealth IR-1 IR-2 IR-3 OR-1 OR-2True Class0.9896 0.0000 0.0000 0.0104 0.0000 0.0000
0.0179 0.9732 0.0089 0.0000 0.0000 0.0000
0.0208 0.0208 0.9583 0.0000 0.0000 0.0000
0.0000 0.0000 0.0000 1.0000 0.0000 0.0000
0.0000 0.0000 0.0000 0.0089 0.9732 0.0179
0.0000 0.0000 0.0000 0.0000 0.0127 0.9873
0.00.20.40.60.81.0 (d) TS-TCC (PUB)
Choked flow Constant Incipient Non
Predicted ClassChoked flow Constant Incipient NonTrue Class1.0000 0.0000 0.0000 0.0000
0.0222 0.9778 0.0000 0.0000
0.0000 0.5750 0.1375 0.2875
0.0000 0.0000 0.0000 1.0000
0.00.20.40.60.81.0
(e) HKG+Swin-B (Cavitation-Short)
Choked flow Constant Incipient Non
Predicted ClassChoked flow Constant Incipient NonTrue Class0.9329 0.0257 0.0193 0.0221
0.0230 0.9303 0.0235 0.0232
0.0211 0.0171 0.9418 0.0201
0.0235 0.0241 0.0214 0.9310
0.20.40.60.8 (f) HKG+Swin-B (Cavitation-Long)
Choked flow Constant Incipient Non
Predicted ClassChoked flow Constant Incipient NonTrue Class1.0000 0.0000 0.0000 0.0000
0.0000 1.0000 0.0000 0.0000
0.0000 0.0025 0.9950 0.0025
0.0025 0.0050 0.0025 0.9900
0.00.20.40.60.81.0 (g) HKG+Swin-B (Cavitation-Noise)
Health IR-1 IR-2 IR-3 OR-1 OR-2
Predicted ClassHealth IR-1 IR-2 IR-3 OR-1 OR-2True Class1.0000 0.0000 0.0000 0.0000 0.0000 0.0000
0.0089 0.9821 0.0000 0.0089 0.0000 0.0000
0.0000 0.0000 0.9792 0.0000 0.0000 0.0208
0.0000 0.0000 0.0000 1.0000 0.0000 0.0000
0.0089 0.0000 0.0000 0.0000 0.9911 0.0000
0.0127 0.0000 0.0000 0.0000 0.0000 0.9873
0.00.20.40.60.81.0 (h) HKG+ViT-S (PUB)
Figure A4: The confusion matrix of HKG with different backbone networks on different datasets. (a)-(c) and (e)-(g) denote the
confusion matrix on Cavitation-Short, Cavitation-Long and Cavitation-Noise, respectively. (d) and (h) on the PUB dataset.
Table A4: Bearing fault damage levels on the PUB.
Damage level Percentage values Bearing limitations
1 0-2% â‰¤2 mm
2 2-5% >2 mm
3 5-15% >4.5 mm
Table A5: Bearing fault types and file codes on the PUB.
Fault type HealthyOR damage IR damage
OR-1 OR-2 IR-1 IR-2 IR-3
File codeK001 KA01 KA03 KI01 KI07 KI16
K002 KA05 KA06 KI03 KI08 -
K003 KA04 KA08 KI04 KI18 -
K004 KA07 KA09 KI05 - -
K005 KA15 KA16 KI14 - -
K006 KA22 - KI17 - -
- KA30 - KI21 - -
Table A1: Cavitation datasets content details.
DatasetCavitation Non-cavitation
choked flow constant incipient turbulent no flow
Cavitation-Short 72 93 40 118 33
Cavitation-Long 148 396 64 183 15
Cavitation-Noise 40 40 40 40 0Table A2: Details of cavitation datasets valve operation.
DatasetOperation parameters
Valve stroke
(mm)Upstream pressure
(bar)Temperature
(â—¦C)
Cavitation-Short [15,13.5,11.25,7.5,3.75,1.5,0.75] [10,9,6,4] 25-50
Cavitation-Long [60,55,45,30,25,15,6] [10,6,4] 23-52
Cavitation-Noise 15 10 32-39
Table A3: Details of the training and test sets. (Â·)denotes the
number after the sliding window (window size is 466944).
DatasetTraining set Testing set
CavitationNonCavitationNon
Choked flowConstantIncipient Choked flowConstantIncipient
Cavitation-Short 58( Ã—10) 75(Ã—10) 32(Ã—10) 121(Ã—10) 14(Ã—10) 18(Ã—10) 8(Ã—10) 30(Ã—10)
Cavitation-Long 118( Ã—83) 317(Ã—83) 52(Ã—83) 158(Ã—83) 30(Ã—83) 79(Ã—83) 12(Ã—83) 40(Ã—83)
Cavitation-Noise 32( Ã—83) 32(Ã—83) 32(Ã—83) 32(Ã—83) 8(Ã—83) 8(Ã—83) 8(Ã—83) 8(Ã—83)
(Hierarchy II), and bearing IR/OR intensity diagnosis (Hierarchy
III-IR/III-OR), as shown in Figure A3.
B.3 Results
The confusion matrix of HKG with different backbone networks
on four real-world datasets, see Figure A4.
5668