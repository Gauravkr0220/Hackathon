VertiMRF: Differentially Private Vertical Federated Data Synthesis
Fangyuan Zhao
Xiâ€™an Jiaotong University
Xiâ€™an, China
zfy1454236335@stu.xjtu.edu.cnZitao Li
Alibaba Group
Bellevue, United States
zitao.l@alibaba-inc.comXuebin Ren
Xiâ€™an Jiaotong University
Xiâ€™an, China
xuebinren@mail.xjtu.edu.cn
Bolin Ding
Alibaba Group
Bellevue, United States
bolin.ding@alibaba-inc.comShusen Yangâˆ—
Xiâ€™an Jiaotong University
Xiâ€™an, China
shusenyang@mail.xjtu.edu.cnYaliang Liâˆ—
Alibaba Group
Bellevue, United States
yaliang.li@alibaba-inc.com
Abstract
Data synthesis is a promising solution to share data for various
downstream analytic tasks without exposing raw data. However,
without a theoretical privacy guarantee, a synthetic dataset would
still leak some sensitive information in raw data. As a countermea-
sure, differential privacy is widely adopted to safeguard data syn-
thesis by strictly limiting the released information. This technique
is advantageous yet presents significant challenges in the vertical
federated setting, where data attributes are distributed among dif-
ferent data parties. The main challenge lies in maintaining privacy
while efficiently and precisely reconstructing the correlation be-
tween attributes. In this paper, we propose a novel algorithm called
VertiMRF, designed explicitly for generating synthetic data in the
vertical setting and providing differential privacy protection for
all information shared from data parties. We introduce techniques
based on the Flajolet-Martin (FM) sketch for encoding local data
satisfying differential privacy and estimating cross-party marginals.
We provide theoretical privacy and utility proof for encoding in
this multi-attribute data. Collecting the locally generated private
Markov Random Field (MRF) and the sketches, a central server can
reconstruct a global MRF, maintaining the most useful information.
Two critical techniques introduced in our VertiMRF are dimension
reduction and consistency enforcement, preventing the noise of FM
sketch from overwhelming the information of attributes with large
domain sizes when building the global MRF. These two techniques
allow flexible and inconsistent binning strategies of local private
MRF and the data sketching module, which can preserve informa-
tion to the greatest extent. We conduct extensive experiments on
four real-world datasets to evaluate the effectiveness of VertiMRF.
End-to-end comparisons demonstrate the superiority of VertiMRF.
âˆ—Both are corresponding authors of this research. Work was done while the first author
was an intern at Alibaba Group.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671771CCS Concepts
â€¢Security and privacy â†’Privacy-preserving protocols.
Keywords
Vertical Federated Learning, Differential Privacy, Data Synthesis
ACM Reference Format:
Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang
Li. 2024. VertiMRF: Differentially Private Vertical Federated Data Synthesis.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671771
1 Introduction
With the increasing stringency of data privacy regulations such as
the European General Data Protection Regulation (GDPR) [ 52] and
the California Consumer Privacy Act [ 40], data privacy has become
a significant concern for various data analysis tasks. Following this
trend, data synthesis has emerged as a promising technique. For the
tabular data domain, the synthesis algorithms aim to generate and
release synthetic data that preserves the statistical characteristics
of the original data, allowing for diverse data analysis tasks to be
conducted without access to the original real data from individuals.
Coupled with differential privacy (DP) [ 10,43,61,63] techniques,
the synthetic data can provide theoretical privacy guarantees for
arbitrary individual records in the original datasets. Compared with
other DP algorithms for specific analytic tasks, DP data synthesis
can support an unlimited number of unrestricted downstream tasks
without additional privacy loss other than the one occurring during
data synthesis [ 17]. The main challenge emerges when ensuring
DP while generating synthetic data of high quality. A growing
body of academic research [ 2,4,5,11,19,34,35,42,54,60â€“62] has
focused on improving the trade-off between privacy and utility of
DP synthetic data and already obtained promising results. However,
these studies primarily focus on the centralized setting, assuming
that the raw data has already been collected by a trusted curator.
To realize the value of data at the furthest level, multiple data par-
ties may want to cooperate on some tasks for more comprehensive
and accurate information. If such cooperation is achieved with-
out sharing data directly, the setting is generally called federated
learning (FL) [ 20,28,59]. A relatively well-studied scenario in FL is
that data parties have data with the same set of attributes but from
different groups of individuals. This scenario is called horizontal
federated learning (HFL) because the local dataset can be obtained
4431
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
by splitting a virtual global dataset by individuals [ 36]. Under such
a setting, several studies have focused on DP data synthesis un-
der the horizontally distributed [ 48] and local DP settings [ 44].
Nevertheless, another attractive but challenging case is when data
parties have data from the same set of individuals but on different
attributes [ 16,29,30,32]. Symmetrically, this setting is called ver-
tical federated learning (VFL) as local datasets can be derived by
dividing a global dataset by attributes. VFL techniques attract the
attention of many medical or fintech companies [ 55] because their
model accuracy can be boosted by more comprehensive informa-
tion brought by VFL. In this paper, we focus on data synthesis in
the VFL setting as it has great potential in various aspects.
1) It facilitates the cross-party data analysis. Simply combining the
synthetic data generated independently by the multiple parties
loses the statistical property of cross-party attributes. However,
when a VFL data synthesis algorithm that accurately captures the
cross-party correlation is available, any downstream correlation
analysis can be done efficiently once the synthetic data is ready. 2) It
enable validating or tuning general VFL algorithms under controllable
privacy risk. For example, VFL tasks often involve substantial costs
for hyperparameter tuning among multi-parties, due to the strict
limitations of cross-party data access. Releasing a synthetic dataset
that preserves the statistical characteristics of the original data can
help select optimal hyper-parameters before model training.
Despite the great potential, there are following challenges that
hinder the practical applications.
C1: Information loss when estimating cross-party attribute correla-
tions. Unlike algorithms in the central setting that can access all data
attributes, VFL synthesis algorithms that can faithfully generate
data in global-view must have components to estimate the corre-
lation of the cross-party attributes, either explicitly or implicitly.
However, such estimation must suffer information loss because of
either the distillation of raw data or added randomness for privacy.
C2: Composing and trade-off the intra-party and cross-party informa-
tion. It is known that statistics estimated in the central DP setting
can have higher accuracy than the same ones obtained in the dis-
tributed DP settings. Although the intuitive idea following this is
to utilize as much information as possible that does not rely on
cross-party cooperation, how to effectively and efficiently combine
and balance this information with estimated cross-party correlation
information remains to be explored.
C3: Curse of dimensionality. In VFL settings, a record may contain
multiple attributes that distributed among multiple parties, each
attribute with large domain size. In this case, there are multiple
cross-party attribute combinations to estimate, which would intro-
duce overwhelming noises and huge communication costs.
Although there are a few works on DP data synthesis under the
vertical setting, they still have limitations related to the challenges
above. DistDiffGen [ 38] is a two-party DP data synthesis framework.
It falls short of handling C1 and C3 because it relies on a given
taxonomy tree requiring strong prior knowledge and is tailored
to classification tasks only. VertiGAN [ 18] adapts the DP-WGAN
approach to vertical setting [ 18]. However, the GAN-based models
are proven to be not suitable for synthesizing tabular data with DP,
which indicates that C1 and C2 still hinder its practical application.
DPLT [ 50] utilizes a latent tree model to capture the correlation
among cross-party attributions. However, its application is limitedby C3 because it is designed for datasets with binary attributes
and suffers from the huge communication and computation costs
incurred by the complicated cryptography protocol.
To handle the challenges, we propose VertiMRF for generating
high-quality synthetic data with differential privacy guarantees in
the VFL setting with multiple data parties and a semi-honest central
server. Our key observation is that the central DP data synthesis
can achieve great performance in terms of privacy-utility trade-off,
and the cross-party statistic estimation is necessary but may un-
avoidably be less accurate. Thus, VertiMRF adapts, combines, and
balances these two components. VertiMRF adapts PrivMRF [ 4] to
capture and share differentially private intra-party attribute statis-
tic information. We then design special protocols to let the data
parties encode and the server decode the cross-party attribute corre-
lation information. With both intra-party and cross-party attribute
correlation information, the server can reconstruct a global MRF
for full-view data synthesis. Our key contributions assembled in
VertiMRF are summarized as follows:
â€¢We propose a communication efficient and differentially private
vertical data synthesis framework VertiMRF. VertiMRF merges
a sequence of strategies that allow an untrusted server to con-
struct a global Markov Random Field by merging and balancing
differential private encoded information.
â€¢We incorporate a novel Flajolet-Martin (FM) sketch based ap-
proach to estimating cross-party multi-attribute marginals. This
approach is a key component of VertiMRF to estimate cross-party
correlations with relatively low error while protecting privacy.
Theoretical privacy guarantee and error analysis are provided.
â€¢We design two critical techniques into VertiMRF to prevent the
noise of FM-sketch from obscuring the useful information of
attributes with large domain sizes when building the global MRF,
including a dimension reduction technique to tune the granulari-
ties of attributes while preserving the statistical information and
a consistency enforcement technique to maintain the consistency
among frequencies of different granularities.
â€¢We conduct empirical validation on four real-world datasets. The
end-to-end comparison results demonstrate the superiority of our
approach to the baseline algorithms. Furthermore, the impact and
effectiveness of each component of our approach are validated
by ablation studies.
2 Preliminaries
2.1 Differential Privacy
Differential privacy is a rigorous privacy notion that quantifies the
privacy loss of algorithms by analyzing the statistical difference
between the algorithm outputs on neighboring datasets differing
on only one record.
Definition 1 (Differential Privacy [ 10]).A randomized mechanism
Msatisfies(ğœ–,ğ›¿)-DP if for any neighboring datasets ğ·,ğ·â€²that
differ on only one record, their outputs fall in any ğ‘…âŠ‚ğ‘…ğ‘ğ‘›ğ‘”ğ‘’(M)
with probability ğ‘ƒğ‘Ÿ[M(ğ·)âŠ†ğ‘…]â‰¤exp(ğœ–)ğ‘ƒğ‘Ÿ[M(ğ·â€²)âŠ†ğ‘…]+ğ›¿.
2.2 DP Flajolet-Martin Sketch
Flajolet-Martin (FM) Sketch is a probabilistic data structure for
multi-set cardinality estimation with DP guarantee. It is constructed
4432VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
by hashing each element in a multi-set to an integer by a hash
functionHwith a keyğœ‰. The hashed integers are then independent
geometric random variables with the parameterğ›¾
1+ğ›¾ifğœ‰is sampled
from a large set uniformly. Note that, the duplicated elements in
the multi-set are mapped to the same integer. The cardinality ğ‘˜can
be estimated as ğ‘˜=(1+ğ›¾)ğ›¼whereğ›¼denotes the maximum of the
observed integer after hashing.
The FM sketch-based cardinality estimation is widely used due to
its appealing property that the sketch structure is mergeable. That
is, given two different multi-set X1andX2and their corresponding
FM sketches ğ›¼1andğ›¼2, then the cardinality of their union X1âˆª
X2can be simply estimated as (1+ğ›¾)max(ğ›¼1,ğ›¼2). Based on this
and the inclusion-exclusion principle, i.e., X1âˆ©X 2=X2âˆªX2,
the cardinality of the intersection of two multi-sets can also be
estimated. Recent studies [ 8,47] have demonstrated that FM-sketch
can preserve DP under certain conditions. Specifically, if inserting
ğ‘˜ğ‘=1
ğ‘’ğœ–âˆ’1phantom elements into the multi-set and ensuring the
maximum of the geometric random variables is lower bounded by
âŒˆlog1+ğ›¾1
1âˆ’ğ‘’âˆ’ğœ–âŒ‰, then the process of selecting the maximum of these
random variables ensures ğœ–-DP. The DP FM-sketching algorithm is
detailed in Algorithm 2 in Appendix A.
2.3 DP Data Synthesis
Letğ·be a set of data tuples {ğ‘¥(1),...,ğ‘¥(ğ‘›)}. Each tuple consists
of values of a set of attributes A={ğ´1,...,ğ´ğ‘‘}. Each attribute
ğ´ğ‘—,âˆ€ğ‘—âˆˆ[ğ‘‘]has domain size ğ‘¢ğ‘—. Without loss of generality, we
denote the domain of ğ´ğ‘—as[ğ‘¢ğ‘—]â‰œ{1,...,ğ‘¢ğ‘—}. Withğ‘€âŠ‚A,ğ‘¥(ğ‘™)
ğ‘€
denotes the values of tuple ğ‘¥(ğ‘™)on an attribute set ğ‘€. Letğ‘‡ğ‘€be the
counts of occurrences of all possible value tuples of attributes ğ‘€in
ğ·. That is,ğ‘‡ğ‘€is a vector of lengthÃ
ğ´ğ‘—âˆˆğ‘€ğ‘¢ğ‘—and each element is
defined as
ğ‘‡ğ‘€[v]=âˆ‘ï¸
ğ‘™âˆˆ[ğ‘›]I(ğ‘¥(ğ‘™)
ğ‘€=v),âˆ€vâˆˆÃ–
ğ´ğ‘—âˆˆğ‘€[ğ‘¢ğ‘—] (1)
ğ‘‡ğ‘€is referred as the contingency histogram ofğ‘€.
Data synthesis focuses on generating a dataset Ë†ğ·givenğ·such
that ideallyâˆ€ğ‘€âŠ†A,Ë†ğ‘‡ğ‘€â‰ˆğ‘‡ğ‘€. A key challenge of DP data syn-
thesis is to circumvent the curse of dimensionality incurred by a
largeğ‘‘. Asğ‘‘increases, the error of ğ‘‡Agrows exponentially, as DP
noise has to be added to each count of the contingency histogram.
To address this challenge, there have been works [ 4,34,35,60,62]
that propose to utilize low-way marginal distributions to approxi-
mate the high-way distribution without losing much correlations
among the attributes. Among these, PrivMRF [ 4], utilizing Markov
Random Field (MRF) to model the attribute correlations, shows the
state-of-the-art performance. PrivMRF consists of four phases:
â€¢Phases 1: Generate attribute graph. PrivMRF starts by gen-
erating an attribute graph Gthrough greedily linking up each
attribute pair(ğ´ğ‘–,ğ´ğ‘—)in the descending order of noisy R-scores:
ğ‘…(ğ´ğ‘–,ğ´ğ‘—)=ğ‘›
2ğ‘ƒğ‘Ÿ[ğ´ğ‘–,ğ´ğ‘—]âˆ’ğ‘ƒğ‘Ÿ[ğ´ğ‘–]Â·ğ‘ƒğ‘Ÿ[ğ´ğ‘—]1+N( 0,ğœ2
ğ‘…).(2)
â€¢Phases 2: Choose candidate marginal set. PrivMRF samples a
set of candidate marginals Ufrom the cliques of triangulated G
and ensure each marginal ğ‘€âˆˆU satisfies thatğ‘›Ã
ğ´ğ‘–âˆˆğ‘€ğ‘¢ğ‘–â‰¤ğœƒÂ·ğ‘”,whereğ‘”denotes the expected absolute value of the noise to be
injected into each count of ğ‘‡ğ‘€.
â€¢Phases 3: Initialize the marginal set. FromU, PrivMRF selects
the most highly correlated marginal for each attribute to consti-
tute an initialized marginal set S, which is used to estimate the
parameters Î˜of the MRF. Î˜is a real vector where each element
corresponds to an entry in a contingency histogram ğ‘‡ğ‘€,âˆ€ğ‘€âˆˆS.
The MRF models the distribution of arbitrary tuple ğ‘¥as:
ğ‘ƒğ‘Ÿ[ğ‘¥]âˆÃ–
ğ‘€âˆˆSexp(Î˜ğ‘€[ğ‘¥ğ‘€]) (3)
where Î˜ğ‘€denotes the sub-vector of Î˜corresponding to ğ‘€, and
Î˜ğ‘€[ğ‘¥ğ‘€]is the element corresponding to ğ‘¥ğ‘€.
â€¢Phases 4: Refine the marginal set. PrivMRF proceeds to refine
the marginal setSby inserting marginals that cannot be accu-
rately inferred by the MRF and iteratively refine the estimation
of MRF.
3 Differentially Private Vertical Data Synthesis
We provide the problem definition of DP data synthesis in the
vertical setting and an overview of our solution in this section.
3.1 Problem Definition
We consider a system constituted by ğ‘šdata parties and an untrusted
central server orchestrating the overall process. Each data party
Pğ‘–,âˆ€ğ‘–âˆˆ[ğ‘š], possesses usersâ€™ data ğ·ğ‘–={ğ‘¥(1)
Ağ‘–,...,ğ‘¥(ğ‘›)
Ağ‘–}with a
subset of attributes Ağ‘–âŠ‚A . We assume that the userâ€™s data has
been aligned across these ğ‘šdata parties by some record ID (e.g.,
social security number and phone number) with some private set
intersection method [ 6,9,22]. That is,ğ‘¥(ğ‘™)
Ağ‘–andğ‘¥(ğ‘™)
Ağ‘—are data tuples
of a same individual ğ‘™but on different attributes. The aligned data
is a common setting with the vertical tasks [ 7,15,31,58]. Virtually
speaking, there is a global dataset ğ·=(ğ·1|...|ğ·ğ‘š)with attributes
A=âˆªğ‘–âˆˆ[ğ‘š]Ağ‘–if all data partiesâ€™ data can be merged.
Adversary model. We consider the central server to be honest but
curious, which would execute the protocol honestly but try his best
to infer the private information of the input dataset. However, we
assume that none of data parties is interested in colluding with
the server because privacy regulations prevent data parties from
doing so. We consider the adversary outside the system as all the
third-party data analysts who aim to infer some private information
from the synthetic dataset and the intermediate results carried out
in the communication between data parties and the server.
Our goal. Our work aims to generate a collection of synthetic data Ë†ğ·
with attributesA, which follows the data distribution as the virtual
global dataset ğ·as closely as possible while protecting the privacy.
3.2 Overview of Our Solution
With the known private data synthesis algorithms, such as PrivMRF,
each client can publish their local private data; then a full-view
synthetic data can be derived by composing the data of different at-
tributes together. Despite this straightforward idea, the cross-party
attribute correlations are completely lost. Thus, we need to solve
the following three problems when improving the synthetic data
utility while preserving data privacy: 1) How to estimate cross-
party attribute correlations with comparable utility and provable
4433KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
Optimize ğš¯ OptMRF
Parameterized as ğš¯ Centralserver
Local party 2Local party 1
Estimate ğš¯ Phase 5InitMRFGraphComLocMRFLocEncPhase 6Phase 4Phase 3Phase 2Phase 1
Infer with ğš¯ Synthesis
LocMRFLocEncPhase 1Phase 2
IDğ‘¨ğŸâ€¦ğ‘¨ğŸ’1â€¦IDğ‘¨ğŸ“â€¦ğ‘¨ğŸ–1â€¦Attrğ‘´ğŸğ‘¨ğŸğ‘€$â€¦â€¦ğ‘¨ğŸ’ğ‘€&Attrğ‘´ğŸğ‘¨ğŸ“ğ‘€(â€¦â€¦ğ‘¨ğŸ–ğ‘€)
Figure 1: Workflow of VertiMRF
mem.ğ´!ğˆ"!"ğˆ"#"ğˆ"$"mem.ğ´#ğˆ"!%ğˆ"#%DPFMğ‘´ğ’Šğœ¶"!"ğœ¶"#"ğœ¶"$"ğ‘´ğ’‹ğœ¶ğ‘£1ğ‘—ğœ¶ğ‘£2ğ‘—ğ‘›	âˆ’	|ğˆ"!"âˆ©ğˆ"!%||ğˆ"#"âˆªğˆ"$"âˆªğˆ"#%|maxğ‘‡'[ğ‘£(!,ğ‘£(#]	=estimate=inclusion-exclusionDPFMDPFMDPFMDPFMLocEncCarEstCentralserver Figure 2: LocEnc and CarEst.
privacy guarantee? 2) How to merge and tradeoff the intra-party
and cross-party attribute correlations estimated with different es-
timation errors while preserving as more useful information as
possible? 3) How to tackle the curse of dimensionality, i.e., the
overwhelming noises, when domain sizes of attributes are large?
By solving the three problems, we propose VertiMRF , a novel
DP data synthesis approach. As shown in Figure 1 and Algorithm 1,
VertiMRF can be divided into the following six phases:
â€¢Phase 1: Each partyPğ‘–constructs a local Markov Random Field
MRFğ‘–to capture the correlation among local attributes Ağ‘–. Besides,
Pğ‘–preserves the inner results, including the local attribute graph
Gğ‘–and the marginal set Sğ‘–(sub-procedure LocMRF).
â€¢Phase 2: Each partyPğ‘–encodes local dataset with attributes
Ağ‘–via differentially private FM sketch. Both the codes Mğ‘–and
{MRFğ‘–,Gğ‘–,Sğ‘–}are sent to the server (sub-procedure LocEnc).
â€¢Phase 3: The server generates a global attribute graph Gby
combining received disjoint local attribute graphs {Gğ‘–|ğ‘–âˆˆ[ğ‘š]}.
In the combining, server links up cross-party attribute pairs with
higher R-scores estimated over the encoded attributes {ğ‘€ğ‘–,ğ‘–âˆˆ
[ğ‘š]}. (sub-procedure GraphCom).
â€¢Phase 4: The server initializes a marginal set Sby taking the
union of the received local marginal set {Sğ‘–|ğ‘–âˆˆ[ğ‘š]}. Based on
S, the parameter Î˜of the global MRF is initialized with each
contingency histogram ğ‘‡ğ‘€,âˆ€ğ‘€âˆˆSinferred from the received
local MRFs (sub-procedure InitMRF).
â€¢Phase 5: The server selects a set of cross-party marginals Sğ‘
from the cliques of G. Based on theSğ‘,Î˜is further optimized.
In the optimization, each contingency histogram ğ‘‡ğ‘€,âˆ€ğ‘€âˆˆSğ‘is
estimated over the encoded attributes (sub-procedure OptMRF).
â€¢Phase 6: The server generates synthetic data by sampling from
the data distribution approximated by the global MRF.
In what follows, we show the solution for Phase 1-2 in Section 4
which describes the DP information sharing approaches of each
local party. Then we describe Phase 3-6 in Section 5, presenting
how to use the shared DP information to construct a global MRF.
4 Differentially Private Information Sharing
Based on our security setting and DPâ€™s resistance to post-processing,
the key to satisfying privacy protection is to ensure differential
privacy guarantee for all the information shared from local parties,
which are the outputs of LocMRF inPhase 1 andLocEnc Phase 2
(in brackets Figure 1). Thus, we introduce the algorithms for LocMRFAlgorithm 1 VertiMRF
Input: The partitioned dataset ğ·={ğ·ğ‘–,ğ‘–âˆˆ[ğ‘š]}, domain([ğ‘¢1]Ã—
...Ã—[ğ‘¢ğ‘‘]), maximal clique size ğœ, total privacy budget (ğœ–,ğ›¿)is
divided asğœ–0=ğœ–
2ğ‘š,ğ›¿0=ğ›¿
2ğ‘š,ğœ–1=ğœ–
2,ğ›¿1=ğ›¿
2.
Output: Synthesized data Ë†ğ·.
1:Each local partyPğ‘–:
(a). constructs local MRF:{MRFğ‘–,Gğ‘–,Sğ‘–}â† LocMRF(ğ·ğ‘–,ğœ,ğœ– 0,ğ›¿0).
2:Each local partyPğ‘–:
(a). encodes local attributes: Mğ‘–â†LocEnc(ğ·ğ‘–,Ağ‘–,ğœ–1,ğ›¿1).
(b). sendsMğ‘–and{MRFğ‘–,Gğ‘–,Sğ‘–}to server.
3:Central server:
(a). generates global graph: Gâ†GraphCom({Gğ‘–,Mğ‘–|ğ‘–âˆˆ[ğ‘š]}).
4:Central server:
(a). initializes marginal set: Sâ†Ãğ‘š
ğ‘–=1{Sğ‘–}.
(b). initializes parameter Î˜of the global MRF based on S.
5:Central server:
(a). selects cross-party marginals Sğ‘from triangulatedG.
(b). optimizes Î˜based onSğ‘.
6:Central server:
(a). samples Ë†ğ·based on the optimized global MRF.
andLocEnc (together with its closely paired CarEst ), providing
bases of the following synthesis steps.
4.1 Local PrivMRF in Phase 1
Each local partyPğ‘–directly applies the PrivMRF approach to con-
struct MRFğ‘–. As shown in Section 2.3, there would be inner results
generated when constructing MRFğ‘–, including the attribute graph
Gğ‘–and the refined marginal set Sğ‘–. Apart from MRFğ‘–, bothGğ‘–and
Sğ‘–should also be preserved and sent to the central server. Notably,
because the maximal clique size for the global MRF is always lim-
ited to control the complexity of the attribute graph, the maximal
clique size of each local MRF should also be limited. The maximal
local clique size for each MRFğ‘–is set asğœâ€²â‰¤ğœ
ğ‘šÂ·Â¯ğ‘¢2, with Â¯ğ‘¢=Ã
ğ‘—ğ‘¢ğ‘—
ğ‘‘
andğœis threshold of the clique size for global MRF. The constructed
MRFğ‘–captures the correlations among the local attributes.
4.2 Sketch-based LocEnc and CarEst
As explained in Section 2.2, FM sketch can be used to estimate the
cardinality of a multi-set. And the estimation process can easily
satisfy DP by incorporating phantom elements and bounding the
maximum value of the hashed geometric variables. Building on
4434VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
this idea, we design our sketch-based LocEnc andCarEst . Figure 2
visualizes the rationale of both sketch-based LocEnc andCarEst.
Sketch-based LocEnc .Each data partyPğ‘–encodes the membership
information of local attribute ğ´ğ‘—using an FM sketch. This infor-
mation, denoted as
Iğ‘£ğ‘—
1,...,Iğ‘£ğ‘—
ğ‘¢ğ‘—
, consists of ğ‘¢ğ‘—ID sets. Each set
Iğ‘£ğ‘—
ğ‘–contains the IDs of records ğ‘¥withğ‘¥(ğ´ğ‘—)=ğ‘£ğ‘—
ğ‘–. The sketch-based
LocEnc involves two main procedures: the generation of hash keys
and the generation of sketches.
Due to privacy concern, hash keys should be collaboratively
generated by data parties and kept unknown to the central server.
There are multiple secure multi-party computation (SMC) proto-
cols can be applied to achieve this, such as the Diffie-Hellman
protocol [ 23], which allows multiple parties to negotiate a random
number securely even if the central server is semi-honest [23].
Next, each party encodes the membership information of lo-
cal attributes using DPFM (Algorithm 2) algorithm with the gen-
erated hash key ğœ‰. Specifically, for the membership information
{Iğ‘£ğ‘—
1,...,Iğ‘£ğ‘—
ğ‘¢ğ‘—}of attributeğ´ğ‘—âˆˆAğ‘–, partyPğ‘–applies the DPFM algo-
rithm to each Iğ‘£ğ‘—
ğ‘–with a given privacy budget ğœ–â€². This generates a DP
FM sketch tuple(ğ›¼ğ‘£ğ‘—
1,...,ğ›¼ğ‘£ğ‘—
ğ‘¢ğ‘—)forğ´ğ‘—âˆˆAğ‘–. Considering all local
attributes, partyPğ‘–composes a tuple set {(ğ›¼ğ‘£ğ‘—
1,...,ğ›¼ğ‘£ğ‘—
ğ‘¢ğ‘—)|ğ´ğ‘—âˆˆAğ‘–}.
To enhance utility, this process is repeated ğ‘¡times, and partyPğ‘–
sendsğ‘¡tuple sets(
M(â„)
ğ‘–â‰œ( 
ğ›¼(â„)
ğ‘£ğ‘—
1,...,ğ›¼(â„)
ğ‘£ğ‘—
ğ‘¢ğ‘—!ğ´ğ‘—âˆˆAğ‘–)â„âˆˆ[ğ‘¡])
to the server.
Sketch-based CarEst .As mentioned in Section 2.2, the FM sketch
enables us to estimate the cardinality of the intersection of multi-
ple sets using the inclusion-exclusion principle. This property can
be extended to the DP FM sketch, allowing the central server to
estimate the contingency histogram of a marginal.
After receiving all sketches from data parties, the central server
aggregates them into ğ‘¡sets of sketch tuples
(
M(â„)â‰œ( 
ğ›¼(â„)
ğ‘£ğ‘—
1,...,ğ›¼(â„)
ğ‘£ğ‘—
ğ‘¢ğ‘—!
|ğ‘—âˆˆ[ğ‘‘])
|â„âˆˆ[ğ‘¡])
.
For eachğ‘™-way marginal ğ‘€=(ğ´1,...,ğ´ğ‘™), the estimation of the
contingency histogram ğ‘‡ğ‘€involves estimating the cardinality of
the intersection setÃ‘ğ‘™
ğ‘–=1Iğ‘£(ğ‘–)for each(ğ‘£(1),...,ğ‘£(ğ‘™))âˆˆÃğ‘™
ğ‘–=1[ğ‘¢ğ‘–].
Here, Iğ‘£(ğ‘–)represents the membership information of attribute
ğ´ğ‘–with value ğ‘£(ğ‘–). Using the inclusion-exclusion principle (i.e.,
Ã‘ğ‘™
ğ‘–=1Iğ‘£(ğ‘–)=Ãğ‘™
ğ‘–=1Iğ‘£(ğ‘–)), the cardinality ofÃ‘ğ‘™
ğ‘–=1Iğ‘£(ğ‘–)can be deter-
mined by calculating the cardinality ofÃğ‘™
ğ‘–=1Iğ‘£(ğ‘–), whereXdenotes
the complementary set of X. Thus, estimating the cardinality of
an intersection is transformed into estimating the cardinality of
the complementary set of a union. The basic approach to estimateÃğ‘™
ğ‘–=1Iğ‘£(ğ‘–)is as follows: first, estimateÃğ‘™
ğ‘–=1Iğ‘£(ğ‘–)using the merge-
able property of sketches, and then subtract this estimate from a
DP sanitized data number Ë†ğ‘›.
For eachM(â„)among allğ‘¡sketch sets, the sketch of Iğ‘£(ğ‘–)can be
estimated by max
ğ›¼(â„)
ğ‘£ğ‘–
ğ‘—|ğ‘—âˆˆ[ğ‘¢ğ‘–],ğ‘£ğ‘–
ğ‘™â‰ ğ‘£(ğ‘–)
. Here,ğ›¼(â„)
ğ‘£ğ‘–
ğ‘—representsthe sketch corresponding to attribute ğ´ğ‘–with valueğ‘£ğ‘–
ğ‘—. Furthermore,
the sketch ofÃğ‘—
ğ‘–=1Iğ‘£(ğ‘–)can be estimated by
max
max
ğ›¼(â„)
ğ‘£ğ‘–
ğ‘—|ğ‘—âˆˆ[ğ‘¢ğ‘–],ğ‘£ğ‘–
ğ‘—â‰ ğ‘£(ğ‘–)
|ğ´ğ‘–âˆˆğ‘€
.
After obtaining ğ‘¡estimates of the sketch ofÃğ‘—
ğ‘–=1Iğ‘£(ğ‘–), a more stable
and accurate estimate ğ›¼can be obtained by taking the harmonic
mean. Furthermore, since the above sketch estimation process in-
volves max operations onÃğ‘™
ğ‘–=1(ğ‘¢ğ‘–âˆ’1)sketches, each of which
introducesğ‘˜ğ‘phantom elements as shown in Section 2.2, there
should beÃğ‘™
ğ‘–=1(ğ‘¢ğ‘–âˆ’1)
Â·ğ‘˜ğ‘phantom elements taken into ac-
count in total. By subtracting those phantom elements,Ãğ‘™
ğ‘–=1Iğ‘£(ğ‘–)
can be estimated by (1+ğ›¾)ğ›¼âˆ’Ãğ‘™
ğ‘–=1(ğ‘¢ğ‘–âˆ’1)
Â·ğ‘˜ğ‘. Finally, the car-
dinality ofÃ‘ğ‘™
ğ‘–=1Iğ‘£(ğ‘–)can be obtained by subtracting the estimatedÃğ‘™
ğ‘–=1Iğ‘£(ğ‘–)from a DP sanitized data number Ë†ğ‘›and ensuring the
non-negativity.
Theorem 2 (Privacy Analysis). Suppose the FM sketch ğ›¼(â„)
ğ‘£ğ‘–
ğ‘—
for valueğ‘£ğ‘–
ğ‘—of attributeğ´ğ‘–is generated with ğœ–â€²-DP in theâ„-th run.
Then, the sketch-based LocEnc method in Algorithm ??guarantees
(4ğœ–â€²âˆšï¸
ğ‘¡ğ‘‘log(1/ğ›¿),ğ›¿)-DP for allğ›¿<1.
Theorem 3 (Error Analysis). Letğ‘€={ğ´1,...,ğ´ğ‘™}be anğ‘™-
way marginal, Ë†ğ‘‡ğ‘€be the contingency histogram of ğ‘€estimated using
sketch-based CarEst with privacy parameter (ğœ–,ğ›¿)and distribution
parameterğ›¾. For each vâˆˆÃğ‘™
ğ‘–=1[ğ‘¢ğ‘–], the following inequality holds:
|Ë†ğ‘‡ğ‘€[v]âˆ’ğ‘‡ğ‘€[v]|
ğ‘‡ğ‘€[v]â‰¤ğ›¾Â·(ğ‘›
ğ‘‡ğ‘€[v]âˆ’1)+Ë†ğ‘+ğ¶
ğ‘‡ğ‘€[v], (4)
with a probability of at least 1âˆ’ğ›½. Here, Ë†ğ‘represents the Laplacian
noise added to the data number ğ‘›, andğ¶=ğ‘‚(log1/2(1/ğ›¿)log1/4(1/ğ›½)
ğœ–â€²).
Due to space limitation, proofs are shown in Appendix C. As
stated in Theorem 3, the relative error tends to be larger when the
proportion of ğ‘‡ğ‘€[v]inğ‘›decreases or when ğ‘‡ğ‘€[v]decreases.
4.3 Privacy and Communication Cost
Overall Privacy Analysis. As shown in Algorithm 1, LocMRF on
allğ‘šparties consumes(ğ‘šÂ·ğœ–
2ğ‘š,ğ‘šÂ·ğ›¿
2ğ‘š)-DP. As stated in Theorem 2,
the remaining(ğœ–
2,ğ›¿
2)-DP is allocated for encoding the ğ‘‘attributes
forğ‘¡iterations in LocEnc . According to the sequential composition
property of DP, we can conclude that VertiMRF satisfies(ğœ–,ğ›¿)-DP.
Communication Cost. There is one communication round be-
tween each partyPğ‘–and the central server in VertiMRF. The com-
munication includes encoded attributes Mğ‘–and the local MRF
information{MRFğ‘–,Sğ‘–,Gğ‘–}. For sketch-based LocEnc ,Mğ‘–contains
ğ‘¡Ã
ğ´ğ‘—âˆˆAğ‘–ğ‘¢ğ‘—sketches. MRFğ‘–is parameterized by a vector Î˜with
lengthÃ
ğ‘€âˆˆğ‘†ğ‘–Ã
ğ´ğ‘—âˆˆğ‘€ğ‘¢ğ‘—, controlled by the maximal clique size ğœâ€²
for each local MRF. Gğ‘–is represented by a(|Ağ‘–|Ã—|Ağ‘–|)-dimensional
adjacent matrix, with |Ağ‘–|<ğ‘‘. The information in Sğ‘–, which con-
tains several attribute tuples, can be ignored in terms of communi-
cation costs. Considering a total of ğ‘šparties, the communication
cost of VertiMRF isğ‘‚(ğ‘¡ğ‘‘Â¯ğ‘¢)+ğ‘‚(ğ‘‘2)+ğ‘‚(ğ‘šğœâ€²). Here Â¯ğ‘¢=Ã
ğ‘—ğ‘¢ğ‘—
ğ‘‘.
4435KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
5 MRF Generation in Central Server
After receiving local MRFs and encoded attributes Mfrom all parties,
the process of the central server can be divided into the following
phases: generating the global attribute graph (Phase 3), initializing
the marginal set thereby estimating the MRF parameter (Phase 4),
refining the marginal set thereby optimizing the MRF parameter
(Phase 5) and finally sampling the synthetic data (Phase 6).
5.1 GraphCom in Phase 3
Since the local attribute graphs are disjoint and each one accurately
represents the correlation among a subset of attributes, a basic
approach to creating a global attribute graph is to combine the
disjoint graphs by linking up certain cross-party attribute pairs.
However, there are two constraints (CSTR) that must be satisfied
when selecting such cross-party attribute pairs, denoted as (ğ´ğ‘–,ğ´ğ‘—):
â€¢CSTR1:(ğ´ğ‘–,ğ´ğ‘—)should exhibit strong correlation.
â€¢CSTR2: The domain size of maximal cliques in the resulting at-
tribute graph should not exceed a predefined threshold value ğœ.
To satisfy CSTR1, the central server estimates the R-score [ 4]
ğ‘…(ğ´ğ‘–,ğ´ğ‘—)for each cross-party attribute pair (ğ´ğ‘–,ğ´ğ‘—)with CarEst
approach introduced in Section 4 over the received encoded at-
tributesM:ğ‘…(ğ´ğ‘–,ğ´ğ‘—) â‰ˆË†ğ‘›
2Ë†ğ‘‡(ğ´ğ‘–,ğ´ğ‘—)
Ë†ğ‘›âˆ’Ë†ğ‘‡ğ´ğ‘–
Ë†ğ‘›Â·Ë†ğ‘‡ğ´ğ‘–
Ë†ğ‘›1,where Ë†ğ‘‡de-
notes the estimated contingency histogram. As explained in Sec-
tion 2.3, attribute pairs with higher R-scores indicate stronger cor-
relation. After the estimation, the server sorts all attribute pairs in
descending order based on their estimated R-scores and greedily
connects them in the global attribute graph.
For CSTR2, whenever a link between cross-party attributes is
added toG, the server checks the domain size of the maximal clique
in the triangulated Gto ensure it does not exceed ğœ.ğœis always
set empirically to strike the tradeoff between the model utility and
computation complexity. A larger ğœenables more flexible marginal
selection but incur high computational efficiency. According to
our observation,[105,5Ã—106]is an suitable range for ğœ. If CSTR2
is satisfied, the process of adding links continues. This process
continues until it is no longer possible to satisfy CSTR2.
5.2 InitMRF in Phase 4
After generating the global attribute graph, the next step is to con-
struct the global MRF, which essentially is to learn a parameter
vector Î˜on a marginal setSby reducing the inferring error of Î˜
onS. However, unlike the centralized setting, the central server in
the vertical setting lacks access to the raw data, it is not practical to
compute sufficiently accurate correlations over the received noisy
information to select the representative marginals to constitute S.
More severely, the true value of the contingency histograms are
unavailable to compute the inferring error of Î˜. Therefore, it is
essential to select marginals that can be accurately estimated based
on the DP shared information of local parties. With the observation
that local MRFs can estimate their marginals with relative low error,
we take the union of the local marginal sets as the initialized S,
that isS=âˆªğ‘š
ğ‘–=1Sğ‘–and take the local MRFinferred contingency
histogramsâˆªğ‘š
ğ‘–=1{MRFğ‘–(ğ‘€)|âˆ€ğ‘€âˆˆSğ‘–}as the ground truth of contin-
gency histograms, where MRFğ‘–(ğ‘€)refers to the inferred result ofMRFğ‘–onğ‘€. Based on this ground truth and the initialized S, the
server initializes the global MRF.
5.3 OptMRF in Phase 5
After initialization, the encoded correlation in the local MRFs has
already been transferred to the global MRF. However, the correla-
tion among cross-party attributes has not been characterized by
the global MRF. To address this, the central server further refines S
by inserting cross-party marginals whose contingency histograms
can be estimated using the CarEst approach over the encoded local
attributesM. To minimize noise, we mainly select the low-way
cross-party marginals denoted as Sğ‘. Specifically, the average count
in each cell of ğ‘‡ğ‘€of each marginal ğ‘€âˆˆSğ‘is controlled to be larger
than a threshold ğ‘‘ğ‘, as given byË†ğ‘›Ã
ğ´ğ‘–âˆˆğ‘€|ğ‘¢ğ‘–|â‰¥ğ‘‘ğ‘, whereğ‘‘ğ‘controls
the error of the estimation of CarEst , which is also set empirically.
The optimization of Î˜involves multiple rounds. In each round, the
server randomly samples several cross-party marginals from Sğ‘
and optimize Î˜mainly on the ones with significant inferring error,
as measured by the L1 distance between the inferred histograms of
the global MRF and the true values estimated using CarEst over
the encoded attributes M. Once the global MRF is constructed, the
synthetic data can be sampled from the global MRF [4].
6 Dimension Reduction and Consistency
While Phase 1 - 5 with details introduced in Section 4 and Sec-
tion 5 can seemly compose a complete algorithm for differentially
private vertical data synthesis, it still suffers the curse of dimen-
sionality when dealing with attributes with large domain sizes. A
straightforward idea is tuning the granularity of attributes. With
a coarser granularity, the LocEnc-CarEst can have smaller rela-
tive errors, but the LocMRF and global MRF becomes inferior to its
best performance with more fine-grained granularity. Thus, config-
uring different granularities for those parts can be an alternative
improvement. However, there are two issues for this inconsistent
granularity solution: 1) how to reduce dimension while keeping
as much information as possible; 2) how to enforce consistency
between the frequencies of different granularities.
6.1 Dimension Reduction
The basic idea is to approximate the high-dimensional distributions
using low-dimensional ones. According to the joint distribution for-
mula, when considering (ğ´,ğµ)as a marginal for estimation, where
ğ‘‹andğ‘Œare the binned versions of ğ´andğµrespectively, the high-
dimensional marginal distribution can be estimated as
ğ‘ƒğ‘Ÿ[ğ´,ğµ]â‰ˆâˆ‘ï¸
(ğ‘‹,ğ‘Œ)ğ‘ƒğ‘Ÿ[ğ‘‹,ğ‘Œ]Â·ğ‘ƒğ‘Ÿ[ğ´|ğ‘‹]Â·ğ‘ƒğ‘Ÿ[ğµ|ğ‘Œ]. (5)
Here,ğ‘ƒğ‘Ÿ[ğ‘‹,ğ‘Œ]represents the low-dimensional distribution over
the binned attributes, while ğ‘ƒğ‘Ÿ[ğ´|ğ‘‹]andğ‘ƒğ‘Ÿ[ğµ|ğ‘Œ]are referred to as
value distributions and are also low-dimensional. Figure 3 provides
a visualization of our dimension reduction technique.
Inspired by this, we conduct equal-width binning for each at-
tribute of large domain size and preserve the value distribution in
each bin. Since value distributions contain statistical information
of attributes, Laplacian mechanism with noise scale1
ğœ–â€²is applied to
protect each element of value distributions, where ğœ–â€²is the privacy
4436VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
!ğ‘‡(",$)ğ‘‡(&,')CarEstHisRechigh-dim attrs!ğ‘‡(&,')low-dim attrsBinning
Figure 3: Instantiation of Dimension Reduction.
budget. When computing the high-dimensional marginal distri-
bution, the proposed CarEst is applied over the binned attributes
and outputs a low-dimensional marginal distribution, based on
which and the preserved value distributions, the original marginal
distribution can be recovered according to Equation (5) (HisRec).
6.2 Consistency Enforcement
As discussed in Section 5.3, estimating contingency histograms
for intra-party and cross-party marginals in the marginal set Sis
vital for constructing the global MRF. Intra-party marginals are
estimated using local MRFs, while cross-party marginals are esti-
mated using CarEst . Nevertheless, variations in the sources of
randomness can cause inconsistencies between the estimated his-
tograms from local MRFs and CarEst for specific attribute sets. To
this end, we propose a two-step technique to ensure consistency
when estimating marginals. Before the two-steps, the estimated
contingency histograms are transformed into marginal distribu-
tions. After enforcing consistency, distributions are transformed
back to contingency histograms to optimize the global MRF.
Step 1: consistency. LetË†ğ‘‡ğ‘€1denote an marginal estimated by
CarEst andeğ‘‡ğ‘€2be an marginal estimated by LocMRF . The goal is to
ensure the consistency of Ë†ğ‘‡ğ‘€1andeğ‘‡ğ‘€2on their common attributes
ğ´=ğ‘€1âˆ©ğ‘€2. Following the method in [ 41], the basic idea is to first
establish an agreement on the marginal ğ‘‡ğ´ofğ´, i.e., taking the arith-
metic mean ğ‘‡ğ´[a]=Ã
vğ´=ğ‘Ë†ğ‘‡ğ‘€1[v]+Ã
vğ´=ğ‘eğ‘‡ğ‘€2[v]
2,âˆ€aâˆˆÃ
ğ´ğ‘—âˆˆğ´[ğ‘¢ğ‘—]
with vğ´denoting the value of vonğ´, and then update both Ë†ğ‘‡ğ‘€1
andeğ‘‡ğ‘€2to be consistent with ğ‘‡ğ´by distributing the difference with
ğ‘‡ğ´equally among all affected cells in Ë†ğ‘‡ğ‘€1andeğ‘‡ğ‘€2.
Step 2: validation. After the consistency, the marginal may be-
come invalid (i.e., some probability estimations are negative, and
the sum does not equal to 1). To this end, we set the negative num-
bers to 0 and conduct normalization to validate the distribution.
The challenge emerges when we need to keep consistency and vali-
dation of marginals simultaneously, one operation may invalidate
the effect produced by another one. We iterate the two operations
multiple times to ensure the consistency and validation.
7 Experiments
In this section, we conduct end-to-end comparisons of VertiMRF to
baseline methods and validate its robust advantage under different
VFL settings.
7.1 Experiment settings
Datasets. We evaluate our algorithms on four widely used datasets [ 4,
35,60] in Table 1. NLTCS [ 33] collects 21,574 records from a study
on health status of older adults. Adult [ 3] contains 45,222 instances
obtained from IPUMS. BR2000 [ 46] consists of 38,000 records fromTable 1: Characteristics of Datasets
Dataset Records Attrs Dom. Dom. Size Attr. Split
NLTCS 21574 16 2 â‰ˆ6Ã—1048&8
Adult 45222 15 2-42 â‰ˆ4Ã—10148&7
BR2000 38000 13 2-21 â‰ˆ3Ã—1097&6
Fire 305119 15 2-46 â‰ˆ1Ã—10158&7
population Census in Brazil. Fire [ 45] includes 305,119 records of
fire unit responses to calls in San Francisco.
Metrics. We evaluate the performance based on two metrics [ 4,60,
62].ğ‘™-way TVD (ğ‘™âˆˆ{3,4}) is measured by computing the average
Total Variation Distance (TVD) between raw and synthetic data
across 300 sampled marginals from synthetic data, repeating the
process 10 times. Misclassification Rate is obtained by training
SVM classifiers using synthetic data to predict specific attributes
based on others. Using 80%raw data for synthesis and classifier
training, the misclassification rate is assessed via a test set (remain-
ing20%).
Compared methods.1We compare four methods. VertiGAN [18]
employs a partitioned GAN with a multi-output global genera-
tor and multiple local discriminators which are trained with DP-
SGD [ 1].Centralized refers to PrivMRF [ 4] in the centralized set-
ting. VertiMRF-FO &VertiMRF-FM are based on our proposed
VertiMRF framework, with one equipped with Frequency Oracle
based LocEnc approach (shown in Appendix B) and the other with
sketch-based LocEnc approach.
Parameter setting. In our experiments, we use default values for
VertiMRF-FM, setting the repetition number of the DP FM sketch
toğ‘¡=2000 andğ›¿=1/ğ‘›. The network structure of VertiGAN
follows the configuration described in the original paper [ 18] and
the privacy is tracked with RDP [ 37]. For all datasets except NLTCS,
we set the binning number to ğ‘=4. As for the privacy budget
allocation, we allocate 40%toLocMRF ,40%toLocEnc (with 10%of
the40%used to generate a noisy data count Ë†ğ‘›), and the rest 20%for
sanitizing value distributions in the binning procedure. By default,
our algorithms are validated in a two-party setting, the attribute
distribution on the two parties is shown in the "Attr. Split" row of
Table 1, e.g., "8&7" means that 8attributes are assigned to one party
and other 7attributes are assigned to the other one.
7.2 End to End Comparisons
Comparison on ğ‘™-way TVD. Figure 4 compares the methods based
on the average TVD of the 3-way and 4-way marginals. As shown,
VertiMRF-FM andVertiMRF-FO consistently produce smaller TVD
than Verti-GAN regardless of privacy cost or dataset. This demon-
strates the superiority of VertiMRF. Additionally, VertiMRF-FM out-
performs VertiMRF-FO across all cases, indicating that the sketch-
based LocEnc andCarEst can provide more accurate estimation of
the cross-party marginals compared to the FO-based approaches.
It is worth noting that VertiGAN consistently yields significantly
1In addition, we encountered the DPLT approach [ 50], which utilizes a latent tree
structure to capture attribute correlations. Despite our diligent efforts to replicate
DPLT, we faced ambiguity regarding data synthesis from the constructed tree. As a
result, we have chosen not to include DPLT in our comparison.
4437KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
0.4 0.8 1.6 3.20.000.25 3-way TVD
NLTCS
0.4 0.8 1.6 3.20.250.50
Adult
0.4 0.8 1.6 3.20.00.5
BR2000
0.4 0.8 1.6 3.20.00.5
Fire
0.4 0.8 1.6 3.20.00.5 4-way TVD
NLTCS
0.4 0.8 1.6 3.20.250.500.75
Adult
0.4 0.8 1.6 3.20.00.5
BR2000
0.4 0.8 1.6 3.20.00.5
Fire
Privacy budgetVertiMRF-FM VertiMRF-FO VertiGAN Centralized
Figure 4:ğ‘™-way TVD vs. privacy budget ğœ–on four datasets.
0.4 0.8 1.6 3.20.20.4
NLTCS, Y = outside
0.4 0.8 1.6 3.20.20.4
NLTCS, Y = bathing
0.4 0.8 1.6 3.20.250.50
NLTCS, Y = money
0.4 0.8 1.6 3.20.20.4
NLTCS, Y = traveling
0.4 0.8 1.6 3.20.250.50
Adult, Y = marital
0.4 0.8 1.6 3.20.20.4
Adult, Y = race
0.4 0.8 1.6 3.20.20.4
Adult, Y = capital gain
0.4 0.8 1.6 3.20.20.4
Adult, Y = incomeMisclassfication  Rate
Privacy budgetVertiMRF-FM VertiMRF-FO VertiGAN Centralized
Figure 5: SVM misclassification rate vs. privacy budget ğœ–on NLTCS and Adult datasets.
3-way 4-way 5-way
 NLTCS0.00.10.2TVD
3-way 4-way 5-way
Adult0.00.5m=2m=4m=8m=d
Figure 6: Impact of party number ğ‘š(ğœ–=0.8).
larger TVD results. This can be attributed to the fact that GAN-
based data synthesis methods are not well-suited for synthesiz-
ing tabular data, as discussed in previous studies [ 4,35]. Further-
more, the advantages of Centralized over VertiMRF-FM become
more prominent in datasets with larger domain sizes, such as adult,
BR2000, and Fire. Although VertiMRF-FM performs closely to Cen-
tralized on NLTCS when ğœ–is larger, the difference becomes more
pronounced in the other three datasets due to their larger domain
sizes. This aligns with our analysis in Theorem 3. A larger domain
size leads to smaller average count in a contingency histogram,
thereby deriving a larger estimation error of CarEst.Comparison on SVM classification. Figure 5 presents the aver-
age misclassification rates of the SVM classifiers trained on the
synthetic data. VertiMRF-FM consistently outperforms other ver-
tical methods. Misclassification rates of VertiGAN are as high as
40% even when ğœ–=3.2, which is significantly larger than both
VertiMRF-FM andVertiMRF-FO methods. Additionally, the advan-
tages of centralized over VertiMRF-FM are magnified as the domain
size of the dataset increases. These findings align with results shown
in Figure 4, illustrating the effectiveness of VertiMRF-FM and the
negative impact of large domain sizes.
Impact of the number of parties. We examine the impact of the
party number ğ‘šon the utility of synthetic data. Figure 6 compares
the TVD obtained under different settings of ğ‘šon NLTCS and
Adult datasets with ğœ–=0.8. In the experiments, ğ‘š=ğ‘‘indicates
that theğ‘‘attributes are distributed to dparties, with each party
having one distinct attribute. The results demonstrate that as ğ‘š
increases, the TVD results also increase. This is primarily because
when attributes are partitioned to more parties, LocMRF with high
precision contributes less to the global MRF. In such cases, the
LocEnc andCarEst procedures dominate the errors.
4438VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 2: 3-way TVD under different attribute distributions
Splitters Params. VertiMRF-FM VertiMRF-FO VertiGAN
Importance0.1 0.0583 (Â±0.005) 0.234(Â±0.023) 0.426 (Â±0.027)
1 0.0667 (Â±0.021) 0.249 (Â±0.017) 0.430 (Â±0.056)
10 0.0589 (Â±0.006) 0.257 (Â±0.019) 0.458 (Â±0.081)
100 0.0648 (Â±0.007) 0.266 (Â±0.022) 0.465 (Â±0.068)
Correlation0 0.0735 (Â±0.007) 0.261(Â±0.027) 0.436 (Â±0.034)
0.3 0.0524 (Â±0.006) 0.296 (Â±0.024) 0.416 (Â±0.031)
0.6 0.0684 (Â±0.006) 0.272 (Â±0.023) 0.438 (Â±0.038)
1.0 0.0678 (Â±0.009) 0.281 (Â±0.034) 0.401 (Â±0.042)
Table 3: Communication cost and computation time
Dataset Methods Commu. costCompu. time
per party server
AdultVertiMRF-FM (ğ‘¡=2000) 15Mb 23.1min 67min
VertiMRF-FM
(ğ‘¡=2000,ğ‘¡â„ğ‘Ÿğ‘’ğ‘ğ‘‘ğ‘  =40)4.9Mb 4.1min 67min
VertiMRF-FM (ğ‘¡=8000) 22Mb 93min 67min
VertiMRF-FO 18Mb 2.5min 67min
VertiGAN 112Mb 8.3min 10s
Centralized - - 16min
Impact of different attribute distributions. We calibrate the im-
portance and correlation of attributes from different data parties
based on the attribute splitters proposed for VFL tasks in Vert-
ibench [ 57], thereby evaluating the impact of varying attribute
distributions on algorithm performance. Table 2 summarizes the
resulting 3-way TVD results, i.e., mean and standard deviation
across 5 independent runs, under different parameter settings for
each algorithm on NLTCS dataset. As shown, the superiority of
VertiMRF-FM on other baseline algorithms is significant and sta-
ble with respect to different splitting strategies. Furthermore, the
TVD results for all algorithms fluctuate within a narrow range as
parametersğ›¼andğ›½vary, indicating that the performance of these
algorithms is robust against variations in feature splits.
Communication and computation cost. Table 3 compares the
communication costs and computation time of the four methods on
Adult. As analyzed in Section 4.3 and Appendix B, the communica-
tion overhead of VertiMRF-FM is expected to be smaller than that
ofVertiMRF-FO whenğ‘¡Â¯ğ‘¢<ğ‘›. Consistent with our analysis, we
observe that the overhead of VertiMRF-FM is smaller than that of
VertiMRF-FO whenğ‘¡Â¯ğ‘¢<ğ‘›withğ‘¡=2000 but larger when ğ‘¡Â¯ğ‘¢>ğ‘›
withğ‘¡=8000. The communication in VertiGAN involves sending
gradients of local generators to the server and the updated model
to local parties. The overall communication cost depends on the
model size and the number of communication rounds.
In terms of computation time, when using the sketch-based
LocEnc , each local party needs to perform ğ‘¡ğ‘›hash mappings, whereas
the FO-based LocEnc only requires ğ‘›|ğ´ğ‘–|perturbations. Since ğ‘¡>>
|ğ´ğ‘–|, the FO-based LocEnc requires less computation time. The hash
mappings can be accelerated by parallel computation since they
run independently. By introducing 40parallel threads, the compu-
tation time can be significantly reduced. On the server side, the
computation time is nearly identical for both VertiMRF-FM andVertiMRF-FO. Thatâ€™s because apart from CarEst , both methods
execute identical computations on the server side. Whether it is
FO-based CarEst or sketch-based CarEst , the computation pro-
cess solely involves simple calculations and does not significantly
affect the computation time. In VertiGAN, each party generates
fake data and computes model gradients, while the server aggre-
gates and broadcasts the updated model. Therefore, the most time
consumption occurs at the local party.
8 Related Work
We review related work from the following two perspectives.
DP data synthesis. There have been plenty of approaches [ 13,
17,24,25,27,35,44] to generate synthetic data with DP guaran-
tee, which can be categorized into GAN-based [ 2,11,61], game-
based [ 12,14,51], and marginal-based approaches [ 4,34,35,60,62].
Among them, the marginal-based ones tend to perform best, aiming
to approximate the joint distribution of high-dimensional data with
multiple low-way marginals. For example, PrivBayes [ 60] utilizes
the Bayesian network to select low-way marginals to approximate
a high-dimensional distribution. PrivMRF [ 4] applies a Markov
Random Field to model the data distribution, enabling flexible se-
lection of low-way marginals. Without learning a graph structure,
PrivSyn [ 62] greedily searches numerous low-way marginals to
represent and synthesize the dataset directly. Despite high utility,
these approaches cannot be directly extended to VFL settings.
Private vertical data synthesis. There are several works [ 18,
38,39,50] on the private data synthesis under vertical setting.
Among those works, some are based on the privacy model of k-
anonymity [ 49], which is vulnerable to various privacy attacks [ 21,
56]. A few works [ 18,38,50] explore DP data synthesis under
vertical settings. For instance, [ 38] proposes a two-party DP data
synthesis framework tailored for classification tasks. [ 50] utilizes a
latent tree model to capture the cross-party correlations on datasets
with binary attributes. DP-WGAN is also adapted to the vertical set-
ting [ 18] to generate synthetic data but performs poorly on tabular
data. To the best of our knowledge, we are the first work applicable
to the multi-party and high-dimensional data context.
9 Conclusion
We have presented VertiMRF, a novel differentially private algo-
rithm to generate synthetic data in the vertical federated setting. In
particular, VertiMRF has each party share a local MRF and multiple
DP FM-sketches of local attributes, based on that, the central server
can build an MRF to approximate global data distribution without
access to the raw data and violation of DP. Additionally, we also
provided two techniques tailored for datasets with large attribute
domain sizes. Finally, we empirically demonstrate the superiority
ofVertiMRF on four real world datasets.
Acknowledgments
This work was supported in part by the National Key Research and
Development Program of China under Grants 2022YFA1004100, and
2020YFA0713900; in part by the National Natural Science Founda-
tion of China under Grants 62172329, U21A6005, 61772410, 61802298;
in part by the Science and Technology Plan Project of Henan
province under Grant 232102211007.
4439KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
References
[1]M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang. Deep learning with differential privacy. In Proc. CCS, pages 308â€“318,
2016.
[2]N. C. Abay, Y. Zhou, M. Kantarcioglu, B. Thuraisingham, and L. Sweeney. Privacy
preserving synthetic data release using deep learning. In Proc. ECML PKDD 2018,
pages 510â€“526. Springer, 2019.
[3] A. Asuncion and D. Newman. Uci machine learning repository, 2007.
[4]K. Cai, X. Lei, J. Wei, and X. Xiao. Data synthesis via differentially private markov
random fields. Proc. VLDB Endow., 14(11):2190â€“2202, 2021.
[5]D. Chen, T. Orekondy, and M. Fritz. Gs-wgan: A gradient-sanitized approach for
learning differentially private generators. Proc. NeurIPS, 33:12673â€“12684, 2020.
[6]H. Chen, K. Laine, and P. Rindal. Fast private set intersection from homomorphic
encryption. In Proc. CCS, pages 1243â€“1255, 2017.
[7]W. Chen, G. Ma, T. Fan, Y. Kang, Q. Xu, and Q. Yang. Secureboost+: A high
performance gradient boosting tree framework for large scale vertical federated
learning. arXiv preprint arXiv:2110.10927, 2021.
[8]C. Dickens, J. Thaler, and D. Ting. Order-invariant cardinality estimators are
differentially private. In Proc. NeurIPS, pages 15204â€“15216, 2022.
[9]C. Dong, L. Chen, and Z. Wen. When private set intersection meets big data: an
efficient and scalable protocol. In Proc. CCS, pages 789â€“800, 2013.
[10] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity
in private data analysis. In Proc. TCC, pages 265â€“284. Springer, 2006.
[11] L. Frigerio, A. S. de Oliveira, L. Gomez, and P. Duverger. Differentially private
generative adversarial networks for time series, continuous, and discrete open
data. In Proc. IFIP SEC, pages 151â€“164. Springer, 2019.
[12] M. Gaboardi, E. J. G. Arias, J. Hsu, A. Roth, and Z. S. Wu. Dual query: Practical
private query release for high dimensional data. In Proc. ICML, pages 1170â€“1178.
PMLR, 2014.
[13] C. Ge, S. Mohapatra, X. He, and I. F. Ilyas. Kamino: Constraint-aware differentially
private data synthesis. arXiv preprint arXiv:2012.15713, 2020.
[14] M. Hardt, K. Ligett, and F. McSherry. A simple and practical algorithm for
differentially private data release. In Proc. NeurIPS, 2012.
[15] S. Hardy, W. Henecka, H. Ivey-Law, R. Nock, G. Patrini, G. Smith, and B. Thorne.
Private federated learning on vertically partitioned data via entity resolution and
additively homomorphic encryption. arXiv preprint arXiv:1711.10677, 2017.
[16] Y. Hu, D. Niu, J. Yang, and S. Zhou. FDML: A collaborative machine learning
framework for distributed features. In Proc. SIGKDD, KDD â€™19, page 2232â€“2240,
New York, NY, USA, 2019. Association for Computing Machinery.
[17] Y. Hu, F. Wu, Q. Li, Y. Long, G. Garrido, C. Ge, B. Ding, D. Forsyth, B. Li, and
D. Song. Sok: Privacy-preserving data synthesis. In Proc. S&P, pages 2â€“2, 2023.
[18] X. Jiang, Y. Zhang, X. Zhou, and J. Grossklags. Distributed gan-based privacy-
preserving publication of vertically-partitioned data. Proc. PET, 2:236â€“250, 2023.
[19] J. Jordon, J. Yoon, and M. Van Der Schaar. Pate-gan: Generating synthetic data
with differential privacy guarantees. In Proc. ICLR, 2018.
[20] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, et al. Advances and open
problems in federated learning. Foundations and TrendsÂ® in Machine Learning,
14(1â€“2):1â€“210, 2021.
[21] D. Kifer. Attacks on privacy and definettiâ€™s theorem. In Proc. SIGMOD, pages
127â€“138, 2009.
[22] V. Kolesnikov, R. Kumaresan, M. Rosulek, and N. Trieu. Efficient batched oblivious
prf with applications to private set intersection. In Proc. CCS, pages 818â€“829,
2016.
[23] H. Krawczyk. Hmqv: A high-performance secure diffie-hellman protocol. In Proc.
CRYPTO, pages 546â€“566. Springer, 2005.
[24] H. Li, L. Xiong, and X. Jiang. Differentially private synthesization of multi-
dimensional data using copula functions. In Advances in database technology:
proceedings. International conference on extending database technology, volume
2014, page 475. NIH Public Access, 2014.
[25] H. Li, L. Xiong, L. Zhang, and X. Jiang. Dpsynthesizer: differentially private data
synthesizer for privacy preserving data sharing. In Proc. VLDB Endow., volume 7,
page 1677. NIH Public Access, 2014.
[26] N. Li, M. Lyu, D. Su, and W. Yang. Differential privacy: From theory to practice.
Springer, 2017.
[27] N. Li, Z. Zhang, and T. Wang. Dpsyn: Experiences in the nist differential privacy
data synthesis challenges. arXiv preprint arXiv:2106.12949, 2021.
[28] Z. Li, B. Ding, L. Yao, Y. Li, X. Xiao, and J. Zhou. Performance-based pricing for
federated learning via auction. Proc. VLDB Endowment, 17(6):1269â€“1282, 2024.
[29] Z. Li, B. Ding, C. Zhang, N. Li, and J. Zhou. Federated matrix factorization with
privacy guarantee. Proc. VLDB Endow., 15(4):900â€“913, dec 2021.
[30] Z. Li, T. Wang, and N. Li. Differentially private vertical federated clustering. Proc.
VLDB Endow., 16(6):1277â€“1290, 2023.
[31] Y. Liu, Y. Kang, X. Zhang, L. Li, Y. Cheng, T. Chen, M. Hong, and Q. Yang.
A communication efficient collaborative learning framework for distributed
features. arXiv preprint arXiv:1912.11187, 2019.
[32] Y. Liu, Y. Liu, Z. Liu, Y. Liang, C. Meng, J. Zhang, and Y. Zheng. Federated forest.
IEEE Transactions on Big Data, (01):1â€“1, 2020.[33] K. G. Manton. National long-term care survey: 1982, 1984, 1989, 1994, 1999, and
2004. Inter-university Consortium for Political and Social Research, 2010.
[34] R. McKenna, G. Miklau, and D. Sheldon. Winning the nist contest: A scalable
and general approach to differentially private synthetic data. arXiv preprint
arXiv:2108.04978, 2021.
[35] R. McKenna, D. Sheldon, and G. Miklau. Graphical-model based estimation and
inference for differential privacy. In Proc. ICML, pages 4435â€“4444. PMLR, 2019.
[36] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas.
Communication-efficient learning of deep networks from decentralized data.
InProc. AISTATS, pages 1273â€“1282. PMLR, 2017.
[37] I. Mironov. RÃ©nyi differential privacy. In Proc. CSF, pages 263â€“275. IEEE, 2017.
[38] N. Mohammed, D. Alhadidi, B. C. Fung, and M. Debbabi. Secure two-party
differentially private data release for vertically partitioned data. IEEE transactions
on dependable and secure computing, 11(1):59â€“71, 2013.
[39] N. Mohammed, B. C. Fung, and M. Debbabi. Anonymity meets game theory:
secure data integration with malicious participants. The VLDB Journal, 20:567â€“
588, 2011.
[40] S. L. Pardau. The california consumer privacy act: Towards a european-style
privacy regime in the united states. J. Tech. L. & Polâ€™y, 23:68, 2018.
[41] W. Qardaji, W. Yang, and N. Li. Priview: practical differentially private release of
marginal contingency tables. In Proc. SIGMOD, pages 1435â€“1446, 2014.
[42] X. Ren, L. Shi, W. Yu, S. Yang, C. Zhao, and Z. Xu. Ldp-ids: Local differential
privacy for infinite data streams. In Proc. SIGMOD, pages 1064â€“1077, 2022.
[43] X. Ren, S. Yang, C. Zhao, J. McCann, and Z. Xu. Belt and brace: When federated
learning meets differential privacy. arXiv preprint arXiv:2404.18814, 2024.
[44] X. Ren, C.-M. Yu, W. Yu, S. Yang, X. Yang, J. A. McCann, and S. Y. Philip. Lopub:
high-dimensional crowdsourced data publication with local differential privacy.
IEEE Transactions on Information Forensics and Security, 13(9):2151â€“2166, 2018.
[45] D. Ridgeway, M. F. Theofanos, T. W. Manley, and C. Task. Challenge design and
lessons learned from the 2018 differential privacy challenges. Technical report,
Technical Report NIST Technical Note 2151â€ 2021.
[46] S. Ruggles, K. Genadek, G. Ronald, G. Josiah, and M. Sobek. Ipums usa: Version
6.0. Technical report, Minneapolis: University of Minnesota, 2015.
[47] A. Smith, S. Song, and A. Guha Thakurta. The flajolet-martin sketch itself
preserves differential privacy: Private counting with minimal space. In Proc.
NeurIPS, pages 19561â€“19572, 2020.
[48] S. Su, P. Tang, X. Cheng, R. Chen, and Z. Wu. Differentially private multi-party
high-dimensional data publishing. In Proc. ICDE, pages 205â€“216, 2016.
[49] L. Sweeney. k-anonymity: A model for protecting privacy. International journal
of uncertainty, fuzziness and knowledge-based systems, 10(05):557â€“570, 2002.
[50] P. Tang, X. Cheng, S. Su, R. Chen, and H. Shao. Differentially private publication of
vertically partitioned data. IEEE transactions on dependable and secure computing,
18(2):780â€“795, 2019.
[51] G. Vietri, G. Tian, M. Bun, T. Steinke, and S. Wu. New oracle-efficient algorithms
for private synthetic data release. In Proc. ICML, pages 9765â€“9774. PMLR, 2020.
[52] P. Voigt and A. Von dem Bussche. The eu general data protection regulation (gdpr).
A Practical Guide, 1st Ed., Cham: Springer International Publishing, 10(3152676):10â€“
5555, 2017.
[53] T. Wang, B. Ding, J. Zhou, C. Hong, Z. Huang, N. Li, and S. Jha. Answering
multi-dimensional analytical queries under local differential privacy. In Proc.
SIGMOD, pages 159â€“176, 2019.
[54] T. Wang, X. Yang, X. Ren, W. Yu, and S. Yang. Locally private high-dimensional
crowdsourced data release based on copula functions. IEEE Transactions on
Services Computing, 15(2):778â€“792, 2019.
[55] WeBank. Webank use case. https://www.fedai.org/cases/a-case-of-traffic-
violations-insurance-using-federated-learning/, 2022.
[56] R. C.-W. Wong, A. W.-C. Fu, K. Wang, and J. Pei. Minimality attack in privacy
preserving data publishing. In Proc. VLDB Endow., pages 543â€“554, 2007.
[57] Z. Wu, J. Hou, and B. He. Vertibench: Advancing feature distribution diversity in
vertical federated learning benchmarks. arXiv preprint arXiv:2307.02040, 2023.
[58] C. Xie, P.-Y. Chen, C. Zhang, and B. Li. Improving privacy-preserving verti-
cal federated learning by efficient communication with admm. arXiv preprint
arXiv:2207.10226, 2022.
[59] Y. Xie, Z. Wang, D. Gao, D. Chen, L. Yao, W. Kuang, Y. Li, B. Ding, and J. Zhou.
Federatedscope: A flexible federated learning platform for heterogeneity. Proc.
VLDB Endow., 16(5):1059â€“1072, 2023.
[60] J. Zhang, G. Cormode, C. M. Procopiuc, D. Srivastava, and X. Xiao. Privbayes:
Private data release via bayesian networks. ACM Transactions on Database
Systems (TODS), 42(4):1â€“41, 2017.
[61] X. Zhang, S. Ji, and T. Wang. Differentially private releasing via deep generative
model (technical report). arXiv preprint arXiv:1801.01594, 2018.
[62] Z. Zhang, T. Wang, N. Li, J. Honorio, M. Backes, S. He, J. Chen, and Y. Zhang.
Privsyn: Differentially private data synthesis. In Proc. USENIX Security, pages
929â€“946, 2021.
[63] F. Zhao, X. Ren, S. Yang, Q. Han, P. Zhao, and X. Yang. Latent dirichlet alloca-
tion model training with differential privacy. IEEE Transactions on Information
Forensics and Security, 16:1290â€“1305, 2020.
4440VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
A Pseudo-code of DP FM-sketching algorithm
Here is the pseudo-code of the DP FM-sketching algorithm dis-
cussed in Section 2.2.
Algorithm 2 DPFM
Input: Multi-setX={ğ‘¥1,...,ğ‘¥ğ‘›}, domain[ğ‘¢], distribution param-
eterğ›¾, privacy budget ğœ–â€², hash keyğœ‰âˆ¼ğ‘ˆğ‘›ğ‘–ğ‘“ğ‘œğ‘Ÿğ‘š(ğ‘…).
Output: DP FM-sketch ğ›¼forX.
1:ğ‘˜ğ‘â†âŒˆ1
ğ‘’ğœ–â€²âˆ’1âŒ‰,ğ›¼ğ‘šğ‘–ğ‘›â†âŒˆlog1+ğ›¾1
1âˆ’ğ‘’âˆ’ğœ–â€²âŒ‰
2:ğ›¼ğ‘â†max{ğ‘Œ1,...,ğ‘Œğ‘˜ğ‘}whereğ‘Œğ‘–âˆ¼ğºğ‘’ğ‘œğ‘šğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘(ğ›¾
1+ğ›¾),âˆ€ğ‘–â‰¤ğ‘˜ğ‘
3:ğ›¼Xâ†max{Hğœ‰(ğ‘¥ğ‘—)},âˆ€ğ‘¥ğ‘—âˆˆX.
4:return max
ğ›¼X,ğ›¼ğ‘,ğ›¼ğ‘šğ‘–ğ‘›	
B Frequency Oracle based LocEnc and CarEst
We use the widely known Frequency Oracle (FO) protocol, called the
Generalized Random Response technique (GRR) [ 53], to implement
a baseline for LocEnc.
FO-based LocEnc .Each partyPğ‘–employs GRR to encode the local
dataset. Specifically, for each local attribute ğ´ğ‘—âˆˆAğ‘–, a valueğ‘£(ğ‘—)
is perturbed to an arbitrary ğ‘£â€²
(ğ‘—)âˆˆ[ğ‘¢ğ‘—]with probabilities:
ğ‘ƒğ‘Ÿh
ğ‘£â€²
(ğ‘—)=ğ‘£i
=ï£±ï£´ï£´ ï£²
ï£´ï£´ï£³ğ‘’ğœ–â€²
ğ‘’ğœ–â€²+ğ‘¢ğ‘—âˆ’1, ğ‘£=ğ‘£(ğ‘—)
1
ğ‘’ğœ–â€²+ğ‘¢ğ‘—âˆ’1, ğ‘£â‰ ğ‘£(ğ‘—)(6)
Here,ğœ–â€²denotes LDP level preserved by the GRR technique for each
attribute. After applying GRR to each userâ€™s data value in the local
datasetğ·ğ‘–, we obtain a perturbed version eğ·ğ‘–. The partition of eğ·ğ‘–
restricted to ğ´ğ‘—, denoted asMğ‘—, is taken as the encoded attribute of
ğ´ğ‘—. Subsequently, the encoded local attributes Mğ‘–={Mğ‘—,âˆ€ğ´ğ‘—âˆˆ
Ağ‘–}are reported to the central server.
FO-based CarEst .After receiving the reported encoded attributes
M={Mğ‘—|ğ‘—âˆˆ[ğ‘‘]}, the central server can estimate the contin-
gency histogram of any arbitrary marginal. For an ğ‘™-way marginal
ğ‘€=(ğ´1,...,ğ´ğ‘™), we obtain a noisy contingency histogram Ë†ğ‘‡ğ‘€by
counting the occurrences of each value tuple v=(ğ‘£(1),...,ğ‘£(ğ‘™))âˆˆÃğ‘™
ğ‘–=1[ğ‘¢ğ‘–]fromM. However, relying solely on this estimation can
introduce considerable bias. To mitigate this issue, a commonly
employed technique is to utilize a transition probability matrix ğ‘ƒto
overcome the bias, which would then produce an unbiased estimate.
As shown in Equation (6), different attributes are encoded inde-
pendently in LocEnc procedure. So each tuple v=(ğ‘£(1),...,ğ‘£(ğ‘™))
can be encoded as arbitrary vâ€²=(ğ‘£â€²
(1),...,ğ‘£â€²
(ğ‘™))with probability
ğ‘ƒğ‘Ÿ[vâ†’vâ€²]=Ã
ğ´ğ‘–âˆˆğ‘€ğ‘ƒğ‘Ÿh
ğ‘£(ğ‘–)â†’ğ‘£â€²
(ğ‘–)i
.Since there areÃ
ğ´ğ‘–âˆˆğ‘€ğ‘¢ğ‘–
possible values for vin total, we can construct a Ã
ğ´ğ‘–âˆˆğ‘€ğ‘¢ğ‘–Ã— Ã
ğ´ğ‘–âˆˆğ‘€ğ‘¢ğ‘–-dimensional probability matrix ğ‘ƒto establish the tran-
sition relationship between ğ‘‡ğ‘€and the noisy Ë†ğ‘‡ğ‘€. That isğ‘ƒÂ·ğ‘‡ğ‘€=
E[Ë†ğ‘‡ğ‘€], where the expectation accounts for the randomness of GRR.
Therefore,ğ‘‡ğ‘€can be estimated as ğ‘ƒâˆ’1Â·Ë†ğ‘‡ğ‘€, where the existence of
ğ‘ƒâˆ’1is guaranteed by the positive definite property of the matrix.
Furthermore, it can be shown that
E[ğ‘ƒâˆ’1Â·Ë†ğ‘‡ğ‘€]=ğ‘ƒâˆ’1Â·E[Ë†ğ‘‡ğ‘€]=ğ‘ƒâˆ’1Â·ğ‘ƒÂ·ğ‘‡ğ‘€=ğ‘‡ğ‘€.This implies that ğ‘ƒâˆ’1Â·Ë†ğ‘‡ğ‘€is an unbiased estimator of ğ‘‡ğ‘€.
Privacy Analysis We notice that GRR achieves unbounded DP [ 26]
which considers the neighboring dataset by replacing one record.
It has been shown that any algorithm satisfying ğœ–unbounded DP
also satisfies 2ğœ–bounded DP, where bounded DP considers neigh-
boring datasets obtained by adding or removing a single record. In
this paper, we consider bounded DP for consistency. Thus, given
ğœ–â€², each perturbation in Equation (6) should satisfyğœ–â€²
2-DP. The
privacy guarantee of the FO-based LocEnc procedure can be ob-
tained by applying the sequential composition of DP, resulting
in an overall privacy guarantee of ğ‘‘ğœ–â€²/2, whereğ‘‘represents the
number of attributes in each record. However, Lemma 1 demon-
strates that RÃ©nyi Differential Privacy (RDP) [ 37] provides an alter-
native bound for the composition of multiple DP algorithms, that is
(4ğœ–â€²
2âˆšï¸
2ğ‘‘log(1/ğ›¿),ğ›¿)-DP, where 0<ğ›¿<1andlog(1/ğ›¿)â‰¥ğ‘›(ğœ–â€²
2)2.
To obtain the tighter bound, we take the minimum between the
two bounds, that is minn
ğ‘‘ğœ–â€²/2,2ğœ–â€²âˆšï¸
2ğ‘‘log(1/ğ›¿)o
with a tolerance
probability of ğ›¿. Here,ğ›¿=0when the minimum taking ğ‘‘ğœ–â€²/2.
Lemma 1 (DP Composition based on RDP). Letğ‘“be the compo-
sition ofğ‘›mechanisms that satisfies ğœ–-DP, then for each 0<ğ›¿<1
with log(1/ğ›¿)â‰¥ğ‘›ğœ–2,ğ‘“satisfies(4ğœ–âˆšï¸
2ğ‘›log 1/ğ›¿,ğ›¿)-DP.
Communication cost of VertiMRF-FO. Same as VertiMRF-FM,
there is only one communication round between each party Pğ‘–and
the central server in VertiMRF-FO . The communication includes
encoded attributesMğ‘–and the local MRF information {MRFğ‘–,Sğ‘–,Gğ‘–}.
The only difference between the communication contents of VertiMRF-
FMandVertiMRF-FO isMğ‘–. For FO-based LocEnc ,Mğ‘–contains
a noisy version of local dataset. the communication cost can be
bounded by ğ‘‚(ğ‘›ğ‘‘). Therefore, considering a total of ğ‘šparties, the
communication cost of VertiMRF-FO isğ‘‚(ğ‘›ğ‘‘)+ğ‘‚(ğ‘‘2)+ğ‘‚(ğ‘šğœâ€²).
C Proofs of Theorems
C.1 Proof of Theorem 2
Proof. Letğ·andğ·â€²be neighboring datasets satisfying ğ·âˆ‡ğ·â€²=
ğ‘‹ğ‘–ğ‘‘=n
ğ‘£1
ğ‘–ğ‘‘,...,ğ‘£ğ‘‘
ğ‘–ğ‘‘o
, whereğ‘–ğ‘‘denotes the record-index of ğ‘‹ğ‘–ğ‘‘,ğ‘£ğ‘—
ğ‘–ğ‘‘is
the corresponding attribute value of ğ´ğ‘—. Letğ‘“be the sketch-based
LocEnc algorithm which maps ğ‘¡hash keys and input dataset to ğ‘¡
set of sketch tuples
(
M(â„)â‰œ(
M(â„)
ğ‘—â‰œ 
ğ›¼(â„)
ğ‘£ğ‘—
1,...,ğ›¼(â„)
ğ‘£ğ‘—
ğ‘¢ğ‘—!
|ğ‘—âˆˆ[ğ‘‘])
|â„âˆˆ[ğ‘¡])
.
whereğ›¼(â„)
ğ‘£ğ‘—
ğ‘–denotes the sketch of the ID set for ğ´ğ‘—=ğ‘£ğ‘—
ğ‘–generated
with the hash key ğœ‰â„.
We first calculate the privacy cost when applying a hash key
ğœ‰â„to the overall input dataset and returning sketch tuples M(â„).
M(â„)hasğ‘‘sketch tuples andÃğ‘‘
ğ‘–=1ğ‘¢ğ‘–sketches in total. Since ğ‘‹ğ‘–ğ‘‘
can only take one value ğ‘£ğ‘—
ğ‘–ğ‘‘of each attribute ğ´ğ‘—, then there should
also be one sketch ğ›¼(â„)
ğ‘£ğ‘—
ğ‘–ğ‘‘inM(â„)
ğ‘—may be different for ğ·andğ·â€².
Therefore, according to the definition of RDP, it holds that
4441KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
exp
(ğœ†âˆ’1)ğ·ğœ† ğ‘“(ğ·,ğœ‰â„)|ğ‘“(ğ·â€²,ğœ‰â„)
(7)
=âˆ‘ï¸
M(â„)ğ‘ƒğ‘Ÿ[M(â„)]ğœ†ğ‘ƒğ‘Ÿâ€²[M(â„)]1âˆ’ğœ†(8)
=âˆâˆ‘ï¸
ğ›¼(â„)
ğ‘£1
ğ‘–ğ‘‘=0...âˆâˆ‘ï¸
ğ›¼(â„)
ğ‘£ğ‘‘
ğ‘–ğ‘‘=0{[ğ‘ƒğ‘Ÿ[ğ›¼(â„)
ğ‘£1
ğ‘–ğ‘‘]Ã–
1<ğ‘–â‰¤ğ‘‘ğ‘ƒğ‘Ÿ[ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘|{ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘,ğ‘¡<ğ‘–}]]ğœ†Â·(9)
[ğ‘ƒğ‘Ÿâ€²[ğ›¼(â„)
ğ‘£1
ğ‘–ğ‘‘]Ã–
1<ğ‘–â‰¤ğ‘‘ğ‘ƒğ‘Ÿâ€²[ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘|{ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘,ğ‘¡<ğ‘–}]]1âˆ’ğœ†}Â· (10)
âˆ‘ï¸
M(â„)
Â¬[ğ‘ƒğ‘Ÿ[M(â„)
Â¬|Â®ğ›¼]]ğœ†[ğ‘ƒğ‘Ÿâ€²[M(â„)
Â¬|Â®ğ›¼]]1âˆ’ğœ†
|                                               {z                                               }
=1(11)
where the second equality follows the joint distribution formula,
Â®ğ›¼â‰œ{ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘,1â‰¤ğ‘–â‰¤ğ‘‘}andM(â„)
Â¬denotes other sketches in M(â„)
besidesÂ®ğ›¼.
Now consider term ğ‘ƒğ‘Ÿ
ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘|
ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘,ğ‘¡<ğ‘–
, there are two cases:
â€¢âˆ€ğ‘¡,ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘â‰ ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘. In such case, since Hğœ‰map distinct elements to
independent variables and the ğ‘˜ğ‘phantom elements are inde-
pendently sampled, then ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘is independent of ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘,âˆ€ğ‘¡. That
indicates
ğ‘ƒğ‘Ÿ
ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘|
ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘,ğ‘¡<ğ‘–
=ğ‘ƒğ‘Ÿ
ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘
.
â€¢âˆƒğ‘¡,ğ‘ .ğ‘¡.,ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘=ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘. In such case, it should hold that ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘â‰¥
Hğœ‰â„(ğ‘–ğ‘‘). That indicates
ğ‘ƒğ‘Ÿ
ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘|
ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘,ğ‘¡<ğ‘–
=ğ‘ƒğ‘Ÿâ€²
ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘|
ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘,ğ‘¡<ğ‘–
.
The left side of above Equation is the probability that ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘is
the maximal among all elements in the set of hashed record ids
and sampled geometric random variables on ğ·. Since we have
known thatHğœ‰â„(ğ‘–ğ‘‘)is not or not the only one maximal element
in the set, then we can just consider other hashed ids and sampled
variables. The ids are same for ğ·andğ·â€²and each of the variables
are i.i.d sampled from the same distribution, which can easily
derive the equality of above equation.
W.l.o.g., we assume there are ğ‘ terms

ğ‘ƒğ‘Ÿ
ğ›¼(â„)
ğ‘£ğ‘—
ğ‘–ğ‘‘|
ğ›¼(â„)
ğ‘£ğ‘¡
ğ‘–ğ‘‘,ğ‘¡<ğ‘—
,(ğ‘‘âˆ’ğ‘ +1)â‰¤ğ‘—â‰¤ğ‘‘
that satisfy the second case. Then, Equation (7) can be bounded by:
exp
(ğœ†âˆ’1)ğ·ğœ† ğ‘“(ğ·,ğœ‰â„)|ğ‘“(ğ·â€²,ğœ‰â„)
(12)
=âˆâˆ‘ï¸
ğ›¼(â„)
ğ‘£1
ğ‘–ğ‘‘=0...âˆâˆ‘ï¸
ğ›¼(â„)
ğ‘£ğ‘‘âˆ’ğ‘ 
ğ‘–ğ‘‘=0"ğ‘‘âˆ’ğ‘ Ã–
ğ‘–=1ğ‘ƒğ‘Ÿ[ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘]#ğœ†
Â·"ğ‘‘âˆ’ğ‘ Ã–
ğ‘–=1ğ‘ƒğ‘Ÿâ€²[ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘]#1âˆ’ğœ†
(13)
=ğ‘‘âˆ’ğ‘ Ã–
ğ‘–=1ï£±ï£´ï£´ï£´ï£´ï£´ ï£²
ï£´ï£´ï£´ï£´ï£´ï£³âˆâˆ‘ï¸
ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘=0
ğ‘ƒğ‘Ÿ[ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘]ğœ†
ğ‘ƒğ‘Ÿâ€²[ğ›¼(â„)
ğ‘£ğ‘–
ğ‘–ğ‘‘]1âˆ’ğœ†ï£¼ï£´ï£´ï£´ï£´ï£´ ï£½
ï£´ï£´ï£´ï£´ï£´ï£¾|                                             {z                                             }
ğ‘¡ğ‘’ğ‘Ÿğ‘š(ğ‘–)(14)Theorem 2.5 in [ 47] demonstrates a statistical bound of ğœ–â€²under DP
framework. According to the definition of RDP and the translation
with DP, it holds that ğ‘¡ğ‘’ğ‘Ÿğ‘š(ğ‘–)â‰¤exp[(ğœ†âˆ’1)(2ğœ†(ğœ–â€²)2)]. Then we
can derive that
exp
(ğœ†âˆ’1)ğ·ğœ† ğ‘“(ğ·,ğœ‰â„)|ğ‘“(ğ·â€²,ğœ‰â„)
(15)
â‰¤exp[(ğœ†âˆ’1)(2(ğ‘‘âˆ’ğ‘ )ğœ†(ğœ–â€²)2)]â‰¤ exp[(ğœ†âˆ’1)(2ğ‘‘ğœ†(ğœ–â€²)2)](16)
So far, we have proved that applying one hash key to map the
overall input data satisfies (ğœ†,2ğ‘‘ğœ†(ğœ–â€²)2)-RDP in a single run. Next,
according to the sequential composition theorem of RDP [ 37],
LocEnc algorithm involving ğ‘¡runs of the FM sketch generation
process should satisfy (ğœ†,2ğ‘¡ğ‘‘ğœ†(ğœ–â€²)2)-RDP, which can be further
translated to(4ğœ–âˆšï¸
ğ‘¡ğ‘‘log(1/ğ›¿),ğ›¿)-DP,âˆ€ğ›¿<1if settingğ›¼â‰¥2.â–¡
C.2 Proof of Theorem 3
Our proof is based on a lemma [ 47] that bounds the error of the
cardinality estimated by the DPFM algorithm shown in Algorithm 2.
Lemma 2. Letğ‘˜ğ¹ğ‘€be the estimated cardinality by Algorithm 2
with inputs ğ›¾,ğœ–,ğ›¿,ğ›½âˆˆ(0,1), usingğ‘¡=100âˆš
log(1/ğ›½)
ğ›¾2 repeats, then
for each multi-setXâŠ‚ğ‘¢, it holds that
|X|
1+ğ›¾âˆ’ğ‘‚â‰¤ğ‘˜ğ¹ğ‘€â‰¤(1+ğ›¾)Â·|X|+ğ¶ (17)
with probability at least 1âˆ’ğ›½, whereğ¶=ğ‘‚(log1/2(1/ğ›¿)log1/4(1/ğ›½)
ğœ–).
Proof. We first bound each cardinality Ë†ğ‘‡ğ‘€[v]estimated by FM
sketch. As shown in Section 4.2, we compute each Ë†ğ‘‡ğ‘€[v]using the
inclusion-exclusion principle and the mergeable property of sketch,
that is|ğ´âˆ©ğµ|=Ë†ğ‘›âˆ’|Â¯ğ´âˆªÂ¯ğµ|, where Ë†ğ‘›denotes the noisy data number
sanitized by adding a Laplacian noise Ë†ğ‘. Combining with lemma 2,
we can derive that
âˆ’ğ›¾ğ‘›+(1+ğ›¾)ğ‘‡ğ‘€[v]+ Ë†ğ‘âˆ’ğ¶â‰¤Ë†ğ‘‡ğ‘€[v]â‰¤ğ›¾
1+ğ›¾ğ‘›+ğ‘‡ğ‘€[v]
1+ğ›¾+Ë†ğ‘+ğ¶
(18)
By subtracting ğ‘‡ğ‘€[v]for both sides of Equation 18, we can obtain
that:
âˆ’ğ›¾ğ‘›+ğ›¾ğ‘‡ğ‘€[v]+Ë†ğ‘âˆ’ğ¶â‰¤Ë†ğ‘‡ğ‘€[v]âˆ’ğ‘‡ğ‘€[v]â‰¤ğ›¾
1+ğ›¾ğ‘›âˆ’ğ›¾ğ‘‡ğ‘€[v]
1+ğ›¾+Ë†ğ‘+ğ¶(19)
By taking the absolute value for both sides and dividing them by
ğ‘‡ğ‘€[v], we can derive that
|Ë†ğ‘‡ğ‘€[v]âˆ’ğ‘‡ğ‘€[v]|
ğ‘‡ğ‘€[v](20)
â‰¤maxğ›¾
1+ğ›¾(ğ‘›
ğ‘‡ğ‘€[v]âˆ’1)+Ë†ğ‘+ğ¶
ğ‘‡ğ‘€[v],ğ›¾(ğ‘›
ğ‘‡ğ‘€[v]âˆ’1)âˆ’Ë†ğ‘âˆ’ğ¶
ğ‘‡ğ‘€[v]
(21)
â‰¤ğ›¾(ğ‘›
ğ‘‡ğ‘€[v]âˆ’1)+Ë†ğ‘+ğ¶
ğ‘‡ğ‘€[v]. (22)
According to Lemma 2, the above bound holds with probability
1âˆ’ğ›½, andğ¶=ğ‘‚(log1/2(1/ğ›¿)log1/4(1/ğ›½)
ğœ–). â–¡
4442