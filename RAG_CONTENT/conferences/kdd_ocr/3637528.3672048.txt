Predicting Cascading Failures with a Hyperparametric Diffusion
Model
Bin Xiang
CNRS@CREATE
Singapore, Singapore
bin.xiang@cnrsatcreate.sgBogdan Cautis
University of Paris-Saclay, CNRS LISN
Saclay, France
bogdan.cautis@universite-paris-saclay.frXiaokui Xiao
National University of Singapore
Singapore, Singapore
xkxiao@nus.edu.sg
Olga Mula
Eindhoven University of Technology
Eindhoven, Netherlands
o.mula@tue.nlDusit Niyato
Nanyang Technological University
Singapore, Singapore
dniyato@ntu.edu.sgLaks V.S. Lakshmanan
University of British Columbia
Vancouver, Canada
laks@cs.ubc.ca
Abstract
In this paper, we study cascading failures in power grids through the
lens of information diffusion models. Similar to the spread of rumors
or influence in an online social network, it has been observed that
failures (outages) in a power grid can spread contagiously, driven by
viral spread mechanisms. We employ a stochastic diffusion model
that is Markovian (memoryless) and local (the activation of one
node, i.e., transmission line, can only be caused by its neighbors).
Our model integrates viral diffusion principles with physics-based
concepts, by correlating the diffusion weights (contagion probabili-
ties between transmission lines) with the hyperparametric Informa-
tion Cascades (IC) model. We show that this diffusion model can be
learned from traces of cascading failures, enabling accurate model-
ing and prediction of failure propagation. This approach facilitates
actionable information through well-understood and efficient graph
analysis methods and graph diffusion simulations. Furthermore, by
leveraging the hyperparametric model, we can predict diffusion
and mitigate the risks of cascading failures even in unseen grid
configurations, whereas existing methods falter due to a lack of
training data. Extensive experiments based on a benchmark power
grid and simulations therein show that our approach effectively
captures the failure diffusion phenomena and guides decisions to
strengthen the grid, reducing the risk of large-scale cascading fail-
ures. Additionally, we characterize our modelâ€™s sample complexity,
improving upon the existing bound.
CCS Concepts
â€¢Computing methodologies â†’Learning in probabilistic
graphical models; â€¢Theory of computation â†’Sample com-
plexity and generalization bounds.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672048Keywords
Cascading failures, diffusion graphs, independent cascades, hyper-
parametric model, learnability, power grids.
ACM Reference Format:
Bin Xiang, Bogdan Cautis, Xiaokui Xiao, Olga Mula, Dusit Niyato, and Laks
V.S. Lakshmanan. 2024. Predicting Cascading Failures with a Hyperpara-
metric Diffusion Model. In Proceedings of the 30th ACM SIGKDD Con-
ference on Knowledge Discovery and Data Mining (KDD â€™24), August 25â€“
29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3637528.3672048
1 Introduction
Interest in information diffusion and influence, initially motivated
by social networks and viral marketing [ 2,23], has expanded signif-
icantly in recent years. Researchers have recognized the potential
applicability of these methods beyond the social media sphere, as
diffusion phenomena and algorithms for understanding viral spread,
leveraging its reach or mitigating its risks, are now being applied in
public health and epidemiology [ 13], transportation and logistics
[26], internet virus propagation and cyber-security [ 32], complex
biological systems [3], or ad-hoc communication networks [44].
Besides these diverse fields, one critical domain stands out, per-
taining to cascading failures in power transmission networks, where
viral spread phenomena can exert a significant impact, potentially
disrupting our society. Just as rumors or influence may spread in
an online social network, it has been observed and confirmed by
research that failures (outages) in a power grid are contagious and
can be described by viral spread mechanisms [ 18,24]. Indeed, due
to recent events like the 2021 Texas blackouts [ 1], the issue of cas-
cading grid failures has made headlines and gained a lot of attention
[34]. In short, a cascading failure in a power grid represents the
event of successive interdependent failures of components in the
system. Usually initiated by one or a few source outages, due to en-
dogenous or exogenous disturbances, they propagate in a relatively
short lapse of time, potentially leading to large blackouts [18].
The analysis and prediction of such events is challenging be-
cause cascading failures are in general non-contiguous / non-local
with respect to the physical topology of the power grid. This means
that a failure of a specific transmission line may cause the failure
of another one that is geographically distant and not directly cou-
pled [ 20], e.g., may be even located hundreds of kilometers away, as
3495
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bin Xiang et al.
documented in the Western US blackout of July 2, 96 [ 41]. This moti-
vated researchers to study analytical frameworks that are based on
graphs whose topology is not necessarily close to that the physical
grid [ 6,19]. In particular, data-driven approaches were proposed,
leading to the development of graph models of the observed in-
teractions among components of the power grid [ 14,18,19,42].
See [ 29] for a recent survey on cascading failure analysis in power
grids, based on interaction graphs, which model power grids with
the nodes representing electrical components of interest such as
buses or transmission lines and the edges representing interactions
observed in known cascades of failures.
However, constructing interaction / diffusion graphs that accu-
rately capture cascading patterns hinges on two crucial factors:
sufficient data quantity and high data quality. Only then can net-
work analysis effectively reveal these patterns and ultimately guide
decisions for mitigating cascading blackouts (e.g., by upgrading
selected transmission lines). Yet real-world historical data of cas-
cading failures is hard to obtain, and the alternative to it, coming
from grid simulators (e.g., quasi-steady-state or dynamic power
network models [ 20,37]) may introduce artificial biases and errors.
Furthermore, a significant limitation of these methods is the inabil-
ity to adapt to unseen grid configurations. They rely on past data,
potentially missing rare or unique interactions between transmis-
sion lines, which are latent. This hinders their effectiveness in novel
grid configurations and poses a significant challenge, as decisions
involving grid configuration provisioning may be time-critical.
In this paper, we study cascading failures in power grids through
the lens of information diffusion models. We make use of a classic
stochastic diffusion model, known as Independent Cascades (IC),
which is Markovian (memoryless) and local (the activation of one
node, i.e., transmission line, can only be caused by its neighbors).
Our model intentionally embraces such simplifying assumptions
to exploit the efficiency and interpretability of established graph
analysis tools and simulations for diffusion processes, thereby fa-
cilitating more readily actionable insights. Potential limitations in
capturing intricate dependencies are counterbalanced by integrat-
ingphysics-based concepts into the viral diffusion model, aiming to
(i) enhance model fidelity and (ii) reduce the sample complexity of
the learning task. More precisely, we impose correlations on the dif-
fusion weights (contagion probabilities between transmission lines)
with the hyperparametric IC model of [ 22]. The model â€“ initially mo-
tivated by diffusion scenarios in social media â€“ assumes that each
node in the diffusion graph has features encapsulating its diffusion-
relevant properties. Then, the diffusion weight between a pair of
nodes is a function of their features and a global, low-dimensional
hyperparameter. Indeed, existing studies have demonstrated strong
correlations between features of the transmission lines, which may
be physics-based or topology / connectivity-based, and their stabil-
ity w.r.t. failures in the grid [ 38,40]. Furthermore, since the diffusion
probabilities are correlated, each observation provides information
about all edges in the network, thereby minimizing training data
requirements for robust predictions.
The main contributions of our paper can be summarized as follows:
â€¢We revisit the hyperparametric IC model of [ 22], adapting it to
the spread of failures in a diffusion graph having as nodes the
transmission lines of the power grid.â€¢We present a learning algorithm for this model, based on known
cascades of failure traces. Initializing with a complete graph
representing all possible connections (accounting for non-local
propagation), the algorithm learns diffusion probabilities over
edges, effectively sparsifying the network to reflect the most
influential interactions.
â€¢Extensive experiments, based on a benchmark power grid and
simulations therein, show that our approach can accurately model
and predict how failures may propagate, and that its predictions
can guide the decisions to consolidate the grid and thus reduce
the risk of large cascading failures.
â€¢Furthermore, by leveraging the hyperparametric model, we show
that we can make diffusion predictions and mitigate the risks of
cascading failures even in unseen grid configurations, for which
existing methods cannot apply due to lack of training data.
â€¢Finally, we characterize the sample-complexity of our learning
algorithm, improving upon the best known bound of [22].
2 Related Work
The state of the art for analyzing and learning cascading failures in
power grids can be mainly categorized into deterministic andsto-
chastic ones. We note that while deep learning has shown promise
in predicting cascading failures (e.g., [ 47]), these approaches lack
interpretability and rigorous theoretical performance guarantees.
Deterministic methods are mainly based on the OPA (ORNL-
PSerc-Alaska) model [ 8,9], which simulates the power systemâ€™s
response after contingencies of transmission line failures. They
can provide detailed processes, tracing the cascading failures in
the system, but they usually incur performance issues due to the
computation of optimal power flow.
Stochastic approaches adopt different types of models based on
Markov chains or statistical learning. The main idea of these ap-
proaches is to estimate an influence (or contagion) probability ma-
trix. Specifically, traditional Markov chain-based approaches [ 33,
46] view a cascading process as a sequence of transitions among
states, where each state encapsulates the status of a group of nodes.
The effectiveness of such an approach is impacted by the design of
the state space and by the combinatorial characteristics of states.
Specifically, by design, the individual node-to-node transition prob-
abilities are not directly estimated in such approaches. To address
this issue, branching processes (a variant of Markov chains) have
been used in [ 7,18â€“20], where each failure in one stage is assumed
to generate some random failures in the subsequent stage, following
an offspring distribution such as Poisson. Finally, the more recent
statistical learning approaches [ 14,42] apply non-parametric regres-
sion models to fit the cascading processes, based on given historical
traces of cascading failures.
As mentioned previously, a major limitation of the aforemen-
tioned approaches is their inability to adapt to unseen grid config-
urations. More precisely, such models can only be applied to the
same fixed power system configuration that produced the cascading
logs. As shown in our experiments, any small change or perturba-
tion in the power system may drastically impact their effectiveness.
This poses a significant challenge, since some decisions may be
time-critical and cannot be delayed until new cascading traces are
produced (e.g., by grid simulations) to retrain upon.
3496Predicting Cascading Failures with a Hyperparametric Diffusion Model KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Information diffusion and influence maximization were pioneered
by the seminal works of [ 10,23]. Diffusion models such as Inde-
pendent Cascades (IC), Linear Threshold (LT), and generalizations
thereof were introduced in [ 23]. The problem of Influence Maxi-
mization (IM) â€“ selecting a set of seed nodes that maximize the
expected spread in a diffusion network under a certain diffusion
model â€“ was also introduced in [ 23] and studied extensively since.
See the recent survey [ 27] for a detailed review of the IM literature.
While classic IM methods assume that the underlying diffusion
network, including the influence probabilities associated with each
connection, is known, this assumption rarely holds in practice. A
rich body of work has been devoted to learning the underlying
diffusion network when historical cascades of propagation traces
are available [11, 15, 16, 30, 35].
Often, the drawback of such methods is their high sample-comple-
xity, as discussed in [ 22], which proposes an alternative approach,
with lower sample-complexity, based on a hyperparametric IC
model. They assume nodes / edges have features, which induce
correlations between the diffusion probabilities of different edges.
This allows to minimize training data requirements for robust pre-
dictions, as also shown in [21].
Our study starts with the thesis that methods of information
diffusion analysis from the rich IM literature may be applicable to
other fields such as cascading failures in power grids, enabling us
to leverage well-established techniques, thus leading more readily
to actionable insights. Nevertheless, important differences have to
be taken into account, such as the fact that failures may propagate
non-locally, in a physical system such as the power grid, while infor-
mation in a social network may spreed to the connected â€œneighborsâ€
in a sparse online network. By integrating physics-based concepts
into a diffusion model and by designing an adapted learning ap-
proach, we aim to address the specificity of this application scenario,
in this way improving the modelâ€™s effectiveness and its training
data requirements such as sample-complexity. The merging of vi-
ral diffusion principles with physics-based notions is supported
by recent studies showing that the physical features of a power
grid exhibit strong correlations with the systemâ€™s stability [ 38,40].
This suggests that such features can be used to train a cascading
failure model, one having a better potential for generalization and
robustness to grid changes. In comparison with the works discussed
here, the hyperparametric approach allows us to (i) enhance model
fidelity and (ii) reduce the sample complexity of the learning task.
Moreover, its predictions can guide the decisions to consolidate
the grid and thus reduce the risk of large CFs. Importantly, the
hyperparametric approach enables us to make diffusion predictions
and mitigate the risks of CFs even in unseen grid configurations, for
which existing methods cannot apply due to lack of training data.
3 Diffusion Model
3.1 Classic Diffusion Models
We start with the premise that CFs bear resemblance to the well-
studied processes of information diffusion in generic settings, par-
ticularly using the classic Independent Cascade (IC) model [ 23],
which we briefly review next.
IC Model: In the classic IC model, we have a graph G(V,E)and
a probability ğ‘ğ‘¢ğ‘£associated with every edge (ğ‘¢,ğ‘£)âˆˆE . Diffusionproceeds in discrete time steps. At time ğ‘¡=0, only the seed nodes,
the initiators of a cascade, are active. Once activated, a node remains
active. Every node ğ‘¢that became active at time ğ‘¡>0has one chance
to activate each of its inactive neighbors ğ‘£, with probability ğ‘ğ‘¢ğ‘£.
The propagation terminates when a fixpoint is reached and no more
nodes can become active. The classic IM problem aims at finding ğ‘˜
seed nodes that lead to the maximum number of activated nodes in
expectation, also known as (expected) spread.
Hyperparametric IC Model: An instance of IC model is charac-
terized by the edge probabilities. Since these parameters may not be
known or learned exactly, there has been an investigation of IM over
a set of model instances corresponding to the uncertainty in our
knowledge of edge probabilities [ 5,17,22]. A particularly elegant
approach among those is the so-called hyperparametric IC model
[22]. It postulates a vector of features associated with each node
which are relevant to the node exerting and experiencing influence.
Examples of such features include age, gender, profession, degree,
pagerank, etc. The influence between a pair of nodes is a function
of the node features and a global low dimensional hyperparameter
ğœ½. More precisely, the hyperparametric model ğ»:Î˜Ã—ğ‘‹â†’[0,1]
restricts the IC model by imposing correlations among edge prob-
abilities. Each edge (ğ‘¢,ğ‘£)âˆˆE is associated with a ğ‘‘-dimensional
vector ğ’™ğ‘¢ğ‘£âˆˆğ‘‹, whereğ‘‹âŠ† [0,1]ğ‘‘which encodes the features
associated with its endpoints. The probability of ğ‘¢influencing ğ‘£
is a function of ğ’™ğ‘¢ğ‘£and a low-dimensional hyperparameter, i.e.,
ğ»(ğ’™ğ‘¢ğ‘£,ğœ½), where ğœ½âˆˆÎ˜âŠ†[âˆ’ğµ,ğµ]ğ‘‘, for some constant ğµ>0.
3.2 Adaptation to Power Grids
Diffusion graph: Earlier attempts to model power grids as graphs,
with nodes representing generators or buses and edges represent-
ing transmission lines were found to be ineffective in predicting
failures as these can propagate in a manner that transcends the grid
topology [ 7]. As such, we do not discuss these approaches further.
Network models where nodes represent transmission lines and
edges are based on observed cascades of failures have been found
to be more successful in modeling and predicting failure cascades
[18]. However, unlike in applications such as social networks, the
diffusion graph underlying cascading failures in power grids is not
explicitly available and must be learned from available cascades.
In these applications, a set of cascades Kis available, where for
eachğ‘˜âˆˆK, the cascade consists of a sequence of sets of nodes (i.e.,
transmission lines) (V0,V1,...,VTğ‘˜), whereVğ‘¡is the set of nodes
that failed at time ğ‘¡âˆˆ[0,Tğ‘˜]. It is assumed that any node that failed
at timeğ‘¡could influence any node that failed at the next time step
ğ‘¡+1. With no further information available on failure propagation,
we allow the possibility that the diffusion graph contains an edge
(ğ‘¢,ğ‘£), for allğ‘¢âˆˆVğ‘¡andğ‘£âˆˆVğ‘¡+1. Given a set of such cascades K,
we learn the most likely diffusion graph that explains all observed
failure cascades using a learning algorithm, which tries to sparsify
the above graph.
Choice of Model: As discussed in Section 2, most prior research
on cascading failures (CFs) uses statistical or probabilistic frame-
works, such as branching processes or Markov chains, to analyze
interactions. However, these methods often work only for specific
cases, rendering them less reliable for broader applications. We
posit that hyperparametric modeling can offer a more effective
3497KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bin Xiang et al.
solution, as evidenced by its potential in studies of information dif-
fusion in social networks [ 21,22]. Nevertheless, CFs in power grids
pose unique challenges: non-local cascades, complex networks, and
intricate physical properties. To address these issues, we leverage
the physical and topological features of power grids to unravel the
intricate dynamics of cascading failures. We propose an adaptation
of the hyperparametric model that quantifies influence probabilities
using these features, coupled with data from observed CF events.
Influence probability: Various functions can be used to model
the relationship between features, the hyperparameter, and the
likelihood of influence. We adopt here the logistic function, which
is frequently used in the existing literature. Let ğ‘ğ‘¢ğ‘£denote the in-
fluence probability from line ğ‘¢toğ‘£,ğ’™ğ‘¢ğ‘£the vector of features of the
endpoints (transmission lines) ğ‘¢andğ‘£, and ğœ½the hyperparameter
vector. Then, the influence probability function is
ğ‘ğ‘¢ğ‘£=1
1+ğ‘’âˆ’ğœ½Tğ’™ğ‘¢ğ‘£. (1)
The feature values are assumed to be normalized, i.e., ğ’™ğ‘¢ğ‘£âˆˆ
[âˆ’1,1]ğ‘‘, whereğ‘‘is the dimensionality of the hyperparameter.
While most features exhibit non-negative values, some, such as
impedance, may span both negative and non-negative ranges. The
hyperparameter vector is confined within a specific hypothesis
space, i.e., ğœ½âˆˆH=[âˆ’ğµ,ğµ]ğ‘‘, for some constant ğµ>0.
In the context of CFs, a line failure is analogous to the activation
of a node in the IC model. Despite the complexity of failure propa-
gations in power grids, it is often assumed for analytical purposes
that the influence between elements is independent, simplifying
the study of transmission line interactions [20].
In summary, the primary distinctions between CFs in a power
grid and traditional IC settings include: (i) the influence graph for
CFs, unlike the physical grid of a power system, is conceptual and
initially viewed as a complete graph (due to non-contiguous events),
whereas a social networkâ€™s known topology serves as the influence
medium, and (ii) the influence probability matrix for CFs will be
linked to physical and topological features from the power grid, by
a hyperparametric model.
Recall that a cascade of failures in a power grid consists of a
sequence of sets of lines (V0,V1,...,VTğ‘˜)that fail at successive time
steps. Recall that the influence graph G(V,E)starts as a complete
one, where any node ğ‘¢âˆˆVğ‘˜,ğ‘¡can potentially influence any node
ğ‘£âˆˆVğ‘˜,ğ‘¡+1. From the independent cascading assumption, a set of
positive samplesS+
ğ‘˜ğ‘¡can be associated with each diffusion step,
defined as:
S+
ğ‘˜ğ‘¡={(ğ‘¢,ğ‘£)|ğ‘¢âˆˆVğ‘˜,ğ‘¡,ğ‘£âˆˆVğ‘˜,ğ‘¡+1},âˆ€ğ‘˜âˆˆK,âˆ€ğ‘¡âˆˆTğ‘˜.(2)
That is, in cascade ğ‘˜, eachğ‘£âˆˆVğ‘˜,ğ‘¡+1at timeğ‘¡+1is â€œactivatedâ€ due
to the set of nodes Vğ‘˜,ğ‘¡which became active at time ğ‘¡. Note that
anynodeğ‘¢âˆˆV ğ‘˜,ğ‘¡could have activated ğ‘£âˆˆV ğ‘˜,ğ‘¡+1, we have no
information on exactly which one, and we use this pairwise notation
to adhere to the standard notation where every node is atomic
and does not contain sets. For convenience, we sometimes abuse
notation and denote the positive samples as S+
ğ‘˜ğ‘¡={(Vğ‘˜,ğ‘¡,ğ‘£)|ğ‘£âˆˆ
Vğ‘˜,ğ‘¡+1},âˆ€ğ‘˜âˆˆK,âˆ€ğ‘¡âˆˆTğ‘˜.
This setup also implicitly includes a set Sâˆ’
ğ‘˜ğ‘¡ofnegative samples,
representing node pairs that do not influence each other within agiven time step:
Sâˆ’
ğ‘˜ğ‘¡={(ğ‘¢,ğ‘£)|ğ‘¢âˆˆVğ‘˜,ğ‘¡,ğ‘£âˆ‰Ãğ‘¡+1
ğœ=0Vğ‘˜,ğœ},âˆ€ğ‘˜âˆˆK,âˆ€ğ‘¡âˆˆTğ‘˜.(3)
Again, we sometimes abuse notation for convenience and write
the negative sample as Sâˆ’
ğ‘˜ğ‘¡={(Vğ‘˜,ğ‘¡,ğ‘£)|ğ‘£âˆ‰Ãğ‘¡+1
ğœ=0Vğ‘˜,ğœ},âˆ€ğ‘˜âˆˆ
K,âˆ€ğ‘¡âˆˆTğ‘˜.Letğ’”=(Vğ’”,ğ‘£)âˆˆS+
ğ‘˜,ğ‘¡be a positive sample, where
Vğ’”is the set of nodes that may influence ğ‘£in sample ğ’”. Based on
Eq.(1), the likelihood of a positive sample in one diffusion step, for
anyğ’”âˆˆS+
ğ‘˜ğ‘¡, is:
ğ‘ƒ(ğœ½|ğ’™,ğ’”)=1âˆ’Ã
ğ‘¢âˆˆV ğ’”(1âˆ’ğ‘ğ‘¢ğ‘£). (4)
For any negative sample ğ’”=(Vğ’”,ğ‘£) âˆˆ Sâˆ’
ğ‘˜,ğ‘¡, the likelihood is
1âˆ’ğ‘ƒ(ğœ½|ğ’™,ğ’”).
Estimator: Given this CF model, the traditional Maximum Like-
lihood Estimation (MLE) method can be applied to estimate the
hyperparameter. The idea is to maximize the likelihood between
the predictions of the hyperparametric model and the ground truth
of event data.
Based on Eq. (4), the likelihood of one diffusion step can be
formulated asÃ
ğ’”âˆˆS+
ğ‘˜ğ‘¡ğ‘ƒ(ğœ½|ğ’™,ğ’”)Ã
ğ’”âˆˆSâˆ’
ğ‘˜ğ‘¡(1âˆ’ğ‘ƒ(ğœ½|ğ’™,ğ’”)). Letğ‘¦=
IS+
ğ‘˜ğ‘¡(ğ’”)denote an indicator function which equals 1 if ğ’”âˆˆS+
ğ‘˜ğ‘¡, 0
otherwise. Then, the log-likelihood, known as the cross-entropy is:
ğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦)=ğ‘¦logğ‘ƒ(ğœ½|ğ’™,ğ’”)+(1âˆ’ğ‘¦)log(1âˆ’ğ‘ƒ(ğœ½|ğ’™,ğ’”)).(5)
LetS={(ğ’”,ğ‘¦)|ğ’”âˆˆS+
ğ‘˜ğ‘¡âˆªSâˆ’
ğ‘˜ğ‘¡,ğ‘¦=IS+
ğ‘˜ğ‘¡(ğ’”),ğ‘˜âˆˆK,ğ‘¡âˆˆTğ‘˜}denote
all the samples of the cascade events. Notice that the set of positive
samples isS+={ğ’”|(ğ’”,1)âˆˆS} and the set of negative samples is
Sâˆ’={ğ’”|(ğ’”,0)âˆˆS} .
Then, the expected log-likelihood over Scan be written as:
LS(ğœ½|ğ’™)=1
|S|âˆ‘ï¸
(ğ’”,ğ‘¦)âˆˆSğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦). (6)
Finally, the empirical estimator can be written as:
Ë†ğœ½=argmax
ğœ½âˆˆHLS(ğœ½|ğ’™). (7)
4 Learnability
In this section, we study the Probably Approximately Correct (PAC)
learnability [ 36,39] of our model, drawing on the theory of sample
complexity analysis [ 36] for the MLE approach. The log-likelihood
function family w.r.t. the cascading failure model, which is initially
part of an infinite hypothesis space, is transformed into a finite
hypothesis space using covering theory and Lipschitz continuity
analysis for the diffusion probability function. This transformation
allows us to examine the complexity more effectively. We examine
the conditional concavity of the empirical log-likelihood function,
which paves the way for applying Rademacher complexity to assess
the modelâ€™s sample complexity. Rademacher complexity is crucial
as it evaluates the expressiveness of a function class by its ability
to fit a hypothesis set to a random distribution, which is closely
linked to sample complexity [28].
Building on this foundation, we derive the sample complexity
for our model. Detailed proofs of these theoretical findings can be
found in the extended version of this paper [43].
Definition 4.1 (Agnostic PAC learnability [ 36,39]).
A hypothesis class His PAC learnable if, for any ğœ€,ğ›¿âˆˆ(0,1), and
3498Predicting Cascading Failures with a Hyperparametric Diffusion Model KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
for any distribution Dover the product space of examples Xand
labelsY, there exists a polynomial function ğ‘šHand a learning
algorithmA, such that whenAis run onâ‰¥ğ‘šH(ğœ€,ğ›¿)i.i.d. samples
fromD, it produces a hypothesis â„that, with probability â‰¥1âˆ’ğ›¿,
achieves a lossLD(â„)that is within ğœ€of the minimum possible
loss over all hypotheses in H.
Following [ 22,31], we assume that the influence probability ğ‘ğ‘¢ğ‘£
is restricted to the interval [ğœ†,1âˆ’ğœ†], whereğœ†âˆˆ(0,0.5)is a constant
that controls the precision of our estimates. W.l.o.g., we also assume
that each node in the network has at least one significant feature.
Together, these assumptions allow us to bound the magnitude of
the influence weights, which enables us to define the range of the
hypothesis spaceH.
We next analyze the Lipschitz continuity of the log-likelihood
function, based on its gradient:
âˆ‡ğœ½ğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦)=ğ‘¦
ğ‘ƒ(ğœ½|ğ’™,ğ’”)âˆ’1âˆ’ğ‘¦
1âˆ’ğ‘ƒ(ğœ½|ğ’™,ğ’”)
âˆ‡ğœ½ğ‘ƒ(ğœ½|ğ’™,ğ’”),(8)
where the gradient of ğ‘ƒw.r.t. ğœ½is given by:
âˆ‡ğœ½ğ‘ƒ(ğœ½|ğ’™,ğ’”)=âˆ‘ï¸
ğ‘¢âˆˆV ğ’”âˆ‡ğœ½ğ‘ğ‘¢ğ‘£Ã–
ğ‘¢â€²âˆˆV ğ’”\{ğ‘¢}(1âˆ’ğ‘ğ‘¢â€²ğ‘£). (9)
Previous work [22, 31] had established a relatively loose bound of
the Lipschitz continuity of ğ¿(Â·)w.r.t.â„“ğ‘-norm as follows:
âˆ¥âˆ‡ğ¿âˆ¥ğ‘=ğ‘¦
ğ‘ƒâˆ’1âˆ’ğ‘¦
1âˆ’ğ‘ƒâˆ¥âˆ‡ğ‘ƒâˆ¥ğ‘â©½max{1
ğ‘ƒ,1
1âˆ’ğ‘ƒ}Â·supâˆ¥âˆ‡ğ‘ƒâˆ¥ğ‘.
Based on the fact that âˆ¥âˆ‡ğ‘ğ‘¢ğ‘£âˆ¥âˆâ©½1,ğ‘ğ‘¢ğ‘£âˆˆ [ğœ†,1âˆ’ğœ†], and the
definition ofâˆ‡ğ‘ƒ(see Eq. (9)), we haveâˆ¥âˆ‡ğ‘ƒâˆ¥âˆâ©½ğ‘(1âˆ’ğœ†)ğ‘âˆ’1,
whereğ‘â©½|V|is the maximum number of active neighbor nodes.
From Eq. (4),ğ‘ƒ(ğœ½|ğ’™,ğ’”)âˆˆ[ğœ†,1âˆ’ğœ†ğ‘‰ğ’”], from which we can show
max{1
ğ‘ƒ,1
1âˆ’ğ‘ƒ}=1
ğœ†ğ‘. This leads to a loose Lipschitz bound ofğœŒ
ğœ†ğ‘,
whereğœŒ=ğ‘(1âˆ’ğœ†)ğ‘âˆ’1ğ‘âˆš
ğ‘‘. Note thatğœ†>0is a small value defining
the precision, e.g., 10âˆ’9. We derive a tighter bound in what follows.
Lemma 4.2. The log-likelihood function ğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦)is bounded
and(ğ‘‰ğ’”ğ‘âˆš
ğ‘‘log1
ğœ†)-Lipschitz w.r.t. â„“ğ‘-normâˆ€ğ‘â©¾1, whereğ‘‘=dim(ğ’™).
To examine the sample complexity of our model, we first investi-
gate whether the log-likelihood function is concave. The idea is that
if it is concave, then we can derive the sample complexity based
on optimization theory [ 36]. If not, then a canonical approach is
to utilize the Rademacher complexity framework. The following
lemma settles the question.
Lemma 4.3. The log-likelihood for one sample, i.e., ğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦),
is concave in ğœ½if the sample is either negative with ğ‘¦=0, or positive
withğ‘¦=1and|Vğ’”|=1,âˆ€ğ’”âˆˆS+. Otherwise, it is not concave.
It follows from Lemma 4.3 that, in general, the expected log-
likelihoodLS(ğœ½|ğ’™)overSis non-concave. More results on the
general and conditional concavity analysis can be found in the
extended version of this paper [43].
Given this, we resort to Rademacher bound theory to characterize
the sample complexity of our model [ 36]. LetFbe the family of
log-likelihood functions ğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦)on hypothesis ğœ½âˆˆH, defined
as:
Fdef={ğ‘“:(ğ’”,ğ‘¦)â†¦â†’ğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦)|ğœ½âˆˆH}.LetF(S) denote the set of vectors of likelihood values to which F
evaluates each sample in S, defined as:
F(S)def={[ğ‘“(ğ’”,ğ‘¦)]ğ’”,ğ‘¦âˆˆS|ğ‘“âˆˆF}.
We have the following lemmas.
Lemma 4.4 (Covering Number). LetNâˆ(ğœ€,F(S)) be the
â„“âˆ-normğœ€-covering number of F(S) , then
Nâˆ(ğœ€,F(S)) â©½&
ğµğ‘‰log1
ğœ†
ğœ€'ğ‘‘
, (10)
whereğ‘‰=maxğ’”âˆˆSğ‘‰ğ’”â©½|V|is the maximum number of activated
nodes.
Lemma 4.5 (Rademacher Bound). LetR(F(S)) denote the
Rademacher complexity of Fw.r.t.Swith sample size ğ‘š=|S|, then
R(F(S)) â©½ğ‘‰log1
ğœ†âˆšï¸‚
2 logNâˆ(ğœ€,F(S))
ğ‘š+ğœ€. (11)
LetLD(ğœ½|ğ’™)denote the expected log-likelihood on a hypoth-
esisğœ½âˆˆH w.r.t. the distribution Dover data(ğ’”,ğ‘¦)and a fixed
feature ğ’™, defined as:
LD(ğœ½|ğ’™)def=Eğ’”,ğ‘¦âˆ¼D[ğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦)]. (12)
Based on Lemmas 4.4 and 4.5, we have the following result.
Lemma 4.6 (Sample Complexity). For everyğœ€,ğ›¿âˆˆ(0,1)and
data distributionD, when running the MLE algorithm on â©¾ğ‘š(ğœ€,ğ›¿)
i.i.d. samples drawn from D, where
ğ‘š(ğœ€,ğ›¿)=O 
ğ‘‰2log21
ğœ†
ğœ€2 
ğ‘‘logğµğ‘‰log1
ğœ†
ğœ€+log1
ğ›¿!!
,
the algorithm returns a hypothesis Ë†ğœ½(i.e., Eq. (7)) that satisfies, w.p.
at least 1âˆ’ğ›¿,
supğœ½âˆˆHLD(ğœ½|ğ’™)âˆ’LD(Ë†ğœ½|ğ’™)â©½ğœ€. (13)
It immediately follows from Lemma 4.6 that the hypothesis for the
cascading failure model is PAC learnable.
5 Overall Solution
Section 4 establishes that the expected log-likelihood is in general
non-concave. The standard solution strategies for this type of prob-
lem include stochastic gradient descent (SGD) or a quasi-Newton
approach such as L-BFGS-B [ 4]. In our work, we adopt the latter,
as it offers faster convergence and can be more easily parallelized.
From a computational standpoint, the availability of an analytic
gradient enables us to accurately compute values for either the
entire dataset, or for large batches thereof in parallel. This com-
putation is facilitated by a GPU-accelerated workflow, designed
to leverage the structural properties of the gradient and of the
dataset. Specifically, observe that the gradient of the log-likelihood
functions mainly consists of terms such as ğ‘ƒ(ğœ½|ğ’™,ğ’”)and Ë†ğ’™ğ’”(ğœ½).
With ğœ½fixed in each iteration, the terms [ğ‘’ğœ½Tğ’™ğ‘¢ğ‘£]ğ‘¢ğ‘£âˆˆV2can be
pre-computed. The subsequent computation of the terms ğ‘ƒ(ğœ½|ğ’™,ğ’”)
and Ë†ğ’™ğ’”(ğœ½)involves simple operations such as summation or multi-
plication with ğ‘¢âˆˆVğ’”. Consequently, the gradient âˆ‡ğœ½ğ¿(ğœ½|ğ’™,ğ’”,ğ‘¦)
for individuals, as well as âˆ‡ğœ½LS(ğœ½|ğ’™)for entire sample set, can
be computed in parallel.
3499KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bin Xiang et al.
Moreover, as discussed in Sections 3 and 4, the interactions
within our model form a complete graph. For each cascade ğ‘˜âˆˆK,
a given sample((Vğ’”,ğ‘£),1)âˆˆS implies the existence of samples
{((V ğ’”,ğ‘£â€²),0)|ğ‘£â€²âˆˆV\V ğ’”âˆª{ğ‘£}}, for allğ‘£â€²s.t.((Vğ’”,ğ‘£â€²),1)âˆ‰S.
Therefore,|S|â©¾|K||V| . When accounting for the |V|âˆ’ğ‘›contin-
gencies cascading (see Section 3, ğ‘›â©¾1), the size of ğ‘†isO(|V|ğ‘›+1).
Despite the relative sparsity of samples, they can be efficiently en-
coded and aggregated using the sample key (Vğ’”,ğ‘£)into different
matrices for optimized storage and computation.
Algorithm 1 summarizes the overall workflow for learning a
Hyperparametric diffusion model for predicting Cascading Failures
(denoted HCF).
Algorithm 1 Learning workflow of HCF
Input: cascading failures, power grid topology and settings.
Output: predicted cascading failures.
1:Extract physical/topological features ğ’™from power grid
2:Encode samplesSand construct MLE optimization (see Eq. (7))
3:Run L-BFGS-B for MLE to learn the hyperparameter ğœ½
4:Compute diffusion probability matrix based on Eq. (1)
5:Run Monte Carlo simulations to predict cascading failures
6 Experiments
Our approach was implemented in Python using GPUs, with the
OpenCL standard1. The experiments were mainly performed on
a laptop Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz with 16 GB
memory (denoted L) and a server with AMD EPYC 7713 processor
and 128 GB memory (denoted S).
Datasets. Acquiring real-world cascading failure datasets in the
power systems community is challenging, due to privacy concerns
and confidentiality. Available data, such as the one used in [ 45],
often lacks crucial physical settings like power supply / demand,
while the topology can only be partially recovered from the cas-
cading traces. This limited information hinders the application of
parametric models that depend on it for reasoning.
Therefore, for our analysis, we leverage the IEEE300 standard
power grid (i.e, a 300Bus having 516transmission lines), which
offers comprehensive details like power supply / demand, line
impedance, capacities, and topology. This information facilitates
the extraction of the relevant physical features used in our learn-
ing process. Specifically, we extract 22basic features based on the
pre-cascading balanced power flow and grid topology.
To generate CF events, we leverage the widely used DCSep-
Sim [ 12] simulator. We simulate power flow and cascading pro-
cesses by strategically cutting lines, triggering power imbalances,
and rerouting flow. If overloaded lines exceed their capacity, outages
occur, cascading through the system until equilibrium is reached.
We generate 100k Monte Carlo traces per power grid instance, by
having each transmission line fail with a probability of 1/516.
A similar experiment on a dataset obtained from the larger Polish
grid is described in the appendix.
Validation and testing approach. Due to the stochastic nature of
our model, the traditional cross-validation and testing process can
not be directly applied. Instead, we propose a different validation
1Source code is available at https://github.com/unkux/Learn_CF.and testing process, relying on the IEEE300 standard power grid
and the DCSepSim simulations. Given an initial power grid con-
figuration, we apply perturbations on the power demand settings
or on the physical topology, to obtain a set of different power grid
instances. The model will be trained on only one of the power grid
instances, and tested on the others. In some of the experiments, the
initial power grid instance is close to saturation with respect to the
power supply / demand â€“ and thus more inclined to exhibit cas-
cading failures â€“ in order to observe the performance of the tested
methods under extreme conditions. Here we define 2subscript no-
tations, in the context of a each figure: ğ‘–ğ‘–for a model learned from
the instance ğ‘–and tested on that same instance, and ğ‘–1for a model
learned on instance 1in that figure and tested on instance ğ‘–. The
top 5% most critical transmission lines w.r.t. cascading failure size
were considered for the evaluation.
Evaluation metrics. Our evaluation focuses on two error types
related to predicting cascading failures. The first metric, Distribu-
tion Error (DE), compares the expected number of failures per line
across the actual DCSepSim simulations and the model-generated
cascades. For each line in the cascading failure dataset, we count the
failures. Then, using the trained model and Monte Carlo diffusions,
we generate new cascades and repeat the count on those simulated
lines. Finally, we compare the distributions of failure counts using
either mean absolute error or relative error.
The second metric, Probability Error (PE), is based on the prob-
ability matrix, and can only be applied for our hyperparametric
model. We stress that in the cascading failures data the interactions
between lines are only partially observed, i.e., given a cascading
sample(Vğ’”,ğ‘£), there is no information for which node ğ‘¢âˆˆVğ’”
triggered the activation of node ğ‘£. This means that simple frequency-
based estimation would lead to biased results due to over-counting,
hence ground truth influence probabilities are unavailable. To miti-
gate this issue, we define 3types of mean absolute / relative errors
(using the same subscript notation): ğ‘ƒğ‘–ğ‘–âˆ’ğ‘ƒğ‘–1for the prediction error,
ğ‘ƒğ‘–ğ‘–âˆ’ğ‘ƒ11for the probabilitiesâ€™ changes from instance ğ‘–to instance
1, andğ‘ƒğ‘–1âˆ’ğ‘ƒ11for the probabilitiesâ€™ changes when applying the
model learned on instance 1in the figure to instance ğ‘–.
Baseline methods. Recall that existing non-parametric approaches,
like [ 14,20,42], struggle with even slight changes in a power grid
(e.g., power demand or topology). Trained on data from a specific
grid instance, they lack generalizability and require retraining for
new instances. Due to this reliance on specific grid data, our method
offers an advantage under certain conditions. If the topology re-
mains fixed while other factors like power demand change, we can
directly compare our approach with the existing ones, by evalu-
ating their pre-trained models on unseen instances. However, if
the topology itself undergoes changes, adapting these models for
comparison on new instances becomes unfeasible.
In what follows, for a fixed topology incurring power demand
changes, we compare the performance of our approach with the
state-of-the-art Branching Process (in short, BP) method of [20].
A similar experiment involving another state-of-the-art method
[42] is described in the appendix.
6.1 Distribution of Cascades
We first compare the probability distribution and occurrence rate
of CFs in the original dataset (IEEE300 with demand factor 1).
3500Predicting Cascading Failures with a Hyperparametric Diffusion Model KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
12 5 102 510 âˆ’5 10 âˆ’4 10 âˆ’3 10 âˆ’2 10 âˆ’1 Data HCF BP
Cascading sizeProbability
(a) Probability distribution.
104
103
102
Occurrence rate (empirical)104
103
102
Occurrence rate (diffusion model) (b) Failure occurrence rate.
Figure 1: Probability distribution of cascades and failure oc-
currence rate (excluding initial failures) for IEEE300.
Fig. 1(a) shows the probability distribution of cascade sizes (num-
ber of failures) for (i) the cascades original CF data, (ii) the ones
simulated by our hyperparametric diffusion model, (iii) the ones
simulated by the BP approach. Note that the original data exhibits
an abnormal distribution, beginning with many small size cascades,
reaching a trough around size 10, and following with several small
peaks around size 20. Regarding the simulated data, both models
align well with the original data for small cascades, while for the
moderate and larger cascade, our model shows better prediction.
Fig. 1(b) compares the failure occurrence rate of lines (excluding
initial failures) in the original cascade dataset (empirical) and in our
hyperparametric diffusion model. Our prediction aligns well with
the dataset in the range of occurrence rate larger than 10âˆ’3, and
diverges moderately for the lower range, where are situated the
small cascading failures, which are more difficult to be predicted.
6.2 Model Generalization
We study in this section the generalization ability of our model
in the following directions. First, in Sec. 6.2.1, given the original,
standard IEEE300 power grid, and the CFs generated by the DCSep-
Sim simulator, we increase the user power demands of a specific
region in the grid to different levels â€“ moderate, heavy, or severe
â€“ and regenerate corresponding CFs. Note that the increasing fac-
tors remain in a range that ensures the resulting power system is
stable, i.e., works normally with a balanced power flow. Second, in
Sec. 6.2.2, from the CFs of the original grid, we pick the 10most
frequent lines therein, and remove each of them, one at a time, from
the original grid, to generate 10 new grids having a slightly different
physical topology; again, all these have a balanced power flow. The
rationale is that these lines can be seen as highly critical. We use a
similar subscript notation as before, in the context of each figure:
ğ‘–ğ‘–for a model learned from the instance ğ‘–and tested on that same
instance, and ğ‘–ğ‘—for a model learned on instance ğ‘—in that figure and
tested on instance ğ‘–.
6.2.1 Power demand changes. In Fig. 2, the power demands of
the original power grid instance in the region <20% quantile are
scaled from 1to10to produce 10different grid instances. When
the increasing factor is higher than 10, the power grid will not
work normally. Therefore, the settings we selected provide a coarse-
grained full-scope examination of performance by power demand.
The plots show the mean relative DEs and PEs of all lines.
Figs. 2(a) and 2(e) show respectively the mean relative DEs and
PEs for the full-scope demand change ( [1,10], with basis instance
1.0). First, in Fig. 2(a), when the demand factor <5.0, our testingresults show large relative errors; however, the corresponding ab-
solute errors in this region for all approaches are quite small (see
Appendix A) and the relative error in this case is less indicative of
performance as the values are relatively small. For the retraining
results, the performance is quite constant. Beyond the <5.0region,
the testing results are very similar, but the errors become quite
large. This is to be expected, since the power grid has experienced
large power demand changes. Indeed, it is challenging for the model
that is trained on the initial instance (1 .00) to capture a very â€œdis-
tantâ€ instance such as 10.0. As for the retraining results, when the
demand factor is in the region >5.0, our model achieves lower
relative errors (around 0.3) than BP, with a gap around 0.35. In
Fig. 2(e) â€“ mean relative PEs â€“ we can notice that ğ‘ƒğ‘–ğ‘–âˆ’ğ‘ƒğ‘–1, which is
an indicator of our model generalization capability, follows a similar
trend as with the DE values. Recall ğ‘ƒğ‘–ğ‘–âˆ’ğ‘ƒ11indicates the changes
in predicted probabilities when retraining on a different instance.
We can notice that the cascading behavior of the grid instances
indeed experience significant changes when the demand factor is in
the region <5.0. The model learned on the initial instance becomes
less applicable as the power demand changes.
Regarding the moderate demand changes (in the range [4,5]),
zoomed upon in Fig. 2(b) and 2(f), the basis instance for training is
moved to 4.0. The results show a different pattern compared with
the previous full-scope case. Now, prediction on other instances
becomes more accurate, as the power changes are less drastic. In
the region >4.2, all approaches have an error around 0.6, and show
a stable performance. For the retraining ( ğ‘–ğ‘–) results, our model has
relative errors around 0.2âˆ¼0.3, and performs better than BP, by
a margin of around 0.1(so around 50%). For the generalization
testing results ( ğ‘–1), our model shows similar performance as BP
(but outperforms it, by a margin of around 18%, in terms of mean
absolute error, see Appendix A). For the PEs, in Fig. 2(f), the pattern
is also rather different from the full-scope case. The results are
aligned with the corresponding failure distribution errors. One
conclusion we can draw here is that in practice it may be preferable
to retrain in different regions in the spectrum of power demand
changes, in order to have more robust / generalizable predictions.
In the region of heavy power demand changes (range [6,7]),
zoomed upon in Figs. 2(c) and 2(g), the general trend is again quite
different from the moderate case, showing a wave or step pattern.
This is most likely indicative of the complex behaviors of CFs as
the demand is changing. Regarding the DE metric, after retraining
at6.0, all models have a longer applicable range from 6.0to6.6. In
comparison, our model outperforms BP by a 0.2margin in average,
when testing generalizability ( ğ‘–1), and a 0.4margin when retrain-
ing (ğ‘–ğ‘–). Beyond point 6.6, there is again a large increase of errors.
Nevertheless, both our testing and retraining errors are lower than
the ones of BP. The PE values shown in Fig. 2(g) follow a similar
step pattern as the DE ones in Fig. 2(c).
Finally, moving to the severe demand changes (range [9,10]),
shown in Figs. 2(d) and 2(h), in contrast to the heavy case, the
error trends for all approaches become smoother. For Fig. 2(d), the
DEs present a Z-shape pattern. Our retraining ( ğ‘–ğ‘–) results are stable
around 0.28, while the testing ones ( ğ‘–1) increase smoothly up to
around 0.60. Both the absolute and relative PEs of the BP model stay
around 60%. Our model outperforms BP with a margin of around
0.35when retraining, resp. around 0.23when testing directly. The
3501KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bin Xiang et al.
1.00 3.00 5.00 7.00 9.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)BP (ii)
BP (i1)
(a) Failure distribution error
4.00 4.20 4.40 4.60 4.80 5.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)BP (ii)
BP (i1) (b) Failure distribution error
6.00 6.20 6.40 6.60 6.80 7.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)BP (ii)
BP (i1) (c) Failure distribution error
9.00 9.20 9.40 9.60 9.80 10.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)BP (ii)
BP (i1) (d) Failure distribution error
1.00 3.00 5.00 7.00 9.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11
(e) Probability error
4.00 4.20 4.40 4.60 4.80 5.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11 (f) Probability error
6.00 6.20 6.40 6.60 6.80 7.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11 (g) Probability error
9.00 9.20 9.40 9.60 9.80 10.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11 (h) Probability error
Figure 2: Mean relative error for line failure distribution and diffusion probability matrix (IEEE300 dataset).
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative errorHCF (ii)
HCF (ij)
BP (ii)
(a) Original grid
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative errorHCF (ii)
HCF (ij)
BP (ii) (b) Grid (L-85 removed)
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative errorHCF (ii)
HCF (ij)
BP (ii) (c) Grid (L-138 removed)
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative errorHCF (ii)
HCF (ij)
BP (ii) (d) Grid (L-141 removed)
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative errorHCF (ii)
HCF (ij)
BP (ii) (e) Grid (L-379 removed)
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pij
(f) Original grid
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pij (g) Grid (L-85 removed)
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pij (h) Grid (L-138 removed)
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pij (i) Grid (L-141 removed)
Org.568485104138140141170274379
Instance (grid topology)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pij (j) Grid (L-379 removed)
Figure 3: Training the model with CF data from one grid, testing on the others (IEEE300 dataset).
PEs in Fig. 2(h) remain lower than 0.4and lower than those observed
in the previous three cases. We believe that in this severe case, as
the demands increase towards the limit, the CF patterns converge
as well, leading to more stable performance.
One important conclusion from these three cases â€“ moderate,
heavy, or severe power demand changes â€“ is that the distribution
of CFs changes significantly; this leads to settings where the basic
assumption of Poisson offspring distribution (on which BP relies)
no longer holds, causing BPâ€™s decrease in performance. In contrast,
since our hyperparametric diffusion model learns to predict the
diffusion probabilities, and by extension the CFs, based on the
physical and topological features, it can capture the underlying
physics dynamics better than BPâ€™s non-parametric approach.
6.2.2 Topology changes. When changing the topology of the power
grid, by removing one transmission line, the state-of-the-art ap-
proaches cannot be applied without retraining (no ğ‘–ğ‘—cross train-test
experiment is possible). Therefore, only their retraining results ( ğ‘–ğ‘–)
can be obtained. In Fig. 3, we start from the original power grid(marked as â€œOrg.â€), each time removing one line (shown in x-axis)
and generate 10different power grids. In the figures, the value
marked in red refers to the training instance. In terms of retrain-
ing results, our model slightly outperforms BP, with error around
0.2-0.3. For testing results ( ğ‘–ğ‘—), our model has a general stable perfor-
mance around 0.3on an average. There are a few peaks appearing
for instances 56,140, and 274: when the model is trained based
on instance â€œOrg.â€, 85,138, or 379, the testing results on instance
56show a larger relative error, approximately in the range 0.6-0.8.
When the model is trained on instance 379, the test results show a
large error on instances 140and274.
6.3 Mitigating CFs
In this section, based on the diffusion probability matrix we learned,
we consider an initial attempt to mitigate the risks of CFs, by in-
creasing the capacity of certain nodes in our diffusion graph (i.e.,
transmission lines in the original power grid). In order to select the
lines to be consolidated, we apply the traditional IM algorithm CELF
3502Predicting Cascading Failures with a Hyperparametric Diffusion Model KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
(a) Physical graph.
 (b) Diffusion graph.
0 15 30 45 60
Cascade size02505007501000125015001750No. of cascadesBefore
After (c) Cascading failures reduction.
Figure 4: Physical graph of power grid, and the diffusion graph learned from the hyperparametric model, filtered with the
probability value ğ‘ğ‘¢ğ‘£â©¾0.01. Cascade failures before and after increasing the capacities of ten most critical branches (IEEE300
dataset).
[25] to retrieve the top 10seeds, corresponding in some sense to the
10most critical lines, their failure leading to the largest expected
cascade. We doubled the capacity of these lines, and re-simulate
the CFs in order to observe to which extent the CFs were mitigated.
Figures 4(a) and 4(b) illustrate respectively the physical grid
and the diffusion graph, along with the 10selected transmission
lines. They can be viewed as â€œdualâ€ graphs, where the edges in
Fig. 4(a) (marked in gray) correspond to nodes (marked in red) in
the diffusion graph. Recall that, in the power grid, nodes represent
load or generator buses. We can observe that the grid is sparse,
while the diffusion graph is rather dense (conceptually complete);
in our illustration, we filtered out the edges with ğ‘ğ‘¢ğ‘£â‰¤0.01.
We compare the distribution of cascade sizes, before and after
doubling the capacity of the selected 10seed nodes, in Fig. 4(c).
There is a clear effect of reduction in CFs for all size ranges (i.e.,
[0,15],[15,30],[30,45],[45,60], as the maximum cascade for this
power grid is of size 60). For each of these ranges, CFs are respec-
tively decreased by around 18%, 36%, 9%, and 75%. We interpret this
result as a promising one, and we intend to explore further options
for reducing the potential spread in the resulting diffusion graph.
6.4 Running Time
Running time is mainly influenced by two factors: the specific grid
instance and the size of the diffusion samples used for training.
Table 1 shows both the training and testing time for 3 instances
with power demand changes on the IEEE300 grid. It is important
to note that training for any method in this context is unlikely to
be real-time. HCFâ€™s training is much longer compared with BP,
when running on L. However, once our model is learned, it can be
directly applied when the grid changes; the other approaches need
to retrain the model on a new dataset, which requires a long time to
collect (or, in some cases, a new dataset might not even be available).
The ability to function effectively in new grid configurations is
crucial, as decisions about grid provisioning are time-sensitive.
This highlights once more the importance of model adaptation to
unseen grid configurations.
7 Conclusion
We present a new approach for predicting cascading failures in
power grids by integrating physical and topological features from
the grid into a hyperparametric model. Our methodology spans theTable 1: Training and testing time (seconds) per instance for
the IEEE300 grid on laptop (L) and server (S).
1.0 5.0 10.0
Train. Test. Train. Test. Train. Test.
HCF (L) 238 2 602 9 2521 16
BP (L) 10 15 27 38 63 84
HCF (S) 28 4 57 4 161 5
BP (S) 9 14 22 35 51 70
extraction of critical features, construction of a Maximum Likeli-
hood Estimation (MLE) optimization framework, and application of
the L-BFGS-B algorithm to learn the hyperparameters influencing
the diffusion of failures. The resulting diffusion probability matrix
is used to run Monte Carlo simulations, providing a robust pre-
dictive framework for cascading failures. In the future, we plan to
explore how real-time data from fluctuating grid conditions can be
integrated to dynamically adjust the predictive model.
Acknowledgments
This research is part of the programme DesCartes and is supported
by the National Research Foundation, Prime Ministerâ€™s Office, Sin-
gapore under its Campus for Research Excellence and Technological
Enterprise (CREATE) programme. Lakshmananâ€™s research was sup-
ported in part by a grant from NSERC (Canada).
References
[1]2021. 2021 Texas power crisis. https://en.wikipedia.org/wiki/2021_Texas_power_
crisis.
[2]Christian Borgs, Michael Brautbar, Jennifer Chayes, and Brendan Lucier. 2014.
Maximizing social influence in nearly optimal time. In Proceedings of the twenty-
fifth annual ACM-SIAM symposium on Discrete algorithms. SIAM, 946â€“957.
[3] Charlotte Borrvall, Bo Ebenman, and Tomas Jonsson Tomas Jonsson. 2000. Bio-
diversity lessens the risk of cascading extinction in model food webs. Ecology
Letters 3, 2 (2000), 131â€“136. https://doi.org/10.1046/j.1461-0248.2000.00130.x
[4]Richard H Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu. 1995. A limited
memory algorithm for bound constrained optimization. SIAM Journal on scientific
computing 16, 5 (1995), 1190â€“1208.
[5]Robert S Chen, Brendan Lucier, Yaron Singer, and Vasilis Syrgkanis. 2017. Ro-
bust optimization for non-convex objectives. Advances in Neural Information
Processing Systems 30 (2017).
[6]Eduardo Cotilla-Sanchez, Paul DH Hines, Clayton Barrows, and Seth Blumsack.
2012. Comparing the topological and electrical structure of the North American
electric power infrastructure. IEEE Systems Journal 6, 4 (2012), 616â€“626.
3503KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bin Xiang et al.
[7]Ian Dobson. 2012. Estimating the propagation and extent of cascading line
outages from utility data with a branching process. IEEE Transactions on Power
Systems 27, 4 (2012), 2146â€“2155.
[8]Ian Dobson, Benjamin A Carreras, Vickie E Lynch, and David E Newman. 2001.
An initial model for complex dynamics in electric power system blackouts. In
Proceedings of the 34th Annual Hawaii International Conference on System Sciences .
IEEE.
[9]Ian Dobson, Benjamin A Carreras, Vickie E Lynch, and David E Newman. 2007.
Complex systems analysis of series of blackouts: Cascading failure, critical points,
and self-organization. Chaos: An Interdisciplinary Journal of Nonlinear Science 17,
2 (2007).
[10] Pedro M. Domingos and Matthew Richardson. 2001. Mining the network value
of customers. In Proceedings of the seventh ACM SIGKDD international conference
on Knowledge discovery and data mining, San Francisco, CA, USA, August 26-29,
2001. 57â€“66.
[11] Nan Du, Yingyu Liang, Maria-Florina Balcan, and Le Song. 2014. Influence
Function Learning in Information Diffusion Networks. In Proceedings of the 31th
International Conference on Machine Learning, ICML 2014, Beijing, China, 21-
26 June 2014 (JMLR Workshop and Conference Proceedings, Vol. 32). JMLR.org,
2016â€“2024. http://proceedings.mlr.press/v32/du14.html
[12] Margaret J Eppstein and Paul DH Hines. 2012. A â€œrandom chemistryâ€ algorithm
for identifying collections of multiple contingencies that initiate cascading failure.
IEEE Transactions on Power Systems 27, 3 (2012), 1698â€“1705.
[13] Christophe Fraser, Steven Riley, Neil M Ferguson, Peter C Gandy, Thomas H
Ryan, Donald J Read, and et al. 2007. Tracking Ebola Epidemics with Big Data:
Algorithms and Insights. PLoS Med 4, 9 (2007), e311.
[14] Abdorasoul Ghasemi and Holger Kantz. 2022. Higher-order interaction learning
of line failure cascading in power networks. Chaos: An Interdisciplinary Journal
of Nonlinear Science 32, 7 (2022).
[15] Manuel Gomez-Rodriguez, Jure Leskovec, and Andreas Krause. 2010. Inferring
networks of diffusion and influence. In SIGKDD. 1019â€“1028.
[16] Amit Goyal, Francesco Bonchi, and Laks V. S. Lakshmanan. 2010. Learning
influence probabilities in social networks. In Proceedings of the Third International
Conference on Web Search and Web Data Mining, WSDM 2010, New York, NY, USA,
February 4-6, 2010. ACM, 241â€“250. https://doi.org/10.1145/1718487.1718518
[17] Xinran He and David Kempe. 2018. Stability and robustness in influence max-
imization. ACM Transactions on Knowledge Discovery from Data (TKDD) 12, 6
(2018), 1â€“34.
[18] Paul Hines, Karthikeyan Balasubramaniam, and Eduardo Cotilla Sanchez. 2009.
Cascading failures in power grids. IEEE Potentials 28, 5 (2009), 24â€“30.
[19] Paul Hines, Eduardo Cotilla-Sanchez, and Seth Blumsack. 2010. Do topological
models provide good information about electricity infrastructure vulnerability?
Chaos: An Interdisciplinary Journal of Nonlinear Science 20, 3 (2010), 033122.
[20] Paul DH Hines, Ian Dobson, and Pooya Rezaei. 2016. Cascading power outages
propagate locally in an influence graph that is not the actual grid topology. IEEE
Transactions on Power Systems 32, 2 (2016), 958â€“967.
[21] Dimitris Kalimeris, Gal Kaplun, and Yaron Singer. 2019. Robust influence max-
imization for hyperparametric models. In International Conference on Machine
Learning. PMLR, 3192â€“3200.
[22] Dimitris Kalimeris, Yaron Singer, Karthik Subbian, and Udi Weinsberg. 2018.
Learning diffusion using hyperparameters. In International Conference on Machine
Learning. PMLR, 2420â€“2428.
[23] David Kempe, Jon Kleinberg, and Ã‰va Tardos. 2003. Maximizing the spread of
influence through a social network. In Proceedings of the ninth ACM SIGKDD
international conference on Knowledge discovery and data mining. ACM, 137â€“146.
[24] R. Kinney, P. Crucitti, R. Albert, and V. Latora. 2005. Modeling cascading failures
in the North American power grid. The European Physical Journal B 46, 1 (July
2005), 101â€“107. https://doi.org/10.1140/epjb/e2005-00237-9
[25] Jure Leskovec, Andreas Krause, Carlos Guestrin, Christos Faloutsos, Jeanne M.
VanBriesen, and Natalie S. Glance. 2007. Cost-effective outbreak detection in
networks. In Proceedings of the 13th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, San Jose, California, USA, August 12-15,
2007. 420â€“429.
[26] Bo Li, Liejun Duan, Ligeng Fu, Shaohui Sun, Zhiqiang Li, and Ruoyu Wang. 2017.
Optimizing Traffic Signal Control Using Information Diffusion in Urban Traffic
Networks. IEEE Transactions on Intelligent Transportation Systems 18, 8 (2017),
2224â€“2236.[27] Yandi Li, Haobo Gao, Yunxuan Gao, Jianxiong Guo, and Weili Wu. 2023. A Survey
on Influence Maximization: From an ML-Based Combinatorial Optimization.
ACM Trans. Knowl. Discov. Data 17, 9, Article 133 (jul 2023), 50 pages. https:
//doi.org/10.1145/3604559
[28] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. 2018. Foundations
of machine learning. MIT press.
[29] Upama Nakarmi, Mahshid Rahnamay Naeini, Md Jakir Hossain, and Md Abul
Hasnat. 2020. Interaction graphs for cascading failure analysis in power grids: A
survey. Energies 13, 9 (2020), 2219.
[30] Harikrishna Narasimhan, David C. Parkes, and Yaron Singer. 2015. Learnability
of Influence in Networks. In Advances in Neural Information Processing Systems
28: Annual Conference on Neural Information Processing Systems 2015, December
7-12, 2015, Montreal, Quebec, Canada. 3186â€“3194. https://proceedings.neurips.cc/
paper/2015/hash/4a2ddf148c5a9c42151a529e8cbdcc06-Abstract.html
[31] Harikrishna Narasimhan, David C Parkes, and Yaron Singer. 2015. Learnability
of influence in networks. Advances in Neural Information Processing Systems 28
(2015).
[32] Romualdo Pastor-Satorras and Alessandro Vespignani. 2001. Epidemic Spreading
in Scale-Free Networks. Phys. Rev. Lett. 86 (Apr 2001), 3200â€“3203. Issue 14.
https://doi.org/10.1103/PhysRevLett.86.3200
[33] Mahshid Rahnamay-Naeini and Majeed M Hayat. 2016. Cascading failures in
interdependent infrastructures: An interdependent Markov-chain approach. IEEE
Transactions on Smart Grid 7, 4 (2016), 1997â€“2006.
[34] Michael Roth, Torsten Knuppel, Kevin Star, and Ignacio Perez-Arriaga. 2022.
Investigating the February 2021 Texas Blackouts: Understanding the Cascading
Failures that Led to Widespread Outages. Proc. IEEE 110, 6 (2022), 905â€“924.
[35] Kazumi Saito, Ryohei Nakano, and Masahiro Kimura. 2008. Prediction of Infor-
mation Diffusion Probabilities for Independent Cascade Model. In Knowledge-
Based Intelligent Information and Engineering Systems . Springer Berlin Heidelberg,
Berlin, Heidelberg, 67â€“75.
[36] Shai Shalev-Shwartz and Shai Ben-David. 2014. Understanding machine learning:
From theory to algorithms. Cambridge university press.
[37] Jiajia Song, Eduardo Cotilla-Sanchez, Goodarz Ghanavati, and Paul DH Hines.
2015. Dynamic modeling of cascading failure in power systems. IEEE Transactions
on Power Systems 31, 3 (2015), 2085â€“2095.
[38] Maurizio Titz, Franz Kaiser, Johannes Kruse, and Dirk Witthaut. 2022. Predicting
Dynamic Stability from Static Features in Power Grid Models using Machine
Learning. arXiv preprint arXiv:2210.09266 (2022).
[39] Leslie G Valiant. 1984. A theory of the learnable. Commun. ACM 27, 11 (1984),
1134â€“1142.
[40] Dirk Witthaut, Martin Rohden, Xiaozhu Zhang, Sarah Hallerberg, and Marc
Timme. 2016. Critical links and nonlocal rerouting in complex supply networks.
Physical review letters 116, 13 (2016), 138701.
[41] WSCC Operations Committee. 1996. Western Systems Coordinating Council
Disturbance Report For the Power System Outages that Occurred on the Western
Interconnection on July 2, 1996 and July 3, 1996.
[42] Xinyu Wu, Dan Wu, and Eytan Modiano. 2021. Predicting failure cascades in
large scale power systems via the influence model framework. IEEE Transactions
on Power Systems 36, 5 (2021), 4778â€“4790.
[43] Bin Xiang, Bogdan Cautis, Xiaokui Xiao, Olga Mula, Dusit Niyato, and Laks
V. S. Lakshmanan. 2024. Predicting Cascading Failures with a Hyperparametric
Diffusion Model. arXiv:2406.08522
[44] Wenwu Yu, Pietro DeLellis, Guanrong Chen, Mario di Bernardo, and JÃ¼rgen
Kurths. 2012. Distributed Adaptive Control of Synchronization in Complex
Networks. IEEE Trans. Automat. Control 57, 8 (2012), 2153â€“2158. https://doi.org/
10.1109/TAC.2012.2183190
[45] Kai Zhou, Ian Dobson, Paul DH Hines, and Zhaoyu Wang. 2018. Can an influence
graph driven by outage data determine transmission line upgrades that miti-
gate cascading blackouts?. In 2018 IEEE International Conference on Probabilistic
Methods Applied to Power Systems (PMAPS). IEEE, 1â€“6.
[46] Kai Zhou, Ian Dobson, Zhaoyu Wang, Alexander Roitershtein, and Arka P Ghosh.
2020. A Markovian influence graph formed from utility line outage data to
mitigate large cascades. IEEE Transactions on Power Systems 35, 4 (2020), 3224â€“
3235.
[47] Tianxin Zhou, Xiang Li, and Haibing Lu. 2021. Power Grid Cascading Failure
Prediction Based on Transformer. In International Conference on Computational
Data and Social Networks. Springer, 156â€“167.
3504Predicting Cascading Failures with a Hyperparametric Diffusion Model KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
1.00 3.00 5.00 7.00 9.00
Instance (demand factor)01234Mean absolute error1e4
HCF (ii)
HCF (i1)
BP (ii)
BP (i1)
(a) Distribution error
4.00 4.20 4.40 4.60 4.80 5.00
Instance (demand factor)0.20.40.60.81.0Mean absolute error1e4
HCF (ii)
HCF (i1)BP (ii)
BP (i1) (b) Distribution error
6.00 6.20 6.40 6.60 6.80 7.00
Instance (demand factor)0.51.01.52.02.53.0Mean absolute error1e4
HCF (ii)
HCF (i1)
BP (ii)
BP (i1) (c) Distribution error
9.00 9.20 9.40 9.60 9.80 10.00
Instance (demand factor)1.01.52.02.53.03.5Mean absolute error1e4
HCF (ii)
HCF (i1)
BP (ii)
BP (i1) (d) Distribution error
1.00 3.00 5.00 7.00 9.00
Instance (demand factor)0.00.20.40.60.81.01.2Mean absolute error1e2
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11
(e) Probability error
4.00 4.20 4.40 4.60 4.80 5.00
Instance (demand factor)0.00.51.01.52.02.5Mean absolute error1e3
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11 (f) Probability error
6.00 6.20 6.40 6.60 6.80 7.00
Instance (demand factor)02468Mean absolute error1e3
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11 (g) Probability error
9.00 9.20 9.40 9.60 9.80 10.00
Instance (demand factor)0.00.51.01.52.02.53.0Mean absolute error1e3
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11 (h) Probability error
Figure 5: Mean absolute error for line failure distribution and diffusion probability matrix (IEEE300 dataset).
1.00 1.10 1.20 1.30 1.40 1.50
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)
BP (ii)
BP (i1)
(a) Relative distribution error
1.00 1.10 1.20 1.30 1.40 1.50
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11 (b) Relative probability error
1.00 1.10 1.20 1.30 1.40 1.50
Instance (demand factor)1.01.21.41.61.8Mean absolute error1e5
HCF (ii)
HCF (i1)
BP (ii)
BP (i1) (c) Absolute distribution error
1.00 1.10 1.20 1.30 1.40 1.50
Instance (demand factor)01234Mean absolute error1e4
Piiâˆ’Pi1
Pi1âˆ’P11
Piiâˆ’P11 (d) Absolute probability error
Figure 6: Mean relative and absolute error for line failure distribution and diffusion probability matrix on Polish grid.
1.00 3.00 5.00 7.00 9.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)BP (ii)
BP (i1)MK (ii)
MK (i1)
(a) Distribution error
4.00 4.20 4.40 4.60 4.80 5.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)BP (ii)
BP (i1)MK (ii)
MK (i1) (b) Distribution error
6.00 6.20 6.40 6.60 6.80 7.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)BP (ii)
BP (i1)MK (ii)
MK (i1) (c) Distribution error
9.00 9.20 9.40 9.60 9.80 10.00
Instance (demand factor)0.00.20.40.60.81.0Mean relative error
HCF (ii)
HCF (i1)BP (ii)
BP (i1)MK (ii)
MK (i1) (d) Distribution error
Figure 7: Mean relative error for line failure distribution and diffusion probability matrix on IEEE300 grid (compared with MK).
A Additional Experimental Results
A.1 Other Experiments on the IEEE300 Dataset
Fig. 5 shows the mean absolute error for line failure distribution
and the diffusion probability matrix on the IEEE300 grid, comple-
menting the mean relative error results shown in Fig. 2, once again
evaluating the performance of the tested methods when the power
demand changes. The variation trend of the error is consistent with
the one in Fig. 2, and in all cases, HCF exhibits a better generaliza-
tion performance than the BP method.
A.2 Experiments on the Polish Grid
In the domain of power systems, the power grid network IEEE300
(300 nodes, 516 edges) is a relatively large physical network corre-
sponding to a metropolitan scale. To further evaluate the scalabilityof the compared methods, we expanded our experiments to test
with a larger power system, the Polish power grid (2383 nodes, 2896
edges), obtained from the open-source MATPOWER framework2.
To obtain the dataset of cascading failures, the grid simulator is
running up to 70h for generating 500K cascades per instance. Here
we generated 10 instances with the demand factor ranging from 1.0
to 1.5. Note that when the increasing demand factor is above 1.5 the
Polish power grid is over-saturated and cannot be balanced. Once
more, following the evaluation design of [ 20], only the most critical
transmission lines w.r.t. the cascading failures size were considered
for the evaluation (top 0.8% lines).
From Fig. 6, we can conclude that HCF has good predictive
performance on this larger dataset, and achieves better results
2https://matpower.org
3505KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bin Xiang et al.
Table 2: Sensitivity w.r.t. hyperparameter dimension.
Dimension\Instance 1.0 5.0 10.0
ğ‘‘=200 0.33 0.38 0.37
ğ‘‘=250 0.29 0.37 0.30
ğ‘‘=300 0.27 0.36 0.29
compared with BP. We would like to emphasize here that the errors
of both approaches are relatively large mainly due to the filtered
(critical) transmission lines on which the evaluation is done and
to the rather limited sample size relative to this increased network
scale.
A.3 Experiments with SOTA method MK [42]
Despite the common limitation of existing algorithms in dealing
with unseen configurations, for a more comprehensive evalua-
tion, we expand the experiments to include an additional method,
MK [ 42] (Fig. 7). It uses non-parametric regression to model the
cascading processes. The performance of MK oscillates a lot, andfor most instances, it exhibits on average poorer performance com-
pared with the other methods, whenever the cascading failures
distribution experiences significant changes as the demand factor
changes. When the demand factor is within [9,10](see Fig. 7(d)),
cascading failures are large but the change in cascading failures
distribution is small, thus MK performs better. Finally, training MK
takes longer (âˆ¼24h) and has a large memory footprint ( âˆ¼60GB) per
instance, as MK entails solving a large-size constrained nonlinear
optimization problem, and the testing time takes around 18 min
per instance3.
A.4 Sensitivity Analysis
The main ingredient of our diffusion model is the hyperparameter
vector, which is learned from data, where one controllable factor is
its dimension. To study sensitivity to the hyperparameterâ€™s dimen-
sion, we evaluated in one experiment the changes of mean relative
error when varying the dimension, as in Table 2.
3We stress that we could not run MK on the Polish grid, due to its large computation
time and memory requirements.
3506