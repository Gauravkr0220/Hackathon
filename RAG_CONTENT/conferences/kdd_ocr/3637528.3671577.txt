Beyond Binary Preference: Leveraging Bayesian Approaches for
Joint Optimization of Ranking and Calibration
Chang Liuâˆ—â€ 
isonomialiu@sjtu.edu.cn
Shanghai Jiao Tong University
Shanghai, ChinaQiwei Wangâˆ—
shimmerwang@tencent.com
Tencent, Shenzhen, ChinaWenqing Linâ€¡
edwlin@tencent.com
Tencent, Shenzhen, China
Yue Dingâ€¡
dingyue@sjtu.edu.cn
Shanghai Jiao Tong University
Shanghai, ChinaHongtao Lu
htlu@sjtu.edu.cn
Shanghai Jiao Tong University
Shanghai, China
ABSTRACT
Predicting click-through rate (CTR) is a critical task in recommen-
dation systems, where the models are optimized with pointwise
loss to infer the probability of items being clicked. In industrialpractice, applications also require ranking items based on theseprobabilities. Existing solutions primarily combine the ranking-based loss, i.e.,pairwise and listwise loss, with CTR prediction.
However,theycanhardlycalibrateorgeneralizewellinCTRsce-
narioswheretheclicksreflectthebinarypreference.Thisisbecausethebinaryclickfeedbackleadstoalargenumberofties,whichren-
ders high data sparsity. In this paper, we propose an effective data
augmentation strategy, named Beyond Binary Preference (BBP)training framework, to address this problem. Our key idea is to
breakthetiesbyleveragingBayesianapproaches,wherethebeta
distribution models click behavior as probability distributions in
thetrainingdatathatnaturallybreakties.Therefore,wecanobtain
an auxiliary training label that generates more comparable pairs
andimprovestherankingperformance.Besides,BBPformulates
rankingandcalibrationasamulti-taskframeworktooptimizeboth
objectives simultaneously. Through extensive offline experiments
and online tests on various datasets, we demonstrate that BBP sig-
nificantly outperforms state-of-the-art methods in both ranking
andcalibrationcapabilities,showcasingitseffectivenessinaddress-
ing the limitations of existing methods. Our code is available at
https://github.com/AlvinIsonomia/BBP.
CCS CONCEPTS
â€¢Information systems â†’Recommender systems.
âˆ—Both authors contributed equally to this research.
â€ This work was done while Chang Liu was an intern at Tencent.
â€¡Corresponding authors: Wenqing Lin and Yue Ding.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671577KEYWORDS
Click-throughrate prediction;Bayesianapproach; Ranking;Cali-
bration; Recommendation Systems
ACM Reference Format:
Chang Liu, Qiwei Wang, Wenqing Lin, Yue Ding, and Hongtao Lu. 2024.
Beyond Binary Preference: Leveraging Bayesian Approaches for Joint Op-
timization of Ranking and Calibration. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD â€™24),
August25â€“29,2024,Barcelona,Spain. ACM,NewYork,NY,USA,12pages.
https://doi.org/10.1145/3637528.3671577
1 INTRODUCTION
Click-throughrate (CTR)is theprobability ofa userclickingon a
recommended item. CTR prediction, which attempts to estimate
the CTR given a user-item impression accurately, is critical forachieving precise recommendations and increasing revenue forenterprises [
34,59]. Consequently, it plays a significant role in
recommendation systems, such as online advertising and in-game
player friend recommendations [18, 31, 32, 52, 55, 56, 61].
Inindustrialapplications,therearetwousecasesforCTRpre-
diction models: 1) forms an advertisement ranked list accordingto predicted CTR, and 2) calibrates click probabilities for down-
streamingrecommendationtasks.Forexample,insponsoredsearch,
thefinalpresentationtousersisarankedlistofads[ 27],andthe
calibrated scores produced is a required input for computing thecost-per-click (CPC)after ad impressions,which decides thepre-
sentationofanadbasedonathreshold[ 51].Therefore,thereisa
significant demand for a CTR prediction model that can align with
the actual click-through rate (i.e., calibration) and lead to a correct
ranking[43].Existingmethodscombinepairwiseandlistwisetrain-
ing in Learn-to-Rank (LTR) [ 7,33] with CTR predictions. Recent
works focus on enhancing ranking performance in CTR prediction
with pairwise and listwise methods. For example, Bayesian Person-
alized Ranking [ 40] and Smooth-AUC [ 47] leverage the pairwise
training.RegressionCompatibleRanking[ 3],ScaleCalibration[ 51],
andJointoptimizationofRankingandCalibration[ 44]furtherin-
troduce listwise loss to enhance the ranking performance.
Despite their reported success, they may fall into sub-optimal
duetothebinaryfeedback.Thekeyissueignoredisthat thebinary
feedbackleadstoalargenumberofties,whichconsequently
causesinsufficientfeasibletrainingpairs.SincetheLTRmethods
5442
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Chang Liu, Qiwei Wang, Wenqing Lin, Yue Ding, and Hongtao Lu
Figure1:Visualizationoftheratiooffeasiblepreferencepair
to all possible pairs. Since the preference feedback in the
CTR scenario is binary, the ratio of feasible pairs is strongly
affected by the positive item ratio and can be very sparse.
optimize models based on preference pairs ( e.g.,two items with dif-
ferentpreferencesforthesameuser),thepositiveratiowillstrongly
affect the number of feasible training pairs. We present a toy ex-
ample in Figure 1 with ğ‘items to better illustrate the situation.
Under the best condition, only half of the/parenleftbigğ‘
2/parenrightbigpossible pairs can be
constructed as the preference pairs, with the positive-item ratio be-ing50%.Furthermore,thepositivefeedback(userclicks)inthereal
world is highly sparse. For example, if only 10% are positive items,
there will be only 18% feasible pairs. Therefore, binary preference
restricts the effectiveness of existing methods for CTR predictions.
To address this issue, we propose the Beyond Binary Preference
(BBP) training framework. Our key idea is to augment training
labelswithcontinuousBayesianprobabilitytobreaktheties.We
treat the historical records as an observation sequence of Bernoulli
trails and calculate the estimated probability score for all users and
items through Bayesian smoothing [ 42]. Afterward, we combine
the probability score and binary feedback to break the ties andoptimize the model. Since the prior ranking score is continuous
ratherthanbinary,morepreferencepairsareconstructed,which
addresses the data sparsity caused by binary feedback. For jointoptimization of ranking and calibration. In particular, we designa multi-task learning framework with a global context ranking
lossthatreusesthearbitraryuser-itempairsinthesamebatchtoaugmentmorepreferencepairs.Extensiveofflineexperiments on
three public benchmark datasets and online A/B testing on two
real-world scenarios demonstrate that our BBP framework outper-
forms the state-of-the-art (SOTA) competitors in both ranking and
calibration capabilities.
Contributions. The contributions of our paper include:
â€¢To the best of our knowledge, we are the first to identify and ad-
dress the problem of insufficient samples for ranking loss caused
by binary preference feedback in CTR prediction.
â€¢We propose the Beyond Binary Preference (BBP), which models
andestimatesapersonalizedbetadistributiontoeachuserand
item in the training set with Bayesian methods. BBP further
generatesacontinuouslycomparablerankingscorelabeltobreak
the ties caused by the binary preference feedback.â€¢WedemonstratetheeffectivenessoftheBBPframeworkthrough
extensiveofflineexperimentsandonlineA/Btests.BBPoutper-
formsallSOTAcompetitorssignificantly( ğ‘-value<0.05)inboth
calibrationandrankingmetricsonthreepublicbenchmarks.The
deployedBBPbasedrecommendationmodulesincreaseatleast
10.28% more friends in two Tencent online games than competi-
tors relatively.
2 RELATED WORK
2.1 CTR Prediction
Pointwise training and calibration. CTR prediction usually op-
timizes the models with the Binary Cross Entropy (BCE) loss func-
tion; therefore its prediction scores strictly calibrate click proba-
bilities that an item on a website (such as an advertisement) willbe clicked [
13,38]. Existing methods study various model archi-
tectures for more accurate CTR prediction, including statistical
methods[ 12,48],logisticregression[ 36,41],factorizationmachines
[23,39],andDNNs-basedCTRmodels[ 8,14,15,20,29,59].How-
ever, pointwise training suffers from limited ranking performance,
resulting in sub-optimal recommendation outcomes. It is worth
mentioning that the calibration ability of CTR models can be con-
fused with a different research topic called â€œuncertainty calibra-
tionâ€ [9,25]. In uncertainty calibration, the focus is on confidence
estimates rather than calibrating the modelâ€™s output with click
probabilities.
Ranking-basedCTRprediction .Inindustrialapplications,the
rankingabilityofCTRmodelsisalsocrucial[ 13,33],asweneed
to provide an advertisement ranked list for down-streaming rec-
ommendationtasks.RecentworkhasdemonstratedthattheCTR
models trained with pointwise loss suffer from limited rankingperformance [
3,44,47,51] due to a lack of preference ordering
information during the training. To address this issue, researchers
have proposed various pairwise and listwise approaches, which
differ from pointwise methods in that they directly optimize rank-
ing objectives. Pairwise methods compare pairs of items, while
listwisemethodsconsidertheentireimpressionlistofitemsforthe
user. These approaches aim to directly optimize ranking metrics
such as AUC (Area Under the Curve) [ 11] and NDCG (Normalized
Discounted Cumulative Gain) [ 21]. Bayesian Personalized Ranking
(BPR) [40] optimizes the order of pairs of positive and negative
items. Smooth-AUC (SAUC) loss introduces a smooth approxima-
tionofAUCusingasigmoidfunction.Thoughadvancedranking
lossesmayproducesignificantlybetterrankingperformance,the
training instability issues prohibit their usage in the CTR predic-
tions,asthescoresmaykeepdriftingduringmodeltraining[ 6,51].
Thiswillcausenumericalfailuresinreal-worldlargescalelearn-
ing systems, especially under the continual learning paradigm. For
example,onehastomodifythethresholdinCPCtokeepupwith
the temporal dynamics of systems updates.
Jointoptimizationofrankingandcalibration.TrainingCTR
models that can rank and calibrate well has been extensively stud-
iedinthelastdecades[ 3,44,51].RegressionCompatibleRanking
(RCR)[3]achievesatrade-offbetweenranking(ListNet[ 50])and
calibratedregression(BCE)ratherthanpost-processingmethods
5443Beyond Binary Preference: Leveraging Bayesian Approaches for Joint Optimization of Ranking and Calibration KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
[37]. Scale Calibration (SC) [ 51] performs scale calibration of rank-
ingmodelsbyintroducingatrainableparameterinthesoftmaxloss,
addressingtraininginstabilityissues.JointoptimizationofRanking
andCalibration(JRC)[ 44]simultaneouslyoptimizesrankingand
calibration abilities by contrasting the logit value for samples with
different labels and constraining the predicted probability as the
logit subtraction. However, they overlooked the data sparsity due
to the ubiquitous ties (i.e., pairs with the same label will not be
used for training). In this paper, we propose the Beyond Binary
Preference(BBP)trainingframeworktoaddressthelimitationsofranking-based CTR training further.
2.2 Learning-to-rank with Ties
Learning-to-rank with ties has been a focus of research as it ad-dresses the issue of instances having nearly identical degrees of
relevance,referredtoasâ€˜tiesâ€™[ 5].Therearetwolinesofresearch
to make full use of ties. One option is to force the model to output
similar predictions for items with the same label. Examples of this
approach include designing an extra loss function for the samerelevance [
60], re-ranking items with a given pairwise relevance
threshold [ 57], and using a hashing function for tie-aware ranking
[17], among others. The other option, in contrast, is to break the
tiesduring training by ensuring that no equal relevance exists. For
instance,uRank[ 62]overcomesthetieissueofexistingPlackett-
Luce models by maximizing the likelihood of selecting documents
with high ratings over documents with low ratings. Savant [ 26]
randomlyassignsthesamerelevancetodifferentlabelsusingdif-
ferent random seeds. However, existing methods fall short in CTR
predictiontaskswhentherelevanceisbinary.AsshowninFigure1,
the number of ties is almost always greater than the number of
comparablepreferencepairs.Thehighdatasparsitygreatlyrestricts
theeffectivenessofexistingmethods.OurBBPmethodleverages
Bayesianprobabilitiestotransformbinarylabelsintocontinuous
scores, effectively breaking the ties in CTR prediction.
3 PRELIMINARIES
3.1 CTR Prediction
LetDbe an impression dataset. In CTR prediction, typically, each
sample in Dconsists of examples represented as tuples (ğ‘¢,ğ‘£,ğ‘¦ğ‘¢,ğ‘£),
whereğ‘¢âˆˆUbeauserID, ğ‘£âˆˆVbeanitemID,and ğ‘¦ğ‘¢,ğ‘£âˆˆ{0,1}
is the binary preference label, i.e.,user clicks. The CTR prediction
modelğ‘“aims to assign a score ğ‘ to a user item pair (ğ‘¢,ğ‘£)given
its feature vector xğ‘¢,ğ‘£,i.e.,ğ‘ ğ‘¢,ğ‘£=ğ‘“(xğ‘¢,ğ‘£). The output ğ‘ indicates
thelikelihoodthatuser ğ‘¢willclickitem ğ‘£.Themodel ğ‘“isusually
optimized from the following two aspects.
Calibration.Traditionally,thecalibratedCTRmodelislearnedand
evaluatedwithbinarypreferenceinthepointwisesetting[ 3,44].
The loss function in learning is defined on a single data point xğ‘¢,ğ‘£
of each user-item pair in dataset D. Formally, the empirical risk
function of calibration Lcalis defined as:
Lcal=/summationdisplay.1
(ğ‘¢,ğ‘£,ğ‘¦ğ‘¢,ğ‘£)âˆˆDâ„“cal/parenleftbigğœ(ğ‘ ğ‘¢,ğ‘£),ğ‘¦ğ‘¢,ğ‘£/parenrightbig, (1)
whereğ‘ ğ‘¢,ğ‘£=ğ‘“(xğ‘¢,ğ‘£),ğœis the sigmoid function, ğ‘¦ğ‘¢,ğ‘£is the bi-
nary preference feedback for user item pair (ğ‘¢,ğ‘£),â„“cal(ğ‘ ğ‘¢,ğ‘£,ğ‘¦ğ‘¢,ğ‘£)
denotesapointwiselossfunctionbasedonabinaryclassification 
	




	

	



	
		

	 





	


Figure 2: The graphical model of the CTR, where shaded
variables (impression ğ¼and click ğ¶) are observable.
measure[ 16].Inthisway,thepredictionofthemodel ğ‘“indicates
click probability.
Ranking . As discussed above, industrial applications also leverage
predictionscore ğ‘“(ğ‘¢,ğ‘£)torankthecandidateitems.TheCTRmodel
ğ‘“is still defined on a user-item pair (ğ‘¢,ğ‘£), and the loss function
is defined on two data points xğ‘¢,ğ‘£andxğ‘¢,ğ‘£/primethat can formulate
preference judgement pairs [58].
Definition1(preferencejudgementpair). Formally,given
two items ğ‘£andğ‘£/primeto the same user ğ‘¢, a preference judgement pair
isdefinedas: (ğ‘¢,ğ‘£)/follows(ğ‘¢,ğ‘£/prime),whereğ‘¦ğ‘¢,ğ‘£isgreaterthan ğ‘¦ğ‘£,ğ‘£/prime.Inthe
contextofbinarypreference,itmeans ğ‘£istheclickeditem,and ğ‘£/primeis
unclicked by the user ğ‘¢.
Therefore, the empirical risk function Lrankis defined as:
Lrank=/summationdisplay.1
/angbracketleft(ğ‘¢,ğ‘£)/follows(ğ‘¢,ğ‘£/prime)/angbracketrightâ„“rank/parenleftBig
ğ‘ ğ‘¢,ğ‘£,ğ‘¦ğ‘¢,ğ‘£,ğ‘ ğ‘¢,ğ‘£/prime,ğ‘¦ğ‘¢,ğ‘£/prime/parenrightBig
,(2)
whereâ„“rank/parenleftBig
ğ‘ ğ‘¢,ğ‘£,ğ‘¦ğ‘¢,ğ‘£,ğ‘ ğ‘¢,ğ‘£/prime,ğ‘¦ğ‘¢,ğ‘£/prime/parenrightBig
denotes a pairwise loss function.
As the labels are binary, i.e.,click or not click, there will be a large
number ofties, as mentioned inSection 1. As tiescannot perform
preference judgments, existing methods usually drop them during
the training, which may lead to sub-optimal.
Inthiswork,weaddressthislimitationbybringinganaugmented
label to break the ties. Specifically, we model the click behaviors
andusetheoverallhistoricalCTRaspriorprobabilities.Withmore
impressionsobservedinthechronicsequence,wegraduallyupdate
user-item pair posterior probabilities with Bayesian Smoothing as
the augmented label.
3.2 Click Behavior Modeling
OurclickbehaviormodelisshowninFigure2:whenauserreceivesanimpression ofan item,theuser decidesto clickor notaccording
to his/her interest. Considering the binary nature of the click be-
havior, we treat each user-item impression as a Bernoulli trial withanunderlyingprobability
ğ‘Ÿ,i.e.,ğ¶âˆ¼Binomial(ğ¼,ğ‘Ÿ).Inaddition,the
underlying probability ğ‘Ÿthat a user clicks an item follows a beta
distribution, i.e.,ğ‘Ÿâˆ¼Beta(ğ›¼,ğ›½).
Wechoosethebetadistributionbecauseitcanrepresentavariety
ofdistributions,whichhasbeenwidelyappliedtomanydifferent
settings[22,24].Despitethewideapplicability,thebetadistribution
onlyhastwoparameters: ğ›¼>0andğ›½>0.Itsprobabilitydensity
5444KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Chang Liu, Qiwei Wang, Wenqing Lin, Yue Ding, and Hongtao Lu
function (PDF) is defined as:
PDF(ğ‘¥;ğ›¼,ğ›½)=ğ‘¥ğ›¼âˆ’1(1âˆ’ğ‘¥)ğ›½âˆ’1
ğµ(ğ›¼,ğ›½), (3)
where the normalization factor, ğµ(ğ›¼,ğ›½)=âˆ«1
0PDF(ğ‘¡;ğ›¼,ğ›½)ğ‘‘ğ‘¡,i st h e
complete regularized beta function that ensures that the PDF inte-
grates into one. It models the likelihood function of the parameter
underlyingaBernoullitrail,where ğ›¼âˆ’1isthenumberofsuccesses
(click)and ğ›½âˆ’1isthenumberoffailures.Foranintuitiveunder-
standing,intheCTRpredictions,itmeans ğ›¼+ğ›½âˆ’2impressionsfor
auser-itempairwhere ğ›¼âˆ’1clicksand ğ›½âˆ’1unclicksareobserved.
Iftheclick probabilityoftheuser-item pairis ğ‘Ÿ,theprobability of
theaboveobservationswouldbeproportionalto ğ‘Ÿğ›¼âˆ’1(1âˆ’ğ‘Ÿ)ğ›½âˆ’1.
Themeanofthedistribution ğœ‡isdeterminedbytheratio ğ›¼andthe
sumğ›¼+ğ›½, where an ğ›¼higher than the ğ›½means that the mean is
closer to 1 than to 0, and vice versa. We further have:
E[ğ‘Ÿ]=ğœ‡=ğ›¼
ğ›¼+ğ›½, (4)
whereE[ğ‘Ÿ]reflects the expectation of the click probability for the
user-item pair. The conjugacy between Binomial and Beta enables
ustoestimatetheusersâ€™preferenceateachtimeperiodgiventhe
historical observations with Bayesian approaches. The distribu-
tion of the click observations related to the underlying preference
distributioncanthenbeexpressedassmoothingthepersonalized
distribution from the empirical prior distribution, which will be de-
scribedinEq.(8)indetail.Inthefollowingsection,wewillleverage
thepersonalizeddistributionsastheaugmentlabelstobreakthe
ties and address the data sparsity caused by the binary preference.
4 METHODOLOGY
Ourgoalistoestimateacontinuousaugmentrankingscoretobreak
theubiquitousbinaryties.WefirstleverageBayesiansmoothing
to estimate the Bayesian probabilities according to the historicalobservations in Sec. 4.1. Furthermore, we combine the estimatedprobabilities with binary labels as augmented preference scores,
whichenablesustoextendthepreferencejudgmentpairsdefini-
tion in Sec. 4.2. Since the augmented score is continuous, it breaks
the ties from binary labels. Finally, we jointly optimize the rank-ingandcalibrationinamultitasklearningframeworkinSec.4.3.
Specifically, we design a global context ranking loss that compares
arbitrary user-item pairs instead of items for the same user, which
improves the model performance further.
4.1 Learning Beta Distribution for Click
Inference
WiththebehaviormodelinginSec.3.2,weaimtoestimatethebeta
distribution for the user behavior, which is used as the augmentlabel with Bayesian approaches. The main idea is to arrange the
historical datachronologically andgradually update thepersonal-
izedbetadistributionforeachuser(item)withBayesiansmoothing
from an initial distribution.
Dataformulation. Astheuserâ€™sfeedbackisgraduallycollected
fromtheCTRsystemsâ€™onlineservingprocess,itnaturallyforms
a Bernoulli trial sequence. Let Vğ‘¢={ğ‘£|(ğ‘¢,ğ‘£,ğ‘¦)âˆˆD }be the in-
teracted item set of user ğ‘¢induced by D. Similarly, we can alsodenoteUğ‘£={ğ‘¢|(ğ‘¢,ğ‘£,ğ‘¦)âˆˆD }as the interacted user set for item
ğ‘£. Admittedly, in click behavior modeling, the click rate ğ‘Ÿshould
dependonthespecificuser-itempair.Unfortunately,historicaldata
is often very sparse (i.e., a userğ‘¢always has only been exposed
toafewitemsintheentireitemset V).Thismakesitdifficultto
estimatethebetadistributionforeachuser-itempair.Therefore,we
estimate the click probability distribution for each user ğ‘¢and each
itemğ‘£independently. Intuitively, this can be understood as model-
ingwhetherauserismorewillingtoclickonitemsandwhether
an item is more attractive for users to click on.
Given the collected dataset D, we first reorganize it chronically
basedonğ¾periodsoftime, i.e.,D={D1,D2,Â·Â·Â·,Dğ¾},wherethe
Dğ‘˜is the sub-dataset of the ğ‘˜-th period. The period here can be a
period of time (such as a day or a week), or in extreme cases, it can
be each timestamp. Without loss of generalization, the methodsfor modeling users and items are the same. Therefore, we only
introducethe clickprobabilitydistribution estimationof theitem
in detail here. Let ğ¼ğ‘£=/parenleftBig
ğ¼ğ‘£
1,ğ¼ğ‘£
2,Â·Â·Â·,ğ¼ğ‘£
ğ¾/parenrightBig
be a sequence of impression
sequence for item ğ‘£with length ğ¾, andğ¶ğ‘£=/parenleftBig
ğ¶ğ‘£
1,ğ¶ğ‘£
2,Â·Â·Â·,ğ¶ğ‘£
ğ¾/parenrightBig
be a sequence of clicks for item ğ‘£. Hereğ¼ğ‘£
ğ‘˜=|(ğ‘¢,ğ‘£,ğ‘¦ğ‘¢,ğ‘£)|, where
(ğ‘¢,ğ‘£,ğ‘¦ğ‘¢,ğ‘£)âˆˆDğ‘˜, andğ¶ğ‘£
ğ‘˜=/summationtext.1
(ğ‘¢,ğ‘£,ğ‘¦ğ‘¢,ğ‘£)âˆˆDğ‘˜ğ‘¦ğ‘¢,ğ‘£. Next, we detail
how to leverage the arranged sequence to update the personalized
beta distribution for item ğ‘£.
Initializing the beta distribution. In real applications, to obtain
amoreaccurateestimation,especiallyfortheusers/itemswithrarehistoricalimpressionrecords,wecaninitializethebetadistribution
by learning from all the historical data.
Let Beta( ğ›¼0,ğ›½0) denote the initialized beta distribution as the
prior distribution for all items. The ğ›¼0is the average click number
amongallitems,and ğ›½0istheaverageunclickedimpressionnumber.
Then the initialized distribution is given by:
ğ›¼0=1
|V|/summationdisplay.1
ğ‘£âˆˆV/summationdisplay.1
ğ‘¢âˆˆUğ‘£ğ‘¦ğ‘¢,ğ‘£,ğ›½0=1
|V|/summationdisplay.1
ğ‘£âˆˆV/summationdisplay.1
ğ‘¢âˆˆUğ‘£(1âˆ’ğ‘¦ğ‘¢,ğ‘£),(5)
where|V|the number of item and Uğ‘£={ğ‘¢|(ğ‘¢,ğ‘£,ğ‘¦)âˆˆD }is the
interactedusersetforitem ğ‘£.Notethatitâ€™sbettertousethedatasets
fromD0wherethe0-thperiodmeansthatallavailablehistorical
impressions before D1. However, if the D0is unavailable, we can
simply leverage the statistics from current D.
Updating thepersonalized distribution. Given thebeta distri-
butionBeta(ğ›¼ğ‘£,ğ›½ğ‘£),wecanderivethelikelihoodthatweobserve
click sequence ğ¶ğ‘£
ğ‘˜given the impression sequence for ğ¼ğ‘£
ğ‘˜as:
ğ‘ƒ(ğ¶ğ‘£|ğ¼ğ‘£;ğ›¼ğ‘£,ğ›½ğ‘£)=ğ¾/productdisplay.1
ğ‘˜=1Î“(ğ›¼ğ‘£+ğ›½ğ‘£)
Î“/parenleftBig
ğ¼ğ‘£
ğ‘˜+ğ›¼ğ‘£+ğ›½ğ‘£/parenrightBigÎ“/parenleftBig
ğ›¼ğ‘£+ğ¶ğ‘£
ğ‘˜/parenrightBig
Î“(ğ›¼ğ‘£)Î“/parenleftBig
ğ¼ğ‘£
ğ‘˜âˆ’ğ¶ğ‘£
ğ‘˜+ğ›½ğ‘£/parenrightBig
Î“(ğ›½ğ‘£),
(6)
wherethe Î“(Â·)isthegammafunction[ 2].Toinvestigatewhatisthe
optimalğ›¼ğ‘£,ğ›½ğ‘£, we take the partial derivatives of the log-likelihood
function with respect to ğ›¼ğ‘£andğ›½ğ‘£as:
5445Beyond Binary Preference: Leveraging Bayesian Approaches for Joint Optimization of Ranking and Calibration KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
ğ‘‘logğ‘ƒ(ğ¶ğ‘£|ğ¼ğ‘£;ğ›¼ğ‘£,ğ›½ğ‘£)
ğ‘‘ğ›¼ğ‘£=ğ¾/summationdisplay.1
ğ‘˜=1[ğœ“(ğ›¼ğ‘£+ğ›½ğ‘£)âˆ’ğœ“/parenleftBig
ğ¼ğ‘£
ğ‘˜+ğ›¼ğ‘£+ğ›½ğ‘£/parenrightBig
+ğœ“/parenleftBig
ğ›¼ğ‘£+ğ¶ğ‘£
ğ‘˜/parenrightBig
âˆ’ğœ“(ğ›¼ğ‘£)],
ğ‘‘logğ‘ƒ(ğ¶ğ‘£|ğ¼ğ‘£;ğ›¼ğ‘£,ğ›½ğ‘£)
ğ‘‘ğ›½ğ‘£=ğ¾/summationdisplay.1
ğ‘˜=1[ğœ“(ğ›¼ğ‘£+ğ›½ğ‘£)âˆ’ğœ“/parenleftBig
ğ¼ğ‘£
ğ‘˜+ğ›¼ğ‘£+ğ›½ğ‘£/parenrightBig
+ğœ“/parenleftBig
ğ¼ğ‘£
ğ‘˜âˆ’ğ¶ğ‘£
ğ‘˜+ğ›½ğ‘£/parenrightBig
âˆ’ğœ“(ğ›½ğ‘£)],(7)
whereğœ“(ğ‘¥)=Î“/prime(ğ‘¥)
Î“(ğ‘¥)is the Psi (digamma) function which can be
calculated quickly with Bernardoâ€™s algorithm [4].
Usingthefixed-pointiterationmethod[ 49],wecanderivethe
update formulas for ğ›¼ğ‘£andğ›½ğ‘£forğ‘iterations:
ğ›¼ğ‘£
ğ‘›=ğ›¼ğ‘£
ğ‘›âˆ’1/summationtext.1ğ¾
ğ‘˜=1/bracketleftBig
ğœ“/parenleftBig
ğ›¼ğ‘£
ğ‘›âˆ’1+ğ¶ğ‘£
ğ‘˜/parenrightBig
âˆ’ğœ“(ğ›¼ğ‘£
ğ‘›âˆ’1)/bracketrightBig
/summationtext.1ğ¾
ğ‘˜=1/bracketleftBig
âˆ’ğœ“(ğ›¼ğ‘£
ğ‘›âˆ’1+ğ›½ğ‘£
ğ‘›âˆ’1)+ğœ“/parenleftBig
ğ¼ğ‘£
ğ‘˜+ğ›¼ğ‘£
ğ‘›âˆ’1+ğ›½ğ‘£
ğ‘›âˆ’1/parenrightBig/bracketrightBig,
ğ›½ğ‘£
ğ‘›=ğ›½ğ‘£
ğ‘›âˆ’1/summationtext.1ğ¾
ğ‘˜=1/bracketleftBig
ğœ“/parenleftBig
ğ¼ğ‘£
ğ‘˜âˆ’ğ¶ğ‘£
ğ‘˜+ğ›½ğ‘£
ğ‘›âˆ’1/parenrightBig
âˆ’ğœ“(ğ›½ğ‘£
ğ‘›âˆ’1)/bracketrightBig
/summationtext.1ğ¾
ğ‘˜=1/bracketleftBig
âˆ’ğœ“(ğ›¼ğ‘£
ğ‘›âˆ’1+ğ›½ğ‘£
ğ‘›âˆ’1)+ğœ“/parenleftBig
ğ¼ğ‘£
ğ‘˜+ğ›¼ğ‘£
ğ‘›âˆ’1+ğ›½ğ‘£
ğ‘›âˆ’1/parenrightBig/bracketrightBig,(8)
where the ğ‘›âˆˆ[1,2,Â·Â·Â·,ğ‘]is the iteration index. The iteration
processcontinuesuntilconvergenceorthemaximumnumberof
iterations is reached. We treat the output distribution Beta(ğ›¼ğ‘£,ğ›½ğ‘£)
as the final personalized distribution for item ğ‘£â€™s click probability.
Getting personalized posterior probabilities. For the posterior
probability estimation, under the prior personalized probability
Beta(ğ›¼ğ‘£,ğ›½ğ‘£), as in the last period we observe ğ¶ğ‘£
ğ‘˜clicks after ğ¼ğ‘£
ğ‘˜
impressions,thentheposteriordistributionis Beta(ğ›¼ğ‘£+ğ¶ğ‘£
ğ‘˜,ğ›½ğ‘£+
ğ¼ğ‘£
ğ‘˜âˆ’ğ¶ğ‘£
ğ‘˜).AccordingtotheexpectationinEq.(4),wecaneasilyobtain
ğ‘ƒğ‘£
clicked=ğ›¼ğ‘£+ğ¶ğ‘£
ğ‘˜
ğ¼ğ‘£
ğ‘˜+ğ›¼ğ‘£+ğ›½ğ‘£.Similarly,wecancomputethebetadistribution
for userğ‘¢clicks and the corresponding probability ğ‘ƒğ‘¢
click.
We can use the estimated posterior probability as augmented
labels to break ties in binary labels. This approach provides a con-
tinuousscorethatcaneffectivelybreaktiesinbinaryclick-through
rate prediction tasks, enhancing the modelâ€™s ranking performance
while maintaining its calibrated outputs.
4.2 Constructing Extended Preference Pairs
Based on the estimated posterior probabilities, we now can extend
theDefinition1of preferencepair evenwhen (ğ‘£,ğ‘£/prime)hasthesame
binary preferences. Firstly, we utilize an aggregation function to
readout from the estimated probability of user clicks ğ‘ƒğ‘¢
clickand the
probability of the item being clicked ğ‘ƒğ‘£
clicked, and finally obtain a
scalar as the final posterior probability as:
ğ‘ƒagg=agg(ğ‘ƒğ‘¢
click,ğ‘ƒğ‘£
clicked), (9)
where the aggregation function agg(Â·)could be any function such
as the maximum or the average function.
The final augmented preference score ğ‘§is then obtained by
summing the pooled probability and the original click label:
ğ‘§=ğ‘ƒagg+ğ‘¦. (10)
Wecanclearlyseethatevenifthepair (ğ‘¢,ğ‘£),(ğ‘¢,ğ‘£/prime)hasthesame
binary preferences, it is less likely that they also have the sameposterior probabilities at the same time. In this way, we are able to
extendthedefinitionofthepreferencepairinSection3.1asfollows:
Definition 2 (Extended preference judgement pair). An
extendedpreferencejudgementpairisdefineas: (ğ‘¢,ğ‘£)â‹—(ğ‘¢,ğ‘£/prime),where
ğ‘§ğ‘¢,ğ‘£is greater than ğ‘§ğ‘¢,ğ‘£/prime.
In summary, our proposed BBP ranking framework is able to
construct pairs even with the same preferences ( i.e.,1v s .1o r0
vs. 0). Although our model does not explicitly output a ranking
score,thisapproachisconsistentwithourgoalofhavinguseritems
with higher ranking scores (i.e., clicked or with higher posterior
probability) associated with a higher predicted output probability.
4.3 Beyond Binary Preference Ranking
This ranking-based approach enables us to go one step further and
perform global context ranking. In other words, when building the
dataset,wedonotnecessarilyhavetoconsiderthesamecontext
(such as the clicked item and the unclicked item of the same user).
Instead,wecanrankthecorrelationsbetweenanyuseranditem
pairs.Thisfurtherimprovesthenumberoftrainingsamplesandthe
training flexibility of our model, as we no longer need to construct
a loss function based on the same user. By incorporating global
context ranking, our BBP framework can better generalize and
adapttovariousrankingscenarios,enhancingitsperformancein
real-world CTR prediction tasks.
During training, we construct a global context ranking loss.
Specifically, in each batch of a training set with a size of ğµ,w e
computethedifferencebetweentheirscoresandobtainthelabelof
the partial order relationship:
Î”ğ‘§(ğ‘¢,ğ‘£)â‹—(ğ‘¢/prime,ğ‘£/prime)=ğ‘§(ğ‘¢,ğ‘£)âˆ’ğ‘§(ğ‘¢/prime,ğ‘£/prime), (11)
where(ğ‘¢,ğ‘£)and(ğ‘¢/prime,ğ‘£/prime)are two user item pairs and ğ‘§(ğ‘¢,ğ‘£)and
ğ‘§(ğ‘¢/prime,ğ‘£/prime)are their corresponding scores.
We then define an indicator function I(Â·)that returns one if the
difference is greater than 0, and 0 otherwise:
I(Î”ğ‘§(ğ‘¢,ğ‘£)â‹—(ğ‘¢/prime,ğ‘£/prime))=/braceleftBigg
1,ifÎ”ğ‘§(ğ‘¢,ğ‘£)â‹—(ğ‘¢/prime,ğ‘£/prime)>0
0,otherwise.(12)
We can also compute the difference of the corresponding model
output:
Î”ğ‘ (ğ‘¢,ğ‘£)â‹—(ğ‘¢/prime,ğ‘£/prime)=ğœ(ğ‘“(xğ‘¢,ğ‘£)âˆ’ğ‘“(xğ‘¢/prime,ğ‘£/prime)) (13)
After that, we check whether the partial order relationship (differ-
ence) between the modelâ€™s output ğ‘“(xğ‘¢,ğ‘£)is consistent with the
partial order relationship label. The calculation is given by:
Lrank=âˆ’1
ğ‘€ğ‘€/summationdisplay.1
(ğ‘¢,ğ‘£)/follows(ğ‘¢/prime,ğ‘£/prime)log/parenleftBig
ğœ/parenleftBig
Î”ğ‘ (ğ‘¢,ğ‘£)â‹—(ğ‘¢/prime,ğ‘£/prime)Â·I(Î”ğ‘§(ğ‘¢,ğ‘£)â‹—(ğ‘¢/prime,ğ‘£/prime))/parenrightBig/parenrightBig
,
(14)
whereğ‘€=/parenleftbigğµ
2/parenrightbigisthesizeofpreferencepairs, ğµisthebatchsize,and
ğœ(Â·)is the sigmoid function. We compare all possible/parenleftbigğµ
2/parenrightbigdifferent
user item pairsâ€™ partial order (ğ‘¢,ğ‘£)/follows(ğ‘¢/prime,ğ‘£/prime)in this batch.
Following the SOTA methods [ 3,44], we optimize the binary
cross entropy loss per batch as the calibration loss Lcal:
Lcal=âˆ’1
ğµ/summationdisplay.1
(ğ‘¢,ğ‘£,ğ‘¦)ğ‘¦ğ‘¢,ğ‘£logğœ(ğ‘ )ğ‘¢,ğ‘£+(1âˆ’ğ‘¦ğ‘¢,ğ‘£)log(1âˆ’ğœ(ğ‘ )ğ‘¢,ğ‘£).(15)
5446KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Chang Liu, Qiwei Wang, Wenqing Lin, Yue Ding, and Hongtao Lu
As a multi-task framework, the final loss is the weighted sum of
the calibration loss and the ranking loss:
Ltotal=ğœ†Lğµğ¶ğ¸+(1âˆ’ğœ†)Lrank, (16)
whereğœ†âˆˆ[0,1]istheweightingfactorhyper-parameter.Empiri-
cally, we find that ğœ†is a stable hyper-parameter that is free from
time-consumingfine-tuning.WeprovideaTensorFlow-stylepseudo
code of the Beyond Binary Preference (BBP) training paradigm in
Algorithm 1.
To better build the intuition of our BBP and facilitate further
application and research, we provide the source code of BBP on
https://github.com/AlvinIsonomia/BBP.
4.4 Computational Complexity Analysis
We provide in detail computational complexity analysis in both
theory and deployed systems running time.
Firstly,letushave ğ‘recordsinourdataset.AsshowninSec.4.1,
thepre-computinghasthreesteps.Thefirststepisaveragingthe
whole dataset, so the complexity is ğ‘‚(ğ‘). The second step uses
the fixed-point iteration method to update the personalized beta
distribution.Notethatwesetaconstantmaximumiterationstep,
and the total length is also ğ‘for the impression ( ğ¼) and click ( ğ¶)
sequence,respectively.So, thecomplexityisalso ğ‘‚(ğ‘).Thethird
step estimates the posterior probabilities for all users and items.
Note that the complexity for each user or item is ğ‘‚(1), and the
number of users and items is always less than the number of total
recordsN(becauserecordscomefromthecombinationofusersand
items). So, in summary, the computational complexity for our pre-
computingis ğ‘‚(ğ‘),whichmeansourmethodislinearlyscalable
with the amount of data.
In practice, we record the time used in our large-scale industrial
datasetsofTencentgames.Inourdeployedinstance,ittakesaround
31 minutes to pre-compute 38 million interaction records, which is
fastenoughtopre-computethebetadistributionsformillionsof
records daily. Moreover, given that the training time cost is around
6 7 hours, the pre-computing takes only less than 8% of the total
time (i.e., pre-computing + training).
5 EXPERIMENTS ON PUBLIC DATASETS
5.1 Experimental Settings
The experiments conducted in this study on public datasets are
designed to address the following three research questions:
RQ1:Does the BBP framework outperform the existing state-of-
the-art (SOTA) models in CTR prediction tasks?
RQ2:Does BBPâ€™s breaking ties in CTR improve the performance?
RQ3:DoestheglobalcontextsfurtherenhanceBBPâ€™sperformance?
Experimental environments. We conduct the experiments on a
machineequippedwithaTeslaV100GPUwith16GBGPUmemory,
22CPUcores,and90GBsharedCPUmemorywithTensorFlow[ 1].
Datasets.WeusethreesubsetsoftheAmazondatasets[ 35]:Cloth-
ing,Music,andElectronics.Followingtheprocessingin[ 28],we
treatedthesampleswithratingsgreaterthanfouraspositiveand
negative. Meanwhile, we only use samples where the items have a
pictureandmorethanfivecomments.Thefeaturesweusedinclude
image features (image embeddings extracted by the pre-trainedVGG-16[ 45]featureextractor),textfeatures(reviewembeddings
extractedbythepre-trainedBERT[ 10]),userprofile(averagevector
ofuserhistorical reviewembeddings),anditem attribute(average
vector of item history review embeddings).
To ensure a robust evaluation of our model, we split the dataset
based on the userâ€™s ID into a 7:1:2 ratio for the training, valida-
tion,andtestsets.Thisprocedureguaranteesthatallusersinthe
validation and test sets are not present in the training set, thus
providinganunbiasedassessmentofthemodelâ€™sperformanceon
unseen users. Furthermore, to avoid the risk of label leakage, we
constructed Bernoulli trials only on the training set and performed
Bayesian smoothing. This step ensures modelsâ€™ generalization and
effectiveness in real-world CTR prediction tasks. By adopting this
user-basedsplittingstrategyandincorporatingBayesiansmooth-
ing,wecanbetterunderstandthemodelâ€™sgeneralizationcapability
and performance in CTR prediction tasks.
5.2 Hyper-parameter settings
We use Adam as the optimizer. We set the batch size to 256 and
thelearningrateto1e-3.Weclipthegradientswherethenormis
largerthan5.Duringtraining,forevery100iterations,wecompute
theAUC onthe validationset andfinallyreport thetest AUCand
LogLosswiththecheckpointwiththehighestvalidationAUCscore.
For the AutoInt model, we use ReLU as the activation function, set
theembeddingdimensionforeachfeatureto8,thenumberofheads
to 2, the dimension of the heads to 4, the attention dropout rate to
0.1, and the number of hidden units to [512,256,64].
Specifically, we simply set ğœ†to 0.5 in Eq. (16) to take the balance
between calibration and ranking.
Comparedmethods.WecompareourBBPwithfiveSOTAranking-
basedmethods:BayesianPersonalizedRanking(BPR)[ 40],Smooth-
AUC(SAUC)[ 47],RegressionCompatibleRanking(RCR)[ 3],Scale
Calibration(SC)[ 51],andJointoptimizationofRankingandCali-
bration(JRC)[ 44]asthetrainingmethods.Sincethispaperfocuses
onthetrainingparadigm, i.e.,lossfunction,wechooseAutoInt[ 46]
asourbackbonemodelforexperiments.AutoIntisamainstream
self-attention-based neural network for recommendation systems,
whichcanfindlow-dimensionalrepresentationsandefficientcombi-
nationsofsparse,high-dimensionalfeatures.Forafaircomparison,
we keep the model capacities the same for all methods. JRC re-
quiresmodifyingtheoutputlayertooutputtwologitsinsteadof
the default one.
5.3 Metrics
Inthisstudy,wechooseLogLossasthecalibrationmetricandAUC
astherankingmetric.Thesemetricsareselectedbecausewecan
only obtain binary preference information in the training datasets.
The equations and notation descriptions for LogLoss and AUC are
as follows:
LogLoss. LogLoss measures the performance of a classification
model by calculating the logarithm of the likelihood of the true
labels given the predicted probabilities. For a binary classification
5447Beyond Binary Preference: Leveraging Bayesian Approaches for Joint Optimization of Ranking and Calibration KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Algorithm 1: A TensorFlow-style pseudo code of Beyond Binary Preference (BBP) training paradigm.
1import tensorflow as tf
2import tensorflow.keras.backend as K
3# B: batch size, label_list: [B, 1], score_list: [B, 1].
4# Feed forward computation to get the prediction and compute BCE loss with binary click label.
5logits =model(inputs)
6pred =K.sigmoid(logits)
7bce_loss =tf.keras.losses.BinaryCrossentropy(label_list, pred)
8# Compute Beyond Binary Preference (BBP) ranking loss with pre -computed float ranking score.
9BBP_matrix =pred -tf.transpose(pred)
10BBP_label =tf.cast(tf.sign(score_list -tf.transpose(score_list)), dtype ="float")
11BBP_loss =-K.mean(K.log(K.sigmoid(BBP_matrix *BBP_label)))
12totoal_loss =bce_loss +BBP_loss
Table1:Statisticsofthepublicuser-itemrecommendation
datasets.
#Users #Items #Interactions
Clothing 39,387 23,033 278,651
Music 5,541 3,568 64,704
Electronics 192,403 63,001 1,688,104
problem, the LogLoss is defined as:
LogLoss =âˆ’1
ğ‘‡testğ‘‡test/summationdisplay.1
ğ‘–=1/bracketleftbig
ğ‘¦ğ‘¢ğ‘–,ğ‘£ğ‘–log(ğ‘ğ‘¢ğ‘–,ğ‘£ğ‘–)+(1âˆ’ğ‘¦ğ‘¢ğ‘–,ğ‘£ğ‘–)log(1âˆ’ğ‘ğ‘¢ğ‘–,ğ‘£ğ‘–)/bracketrightbig
,
(17)
whereğ‘‡testisthenumberoftestimpressions, ğ‘¦ğ‘¢ğ‘–,ğ‘£ğ‘–isthetruelabel
of theğ‘–-th impression, and ğ‘ğ‘¢,ğ‘£ğ‘–is the predicted CTR of the ğ‘–-th
impression.
AUC.TheAreaUndertheReceiverOperatingCharacteristic(ROC)
Curve (AUC) is a widely used metric for evaluating the ranking
performance of a binary classifier. The AUC is defined as:
AUC =1
|ğ‘‡P|Ã—|ğ‘‡N|/summationtext.1|ğ‘‡P|
ğ‘–=1/summationtext.1|ğ‘‡N|
ğ‘—=1{I[(ğ‘ ğ‘¢ğ‘–,ğ‘£ğ‘–âˆ’ğ‘ ğ‘¢ğ‘—,ğ‘£ğ‘—)>0]
+1
2I[(ğ‘ ğ‘¢ğ‘–,ğ‘£ğ‘–âˆ’ğ‘ ğ‘¢ğ‘–,ğ‘£ğ‘–)=0]/bracerightbig
,(18)
whereğ‘‡Pandğ‘‡Nrepresent the positive and negative impression
set for the test dataset, respectively, and |Â·|denotes the set size.
ğ‘ ğ‘¢ğ‘–,ğ‘£ğ‘–indicates the preference score by user ğ‘¢ğ‘–on itemğ‘£ğ‘–.I[Â·]is an
indicatorfunctionthattakesthevalueoneiftheconditioninside
the brackets is true and 0 otherwise.
5.4 Results in Public Datasets (RQ1)
To answer RQ1and validate the performance of different train-
ing paradigms for click-through rate (CTR) prediction, we conduct
experimentsonthreepublicdatasets:Clothing,Music,andElectron-
ics. As shown in Table 2, our proposed BBP method consistently
outperformsallpointwise,pairwise,andlistwisealternativesacross
all datasets regarding LogLoss and AUC metrics.
Thepairwisetrainingparadigms,includingBPR[ 40]andSAUC[ 47],
struggle with calibration and achieve limited ranking performance.
TheirLogLossvaluesaresignificantlyworsethantheBinaryCross
Entropy (BCE) baseline, as indicated by the red color. Since BPR
andSAUCignorethecalibrationlossduringtraining,thepredictedscore keeps drifting and can raisea NaN (Not a Number) LogLoss
for calculating log(0). Although they show some improvements in
AUC compared to the baseline, their performance is still inferior
tothelistwiseandourBBPmethods.Sincepairwisebaselinesin-
cluding BPR and SAUC are not designed for calibration, we modify
them by using calibrated loss. Specifically, we add the pairwise
losseswithaweightedBCEloss,similartoEq.(16).Wehavecon-
ducted additional experiments after fine-tuning the weight of BCE
loss as our BBP does. The results show that BBP also significantly
outperforms calibrated pairwise competitors for all metrics.
Ontheotherhand,listwisemethodshandlecalibrationandrank-
ing simultaneously due to their multi-task design. They achieve
betterperformancethanthepairwisemethods,withSC[ 51]and
JRC[44]oftenbeingthebest-performingalternativestoourmethod.
However, their performance still falls short compared to BBP, as
the significant ğ‘-values indicate.
With its beyond binary preference ranking, our BBP method
stands out by achieving the best performance across all datasets
andmetrics.TheLogLossvaluesarethelowest,andtheAUCvalues
are the highest among all methods, indicating that BBP provides
thebestcalibrationandranking.Thesignificant ğ‘-valuesfurther
confirm the superiority of BBP over all competitors. As shownin Eq. (9), BBP can leverage different functions to aggregate the
possibilitiesfromuseranditem.Wetaketheaverageandmaximum
functionsasexamples,namelyBBP-AverageandBBP-Maximum.
Wefindthattheperformancewiththesetwoaggregationfunctions
has no significant difference ( ğ‘-values > 0.05).
Inconclusion,theexperimentalresultsdemonstratetheeffective-
ness of our BBP method in CTR prediction. It provides significant
advantagesoverallSOTAcompetitors,especiallythepairwisetech-
niques, and sets a new benchmark for CTR prediction.
5.5 Ablation Study (RQ2 and RQ3)
We conduct an ablation study to investigate the contributions of
BBPâ€™s ability to break ties and the global context ranking to its
performance.Weimplementthreevariantsofourproposedmethod,andallvariantsimplementBCEasthecalibrationloss: Case1:The
rankinglossinEq.(14)onlycompareitem ğ‘£fromthesameuser ğ‘¢
with their binary click label ğ‘¦.Case 2:The ranking loss in Eq.(14)
only compare item ğ‘£from the same user ğ‘¢with their estimated
5448KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Chang Liu, Qiwei Wang, Wenqing Lin, Yue Ding, and Hongtao Lu
Table2:ComparisonofoverallperformanceforCTRpredictionbasedondifferenttrainingparadigms,withaverageresults
reportedoverfiverandomseeds.LogLoss â†“isacalibrationmetricwherelowervaluesarebetter.AUC â†‘isarankingmetric,
withhighervaluespreferable.The underlined valueshighlightthebestperformance,excludingourproposedmethod.The
ğ‘-valueisobtainedthroughat-testbetweenourmethodandthebest-performingalternative.BoldvaluesindicatethatourBBP
methodsignificantly outperformsallcompetitors (determinedby thesignificanceat ğ‘<0.05),no matterwhich implemented
aggregation function. Results significantly worse than the Binary Cross Entropy (BCE) baseline are denoted in red, while those
significantly better are marked in green. The color significance is also based on the ğ‘<0.05threshold.
Dataset Clothing Music Electronics
Metric LogLossâ†“AUCâ†‘LogLossâ†“AUCâ†‘LogLossâ†“AUCâ†‘
Pointwise BCE 0.6184 0.7695 0.6414 0.7246 0.6522 0.7242
BPR (UAIâ€™09) 17.4783 0.7754 NaN 0.7307 NaN 0.7294
BPR + BCE 0.6289 0.7720 0.6851 0.7286 0.6451 0.7282PairwiseSAUC (SIGIRâ€™22) 8.3426 0.7785 0.7292 0.7371 NaN 0.7361
SAUC + BCE 0.6028 0.7792 0.6712 0.7338 0.6558 0.7368
RCR (CIKMâ€™23) 0.6523 0.7808 0.6846 0.7398 0.6540 0.7409
SC (KDDâ€™22) 0.5636 0.7839 0.6590 0.7418 0.6564 0.7508 Listwise
JRC (KDDâ€™23) 0.6187 0.7886 0.6487 0.7474 0.5955 0.7447
BBP-Average 0.5413 0.7965 0.5996 0.7562 0.5754 0.7590
BBP-Maximum 0.5471 0.7942 0.5952 0.7541 0.5747 0.7566 Ours
ğ‘-value 1.23E-03 2.35E-02 7.79E-04 4.41E-02 3.30E-02 1.00E-03
scoreğ‘ inEq.10. Case3(BBP): TherankinglossEq.(14)compare
allğ‘¢âˆ’ğ‘£pairs in each sampled batch with their estimated score ğ‘ .
To address RQ2,i.e.,to show that even without the augmen-
tationofglobalcontexts,theBBPframeworkcanimprovemodel
performance withits abilityto breakties using Bayesianprobabil-
ities. We can compare the average performance between Case 1
and Case 2. To further address RQ3,i.e.,to confirm that the global
contextrankingcanfurtherimprovemodelperformance,wecan
compareCase2withCase3(ourBBP).AsshowninFigure3,theex-
perimentalresultsdemonstratethattheperformanceofthemodelsfollowstheorder:Case3(BBP)>Case2>Case1.Theimprovement
observed between Case 3 and Case 2 is smaller than between Case
2and1.ThisindicatesthattheprimaryenhancementofBBPisdue
tobreakingmanybinaryties,andthescoreestimateprovidedby
the Bayesian probabilities is meaningful (RQ2). The global context
also contributes to the improvement of BBP (RQ3).
Moreover, as illustrated in Algorithm 1 in the appendix, the
global context enables on-the-fly ranking with naive pointwise
training,makingiteasiertodeploy.Unlikestate-of-the-artmethods[
3,40,44,47,51],wedonotneedtobeconcernedaboutwhetherthe
trainingbatchisunderthesamecontext.ThisflexibilityallowsBBP
to adapt to various ranking scenarios more effectively, enhancing
its performance in real-world CTR prediction tasks.
In summary, the ablationstudy demonstrates that BBPâ€™s ability
to break ties and the incorporation of global contexts contributeto performance improvement. The primary enhancement comes
frombreakingties usingBayesianprobabilities.Atthesame time,
incorporatingglobalcontextsfurtherboostsperformanceandoffers
greater flexibility and adaptability in various ranking scenarios.Figure 3: Ablation study results on Amazon datasets.
6 INDUSTRIAL DEPLOYMENT
6.1 In-Game Friend Recommendation
WehavedeployedourBBPtrainingparadigmmodelanditstoptwo
competitors, SC and JRC, on two Tencent games: a mobile battle
royale game denoted by X and a casual party game denoted by Y.
CTR Prediction for Friend Recommendation. The deployed
methods serve for friend recommendation tasks in both real-world
games. The friend recommendation is a resident module in both
gamesXandY.Whenaplayer ğ‘¢(inviter)accessestherecommenda-
tionmoduletofindsomeotherplayerstobecomein-gamefriends, ğ‘¢
seesanorderedlistofinteractednon-friendplayers.Thisgenerates
animpression recordintherecommendationlogs, and ğ‘¢candecide
to click on a non-friend player ğ‘£(invitee) or not. Inviter ğ‘¢can click
oneormultipleinvitees.Onceinviter ğ‘¢clicksonarecommended
inviteeğ‘£,itsendsafriendrequestandgeneratesa clickrecordinthe
recommendationlogs.Therequestrequiresapproval;theclicked
inviteeğ‘£can decide to accept or reject it. If ğ‘¢andğ‘£successfully
become in-game friends, the recommendation module generates a
successrecord. In summary, the CTR prediction model is used to
infertheprobabilitythataninviter ğ‘¢clicksonaninvitee ğ‘£,andthen
the recommendation list is generated according to the descending
order of predicted CTR.
5449Beyond Binary Preference: Leveraging Bayesian Approaches for Joint Optimization of Ranking and Calibration KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Offlinedatasetcollection. Wegathertheone-weeklogsoflog-in
players, and we consider the inviters ğ‘¢who clicked at least one
inviteeğ‘£as the positive examples in the beforehand recommenda-
tion module. We treat the clicked invitees as positive samples and
the unclicked ones as negative samples. If an inviter ğ‘¢clicks on
an invitee ğ‘£at least once, the interaction is viewed as a positive
sample, and we will filter out repeated ğ‘¢âˆ’ğ‘£pairs. Each dataset
contains thelogs of thein-game recommendation modules of all
logged-inplayerswithinsevencontiguousdays,alongwiththeir
in-game features as follows:
â€¢Playersâ€™ profile data, including all related in-game attribute data
of a player, such as the game level, gender, online time, etc.
â€¢Pairwiseinteractionfeatures,includingtheinteractiondatabe-
tweenthe ğ‘¢andğ‘£,suchasthenumberofcommonfriends,and
the number of common matches etc.
â€¢Playersâ€™socialnetworkproperties( i.e.,theexistingin-gamesocial
networkproperties),includingthelocalnetworkstructure,the
number of friends, etc.
All raw features are standardized using min-max normalization
beforebeingfed intotheCTRpredictionmodels.The statisticsof
games X and Y can be found in Table 3.
6.2 Offline Evaluation
We first trainthe modelswith datasetsX andYoffline toevaluate
their performance. We split the dataset by inviter ğ‘¢â€™s id into a 7:1:2
ratio for training, validating, and testing datasets. We perform the
Bayesian smoothingonly onthe train setlike Section5.1 to avoid
label leakage. For the evaluation metrics, since we are interestedin whether the inviter
ğ‘¢would click the invitee ğ‘£in the friend
recommendation list, we report Hit rate@N and NDCG@N, where
N is 10, 20, and 50 to show the performance of models on different
positions. As summarized in Table 4, the offline evaluation results
demonstrate the effectiveness of our BBP method compared to the
competing methods in all metrics. This observation justifies that
our method is more effective than the competitors for ranking the
player list in real-world friend recommendation tasks.
6.3 Online Evaluation
Toevaluatetheperformanceofthevariousmethodsinanonline
setting, we additionally conduct online A/B tests on both games[
19,30â€“32,53â€“56]. The friend recommendation module in each
game is updated with the deployed models, and their performance
is monitored over one week (from 2024/01/19 - 2024/01/25). We
evaluateBBP,SC,andJRCinthefriendrecommendationtaskusing
threemetrics: (i)ClickRate,whichistheproportionof clickuser
amongimpression records;(ii)Approval Rate, the proportion of
successapproval among clickinvitations; and (iii)overall Friend
Rate, the proportion of successapproval among impression records.
The overall Approval Rate is the product of the Click Rate and the
Approval Rate after invitations are sent, i.e., Friend Rate =Click
RateÃ—Approval Rate.
The online evaluation results in Table 5 demonstrate that our
proposedBBPmethodconsistentlyoutperformsthestate-of-the-art
(SOTA) methods SC and JRC in terms of Click Rate, Approval Rate
andFriendRateforbothgamesXandY.Specifically,considering
the definition of Friend Rate, the BPR we proposed can increaseTable 3: Statistics of real-world game datasets.
GAME #Users #Interactions #Features
X 3,240,444 38,024,787 74
Y 754,776 20,906,940 229
Table 4: The results of the offline evaluation.
GAME X HIT@10 NDCG@10 HIT@20 NDCG@20 HIT@50 NDCG@50
Baseline 0.3202 0.2422 0.3503 0.2498 0.3743 0.2547
SC 0.3224 0.2483 0.3505 0.2555 0.3735 0.2601
JRC 0.3157 0.2373 0.3460 0.2450 0.3717 0.2502
Ours 0.3287 0.2581 0.3545 0.2580 0.3765 0.2624
GAME Y HIT@10 NDCG@10 HIT@20 NDCG@20 HIT@50 NDCG@50
Baseline 0.3817 0.2678 0.4523 0.2869 0.5005 0.2944
SC 0.3879 0.2715 0.4547 0.2889 0.5016 0.2977
JRC 0.3873 0.2707 0.4550 0.2882 0.5015 0.2959
Ours 0.3897 0.2728 0.4561 0.2900 0.5022 0.2985
Table5:TheperformanceliftoftheproposedBBPcompared
with the SOTA methods.
Metric Click Rate Approval Rate Friend Rate
GAME X Y X Y X Y
vs. SC 3.94% 2.93% 4.41% 9.26% 11.59% 18.92%
vs. JRC 10.90% 3.00% 7.73% 4.33% 22.82% 10.28%
the number of new friends for the in-game friend recommendation
module by more than 10.28% compared to SOTA methods. The
proposed BBP method has now been fully deployed into the in-game
friend recommendation systems of Tencent Games X and Y.
These results indicate that the BBP method is highly effective
in enhancing the friend recommendation module in both games,
leadingtohigheruserengagementandsatisfaction.Thesuperior
performance of BBP in real-world scenarios further validates its
effectiveness and applicability in CTR prediction and downstream
recommendation tasks.
7 CONCLUSION
ThispaperpresentstheBeyondBinaryPreference(BBP)training
framework for CTR prediction, which addresses the limitationsof insufficient training pairs caused by binary preference. BBPestimates probability distributions for users and items through
Bayesiansmoothing.Theestimatedprobabilitiestheneliminatethe
ties as augmented labels. BBP also design a global context ranking
loss to augment more preference pairs further during training.
We have demonstrated that the BBP framework outperforms
all current state-of-the-art competitors in rankingand calibration
capabilitiesthroughextensiveofflineexperimentsandonlineA/B
testsonvarioususer-itemrecommendationdatasetsandin-game
friend recommendation scenarios. The implementation code for
BBPhasbeenprovidedassupplementarymaterialstoencourage
further development by the research community.
ACKNOWLEDGEMENT
This work is supported by the National Nature Science Foundation
of China under Grant 62176155 and Shanghai Municipal Science
and Technology Major Project under Grant 2021SHZDZX0102.
5450KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Chang Liu, Qiwei Wang, Wenqing Lin, Yue Ding, and Hongtao Lu
REFERENCES
[1]MartÃ­nAbadi,PaulBarham,JianminChen,ZhifengChen,AndyDavis,Jeffrey
Dean,MatthieuDevin,SanjayGhemawat,GeoffreyIrving,MichaelIsard,Manju-
nathKudlur,JoshLevenberg,RajatMonga,SherryMoore,DerekGordonMurray,
Benoit Steiner, Paul A. Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke,
Yuan Yu, and Xiaoqiang Zheng. 2016. TensorFlow: A System for Large-Scale
Machine Learning. In OSDI. USENIX Association, 265â€“283.
[2] Richard A Askey and Ranjan Roy. 2010. Gamma function.[3]
Aijun Bai, Rolf Jagerman, Zhen Qin, Le Yan, Pratyush Kar, Bing-Rong Lin, Xuan-
huiWang,MichaelBendersky,andMarcNajork.2023. RegressionCompatible
Listwise Objectives for Calibrated Ranking with Binary Relevance. In CIKM.
ACM, 4502â€“4508.
[4]Jose MBernardo.1976. Algorithm AS103: Psi (digamma) function. Journal of
the Royal Statistical Society. Series C (Applied Statistics) 25, 3 (1976), 315â€“317.
[5]Bryan Brancotte, Bo Yang, Guillaume Blin, Sarah Cohen Boulakia, Alain Denise,
and Sylvie Hamel. 2015. Rank aggregation with ties: Experiments and Analysis.
Proc. VLDB Endow. 8, 11 (2015), 1202â€“1213.
[6]Sebastian Bruch, ShuguangHan, Michael Bendersky, and MarcNajork. 2020. A
StochasticTreatmentofLearningtoRankScoringFunctions.In WSDM.ACM,
61â€“69.
[7]Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to
rank: from pairwiseapproach to listwise approach. In ICML (ACMInternational
Conference Proceeding Series, Vol. 227). ACM, 129â€“136.
[8]Heng-TzeCheng,LeventKoc,JeremiahHarmsen,TalShaked,TusharChandra,
HrishiAradhye,GlenAnderson,GregCorrado,WeiChai,MustafaIspir,Rohan
Anil,ZakariaHaque,LichanHong,VihanJain,XiaobingLiu,andHemalShah.
2016. Wide & Deep Learning for Recommender Systems. (2016), 7â€“10.
[9]DanielCohen,BhaskarMitra,OlegLesota,NavidRekabsaz,andCarstenEickhoff.
2021. Not All Relevance Scores are Equal: Efficient Uncertainty and Calibration
Modeling for Deep Retrieval Models. In SIGIR. ACM, 654â€“664.
[10]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019. BERT:
Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.In
NAACL-HLT (1). Association for Computational Linguistics, 4171â€“4186.
[11]TomFawcett.2006. AnintroductiontoROCanalysis. PatternRecognit.Lett. 27,8
(2006), 861â€“874.
[12]ThoreGraepel,JoaquinQuiÃ±oneroCandela,ThomasBorchert,andRalfHerbrich.
2010. Web-ScaleBayesianClick-ThroughratePredictionforSponsoredSearch
Advertising in Microsoftâ€™s Bing Search Engine. In ICML. Omnipress, 13â€“20.
[13]ChuanGuo,GeoffPleiss,YuSun,andKilianQ.Weinberger.2017. OnCalibration
of Modern Neural Networks. In ICML (Proceedings of Machine Learning Research,
Vol. 70). PMLR, 1321â€“1330.
[14]HuifengGuo,BoChen,RuimingTang,WeinanZhang,ZhenguoLi,andXiuqiang
He.2021. AnEmbeddingLearningFrameworkforNumericalFeaturesinCTR
Prediction. In KDD. ACM, 2910â€“2918.
[15]HuifengGuo,RuimingTang,YunmingYe,ZhenguoLi,andXiuqiangHe.2017.
DeepFM: A Factorization-Machine based Neural Network for CTR Prediction.
(2017), 1725â€“1731.
[16]Trevor Hastie, Robert Tibshirani, and Jerome H. Friedman. 2009. The Elements of
StatisticalLearning:DataMining,Inference,andPrediction,2ndEdition . Springer.
[17]Kun He, Fatih Ã‡akir, Sarah Adel Bargal, and Stan Sclaroff. 2018. Hashing as Tie-
AwareLearningtoRank.In CVPR.ComputerVisionFoundation/IEEEComputer
Society, 4023â€“4032.
[18]XinranHe,JunfengPan,OuJin,TianbingXu,BoLiu,TaoXu,YanxinShi,Antoine
Atallah, Ralf Herbrich, Stuart Bowers, and Joaquin QuiÃ±onero Candela. 2014.
Practical Lessons from Predicting Clicks on Ads at Facebook. In ADKDD@KDD.
ACM, 5:1â€“5:9.
[19]Shixun Huang, Wenqing Lin, Zhifeng Bao, and Jiachen Sun. 2022. Influence
MaximizationinReal-WorldClosedSocialNetworks. Proc.VLDBEndow. 16,2
(2022), 180â€“192.
[20]Tongwen Huang, Zhiqi Zhang, and Junlin Zhang. 2019. FiBiNET: combining fea-
tureimportanceandbilinearfeatureinteractionforclick-throughrateprediction.
InRecSys. ACM, 169â€“177.
[21] Kalervo JÃ¤rvelin and Jaana KekÃ¤lÃ¤inen. 2002. Cumulated gain-based evaluation
of IR techniques. ACM Trans. Inf. Syst. 20, 4 (2002), 422â€“446.
[22]NormanLloydJohnson,SamuelKotz, andNarayanaswamyBalakrishnan.1972.
Continuous multivariate distributions. Vol. 7. Wiley New York.
[23]Yu-Chin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. 2016. Field-
aware Factorization Machines for CTR Prediction. In RecSys. ACM, 43â€“50.
[24]NormanKnyazevandHarrieOosterhuis.2023. ALightweightMethodforModel-
ing Confidence in Recommendations with Learned Beta Distributions. In RecSys.
ACM, 306â€“317.
[25]RanganathKrishnanandOmeshTickoo.2020. Improvingmodelcalibrationwith
accuracy versus uncertainty optimization. In NeurIPS.
[26]Tien-Duy B. Le, David Lo, Claire Le Goues, and Lars Grunske. 2016. A learning-
to-rank based fault localization approach using likely invariants. In ISSTA. ACM,
177â€“188.
[27]ChengLi,YueLu,QiaozhuMei,DongWang,andSandeepPandey.2015. Click-
throughPredictionforAdvertisinginTwitterTimeline.In KDD.ACM,1959â€“1968.[28]Xiang Li, Chao Wang, Jiwei Tan, Xiaoyi Zeng, Dan Ou, and Bo Zheng. 2020. Ad-
versarialMultimodalRepresentationLearningforClick-ThroughRatePrediction.
InWWW. ACM / IW3C2, 827â€“836.
[29]JianxunLian,XiaohuanZhou,FuzhengZhang,ZhongxiaChen,XingXie,and
Guangzhong Sun. 2018. xDeepFM: Combining Explicit and Implicit Feature
Interactions for Recommender Systems. In KDD. ACM, 1754â€“1763.
[30]Wenqing Lin. 2019. Distributed Algorithms for Fully Personalized PageRank on
Large Graphs. In WWW. ACM, 1084â€“1094.
[31]Wenqing Lin. 2021. Large-ScaleNetwork Embedding in Apache Spark.In KDD.
ACM, 3271â€“3279.
[32]Wenqing Lin, Feng He, Faqiang Zhang, Xu Cheng, and Hongyun Cai. 2020.
InitializationforNetworkEmbedding:AGraphPartitionApproach.In WSDM.
ACM, 367â€“374.
[33]Tie-Yan Liu. 2010. Learning to rank for information retrieval. In SIGIR. ACM,
904.
[34]BoxiangLyu,ZheFeng,ZacharyRobertson,andSanmiKoyejo.2023. Pairwise
Ranking Losses of Click-Through Rates Prediction for Welfare Maximization in
AdAuctions.In ICML(ProceedingsofMachineLearningResearch,Vol.202).PMLR,
23239â€“23263.
[35]Julian J. McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel.
2015. Image-Based Recommendations on Styles and Substitutes. In SIGIR. ACM,
43â€“52.
[36]H. Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner,
JulianGrady,LanNie,ToddPhillips,EugeneDavydov,DanielGolovin,Sharat
Chikkerur, DanLiu, Martin Wattenberg,Arnar Mar Hrafnkelsson,Tom Boulos,
and Jeremy Kubica. 2013. Ad click prediction: a view from the trenches. In KDD.
ACM, 1222â€“1230.
[37]Aditya Krishna Menon, Xiaoqian Jiang, Shankar Vembu, Charles Elkan, andLucila Ohno-Machado. 2012. Predicting accurate probabilities with a ranking
loss. (2012).
[38]MatthiasMinderer,JosipDjolonga,RobRomijnders,FrancesHubis,XiaohuaZhai,
Neil Houlsby, DustinTran, andMario Lucic.2021. Revisiting theCalibration of
Modern Neural Networks. (2021), 15682â€“15694.
[39]Steffen Rendle. 2010. Factorization Machines. In ICDM. IEEE Computer Society,
995â€“1000.
[40]SteffenRendle,ChristophFreudenthaler,ZenoGantner,andLarsSchmidt-Thieme.2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In UAI.A U A I
Press, 452â€“461.
[41]Matthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting
clicks: estimating the click-through rate for new ads. In WWW. ACM, 521â€“530.
[42]SimoSÃ¤rkkÃ¤.2013. BayesianFilteringandSmoothing.In InstituteofMathematical
Statistics textbooks.
[43] D. Sculley. 2010. Combined regression and ranking. In KDD. ACM, 979â€“988.
[44]Xiang-Rong Sheng, Jingyue Gao, Yueyao Cheng, Siran Yang, Shuguang Han,
HongboDeng,YuningJiang,JianXu,andBoZheng.2023. JointOptimization
ofRankingandCalibrationwithContextualizedHybridModel.In KDD.ACM,
4813â€“4822.
[45]KarenSimonyanandAndrewZisserman.2015. VeryDeepConvolutionalNet-
works for Large-Scale Image Recognition. (2015).
[46]Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang,
andJianTang.2019. AutoInt:AutomaticFeatureInteractionLearningviaSelf-
Attentive Neural Networks. In CIKM. ACM, 1161â€“1170.
[47]ShuangTang,FangyuanLuo,andJunWu.2022. Smooth-AUC:Smoothingthe
Path Towards Rank-based CTR Prediction. In SIGIR. ACM, 2400â€“2404.
[48]XueruiWang, WeiLi,YingCui, RuofeiZhang,andJianchangMao. 2011. Click-
throughrateestimationforrareeventsinonlineadvertising.In Onlinemultimedia
advertising: Techniques and technologies. IGI Global, 1â€“12.
[49]XinlongWeng.1991. Fixedpointiterationforlocalstrictlypseudo-contractive
mapping.
[50]FenXia,Tie-YanLiu,JueWang,WenshengZhang,andHangLi.2008. Listwise
approach to learning to rank: theory and algorithm. In ICML (ACM International
Conference Proceeding Series, Vol. 307). ACM, 1192â€“1199.
[51]LeYan,ZhenQin,XuanhuiWang,MichaelBendersky,andMarcNajork.2022.
Scale Calibration of Deep Ranking Models. In KDD. ACM, 4300â€“4309.
[52]Yanwu Yang and Panyu Zhai. 2022. Click-through rate prediction in online
advertising: A literature review. Inf. Process. Manag. 59, 2 (2022), 102853.
[53]Shiqi Zhang, Yiqian Huang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, and Bo
Tang.2023. CapacityConstrainedInfluenceMaximizationinSocialNetworks.In
KDD. ACM, 3376â€“3385.
[54]Shiqi Zhang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, Yiqian Huang, and Bo
Tang. 2024. Information Diffusion Meets Invitation Mechanism. In WWW. ACM,
383â€“392.
[55] Shiqi Zhang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, and Bo Tang. 2022. Mea-
suringFriendshipCloseness:APerspectiveofSocialIdentityTheory.In CIKM.
ACM, 3664â€“3673.
[56]Xingyi Zhang, Shuliang Xu, Wenqing Lin, and Sibo Wang. 2023. Constrained
Social Community Recommendation. In KDD. ACM, 5586â€“5596.
5451Beyond Binary Preference: Leveraging Bayesian Approaches for Joint Optimization of Ranking and Calibration KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
[57]Piplong Zhao, Ou Wu, Liyuan Guo, Weiming Hu, and Jinfeng Yang. 2016. Deep
learning-based learning to rank with ties for image re-ranking. (2016), 452â€“456.
[58]ZhaohuiZheng,KekeChen,GordonSun,andHongyuanZha.2007. Aregression
framework for learning ranking functions using relative relevance judgments. In
SIGIR. ACM, 287â€“294.
[59]Guorui Zhou, Xiaoqiang Zhu, Chengru Song, Ying Fan, Han Zhu, Xiao Ma,
YanghuiYan,JunqiJin,HanLi,andKunGai.2018. DeepInterestNetworkfor
Click-Through Rate Prediction. In KDD. ACM, 1059â€“1068.
[60]KeZhou,Gui-RongXue,HongyuanZha,andYongYu.2008. Learningtorank
with ties. In SIGIR. ACM, 275â€“282.
[61]JiemingZhu,JinyangLiu,ShuaiYang,QiZhang,andXiuqiangHe.2021. Open
Benchmarking for Click-Through Rate Prediction. In CIKM. ACM, 2759â€“2769.
[62]Xiaofeng Zhu and Diego Klabjan. 2020. Listwise Learning to Rank by Exploring
Unique Ratings. In WSDM. ACM, 798â€“806.
A EMPIRICAL STUDY ABOUT USER
BEHAVIOR
A.1 The Beta Distribution Assumption
Click-through rate (CTR) is the probability of a user clicking on
an item. Considering the binary nature of the clicking behavior
(click or not), it can be modeled as a Bernoulli trial with an under-
lying probability ğ‘Ÿ. Tofurther validateour assumptionabout beta
distribution,weconducttheKolmogorov-Smirnovtestandother
data-basedanalysestoshowthattheassumptionisreasonablein
our deployed system.
Firstly, we conduct a Kolmogorov-Smirnov test on the active
usersâ€™ click rates and our estimated beta distribution. The H0 isthe click rate that obeys our estimated beta distribution. The re-sult shows that the K-S statistic is 0.01641195 and the p-value is0.13383894. Given that the p-value > 0.05, we accept the H0 that
the usersâ€™ click rates obey a beta distribution.
Secondly, we provide a Quantile-Quantile plot to show the re-
lationship between our estimated beta distribution (Theoretical
Quantiles) with real-world playersâ€™ behavior (Sample Quantiles).
Figure 4: The Q-Q plot of user click rate in our deployed
system.
As shown in Fig. 4, the Quantile-Quantile plot shows that the
real-world playersâ€™ behavior fits nicely with our estimated beta
distribution.A.2 The Confidence Level Distribution with
Number of Training Samples
BBP may fail to estimate personalized distributions with high con-
fidence levels for users with limited samples in the training set.
Intuitively,theBayesiansmoothingdrivestheposteriorprobabili-
tiesfromtheinitializedbetadistributiontoamorepersonalizedone.If the user does not have enough samples, their posterior probabili-
ties will be similar to the posterior probability from our initialized
beta distribution.Inthe extremecase,if theuserdoes nothaveany
historical data, his posterior probability will be derived from the
initializedbetadistribution.Aswetreatimpressionsandclicksas
visiblevariablesofauserthatobeyaBinomialdistributionwithan
underlyingprobability ğ‘Ÿ.OurBayesiansmoothingaimstoestimate
personalized posterior probabilities for the Binomial distribution.
We provide further tests on the visible user behavior, i.e., the
clickobeyingthepersonalizeddistributionestimatedbyBBP.We
testactiveplayersinourdeployedsystem.Theresultshowsthat
70.43%ofthetotalplayersobeytheirpersonalizeddistributionof
BBP, determined by the significance at p-value > 0.05. We agree
with you that the number of samples of users is important because
we find that less than 30% of players fail in the test of their limited
records in real-world applications. We also provide a Boxplot to
showtheconfidenceofthepersonalizeddistributionamongplayers,
illustrating that most players obey their personalized distribution.
Figure5:Theconfidenceleveldistributionofuserobeying
the BBPâ€™s output estimation in our deployed system.
Due to the complexity of real-world deployment scenarios, it is
unavoidablethatsomeuserswithinsufficientdata(suchas cold-start
players who have just joined the game). However, BBP has already
outperformedallcompetitorsinouronlineandofflineexperiments.
B IMPACT OF HYPER-PARAMETER
Empirically, we find that ğœ†is a stable hyper-parameter that is free
from time-consuming fine-tuning. Intuitively, as we design both
calibration loss in Eq. (15) and ranking loss in Eq. (14) in a sigmoid-
then-logstyle,thescaleofthetwolossesaresimilar.Toshowour
intuition, we perform a grid search of ğœ†in [0.1, 0.3, 0.5, 0.7, 0.9] on
the Music dataset and report the average LogLoss and AUC metric
w.r.t.the different ğœ†.
As shown in Figure 6 and Figure 7, when we increase the ğœ†, the
totallossprefersmorecalibrationduringtraining,whichleadsto
5452KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Chang Liu, Qiwei Wang, Wenqing Lin, Yue Ding, and Hongtao Lu
Figure 6: Calibration Performance (LogLoss) of BBP w.r.t.
different hyper-prameter ğœ†on the Music dataset.
Figure 7: Ranking Performance (AUC) of BBP w.r.t.different
hyper-prameter ğœ†on the Music dataset.lowerLogLossandAUCatthesametime.However,insuchalarge
range, BBP continues to outperform the best baseline (represented
with dashed lines).
This analysis demonstrates that the hyper-parameter ğœ†is sta-
ble and does not require extensive fine-tuning, which simplifies
thetraining processandmakesBBP morepracticalfor real-world
applications.Furthermore,therobustperformanceofBBPacross
differentvaluesof ğœ†highlightsitseffectivenessinbalancingcali-
bration and ranking losses, resulting in superior CTR prediction
performance compared to the baselines.
5453