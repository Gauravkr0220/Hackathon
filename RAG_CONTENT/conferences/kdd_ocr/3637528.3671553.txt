MGMatch: Fast Matchmaking with Nonlinear Objective and
Constraints via Multimodal Deep Graph Learning
Yu Sunâˆ—
Shandong University
Qingdao, Shandong, China
202236973@mail.sdu.edu.cnKai Wangâˆ—
Fuxi AI Lab, NetEase Inc.
Hangzhou, Zhejiang, China
wangkai02@corp.netease.comZhipeng Hu
Fuxi AI Lab, NetEase Inc.
Hangzhou, Zhejiang, China
zphu@corp.netease.com
Runze Wuâ€ 
Fuxi AI Lab, NetEase Inc.
Hangzhou, Zhejiang, China
wurunze1@corp.netease.comYaoxin Wu
Eindhoven University of Technology
Eindhoven, Netherlands
y.wu2@tue.nlWen Songâ€ 
Shandong University
Qingdao, Shandong, China
wensong@email.sdu.edu.cn
Xudong Shen
Fuxi AI Lab, NetEase Inc.
Hangzhou, Zhejiang, China
hzshenxudong@corp.netease.comTangjie Lv
Fuxi AI Lab, NetEase Inc.
Hangzhou, Zhejiang, China
hzlvtangjie@corp.netease.comChangjie Fan
Fuxi AI Lab, NetEase Inc.
Hangzhou, Zhejiang, China
fanchangjie@corp.netease.com
ABSTRACT
As a core problem of online games, matchmaking is to assign play-
ers into multiple teams to maximize their gaming experience. With
the rapid development of game industry, it is increasingly difficulty
to explicitly model playersâ€™ experiences as linear functions. Instead,
it is often modeled in a data-driven way by training a neural net-
work. Meanwhile, complex rules must be satisfied to ensure the
robustness of matchmaking, which are often described using logi-
cal operators. Therefore, matchmaking in practical scenarios is a
challenging combinatorial optimization problem with nonlinear
objective, linear constraints and logical constraints, which receives
much less attention in previous research. In this paper, we pro-
pose a novel deep learning method for high-quality matchmaking
in real-time. We first cast the problem as standard mixed-integer
programming (MIP) by linearizing ReLU networks and logical con-
straints. Then, based on supervised learning, we design and train
a multi-modal graph learning architecture to predict optimal solu-
tions end-to-end from instance data, and solve a surrogate problem
to efficiently obtain feasible solutions. Evaluation results on real
industry datasets show that our method can deliver near-optimal
solutions within 100ms.
âˆ—Both authors contributed equally to this research.
â€ Corresponding authors.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671553CCS CONCEPTS
â€¢Information systems â†’Massively multiplayer online games;
Data mining ;â€¢Computing methodologies â†’Machine learn-
ing;Supervised learning.
KEYWORDS
Game matchmaking, multimodal neural network, deep graph learn-
ing
ACM Reference Format:
Yu Sun, Kai Wang, Zhipeng Hu, Runze Wu, Yaoxin Wu, Wen Song, Xudong
Shen, Tangjie Lv, and Changjie Fan. 2024. MGMatch: Fast Matchmaking with
Nonlinear Objective and Constraints via Multimodal Deep Graph Learning.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3637528.3671553
1 INTRODUCTION
In recent years, player(s)-versus-player(s) (PVP) online games have
become one of the most popular game types. They not only provide
a competitive platform for player confrontation or cooperation, but
also provide a social platform to interact with other players. As a
core part of PVP online games, matchmaking system usually re-
ceives requests from players for the same period of time, and selects
several players from a candidate pool according to matchmaking
rules to form a match [ 17,19,27]. A common matchmaking system
is the ELO rating system [ 13], which evaluates a playerâ€™s skill rating
and recent performance to build a balanced game by minimizing
the rating gap between the two sides.
Efficiently solving practical matchmaking problems is non-trivial.
First, as a combinatorial optimization problem (COP), the number of
possible team compositions grows exponentially with the increase
of number of players. However, the algorithm should produce re-
sults very fast (e.g., within 100ms) to avoid keeping players wait-
ing. Second, the optimization objective could be nonlinear. While
balance is an important metric, other factors such as playerâ€™s ex-
perience and satisfaction should also be considered. Simple linear
5741
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yu Sun et al.
objective functions cannot capture such complicated relationships,
and in practice deep neural networks are often used to fit a complex
nonlinear function to evaluate matching results [ 8,11,17]. Third,
to model matchmaking rules, complex logical constraints (such as
IF, AND, OR, NOT) are needed. Moreover, matchmaking rules often
vary with the number and features of candidate players, so the type
and number of constraints are different for each problem instance.
Thus, game matchmaking in practical scenarios is a challeng-
ing combinatorial optimization problem with nonlinear objective
and constraints, and to the best of our knowledge, has not been
sufficiently discussed in the past. To solve constrained COP, practi-
tioners often resort to Mixed Integer Programming (MIP) solvers
such as SCIP [ 4], GUROBI [ 22], OR-Tools [ 37], etc. However, for
online game matchmaking, MIP solvers can not directly take neu-
ral network as the optimization objective. Meanwhile, the solving
efficiency of MIP solvers cannot meet the requirement of online
matchmaking. While it is possible to develop dedicated heuristic
algorithms for fast solving, they are incapable in handling complex
constraints and the solution quality is often low.
The application of deep learning in solving COP has attracted
much attention recently [3, 6]. Through carefully designed neural
architecture and training scheme, neural networks are able to learn
hidden patterns and knowledge offline from historical data, so as
to speed up online solving [ 45]. This new paradigm, called neural
combinatorial optimization (NCO), has also been explored in online
game matchmaking [ 8,11,17,49]. State-of-the-art methods [ 11,49]
formulate matchmaking as a sequential decision problem, where a
player is picked out from the pool at each step to form teams, and
employ deep reinforcement learning (DRL) to train matchmaking
policies. However, our problem is much more difficult than those
studied in previous works, making DRL much less effective. Due to
the existence of complex constraints, feasible solutions are sparse
in the solution space. For DRL based methods, the step-by-step con-
struction process cannot guarantee to find feasible solutions, hence
the DRL agentsâ€™ exploration efficiency is extremely low, making
them unable to converge in our case.
In this paper, instead of using DRL, we propose a novel super-
vised learning method to solve practical matchmaking problems
with nonlinear objective and constraints. We formulate this com-
plex problem as a MIP following recent linearization technique,
which allows us to solve it optimally using standard MIP solvers.
While directly solving this model is not viable for online real-time
matchmaking, it enables us to collect optimal solutions as labels
much more efficiently than the self-exploration of DRL. To accel-
erate MIP solving, we train a neural network that takes input a
matchmaking instance to directly predict the team assignment of
each player in one shot. Specifically, based on the graph formula-
tion of MIP, we design a multimodal network to capture essential
features of the matchmaking problem by learning its latent MIP
representation. Based on the assignment prediction, we solve a
surrogate MIP problem much simpler than the original one, so that
to meet the requirement of real-time solving. While we focus on
online game matchmaking in this paper, our method is not lim-
ited to it. We believe our method provides a new paradigm for
rapidly solving more general nonlinearly constrained optimization
problems with neural network objectives.
To summarize, our contributions are as follows:â€¢We propose an efficient Multimodal Graph learning based
Match making method MGMatch, to solve the online game
matchmaking problem with neural network objective, linear
constraints and logical constraints in milliseconds.
â€¢We transform the matchmaking problem with ReLU network
objectives and logical constraints as a standard MIP, which
enables obtaining optimal solutions as training labels using
MIP solvers, without the need of self-exploration as in DRL.
â€¢We design a multimodal neural network to extract rich fea-
tures from graph based MIP representation. Based on this ar-
chitecture, we directly predict the probability of each playerâ€™s
team assignment, and then solve a simple MIP problem to
obtain high-quality matchmaking solutions.
â€¢We conduct extensive evaluation on real-world game match-
making datasets, as well as online deployment test. Results
show that our method significantly outperforms state-of-the-
art DRL based methods, and is several orders of magnitude
faster than the widely used SCIP solver.
2 RELATED WORKS
Traditional matchmaking strategy. Classical research on match-
making system focus on individual competitive games such as Chess
(1-vs-1). By establishing individual playerâ€™s skill level model, they
aim at building a balanced match [ 17]. Typical matchmaking sys-
tems such as ELO [ 13], Bradley-Terry [ 5] and TrueSkill [ 27], Glicko
[16] have been widely used in individual competitive games [ 15].
However, for team competitions, we need to evaluate the skill level
of the team as a whole rather than individual players, so match-
making based on individual playerâ€™s skill level is no longer suitable
[17]. There are also many strategies take team effects into account,
improving classical strategies and extending them to team compe-
titions [ 34,39,41]. However, these strategies are still devoted to
evaluating individual abilities and interactions, while higher-order
interactions between players are largely ignored [17].
Deep learning based matchmaking. Inspired by the recent surge
of NCO [ 14,32,51], game matchmaking based on deep (reinforce-
ment) learning has received increasing attention lately. EoMM [ 8]
proposed a framework that maximizes the overall engagement of
players, and proved that matchmmaking based on equal skills is
a special case of EOMM. OptMatch [ 17] trains a neural network
to predict matchmaking quality by capturing high-order interper-
sonal interactions. During online planning, a heuristic is utilized
to generate multiple solutions and return the best one with the
highest predicted quality. GloMatch [ 11] formalizes game match-
making as a sequential decision problem, and introduces DRL to
learn high-quality matchmaking policies to pick out players from
the pool in each step. EnMatch [ 49] proposed to learn to predict
the engagement of each player, and employed DRL to train a graph
based policy network to maximize the gross player engagement. De-
spite its success in game matchmaking, DRL encounters difficulties
in solving our problem. Specifically, the neural network objective,
some linear constraints and logical constraints are defined on com-
plete solutions, and cannot be decomposed to partial solutions. This
means solution quality and feasibility can only be evaluated after a
complete DRL episode, inevitably resulting in sparse reward and
more severely, extremely low exploration efficiency since a large
5742MGMatch: Fast Matchmaking with Nonlinear Objective and Constraints via Multimodal Deep Graph Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Figure 1: Overall workflow of our method
number of training episodes end with infeasible solutions. In con-
trast, our supervised learning method directly use optimal solutions
as training labels. In addition, DRL agent needs to query the policy
network at every step, which is relatively slower than our method
which predicts the team assignment probabilities in one shot.
Neural MIP solving. As a general tool for modeling and solving
COP, using deep learning to accelerate MIP solving has attracted
much attention. One direction is to predict critical decisions in the
branch-and-cut algorithm of MIP solvers instead of using traditional
hand-crafted heuristics. Typical works include learning to branch
[14,21,40], learning to select node [ 25,43], learning to cut [ 36,46],
etc. Some researchers focus on learning large neighborhood search
policy to improve MIP solvers from the outside [ 29,44,50]. Our
work is more in line with MIP solution prediction [ 12,24,35], which
employs supervised learning to predict variable assignments end-
to-end. However, all existing neural MIP methods focus on standard
MIP problems with linear objectives and constraints, and the neural
architecture is all based on the bipartite graph neural network [ 14].
In contrast, we study a more complicated MIP problem with neural
network objective, linear constraints and logical constraints, and
propose a novel multimodal graph learning architecture to extract
features beyond the bipartite graph based MIP representation.
3 PROBLEM FORMULATION
The game matchmaking problem could be viewed as a variant of
a well-known COP, the assignment problem [ 7]. Givenğ‘play-
ers in the candidate pool, ğ·Ã—ğ¾players need to be picked out to
formğ·teams, each with ğ¾players. While our method can handle
matchmaking with unequal team size, without loss of generality,
we assume all teams have the same number of players. Given a
binary decision variable ğ‘¥ğ‘–ğ‘—indicating whether player ğ‘–is assigned
to teamğ‘—(ğ‘¥ğ‘–ğ‘—=1) or not, we collect all decision variables as a
matrixğ‘‹=[ğ‘¥ğ‘–ğ‘—]ğ‘Ã—ğ·, which can also be flattened as a vector
Â¯ğ‘‹=[ğ‘¥11,...,ğ‘¥ğ‘Ã—ğ·]T. Our aim is to find the best team assignment
to maximize playersâ€™ engagement:
max
ğ‘‹ğ¸ğ‘›ğº(ğ‘‹,ğ¼|ğœƒ) (1)
s.t.ğ·âˆ‘ï¸
ğ‘—=1ğ‘¥ğ‘–ğ‘—â‰¤1,âˆ€1â‰¤ğ‘–â‰¤ğ‘ (2)
ğ‘âˆ‘ï¸
ğ‘–=1ğ‘¥ğ‘–ğ‘—=ğ¾,âˆ€1â‰¤ğ‘—â‰¤ğ· (3)
ğ´Ë†ğ‘‹â‰¤ğ‘ (4)
ğ¿ğ¶={ğ¿ğ¶1,...,ğ¿ğ¶ğ‘›ğ‘} (5)
ğ‘¥ğ‘–ğ‘—âˆˆ{0,1},âˆ€1â‰¤ğ‘–â‰¤ğ‘,1â‰¤ğ‘—â‰¤ğ· (6)Here, the objective function ğ¸ğ‘›ğº(Â·|ğœƒ)is a pre-trained neural net-
work parameterized by ğœƒto predict the engagement of solution
ğ‘‹.ğ¼=[ğ¼1,...,ğ¼ğ‘]Tis the player feature matrix, where ğ¼ğ‘–âˆˆRğ‘‘ğ‘is
ağ‘‘ğ‘-dimensional raw feature vector of player ğ‘–recording impor-
tant player properties such as rank rating, win percentage, recent
performance, common occupation, etc. Constraints (2) ensure each
player is assigned to one team at most. Constraints (3) state that
each team consists of exactly ğ¾players. Constraints (4) and (5)
describe game matchmaking rules, which could be different across
different games and instances. Specifically, constraints (4) are a set
ofğ‘›ğ‘™linear constraints written in the standard MIP form, where Ë†ğ‘‹
is ağ‘‰-dimensional vector including all the ğ‘Ã—ğ·variables in Â¯ğ‘‹
andğ‘›ğ‘auxiliary variables for modeling some rules, and ğ´âˆˆRğ‘›ğ‘™Ã—ğ‘‰
andğ‘âˆˆRğ‘›ğ‘™are the coefficient matrix and right-hand-side vec-
tor respectively; constraints (5) are a set of ğ‘›ğ‘logical constraints,
each consists of a logical condition and a linear constraints (only
enforced when the condition is true), a simple example is as bellow:
if(NOTğ‘¥1ANDğ‘¥2):ğ‘¥3+ğ‘¥4<1 (7)
whereğ‘¥1,ğ‘¥2,ğ‘¥3,ğ‘¥4âˆˆ{0,1}. Most logical operators supported by
MIP solver such as IF, AND, OR, NOT, can be easily translated into
the patterns like Eq. (7).
The above problem is different from and much harder than stan-
dard MIP problem. While some of modern MIP solvers can incor-
porate logical constraints, they cannot directly accept nonlinear
neural networks as objective functions. Furthermore, their solving
efficiency cannot reach the requirement of real-time matchmaking.
Motivated by recent research on neural combinatorial optimization,
we design a novel data-driven method to significantly accelerate
the speed of solving this challenging problem.
4 METHODOLOGY
This section introduces our method MGMatch in detail. We first
present the design of engagement network, and discuss how to
incorporate it into standard MIP solver. Then, we propose a multi-
modal graph learning method to directly predict the team assign-
ment probability of each player, supervised by optimal solutions.
Finally, based on the prediction results, we formulate a surrogate
MIP problem to obtain high-quality feasible solutions in real time.
The overall workflow of our method is shown in Figure 1.
4.1 Engagement Network
As previously mentioned, playersâ€™ engagement is the key perfor-
mance indicator of matchmaking. In practice, engagement is estab-
lished in a data-driven way [ 8] , e.g., learned from historical data
using deep neural networks. Due to complex interactions among
players within a team or even across teams, engagement should
5743KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yu Sun et al.
be evaluated on the whole team assignment (e.g., ğ¸ğ‘›ğº in Eq. (1) is
defined on complete solution ğ‘‹), and is very hard to be modeled as
a linear combination of individual decision variables [11, 49].
However, MIP solvers mainly take linear or convex functions as
objectives. Fortunately, some recent works have noticed the impor-
tance of using neural networks as nonlinear objective functions [ 1].
This technique has recently been applied in deep reinforcement
learning [ 10,38], neural network verification [ 9,47], and neural
network precise compression [ 42]. The key idea is to exploit the
piecewise linear property of some standard neural units, such as
the rectified linear unit (ReLU), to linearize the nonlinear objective
using the well-known big- ğ‘€technique [20].
Figure 2: Architecture of the engagement network
Inspired by these studies, we design an engagement network
ğ¸ğ‘›ğº that can be processed by MIP solvers, as shown in Figure 2.
Taking input the playersâ€™ raw feature matrix ğ¼and a matchmaking
solutionğ‘‹,ğ¸ğ‘›ğº first captures the high-level representation (or
embedding) of each player ğ‘–by applying a feature extraction layer
toğ¼ğ‘–. Leteğ¼=[eğ¼1,...,eğ¼ğ‘]Tbe the extracted player embedding matrix,
where each eğ¼ğ‘–is of dimension ğ‘‘eğ‘. While it is possible to apply
more advanced structures, we use a multi-layer perceptron (MLP)
as the feature extraction layer. Then, based on ğ‘‹, we apply sum
pooling to the embeddings of players in each team to obtain a ğ‘‘eğ‘-
dimensional embedding for each team. Finally, we concatenate the
ğ·team embeddings, and feed it into an MLP with ReLU activation
to obtain the engagement prediction. To train the engagement
network, we collect a dataset of about 500,000 matches from recent
operation history. The loss function for training ğ¸ğ‘›ğº is:
Lğ¸ğ‘›ğº=1
ğµğµâˆ‘ï¸
ğ‘–=1
ğ¸ğ‘›ğº
ğ‘‹ğ‘–,ğ¼ğ‘–|ğœƒ
âˆ’ğ‘¦ğ‘–2
(8)
whereğµis dataset size, ğœƒis trainable parameters, and ğ‘‹ğ‘–,ğ¼ğ‘–,ğ‘¦ğ‘–are
the solution, player raw features, and label of the ğ‘–-th data point.
As shown in Appendix F, the prediction of ğ¸ğ‘›ğº is fairly accurate.
Linearization. Given a trained engagement network as the
objective function, we can use big- ğ‘€to linearize it with additional
variables and constraints. In fact, big- ğ‘€can also be used to linerize
the logical constraints in Eq. (5) [ 20]. More detailed description
about the big- ğ‘€transformation are provided in Appendix D. In this
way, we can formulate the matchmaking problem as a standard MIP
and solve it using solvers to obtain optimal solutions. However, the
big-ğ‘€based linearization introduces a large number of additional
variables and constraints, so that directly solving the transformed
MIP problem cannot meet the efficiency requirement of online game
matchmaking. In the following subsection, we develop a supervised
learning method to efficiently predict the solution, without the need
of solving the transformed MIP problem.4.2 Multimodal MIP Solution Prediction
Previous works on neural MIP solving have shown a promising
potential to predict values of binary variables in the optimal so-
lution, by estimating probability of each variable taking value 1
[12,24,35]. They consider an MIP instance as a bipartite graph [ 14]
with variable nodes and constraint nodes, and employ graph neural
networks as the neural architecture backbone to extract variable
features for probability prediction. However, existing methods can
only handle standard MIP with linear objective and constraints. An
easy-to-think solution is to apply the bipartite graph representation
to the linearized MIP problem. However, such a method may create
two issues. First, big- ğ‘€will increase the number of constraints and
variables, thereby increasing the complexity of prediction learning.
Second, coefficients in the objectives and constraints are important
input features of the graph neural network. But ğ‘€is usually a much
larger constant than other coefficients, which creates inconsistency
in data scale and could affect training stability.
Inspired by multimodal machine learning [ 2], we propose a mul-
timodal MIP network to combine different types of representations
required for matchmaking to generate high-quality prediction. Our
neural architecture captures three parts of representations, includ-
ing linear constraints, logical constraints, and player features. The
first two parts are captured by a bi-modal bipartite graph con-
volutional network (BB-GCN), and the last part is learned by a
Transformer [ 48] based team embedding network. In the experi-
ments, we will show that our multimodal architecture performs
significantly better than directly applying previous bipartite graph
neural network. The architecture is shown in Figure 3.
Figure 3: Architecture of the multimodal network
4.2.1 Bi-modal Bipartite GCN. To represent both the linear and
logical constraints in Eq. (2)-(5), we modify the existing bipartite
graph formulation in previous neural MIP methods [ 14,35,50], and
define a bi-modal bipartite graph denoted as G=(V,C,E), with
two types of constraint nodes. Specifically (detailed definitions of
the raw features can be found in Appendix G):
â€¢V={ğ‘£ğ‘–|ğ‘–=1,...,ğ‘‰}is the raw feature set of variable nodes,
whereğ‘£ğ‘–âˆˆRğ‘‘ğ‘£denotes the ğ‘‘ğ‘£-dimensional raw feature
vector of variable Ë†ğ‘¥ğ‘–inË†ğ‘‹.
â€¢C=Cğ‘™âˆªCğ‘={ğ‘ğ‘—|ğ‘—=1,...,ğ¶}is the raw feature set of
constraint nodes, where Cğ‘™covers all linear constraints in
Eq. (2)-(4),Cğ‘covers the linear constraint part of all logical
constraints in Eq. (5), e.g., ğ‘¥1+ğ‘¥2â‰¤1in Eq. (7), and ğ‘ğ‘—âˆˆRğ‘‘ğ‘
is ağ‘‘ğ‘-dimensional raw feature vector of constraint ğ‘—;
â€¢E={ğ‘’ğ‘–,ğ‘—|ğ‘–=1,...,ğ‘‰ ;ğ‘—=1,...,ğ¶}âˆˆRğ¶Ã—ğ‘‰Ã—ğ‘‘ğ‘’is the raw feature
set of edges, where ğ‘’ğ‘–,ğ‘—âˆˆRğ‘‘ğ‘’denotes ağ‘‘ğ‘’-dimensional
5744MGMatch: Fast Matchmaking with Nonlinear Objective and Constraints via Multimodal Deep Graph Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Figure 4: Illustration of key components in our MGMatch architecture
raw feature vector of edge (ğ‘–,ğ‘—)if variable Ë†ğ‘¥ğ‘–is involved in
constraintğ‘—, otherwiseğ‘’ğ‘–,ğ‘—is a zero vector.
Based on standard graph convolutional network (GCN) [ 31], we
design a bi-modal bipartite convolutional neural network (BB-GCN)
to process the above defined Gwith two constraint types, so as
to obtain useful representations of each variable, i.e., embeddings.
Before feeding the raw features V,C,Einto BB-GCN, we first pro-
cess them using MLPs to get the initial embeddings (of dimension
ğ‘‘â„=32) of variable nodes, constraint nodes and edges as follows:
V(0)=MLP(0)
ğ‘(V),C(0)=MLP(0)
ğ‘£(C),E=MLPğ‘’(E)(9)
where MLP(0)
ğ‘,MLP(0)
ğ‘£andMLPğ‘’are two-layer perceptrons with
ReLU activation. Then, we update the embeddings of variable nodes
and constraint nodes by performing ğ¾iterations of graph convo-
lution, with each involving two interleaved half-convolutions as
follows (an illustration is given in Figure 4 (a)).
The first half-convolution is to update constraint node embed-
dings based on variable node embeddings, which includes two parts:
linear constraint nodes update and logical constraint nodes update.
For linear constraints (also include the linear part of each logical
constraint), we follow existing neural MIP methods [ 14,24,35], and
update the corresponding embeddings as follows:
ğ‘(ğ‘˜+1)
ğ‘—â†MLP(ğ‘˜)
ğ‘ï£®ï£¯ï£¯ï£¯ï£¯ï£°ğ‘(ğ‘˜)
ğ‘—:âˆ‘ï¸
ğ‘–âˆˆN(ğ‘—)MLP(ğ‘˜)
ğ‘¡1
ğ‘(ğ‘˜)
ğ‘—,ğ‘£(ğ‘˜)
ğ‘–,ğ‘’ğ‘–,ğ‘—ï£¹ï£ºï£ºï£ºï£ºï£»(10)
where MLP(ğ‘˜)
ğ‘andMLP(ğ‘˜)
ğ‘¡1are two-layer perceptrons with ReLU
activation;ğ‘(ğ‘˜+1)
ğ‘—is the updated embedding of constraint node ğ‘—;
N(ğ‘—)includes all variable nodes involved in constraint ğ‘—;ğ‘(ğ‘˜)
ğ‘—,ğ‘£(ğ‘˜)
ğ‘–
are the previous embeddings of constraint node ğ‘—and variable node
ğ‘–, andğ‘’ğ‘–,ğ‘—is the corresponding embedding in Ewhich describes the
edge between ğ‘–andğ‘—; and[:]is concatenation. Eq. (10) means that
the linear constraint node embedding is updated by aggregating
surrounding information from the involved variables and edges, as
well as its embedding obtained in the previous iteration.
Besides linear constraints, there are many complex rules in the
matchmaking problem that can be modeled in the form of logical
constraints. They are more in line with peopleâ€™s use habits and can
model many complex logic rules in practical problems. However,
despite the wide applications of logical constraints, they are largely
ignored in previous neural MIP methods. To represent logical con-
straints, we propose a hypernetwork [ 23] based neural structure.
Hypernetwork is a kind of conditional network, which takes specificfeatures (that reflect the condition) as inputs to generate weights
of the target network. It enables us to train a single network that
accepts combinations of variable node embeddings (as conditions)
to adaptively generate target networks, which are used to process
logical constraint nodes under different conditions, and generate
their embeddings. Our hypernetwork structure is shown in Figure
4 (c), and the computation in ğ‘˜-th layer of BB-GCN is listed below:
eV(ğ‘˜)â†h
MLP(ğ‘˜)
Ë†ğ‘£
ğ¿ğ¹ğ‘—
V(ğ‘˜)ğ‘—=1,Â·Â·Â·,ğ‘›ğ‘i
(11)
ğœ“(ğ‘˜)â†â„ğ‘¦
eV(ğ‘˜)ğœ™(ğ‘˜)
(12)
C(ğ‘˜+1)
ğ‘â†C(ğ‘˜+1)
ğ‘âŠ™
ğ‘¡ğ‘”
C(ğ‘˜+1)
ğ‘ğœ“(ğ‘˜)
âˆ—ğ½
(13)
where MLP(ğ‘˜)
Ë†ğ‘£is two-layer perceptrons with ReLU activation, ğœ™(ğ‘˜)
is the trainable parameters of the hypernetwork, âŠ™is the Hadamard
product,âˆ—is matmul product, and ğ½is an all-one matrix. In Eq. (11),
ğ¿ğ¹ğ‘—selects the variable node embeddings associated with the con-
dition of logical constraint ğ¿ğ¶ğ‘—and supplements them with logical
features (an example is given in Appendix H), which is fed into
MLP(ğ‘˜)
Ë†ğ‘£to generate embeddings for each logical condition. Then,
in Eq. (12), the hypernetwork â„ğ‘¦(Â·|ğœ™(ğ‘˜))takes input the logical
condition embeddings eV(ğ‘˜)to generate parameters of the target
networksğœ“(ğ‘˜). Finally, in Eq. (13), the target network ğ‘¡ğ‘”(Â·|ğœ“(ğ‘˜))
takes the embedding of the linear part of each logical constraint
(C(ğ‘˜+1)
ğ‘ , the purple node in Figure 4 (a)) as input, and injects the
logical condition embedding learned in ğœ“(ğ‘˜)by performing a dot
product attention, so as to update the embedding of each logical
constraint (the yellow node in Figure 4 (a)).
The second half-convolution is to update variable node em-
beddings based on the updated constraint embeddings:
ğ‘£(ğ‘˜+1)
ğ‘–â†MLP(ğ‘˜)
ğ‘£ï£®ï£¯ï£¯ï£¯ï£¯ï£°ğ‘£(ğ‘˜)
ğ‘–:âˆ‘ï¸
ğ‘—âˆˆN(ğ‘–)MLP(ğ‘˜)
ğ‘¡2
ğ‘(ğ‘˜+1)
ğ‘—,ğ‘£(ğ‘˜)
ğ‘–,ğ‘’ğ‘–,ğ‘—ï£¹ï£ºï£ºï£ºï£ºï£»(14)
where MLP(ğ‘˜)
ğ‘andMLP(ğ‘˜)
ğ‘¡2are two-layer perceptrons with ReLU
activation,N(ğ‘–)is the set of all constraints which variable ğ‘–is in-
volved in, and ğ‘(ğ‘˜+1)
ğ‘—denotes the updated embedding of linear or
logical constraint, depending on the variable-constraint relation-
ship. Eq. (14) indicates that the information of constraint nodes are
passed and aggregated to the associated variable node in the ğ‘˜-th
layer of BB-GCN.
Since we only focus on predicting the player-team assignment
variablesğ‘¥ğ‘–ğ‘—, we collect the ğ‘Ã—ğ·corresponding variable node
5745KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yu Sun et al.
embeddings after ğ¾rounds of graph convolutions in BB-GCN, i.e.,
Â¯V(ğ¾), and further pass it through an MLP to obtain the final ğ‘‘â„-
dimensional variable embeddings as follows:
X_Embed =MLPğ¹
Â¯V(ğ¾)
(15)
where MLPğ¹is a two-layer perceptron with ReLU activation with
the output X_EmbedâˆˆR(ğ‘Ã—ğ·)Ã—ğ‘‘â„.
4.2.2 Team Embedding Network. While BB-GCN effectively
learns variable and constraint embeddings, it cannot capture infor-
mation with respect to player features and the nonlinear objective
function (engagement network), which is important for solution
prediction. In light of this, we design a team embedding network
to improve the prediction accuracy of matchmaking solutions. The
network structure is illustrated in Figure 4 (b). Given ğ·teams, we
process player features in each team by the following intra-team
embedding layer:
Intra_team ğ‘—=Encoder(1)
ğ‘—
[eğ¼1,...,eğ¼ğ‘]
,âˆ€ğ‘—=1,...,ğ· (16)
where[eğ¼1,...,eğ¼ğ‘]is the player embeddings produced by the feature
extraction layer of the engagement network. We employ the en-
coder block in Transformer [ 48] to build intra-team representations,
Intra_team ğ‘—âˆˆRğ‘Ã—ğ‘‘eğ‘, capturing interactions between each player
and its (potential) teammates. Then, we apply another Transformer
encoder to all the ğ‘Ã—ğ·intra-team representations, to obtain the
final team embeddings as follows:
T_Embed =Encoder(2)([Intra_team 1,...,Intra_team ğ·])(17)
where we further construct the representations between different
teams to obtain T_EmbedâˆˆR(ğ‘Ã—ğ·)Ã—ğ‘‘eğ‘.
4.2.3 Loss Function. To obtain the solution probability predic-
tion, we concatenate the output of BB-GCN and team embedding
network, and apply an MLP as follows:
ğ‘ƒ=MLPğ‘†[X_Embed :T_Embed] (18)
whereğ‘ƒ={ğ‘ğ‘–ğ‘—|ğ‘–=1,...,ğ‘ ;ğ‘—=1,...,ğ·}denotes the probability vector,
with each element ğ‘ğ‘–ğ‘—representing the probability of a player being
assigned to a team (i.e., ğ‘¥ğ‘–ğ‘—=1).MLPğ‘†is a two layer MLP with
ReLU activation for the first layer and Sigmoid activation for the
output layer. We adopt supervised learning to train the multimodal
MIP network, approximating the probabilities of decision variables
(i.e.,ğ‘ƒ) to the optimal solutions (i.e., labels). Specifically, we solve ğµ
matchmaking instances optimally using the big- ğ‘€transformation,
and update the network by the cross entropy loss below:
Lğ‘€ğº=1
ğµğ‘ğ·ğµâˆ‘ï¸
ğ‘˜=1ğ·âˆ‘ï¸
ğ‘—=1ğ‘âˆ‘ï¸
ğ‘–=1âˆ’h
ğ‘¦ğ‘˜
ğ‘–ğ‘—log(ğ‘ğ‘˜
ğ‘–ğ‘—)+(1âˆ’ğ‘¦ğ‘˜
ğ‘–ğ‘—)log(1âˆ’ğ‘ğ‘˜
ğ‘–ğ‘—)i
(19)
whereğ‘¦ğ‘˜
ğ‘–ğ‘—is the binary label, meaning that player ğ‘–is assigned to
teamğ‘—in theğ‘˜-th optimal solution in the training dataset.
4.3 Surrogate Problem
Although our method can produce high-quality solution prediction
ğ‘ƒ, directly sampling from it cannot guarantee solution feasibility.
Therefore, we propose to solve a surrogate of the problem in Eq.Table 1: Summary Statistics of the Datasets
Dataset #Matches # Features Match Mode
Dunk City Dynasty 100,000 196 3-vs-3
Justice Online 30,000 66 12-vs-12
(1)-(6) using standard MIP solver, where the nonlinear objective (1)
is replaced by a linear surrogate objective:
max
ğ‘‹ğ‘†(ğ‘‹,ğ‘ƒ)=ğ·âˆ‘ï¸
ğ‘—=1ğ‘âˆ‘ï¸
ğ‘–=1ğ‘ğ‘–ğ‘—ğ‘¥ğ‘–ğ‘— (20)
s.t.ğ‘‹âˆˆÎ© (21)
whereğ‘ƒ={ğ‘ğ‘–ğ‘—|ğ‘–=1,...,ğ‘ ;ğ‘—=1,...,ğ·}is the solution probability
prediction, and Î©is the feasible region specified by Eq. (2)-(6). The
rational of the surrogate problem is briefly explained as follows.
If we flatten ğ‘‹andğ‘ƒas two vectors, then the surrogate objective
ğ‘†(ğ‘‹,ğ‘ƒ)=ğ‘‹Â·ğ‘ƒ=|ğ‘‹||ğ‘ƒ|cos(ğ‘‹,ğ‘ƒ)is the dot product between ğ‘‹and
ğ‘ƒ. According to constraints in Eq. (3), any feasible solution should
satisfy|ğ‘‹|=ğ¾Ã—ğ·since exactly ğ·teams are formed and each with
ğ¾players. Since|ğ‘ƒ|is a constant, maximizing ğ‘†(ğ‘‹,ğ‘ƒ)is equivalent
to maximizing cos(ğ‘‹,ğ‘ƒ). So intuitively, in the feasible region of
the original problem, we find the optimal solution that best follows
the direction of the predicted probability vector. It is easy to verify
that if the prediction ğ‘ƒ=ğ‘ƒâˆ—is absolutely accurate, then ğ‘ƒâˆ—should
be the same as the optimal solution ğ‘‹âˆ—of the original problem,
which should also be the optimal solution of the surrogate problem.
Hence, we can find the original optimal solution by solving the
surrogate problem (though in this case we do not need to solve
it sinceğ‘ƒâˆ—=ğ‘‹âˆ—). In practice the prediction cannot be absolutely
accurate, but we can still get high-quality solutions by solving the
surrogate problem, with much shorter run time in comparison to
solving the original problem. We will verify this in the experiments.
5 EXPERIMENT
In this section, we conduct experiments on real-world online game
matchmaking datasets to evaluate our method.
5.1 Experimental Setting
Datasets. We conducted experiments on Dunk City Dynasty (3-
vs-3) and Justice Online (12-vs-12), two PVP online games released
by NetEase. Both games require to form ğ·=2teams. We collected
a large number of datasets from recent matches, and some statis-
tics are listed in Table 1. Compared with the datasets in previous
works [ 11,17,49], our dataset has a much larger number of player
features, and more complex complex matchmaking rules such as
career choices, individual skill levels, etc. Specifically, the average
number of constraints for Dunk City Dynasty and Justice Online
are74.8and148.7, respectively. We randomly split 70%, 20%, and
10% of the entire dataset as the training, testing, and validation set
respectively.
Model Training and Inference. To collect optimal solutions as
training labels, the advanced MIP solver SCIP is used, which is
also employed to solve the surrogate problem in Eq. (20)-(21). To
train the solution prediction network, we use the ADAM optimizer
[30] for 100 epochs of training. The learning rate is 3e-4 for the
5746MGMatch: Fast Matchmaking with Nonlinear Objective and Constraints via Multimodal Deep Graph Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 2: Experimental results on the industrial datasets. * denotes the optimal solution. The best results except the optimal
SCIP solutions are highlighted in bold.
Dunk City Dynasty (3-vs-3) Justice Online (12-vs-12)
Method Objective Gap Time Method Objective Gap Time
Random 5.61 2.60% 96ms Random / / /
GloMatch [11] 5.09 11.63% 96ms GloMatch [11] / / /
EnMatch [49] 5.33 7.47% 99ms EnMatch [49] / / /
OptMatch [17] 5.67 1.56% 93ms OptMatch [17] 13.83 20.61% 988ms
SCIP w/ time limit 5.51 4.34% 96ms SCIP w/ time limit 7.52 56.83% 990ms
SCIP w/o time limit *5.76 *0.00% 4s SCIP w/o time limit *17.42 *0.00% 19s
MGMatch (ours) 5.74 0.35% 39ms MGMatch (ours) 16.84 3.33% 91ms
BGCN
5.39 6.42% 34ms BGCN 13.48 22.62% 87ms
BGCN-BigM 5.24 9.03% 213ms BGCN-BigM 13.54 22.27% 398ms
first 50 epochs and 3e-6 for the next 50 epochs, and the model that
performs best on the validation set during the training process is
saved as the final model. To ensure the fairness of the experiments,
we run all methods on a single machine with i9-9900K CPU and a
single NVIDIA GeForce RTX 2080S GPU with 24GB memory.
Baselines. Our method is compared with the following methods:
â€¢GloMatch [11]. The first algorithm that introduces DRL to
game matchmaking.
â€¢EnMatch [49]. State-of-the-art DRL based game matchmak-
ing algorithm that greatly improves GloMatch.
â€¢Random. We also test a random policy under the same DRL
environment as GloMatch and EnMatch, where the players
are randomly sampled from the candidate pool.
â€¢OptMatch [17]. A two-stage matchmaking algorithm, where
the first stage trains the model and the second stage evalu-
ates the generated solutions with engagement network and
returns the best one. Here for the second stage, we use state-
of-the-art constraint solver Google OR-Tools [ 37] to generate
as many feasible solutions as possible within the time limit.
â€¢SCIP [4]. State-of-the-art open source MIP solver, which is
applied to the linearized matchmaking MIP. Without time
limit, SCIP is guaranteed to find the optimal solution.
â€¢Bipartite GCN (BGCN). This baseline applies the standard
bipartite GCN architectures widely used in neural MIP meth-
ods (e.g., [ 14,24,35,50]) for solution prediction, which can
only process linear constraints.
â€¢BGCN-BigM. This baseline applies standard BGCN to the
linearized matchmaking MIP problem for solution predic-
tion, which includes all information of the neural network
objective and logical constraints.
For BGCN and BGCN-BigM, the predicted solution probability is
used to solve the surrogate problem in Eq. (20)-(21). Considering
the efficiency requirement of online matchmaking, we set a time
limit (0.1s for Dunk City Dynasty and 1s for Justice Online) for all
methods, except SCIP which is also allowed to run without time
limit. For DRL based methods GloMatch, EnMatch and Random,
we generate as many solutions as possible by sampling the learned
policy within the time limit, and return the best one.Evaluation metrics. We report the results on all testing sets with
three metrics. The metric Objective is the average engagement
of all solutions; note that if no feasible solution is found, the en-
gagement value is 0. The metric Gap is the ratio of Objective with
respect to the optimal solution found by SCIP. The metric Time is
the average solving time.
5.2 Results and Analysis
Experimental results are summarized in Table 2. In Dunk City Dy-
nasty, our method achieve good results in less than 40ms, and is
only 0.35% away from the optimal solution. DRL based methods Glo-
Match and EnMatch do not perform well, because a large number
of generated solutions are infeasible, due to the complex match-
making rules in our case. They are even outperformed by Random,
since it does not need to query policy network and more solutions
can be sampled within the time limit. We have tried to improve
the training performance of DRL based methods with improved
action masking (remove infeasible actions as soon as possible) and
reward design (add infeasible penalty), but it didnâ€™t work very well.
SCIP could achieve the optimum if there is no time limit, but this is
not allowed in practical scenarios because too long solution times
can place a huge burden on the game server and keep players wait-
ing. However, if SCIP is limited to the same run time (0.1) as our
method, the solution quality significantly degrades. Figure 5 shows
the solving progress of our method and SCIP, which clearly demon-
strates the advantage of our method in quickly finding high-quality
solutions. Among the three solution prediction based approaches,
BGCN gives the worst performance due to the lack of modality with
respect to logical constraints and nonlinear objective. While BGCN-
BigM should theoretically covers all the information, however, it
can hardly improve BGCN due to too many additional variables
and the scale issue of the big M values. Moreover, the run time
of BGCN-BigM is much longer since a larger graph needs to be
processed. In contrast, our method has almost the same efficiency
as BGCN, but has significantly better solution quality.
The above observations are consistent for Justice Online, which
is harder than Dunk City Dynasty since the candidate pool is larger
and more constraints are enforced. Nevertheless, the performance
of our method is more prominent. We can see that within 100ms
5747KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yu Sun et al.
Figure 5: Comparison of the solving efficiency between SCIP
and our method
run time, our method has a large improvement over other baseline
methods, and is only 3.33% away from the optimal solution. SCIP
needs 19s on average to find the optimal solution, indicating the
difficulty of Justice Online. Random, GloMatch and EnMatch can
hardly find a feasible solution because the constraints are too com-
plicated. Optmatch did not perform as well as it did in Dunk City
Dynasty, probably because the search space is much larger. BGCN
and BGCN-BigM also performs much worse than our method. In
summary, MGMatch significantly outperforms other methods in
terms of both run time and solution quality.
6 ONLINE DEPLOYMENT
We implemented the proposed MGMatch algorithm in industrial
matchmaking services within the two games, i.e., 3-vs-3 Dunk
City Dynasty and 12-vs-12 Justice Online. Each system primarily
involves complex matchmaking constraints and employs a fixed
deep neural network for simulating player engagement as the ob-
jective function. In a one-week online A/B testing, we compared
MGMatchâ€™s performance with OR-Tools and OptMatch, the best-
performing learning based baseline as in Tabel 2. When OR-Tools
operated without an objective function, the problem degraded into
a search for the first feasible solution. Note that the approach of us-
ing OR-Tools with ReLU network objectives and logical constraints
failed to meet the latency requirements of the live system, and
for the same reason we also do not compare with SCIP. The time
consumption of all algorithms is constrained to within 200ms per
request on the game server.
6.1 Results
As user engagement optimization algorithms significantly impact
the active player count across different A/B test traffic, we utilize
the total number of matches played under the same A/B test traffic
as a measure of user engagement, rather than the average number
of matches per player. This metric is tantamount to the aggregate
of player retention events, where a retention event is defined as a
player participating in the subsequent match within a 30-minute
window. As anticipated, engagement-oriented algorithm MGMatch
significantly outperforms the OR-Tools strategy, which lacks ob-
jective function, by delivering a greater number of match sessions
for players. Consistent with results from offline datasets, MGMatch
notably achieves the highest number of matches, specifically 8.23%
for 3-vs-3 and 9.30% for 12-vs-12 higher than OptMatch. In theTable 3: Online performance comparison on two games. The
best results are marked in Bold.
Dunk City Dynasty Justice Online
OR-Tools 167,773 33,225
OptMatch [17] 179,362 35,152
MGMatch (Ours) 194,130 38,414
Improvement 8.23% 9.30%
expansive 12-vs-12 scenario, MGMatch exhibits even greater im-
provement. This can be attributed to MGMatch being specifically
designed to address complex constrained problems. The results are
summarized in Table 3.
6.2 System Performance
In the online service environment, our multimodal MIP solution
prediction network takes 40-60ms for inference on a GPU device
and 100-200ms on a CPU device. According to online service logs,
matchmaking requests typically involve fewer than 100 players, and
our MGMatch-based system averages less than 100ms in responding
to a matchmaking request using GPU. Our method demonstrates
superior time efficiency compared to reinforcement learning based
method. This is due to MGMatch being invoked only once to gener-
ate the matchmaking solution prediction, as opposed to sequentially
generating matching players one by one in the DRL approaches.
Currently, MGMatch is applied to generate a single match a time,
but its use of optimization solvers naturally allows for expansion
to making multiple matches, which enables further optimizing the
time efficiency of MGMatch.
7 CONCLUSIONS AND FUTURE WORK
In this paper, we propose a novel and fast online game matchmaking
algorithm, which allows solving game matchmaking problems with
neural networks as nonlinear objectives and logical constraints to
model complex matchmaking rules. Extensive experiments on real
industrial datasets and online deployment evaluation show that
our algorithm significantly outperforms other methods in solution
quality and solving speed. A limitation of our approach is that label
collection cost can be a bottleneck for large problems, which is also
a common issue for supervised learning based neural combinatorial
optimization. And although our method has achieved good results,
there is still a gap between the solution obtained by our algorithm
and the optimal solution. To further improve the solution prediction
accuracy is what we need to do in the future. Due to the complexity
of the game matchmaking problem, existing methods based solely
on deep (reinforcement) learning cannot deliver good results, so
an MIP solver is necessary. Designing an end-to-end method for
real-time game matchmaking in practical scenarios is also one of
our future research focuses.
ACKNOWLEDGMENTS
This work is supported by the National Natural Science Foundation
of China under Grant 62102228, and Shandong Provincial Natural
Science Foundation, China under Grant ZR2021QF063.
5748MGMatch: Fast Matchmaking with Nonlinear Objective and Constraints via Multimodal Deep Graph Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
REFERENCES
[1]Ross Anderson, Joey Huchette, Will Ma, Christian Tjandraatmadja, and
Juan Pablo Vielma. 2020. Strong mixed-integer programming formulations for
trained neural networks. Mathematical Programming 183, 1-2 (2020), 3â€“39.
[2]Tadas BaltruÅ¡aitis, Chaitanya Ahuja, and Louis-Philippe Morency. 2018. Multi-
modal machine learning: A survey and taxonomy. IEEE Transactions on Pattern
Analysis and Machine Intelligence 41, 2 (2018), 423â€“443.
[3]Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. 2021. Machine learning for
combinatorial optimization: a methodological tour dâ€™horizon. European Journal
of Operational Research 290, 2 (2021), 405â€“421.
[4]Ksenia Bestuzheva, Mathieu BesanÃ§on, Wei-Kun Chen, Antonia Chmiela, Tim
Donkiewicz, Jasper van Doornmalen, Leon Eifler, Oliver Gaul, Gerald Gamrath,
Ambros Gleixner, et al .2021. The SCIP optimization suite 8.0. arXiv preprint
arXiv:2112.08872 (2021).
[5]Ralph Allan Bradley and Milton E Terry. 1952. Rank analysis of incomplete block
designs: I. The method of paired comparisons. Biometrika 39, 3/4 (1952), 324â€“345.
[6]Quentin Cappart, Didier ChÃ©telat, Elias B Khalil, Andrea Lodi, Christopher Morris,
and Petar VeliÄkoviÄ‡. 2023. Combinatorial optimization and reasoning with graph
neural networks. Journal of Machine Learning Research 24, 130 (2023), 1â€“61.
[7]Dirk G Cattrysse and Luk N Van Wassenhove. 1992. A survey of algorithms for
the generalized assignment problem. European Journal of Operational Research
60, 3 (1992), 260â€“272.
[8]Zhengxing Chen, Su Xue, John Kolen, Navid Aghdaie, Kazi A Zaman, Yizhou Sun,
and Magy Seif El-Nasr. 2017. Eomm: An engagement optimized matchmaking
framework. In Proceedings of the 26th International Conference on World Wide
Web. 1143â€“1150.
[9]Chih-Hong Cheng, Georg NÃ¼hrenberg, and Harald Ruess. 2017. Maximum
resilience of artificial neural networks. In Automated Technology for Verification
and Analysis: 15th International Symposium, ATVA 2017, Pune, India, October 3â€“6,
2017, Proceedings 15. Springer, 251â€“268.
[10] Arthur Delarue, Ross Anderson, and Christian Tjandraatmadja. 2020. Reinforce-
ment learning with combinatorial actions: An application to vehicle routing.
Advances in Neural Information Processing Systems 33 (2020), 609â€“620.
[11] Qilin Deng, Hao Li, Kai Wang, Zhipeng Hu, Runze Wu, Linxia Gong, Jianrong
Tao, Changjie Fan, and Peng Cui. 2021. Globally optimized matchmaking in
online games. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge
Discovery & Data Mining. 2753â€“2763.
[12] Jian-Ya Ding, Chao Zhang, Lei Shen, Shengyin Li, Bing Wang, Yinghui Xu, and
Le Song. 2020. Accelerating primal solution findings for mixed integer programs
based on solution prediction. In Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 34. 1452â€“1459.
[13] Arpad E Elo and Sam Sloan. 1978. The rating of chessplayers: Past and present.
(1978).
[14] Maxime Gasse, Didier ChÃ©telat, Nicola Ferroni, Laurent Charlin, and Andrea
Lodi. 2019. Exact combinatorial optimization with graph convolutional neural
networks. Advances in Neural Information Processing Systems 32 (2019), 15580â€“
15592.
[15] Mark E Glickman. 1995. A comprehensive guide to chess ratings. American Chess
Journal 3, 1 (1995), 59â€“102.
[16] Mark E Glickman. 1999. Parameter estimation in large dynamic paired compari-
son experiments. Journal of the Royal Statistical Society Series C: Applied Statistics
48, 3 (1999), 377â€“394.
[17] Linxia Gong, Xiaochuan Feng, Dezhi Ye, Hao Li, Runze Wu, Jianrong Tao,
Changjie Fan, and Peng Cui. 2020. Optmatch: Optimized matchmaking via
modeling the high-order interactions on the arena. In Proceedings of the 26th
ACM SIGKDD International Conference on Knowledge Discovery & Data Mining.
2300â€“2310.
[18] Yu Gong, Yu Zhu, Lu Duan, Qingwen Liu, Ziyu Guan, Fei Sun, Wenwu Ou, and
Kenny Q Zhu. 2019. Exact-k recommendation via maximal clique optimization.
InProceedings of the 25th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining. 617â€“626.
[19] Thore Graepel and Ralf Herbrich. 2006. Ranking and matchmaking. Game
Developer Magazine 25 (2006), 34.
[20] Ignacio E Grossmann. 2002. Review of nonlinear mixed-integer and disjunctive
programming techniques. Optimization and Engineering 3 (2002), 227â€“252.
[21] Prateek Gupta, Maxime Gasse, Elias Khalil, Pawan Mudigonda, Andrea Lodi, and
Yoshua Bengio. 2020. Hybrid models for learning to branch. Advances in Neural
Information Processing Systems 33 (2020), 18087â€“18097.
[22] LLC Gurobi Optimization. 2021. Gurobi optimizer reference manual.
[23] David Ha, Andrew Dai, and Quoc V. Le. 2016. HyperNetworks. arXiv preprint
arXiv:1609.09106 (2016).
[24] Qingyu Han, Linxin Yang, Qian Chen, Xiang Zhou, Dong Zhang, Akang Wang,
Ruoyu Sun, and Xiaodong Luo. 2023. A GNN-Guided Predict-and-Search Frame-
work for Mixed-Integer Linear Programming. In International Conference on
Learning Representations.
[25] He He, Hal Daume III, and Jason M Eisner. 2014. Learning to search in branch
and bound algorithms. Advances in Neural Information Processing Systems 27(2014), 3293â€“3301.
[26] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition. 770â€“778.
[27] Ralf Herbrich, Tom Minka, and Thore Graepel. 2006. TrueSkillâ„¢: a Bayesian
skill rating system. Advances in Neural Information Processing Systems 19 (2006),
569â€“576.
[28] Jie Hu, Li Shen, and Gang Sun. 2018. Squeeze-and-excitation networks. In Pro-
ceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 7132â€“
7141.
[29] Taoan Huang, Aaron M Ferber, Yuandong Tian, Bistra Dilkina, and Benoit Steiner.
2023. Searching large neighborhoods for integer linear programs with contrastive
learning. In International Conference on Machine Learning. PMLR, 13869â€“13890.
[30] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[31] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph
convolutional networks. arXiv preprint arXiv:1609.02907 (2016).
[32] Wouter Kool, Herke van Hoof, and Max Welling. 2019. Attention, Learn to Solve
Routing Problems!. In International Conference on Learning Representations.
[33] Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-
based learning applied to document recognition. Proc. IEEE 86, 11 (1998), 2278â€“
2324.
[34] Yao Li, Minhao Cheng, Kevin Fujii, Fushing Hsieh, and Cho-Jui Hsieh. 2018.
Learning from group comparisons: exploiting higher order interactions. Advances
in Neural Information Processing Systems 31 (2018), 4981â€“4990.
[35] Vinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid Von Glehn, Pawel Lichocki,
Ivan Lobov, Brendan Oâ€™Donoghue, Nicolas Sonnerat, Christian Tjandraatmadja,
Pengming Wang, et al .2020. Solving mixed integer programs using neural
networks. arXiv preprint arXiv:2012.13349 (2020).
[36] Max B Paulus, Giulia Zarpellon, Andreas Krause, Laurent Charlin, and Chris
Maddison. 2022. Learning to cut by looking ahead: Cutting plane selection
via imitation learning. In International Conference on Machine Learning. PMLR,
17584â€“17600.
[37] Laurent Perron and Vincent Furnon. [n. d.]. OR-Tools. Google. https://developers.
google.com/optimization/
[38] Moonkyung Ryu, Yinlam Chow, Ross Anderson, Christian Tjandraatmadja, and
Craig Boutilier. 2019. CAQL: Continuous action Q-learning. arXiv preprint
arXiv:1909.12397 (2019).
[39] Anna Sapienza, Palash Goyal, and Emilio Ferrara. 2019. Deep neural networks
for optimal team composition. Frontiers in big Data 2 (2019), 14.
[40] Lara Scavuzzo, Feng Chen, Didier ChÃ©telat, Maxime Gasse, Andrea Lodi, Neil
Yorke-Smith, and Karen Aardal. 2022. Learning to branch with tree mdps. Ad-
vances in Neural Information Processing Systems 35 (2022), 18514â€“18526.
[41] Aleksandr Semenov, Peter Romov, Sergey Korolev, Daniil Yashkov, and Kirill
Neklyudov. 2017. Performance of machine learning algorithms in predicting
game outcome from drafts in dota 2. In Analysis of Images, Social Networks and
Texts: 5th International Conference, AIST 2016, Yekaterinburg, Russia, April 7-9,
2016, Revised Selected Papers 5. Springer, 26â€“37.
[42] Thiago Serra, Xin Yu, Abhinav Kumar, and Srikumar Ramalingam. 2021. Scaling
up exact neural network compression by ReLU stability. Advances in neural
information processing systems 34 (2021), 27081â€“27093.
[43] Jialin Song, Ravi Lanka, Yisong Yue, and Masahiro Ono. 2020. Co-training for
policy learning. In Uncertainty in Artificial Intelligence. PMLR, 1191â€“1201.
[44] Jialin Song, Yisong Yue, Bistra Dilkina, et al .2020. A general large neighborhood
search framework for solving integer linear programs. Advances in Neural
Information Processing Systems 33 (2020), 20012â€“20023.
[45] Wen Song, Zhiguang Cao, Jie Zhang, Chi Xu, and Andrew Lim. 2022. Learn-
ing variable ordering heuristics for solving constraint satisfaction problems.
Engineering Applications of Artificial Intelligence 109 (2022), 104603.
[46] Yunhao Tang, Shipra Agrawal, and Yuri Faenza. 2020. Reinforcement learning
for integer programming: Learning to cut. In International conference on machine
learning. PMLR, 9367â€“9376.
[47] Vincent Tjeng, Kai Xiao, and Russ Tedrake. 2017. Evaluating robustness of neural
networks with mixed integer programming. arXiv preprint arXiv:1711.07356
(2017).
[48] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[49] Kai Wang, HaoyuLiu Liu, ZhipengHu Hu, Xiaochuan Feng, Minghao Zhao, Shiwei
Zhao, Runze Wu, Xudong Shen, Lv TangjieLv, and Changjie Fan. 2024. EnMatch:
Matchmaking for Better Player Engagement via Neural Combinatorial Optimiza-
tion. In Proceedings of the AAAI Conference on Artificial Intelligence.
[50] Yaoxin Wu, Wen Song, Zhiguang Cao, and Jie Zhang. 2021. Learning large neigh-
borhood search policy for integer programming. Advances in Neural Information
Processing Systems 34 (2021), 30075â€“30087.
[51] Cong Zhang, Wen Song, Zhiguang Cao, Jie Zhang, Puay Siew Tan, and Xu
Chi. 2020. Learning to dispatch for job shop scheduling via deep reinforcement
learning. Advances in Neural Information Processing Systems 33 (2020), 1621â€“1632.
5749KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yu Sun et al.
A A SHORT INTRODUCTION OF MIP
Mixed Integer Programming ( MIP ) problem is an important part
of operations research optimization. If the objective function of a
MIP problem is linear (which is its standard assumption), it can be
expressed as follows:
maxğ‘¥ğ‘âŠ¤ğ‘¥
s.t.ğ´ğ‘¥â‰¤ğ‘
ğ‘¥âˆˆÎ©(22)
Whereğ‘¥is a vector of variables, ğ‘is the coefficient vector of the
objective function, ğ´is the coefficient matrix of constraints, ğ‘is the
right-hand-side vector, and Î©is the feasible region of ğ‘¥. Many prob-
lems in logistics, transportation and other fields can be modeled as
MIP, such as traveling salesman problem [ 32], job shop scheduling
problem [ 51], etc. Standard MIP instances can be solved by solvers,
such as Gurobi, CPLEX, and SCIP. They use highly optimized exact
algorithms (e.g., branch-and-cut), which has the theoretical guar-
antee of finding the optimal solution. But due to the complexity
of MIP, the exact algorithms are often slow in speed, though it is
possible to terminate the algorithm early with a time limit and use
the returned best solution. Recently, there is a trend of employing
deep learning to assist solvers in handling large-scale problems.
Please see "Neural MIP solving" in Section 2 for more details.
B SOLUTION SPARSITY
We sample 100 instances and 10M solutions for each one using
the procedure in [ 49]. All solutions are feasible with only team
formation constraints (Eq. (2)(3)) as [ 49]. With all constraints in our
paper, only 7.8% and 0.000049% solutions for Dunk City Dynasty
and Justice Online are feasible. In addition, DRL based methods [ 49]
can only obtain a reward after forming a complete match. Under
such sparsity, it is hard for [ 49] to find sufficient training signals
(rewards) and result in low-quality policies.
C ABLATION EXPERIMENT
We provide ablation of including both logical constraints ( LC ) and
team embeddings ( TE ) . TE contributes more than LC which is
expected since LC only accounts for 14% and 11% of all constraints in
Dunk City Dynasty and Justice Online, and TE captures information
of many player features directly related to the objective. In addition,
we try to add all player features to the graph and using BB-GCN
(named All Graph) to predict assignment directly. The results show
that our method is better than All Graph, which may because mixing
all the information in the graph will increase the learning difficulty,
since the player features are only used for the objective and have
no relationship with variables and constraints of MIP.
D BIGM TRANSFORMATION
D.1 ReLU Network
The BigM method is a linearization method commonly used in
operations research [ 20], which transforms a nonlinear constraint
into multiple linear constraints by using a large number M and
multiple intermediate variables. The BigM method, combined with
ReLU networks, has produced a lot of interesting works in differentareas of deep learning [ 38,42,47], which has also inspired this work
on game matchmaking. The ReLU activation ğ‘¦(ğ‘–)
ğ‘™=max(0,ğ‘¥(ğ‘–)
ğ‘™)
can be linearized by the BigM method as below:
ğ‘¦(ğ‘–)
ğ‘™â‰¥0
ğ‘¦(ğ‘–)
ğ‘™â‰¥ğ‘¥(ğ‘–)
ğ‘™
ğ‘€(1âˆ’â„(ğ‘–)
ğ‘™)â‰¥ğ‘¦(ğ‘–)
ğ‘™
ğ‘¥(ğ‘–)
ğ‘™+ğ‘€(1âˆ’ğ‘(ğ‘–)
ğ‘™)â‰¥ğ‘¦(ğ‘–)
ğ‘™
â„(ğ‘–)
ğ‘™+ğ‘(ğ‘–)
ğ‘™â‰¥1
â„(ğ‘–)
ğ‘™,ğ‘(ğ‘–)
ğ‘™âˆˆ{0,1}(23)
whereğ‘¥(ğ‘–)
ğ‘™denotes the input of the ğ‘–-th neuron of the activation
function in layer ğ‘™,ğ‘¦(ğ‘–)
ğ‘™denotes the output, ğ‘€is a very large num-
ber,â„(ğ‘–)
ğ‘™andğ‘(ğ‘–)
ğ‘™are intermediate variables. By the above formulas,
the BigM method can easily transform a multi-layer perceptron
(MLP) with ReLU activation function as an MIP model. We refer
the interested readers to [ 20] for more details on the BigM transfor-
mation. In addition to MLP, many neural networks can be linearly
represented and used in our framework, such as CNN [ 33], ResNet
[26], SENet [28], etc., which we will leave as future work.
Table 4: Ablation Experiment
Dunk City Dynasty Justice Online
BGCN 5.39 13.48
BGCN+LC 5.44 13.54
BGCN+TE 5.66 16.66
All Graph 5.63 14.91
MGMatch 5.74 16.84
D.2 Logical Constraints
Similar to the above, the logical constraints could also be linearized
the BigM method. Taking the OR constraint as a simple example,
ğ‘¥1=1ORğ‘¥2=1can be linearized as below:
ğ‘¥1â‰¤1+ğ‘€(1âˆ’â„)
ğ‘¥2â‰¤1+ğ‘€(1âˆ’ğ‘)
ğ‘¥1â‰¥1âˆ’ğ‘€(1âˆ’â„)
ğ‘¥2â‰¥1âˆ’ğ‘€(1âˆ’ğ‘)
â„+ğ‘â‰¥1
â„,ğ‘âˆˆ{0,1}(24)
whereâ„andğ‘are intermediate variables.
E OFFLINE TRAINING COST
We provide the offline training cost of our method and DRL based
methods, and the results are summarized in Table 5. In offline
training, our major cost is on label collection, while training is
more efficient than DRL. We use three i9-9900K CPUs for label
collection, one i9-9900K CPU and one NVIDIA GeForce RTX 2080S
GPU for training.
5750MGMatch: Fast Matchmaking with Nonlinear Objective and Constraints via Multimodal Deep Graph Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 5: Offline training cost of different method.
Dunk City Dynasty(3vs3) Justice Online(12vs12)
Collect Labels Training Collect Labels Training
GloMatch / 1.1d / 2d
EnMatch / 1.1d / 2d
Ours 1.1d 4.3h 1.4 d 2.8h
Table 6: Prediction accuracies of MGMatch and EnMatch.
Dunk City Dynasty Justice Online
MSE MAE MSE MAE
MGMatch (Ours) 0.177 0.353 0.099 0.198
EnMatch [49] 0.173 0.348 0.097 0.189
Table 7: Raw features of BB-GCN.
Feature Types Description
VariableOut degree of variable
Average coefficients of variable
Maximum coefficients of variable
Minimum coefficients of variable
Binary variable or not
ConstraintAverage coefficients of constraint
Sum of the coefficients of the constraint
Right-hand-side value of the constraint
The sense of the constraint
The serial number of constraints
Linear constraint or not
Edge Coefficient of variable in constraint
F ENGAGEMENT PREDICTION ACCURACY
Although our engagement network employs a simple neural struc-
ture, its prediction accuracy is close to other methods. Here wecompare with EnMatch [ 49], the model with the highest prediction
accuracy in previous works. We use two commonly used metrics,
i.e., Mean Square Error (MSE) and Mean Absolute Error (MAE), to
measure the accuracy and indicate the performance of our method
and EnMatch. Results in Table 6 manifest that the accuracy of our
model is close to that of EnMatch in game matchmaking. Note that
our method has a great improvement both in objective and run
time compared to previous methods, as shown in Table 2 in main
paper, so the small loss of accuracy is acceptable.
G RAW FEATURES OF BB-GCN
To favorably represent an MIP problem by its informative charac-
teristics, we followed the previous works [ 18,24,50] and design
a set of features that can be extracted for variables, constraints,
and edges. These features could be obtained before the problem
is solved, so they are lightweight and meet the need of real-time
solution for game matchmaking. The specific raw features used in
BB-GCN is displayed in Table 7.
H LOGICAL FEATURES
Logical features are independent from the raw features of BB-GCN.
We exclusively design the logical features owing to its difference
from the normal constraints, i.e., the same variable could be used in
different logical conditions in logical constraints, which should be
reflected by different features. We show one example of the logical
features in Table 8.
Table 8: An example of logical feature. The logical features
of a variable node are 1 if it is selected, and -1 if it is selected
and inverted by NOT.
Logical ConstraintLogical Feature
ğ‘¥1ğ‘¥2
if (ğ‘¥1ANDğ‘¥2)ğ‘¥3+ğ‘¥4<1 1 1
if ( NOTğ‘¥1ANDğ‘¥2)ğ‘¥3+ğ‘¥4>1 -1 1
5751