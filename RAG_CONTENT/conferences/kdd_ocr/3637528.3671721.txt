POND: Multi-Source Time Series Domain Adaptation with
Information-Aware Prompt Tuning
Junxiang Wangâˆ—
NEC Labs America
Princeton, New Jersey, USAGuangji Baiâˆ—
Emory University
Atlanta, Georgia, USAWei Cheng
NEC Labs America
Princeton, New Jersey, USA
Zhengzhang Chen
NEC Labs America
Princeton, New Jersey, USALiang Zhao
Emory University
Atlanta, Georgia, USAHaifeng Chen
NEC Labs America
Princeton, New Jersey, USA
ABSTRACT
Time series domain adaptation stands as a pivotal and intricate
challenge with diverse applications, including but not limited to
human activity recognition, sleep stage classification, and machine
fault diagnosis. Despite the numerous domain adaptation tech-
niques proposed to tackle this complex problem, they primarily
focus on domain adaptation from a single source domain. Yet, it is
more crucial to investigate domain adaptation from multiple do-
mains due to the potential for greater improvements. To address
this, three important challenges need to be overcome: 1). The lack
of exploration to utilize domain-specific information for domain
adaptation, 2). The difficulty to learn domain-specific information
that changes over time, and 3). The difficulty to evaluate learned
domain-specific information. In order to tackle these challenges
simultaneously, in this paper, we introduce PrOmpt-based domaiN
Discrimination (POND), the first framework to utilize prompts for
time series domain adaptation. Specifically, to address Challenge
1, we extend the idea of prompt tuning to time series analysis and
learn prompts to capture common and domain-specific information
from all source domains. To handle Challenge 2, we introduce a con-
ditional module for each source domain to generate prompts from
time series input data. For Challenge 3, we propose two criteria to
select good prompts, which are used to choose the most suitable
source domain for domain adaptation. The efficacy and robustness
of our proposed POND model are extensively validated through
experiments across 50 scenarios encompassing four datasets. Ex-
perimental results demonstrate that our proposed POND model
outperforms all state-of-the-art comparison methods by up to 66%
on the F1-score.
CCS CONCEPTS
â€¢Mathematics of computing â†’Time series analysis; â€¢Com-
puting methodologies â†’Transfer learning ; Neural networks;
Supervised learning.
âˆ—Both authors contributed equally to this research.
This work is licensed under a Creative Commons Attribution-
NonCommercial-ShareAlike International 4.0 License.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528 .3671721KEYWORDS
Time Series; Domain Adaptation; Prompt Tuning; Information Bot-
tleneck
ACM Reference Format:
Junxiang Wang, Guangji Bai, Wei Cheng, Zhengzhang Chen, Liang Zhao,
and Haifeng Chen. 2024. POND: Multi-Source Time Series Domain Adap-
tation with Information-Aware Prompt Tuning. In Proceedings of the 30th
ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD
â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, Barcelona, Spain, 12 pages.
https://doi.org/10.1145/3637528 .3671721
1 INTRODUCTION
Due to the prevalence of time series sensor data, time series analysis
has found applications in various real-world scenarios, including
human activity recognition [ 1], sleep stage classification [ 48], and
machine fault diagnosis [ 18,38,39]. In these applications, time
series data are measured under different subjects, operating con-
ditions, or sensor configurations (i.e., domains). In other words,
time series analysis should be conducted across different domains.
Unfortunately, the labels of time series data are difficult to collect
due to the expensive costs of the labeling process [ 42]. To mitigate
labeling costs, researchers aim to leverage labeled data from some
domains (i.e., source domains) to infer labels for unlabeled data
in other domains (i.e., target domains) [ 40], which is defined as a
time series domain adaptation problem. For example, the goal of
the transponder fault diagnosis problem is to detect the working
statuses of transponders (i.e., normal or abnormal) based on fiber-
optic signals. In this problem, the model is trained under certain
working modes (e.g., single mode) using labeled time series data,
and then this trained model is applied to other working modes (e.g.,
multimode).
However, the time series domain adaptation problem is highly
challenging due to complex dynamic time series patterns, distri-
bution shift (i.e., different distributions of inputs among different
domains), and possible label shift (i.e., different distributions of
labels among different domains) [ 2,5,12]. These challenges have
been extensively investigated by researchers, leading to the pro-
posal of various methods to address the domain gap, such as kernel
matching [ 22], context information alignment [ 17], and temporal-
spectral fusion [ 45]. Most existing methods, however, primarily
focus on domain adaptation from a single source domain. Yet, it
is more crucial to investigate it from multiple sources. This is be-
cause the more source domains are utilized, the greater potential
improvements it can achieve. For instance, the collection of labeled
3140
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Junxiang Wang et al.
Figure 1: Pipeline of our proposed POND model: Step 1 pre-
trains the proposed POND model; Step 2 learns prompts of
all source domains and the target domain; Step 3 utilizes
learned prompts to select the most similar source domain to
the target domain for domain adaptation.
signal data from more modes facilitates a better understanding of
transponder statuses. Despite the importance of the multi-source
domain adaptation problem, it is rarely explored in previous lit-
erature and requires attention and extensive investigations from
researchers.
In order to effectively handle the multi-source time series do-
main adaptation problem, three important challenges need to be
overcome: 1. The lack of exploration to utilize domain-specific
information for domain adaptation. Existing domain adaptation
methods primarily focus on learning a common feature extractor
to encode time series inputs from different source domains into
domain-invariant representations, and then apply this feature ex-
tractor to the target domain [ 15,20,23,27,42]. While this strategy
has its rationale, it often overlooks domain-specific information (i.e.,
information unique to a specific time series domain), such as global
trends, local trends, and temporal patterns. Such domain-specific
information is valuable to evaluate which source domains are more
suitable for adaptation to the target domain. 2. The difficulty to
learn domain-specific information that changes over time.
While it is important to capture domain-specific information for
better domain adaptation, such information can be dynamically
changing, which is extremely difficult to capture. In the example of
the transponder fault diagnosis problem, different domains generate
different distributions of fiber-optic signals, which are important
domain-specific information to capture. However, such distribu-
tions can be shifted drastically when the transponder suddenly suf-
fers from a failure. 3. The difficulty to evaluate learned domain-
specific information. Not only is learning domain-specific in-
formation difficult, but it is also challenging to evaluate learned
domain-specific information. In other words, it is unclear whether
learned domain-specific information accurately reflects the true
one. This ambiguity arises because domain-specific information is
often associated with unique but inexplicable underlying patterns.
Unlike images and languages with human-recognizable features,
such time series patterns are difficult for humans to understand
[24]. Consequently, it becomes challenging, if not impossible, for
humans to evaluate whether learned domain-specific information
matches such time series patterns.
In order to tackle these three challenges simultaneously, we
propose PrOmpt-based domaiN Discrimination (POND), the first
framework to utilize prompts for time series domain adaptation to
our knowledge. Its pipeline is shown in Figure 1, which consists
of three steps: model pertaining, prompt tuning, and prompt adap-
tation. Specifically, to address Challenge 1, we extend the idea of
prompt tuning to time series analysis and learn prompts to capture
common and domain-specific information. To handle Challenge2, we introduce a conditional module for each source domain to
generate prompts from time series input data. For Challenge 3,
we propose two criteria to choose good prompts, which are used
to select the most suitable source domain for domain adaptation
(i.e., prompt adaptation). Our contributions can be summarized as
follows:
â€¢Propose a flexible prompt generator to learn domain-
specific information. We extend the idea of prompt tun-
ing to time series analysis to capture information specific
to source domains. However, traditional prompts have lim-
ited flexibility in learning domain-specific information that
evolves over time. To address this limitation, we introduce a
conditional module that generates prompts parameterized
by a neural network to capture domain-specific information.
Theoretical analysis also demonstrates the superiority of our
proposed prompt generator over traditional prompt tuning.
â€¢Develop two criteria for selecting good prompts. We
propose two criteria, fidelity and distinction, to ensure that
prompts accurately capture domain-specific information
from all source domains. Fidelity is achieved by maximiz-
ing the mutual information between prompts and labels,
while distinction is achieved by minimizing the mutual in-
formation between prompts from different source domains.
Theoretical guarantees establish that our generated prompts
maintain fidelity and introduce new information.
â€¢Present an efficient algorithm with a robust architec-
ture. We introduce a simple yet effective optimization algo-
rithm based on meta-learning to efficiently learn the objec-
tive. Additionally, we leverage the Mixture of Experts (MoE)
technique to enhance the robustness of our proposed POND
model.
â€¢Conduct comprehensive experiments on multiple bench-
mark datasets. Extensive experiments across 50 scenarios
on four benchmark datasets demonstrate the effectiveness
and robustness of our proposed POND model. Experimental
results indicate that our proposed POND model outperforms
all state-of-the-art comparison methods by up to 66%on the
F1-score.
2 RELATED WORK
Previous research related to this study can be categorized into two
main areas: time series domain adaptation and Large Language
Models (LLMs) for time series.
Time Series Domain Adaptation: Works in this domain can
be classified into Unsupervised Domain Adaptation (UDA) and su-
pervised methods.
UDA is a common approach, particularly beneficial as it does
not rely on labels in the target domain. For example, Liu and Xue
introduced the Adversarial Spectral Kernel Matching (AdvSKM) ap-
proach, employing a specialized hybrid spectral kernel network to
redefine the Maximum Mean Discrepancy (MMD) metric [ 22]. Lai
et al. aligned context information between different time series do-
mains using a Markov decision process formulation and employed
deep reinforcement learning for anomaly detection [ 17]. He et al.
addressed feature and label shifts between the source and target
domains using temporal and frequency features [ 12]. Other notable
3141POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
approaches include autoregressive models [30], sparse associative
structure alignment [ 4], variational methods [ 20,29], contrastive
learning [47], and temporal-spectral fusion [45].
In addition to UDA, other methods transfer time series knowl-
edge in a supervised manner. For instance, Jin et al. proposed an
attention-based shared module to learn common latent features,
incorporating a domain discriminator retaining domain-specific
features across multiple domains [ 15]. Wilson et al. leveraged target-
domain label distributions to enhance model performance with
benefits from multi-source time series data [ 42]. However, to our
knowledge, all existing time series domain adaptation methods ne-
glect domain-specific information such as unique temporal patterns,
which could potentially be utilized for better domain adaptation.
LLMs for Time Series: Large Language Models (LLMs) have
shown excellent performance in various Natural Language Pro-
cessing (NLP) tasks such as natural language inference, question
answering, and named entity recognition [ 50]. Recent research has
extended LLMs to address time series problems, generally falling
into two classes: prompt tuning and fine-tuning.
In prompt tuning methods, pretrained LLMs use prompts (i.e.,
a sequence of tokens prepended to the time series input) to learn
specific downstream tasks. For example, Xue and Salim proposed
PromptCast, a novel approach that transforms numerical input
and output into prompts and frames the time series forecasting
task in a sentence-to-sentence manner [ 44]. Cao et al. presented
the TEMPO framework, which decomposed complex interactions
between trend, seasonal, and residual components, introducing
selection-based prompts to facilitate distribution adaptation in non-
stationary time series [ 6]. Jin et al. proposed the TIME-LLM frame-
work, reprogramming the input time series with text prototypes
before feeding it into a frozen LLM to align the two modalities,
with Prompt-as-Prefix (PaP) introduced to enrich the input con-
text and guide the transformation of the reprogrammed input [ 13].
LLMTime highlighted the efficacy of LLMs as zero-shot learners
by encoding numbers into texts as prompts and sampling possible
extrapolations as prompt completions [ 11]. Sun et al. proposed the
TEST model, training an encoder to embed time series tokens with
contrastive learning and aligning text prototypes with time series,
utilizing prompts to adapt LLMs to different time series tasks [ 36].
In contrast, fine-tuning is the other type of method to adapt
LLMs to time series, adjusting some components while keeping
others frozen. For example, Zhou et al. presented the OFA frame-
work, where only the embedding and normalization layers of LLMs
were fine-tuned, while self-attention and feed-forward layers re-
mained frozen [ 51]. Chang et al. proposed the Llm4ts framework,
fine-tuning in two stages: first, supervised fine-tuning to orient
the LLM towards time series data, followed by task-specific down-
stream fine-tuning [ 7]. For more information, please refer to the
recent survey paper by Jin et al. [ 14]. While these methods transfer
knowledge from LLMs to the time series domain, they do not ad-
dress the time series domain adaptation problem, where knowledge
from the source time series domain, rather than text, is transferred
to the target domain.
3 PROBLEM SETUP
In this section, we mathematically formulate the multi-source time
series domain adaptation problem. Important notations are shownTable 1: Important notations and Descriptions.
Notations Descriptions
ğ‘†ğ‘– Theğ‘–-th source domain
ğ‘‡ Target domain
ğ¶ Class set
(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—) Theğ‘—-th time series pair for ğ‘†ğ‘–
(ğ‘‹(ğ‘‡)
ğ‘—,ğ‘Œ(ğ‘‡)
ğ‘—) Theğ‘—-th time series pair for ğ‘‡
ğ‘Œ(ğ‘†ğ‘–),ğ‘Œ(ğ‘‡)Label sets for ğ‘†ğ‘–andğ‘‡
ğ‘ƒ Common prompt
Î”ğ‘ƒ(ğ‘†ğ‘–)Domain-level prompt for ğ‘†ğ‘–
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—Instance-level prompt generated by ğ‘‹(ğ‘†ğ‘–)
ğ‘—forğ‘†ğ‘–
in Table 1. Given ğ‘€source time series domains ğ‘†ğ‘–(ğ‘–=1,Â·Â·Â·,ğ‘€)
and a target domain ğ‘‡, theirğ‘—-th time series inputs are denoted
asğ‘‹(ğ‘†ğ‘–)
ğ‘—âˆ¼ğ‘(ğ‘‹|ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)andğ‘‹(ğ‘‡)
ğ‘—âˆ¼ğ‘(ğ‘‹|ğ‘Œ(ğ‘‡)
ğ‘—), respectively, where
ğ‘Œ(ğ‘†ğ‘–)
ğ‘—andğ‘Œ(ğ‘‡)
ğ‘—are corresponding labels of ğ‘‹(ğ‘†ğ‘–)
ğ‘—andğ‘‹(ğ‘‡)
ğ‘—, re-
spectively. Here, ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘‹(ğ‘‡)
ğ‘—âˆˆRğ‘›Ã—ğ¿, whereğ‘›is the number of
channels and ğ¿is the sequence length. The labels ğ‘Œ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘‡)
ğ‘—âˆˆğ¶=
{ğ‘1,ğ‘2,Â·Â·Â·,ğ‘ğ¾}, whereğ‘ğ‘–(ğ‘–=1,Â·Â·Â·,|ğ¶|)represents a label class,
and the number of classes is |ğ¶|.ğ‘Œ(ğ‘†ğ‘–)={ğ‘Œ(ğ‘†ğ‘–)
ğ‘—}andğ‘Œ(ğ‘‡)={ğ‘Œ(ğ‘‡)
ğ‘—}
are the label sets for the source domain ğ‘†ğ‘–and the target domain
ğ‘‡, respectively. Sets ğ‘‹(ğ‘†ğ‘–)={ğ‘‹(ğ‘†ğ‘–)
ğ‘—}andğ‘‹(ğ‘‡)={ğ‘‹(ğ‘‡)
ğ‘—}represent
the input sets for the source domain ğ‘†ğ‘–and the target domain ğ‘‡,
respectively. We assume that the labeled time series of all source
domainsğ‘†ğ‘–(ğ‘–=1,Â·Â·Â·,ğ‘€)are abundant, but the labeled time series
are limited in the target domain ğ‘‡. Then the multi-source time
series domain adaptation problem is formulated as follows:
Problem Formulation: Given the time series input sets ğ‘‹(ğ‘†ğ‘–)
and label sets ğ‘Œ(ğ‘†ğ‘–)(ğ‘–=1,2,...,ğ‘€)ofğ‘€source domains, and the
time series input set ğ‘‹(ğ‘‡)of the target domain ğ‘‡, the goal of the
problem is to predict the label set ğ‘Œ(ğ‘‡)by learning the mapping ğ¹:
ğ¹:ğ‘‹(ğ‘‡)
ğ‘–â†’ğ‘Œ(ğ‘‡)
ğ‘–
Our problem formulation is very flexible: the time series input
can be either univariate (i.e., ğ‘=1) or multivariate (i.e., ğ‘>1);
the time series domain adaptation can be from a single source (i.e.,
ğ‘€=1) or multiple sources (i.e., ğ‘€>1); the classification problem
can be either binary (i.e., ğ¾=2) or multi-class (i.e., ğ¾>2).
4 PROMPT-BASED DOMAIN
DISCRIMINATION
In this section, we present our POND model to address the multi-
source time series domain adaptation problem.
4.1 The Flexible Prompt Generator
The goal of this section is to explore methods for learning infor-
mation that changes over time from different source domains for
domain adaptation (i.e., tackling Challenges 1 and 2). Most existing
papers propose various strategies to extract domain-invariant rep-
resentations from all source domains by making different domains
indistinguishable [ 15,20,27,42,49]. However, this idea may discard
domain-specific information from multiple source domains, which
3142KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Junxiang Wang et al.
indicates which source domain is most similar to the target do-
main. To address this, a natural solution is to directly learn domain-
specific information from the labeled time series pair (ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—).
This motivates us to utilize prompt tuning to learn domain-specific
information, which was first introduced by the NLP community
and demonstrated impressive success in many NLP tasks [ 3,19,21].
Compared with other domain adaptation techniques, prompt tun-
ing has three advantages: firstly, prompts are adjusted via gradi-
ents by labeled data from multiple source domains, which offer
domain-specific information; secondly, prompt tuning leverages
small amounts of labeled data effectively for adaptation, which is
suitable for the target domain with limited labeled data [ 19]; thirdly,
prompts can be utilized as a heuristic to select the most similar
source domain to the target domain for adaptation.
The prompt, which is extended from NLP to time series, is de-
fined as a learnable vector that prepends to the time series input to
learn domain-specific information by the labeled pair (ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—).
Mathematically, let ğ‘ƒ(ğ‘†ğ‘–)âˆˆRğ‘›Ã—ğ‘šbe the prompt of the source do-
mainğ‘†ğ‘–, whereğ‘šis the prompt length. Then, for the ğ‘—-th time series
inputğ‘‹(ğ‘†ğ‘–)
ğ‘—, any time series model takes [ğ‘ƒ(ğ‘†ğ‘–),ğ‘‹(ğ‘†ğ‘–)
ğ‘—](i.e., the con-
catenation of ğ‘ƒ(ğ‘†ğ‘–)andğ‘‹(ğ‘†ğ‘–)
ğ‘—) as its model input. We decompose
ğ‘ƒ(ğ‘†ğ‘–)into two components:
ğ‘ƒ(ğ‘†ğ‘–)=ğ‘ƒ+Î”ğ‘ƒ(ğ‘†ğ‘–)
whereğ‘ƒâˆˆRğ‘›Ã—ğ‘šis a common prompt to learn the common char-
acteristics of all source domains, which can also be directly applied
to the target domain ğ‘‡, andÎ”ğ‘ƒ(ğ‘†ğ‘–)âˆˆRğ‘›Ã—ğ‘šis a prompt to learn
domain-specific information (i.e., information unique to the source
domainğ‘†ğ‘–), which will be utilized to select the most similar source
domain to the target domain ğ‘‡.
While the domain-specific prompt Î”ğ‘ƒ(ğ‘†ğ‘–)is potentially effec-
tive to learn domain-specific information about the source domain
ğ‘†ğ‘–(i.e., address Challenge 1), it cannot directly address Challenge
2. This is because Î”ğ‘ƒ(ğ‘†ğ‘–)is time-independent and has little free-
dom to capture time-dependent domain-specific information (e.g.,
distribution shifts of fiber-optic signals). To tackle this, instead of
using a fixed prompt, we learn such domain-specific information by
prompts generated from the time series input. This is because the
time series input usually contains rich time-dependent information
(e.g., time series distributions and trends). Specifically, we introduce
a conditional module ğ‘”(ğ‘†ğ‘–), parameterized by a neural network, to
generate instance-level prompts based on time series instances:
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—=ğ‘”(ğ‘†ğ‘–)(ğ‘‹(ğ‘†ğ‘–)
ğ‘—;ğœ)âˆˆRğ‘šÃ—ğ‘›
where Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—is the instance-level prompt generated by the time
series input ğ‘‹(ğ‘†ğ‘–)
ğ‘—and a random variable ğœ, and the domain-level
prompt Î”ğ‘ƒ(ğ‘†ğ‘–)is the aggregation of all instance-level prompts
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—(e.g.,Î”ğ‘ƒ(ğ‘†ğ‘–)=1
|ğ‘†ğ‘–|Ã|ğ‘†ğ‘–|
ğ‘—=1Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—). For any time series input
ğ‘‹(ğ‘†ğ‘–)
ğ‘—, its corresponding prompt is formulated as ğ‘ƒ+Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—.
Our proposed prompt generator ğ‘”(ğ‘†ğ‘–)conditionally generates
instance-level prompts for specific time series inputs, which intu-
itively has more freedom of expression to learn domain-specific
information than the traditional prompt tuning. More theoretical
Figure 2: Illustration of two criteria: high fidelity and high
distinction. Fidelity and distinction are represented as areas
ofğ´+ğµandğ¶, respectively.
investigations are provided to illustrate the power of the common
promptğ‘ƒand the prompt generator ğ‘”(ğ‘†ğ‘–)in Section 4.4.
4.2 Two Important Criteria for Good Prompts
In the previous section, we extended prompt tuning to capture
information on specific time series domains. While prompts are
easy to recognize in computer vision and natural language fields,
the learned prompts of time series data are not recognizable to
humans, making it hard, if not impossible, to evaluate whether
prompts are good enough to learn information for time series data.
For example, a hard prompt consists of natural language that clearly
describes the task at hand, explicitly asks the model for some result
or action, and makes it easy to understand why the prompt elicited
such behavior from the model [ 19]. In contrast, the learned prompts
of specific time series domains are visualized as extra time segments,
which are difficult to understand by humans. Moreover, there is a
lack of exploration on what constitutes a good prompt that captures
domain-specific information without human-engineering priors.
From our perspective, ideal prompts to capture domain-specific
information should maintain high fidelity and high distinction, as
illustrated in Figure 2: high fidelity suggests large overlaps between
the learned domain-specific prompts and label information (i.e.,
largeğ´+ğµin Figure 2), and high distinction implies small overlaps
among domain-specific prompts of different source domains (i.e.,
smallğ¶in Figure 2). They are introduced in details as follows:
High Fidelity. One important criterion for the prompt generator
ğ‘”(ğ‘†ğ‘–)is fidelity (i.e., the generated prompt Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—preserves the
domain-specific information of the source domain ğ‘†ğ‘–). Motivated
by the theory of information bottleneck [ 37], high fidelity is defined
as the large mutual information between Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—andğ‘Œ(ğ‘†ğ‘–)
ğ‘—, which
should be maximized:
maxğ‘€âˆ‘ï¸
ğ‘–=1|ğ‘†ğ‘–|âˆ‘ï¸
ğ‘—=1ğ‘€ğ¼(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—), (1)
whereğ‘€ğ¼(â€¢,â€¢)denotes the operator of mutual information. Based
on the definition of mutual information, we have:
ğ‘€ğ¼(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)=ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)âˆ’ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—|Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—),
whereğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)represents the entropy of ğ‘Œ(ğ‘†ğ‘–)
ğ‘—andğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—|Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)
is the entropy of ğ‘Œ(ğ‘†ğ‘–)
ğ‘—conditioned on Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—. Sinceğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)is
constant, Equation (1) is equivalent to minimizing the conditional
3143POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
entropyğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—|Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—), which can be expressed as:
minğ‘€âˆ‘ï¸
ğ‘–=1|ğ‘†ğ‘–|âˆ‘ï¸
ğ‘—=1ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—|Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—).
Due to the computational complexity of the conditional entropy
ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—|Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—), it can be approximated by the cross-entropy be-
tweenğ‘“([Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘‹(ğ‘†ğ‘–)
ğ‘—])andğ‘Œ(ğ‘†ğ‘–)
ğ‘—[24,46], whereğ‘“([Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘‹(ğ‘†ğ‘–)
ğ‘—])
is the prediction obtained by concatenating Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—andğ‘‹(ğ‘†ğ‘–)
ğ‘—as an
input to our proposed POND model, which will be illustrated in
Section 4.4. The fidelity loss is then expressed as:
â„“ğ¹=ğ‘€âˆ‘ï¸
ğ‘–=1|ğ‘†ğ‘–|âˆ‘ï¸
ğ‘—=1ğ‘Œ(ğ‘†ğ‘–)
ğ‘—logğ‘“([Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘‹(ğ‘†ğ‘–)
ğ‘—]). (2)
Now, we theoretically show that the learned prompt Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—, which
minimizes the fidelity loss (i.e., Equation (2)), possesses the follow-
ing properties:
Property 1 (Preserving Fidelity). IfÎ”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—minimizes Equation
(2), the mutual information between Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—and the label ğ‘Œ(ğ‘†ğ‘–)
ğ‘—is
equivalent to that between the time series input ğ‘‹(ğ‘†ğ‘–)
ğ‘—and the label
ğ‘Œ(ğ‘†ğ‘–)
ğ‘—,i.e.,ğ‘€ğ¼(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)=ğ‘€ğ¼(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—).
Property 2 (Adding New Information). By minimizing Equation
(2), the generated prompt Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—contains new information com-
pared to the time series input ğ‘‹(ğ‘†ğ‘–)
ğ‘—,i.e.,ğ»(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)â‰¥ğ»(ğ‘‹(ğ‘†ğ‘–)
ğ‘—).
Detailed proofs are provided in Section A.1 in the Appendix.
These properties demonstrate that minimizing Equation (2)ensures
that the generated prompts will not decrease fidelity and may add
new information to the time series input.
High Distinction. In addition to high fidelity, it is essential
that the generated domain-specific prompt Î”ğ‘ƒ(ğ‘†ğ‘–)distinguishes
the unique information of the source domain ğ‘†ğ‘–from other source
domains. This unique information not only aids in understanding
the differences between multiple time series source domains but also
provides valuable insights for selecting suitable sources for domain
adaptation. To achieve this, from the perspective of information
theory, we define the objective to maintain high distinction as
minimizing the mutual information of domain-specific prompts
between different source domains, which should be minimized as
follows:
minâˆ‘ï¸
ğ‘–1â‰ ğ‘–2ğ‘€ğ¼(Î”ğ‘ƒ(ğ‘†ğ‘–1),Î”ğ‘ƒ(ğ‘†ğ‘–2)), (3)
where Î”ğ‘ƒ(ğ‘†ğ‘–1)andÎ”ğ‘ƒ(ğ‘†ğ‘–2)represent the domain-specific prompts
of any two source domains ğ‘†ğ‘–1andğ‘†ğ‘–2. Equation (3)is computa-
tionally infeasible to minimize directly, but it can be achieved by
minimizing the leave-one-out upper bound [ 24,28]. Other mutual
information upper bounds, such as the contrastive log-ratio bound
[8], can also conveniently be incorporated into our framework.
Therefore, the objective to encourage high distinction is formulatedas minimizing the leave-one-out bound (i.e., discrimination loss):
â„“ğ·=âˆ‘ï¸
ğ‘–1â‰ ğ‘–2Elogexp(sim(Î”ğ‘ƒ(ğ‘†ğ‘–1),Î”ğ‘ƒ(ğ‘†ğ‘–2)))
Ã
ğ‘–â‰ ğ‘–1,ğ‘–â‰ ğ‘–2exp(sim(Î”ğ‘ƒ(ğ‘†ğ‘–1),Î”ğ‘ƒ(ğ‘†ğ‘–))), (4)
where sim(Î”ğ‘ƒ(ğ‘†ğ‘–1),Î”ğ‘ƒ(ğ‘†ğ‘–2))=ğ‘¡ğ‘Ÿ((Î”ğ‘ƒ(ğ‘†ğ‘–1))ğ‘‡Î”ğ‘ƒ(ğ‘†ğ‘–2))denotes the
inner product of the two domain-specific prompts Î”ğ‘ƒ(ğ‘†ğ‘–1)and
Î”ğ‘ƒ(ğ‘†ğ‘–2), andğ‘¡ğ‘Ÿ(ğ´)represents the trace of any matrix ğ´.
4.3 The Learning Objective
After introducing two criteria for selecting good prompts, we present
our learning objective in this section.
Combining the fidelity loss â„“ğ¹in Equation (2)and the discrimi-
nation lossâ„“ğ·in Equation (4), our learning objective is expressed
as follows:
minğ‘ƒ,ğ‘”(ğ‘†ğ‘–)ğº(ğ‘ƒ,ğ‘”(ğ‘†ğ‘–))=â„“ğ‘…+ğœ†1â„“ğ·+ğœ†2â„“ğ¹, (5)
whereâ„“ğ‘…=1
ğ‘€Ãğ‘€
ğ‘–=11
|ğ‘†ğ‘–|Ã|ğ‘†ğ‘–|
ğ‘—=1ğ‘…(ğ‘“([ğ‘ƒ+Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘‹(ğ‘†ğ‘–)
ğ‘—]),ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)is
the training loss that measures the performance of prompt tuning.
Here,ğ‘…(Â·,Â·)is the loss function, and [ğ‘ƒ+Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘‹(ğ‘†ğ‘–)
ğ‘—]is the con-
catenation of the overall prompt ğ‘ƒ+Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—and the time series
inputğ‘‹(ğ‘†ğ‘–)
ğ‘—. Two tuning parameters ğœ†1,ğœ†2>0control the trade-off
among the training loss, the fidelity loss, and the discrimination
loss.
To optimize Equation (5), we need to enumerate all source do-
mains, which may be inefficient and unscalable [ 24]. To address
this, we propose a simple yet effective learning algorithm based on
the classic Reptile meta-learning framework [ 25], which randomly
picks a source domain each time and conducts standard steps of
gradient descent without the need for calculating second deriva-
tives. The learning process is outlined in Algorithm 1. Specifically,
Line 3 updates the prompt generator ğ‘”(ğ‘†ğœ), and Lines 4-5 update the
common prompt ğ‘ƒthrough extrapolation. Here, the local learning
rateğœ‚performs the gradient descent step, and the global learning
rateğ›¿performs the extrapolation step.
Algorithm 1 Reptile-based meta-learning for Prompt Tuning
Require:(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—), the global learning rate ğ›¿âˆˆ (0,1], the local
learning rate ğœ‚>0, the number of global steps ğ‘.
Ensure: the common prompt ğ‘ƒ, the prompt generator ğ‘”(ğ‘†ğ‘–).
1:forğ‘–=1toğ‘do
2: Randomly pick a source time series domain ğ‘†ğœ.
3:ğ‘”(ğ‘†ğœ)â†ğ‘”(ğ‘†ğœ)âˆ’ğœ‚âˆ‡ğ‘”(ğ‘†ğœ)ğº.
4:ğ‘„â†ğ‘ƒâˆ’ğœ‚âˆ‡ğ‘ƒâ„“ğ‘‡.
5:ğ‘ƒâ†ğ‘ƒ+ğ›¿(ğ‘„âˆ’ğ‘ƒ).
6:end for
After learning the common prompt ğ‘ƒand the prompt generator
ğ‘”(ğ‘†ğ‘–), they can be utilized for target domain transfer. Specifically,
the prompt generator ğ‘”(ğ‘‡)is optimized by the labeled time series
pairs(ğ‘‹(ğ‘‡)
ğ‘–,ğ‘Œ(ğ‘‡)
ğ‘–)in the target domain ğ‘‡as follows:
minğ‘”(ğ‘‡)1
|ğ‘‡||ğ‘‡|âˆ‘ï¸
ğ‘–=1ğ‘…(ğ‘“([ğ‘ƒ+Î”ğ‘ƒ(ğ‘‡)
ğ‘–,ğ‘‹(ğ‘‡)
ğ‘–]),ğ‘Œ(ğ‘‡)
ğ‘–), (6)
3144KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Junxiang Wang et al.
where Î”ğ‘ƒ(ğ‘‡)
ğ‘–=ğ‘”(ğ‘‡)(ğ‘‹(ğ‘‡)
ğ‘–)âˆˆRğ‘šÃ—ğ‘›is the instance-level domain-
specific prompt of the time series input ğ‘‹(ğ‘‡)
ğ‘–, and the domain-
level domain-specific prompt of the target domain ğ‘‡isÎ”ğ‘ƒ(ğ‘‡)=
1
|ğ‘‡|Ã|ğ‘‡|
ğ‘—=1Î”ğ‘ƒ(ğ‘‡)
ğ‘—. However,ğ‘”(ğ‘‡)may not be reliable for prediction
due to the limited labeled data involved. To handle this, Î”ğ‘ƒ(ğ‘‡)is
utilized as a heuristic to find the most similar source domain by the
simple nearest neighbor rule (i.e., prompt adaptation):
ğ‘†ğ‘–=arg maxğ‘†ğ‘–sim(Î”ğ‘ƒ(ğ‘†ğ‘–),Î”ğ‘ƒ(ğ‘‡)), (7)
where sim(Î”ğ‘ƒ(ğ‘†ğ‘–),Î”ğ‘ƒ(ğ‘‡))is a similarity function (e.g., cosine sim-
ilarity) between the domain-specific prompts Î”ğ‘ƒ(ğ‘†ğ‘–)andÎ”ğ‘ƒ(ğ‘‡).
Then, we utilize the prompt generator ğ‘”(ğ‘†ğ‘–)for prediction in the
target domain ğ‘‡:ğ‘“([ğ‘ƒ+ğ‘”(ğ‘†ğ‘–)(ğ‘‹(ğ‘‡)
ğ‘—),ğ‘‹(ğ‘‡)
ğ‘—]).
4.4 Discussion
In this section, we discuss the model architecture and implementa-
tion, the theoretical aspects of our proposed POND model, and its
comparison with previous papers.
4.4.1 Model Architecture and Implementation. For the model ar-
chitecture of our proposed POND model, we employ the popular
Mixture of Expert (MoE) technique to enhance performance [ 9]:
each expert makes an independent prediction, and the router is re-
sponsible for learning probability distributions over all predictions.
The overall output of our POND model is a linear combination of
all predictions.
For the architecture of a single expert, the time series input is
fed into â€œa patching layerâ€ (i.e., splitting a timeseries input into
subseries-level patches [ 26]), a projection layer, a position embed-
ding layer, a transformer layer, and a linear head sequentially.
The model implementation is illustrated in the following steps:
(1)Model Pretraining: All experts of our POND model are
pretrained by combining some labeled data from all source
domains (e.g. 60%), and the router, which aggregates outputs
from all experts to make final predictions, is pretrained using
the same labeled data.
(2)Prompt Tuning: Given the pretrained POND model, other
labeled time series data from all source domains (e.g. 40%)
are utilized to learn the common prompt ğ‘ƒand the prompt
generatorğ‘”(ğ‘†ğ‘–)by Equation (5)(i.e., Algorithm 1), and the
prompt generator of the target domain ğ‘”(ğ‘‡)is optimized by
Equation (6).
(3)Prompt Adaptation: The most similar source domain is
selected by Equation (7), whose prompt generator will be
used in the target domain for prediction.
4.4.2 Theoretical Analysis. We demonstrate the commonality and
differences of our proposed POND model compared with tradi-
tional prompt-tuning from the theoretical perspective. Specifically,
we prove that our proposed POND model shares the universal ap-
proximation with prompt tuning, and then we illustrate that our
proposed POND model overcomes the limitation of prompt tun-
ing. Without loss of generality, we assume that only one expert
model is available, and ğœis removed (i.e., Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—=ğ‘”(ğ‘†ğ‘–)(ğ‘‹(ğ‘†ğ‘–)
ğ‘—;ğœ)=
ğ‘”(ğ‘†ğ‘–)(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)). Proofs of all theorems below are shown in SectionA.2 in the Appendix due to space limitations.
One recent paper theoretically proves the universality of prompt
tuning [ 41], and it can be extended to our proposed POND model.
Specifically, for any L-Lipschitz function F:[0,1]ğ‘›Ã—ğ¿â†’[0,1]|ğ¶|
under norm ğ‘, it satisfies the following: âˆ€ğ‘¥1,ğ‘¥2âˆˆ[0,1]ğ‘›Ã—ğ¿,âˆ¥F(ğ‘¥1)âˆ’
F(ğ‘¥2)âˆ¥ğ‘â‰¤Lâˆ¥ğ‘¥1âˆ’ğ‘¥2âˆ¥ğ‘. The approximation error under ğ‘norm is
defined asğ‘‘ğ‘(F1,F2)=(âˆ«
âˆ¥F1(ğ‘¥)âˆ’F 2(ğ‘¥)âˆ¥ğ‘
ğ‘ğ‘‘ğ‘¥)1
ğ‘. Then Theorem
1 states that our proposed POND model can approximate any time
series classifier, which are trained from specific source domains.
Theorem 1 (Universality of our POND Model). Let1â‰¤ğ‘<âˆ
andğœ€>0, andF(ğ‘†ğ‘–):[0,1]ğ‘›Ã—ğ¿â†’[0,1]|ğ¶|is a time series classifer,
which is trained from source domain ğ‘†ğ‘–and isL-Lipschitz, there exist
a prompt length ğ‘šand a POND model ğ‘“such that for anyF(ğ‘†ğ‘–),
we can find a domain-specific prompt generator ğ‘”(ğ‘†ğ‘–):[0,1]ğ‘›Ã—ğ¿â†’
Rğ‘›Ã—ğ‘šfrom source domain ğ‘†ğ‘–withğ‘‘ğ‘(ğ‘“([ğ‘ƒ+ğ‘”(ğ‘†ğ‘–)(Â·),Â·]),F(ğ‘†ğ‘–))<ğœ€
for allğ‘†ğ‘–(ğ‘–=1,2,Â·Â·Â·ğ‘€).
Not only our proposed POND model shares the universality, it
also overcomes the limitations of prompt tuning. The following
theorem states that while prompt tuning may not be flexible enough
to learn some labeled time series pairs, our proposed POND model
can overcome this limitation.
Theorem 2 (Flexibility of of our POND Model). Consider two
labeled time series pairs (ğ‘‹(ğ‘†1)
1=[X1,X0],ğ‘Œ(ğ‘†1)
1)and(ğ‘‹(ğ‘†2)
1=
[X2,X0],ğ‘Œ(ğ‘†2)
1)from two source domains ğ‘†1andğ‘†2, respectively,
whereğ‘Œ(ğ‘†1)
1â‰ ğ‘Œ(ğ‘†1)
2. For some proposed POND model ğ‘“:
(a).[The limitation of prompt tuning ]There exists no prompt ğ‘ƒsuch
thatğ‘“([ğ‘ƒ,ğ‘‹(ğ‘†ğ‘–)
1])=ğ‘Œ(ğ‘†ğ‘–)
1(ğ‘–=1,2).
(b).[Our POND model handles this limitation ]There exist the common
promptğ‘ƒand the prompt generators ğ‘”(ğ‘†ğ‘–)(ğ‘–=1,2)such that
ğ‘“([ğ‘ƒ+ğ‘”(ğ‘†ğ‘–)(ğ‘‹(ğ‘†ğ‘–)
1),ğ‘‹(ğ‘†ğ‘–)
1])=ğ‘Œ(ğ‘†ğ‘–)
1(ğ‘–=1,2).
4.4.3 Comparison and Relation with Previous Methods. Finally, we
compare our proposed POND model with existing multi-source do-
main adaptation approaches, which have the following drawbacks:
(1). Neglection of domain-specific information. The common goal
of existing methods is to make different domains indistinguishable
[49]. However, domain-specific information may be eliminated,
which is important to select which source is the most similar to the
target for adaptation. Our proposed POND model can address this
by prompt tuning: the value of a prompt is updated by the gradient
based on labeled data, which provides domain-specific information.
(2). Inability to capture time-dependent information. Most exist-
ing methods are designed to address domain adaptation problems in
the fields of computer vision and NLP whose information is static,
and they are not able to capture time-dependent information such
as trends and distribution shifts of the time series. Our proposed
POND model can address this by our proposed novel conditional
module: it is learned to generate a prompt for each time series input,
which is flexible to learn time-dependent information.
we show that several classic methods are special cases of our
proposed POND model.
1. Generalization of Prompt Tuning. Letğœ†1=ğœ†2=0, and
ğ‘”(ğ‘†ğ‘–)=0, then our proposed POND model is reduced to the classic
prompt tuning [19].
3145POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 2: Statistics of four datasets.
Dataset # Domain # Channel # Class Seq Len # Train # Test
HAR 30 9 6 128 2300 990
WISDM 36 3 6 128 1350 720
HHAR 9 3 6 128 12716 5218
SSC 20 1 5 3000 14280 6130
2. Generalization of Information Bottleneck. Letğœ†1=0and
ğ‘ƒ=0, then our proposed POND is reduced to the famous informa-
tion bottleneck [37].
3. Generalization of IDPG. Letğœ†1=ğœ†2=0, andğ‘ƒ=0. Then our
proposed POND model is reduced to Instance-Dependent Prompt
Generation (IDPG) [43].
5 EXPERIMENTS
In this section, we employ four benchmark datasets to evaluate
our proposed POND model in comparison with six state-of-the-
art methods. All experiments were conducted on a Linux server
equipped with an Intel(R) Xeon(R) Silver 4214 CPU and an NVIDIA
GPU running version 510. More experiments are included in the
supplementary materials1due to space limitations.
5.1 Experimental Settings
Benchmark Dataset: We evaluated the performance of all methods
on four benchmark datasets, HAR, WISDM, HHAR and SSC [ 31].
The statistics of all benchmark datasets are shown in Table 2, which
are introduced as follows:
1. HAR [ 1]: The Human Activity Recognition (HAR) dataset
incorporates data collected from three sensorsâ€”accelerometer, gy-
roscope, and body sensorsâ€”deployed on 30 subjects (i.e., domains)
engaged in six distinct activities.
2. WISDM [ 16]: The WIreless Sensor Data Mining (WISDM)
dataset, using accelerometer sensors, involves 36 subjects partic-
ipating in activities similar to the HAR dataset, with additional
challenges due to class distribution imbalances among different
subjects.
3. HHAR [ 34]: The Heterogeneity Human Activity Recognition
(HHAR) dataset was collected from 9 subjects using sensor readings
from smartphones and smartwatches.
4. SSC [ 10]: The Sleep Stage Classification (SSC) problem aims
to categorize electroencephalography (EEG) signals into five stages.
We utilize the Sleep-EDF dataset [ 10], including EEG recordings
from 20 healthy subjects.
Comparison Methods: We compared our proposed POND
method with six state-of-the-art time series domain adaptation
approaches: Raincoat [ 12], CoDATs [ 42], Deep Coral [ 35], MMDA
[32], DIRT-T [ 33] and DSAN [ 52]. All comparison methods are
introduced as follows:
1. Raincoat [ 12]: it is an unsupervised domain adaptation method
addressing both feature and label shifts.
2. CoDATs [ 42]: it is the first method to handle multi-source
domain adaptation through adversarial training with weak super-
vision.
3. Deep Coral [ 35]: it minimizes domain shift by aligning second-
order statistics of source and target distributions.
1Link of supplementary materials: https://github .com/xianggebenben/
Junxiang _Wang.github.io/blob/master/supplementary _material/KDD2024/supp .pdf.4. MMDA [ 32]: it integrates Maximum Mean Discrepancy (MMD)
and CORrelation ALignment (CORAL) along with conditional en-
tropy minimization to address domain shift.
5. DIRT-T [ 33]: it utilizes adversarial training, conditional en-
tropy, and a teacher model to align source and target domains.
6. DSAN [ 52]: it minimizes the discrepancy between source and
target domains via a Local Maximum Mean Discrepancy (LMMD)
that aligns relevant subdomain distributions.
Metrics: Two performance metrics were employed: Macro-F1
score and Accuracy. Macro-F1 is the unweighted mean of per-class
F1 scores, treating all classes equally. Accuracy is the ratio of accu-
rately predicted samples to all samples.
Hyperparameter Settings: We adapted the setting of super-
vised domain adaptation, where ten samples in the target domain
were used for domain transfer. All source-target scenarios were
selected randomly to ensure the fairness of the performance eval-
uation. Single-source domain adaptation methods (e.g. Raincoat)
were trained by combining all source domains. For the training
set of all time series source domains, 60%was used for pretraining
our POND model, 20%for prompt tuning, and 20%for validation
sets. The batch size was set to 16. The number of global steps ğ‘,
global learning rate ğ›¿and the local learning rate ğœ‚were set to 50,
0.01 and 0.001, respectively. The number of experts was set to three.
The prompt generator is a two-layer Multi-Layer Perceptron (MLP)
with Tanh activation. For the transformer model, the numbers of
encoder layers, decoder layers, and heads in the multi-head atten-
tion were set to 2, 1, and 4, respectively. The dimensions of the
multi-head attention and the feed-forward layer were set to 16
and 128, respectively. The hyperparameters ğœ†1andğœ†2were chosen
based on performance on the validation set. ğœ†1andğœ†2, along with
other hyperparameters such as the number of epochs, are provided
in Table 3. All methods were averaged by ten times.
Table 3: Hyperparameters of all datasets.
Dataset #Epochs Prompt Length ğœ†1ğœ†2
HAR 50 5 1 1
WISDM 200 3 1 1
HHAR 200 5 1 1
SSC 100 10 0.1 0.1
5.2 Experimental Results
Performance Evaluation: We conducted a comprehensive per-
formance evaluation to test all methods across approximately 50
scenarios on four datasets. Figure 3 displays the F1-score and accu-
racy of all methods on these datasets. Our proposed POND method
consistently outperforms others across all four datasets. Specifi-
cally, on the HAR dataset, the F1-score of POND is approximately
0.9, only 2%lower than the top-performing comparison method,
Raincoat. The F1-score gaps on the HHAR, and SSC datasets are 5%
and4.4%, respectively. The largest gap is observed in the WISDM
dataset, where the F1-score and accuracy of POND hover around
0.6and0.7, while all comparison methods score below 0.35 and 0.6,
respectively. Considering the inherent difficulty of training on the
WISDM dataset due to class imbalance, this highlights the effective-
ness of our proposed POND, especially on challenging datasets.
Among the comparison methods, Raincoat emerges as the best
overall. In terms of F1-score, Raincoat outperforms MMDA by 5%
3146KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Junxiang Wang et al.
(a). HAR.
 (b). WISDM.
(c). HHAR.
 (d). SSC.
Figure 3: The F1-score and accuracy of all methods on four
benchmark datasets: the proposed POND outperforms com-
parison methods consistently.
on the HAR dataset and shows an 8%superiority over CoDATs
on the HHAR dataset. For accuracy, Raincoat performs 7%bet-
ter than DIRT on the HHAR dataset and surpasses Deep Coral
by3%on the SSC dataset. CoDATs and Deep Coral also demon-
strate competitive performance, achieving around 55%accuracy on
the WISDM dataset, while DSAN lags behind at 45%. On the other
hand, MMDA, DIRT, and DSAN exhibit varying performance across
datasets. For instance, DSAN performs comparably to Raincoat on
the SSC dataset but ranks the lowest on the WISDM dataset.
Table 4 presents the performance of all methods across various
scenarios in four datasets, including the upper bound achieved by
training and testing on the target domain. The reported values
include means and standard deviations from ten implementations,
with the best results highlighted in bold. The complete performance
evaluation is available in the supplementary materials1. Overall,
our proposed POND model consistently outperforms all methods,
aligning with the observations in Figure 3. Notably, POND exhibits
superior performance on the challenging WISDM dataset, as indi-
cated by Figure 3. For instance, POND outperforms all comparison
methods by at least 23%when transferring from domains 0-17 to
domain 18. While POND excels overall, there are instances where
comparison methods outperform it. For example, Deep Coral per-
forms better than POND by 2%when transferring domains 1-15 to
domain 28 on the HAR dataset, and MMDA marginally outperforms
POND when transferring domains 1-15 to domain 21 on the HAR
dataset.
In addition to superior performance, our proposed POND model
demonstrates greater stability compared to all comparison meth-
ods, as indicated by lower standard deviations. For instance, the
standard deviation of POND is 0.006when transferring domains
0-9 to domain 17 on the SSC dataset, while the standard deviations
of all comparison methods range between 0.024and0.118, being at
least 3 times larger than that of POND. Importantly, POND achieves
results close to the upper bound in many scenarios, such as "HAR
1-15â†’16", "SSC 0-9â†’18", and "HHAR 0-6 â†’7".
Ablation Study: Next, we demonstrate the ablation study of
the proposed POND method, whose goal is to identify whether all
components of our proposed POND model contribute to the perfor-
mance. Specifically, we explore the necessity of the MoE technique,
common prompt, and prompt generator. The challenging WISDM
(a). F1-score.
 (b). Accuracy.
Figure 4: The F1-score and accuracy of the proposed POND
model with different source domains: the performance grows
with the increase of source domains. (The HHAR dataset has
less than 10 domains.)
dataset was utilized to test the performance. Table 5 illustrates the
performance of different scenarios, all of which were averaged by
10times. The first two rows show the performance with the com-
mon prompt, and the prompt generator available only, respectively.
The fourth to sixth rows demonstrate the performance without the
MoE, common prompt, and prompt generator, respectively, and
the last row shows the performance of the complete POND model.
Overall, our proposed POND model performs best when the MoE,
common prompt, and prompt generator are all available, which
suggests that all components are necessary for the outstanding
performance of our proposed POND model. For example, in the sce-
nario of â€œ18-23â†’6â€, the best performance without any component
only achieves a performance no more than 0.58, whereas that of
the complete POND model is 5%better. The gap is widened to 7%
for the scenario â€œ0-17â†’ 25â€.
Sensitivity Analysis: In this section, we explore how source
domains influence performance on the target domain. Figure 4 illus-
trates the relationship between performance metrics (F1-score and
accuracy) and the number of source domains, averaged over 10 im-
plementations. Generally, our proposed POND model demonstrates
improved performance with an increasing number of source do-
mains. For instance, POND achieves 50%accuracy with two source
domains for training, but this figure rises by 30%when an additional
8 source domains are included. Similarly, the F1-score of POND
increases by 20% when the number of source domains changes
from 2to6. However, some exceptions exist. For example, there
is a notable 25%drop in F1-score when increasing the number of
source domains from 6 to 7 on the WISDM dataset. Another in-
stance involves a 5%performance drop when increasing the source
domains from 4to5on the SSC dataset.
Visualization of Discrimination Loss: Finally, we present
a visualization of the discrimination loss â„“ğ·for pairwise source
domains. Figure 5 illustrates the exponents of discrimination losses
for all pairs of source domains across four datasets. Both the X-axis
and Y-axis represent the indexes of source domains. Darker colors
indicate smaller discrimination losses, reflecting better domain dis-
crimination. The diagonals are left blank. Overall, our proposed
POND model effectively discriminates most source domains, as
evidenced by the predominance of dark squares. For instance, do-
mains 3-5 and domains 6-7 exhibit clear discrimination with losses
below 0.05. Similar effective discrimination is observed for domain
pairs 6 and 0 on the WISDM dataset, domain pairs 1 and 5 on the
HHAR dataset, and domains 5-7 and 0 in the SSC dataset. However,
3147POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 4: F1-score on different scenarios of four datasets: the proposed POND model outperforms all comparison methods.
Scenario Raincoat CoDATs Deep_Coral MMDA DIRT DSAN POND Target Only
HAR 1-15â†’16 0.823Â±0.094 0.767Â±0.093 0.773Â±0.082 0.679Â±0.084 0.612Â±0.135 0.738Â±0.095 0.849Â±0.021 0.856Â±0.027
HAR 1-15â†’20 0.872Â±0.142 0.932Â±0.025 0.923Â±0.023 0.921Â±0.034 0.848Â±0.101 0.929Â±0.033 0.968Â±0.021 0.983Â±0.018
HAR 1-15â†’21 0.867Â±0.141 0.903Â±0.070 0.882Â±0.028 0.974Â±0.039 0.921Â±0.090 0.909Â±0.110 0.972Â±0.021 1.000Â±0.000
HAR 1-15â†’28 0.766Â±0.107 0.775Â±0.166 0.852Â±0.044 0.778Â±0.085 0.671Â±0.175 0.783Â±0.046 0.829Â±0.018 0.853Â±0.019
HAR 16-20â†’1 0.792Â±0.072 0.744Â±0.053 0.667Â±0.077 0.654Â±0.074 0.546Â±0.060 0.698Â±0.037 0.883Â±0.017 0.986Â±0.010
HAR 16-20â†’2 0.825Â±0.048 0.821Â±0.151 0.796Â±0.055 0.651Â±0.045 0.509Â±0.050 0.652Â±0.057 0.936Â±0.017 0.943Â±0.024
HAR 16-20â†’3 0.814Â±0.028 0.746Â±0.078 0.741Â±0.058 0.657Â±0.033 0.605Â±0.056 0.565Â±0.043 0.878Â±0.018 0.978Â±0.013
HAR 16-20â†’4 0.679Â±0.084 0.605Â±0.082 0.479Â±0.110 0.513Â±0.058 0.336Â±0.110 0.436Â±0.032 0.754Â±0.033 0.921Â±0.018
WISDM 0-17â†’18 0.379Â±0.061 0.384Â±0.049 0.346Â±0.023 0.297Â±0.016 0.300Â±0.041 0.287Â±0.045 0.606Â±0.020 0.705Â±0.046
WISDM 0-17â†’20 0.354Â±0.040 0.368Â±0.039 0.376Â±0.031 0.452Â±0.098 0.347Â±0.071 0.269Â±0.064 0.570Â±0.023 0.704Â±0.051
WISDM 0-17â†’21 0.355Â±0.057 0.310Â±0.088 0.259Â±0.018 0.250Â±0.000 0.276Â±0.055 0.245Â±0.046 0.450Â±0.026 0.636Â±0.095
WISDM 0-17â†’23 0.306Â±0.015 0.327Â±0.075 0.318Â±0.031 0.327Â±0.023 0.271Â±0.016 0.277Â±0.044 0.482Â±0.017 0.538Â±0.034
WISDM 0-17â†’25 0.365Â±0.030 0.540Â±0.125 0.435Â±0.043 0.436Â±0.094 0.314Â±0.107 0.353Â±0.120 0.559Â±0.050 0.672Â±0.039
WISDM 0-17â†’28 0.399Â±0.028 0.431Â±0.033 0.418Â±0.032 0.454Â±0.064 0.304Â±0.044 0.339Â±0.030 0.656Â±0.046 0.689Â±0.048
WISDM 0-17â†’30 0.314Â±0.020 0.305Â±0.028 0.298Â±0.023 0.359Â±0.072 0.266Â±0.035 0.246Â±0.076 0.670Â±0.039 0.791Â±0.028
WISDM 18-23â†’5 0.648Â±0.001 0.558Â±0.129 0.534Â±0.102 0.510Â±0.020 0.549Â±0.097 0.484Â±0.055 0.652Â±0.035 0.734Â±0.095
WISDM 18-23â†’6 0.544Â±0.074 0.565Â±0.143 0.437Â±0.078 0.543Â±0.160 0.405Â±0.089 0.454Â±0.112 0.628Â±0.033 0.872Â±0.049
WISDM 18-23â†’7 0.588Â±0.070 0.404Â±0.117 0.530Â±0.094 0.477Â±0.060 0.518Â±0.120 0.476Â±0.127 0.672Â±0.029 0.888Â±0.035
HHAR 0-6â†’7 0.765Â±0.142 0.652Â±0.108 0.815Â±0.105 0.641Â±0.050 0.649Â±0.005 0.730Â±0.164 0.834Â±0.014 0.861Â±0.016
HHAR 5-8â†’2 0.321Â±0.023 0.347Â±0.082 0.309Â±0.032 0.216Â±0.032 0.276Â±0.021 0.314Â±0.095 0.352Â±0.014 0.881Â±0.018
SSC 0-9â†’16 0.578Â±0.028 0.510Â±0.044 0.537Â±0.024 0.559Â±0.027 0.523Â±0.019 0.515Â±0.044 0.568Â±0.012 0.601Â±0.018
SSC 0-9â†’17 0.511Â±0.024 0.413Â±0.118 0.452Â±0.077 0.504Â±0.060 0.530Â±0.053 0.463Â±0.081 0.559Â±0.006 0.602Â±0.014
SSC 0-9â†’18 0.605Â±0.016 0.548Â±0.037 0.544Â±0.046 0.597Â±0.032 0.574Â±0.021 0.569Â±0.046 0.604Â±0.014 0.602Â±0.013
SSC 0-9â†’19 0.562Â±0.024 0.540Â±0.052 0.531Â±0.055 0.570Â±0.044 0.565Â±0.028 0.568Â±0.080 0.570Â±0.010 0.613Â±0.019
SSC 10-12â†’8 0.294Â±0.028 0.380Â±0.066 0.379Â±0.076 0.398Â±0.060 0.322Â±0.048 0.411Â±0.046 0.470Â±0.010 0.531Â±0.019
Table 5: Ablation study on the WISDM dataset: all components of our proposed POND model contribute to the outstanding
performance.
MoECommon
PromptPrompt
Generator0-17â†’ 22 0-17â†’ 23 0-17â†’ 24 0-17â†’ 25 18-23â†’ 5 18-23â†’ 6 Overall
âœ“ 0.622Â±0.057 0.415Â±0.015 0.510Â±0.030 0.581Â±0.036 0.623Â±0.058 0.516Â±0.038 0.545Â±0.039
âœ“ 0.646Â±0.064 0.396Â±0.048 0.527Â±0.030 0.573Â±0.034 0.628Â±0.051 0.512Â±0.057 0.547Â±0.047
âœ“âœ“ 0.632Â±0.069 0.384Â±0.041 0.498Â±0.032 0.572Â±0.045 0.611Â±0.055 0.514Â±0.025 0.535Â±0.045
âœ“ âœ“ 0.575Â±0.043 0.349Â±0.029 0.517Â±0.032 0.584Â±0.030 0.621Â±0.056 0.578Â±0.035 0.537Â±0.038
âœ“âœ“ 0.719Â±0.062 0.405Â±0.052 0.529Â±0.042 0.588Â±0.034 0.616Â±0.050 0.565Â±0.049 0.570Â±0.048
âœ“âœ“âœ“ 0.725Â±0.031 0.482Â±0.017 0.559Â±0.050 0.695Â±0.035 0.652Â±0.035 0.628Â±0.033 0.624Â±0.034
(a). HAR.
 (b). WISDM.
(c). HHAR.
 (d). SSC.
Figure 5: The visualization of the exponent of discrimination
loss: most pairs of source domains are well discriminated.discrimination losses for some domain pairs are larger than others.
For instance, on the HAR dataset, the discrimination loss between
domains 0 and 6 is the largest, approximately 0.30, but still within
an acceptable range. Itâ€™s worth noting that domain discrimination
may not adhere to the transitive property. For example, domains
3 and 9, as well as domains 4 and 9, are well-discriminated, but
domains 3 and 4 are relatively poor-discriminated.
6 CONCLUSION
Time series domain adaptation is an important problem with wide-
ranging applications. Existing techniques primarily address single-
source domain adaptation, yet exploring adaptation from multiple
domains holds promise for greater improvements. In this paper, we
introduce POND, the first framework to utilize prompts for time
series domain adaptation. We extend prompt tuning to time series
analysis to capture common and domain-specific information from
all source domains, introduce conditional modules for prompt gener-
ation, and propose criteria for selecting effective prompts. Through
extensive experiments across 50 scenarios on four datasets, we
demonstrate the efficacy and robustness of POND, outperforming
all state-of-the-art methods by up to 66%on the F1-score.
3148KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Junxiang Wang et al.
REFERENCES
[1]Anguita, D., Ghio, A., Oneto, L., Parra, X., Reyes-Ortiz, J. L., et al. A public
domain dataset for human activity recognition using smartphones. In Esann
(2013), vol. 3, p. 3.
[2]Bai, G., Ling, C., and Zhao, L. Temporal domain generalization with drift-aware
dynamic neural networks. In The Eleventh International Conference on Learning
Representations (2022).
[3]Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P.,
Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models
are few-shot learners. Advances in neural information processing systems 33 (2020),
1877â€“1901.
[4]Cai, R., Chen, J., Li, Z., Chen, W., Zhang, K., Ye, J., Li, Z., Yang, X., and Zhang,
Z.Time series domain adaptation via sparse associative structure alignment.
InProceedings of the AAAI Conference on Artificial Intelligence (2021), vol. 35,
pp. 6859â€“6867.
[5]Cai, Z., Bai, G., Jiang, R., Song, X., and Zhao, L. Continuous temporal domain
generalization. arXiv preprint arXiv:2405.16075 (2024).
[6]Cao, D., Jia, F., Arik, S. O., Pfister, T., Zheng, Y., Ye, W., and Liu, Y. Tempo:
Prompt-based generative pre-trained transformer for time series forecasting.
arXiv preprint arXiv:2310.04948 (2023).
[7]Chang, C., Peng, W.-C., and Chen, T.-F. Llm4ts: Two-stage fine-tuning for
time-series forecasting with pre-trained llms. arXiv preprint arXiv:2308.08469
(2023).
[8]Cheng, P., Hao, W., Dai, S., Liu, J., Gan, Z., and Carin, L. Club: A contrastive
log-ratio upper bound of mutual information. In International conference on
machine learning (2020), PMLR, pp. 1779â€“1788.
[9]Fedus, W., Zoph, B., and Shazeer, N. Switch transformers: Scaling to trillion
parameter models with simple and efficient sparsity. The Journal of Machine
Learning Research 23, 1 (2022), 5232â€“5270.
[10] Goldberger, A. L., Amaral, L. A., Glass, L., Hausdorff, J. M., Ivanov, P. C.,
Mark, R. G., Mietus, J. E., Moody, G. B., Peng, C.-K., and Stanley, H. E. Phys-
iobank, physiotoolkit, and physionet: components of a new research resource
for complex physiologic signals. circulation 101, 23 (2000), e215â€“e220.
[11] Gruver, N., Finzi, M., Qiu, S., and Wilson, A. G. Large language models are
zero-shot time series forecasters. arXiv preprint arXiv:2310.07820 (2023).
[12] He, H., Queen, O., Koker, T., Cuevas, C., Tsiligkaridis, T., and Zitnik, M.
Domain adaptation for time series under feature and label shifts. In Proceedings of
the 40th International Conference on Machine Learning (23â€“29 Jul 2023), A. Krause,
E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, Eds., vol. 202 of
Proceedings of Machine Learning Research, PMLR, pp. 12746â€“12774.
[13] Jin, M., Wang, S., Ma, L., Chu, Z., Zhang, J. Y., Shi, X., Chen, P.-Y., Liang, Y., Li,
Y.-F., Pan, S., et al. Time-llm: Time series forecasting by reprogramming large
language models. arXiv preprint arXiv:2310.01728 (2023).
[14] Jin, M., Wen, Q., Liang, Y., Zhang, C., Xue, S., Wang, X., Zhang, J., Wang, Y.,
Chen, H., Li, X., Pan, S., Tseng, V. S., Zheng, Y., Chen, L., and Xiong, H. Large
models for time series and spatio-temporal data: A survey and outlook. arXiv
preprint arXiv:2310.10196 (2023).
[15] Jin, X., Park, Y., Maddix, D., Wang, H., and Wang, Y. Domain adaptation
for time series forecasting via attention sharing. In International Conference on
Machine Learning (2022), PMLR, pp. 10280â€“10297.
[16] Kwapisz, J. R., Weiss, G. M., and Moore, S. A. Activity recognition using cell
phone accelerometers. ACM SigKDD Explorations Newsletter 12, 2 (2011), 74â€“82.
[17] Lai, K.-H., Wang, L., Chen, H., Zhou, K., Wang, F., Yang, H., and Hu, X. Context-
aware domain adaptation for time series anomaly detection. In Proceedings of
the 2023 SIAM International Conference on Data Mining (SDM) (2023), SIAM,
pp. 676â€“684.
[18] Lessmeier, C., Kimotho, J. K., Zimmer, D., and Sextro, W. Condition monitoring
of bearing damage in electromechanical drive systems by using motor current
signals of electric motors: A benchmark data set for data-driven classification. In
PHM Society European Conference (2016), vol. 3.
[19] Lester, B., Al-Rfou, R., and Constant, N. The power of scale for parameter-
efficient prompt tuning. arXiv preprint arXiv:2104.08691 (2021).
[20] Li, Y., Chen, Z., Zha, D., Du, M., Ni, J., Zhang, D., Chen, H., and Hu, X. Towards
learning disentangled representations for time series. In Proceedings of the
28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (2022),
pp. 3270â€“3278.
[21] Ling, C., Zhao, X., Lu, J., Deng, C., Zheng, C., Wang, J., Chowdhury, T., Li,
Y., Cui, H., Zhao, T., et al. Domain specialization as the key to make large
language models disruptive: A comprehensive survey. arXiv preprint arXiv 2305
(2023).
[22] Liu, Q., and Xue, H. Adversarial spectral kernel matching for unsupervised time
series domain adaptation. In IJCAI (2021), pp. 2744â€“2750.
[23] Luo, C., Chen, Z., Tang, L.-A., Shrivastava, A., Li, Z., Chen, H., and Ye, J. Tinet:
learning invariant networks via knowledge transfer. In Proceedings of the 24th
ACM SIGKDD International Conference on Knowledge Discovery & Data Mining
(2018), pp. 1890â€“1899.
[24] Luo, D., Cheng, W., Wang, Y., Xu, D., Ni, J., Yu, W., Zhang, X., Liu, Y., Chen,
Y., Chen, H., et al. Time series contrastive learning with information-awareaugmentations. In Proceedings of the AAAI Conference on Artificial Intelligence
(2023), vol. 37, pp. 4534â€“4542.
[25] Nichol, A., Achiam, J., and Schulman, J. On first-order meta-learning algo-
rithms. arXiv preprint arXiv:1803.02999 (2018).
[26] Nie, Y., Nguyen, N. H., Sinthong, P., and Kalagnanam, J. A time series is worth
64 words: Long-term forecasting with transformers. In The Eleventh International
Conference on Learning Representations (2022).
[27] Peng, X., Huang, Z., Sun, X., and Saenko, K. Domain agnostic learning with
disentangled representations. In International Conference on Machine Learning
(2019), PMLR, pp. 5102â€“5112.
[28] Poole, B., Ozair, S., Van Den Oord, A., Alemi, A., and Tucker, G. On variational
bounds of mutual information. In International Conference on Machine Learning
(2019), PMLR, pp. 5171â€“5180.
[29] Purushotham, S., Carvalho, W., Nilanon, T., and Liu, Y. Variational recurrent
adversarial deep domain adaptation. In International Conference on Learning
Representations (2016).
[30] Ragab, M., Eldele, E., Chen, Z., Wu, M., Kwoh, C.-K., and Li, X. Self-supervised
autoregressive domain adaptation for time series data. IEEE Transactions on
Neural Networks and Learning Systems (2022).
[31] Ragab, M., Eldele, E., Tan, W. L., Foo, C.-S., Chen, Z., Wu, M., Kwoh, C.-K.,
and Li, X. Adatime: A benchmarking suite for domain adaptation on time series
data. ACM Transactions on Knowledge Discovery from Data 17, 8 (2023), 1â€“18.
[32] Rahman, M. M., Fookes, C., Baktashmotlagh, M., and Sridharan, S. On min-
imum discrepancy estimation for deep domain adaptation. Domain Adaptation
for Visual Understanding (2020), 81â€“94.
[33] Shu, R., Bui, H., Narui, H., and Ermon, S. A dirt-t approach to unsupervised
domain adaptation. In International Conference on Learning Representations (2018).
[34] Stisen, A., Blunck, H., Bhattacharya, S., Prentow, T. S., KjÃ¦rgaard, M. B.,
Dey, A., Sonne, T., and Jensen, M. M. Smart devices are different: Assessing and
mitigatingmobile sensing heterogeneities for activity recognition. In Proceedings
of the 13th ACM conference on embedded networked sensor systems (2015), pp. 127â€“
140.
[35] Sun, B., and Saenko, K. Deep coral: Correlation alignment for deep domain adap-
tation. In Computer Visionâ€“ECCV 2016 Workshops: Amsterdam, The Netherlands,
October 8-10 and 15-16, 2016, Proceedings, Part III 14 (2016), Springer, pp. 443â€“450.
[36] Sun, C., Li, Y., Li, H., and Hong, S. Test: Text prototype aligned embedding to
activate llmâ€™s ability for time series. arXiv preprint arXiv:2308.08241 (2023).
[37] Tishby, N., Pereira, F. C., and Bialek, W. The information bottleneck method.
arXiv preprint physics/0004057 (2000).
[38] Wang, D., Chen, Z., Fu, Y., Liu, Y., and Chen, H. Incremental causal graph
learning for online root cause analysis. In Proceedings of the 29th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (2023), pp. 2269â€“2278.
[39] Wang, D., Chen, Z., Ni, J., Tong, L., Wang, Z., Fu, Y., and Chen, H. Inter-
dependent causal networks for root cause localization. In Proceedings of the
29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (2023),
pp. 5051â€“5060.
[40] Wang, J., and Zhao, L. Multi-instance domain adaptation for vaccine adverse
event detection. In Proceedings of the 2018 World Wide Web Conference (2018),
pp. 97â€“106.
[41] Wang, Y., Chauhan, J., Wang, W., and Hsieh, C.-J. Universality and limitations
of prompt tuning. In Proceedings of Advances in Neural Information Processing
Systems 36 (NeurIPS 2023) (2023).
[42] Wilson, G., Doppa, J. R., and Cook, D. J. Multi-source deep domain adaptation
with weak supervision for time-series sensor data. In Proceedings of the 26th ACM
SIGKDD international conference on knowledge discovery & data mining (2020),
pp. 1768â€“1778.
[43] Wu, Z., Wang, S., Gu, J., Hou, R., Dong, Y., Vydiswaran, V. V., and Ma, H. Idpg:
An instance-dependent prompt generation method. In Proceedings of the 2022
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies (2022), pp. 5507â€“5521.
[44] Xue, H., and Salim, F. D. Promptcast: A new prompt-based learning paradigm
for time series forecasting. IEEE Transactions on Knowledge and Data Engineering
(2023).
[45] Yang, L., and Hong, S. Unsupervised time-series representation learning with
iterative bilinear temporal-spectral fusion. In International Conference on Machine
Learning (2022), PMLR, pp. 25038â€“25054.
[46] Ying, Z., Bourgeois, D., You, J., Zitnik, M., and Leskovec, J. Gnnexplainer: Gen-
erating explanations for graph neural networks. Advances in neural information
processing systems 32 (2019).
[47] Yue, Z., Wang, Y., Duan, J., Yang, T., Huang, C., Tong, Y., and Xu, B. Ts2vec:
Towards universal representation of time series. In Proceedings of the AAAI
Conference on Artificial Intelligence (2022), vol. 36, pp. 8980â€“8987.
[48] Zhao, M., Yue, S., Katabi, D., Jaakkola, T. S., and Bianchi, M. T. Learning sleep
stages from radio signals: A conditional adversarial architecture. In International
Conference on Machine Learning (2017), PMLR, pp. 4100â€“4109.
[49] Zhao, S., Li, B., Xu, P., and Keutzer, K. Multi-source domain adaptation in the
deep learning era: A systematic survey. arXiv preprint arXiv:2002.12169 (2020).
[50] Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B.,
3149POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Zhang, J., Dong, Z., et al. A survey of large language models. arXiv preprint
arXiv:2303.18223 (2023).
[51] Zhou, T., Niu, P., Wang, X., Sun, L., and Jin, R. One fits all: Power general time
series analysis by pretrained lm. arXiv preprint arXiv:2302.11939 (2023).
[52] Zhu, Y., Zhuang, F., Wang, J., Ke, G., Chen, J., Bian, J., Xiong, H., and He, Q.
Deep subdomain adaptation network for image classification. IEEE transactions
on neural networks and learning systems 32, 4 (2020), 1713â€“1722.
Appendix
A MATHEMATICAL PROOFS
A.1 Proofs of Properties 1 and 2
Property 1 (Preserving Fidelity). IfÎ”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—minimizes Equation
(2), the mutual information between Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—and the label ğ‘Œ(ğ‘†ğ‘–)
ğ‘—is
equivalent to that between the time series input ğ‘‹(ğ‘†ğ‘–)
ğ‘—and the label
ğ‘Œ(ğ‘†ğ‘–)
ğ‘—,i.e.,ğ‘€ğ¼(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)=ğ‘€ğ¼(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—).
Proof. From the definition of mutual information, we have:
ğ‘€ğ¼(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
=ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)âˆ’ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—|Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)
=ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)+âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)logğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)
=ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)+âˆ‘ï¸
ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
logğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—).
where V(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)is the set of generated prompts of a time series
inputğ‘‹(ğ‘†ğ‘–)
ğ‘—. Because Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—is a function of ğ‘‹(ğ‘†ğ‘–)
ğ‘—only, this means
thatğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—|ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)=ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—|ğ‘‹(ğ‘†ğ‘–)
ğ‘—). Since the mapping
betweenğ‘‹(ğ‘†ğ‘–)
ğ‘—andÎ”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—is one to many, for each Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—),
we haveğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)=ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—), andğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)=
ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—|ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—). Therefore, we have
ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)=ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—|ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)
=ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—|ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—|ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)
=ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—|ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—|ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)
=ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—).ğ‘€ğ¼(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
=ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)+âˆ‘ï¸
ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
logğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)
=ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)+âˆ‘ï¸
ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—[âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)]
logğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)
=ğ»(ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)+âˆ‘ï¸
ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)logğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—)
ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)
=ğ‘€ğ¼(ğ‘‹(ğ‘†ğ‘–)
ğ‘—,ğ‘Œ(ğ‘†ğ‘–)
ğ‘—).
â–¡
Property 2 (Adding New Information). By minimizing Equation
(2), the generated prompt Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—contains new information com-
paring to the time series input ğ‘‹(ğ‘†ğ‘–)
ğ‘—,i.e.,ğ»(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)â‰¥ğ»(ğ‘‹(ğ‘†ğ‘–)
ğ‘—).
Proof. Without loss of generality, we assume that a finite num-
ber of prompts are generated for each time series input, and each
prompt is generated independently. Then we have ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)=
Ã
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—). It follows that
ğ»(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)
=âˆ’âˆ‘ï¸
ğ‘‹(ğ‘†ğ‘–)
ğ‘—ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)log(ğ‘(ğ‘‹(ğ‘†ğ‘–)
ğ‘—))
=âˆ’âˆ‘ï¸
ğ‘‹(ğ‘†ğ‘–)
ğ‘—[âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)]log([âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)])
=âˆ’âˆ‘ï¸
ğ‘‹(ğ‘†ğ‘–)
ğ‘—âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)log([âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)])
â‰¤âˆ’âˆ‘ï¸
ğ‘‹(ğ‘†ğ‘–)
ğ‘—âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)log(ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—))(Jensenâ€™s Inequality)
=âˆ’âˆ‘ï¸
Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—âˆˆV(ğ‘‹(ğ‘†ğ‘–)
ğ‘—)ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)log(ğ‘(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—))=ğ»(Î”ğ‘ƒ(ğ‘†ğ‘–)
ğ‘—)
â–¡
A.2 Proofs of Theorems 1 and 2
To prove Theorems 1 and 2, we follow the similar procedure of
[41]. To make proofs self-contained, we first mathematically for-
mulate our simplified POND model ğ‘“. Without loss of generality,
we assume that ğ‘“has only one expert transformer network, and it
consists of an attention layer and an MLP layer. The attention layer
and the transformer layer are defined as follows [41]:
3150KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Junxiang Wang et al.
Definition 1 (Attention Layer). Theh-head attention layer be-
tween a time-stamp xand a time series Xis defined as follows:
ğ´ğ‘¡ğ‘¡(x,X)=hâˆ‘ï¸
ğ‘–=1Wğ‘–
ğ‘œWğ‘–
ğ‘£Xğœ((Wğ‘–
ğ‘˜X)ğ‘‡Wğ‘–
ğ‘x)
where Wğ‘–ğ‘,Wğ‘–
ğ‘˜,Wğ‘–ğ‘£andWğ‘–ğ‘œ(ğ‘–=1,Â·Â·Â·,h)are parameterized
weights, and ğœis a softmax operator. The normalizing factor of
1âˆš
dğ‘˜ğ‘is subsumed in the weight matrices Wğ‘–
ğ‘˜for notational sim-
plicity.
We then define the cross-attention between two time series
XâˆˆRğ‘›Ã—ğ¿andXâ€²âˆˆRğ‘›Ã—ğ¿:
ğ´ğ‘¡ğ‘¡(X,Xâ€²)=[ğ´ğ‘¡ğ‘¡(X:,1,Xâ€²),ğ´ğ‘¡ğ‘¡(X:,2,Xâ€²),Â·Â·Â·,ğ´ğ‘¡ğ‘¡(X:,ğ¿,Xâ€²)]
where W:,ğ‘—is theğ‘—-th column of W.
Definition 2 (Simplified POND Model). The simplified POND
modelğ‘“is shown as follows:
ğ‘€ğ¿ğ‘ƒ(X)=[W2ğ‘…ğ¸ğ¿ğ‘ˆ(W1X:,1)+b1+b2+X:,1,Â·Â·Â·,
W2ğ‘…ğ¸ğ¿ğ‘ˆ(W1X:,ğ‘›)+b1+b2+X:,ğ‘›]
ğ‘“(X)=ğ‘€ğ¿ğ‘ƒ(ğ´ğ‘¡ğ‘¡(X,X)+ X).
whereğ‘…ğ¸ğ¿ğ‘ˆ(Â·)is the ReLU activation function.
Theorem 1 (Universality of our POND Model). Let1â‰¤ğ‘<âˆ
andğœ€>0, andF(ğ‘†ğ‘–):[0,1]ğ‘›Ã—ğ¿â†’[0,1]|ğ¶|is a time series classifer,
which is trained from source domain ğ‘†ğ‘–and isL-Lipschitz, there exist
a prompt length ğ‘šand a POND model ğ‘“such that for anyF(ğ‘†ğ‘–),
we can find a domain-specific prompt generator ğ‘”(ğ‘†ğ‘–):[0,1]ğ‘›Ã—ğ¿â†’
Rğ‘›Ã—ğ‘šfrom source domain ğ‘†ğ‘–withğ‘‘ğ‘(ğ‘“([ğ‘ƒ+ğ‘”(ğ‘†ğ‘–)(Â·),Â·]),F(ğ‘†ğ‘–))<ğœ€
for allğ‘†ğ‘–(ğ‘–=1,2,Â·Â·Â·ğ‘€).
Proof. Let the common prompt ğ‘ƒ=0, the prompt generator
ğ‘”(ğ‘†ğ‘–)be constant ğ‘ƒ(ğ‘†ğ‘–), andğ‘“be a transformer with two heads of
size one and four hidden units, then this theorem can be directly
derived from Theorem 1 in [41]. â–¡
To prove Theorem 2, we need two assumptions on our simplified
POND model ğ‘“, which are shown as follows:
Assumption 1 (Assumption on the Attention Layer). ğ´ğ‘¡ğ‘¡(ğ‘‹(ğ‘†1)
1,ğ‘‹(ğ‘†1)
1)+
ğ‘‹(ğ‘†1)
1â‰ ğ´ğ‘¡ğ‘¡(ğ‘‹(ğ‘†2)
1,ğ‘‹(ğ‘†2)
1)+ğ‘‹(ğ‘†2)
1in Theorem 2, and Wğ‘œ,Wğ‘˜,Wğ‘,
andWğ‘£are full rank.
Assumption 2 (Assumption on the MLP Layer). ğ‘Œ(ğ‘†ğ‘–)
1(ğ‘–=1,2)in
Theorem 2 are in the range set of ğ‘€ğ¿ğ‘ƒ . Moreover, the number of
channelsğ‘›â‰¥2+ğ‘‘ğ‘–ğ‘š((ğ‘€ğ¿ğ‘ƒâˆ’1(ğ‘Œ(ğ‘†1)
1)âˆ’X 1)âˆª(ğ‘€ğ¿ğ‘ƒâˆ’1(ğ‘Œ(ğ‘†2)
1)âˆ’X 2))
in Theorem 2. Here ğ‘‘ğ‘–ğ‘š(S)measures the dimension of the subspace
spanned by vectors in a set Sandğ‘€ğ¿ğ‘ƒâˆ’1(y)={x:ğ‘€ğ¿ğ‘ƒ(x)=y}.
Aside from two assumptions, the following Lemma is also useful
to prove Theorem 2.
Lemma 1. (Lemma 7 in [ 41]) Given câˆˆRğ‘›Ã—ğ¿and full-rank attention
weights Wğ‘,Wğ‘˜, and Wğ‘£, there are x0almost everywhere for which
there exists x1âˆˆRğ‘›Ã—ğ¿such thatğ´ğ‘¡ğ‘¡(x0,[x0,x1])||c.
Theorem 2 (Flexibility of of our POND Model). Consider two
labeled time series pairs (ğ‘‹(ğ‘†1)
1=[X1,X0],ğ‘Œ(ğ‘†1)
1)and(ğ‘‹(ğ‘†2)
1=
[X2,X0],ğ‘Œ(ğ‘†2)
1)from two source domains ğ‘†1andğ‘†2, respectively,whereğ‘Œ(ğ‘†1)
1â‰ ğ‘Œ(ğ‘†1)
2. For some proposed POND model ğ‘“:
(a).[The limitation of prompt tuning ]There exists no prompt ğ‘ƒsuch
thatğ‘“([ğ‘ƒ,ğ‘‹(ğ‘†ğ‘–)
1])=ğ‘Œ(ğ‘†ğ‘–)
1(ğ‘–=1,2).
(b).[Our POND Model handles this limitation ]There exist the common
promptğ‘ƒand the prompt generators ğ‘”(ğ‘†ğ‘–)(ğ‘–=1,2)such that
ğ‘“([ğ‘ƒ+ğ‘”(ğ‘†ğ‘–)(ğ‘‹(ğ‘†ğ‘–)
1),ğ‘‹(ğ‘†ğ‘–)
1])=ğ‘Œ(ğ‘†ğ‘–)
1(ğ‘–=1,2).
Proof. (a). Firstly, we consider the prompt ğ‘ƒonly (i.e., with-
out the prompt generator ğ‘”(ğ‘†ğ‘–)), we passğ‘‹(ğ‘†1)
1andğ‘‹(ğ‘†2)
1to the
attention layer to obtain:
ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ,ğ‘‹(ğ‘†1)
1])=ğœ†(ğ‘‹(ğ‘†1)
1,X0,[ğ‘ƒ,ğ‘‹(ğ‘†1)
1])ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†1)
1)
+ğœ†(ğ‘ƒ,X0,[ğ‘ƒ,ğ‘‹(ğ‘†1)
1])ğ´ğ‘¡ğ‘¡(X0,ğ‘ƒ) (8)
ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ,ğ‘‹(ğ‘†2)
1])=ğœ†(ğ‘‹(ğ‘†2)
1,X0,[ğ‘ƒ,ğ‘‹(ğ‘†2)
1])ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†2)
1)
+ğœ†(ğ‘ƒ,X0,[ğ‘ƒ,ğ‘‹(ğ‘†2)
1])ğ´ğ‘¡ğ‘¡(X0,ğ‘ƒ) (9)
whereğœ†(X,Xâ€²,Xâ€²â€²=[X1,X2])âˆˆ( 0,1)is a positive scalar defined
as:
ğœ†(X1,Xâ€²,Xâ€²â€²)=Ã
ğ‘—exp((Wğ‘˜X:,ğ‘—)ğ‘‡(Wğ‘Xâ€²))
Ã
ğ‘—exp((Wğ‘˜Xâ€²â€²
:,ğ‘—)ğ‘‡(Wğ‘Xâ€²))
Based on Equations (8)and(9), we learn that ğ´ğ‘¡ğ‘¡(X0,ğ‘ƒ)is the in-
tersection of ğ¶ğ‘œğ‘›ğ‘’(ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ,ğ‘‹(ğ‘†1)
1]),ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†1)
1))and
ğ¶ğ‘œğ‘›ğ‘’(ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ,ğ‘‹(ğ‘†2)
1],ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†2)
1)), whereğ¶ğ‘œğ‘›ğ‘’(a1,Â·,ağ‘˜)=
{ğ‘¥|ğ‘¥=Ãğ‘˜
ğ‘–=1ğ‘ğ‘–ağ‘–,ğ‘ğ‘–>0(ğ‘–=1,Â·Â·Â·,ğ‘˜)}is a convex cone formed by
ağ‘–(ğ‘–=1,Â·Â·Â·,ğ‘˜). However, due to the same deduction by the proof of
Theorem 2 in [ 41],ğ¶ğ‘œğ‘›ğ‘’(ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ,ğ‘‹(ğ‘†1)
1]),ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†1)
1))and
ğ¶ğ‘œğ‘›ğ‘’(ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ,ğ‘‹(ğ‘†2)
1],ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†2)
1))have no intersection based
on Assumption 2, which contradicts the existence of ğ´ğ‘¡ğ‘¡(X0,ğ‘ƒ).
Therefore, there exists no common prompt ğ‘ƒsuch thatğ‘“([ğ‘ƒ,ğ‘‹(ğ‘†ğ‘–)
1])=
ğ‘Œ(ğ‘†ğ‘–)
1(ğ‘–=1,2).
(b). Secondly, we illustrate the case when both the common prompt
ğ‘ƒand prompt generators ğ‘”(ğ‘†ğ‘–)are available. In this case, Equations
(8) and (9) become the following:
ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ+ğ‘”(ğ‘†1)(ğ‘‹(ğ‘†1)
1),ğ‘‹(ğ‘†1)
1])
=ğœ†(ğ‘‹(ğ‘†1)
1,X0,[ğ‘ƒ+ğ‘”(ğ‘†1)(ğ‘‹(ğ‘†1)
1),ğ‘‹(ğ‘†1)
1])ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†1)
1)
+ğœ†(ğ‘ƒ+ğ‘”(ğ‘†1)(ğ‘‹(ğ‘†1)
1),X0,[ğ‘ƒ+ğ‘”(ğ‘†1)(ğ‘‹(ğ‘†1)
1),ğ‘‹(ğ‘†1)
1])
ğ´ğ‘¡ğ‘¡(X0,ğ‘ƒ+ğ‘”(ğ‘†1)(ğ‘‹(ğ‘†1)
1)) (10)
ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ+ğ‘”(ğ‘†2)(ğ‘‹(ğ‘†2)
1),ğ‘‹(ğ‘†2)
1])
=ğœ†(ğ‘‹(ğ‘†2)
1,X0,[ğ‘ƒ+ğ‘”(ğ‘†2)(ğ‘‹(ğ‘†2)
1),ğ‘‹(ğ‘†2)
1])ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†2)
1)
+ğœ†(ğ‘ƒ+ğ‘”(ğ‘†2)(ğ‘‹(ğ‘†2)
1),X0,[ğ‘ƒ+ğ‘”(ğ‘†2)(ğ‘‹(ğ‘†2)
1),ğ‘‹(ğ‘†2)
1])
ğ´ğ‘¡ğ‘¡(X0,ğ‘ƒ+ğ‘”(ğ‘†2)(ğ‘‹(ğ‘†2)
1)) (11)
Obviously, the role of ğ‘”(ğ‘†ğ‘–)is to findğ´ğ‘¡ğ‘¡(X0,ğ‘ƒ+ğ‘”(ğ‘†1)(ğ‘‹(ğ‘†1)
1))âˆˆ
ğ¶ğ‘œğ‘›ğ‘’(ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ+ğ‘”(ğ‘†1)(ğ‘‹(ğ‘†1)
1),ğ‘‹(ğ‘†1)
1]),ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†1)
1))andğ´ğ‘¡ğ‘¡(X0,ğ‘ƒ+
ğ‘”(ğ‘†2)(ğ‘‹(ğ‘†2)
1))âˆˆğ¶ğ‘œğ‘›ğ‘’(ğ´ğ‘¡ğ‘¡(X0,[ğ‘ƒ+ğ‘”(ğ‘†2)(ğ‘‹(ğ‘†2)
1),ğ‘‹(ğ‘†2)
1]),ğ´ğ‘¡ğ‘¡(X0,ğ‘‹(ğ‘†2)
1))
so that these two cones have no intersections, and therefore the
contradiction mentioned in (a) can be addressed. â–¡
3151