Spending Programmed Bidding: Privacy-friendly Bid
Optimization with ROI Constraint in Online Advertising
Yumin Suâˆ—
ByteDance Inc.
Beijing, China
suyumin@bytedance.comMin Xiangâˆ—
ByteDance Inc.
Beijing, China
xiangmin@bytedance.comYifei Chen
ByteDance Inc.
Beijing, China
chenyifei.ward@bytedance.com
Yanbiao Li
ByteDance Inc.
Beijing, China
liyanbiao@bytedance.comTian Qin
ByteDance Inc.
San Jose, United States
tian.qin@bytedance.comHongyi Zhang
ByteDance Inc.
San Jose, United States
hongyi.zhang@bytedance.com
Yasong Liâ€ 
ByteDance Inc.
Beijing, China
liyasong@bytedance.comXiaobing Liu
ByteDance Inc.
Singapore
will.liu@bytedance.com
Abstract
Privacy policies have disrupted the multi-billion dollar online ad-
vertising market by making real-time and precise user data un-
traceable, which poses significant challenges to the optimization
of Return-On-Investment (ROI) constrained products in the on-
line advertising industry. Privacy protection strategies, including
event aggregation and reporting delays, hinder access to detailed
and instantaneous feedback data, thus incapacitating traditional
identity-revealing attribution techniques. In this paper, we intro-
duces a novel Spending Programmed Bidding (SPB) framework
to navigate these challenges. SPB is a two-stage framework that
separates long horizon delivery spend planning (the macro stage)
and short horizon bidding execution (the micro stage). The macro
stage models the target ROI to achieve maximum utility and de-
rives the expected spend, whereas the micro stage optimizes the
bid price given the expected spend. We further extend our frame-
work to the cross-channel scenario where the agent bids in both
privacy-constrained and identity-revealing attribution channels.
We find that when privacy-constrained channels are present, SPB is
superior to state-of-the-art bidding methods in both offline datasets
and online experiments on a large ad platform.
CCS Concepts
â€¢Information systems â†’Computational advertising.
âˆ—Both authors contributed equally to this research.
â€ Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671540Keywords
Real-Time Bidding; Bid Optimization; Privacy; ROI Constraint; Dis-
play Advertising
ACM Reference Format:
Yumin Su, Min Xiang, Yifei Chen, Yanbiao Li, Tian Qin, Hongyi Zhang,
Yasong Li, and Xiaobing Liu. 2024. Spending Programmed Bidding: Privacy-
friendly Bid Optimization with ROI Constraint in Online Advertising. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 10 pages. https://doi.org/10.1145/3637528.3671540
1 Instruction
Advertisers search for potential consumers to promote their prod-
ucts with a clear Return-On-Investment (ROI) demand and a limited
spend. In the $350 billion online advertising market, Real-Time Bid-
ding (RTB) allows advertisers to bid on a display ad impression in
real time. To support advertisers in achieving their marketing ob-
jectives, a multitude of identity-revealing bidding algorithms have
been developed. Typically, these algorithms generate bids based on
real-time feedback gathered from user behavior event sequences,
such as impressions, clicks, and conversions.
However, the reliance of real-time and precise user data in e-
commerce has become increasingly controversial, triggering wide-
spread concerns about privacy [ 17]. In response to the rising con-
troversy, regulatory agencies (e.g. GDPR1) and key companies (e.g.
Apple2) have formulated a series of policies to protect user privacy
by making user data untraceable. Unfortunately, display advertising
becomes far less effective under privacy regulation and non-data-
driven performance optimization is particularly hard [ 13]. It is no
wonder that according to a research report from Interactive Ad-
vertising Bureau (IAB)[ 9], if tracking were to end, there would be
a shift of nearly $39 billion of advertising revenue away from the
open web by 2025.
1the European General Data Protection Regulation
2https://www.apple.com/legal/privacy/en-ww/
5731
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yumin Su et al.
Striving to move toward a more privacy-sensitive equilibrium in
the advertising market, some companies have proposed correspond-
ing policies. Notably, Apple presented Private Click Measurement
(PCM)3and SKAdNetwork (SKAN)4to help advertisers measure
the success of ad campaigns while maintaining user privacy. How-
ever, these coping strategies still impact the online advertising in
two major aspects: Firstly, event aggregation makes it impossible to
attribute conversion event to a single user click, but only to a cohort
of users based on certain aggregation rules (PCM is based on prior-
ity, while SKAN is based on timing). Therefore, bidding algorithms
can no longer leverage fine-grained & real-time ROI data. Secondly,
reporting delay involves intentionally delaying conversion reports
by 24 to 48 hours. This delay can cause bidding strategies to respond
sluggishly. Moreover, random factors are typically introduced dur-
ing this delay period to mitigate privacy compromises from timing
attacks.
In this paper, a series of innovative methods are proposed to
tackle the ROI constrained spend planning and bidding problem
under privacy protection. Contributions can be summarized as,
(1) A Spending Programmed Bidding framework (SPB) is pro-
posed which innovatively decompose the bidding procedure into
macro and micro stages;(subsection 4.2)
(2) The functional relationship between Gross Merchandise Vol-
ume (GMV) and ROI is theoretically proved, and a stable, light-
weight, effective non-parametric regression model is proposed to
generate bids;(subsection 4.3 and subsection 4.4)
(3) The proposed SPB framework is theoretically extended to
mixed scenarios involving both privacy and non-privacy concerns.
(subsection 4.5)
2 Related Work
Existing research usually focuses on improving traditional identity-
revealing methods which only address a fraction of the problem
and are greatly affected by privacy constraints.
For the reporting delay challenge, most solutions are proposed in
the field of Conversion Rate (CVR) prediction model. [ 30] proposed
a non-parametric delayed feedback model to estimate the time
delay. [ 12] directly quantizes conversions into multiple windows
as a multi-head model. However, considering the tremendous and
stochastic delay of conversions caused by privacy policies, it is
difficult to ensure the estimated stability.
The application of the widely used Proportion Integration Dif-
ferentiation (PID) [ 7,29] in privacy scenarios is also extremely lim-
ited [ 2,5] due to its heavily rely on real-time conversion feedback.
Another type of classic method in the online advertising industry is
Model Predictive Control (MPC) which models the relation between
bid, spend and conversion with fine-grained auction replay data to
predict the optimal bid. Thus suffering from the conversion delay
and inaccuracy problems arising from strict privacy regulation.
Reinforced Learning-based (RL) solutions attempt to optimize
delivery performance by using bidding or spending control through
a learned policy or agent. However, considering the lack of real-
time and fine-grained interactive feedback with the environment,
applying these methods in privacy scenarios is almost ineffective.
3https://webkit.org/blog/8943/privacy-preserving-ad-click-attribution-for-the-web/
4https://developer.apple.com/documentation/storekit/skadnetworkTable 1: Notation Description
Notation Description
ğ‘¥ğ‘– A binary variable with a value of {0,1}, indicating
whether the ad campaign wins an ğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘–
ğ‘ğ‘– Bid price for the ad campaign in ğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘–
ğ‘¤ğ‘ğ‘– Winning price for the ad campaign in ğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘–
ğ‘ğ‘– Conversion events obtained by the ad campaign after
winningğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘–
ğ‘†ğ‘ğ‘ğ‘ Maximum spend within a spending period of the ad
campaign set by advertiser
ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ Target ROI of the ad campaign set by advertiser
3 Preliminary
3.1 Online Stochastic Knapsack Problem
Taking the ROI demand of advertisers and the platform ecology
comprehensively into account, the problem we define to solve is
to maximize GMV with the ROI and spend constraints. Here we
introduce relevant notations in table 1 and then derive the math-
ematical representation of this problem by analogy to the online
stochastic knapsack problem.
For a given advertiserâ€™s ad campaign ğ‘, suppose there are ğ‘auc-
tion opportunities in a preset spending period (e.g. a day). We denote
these opportunities according to their generated order as ğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘–.
Based on the previously stated definitions, we recognize the cumula-
tiveğºğ‘€ğ‘‰ andğ‘†ğ‘ƒğ¸ğ‘ğ· for theğ‘auctions over the spending period
asğ‘ƒğºandğ‘ƒğ‘†, respectively. This corresponds to ğ‘ƒğº=Ãğ‘
ğ‘–=1ğ‘¥ğ‘–Â·ğ‘ğ‘–Â·ğ‘£ğ‘,
whereğ‘£ğ‘represents the value derived from a conversion event for
the advertiser. Consequently, the expected ROI result (hereafter
abbreviated as ğ‘…ğ‘Ÿğ‘’ğ‘ ) can be obtained as follows:
ğ‘…ğ‘Ÿğ‘’ğ‘ =ğ‘ƒğº
ğ‘ƒğ‘†=Ãğ‘
ğ‘–=1ğ‘¥ğ‘–Â·ğ‘ğ‘–Â·ğ‘£ğ‘
Ãğ‘
ğ‘–=1ğ‘¥ğ‘–Â·ğ‘¤ğ‘ğ‘–(1)
For the ad campaign ğ‘, our goal is to maximize ğ‘ƒğºunderğ‘†ğ‘ğ‘ğ‘
andğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ constraints which is formulated as:
ğ‘šğ‘ğ‘¥ğ‘¥ğ‘–ğ‘âˆ‘ï¸
ğ‘–=1ğ‘¥ğ‘–Â·ğ‘ğ‘–Â·ğ‘£ğ‘ (2)
s.t.
ğ‘âˆ‘ï¸
ğ‘–=1ğ‘¥ğ‘–Â·ğ‘¤ğ‘ğ‘–â‰¤ğ‘†ğ‘ğ‘ğ‘ (3)
Ãğ‘
ğ‘–=1ğ‘¥ğ‘–Â·ğ‘ğ‘–Â·ğ‘£ğ‘
Ãğ‘
ğ‘–=1ğ‘¥ğ‘–Â·ğ‘¤ğ‘ğ‘–â‰¥ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ (4)
Referring to [ 34], we define the optimal bidding formula from
the perspective of a single ğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘–as
ğ‘ğ‘–=ğ‘ğ‘–Â·ğ‘£ğ‘
ğ‘Ÿğ‘–(5)
Whereğ‘Ÿğ‘–can be regarded as the ROI of ğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘–. It is worth not-
ing that we can relate our problem to a variant of the well known
Knapsack Problem (KP), i.e., the online stochastic variant. We can
regard each auction opportunity as an item ğ‘–with valueğ‘ƒğ‘”ğ‘–(ğ‘”ğ‘šğ‘£ğ‘–)
and weightğ‘ƒğ‘ğ‘–(ğ‘¤ğ‘ğ‘–). Assuming we have a knapsack with a capacity
5732Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
ofğ‘†ğ‘ğ‘ğ‘, we aim to load the knapsack as much as possible to max-
imize its cumulative value while ensuring the expected ROI and
not exceeding the capacity. However, due to the fact that bidding,
winning, clicking, and conversion occur in chronological order, we
cannot obtain accurate value and weight information in advance,
i.e.ğ‘ğ‘–andğ‘¤ğ‘ğ‘–respectively. Therefore, in bidding strategy, only
historical conversion quantity or model estimates can be used to re-
placeğ‘ğ‘–andğ‘¤ğ‘ğ‘–, and a immediate decision has to be made whether
to pack the item or not.
3.2 Challenges in Privacy Scenarios
As delineated above, the problem represented by Eq. (2) we are
addressing becomes challenging under the constraints imposed by
privacy regulations for the subsequent reasons:
1)Coarse-Grained : The value of ğ‘ğ‘–inğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘–does not cor-
respond one-to-one, thereby complicating the optimization pro-
cess for fine-grained estimation methods such as model-based ap-
proaches.
2)Hysteresis : The reporting delay of ğ‘ğ‘–exceeds 24 hours, while
the frequently adopted spending period is a single day. This dis-
crepancy implies that the regulation of real-time bidding strategies
is executed without a ground truth label.
(3)Stochastic : i.e. random and unpredictable. The value of ğ‘ğ‘–is
not a stationary but a noisier feedback after aggregation, making it
almost impossible to estimate the distribution of ğ‘ğ‘–.
These privacy-related challenges induce considerable and irregu-
lar variance in the estimated deviation ğ‘‘(ğ‘¡)ofğ‘ğ‘–. Given the impact
ofğ‘‘(ğ‘¡), Eq. (5) transforms into
ğ‘ğ‘–=ğ‘ğ‘–Â·ğ‘‘(ğ‘¡)Â·ğ‘£ğ‘
ğ‘Ÿğ‘–=ğ‘ğ‘–Â·ğ‘£ğ‘
ğ‘Ÿğ‘–
ğ‘‘(ğ‘¡)=ğ‘ğ‘–Â·ğ‘£ğ‘
ğ‘Ÿâ€²
ğ‘–(6)
Now, based on Eq. (6), we analyze the applicability of three state-
of-the-art methods in privacy scenarios.
Real-time Feedback Control ğ‘ğ‘–is the observed conversion
events while online bidding process usually requires to calculate the
bid priceğ‘ğ‘–and return it within tens of milliseconds. This notion is
apparently contradictory to the hysteresis characteristic of privacy
scenarios.
Model Predictive Control (MPC) replaces ground truth values
with model-estimated click-through rates ğ‘ğ‘¡ğ‘Ÿğ‘–and conversion rates
ğ‘ğ‘£ğ‘Ÿğ‘–, i.e.,ğ‘ğ‘–=ğ‘ğ‘¡ğ‘Ÿğ‘–âˆ—ğ‘ğ‘£ğ‘Ÿğ‘–. This reliance on model generalization can
partially address the hysteresis issue. Since the historical patterns
are not likely suitable for the future under the stochastic limitation
and conversions cannot be precisely applied back to every fine-
grained individual sample under the coarse-grained constraint, the
accuracy and stability of model estimation cannot be guaranteed.
Thus, the MPC based methods has low applicability in privacy
scenarios.
Reinforced Learning (RL) based methods demand real-time
feedback to adapt bidding policies and actions which are typically
model-based. As a consequence, they encounter similar obstacles
as MPC methods within privacy scenarios..4 Spending Programmed Bidding
4.1 THRESHOLD Algorithm
As analyzed above, the problem under review can be identified
as an online stochastic KP in privacy scenarios. The incomplete-
ness ofğ‘ğ‘–andğ‘¤ğ‘ğ‘–in online auctions indicates that conventional
optimization solutions (e.g., Dynamic Programming) arenâ€™t appli-
cable. Fortunately, it has been asserted by [ 8] that the greedy al-
gorithm serves as a proximal optimal algorithm when the weight
of the item is significantly smaller than the knapsackâ€™s capacity,
i.e.,ğ‘¤ğ‘ğ‘–â‰¤(1âˆ’ğœ†)ğ‘†ğ‘ğ‘ğ‘,0â‰¤ğœ†â‰¤1whereğœ†signifies the degree of
resemblance to the optimal solution. As we will illustrate in the
experimental section, in the TikTok display advertising platform,
ğœ†is generally sizable, thus, this validates the greedy algorithm as
suitable for approximately resolving our problem.
The THRESHOLD, a typical example of greedy algorithms, only
packages an item ğ‘–when its efficiency ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ğ‘–/ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘–(in this case
ğ‘ğ‘–Â·ğ‘£ğ‘/ğ‘¤ğ‘ğ‘–=ğ‘Ÿğ‘–) equals or surpasses a predefined threshold ğ‘…ğ‘¡â„ğ‘Ÿ,
until the knapsack is filled (spend reaches cap) or there are no
items (auction opportunities) left. Once ğ‘…ğ‘¡â„ğ‘Ÿis determined, the
optimal bid can be inferred by substituting ğ‘Ÿğ‘–in Eq. (5) with ğ‘…ğ‘¡â„ğ‘Ÿ.
Earlier researches [ 24] [15] identified the specific threshold ğ‘…ğ‘¡â„ğ‘Ÿ
through feedback mechanism or model learning, which is inherently
limited in privacy scenarios due to aggregation, hysteresis, and
stochastic attributes. Contrarily, our SPB algorithm proves resilient
to these impediments, thereby facilitating valuable results in privacy
situations. Now we introduce the SPB framework in Algorithm 1
and then elaborate in the following subsections.
Algorithm 1 SPB Framework
Input: target ROIğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ , spend capğ‘†ğ‘ğ‘ğ‘set by advertiser
Output: optimalğ‘ğ‘™+1for next time control interval ğ‘¡ğ‘™+1
// Macro Spend Planning
1:Input the target ROI ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ and spend cap ğ‘†ğ‘ğ‘ğ‘, work out at
the total optimal spend ğ‘†(ğ‘œğ‘ğ‘¡)for a spending period
2:Obtain the optimal spend ğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘™+1for the next time interval ğ‘¡ğ‘™+1
// Micro Bidding Optimization
3:Construct an interpolation queue with the point pairs
(ğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘™,ğ‘ğ‘™)and obtainğ‘ğ‘™+1through interpolation or extension
methods
The SPB algorithm introduced here offers several distinct advan-
tages:
1) Innovative Two-Stage Decomposition Framework for Online
Bidding: This approach effectively dampens the impact of model
estimation errors.
2) Applicability in Privacy Scenarios: The application of long-
term cumulated data allows for the effective management of the
three challenges involved in privacy scenarios: coarse-grained, hys-
teresis, and stochastic natures. This level of resolution isnâ€™t achiev-
able with other non-decomposition methods.
3) Complexity Reduction: The original solution space of ğœ’=
[ğ‘¥1,...,ğ‘¥ğ‘–,...,ğ‘¥ğ‘]is reduced from 2ğ‘to just a single dimension,
which only necessitates the determination of ğ‘†(ğ‘œğ‘ğ‘¡).
5733KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yumin Su et al.
Figure 1: THRESHOLD algorithm
4.2 SPB Two-Stage Decomposition
The SPB algorithm, as we have previously discussed, consists of
two stages: macro and micro. This section explains why we split
the algorithm in this way. Subsequent sections will provide further
details about each stage. First, we establish a theorem based on an
ideal scenario, not taking into account ğ‘‘(ğ‘¡). Then, we extend it to a
more common scenario where ğ‘‘(ğ‘¡)is considered. For a short time
periodğ‘¡ğ‘™, the ROI of a single auction can be defined as ğ‘Ÿğ‘–=ğ‘ƒğ‘”ğ‘–/ğ‘ƒğ‘ ğ‘–.
In this context, the THRESHOLD greedy algorithm in an ideal
scenario works as follows:
1) Sort all auction opportunities in a descending order according
toğ‘Ÿğ‘–
2) Select auction opportunities from top to bottom until ğ‘Ÿğ‘–meets
the optimal threshold ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿ, obtain corresponding bid by replacing
ğ‘Ÿğ‘–in Eq. (5) with ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿ.
A demonstration is visualized in Fig. 1. We win all auction oppor-
tunities where ğ‘Ÿğ‘–is greater than or equal to ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿ(shadow region
ğ‘†1in Fig. 1) to achieve the maximization of ğ‘ƒğºunder theğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡
andğ‘†ğ‘ğ‘ğ‘constraints.
Referring to Eq. (6), disregarding ğ‘‘(ğ‘¡)means that the estimated
value ofğ‘ğ‘–is equal to the ground-truth value. For each auction op-
portunity, it can be accurately placed in the corresponding position
in Fig. 1. then we provide a theorem,
Theorem 1. When theğ‘…ğ‘¡â„ğ‘Ÿremains consistent across all auction
opportunities, the optimal solution is achieved.
Proof. We prove by contradiction. Considering the situation of
two different ğ‘…ğ‘¡â„ğ‘Ÿ1andğ‘…ğ‘¡â„ğ‘Ÿ2, assuming the overall ğ‘ƒğºis maximum
withğ‘…ğ‘¡â„ğ‘Ÿ1>ğ‘…ğ‘¡â„ğ‘Ÿ2, then we move ğ‘…ğ‘¡â„ğ‘Ÿ1down of a exiguity Î”ğ‘…âˆ’
ğ‘¡â„ğ‘Ÿ1
and moveğ‘…ğ‘¡â„ğ‘Ÿ2up of a exiguity Î”ğ‘…+
ğ‘¡â„ğ‘Ÿ2withÎ”ğ‘ƒ+
ğ‘†ğ‘¡â„ğ‘Ÿ1=Î”ğ‘ƒâˆ’
ğ‘†ğ‘¡â„ğ‘Ÿ2.
since all auction opportunities are arranged in descending order
by roi, obviously, there is Î”ğ‘…âˆ’
ğ‘Ÿğ‘’ğ‘ 1>Î”ğ‘…+
ğ‘Ÿğ‘’ğ‘ 2. Given that Î”ğ‘ƒğºğ‘¡â„ğ‘Ÿ=
Î”ğ‘ƒğ‘†ğ‘¡â„ğ‘ŸÂ·ğ‘…ğ‘Ÿğ‘’ğ‘ , it naturally follows that Î”ğ‘ƒ+
ğºğ‘¡â„ğ‘Ÿ1>Î”ğ‘ƒâˆ’
ğºğ‘¡â„ğ‘Ÿ2, i.e., mov-
ing a portion of spend in ğ‘…ğ‘¡â„ğ‘Ÿ2toğ‘…ğ‘¡â„ğ‘Ÿ1can obtain a overall ğ‘ƒâ€²
ğºthat
ğ‘ƒâ€²
ğº>ğ‘ƒğº, which contradicts our initial assumption of ğ‘ƒğºbeing
maximal. Proof completed.
Nevertheless, in privacy scenarios, the value of ğ‘‘(ğ‘¡)cannot be
overlooked as it precludes the attainment of real-time ğ‘ğ‘–values in
short time intervals. As previously mentioned,
1) Privacy policies often impose a certain delay (e.g., SKAN
doesnâ€™t surpass 48 hours). By aggregating data over multiple days,
we can get very close to the actual value of ğ‘ğ‘–.2)ğ‘‘(ğ‘¡)doesnâ€™t highly fluctuate within a very short time interval.
Thus, ifğ‘Ÿğ‘–is order-preserving regardless of the value of ğ‘‘(ğ‘¡)for
all auction opportunities, using THRESHOLD algorithm remains a
viable solution even in a short duration.
This insight motivates us to separate the online bidding pro-
cess into two stages: macro andmicro. The macro stage devises the
optimal spend ğ‘†(ğ‘œğ‘ğ‘¡), for a given spending period from archived
data over a long period, and then allocates ğ‘†(ğ‘œğ‘ğ‘¡)for a short time
intervalğ‘¡ğ‘™following a budget allocation curve to get ğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘™. Sub-
sequently, the micro stage generates the real-time bidding price
based onğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘™. It is crucial to note that budget distribution curve
research, a field focused on optimizing budget allocation, ensures a
consistentğ‘…ğ‘¡â„ğ‘Ÿonce the allocated budget is fully spent. While this
study doesnâ€™t focus on this, it leverages existing works like [ 36] to
potentially optimize budget allocation efficiency.
4.3 Macro Spend Planning
As previously stated, the macro stage devises the long-term optimal
spendğ‘†(ğ‘œğ‘ğ‘¡), ensuring this allocated spend aligns with the long-
term optimum in Eq. (2). This problem is modeled by exploring
the relationship between optimal GMV and optimal ROI, and weâ€™ll
demonstrate this with an example. Initially, in the absence of ğ‘‘(ğ‘¡)
considerations, we propose the following theorems under ideal
conditions.
Theorem 2. For an ad campaign with different ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ andğ‘†ğ‘ğ‘ğ‘
constraints, the optimal result roi ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘  is monotone increasing w.r.t.
ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿ.
Proof. To verify the proof more clearly and more intuitive, an
illustration is shown in Fig. 1. Assuming we move ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿbetween
ğ‘…â€²(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿandğ‘…â€²â€²(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿunder different ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ andğ‘†ğ‘ğ‘ğ‘constraints,
we obtain more auction opportunities in the ğ‘†2region. Since ğ‘Ÿğ‘–is
arranged in descending order, any ğ‘Ÿğ‘–in theğ‘†1region is greater than
anyğ‘Ÿğ‘—in theğ‘†2region, i.e.ğ‘Ÿğ‘–>ğ‘Ÿğ‘—, forâˆ€ğ‘–âˆˆğ‘†1,ğ‘—âˆˆğ‘†2. So obvi-
ously the result ROI also follows the same inequality relationship
ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘ ğ‘†1â‰¥ğ‘…ğ‘Ÿğ‘’ğ‘ ğ‘†2, considering Eq. (1), we have
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºğ‘†1
ğ‘ƒğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘†1â‰¥ğ‘ƒğºğ‘†2
ğ‘ƒğ‘†ğ‘†2â‡’ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºğ‘†1Â·ğ‘ƒğ‘†ğ‘†2âˆ’ğ‘ƒğºğ‘†2Â·ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘†1â‰¥0 (7)
We denote the optimal result ROI of the new winning region
ğ‘†1+ğ‘†2asğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘ (ğ‘†1+ğ‘†2), and we compare
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº(ğ‘†1+ğ‘†2)
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†(ğ‘†1+ğ‘†2)âˆ’ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºğ‘†1
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘†1
=âˆ’ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºğ‘†1Â·ğ‘ƒğ‘†ğ‘†2âˆ’ğ‘ƒğºğ‘†2Â·ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘†1
(ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘†1+ğ‘ƒğ‘†ğ‘†2)Â·ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘†1â‰¤0(8)
Eq. (8) indicates that ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘  decreases as ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿdecreases, thus
we have completed the proof.
5734Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Theorem 3. For an ad campaign with different ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ andğ‘†ğ‘ğ‘ğ‘
constraints, the optimal gmv ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºand spendğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†is monotone
decreasing w.r.t. ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘  .
Proof. Same with proof of Theorem2, assuming we move ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿ
betweenğ‘…â€²(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿandğ‘…â€²â€²(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿunder different ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ andğ‘†ğ‘ğ‘ğ‘con-
straints, we win extra auction opportunities with Î”ğ‘ƒğº=ğ‘ƒğºğ‘†2and
Î”ğ‘ƒğ‘†=ğ‘ƒğ‘†ğ‘†2, which are definitely greater than 0. Then we have
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº(ğ‘†1+ğ‘†2)=ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºğ‘†1+ğ‘ƒğºğ‘†2â‰¥ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºğ‘†1andğ‘ƒ(ğ‘œğ‘ğ‘¡)
(ğ‘†1+ğ‘†2)=ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘†1+ğ‘ƒğ‘†ğ‘†2â‰¥
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘†1i.e. the gmv and spend of the new winning region ğ‘†1+ğ‘†2
are greater than the origin winning region ğ‘†1along with ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿ
less thanğ‘…â€²(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿ. Noting that we have proved ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘  is monotone
increasing w.r.t. ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿin Theorem2, we attain ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºandğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†
is monotone decreasing w.r.t. ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘  , thus the proof of Theorem3
has been finished.
With consideration of ğ‘‘(ğ‘¡), the value of ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿin the THRESH-
OLD algorithm may exhibit variations. However, the final optimal
GMV and ROI still conform to Theorem 3. Thus, we can construct a
relation function between the optimal GMV ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºand ROIğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘  .
Treat theğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ , as set by the advertiser, to be the optimal ROI (i.e.,
Eq. (4) is equivalent), allowing for the calculation of optimal GMV
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºand thereby the optimal spend ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†. We compute our func-
tion parameters based on GMV and ROI posterior data aggregated
over a long period (such as n days). Given the minor impact of ğ‘‘(ğ‘¡)
on long-term posterior data :1) ğ‘ğ‘–can be fully restored within 48
hours, and only accumulated data is employed, thereby dodging the
coarse-grained and hysteresis challenges; 2)due to the large sample
size of the long-term results, the stochastic challenges impact is
considerably less than that of small samples in a short period. So
that the optimal functional relationship can be approximated. Letâ€™s
further explain this through a detailed example.
As shown from Fig. 1, ğ‘…ğ‘¡â„ğ‘Ÿindicates the reduction in ğ‘…ğ‘Ÿğ‘’ğ‘ for
each additional auction opportunity, precisely representing the
concept of marginal ROI. Function ğ¹(ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº)=ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘  can take
various forms depending on the circumstances. For clarity, weâ€™ll
provide an example in its simplest form, we simply infer that the
optimal marginal ROI ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿand optimal GMV ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğºbear a linear
relationship according to Theorem2 and Theorem3.
ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘¡â„ğ‘Ÿ=ğ¹â€²(ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº)=ğ‘Â·ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº+ğ‘ (9)
Where a and b are hyperparameters, then we get
ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘  =ğ¹(ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº)=ğ‘Â·ğ‘ƒ2(ğ‘œğ‘ğ‘¡)
ğº
2+ğ‘Â·ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº(10)
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº=âˆšï¸ƒ
ğ‘2+2ğ‘Â·ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘ âˆ’ğ‘
ğ‘(11)
According to Eq. (1), we further obtain
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†=ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğº
ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘ =âˆšï¸ƒ
ğ‘2+2ğ‘Â·ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘ âˆ’ğ‘
ğ‘Â·ğ‘…(ğ‘œğ‘ğ‘¡)
ğ‘Ÿğ‘’ğ‘ (12)To figure out the parameters a and b, the cumulative GMV and
ROI over a defined spending period (such as one day) can be syn-
thesized to generate a single sample point. The data points over
multiple days then can be aggregated and derived parameters a and
b through multi-point fitting. Numerous existing methods can be
consulted for model parameter determination to achieve minimum
MSE across multiple sample points. Once parameters a and b are
determined, we can input the advertiserâ€™s target ROI, ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ , into
Eq. (12) to procure the optimal spending ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†for a defined spend-
ing duration. Given the spend constraint Eq. (3), ğ‘†(ğ‘œğ‘ğ‘¡)is assessed
asmin(ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†,ğ‘†ğ‘ğ‘ğ‘).
After finding the ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†, it is distributed over a shorter period
through a budget allocation curve, obtaining the ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘™for a brief
time interval ğ‘¡ğ‘™. This can guide the optimal bid within ğ‘¡ğ‘™during the
micro stage.
4.4 Micro Bidding Optimization
As previously noted, we have determined the overall optimal spend
ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†in the macro satge. We then use a budget allocation method
to obtain the optimal ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘™for a brief time interval ğ‘¡ğ‘™. The micro
processâ€™ objective is to spend exactly ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘™withinğ‘¡ğ‘™. Ideally, the
THRESHOLD algorithm could be directly employed to compute
ğ‘…ğ‘¡â„ğ‘Ÿthrough Eq. (9), then calculate the optimal bid through Eq. (5).
Nevertheless, in privacy scenarios demanding the consideration
ofğ‘‘(ğ‘¡), short-term GMV and ROI are influenced by the aforemen-
tioned challenges, inhibiting the acquisition of suitable a and b
parameters for Eq. (9). As a result, we need to refine the THRESH-
OLD algorithm to find the specific ğ‘…ğ‘¡â„ğ‘Ÿvalue without depending
on GMV and ROI, ensuring fulfilling the ğ‘ƒ(ğ‘œğ‘ğ‘¡)
ğ‘†ğ‘™spend.
Itâ€™s worth acknowledging that in privacy scenarios, while ğ‘ğ‘–is
impacted by ğ‘‘(ğ‘¡), its spend is unaffected. The spend can be imme-
diately collected as soon as the ad campaign has been displayed
via the widely accepted OCPM mechanism5(or any other pricing
method charging by display or click), indicating that the spend can
be gathered in real-time, undisturbed by hysteresis and stochastic
challenges.
Hence, we aim to build a model for ğ‘…ğ‘¡â„ğ‘Ÿand spendğ‘ƒğ‘†. In accord
with Theorem2 and Theorem3, under ideal circumstances, ğ‘…ğ‘¡â„ğ‘Ÿ
andğ‘ƒğ‘†monotonically decrease. Assuming that ğ‘‘(ğ‘¡)maintains the
ğ‘Ÿğ‘–order for all auction opportunities, Theorem2 and Theorem3
continues to hold in privacy scenarios featuring a different optimal
ğ‘…ğ‘¡â„ğ‘Ÿthan the ideal, as exhibited in Eq. (6).
We propose the following algorithm to construct a linear interpo-
lation model for ğ‘…ğ‘¡â„ğ‘Ÿandğ‘ƒğ‘†, termed the Interpolation-based MPC
method (IMPC). By utilizing spending data from a brief time slice
ğ‘¡ğ‘™only, we can calculate the ğ‘…ğ‘¡â„ğ‘Ÿand thenğ‘ğ‘™+1for the subsequent
time interval ğ‘¡ğ‘™+1. The specific algorithm is delineated in Algorithm
2.
We can summarize that the IMPC, as described in Algorithm 2,
offers several key advantages:
5Advertisers bid for conversions while paying per mille display
5735KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yumin Su et al.
Algorithm 2 Interpolation-based MPC method
Input:(ğ‘ƒğ‘†ğ‘™,ğ‘…ğ‘¡â„ğ‘Ÿğ‘™)for time control interval ğ‘¡ğ‘™;
ğ‘„=ğ‘ğ‘¢ğ‘’ğ‘¢ğ‘’(ğ‘ƒğ‘†ğ‘–,ğ‘…ğ‘¡â„ğ‘Ÿğ‘–),ğ‘–âˆˆ{1,...,ğ¿}for lastğ¿time control in-
tervals
ğ‘‰=ğ‘£ğ‘’ğ‘ğ‘¡ğ‘œğ‘Ÿ(ğ‘†ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘—)for remain time control intervals from
budget allocation methods
ğ‘†(ğ‘œğ‘ğ‘¡)the expected spend in a spending period derived from
the macro stage
ğ‘†ğ‘ğ‘ğ‘maximum spend in a spending period set by advertiser
ğ‘ƒğ‘†cumulative spend in a spending period
Output:ğ‘ğ‘™+1for next time control interval ğ‘¡ğ‘™+1
1:ifğ‘ƒğ‘†>ğ‘†ğ‘ğ‘ğ‘then
2:ğ‘ğ‘™+1=0
3: return
4:else
5: ifğ‘™ğ‘’ğ‘›(ğ‘„)==0then
6:ğ‘ğ‘™+1=ğ‘–ğ‘›ğ‘–ğ‘¡(ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘¡ _ğ‘ğ‘–ğ‘‘)
7: return
8: else
9:ğ‘™ğ‘ğ‘ ğ‘¡ğ‘…ğ‘¡â„ğ‘Ÿ=ğ‘…ğ‘¡â„ğ‘Ÿğ‘™
10: end if
//deal with new data
11: ifğ‘£ğ‘ğ‘™ğ‘–ğ‘‘(ğ‘ƒğ‘†ğ‘™,ğ‘…ğ‘¡â„ğ‘Ÿğ‘™)then
12:ğ‘„=ğ‘ğ‘¢ğ‘ â„(ğ‘„,(ğ‘ƒğ‘†ğ‘™,ğ‘…ğ‘¡â„ğ‘Ÿğ‘™))
13: else
14:ğ‘ğ‘™+1=ğ¹(ğ‘™ğ‘ğ‘ ğ‘¡ğ‘…ğ‘¡â„ğ‘Ÿ)// using Eq. (6)
15: return
16: end if
17: ifğ‘™ğ‘’ğ‘›(ğ‘„)>ğ¿then
18:ğ‘„=ğ‘ğ‘œğ‘(ğ‘„)
19: end if
//calculate the expected spend for ğ‘¡ğ‘™+1
20:ğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘™+1=(ğ‘†(ğ‘œğ‘ğ‘¡)âˆ’ğ‘ƒğ‘†)Â·ğ‘†ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘™+1/Ã
ğ‘—ğ‘†ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘—
//aggregate and average points with similar ğ‘…ğ‘¡â„ğ‘Ÿvalues
21:ğ´ğ‘„=ğ‘ğ‘”ğ‘”ğ‘Ÿğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘œğ‘›(ğ‘„)
//calculate new ğ‘…ğ‘¡â„ğ‘Ÿwith liner interpolation
22:ğ¿ğ¼ğ‘†ğ‘„ =ğ¿ğ‘œğ‘›ğ‘”ğ‘’ğ‘ ğ‘¡ğ¼ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘–ğ‘›ğ‘”ğ‘†ğ‘¢ğ‘ğ‘†ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘’ (ğ´ğ‘„)
23:(ğ‘ƒğ‘†ğ‘¥1,ğ‘…ğ‘¡â„ğ‘Ÿğ‘¥1),(ğ‘ƒğ‘†ğ‘¥2,ğ‘…ğ‘¡â„ğ‘Ÿğ‘¥2)=ğ¶ğ‘™ğ‘œğ‘ ğ‘’ğ‘ ğ‘¡ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡(ğ¿ğ¼ğ‘†ğ‘„,ğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘™+1)
24:ğ‘…ğ‘¡â„ğ‘Ÿğ‘™+1=ğ‘…ğ‘¡â„ğ‘Ÿğ‘¥1+(ğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘™+1âˆ’ğ‘ƒğ‘†ğ‘¥1)Â·ğ‘…ğ‘¡â„ğ‘Ÿğ‘¥2âˆ’ğ‘…ğ‘¡â„ğ‘Ÿğ‘¥1
ğ‘ƒğ‘†ğ‘¥2âˆ’ğ‘ƒğ‘†ğ‘¥1
25:ğ‘ğ‘™+1=ğ¹(ğ‘…ğ‘¡â„ğ‘Ÿğ‘™+1)// using Eq. (6)
26: return
27:end if
1) No Cumulative Error: For each ğ‘¡ğ‘™, the optimal bid ğ‘ğ‘™depends
only on a predetermined ğ‘†(ğ‘œğ‘ğ‘¡)
ğ‘™, and remains unaffected by previous
control effects, unlike feedback control methods.
2) No Prior Function Distribution Required: Essentially as a non-
parametric regression model, it ensures high accuracy.
3) Robustness and Portability: Relying only on real-time settle-
ment data, it proves to be stable and effective even in high-frequency
computations.4.5 Multi Channel Promotion
In practical, advertisers usually place ad campaigns on more than
one channel regardless of privacy constraints with spend sharing,
and each channel has its own ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ constrain. Therefore, the
problem to be solved is extended to
ğ‘šğ‘ğ‘¥ğ‘€âˆ‘ï¸
ğ‘—=1ğ‘ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—Â·ğ‘£ğ‘ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—(13)
s.t.
ğ‘€âˆ‘ï¸
ğ‘—=1ğ‘ƒğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—â‰¤ğ‘†ğ‘ğ‘ğ‘ (14)
ğ‘†ğ‘“ğ‘™ğ‘œğ‘œğ‘Ÿğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—â‰¤ğ‘ƒğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—â‰¤ğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—,âˆ€ğ‘—âˆˆ{1,...,ğ‘€} (15)
ğ‘…ğ‘Ÿğ‘’ğ‘ ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—â‰¥ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—,âˆ€ğ‘—âˆˆ{1,...,ğ‘€} (16)
ğ‘…ğ‘Ÿğ‘’ğ‘ â‰¥ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ (17)
Due to the differences in the estimated deviation ğ‘‘ğ‘™and tar-
get ROIğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ between different channels in mixed privacy and
non-privacy scenarios, the single channel SPB solution proposed
above cannot be directly used. We further expand SPB to multiple
channels, which macro part is jointly solved, while micro part is
separately solved. In the macro part, we need to simultaneously
produce the expected optimal spend ğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—for each channel.
Before that, we provide Theorem 4 and prove it.
Theorem 4. When the overall ğ‘ƒğºis maximum, there must be
equalğ‘…ğ‘¡â„ğ‘Ÿfor each channel.
Proof. We prove by contradiction. Considering the situation
of two channels ğ‘â„1andğ‘â„2, assuming the overall ğ‘ƒğºis maxi-
mum withğ‘…ğ‘¡â„ğ‘Ÿğ‘â„1>ğ‘…ğ‘¡â„ğ‘Ÿğ‘â„2, then we move ğ‘…ğ‘¡â„ğ‘Ÿğ‘â„1down of a
exiguity Î”ğ‘…âˆ’
ğ‘¡â„ğ‘Ÿğ‘â„1and moveğ‘…ğ‘¡â„ğ‘Ÿğ‘â„2up of a exiguity Î”ğ‘…+
ğ‘¡â„ğ‘Ÿğ‘â„2with
Î”ğ‘ƒ+
ğ‘†ğ‘â„1=Î”ğ‘ƒâˆ’
ğ‘†ğ‘â„2. Obviously, there is Î”ğ‘…âˆ’ğ‘Ÿğ‘’ğ‘ ğ‘â„1>Î”ğ‘…+ğ‘Ÿğ‘’ğ‘ ğ‘â„2and
Î”ğ‘ƒğºğ‘â„=Î”ğ‘ƒğ‘†ğ‘â„Â·ğ‘…ğ‘Ÿğ‘’ğ‘ ğ‘â„, then we have Î”ğ‘ƒ+
ğºğ‘â„1>Î”ğ‘ƒâˆ’
ğºğ‘â„2, i.e., mov-
ing a portion of spend in ğ‘â„2toğ‘â„1can obtain a overall ğ‘ƒâ€²
ğºthat
ğ‘ƒâ€²
ğº>ğ‘ƒğº, which contradicts our initial assumption of ğ‘ƒğºbeing
maximal. Proof completed.
According to Theorem 4, we can determine the optimal spend
for each channel through a binary search method which detailed
in Algorithm 3.
Upon determining ğ‘…ğ‘¡â„ğ‘Ÿ, we canâ€™t directly bid using Eq. (5) due to
the variance in ğ‘‘ğ‘™across different channels. We need to first com-
puteğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—akin to the macro stage, constructing a functional
correlation between GMV and ROI for each channel. Subsequently,
the IMPC algorithm is independently applied to ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—to derive
the optimal bid ğ‘ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—.
5 Experiments
In this section, we validate the performance of our proposed SPB
method through online and offline experiments. We first conduct
online experiments on an industrial dataset collected from the
TikTok display advertising platform6to compare the performance
of SPB with other advanced methods in real-world industrial appli-
cation circumstances. As the privacy constrained attribution issue
is recently raised, and due to the need to protect user privacy and
6https://ads.tiktok.com/i18n/dashboard
5736Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Algorithm 3 Multi Channel SPB - macro stage
Input:ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡,ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—,ğ‘†ğ‘ğ‘ğ‘,ğ‘†ğ‘“ğ‘™ğ‘œğ‘œğ‘Ÿğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—
Output:ğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—
1:initialize:ğ‘†(ğ‘œğ‘ğ‘¡)=0,ğ‘ƒğº=0,random(ğ‘…ğ‘¡â„ğ‘Ÿ)
2:repeat
3: foreach channel ğ‘—do
4:ğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—=max(ğ¹ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—(ğ‘…ğ‘¡â„ğ‘Ÿ),ğ‘†ğ‘“ğ‘™ğ‘œğ‘œğ‘Ÿğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—)// using
Eq. 9 and Eq. 10 and Eq. 1
5:ğ‘…ğ‘Ÿğ‘’ğ‘ ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—=ğ¹(ğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—)// using Eq. 12
6:ğ‘ƒğºğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—=ğ¹(ğ‘…ğ‘Ÿğ‘’ğ‘ ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—)// using Eq. 11
7:ğ‘†(ğ‘œğ‘ğ‘¡)+=ğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—,ğ‘ƒğº+=ğ‘ƒğºğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—
8: end for
9:ğ‘…ğ‘Ÿğ‘’ğ‘ =ğ‘ƒğº
ğ‘†(ğ‘œğ‘ğ‘¡)
10: ifğ‘…ğ‘Ÿğ‘’ğ‘ <ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ orğ‘†(ğ‘œğ‘ğ‘¡)>ğ‘†ğ‘ğ‘ğ‘orğ‘…ğ‘Ÿğ‘’ğ‘ ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—<
ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—ğ‘“ğ‘œğ‘Ÿâˆ€ğ‘—then
11: Explore upğ‘…ğ‘¡â„ğ‘Ÿin (ğ‘…ğ‘¡â„ğ‘Ÿ,+âˆ)
12: else
13: Explore down ğ‘…ğ‘¡â„ğ‘Ÿin (0,ğ‘…ğ‘¡â„ğ‘Ÿ)
14: end if
15:untilğ‘…ğ‘¡â„ğ‘Ÿconvergence
16:ğ‘†ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—=ğ¹ğ‘â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ‘—(ğ‘…ğ‘¡â„ğ‘Ÿ)// using Eq. 9
commercial secrets, we are unable to disclose TikTokâ€™s advertis-
ing data. To demonstrate the reproducibility of our work, and to
provide a validation dataset and template code for future users of
our method, we have built a simulated privacy dataset based on
AuctionGym[ 19], and then conduct offline experiments on the simu-
lated dataset. Our simulated dataset and code are publicly available
at https://github.com/cff29546/SpendingProgrammedBidding.
5.1 Experimental Settings
Datasets: Theindustrial dataset is collected from the Tiktok dis-
play advertising platform. As described in Table 2, we randomly
select three datasets for the experiment, one from campaigns using
SKAN attribution, one from campaigns using PCM attribution and
another from campaigns using non-privacy constrained. We evalu-
ated the average ğ‘¤ğ‘/ğ‘ ğ‘ğ‘’ğ‘›ğ‘‘ ratio for each dataset during Aug 1st
to Aug 8th of 2023. As all datasets have small ğ‘¤ğ‘/ğ‘ ğ‘ğ‘’ğ‘›ğ‘‘ ratio, thus
the greedy method in subsection 4.1 is applicable.
Thesimulated dataset is created based on the public simulated
dataset AuctionGym, which is a simulation environment that facili-
tates reproducible offline evaluations for ad allocation and bidding
in online advertising auctions without privacy constraints. We have
enhanced this dataset to meet the three characteristics previously
mentioned for privacy scenarios: coarse-grained, hysteresis, and
stochastic natures. In our enhanced dataset, the number of cam-
paigns and auction opportunities can be set, while still retaining
the attribute of a very small ğ‘¤ğ‘/ğ‘ ğ‘ğ‘’ğ‘›ğ‘‘ proportion. The offline ex-
periment simulates each bidder with 500 random campaigns (runs)
under different postback delay settings of 0, 1, and 2 batches (simu-
lating online days).
Budget Splitting Experimental Mechanism: For the online ex-
periments on the industrial dataset, to split online traffic into testTable 2: summary of industrial datasets
Dataset # Campaigns Avg. ğ‘¤ğ‘/ğ‘ ğ‘ğ‘’ğ‘›ğ‘‘ ğ‘” ğ‘–
SKAN 455 2.82Ã—10âˆ’77% each
PCM 4488 1.24Ã—10âˆ’67% each
non-privacy 1290 6.28Ã—10âˆ’77% each
and control groups, we define the split vector ğº=[ğ‘”1,...,ğ‘”ğ‘–,...,ğ‘”ğ‘]
whereğ‘”ğ‘–âˆˆ(0,1]andÃğ‘
ğ‘–=1ğ‘”ğ‘–=1. Then we split all online auction
opportunities into ğ‘groups by randomly assigning each auction
opportunity to group ğ‘–with a chance of ğ‘”ğ‘–. For each involved adver-
tising campaign, the original spend cap ğ‘†ğ‘ğ‘ğ‘given by the advertiser
is also split into ğ‘groups, with each group ğ‘–having a spend cap
equal toğ‘†ğ‘ğ‘ğ‘Â·ğ‘”ğ‘–and can only participate in auction opportunities
assigned to that group.
SPB method settings: For each campaign, we learn ğ¹(ğ‘ƒğº)=ğ‘…ğ‘Ÿğ‘’ğ‘ 
from its daily history using a 7-day time window. Each daily ğ‘…ğ‘Ÿğ‘’ğ‘ 
andğ‘ƒğºpair within the history window that is no longer affected by
attribution delays is used as a sample. After learning ğ¹(ğ‘ƒğº)=ğ‘…ğ‘Ÿğ‘’ğ‘ ,
ğ‘†(ğ‘œğ‘ğ‘¡)is calculated by inserting ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ .ğ‘†(ğ‘œğ‘ğ‘¡)is then applied in
the micro stage of the following day, where ğ‘¡ğ‘™is set to 20 seconds.
5.2 Performance Measurement
The goal of ROI constrained advertising is to optimise a cam-
paignâ€™s GMV while maintaining an acceptable ROI result. Therefore,
GMV and spending (platform revenue) are calculated for each cam-
paign during the experimental period. Subsequently, campaigns
are grouped based on their ROI and spend utilization performance.
Lastly, the GMV and spending accumulated for each campaign
performance group are used to assess the performance of bidding
methods. As shown in Fig. 2, we define the following campaign
performance groups:
(1) The Violation group includes campaigns whose ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ <
1âˆ’ğœ–1, indicating a violation of the ROI constraint. The ğœ–1is the ROI
volatility tolerance parameter. We use ğœ–1=0.2in our overall per-
formance comparisons. The less GMV and spending in this group
indicate a better bidding method.
(2) The Under Performance group includes campaigns where
ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ >1+ğœ–2andğ‘ƒğ‘†/ğ‘†ğ‘ğ‘ğ‘<1âˆ’ğœ–3, suggesting campaigns
have a good ROI and potential to increase spending. The ğœ–2is the
good ROI discriminant parameter and ğœ–3is the spending capacity
discriminant parameter. We use ğœ–2=0.2andğœ–3=0.1in our overall
performance comparisons. Lower GMV and spending in this group
also indicate a better bidding method.
(3) The Accomplish group comprises all campaigns not included
in the Violation andUnder Performance groups. Higher GMV
and spending in this group would indicate a better bidding method.
Additionally, when ROI is the primary concern, we can combine
groups (2) and (3) to form the Non-Violation group.
5.3 Compared Bidding Methods
In our experiments, we compare the following bidding methods:
Bid Cap: This method attempts to smoothly spend the entire budget
ğ‘†ğ‘ğ‘ğ‘, ensuring that ğ‘…ğ‘¡â„ğ‘Ÿâ‰¥ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ . The smooth spending is similar
to using the micro stage for the entire budget ğ‘†ğ‘ğ‘ğ‘.
5737KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yumin Su et al.
Figure 2: campaign performance groups
Table 3: over all performance compare over SKAN campaigns
Violation Under Performance Accomplish
BidCap(base)
GMV 10.54 (27.24%) 3.58 (9.25%) 24.57 (63.51%)
Spending 19.47 (44.48%) 2.65 (6.06%) 21.65 (49.46%)
# Campaigns 36.53% 13.70% 49.77%
MPC
GMV 11.78 (29.35%) 1.43 (3.56%) 26.93 (67.09%)
Spending 16.99 (38.81%) 0.82 (1.87%) 25.97 (59.32%)
# Campaigns 38.57% 13.45% 47.98%
SPB
GMV 5.61 (11.92%) 4.44 (9.45%) 36.99 (78.63%)
Spending 9.74 (27.55%) 2.31 (6.55%) 23.29 (65.91%)
# Campaigns 40.66% 12.12% 47.19%
MPC: Real-time feedback control using ground truth data is unre-
alistic in scenarios with heavy delays. Therefore, we use true click
events with the model-predicted conversion rate for feedback where
ğ‘ğ‘–=ğ‘ğ‘™ğ‘–ğ‘ğ‘˜âˆ—
ğ‘–Â·ğ‘ğ‘£ğ‘Ÿğ‘–. We then employ a PID controller for real-time
feedback control, where the PID error is given by ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡âˆ’1.
5.4 Online Experimental Performance
5.4.1 Overall Performance Comparisons. In this subsection, we
evaluate the overall performance of our proposed SPB framework
by comparing it comprehensively with various baselines.
Table.3 contains performance data from the online experiment
conducted from July 26, 2023 to August 1, 2023 on SKAN attribution
campaigns. The numbers, which have been desensitized to protect
commercial confidentiality, are collected from all campaigns with 5
or more average daily SKAN conversions. The results show that the
SPB bidding method can improve GMV and revenue in the Accom-
plish group while reducing GMV and revenue in the Violation
group, compared to other methods.
Fig.3 displays the Accomplish groupâ€™s GMV ratio across differ-
ent industrial datasets. Even though the SPB bidding method didnâ€™t
outperform the MPC bidding method in non-privacy attribution
campaigns, it still surpasses the baseline (BidCap) bidding method.
Moreover, the SPB method demonstrates better performance in
privacy-constrained scenarios compared to other bidding methods,
especially in SKAN attribution campaigns.
Figure 3: Accomplish group GMV ratio across datasets
Figure 4: Violation group GMV ratio across different ğœ–1
Figure 5: GMV density over ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡
5.4.2 In-Depth ROI Analysis. In this subsection, we compare the
performance of all bidding methods across different values of ğœ–1.
The data in Fig.4 is calculated from online experimental data
on SKAN attribution campaigns by varying the value of ğœ–1. As
mentioned in the Performance Measurement subsection, ğœ–1is the
ROI volatility tolerance parameter. According to Fig.4, the SPB bid-
ding method sees less increase in the violation groupâ€™s GMV ratio
compared to the other methods when reducing the ROI volatility
tolerance. Moreover, the SPB bidding method has the smallest vio-
lation group GMV ratio at ğœ–1=0, where the non-violation group
must strictly meet the ROI target.
To further analyze the ROI constrained optimization capability
of the SPB bidding method, we list the GMV distribution over
ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ in Fig.5. We can see that the GMV distribution of SPB
is shifted towards ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ >1compared to other bidding
methods. Also, the SPB bidding method generates more GMV with
ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡â‰¥1.0compared to other bidding methods.
5738Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Figure 6: Accomplish group GMV ratio across different delays
Figure 7: Violation group GMV ratio across different delays
5.5 Offline Experimental Performance
We are particularly interested in seeing our proposed method prac-
tically implemented in industrial scenarios, contributing a feasible
solution for computational advertising in privacy-constrained sce-
narios. Our approach is comprehensively applied to TikTokâ€™s ad-
vertising under privacy constraints, exhibiting stable performance
online.
In adherence to user privacy and protection of commercial se-
crets, we cannot disclose TikTokâ€™s advertising data. Hence, we pro-
vide an enhanced simulation environment based on AuctionGym
and establish offline experiments on it. Our main improvements
include:
1) Ensuring ğ‘ğ‘–differences with the original ğ‘ğ‘–values disrupted
by a monotonic disturbance.
2) Incorporating a delay in ğ‘ğ‘–feedback.
3) Aggregating ğ‘ğ‘–results into a single batch instead of instant
feedback after each auction opportunity.
Offline evaluation metrics align with those online, and we set
the advertiser-specified target ROI ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ =1. Furthermore, in
our offline experiments, we have each method compete against the
same environment to obtain results for comparison. And our SPB
method outperforms compared to benchmark methods. Please refer
to the GitHub link provided in section 5 for details.
5.5.1 Overall Performance Comparisons. In alignment with online
experiment findings, the offline results further affirm that SPB
bidding method, relative to others, effectively enhances GMV in
the Accomplish group and decreases Value in the Violation group.
Fig.6 and Fig.7 present the GMV ratios for the Accomplish and
Violation groups over different delays. The SPB method shows
dominance in the Accomplish group with the highest proportion
Figure 8: Violation group GMV ratio across different ğœ–1
Figure 9: GMV density over ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡
in the 0-3 batches delay period, and this lead intensifies as delays
increase. In contrast, the MPC method causes sharp ratio increases
in the Violation group as delays extend. However, the SPB method
increases at a much slower rate, showcasing its better effectiveness
against strict privacy policies.
5.5.2 In-Depth ROI Analysis. Here we compare the performance
of all bidding methods across different values of ğœ–1with a 1 batch
delay. As indicated in the paper, ğœ–1represents the ROI volatility
tolerance parameter. Fig.8 reveals that SPB bidding leads to smaller
increases in violation groupâ€™s GMV ratio compared to MPC when
reducing ROI volatility tolerance. The BidCap method, at the cost
of significantly less GMV compared to other methods, shows the
least violation group Value ratio in our offline experiment.
Further analysis of SPBâ€™s ROI constrained optimization can be
seen in Fig.9, displaying Value distribution over ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ . SPBâ€™s
Value distribution shifts towards ğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ =1, significantly in
a uniform offline environment, compared to other methods. Consis-
tent with our findings in online experiments, SPB could yield more
Value forğ‘…ğ‘Ÿğ‘’ğ‘ /ğ‘…ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡â‰¥1.0than other bidding methods.
6 Conclusions
In this paper, we introduce a novel Spending Programmed Bidding
framework (SPB) designed to address the issue of ROI-constrained
spending planning and bidding within privacy-protected environ-
ments, and extend it to mixed scenarios of privacy and non-privacy.
Through both offline and online experiments, we demonstrated that
our SPB method surpasses other state-of-the-art methods. The ex-
ploration of a more privacy-sensitive equilibrium would be studied
in the future work.
5739KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Yumin Su et al.
References
[1]Deepak Agarwal, Souvik Ghosh, Kai Wei, and Siyu You. 2014. Budget pac-
ing for targeted online advertisements at LinkedIn. In The 20th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, KDD â€™14,
New York, NY, USA - August 24 - 27, 2014, Sofus A. Macskassy, Claudia Perlich,
Jure Leskovec, Wei Wang, and Rayid Ghani (Eds.). ACM, 1613â€“1619. https:
//doi.org/10.1145/2623330.2623366
[2]Karl Johan Astrom and Richard M. Murray. 2008. Feedback Systems: An Introduc-
tion for Scientists and Engineers. Princeton University Press, USA.
[3]Vashist Avadhanula, Riccardo Colini-Baldeschi, Stefano Leonardi, Karthik Abinav
Sankararaman, and Okke Schrijvers. 2021. Stochastic bandits for multi-platform
budget optimization in online advertising. In WWW â€™21: The Web Conference
2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021, Jure Leskovec, Marko
Grobelnik, Marc Najork, Jie Tang, and Leila Zia (Eds.). ACM / IW3C2, 2805â€“2817.
https://doi.org/10.1145/3442381.3450074
[4]Ashwinkumar Badanidiyuru, Andrew Evdokimov, Vinodh Krishnan, Pan Li,
Wynn Vonnegut, and Jayden Wang. 2021. Handling many conversions per click
in modeling delayed feedback. CoRR abs/2101.02284 (2021). arXiv:2101.02284
https://arxiv.org/abs/2101.02284
[5]Stuart Bennett. 1993. A History of Control Engineering 1930-1955 (1st ed.). Peter
Peregrinus, GBR.
[6]Olivier Chapelle. 2014. Modeling delayed feedback in display advertising. In
KDD. 1097â€“1105.
[7]Ye Chen, Pavel Berkhin, Bo Anderson, and Nikhil R Devanur. 2011. Real-time
bidding algorithms for performance-based display ad allocation. In Proceedings
of the 17th ACM SIGKDD international conference on Knowledge discovery and
data mining. 1307â€“1315.
[8]George B Dantzig. 1957. Discrete-variable extremum problems. Operations
research 5, 2 (1957), 266â€“288.
[9]John Deighton and Leora Kornfeld. 2020. The Socioeconomic Impact of Internet
Tracking. Interactive Advertising Bureau (2020).
[10] Simeon Duckworth, Mateusz MyÅ›liwski, and Lars Nesheim. 2023. Taking the
biscuit: how Safari privacy policies affect online advertising. (2023).
[11] Rui Fan and Erick Delage. 2022. Risk-Aware Bid Optimization for Online
Display Advertisement. In Proceedings of the 31st ACM International Confer-
ence on Information & Knowledge Management, Atlanta, GA, USA, October 17-
21, 2022, Mohammad Al Hasan and Li Xiong (Eds.). ACM, 457â€“467. https:
//doi.org/10.1145/3511808.3557436
[12] Hui Gao and Yihan Yang. 2022. Multi-Head Online Learning for Delayed Feedback
Modeling. CoRR abs/2205.12406 (2022). https://doi.org/10.48550/arXiv.2205.12406
arXiv:2205.12406
[13] Avi Goldfarb and Catherine E Tucker. 2011. Privacy regulation and online
advertising. Management science 57, 1 (2011), 57â€“71.
[14] Liyi Guo, Junqi Jin, Haoqi Zhang, Zhenzhe Zheng, Zhiye Yang, Zhizhuang Xing,
Fei Pan, Lvyin Niu, Fan Wu, Haiyang Xu, Chuan Yu, Yuning Jiang, and Xiaoqiang
Zhu. 2021. We Know What You Want: An Advertising Strategy Recommender
System for Online Advertising. In KDD â€™21: The 27th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining, Virtual Event, Singapore, August 14-18,
2021, Feida Zhu, Beng Chin Ooi, and Chunyan Miao (Eds.). ACM, 2919â€“2927.
https://doi.org/10.1145/3447548.3467175
[15] Xiaotian Hao, Zhaoqing Peng, Yi Ma, Guan Wang, Junqi Jin, Jianye Hao, Shan
Chen, Rongquan Bai, Mingzhou Xie, Miao Xu, Zhenzhe Zheng, Chuan Yu, Han
Li, Jian Xu, and Kun Gai. 2020. Dynamic Knapsack Optimization Towards Ef-
ficient Multi-Channel Sequential Advertising. In Proceedings of the 37th Inter-
national Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual
Event (Proceedings of Machine Learning Research, Vol. 119). PMLR, 4060â€“4070.
http://proceedings.mlr.press/v119/hao20b.html
[16] Yue He, Xiujun Chen, Di Wu, Junwei Pan, Qing Tan, Chuan Yu, Jian Xu, and
Xiaoqiang Zhu. 2021. A Unified Solution to Constrained Bidding in Online
Display Advertising. In KDD â€™21: The 27th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining, Virtual Event, Singapore, August 14-18, 2021, Feida
Zhu, Beng Chin Ooi, and Chunyan Miao (Eds.). ACM, 2993â€“3001. https://doi.
org/10.1145/3447548.3467199
[17] ICO. 2019. Update report into adtech and real time bidding. (2019).
[18] Kinshuk Jerath. 2022. Mobile Advertising and the Impact of Appleâ€™s App Tracking
Transparency Policy.
[19] Olivier Jeunen, Sean Murphy, and Ben Allison. 2023. Off-Policy Learning-
to-Bid with AuctionGym. In Proceedings of the 29th ACM SIGKDD Confer-
ence on Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD
â€™23). Association for Computing Machinery, New York, NY, USA, 4219â€“4228.
https://doi.org/10.1145/3580305.3599877
[20] Reinhold Kesler. 2022. The Impact of Appleâ€™s App Tracking Transparency on
App Monetization. Available at SSRN 4090786 (2022).
[21] Konrad Kollnig, Anastasia Shuba, Max Van Kleek, Reuben Binns, and Nigel
Shadbolt. 2022. Goodbye tracking? Impact of iOS app tracking transparency
and privacy labels. In 2022 ACM Conference on Fairness, Accountability, andTransparency. 508â€“520.
[22] Kuang-Chih Lee, Ali Jalali, and Ali Dasdan. 2013. Real Time Bid Optimization
with Smooth Budget Delivery in Online Advertising. CoRR abs/1305.3011 (2013).
arXiv:1305.3011 http://arxiv.org/abs/1305.3011
[23] Xu Li, Michelle Ma Zhang, Zhenya Wang, and Youjun Tong. 2022. Arbitrary
Distribution Modeling with Censorship in Real-Time Bidding Advertising. In
KDD â€™22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data
Mining, Washington, DC, USA, August 14 - 18, 2022, Aidong Zhang and Huzefa
Rangwala (Eds.). ACM, 3250â€“3258. https://doi.org/10.1145/3534678.3539048
[24] Chi-Chun Lin, Kun-Ta Chuang, Wush Chi-Hsuan Wu, and Ming-Syan Chen.
2016. Combining Powers of Two Predictors in Optimizing Real-Time Bidding
Strategy under Constrained Budget. In Proceedings of the 25th ACM International
Conference on Information and Knowledge Management, CIKM 2016, Indianapolis,
IN, USA, October 24-28, 2016, Snehasis Mukhopadhyay, ChengXiang Zhai, Elisa
Bertino, Fabio Crestani, Javed Mostafa, Jie Tang, Luo Si, Xiaofang Zhou, Yi Chang,
Yunyao Li, and Parikshit Sondhi (Eds.). ACM, 2143â€“2148. https://doi.org/10.1145/
2983323.2983656
[25] Pingzhong Tang, Xun Wang, Zihe Wang, Yadong Xu, and Xiwang Yang. 2020.
Optimized Cost per Mille in Feeds Advertising. In Proceedings of the 19th Interna-
tional Conference on Autonomous Agents and MultiAgent Systems. 1359â€“1367.
[26] Haozhe Wang, Chao Du, Panyan Fang, Li He, Liang Wang, and Bo Zheng.
2023. Adversarial Constrained Bidding via Minimax Regret Optimization with
Causality-Aware Reinforcement Learning. In Proceedings of the 29th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA,
USA, August 6-10, 2023, Ambuj K. Singh, Yizhou Sun, Leman Akoglu, Dimitrios
Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, and Jieping Ye (Eds.). ACM,
2314â€“2325. https://doi.org/10.1145/3580305.3599254
[27] Haozhe Wang, Chao Du, Panyan Fang, Shuo Yuan, Xuming He, Liang Wang,
and Bo Zheng. 2022. ROI-Constrained Bidding via Curriculum-Guided Bayesian
Reinforcement Learning. In KDD â€™22: The 28th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18,
2022, Aidong Zhang and Huzefa Rangwala (Eds.). ACM, 4021â€“4031. https:
//doi.org/10.1145/3534678.3539211
[28] Chao Wen, Miao Xu, Zhilin Zhang, Zhenzhe Zheng, Yuhui Wang, Xiangyu Liu, Yu
Rong, Dong Xie, Xiaoyang Tan, Chuan Yu, Jian Xu, Fan Wu, Guihai Chen, and Xi-
aoqiang Zhu. 2021. A Cooperative-Competitive Multi-Agent Framework for Auto-
bidding in Online Advertising. CoRR abs/2106.06224 (2021). arXiv:2106.06224
https://arxiv.org/abs/2106.06224
[29] Xun Yang, Yasong Li, Hao Wang, Di Wu, Qing Tan, Jian Xu, and Kun Gai. 2019.
Bid optimization by multivariable control in display advertising. In Proceedings
of the 25th ACM SIGKDD international conference on knowledge discovery & data
mining. 1966â€“1974.
[30] Yuya Yoshikawa and Yusaku Imai. 2018. A Nonparametric Delayed Feedback
Model for Conversion Rate Prediction. Proc of Jsai 2018 (2018).
[31] Haoqi Zhang, Lvyin Niu, Zhenzhe Zheng, Zhilin Zhang, Shan Gu, Fan Wu, Chuan
Yu, Jian Xu, Guihai Chen, and Bo Zheng. 2023. A Personalized Automated Bidding
Framework for Fairness-aware Online Advertising. In Proceedings of the 29th
ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023,
Long Beach, CA, USA, August 6-10, 2023, Ambuj K. Singh, Yizhou Sun, Leman
Akoglu, Dimitrios Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, and Jieping
Ye (Eds.). ACM, 5544â€“5553. https://doi.org/10.1145/3580305.3599765
[32] Weinan Zhang, Kan Ren, and Jun Wang. 2016. Optimal Real-Time Bidding
Frameworks Discussion. CoRR abs/1602.01007 (2016). arXiv:1602.01007 http:
//arxiv.org/abs/1602.01007
[33] Weinan Zhang, Yifei Rong, Jun Wang, Tianchi Zhu, and Xiaofan Wang. 2016.
Feedback Control of Real-Time Display Advertising. In Proceedings of the Ninth
ACM International Conference on Web Search and Data Mining, San Francisco, CA,
USA, February 22-25, 2016, Paul N. Bennett, Vanja Josifovski, Jennifer Neville, and
Filip Radlinski (Eds.). ACM, 407â€“416. https://doi.org/10.1145/2835776.2835843
[34] Weinan Zhang, Shuai Yuan, and Jun Wang. 2014. Optimal real-time bidding
for display advertising. In The 20th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, KDD â€™14, New York, NY, USA - August 24
- 27, 2014, Sofus A. Macskassy, Claudia Perlich, Jure Leskovec, Wei Wang, and
Rayid Ghani (Eds.). ACM, 1077â€“1086. https://doi.org/10.1145/2623330.2623633
[35] Jun Zhao, Guang Qiu, Ziyu Guan, Wei Zhao, and Xiaofei He. 2018. Deep rein-
forcement learning for sponsored search real-time bidding. In Proceedings of the
24th ACM SIGKDD international conference on knowledge discovery & data mining .
1021â€“1030.
[36] Kui Zhao, Junhao Hua, Ling Yan, Qi Zhang, Huan Xu, and Cheng Yang. 2019. A
unified framework for marketing budget allocation. In Proceedings of the 25th
ACM SIGKDD International Conference on Knowledge Discovery & Data Mining.
1820â€“1830.
[37] Han Zhu, Junqi Jin, Chang Tan, Fei Pan, Yifan Zeng, Han Li, and Kun Gai. 2017.
Optimized Cost per Click in Taobao Display Advertising. In Proceedings of the
23rd ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, Halifax, NS, Canada, August 13 - 17, 2017. ACM, 2191â€“2200. https:
//doi.org/10.1145/3097983.3098134
5740