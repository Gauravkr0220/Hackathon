Cross-Domain LifeLong Sequential Modeling for Online
Click-Through Rate Prediction
Ruijie Hou
Wechat, Tencent
Beijing, China
jerriehou@tencent.comZhaoyang Yangâˆ—
Wechat, Tencent
Guangzhou, China
terrellyang@tencent.comYu Ming
Wechat, Tencent
Guangzhou, China
julyeyang@tencent.com
Hongyu Lu
Wechat, Tencent
Guangzhou, China
dreamlu@tencent.comZhuobin Zheng
Wechat, Tencent
Guangzhou, China
jackzbzheng@tencent.comYu Chen
Wechat, Tencent
Guangzhou, China
nealcui@tencent.com
Qinsong Zeng
Wechat, Tencent
Guangzhou, China
qinzzeng@tencent.comMing Chen
Wechat, Tencent
Guangzhou, China
mingchen@tencent.com
Abstract
Lifelong sequential modeling (LSM) has significantly advanced rec-
ommendation systems on social media platforms. Diverging from
single-domain LSM, cross-domain LSM involves modeling lifelong
behavior sequences from a source domain to a different target do-
main. In this paper, we propose the Lifelong Cross Network (LCN),
a novel approach for cross-domain LSM. LCN features a Cross Rep-
resentation Production (CRP) module that utilizes contrastive loss
to improve the learning of item embeddings, effectively bridging
items across domains. This is important for enhancing the retrieval
of relevant items in cross-domain lifelong sequences. Furthermore,
we propose the Lifelong Attention Pyramid (LAP) module, which
contains three cascading attention levels. By adding an intermedi-
ate level and integrating the results from all three levels, the LAP
module can capture a broad spectrum of user interests and ensure
gradient propagation throughout the sequence. The proposed LAP
can also achieve remarkable consistency across attention levels,
making it possible to further narrow the candidate item pool of the
top level. This allows for the use of advanced attention techniques
to effectively mitigate the impact of the noise in cross-domain se-
quences and improve the non-linearity of the representation, all
while maintaining computational efficiency. Extensive experiments
conducted on both a public dataset and an industrial dataset from
the WeChat Channels platform reveal that the LCN outperforms
current methods in terms of prediction accuracy and online perfor-
mance metrics.
âˆ—corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671601CCS Concepts
â€¢Information systems â†’Learning to rank; Recommender
systems; â€¢Computing methodologies â†’Neural networks.
Keywords
Click-Through Rate Prediction; Lifelong Sequential Modeling; Rec-
ommendation System
ACM Reference Format:
Ruijie Hou, Zhaoyang Yang, Yu Ming, Hongyu Lu, Zhuobin Zheng, Yu Chen,
Qinsong Zeng, and Ming Chen. 2024. Cross-Domain LifeLong Sequential
Modeling for Online Click-Through Rate Prediction. In Proceedings of the
30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
10 pages. https://doi.org/10.1145/3637528.3671601
1 Introduction
Click-through rate (CTR) prediction stands as a fundamental task
in many real-world applications. The precision of CTR prediction
heavily relies on comprehending the usersâ€™ intentions towards the
potential candidates. In recent years, deep neural networks (DNNs)
have made significant strides in improving the accuracy of CTR
prediction. They accomplish this by extracting representations of
user interests from behavior sequences, specifically in relation to
the candidate items [12, 36, 39, 41, 42].
Nowadays, social media platforms such as TikTok, YouTube, and
WeChat Channels, presents billions of items to users every day.
The complexity of user interactions on these platforms has signifi-
cantly increased, posing new challenges in modeling user behavior
sequences. On one hand, the volume of data has expanded exponen-
tially, with some sequences extending to a length of lifelong. On
the other hand, users often engage with a variety of content types,
leading to behavior sequences that contains items from different
domains. This complexity becomes particularly pronounced when
focusing on CTR prediction for smaller-scale domains.
In order to overcome the lack of direct user data in the target
domain, it becomes imperative for models to extract user interests
5116
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruijie Hou et al.
Figure 1: (a) A showcase of video content and live content in
Wechat Channels platform. (b) A comparison between the
statistics of the length of behavior sequence of video content
and live content of users in Wechat Channels platform.
from behavior sequences in an auxiliary source domain. For in-
stance, as illustrated in 1, within WeChat Channels, the median
behavior sequence length for live content is a mere 500, which
is a fraction of the length for video content. Therefore, for live
content CTR prediction, it is imperative to employ cross-domain
lifelong sequential modeling (LSM) of video item interactions. This
approach ensures comprehensive prediction that captures the userâ€™s
integrated interests across the platform.
A common approach to managing lifelong sequences involves
segmenting the modeling into two units: the General Search Unit
(GSU) and the Exact Search Unit (ESU) [ 28]. The GSUâ€™s role is to
sift through the sequence to identify items that are most relevant
to the candidate items. Subsequently, the ESU is responsible for
extracting user interest representations from the items identified
by the GSU. This framework has been the foundation for numerous
studies, leading to notable advancements in the field [4, 5, 8].
Despite their successes, applying these methods to cross-domain
LSM faces two primary challenges. Firstly, the effectiveness of GSU
relies on expressive item embeddings to measure similarity be-
tween usersâ€™ sequence items and candidate items. However, only
optimizing these embeddings based on supervision signals from
the target domain severely restricts their generalizability across
domains and makes it difficult to capture cross-domain relations ac-
curately. Aligning the representation space between candidate items
in target domain and the sequence items in source domain becomes
challenging. Secondly, most ESU methods use simpler attention
techniques to minimize computational demands and maintain con-
sistency with the GSU. However, cross-domain sequence contains
more noise, which highly increases the difficulty and complexity of
modeling. Therefore, more advanced attention techniques are nec-
essary to effectively filter out irrelevant data within the sequence
and enhance the final user interest representations in cross-domain
LSM.
To address these challenges, we propose a novel Lifelong Cross
Network (LCN) for cross-domain LSM. The LCN features a Cross
Representation Production (CRP) module to improve the modelâ€™s
capabilities for item similarities across domains. Our experience
suggests that usersâ€™ short-term behaviors from different domains
indicate similar intrinsic interests, which guides us in designingauxiliary supervision tasks. Inspired by contrastive learning, the
CRP selects positive and negative item pairs from user behavior
sequences within and across domains. This approach provides ad-
ditional supervision on the item embeddings, which enhances the
learning of relationships between items across domains. Addition-
ally, we integrate a Lifelong Attention Pyramid (LAP) module to
enhance the extraction of user interest representations from lifelong
sequences. The LAP module consists of three levels of cascading
attentions, with each level processing top-ranked items from the
previous level. The final output of LAP combines the results from all
three levels, providing a comprehensive representation of user in-
terests. This structure ensures full gradient propagation throughout
the sequence, improving consistency across levels. This consistency
further narrows the item pool of the top attention level, enabling the
incorporation of advanced attention techniques to filter out noise
in cross-domain lifelong sequences and enhance the non-linearity
of representations while maintaining computational efficiency.
We conducted comprehensive experiments using both a public
dataset and an industrial dataset collected from user interactions on
the WeChat Channels platform. The results demonstrate that the
proposed LCN outperforms existing methods in terms of prediction
accuracy. The integration of CRP and LAP modules within the LCN
has shown applicability to different LSM backbones and scenarios.
Notably, the LCN has also achieved significant improvements in the
A/B testing phase for online live content recommendations, with a
relative increase of +2.93% in CTR and +3.27% in stay time. These
results highlight the effectiveness and robustness of the proposed
LCN in enhancing CTR prediction in cross-domain LSM.
2 RELATED WORK
The modeling of user behavior sequences plays a central role in
understanding user intentions, and extensive research has been ded-
icated to this field. It has been observed that models tend to achieve
better performance when longer sequence lengths are incorporated
[27]. With the exponential growth of data, the concept of lifelong
sequential modeling (LSM) has emerged, aiming to extract user in-
terests with respect to the candidate items over extensive sequence
lengths. One notable approach addressing LSM is SIM [ 28], which
divides the process into a General Search Unit (GSU) and an Exact
Search Unit (ESU), thereby managing lifelong sequences with re-
duced computational demands. Subsequent research has built upon
this framework, leading to notable advancements [ 4,5,8,29]. How-
ever, these methods have not fully addressed the unique challenges
associated with cross-domain LSM, and may experience perfor-
mance declines due to insufficient transfer from the source to the
target domain.
There are a diverse array of studies contributing to the field
of cross-domain recommendation (CDR). A significant body of re-
search advocates for the training of independent models within
a source domain [ 16,19,24]. Additionally, the variational auto-
encoder (VAE) framework has been employed in several work to
learn domain-invariant embeddings [ 3,21,30]. Another approach
involves the integration of Meta Networks [ 43,44]. Sequential mod-
eling has also seen the incorporation of CDR techniques. Notably,
PSJNet [ 32] andğœ‹-Net [ 23] have adopted gating mechanisms to
achieve this integration. In parallel, DA-GCN [ 7] and C2DSR [ 2]
5117Cross-Domain LifeLong Sequential Modeling for Online Click-Through Rate Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
have leveraged Graph Neural Networks (GNNs), and RecGURU
[18] has utilized Transformer architectures. However, most of these
studies focus on short sequence modeling, which limit their appli-
cability to LSM due to the inherent differences in sequence length.
Contrastive learning has seen significant advancements in the
fields of computer vision and natural language processing [ 9â€“11,
13,26]. It has also been adapted to enhance the Click-Through
Rate (CTR) prediction tasks [ 2,20,22,31,35,37,38,40]. In the
context of sequential modeling, MISS [ 15] utilizes contrastive learn-
ing to refine interest representation, while AQCL [ 25] introduces
an auxiliary loss to learn item relationships from sparse training
samples. CL4CTR [ 35] aims to enhance item representation quality
through contrastive learning, yet it requires the management of a
large embedding table and triplets during training, which may be
impractical in real-world applications. In this paper, we harness the
principles of contrastive learning to impose additional supervision,
enabling the model to learn item embeddings that can facilitate the
bridging of items across different domains.
3 PRELIMINARIES
Cross-domain LSM involves modeling sequences of user behaviors
from one domain (the source) and applying results gained to a
different domain (the target). The objective of cross-domain LSM is
to extract a representation of user interests based on their lifelong
sequences in the source domain, which can then be used to enhance
the accuracy of click-through rate (CTR) predictions in the target
domain. A key aspect of this scenario is that the same user base is
active in both domains, yet there is no item overlap between them.
Specifically, to formalize the modeling, we consider three distinct
categories of features for each user:
â€¢Basic profile features, denoted as {ğ›½}.
â€¢Short-term behavior sequences in the target domain and the
source domain, represented by Â®ğ»ğ‘‡ğ‘¡={â„ğ‘¡1,â„ğ‘¡2,Â·Â·Â·,â„ğ‘¡ğ‘}
andÂ®ğ»ğ‘†ğ‘¡={â„ğ‘ 1,â„ğ‘ 2,Â·Â·Â·,â„ğ‘ ğ‘}respectively.
â€¢The lifelong behavior sequence in the source domain, repre-
sented byÂ®ğ¿ğ»ğ‘†ğ‘¡={ğ‘™â„ğ‘ 1,ğ‘™â„ğ‘  2,Â·Â·Â·,ğ‘™â„ğ‘ ğ‘€}.
For a given user-item pair < ğ‘¢ğ‘–,ğ‘£ğ‘–>, whereğ‘£ğ‘–is an item from the
target domain, the model aims to predict the click-through rate
(CTR) for user ğ‘¢ğ‘–with respect to item ğ‘£ğ‘–as follows:
ğ‘ğ‘–=ğ‘ƒ(ğ‘¦ğ‘–=1|ğ‘¢ğ‘–,ğ‘£ğ‘–,ğ›½,Â®ğ»ğ‘‡ğ‘¡,Â®ğ»ğ‘†ğ‘¡,Â®ğ¿ğ»ğ‘†ğ‘¡;ğœƒ), (1)
whereğœƒrepresents the parameters of the model.
The main network is optimized using a cross-entropy loss func-
tion, which is defined as follows:
Lğ¶ğ‘‡ğ‘…=âˆ’1
ğµğµâˆ‘ï¸
ğ‘–=1
ğ‘¦ğ‘–âˆ—ğ‘™ğ‘œğ‘”(ğ‘ğ‘–)+(1âˆ’ğ‘¦ğ‘–)âˆ—ğ‘™ğ‘œğ‘”(1âˆ’ğ‘ğ‘–)
,(2)
whereğ‘¦ğ‘–âˆˆ{0,1}represents the actual user feedback, and ğµdenotes
the total number of user-item sample pairs in a training batch.
4 METHODOLOGY
In this paper, we propose a novel approach, the Lifelong Cross
Network (LCN) for cross-domain LSM. The LCN is comprised of
two major components: the Cross Representation Production (CRP)
module and the Lifelong Attention Pyramid (LAP) module.The CRP module is a jointly trained sub-network with the ob-
jective of learning item embeddings that can bridge items across
domains. These embeddings are then utilized within the main net-
work to enhance its ability to identify the most relevant items with
respect to a given candidate item from a lifelong sequence in the
source domain. The LAP module is structured with three levels of
cascading attentions, each processing the top ranked items of the
previous level. The progressive nature of the LAP module ensures
a more context-aware extraction of interest representations that
are directly relevant to the target item.
We show an overview of the proposed LCN in Figure 2.
4.1 Cross Representation Production
A lifelong behavior sequence records a userâ€™s interactions over
an extended period. When considering a particular item, only a
fraction of this sequence may hold predictive value for the userâ€™s
click-through rate (CTR) on that item. This is particularly true for
cross-domain lifelong sequences, where the items originate from a
different domain than the target item. It is crucial for the model to
identify the most relevant items within the sequence to optimize
model capacity and computational efficiency.
Typically, Lifelong Sequence Modeling (LSM) is segmented into
two units: a General Search Unit (GSU) and an Exact Search Unit
(ESU). The role of GSU is to sift through the lifelong sequence and
identify the items most relevant to the candidate item. Its effec-
tiveness highly depends on the quality of the item embeddings
utilized. Previous approaches re-use item embeddings learned dur-
ing training of the model, which are proved to perform well within
the training dataâ€™s distribution. However, when the candidate item
and the sequence items belong to different domains, the embed-
dings must be developed to bridge the gap between source and
target domains. Achieving this is non-trivial, given that the model
is primarily trained on the target domain data.
To overcome this challenge, we propose a Cross Representation
Production (CRP) module that jointly refines cross-domain item
embeddings along with the main network. Drawing inspiration
from contrastive learning, the CRP module pairs positive and nega-
tive examples from userâ€™s short-term behavior sequences Â®ğ»ğ‘‡ğ‘¡and
Â®ğ»ğ‘†ğ‘¡. It then imposes extra supervision on the item embeddings to
enhance learning of relationships between items across domains.
4.1.1 Positive and Negative Sampling. The construction of sam-
ple pairs is fundamental to contrastive learning. Within our CRP
module, we achieve this by selecting items from userâ€™s short-term
behavior sequences. This selection process is grounded in the un-
derstanding that a userâ€™s interests tend to remain stable across
different domains, especially within a short-term period of time.
Consequently, items within a userâ€™s short-term behavior sequence
are likely to exhibit similar characteristics, regardless of their do-
main of origin. This consistency enables us to uniformly sample
both positive and negative pairs across domains.
As depicted in Figure ??, we have designed three distinct types
of positive pairs for each user. To begin with, we select two items,
â„ğ‘¡ğ‘ğ‘¡1andâ„ğ‘¡ğ‘ğ‘¡2, from the target domainâ€™s short-term sequence Â®ğ»ğ‘‡ğ‘¡,
forming a positive pair within the target domain. Similarly, we
5118KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruijie Hou et al.
Figure 2: An overview of the proposed Lifelong Cross Network (LCN). There are two major components in the model: (i)
The Cross Representation Production (CRP) module is a jointly trained sub-network to learn item embeddings capable of
identifying similar items across domains. (ii) The Lifelong Attention Pyramid (LAP) module is composed of three levels of
cascading attentions. These attentions are designed to progressively extract interest representations with respect to candidate
items from the cross-domain lifelong sequence.
Figure 3: An illustration of the Cross Representation Produc-
tion (CRP) module. It samples three distinct types of positive
pairs and negative pairs. We introduce a contrastive loss to
reduce the cosine distance between items in positive pairs
while expand those of negative pairs.
choose two items, â„ğ‘ ğ‘ğ‘ 1andâ„ğ‘ ğ‘ğ‘ 2, from the source domainâ€™s short-
term sequenceÂ®ğ»ğ‘†ğ‘¡, creating a source domain positive pair. These
pairs are intended to encourage the model to bring item embeddings
of similar items closer within their respective domains. To learn
alignment between similar items across domains, we construct a
cross-domain positive pair by selecting one item each from Â®ğ»ğ‘‡ğ‘¡
andÂ®ğ»ğ‘†ğ‘¡, denoted as â„ğ‘¡ğ‘ğ‘1andâ„ğ‘ ğ‘ğ‘2.
Regarding negative sample pairs, we employ a parallel approach
to the positive sampling, but with items from different usersâ€™ behav-
ior sequences within the same training batch. This results in three
types of negative sample pairs: < â„ğ‘¡ğ‘›ğ‘¡1,â„ğ‘¡ğ‘›ğ‘¡2>, <â„ğ‘ ğ‘›ğ‘ 1,â„ğ‘ ğ‘›ğ‘ 2> and
<â„ğ‘¡ğ‘›ğ‘1,â„ğ‘ ğ‘›ğ‘2>. For each type, we sample ğ‘€pairs per training batch,
which are then used as the negative counterparts for all positive
pairs within that batch.
4.1.2 Loss Function. The CRP module employs a contrastive loss
function designed to enforce the model to minimize the cosine
distance between item embeddings for positive pairs within a given
batch. Each type of positive pairs is associated with a corresponding
loss function as follows:Lğ‘ƒğ‘‡=âˆ’1
|ğµ|ğµâˆ‘ï¸
ğ‘–logexp(ğ‘ (htğ‘ğ‘¡1
ğ‘–,htğ‘ğ‘¡2
ğ‘–)/ğœ)
Ãğ‘€
ğ‘—exp(ğ‘ (htğ‘›ğ‘¡1
ğ‘—,htğ‘›ğ‘¡2
ğ‘—)/ğœ)(3)
Lğ‘ƒğ‘†=âˆ’1
|ğµ|ğµâˆ‘ï¸
ğ‘–logexp(ğ‘ (hsğ‘ğ‘ 1
ğ‘–,hsğ‘ğ‘ 2
ğ‘–)/ğœ)
Ãğ‘€
ğ‘—exp(ğ‘ (hsğ‘›ğ‘ 1
ğ‘—,hsğ‘›ğ‘ 2
ğ‘—)/ğœ)(4)
Lğ‘ƒğ¶=âˆ’1
|ğµ|ğµâˆ‘ï¸
ğ‘–logexp(ğ‘ (htğ‘ğ‘1
ğ‘–,hsğ‘ğ‘2
ğ‘–)/ğœ)
Ãğ‘€
ğ‘—exp(ğ‘ (htğ‘›ğ‘1
ğ‘—,hsğ‘›ğ‘2
ğ‘—)/ğœ)(5)
whereğµrepresents the size of training batch, and ğ‘ (ğ‘¥,ğ‘¦)denotes
the cosine similarity between ğ‘¥andğ‘¦.
The final loss of the CRP module, denoted as Lğ¶ğ‘…ğ‘ƒ, is a integra-
tion of Equation 3, 4 and 5:
Lğ¶ğ‘…ğ‘ƒ=ğœ†ğ‘ƒğ‘‡Lğ‘ƒğ‘‡+ğœ†ğ‘ƒğ‘†Lğ‘ƒğ‘†+ğœ†ğ‘ƒğ¶Lğ‘ƒğ¶ (6)
whereğœ†ğ‘ƒğ‘‡,ğœ†ğ‘ƒğ‘†andğœ†ğ‘ƒğ¶represent the loss weights.
In the experimental section, we will demonstrate that integrating
the CRP module substantially enhances the representational quality
of the item embeddings. This improvement, in turn, boosts the final
prediction accuracy across a broad spectrum of LSM frameworks.
4.2 Lifelong Attention Pyramid
Classic LSM framework segments interest extraction into two units:
the General Searching Unit (GSU) and the Exact Searching Unit
(ESU), with the latter generally employing more complex attention
techniques than the former. Although the GSU stage significantly
narrows down the item pool for the ESU stage, the attention utilized
in ESU are often less sophisticated than state-of-the-art (SOTA)
attention techniques to maintain computational efficiency.
In the context of cross-domain LSM, items from the source do-
main in the behavior sequence and the candidate items from the
target domain do not overlap, and the contextual and behavioral
5119Cross-Domain LifeLong Sequential Modeling for Online Click-Through Rate Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
patterns can vary greatly between domains. Consequently, cross-
domain lifelong sequences may introduce more noise, calling for
better consistency across different searching stages and the use of
more advanced attention techniques to interpret the sequences.
To address these challenges, we propose the Lifelong Attention
Pyramid (LAP) module. This module extends the traditional two-
stage framework into a three-level attention pyramid, featuring
cascading levels of attention that aim to refine and streamline the
search process within the lifelong sequence. By achieving better
consistency across levels, the LAP reduces the number of items
progressing to the top level. This reduction allows for the appli-
cation of more advanced attention techniques at the top level to
filter noise and enhance the non-linearity of the representation.
We detail each of the levels, named the Complete-Scope Attention
(CSA), the Median-Scope Attention (MSA), and the Focused-Scope
Attention (FSA), in the following sections.
4.2.1 The Complete-Scope Attention (CSA). As the first level of at-
tention, the Complete-Scope Attention (CSA) mirrors the function
of the GSU from previous frameworks. Within the CSA, a broad
yet general search is executed across the entire lifelong sequence.
The objective is to ensure that every item within the sequence
is accounted for, thereby excluding the least relevant items from
subsequent levels. Meanwhile, the CSA can provide a preliminary
interest representation by implementing a weighted average pool-
ing based on the attention scores derived during the searching.
Given the considerable length of the input at this level and
the less exact precision requirements, we employ a simple inner
product calculation as the attention for the CSA. Formally, for a
given candidate item ğ‘£ğ‘–and the lifelong behavior sequence Â®ğ¿ğ»ğ‘†ğ‘¡=
{ğ‘™â„ğ‘ 1,ğ‘™â„ğ‘  2,Â·Â·Â·,ğ‘™â„ğ‘ ğ‘}, the attention score ğ‘Ÿğ‘ğ‘ ğ‘
ğ‘˜for each item ğ‘™â„ğ‘ ğ‘˜
within the sequence is computed as follows:
ğ‘Ÿğ‘˜=ğ‘’â„
ğ‘˜âŠ™ğ‘’ğ‘£
ğ‘– (7)
whereğ‘’â„
ğ‘˜represents the embedding of the item ğ‘™â„ğ‘ ğ‘˜in the sequence,
andğ‘’ğ‘£
ğ‘–is the embedding of the candidate item.
A straightforward weighted summation based on the score ğ‘Ÿğ‘ğ‘ ğ‘
ğ‘˜
is utilized to generate the interest representation output ğ¼ğ‘…ğ¶ğ‘†ğ´ of
this level:
ğ¼ğ‘…ğ¶ğ‘†ğ´=ğ‘âˆ‘ï¸
ğ‘˜=1ğ‘Ÿğ‘ğ‘ ğ‘
ğ‘˜âˆ—ğ‘’â„
ğ‘˜(8)
The top-ğ¾1items, as ranked by ğ‘Ÿğ‘ğ‘ ğ‘
ğ‘˜, are then selected to con-
struct a reduced sub-sequence Â®ğ¿ğ»ğ‘†ğ‘1, which is subsequently fed
into the second level of attention.
4.2.2 The Median-Scope Attention (MSA). In contrast to previ-
ous two-stage methods, our approach introduces an intermediate
Median-Scope Attention (MSA) level to effectively bridge the first
and third levels. This addition is inspired by the observation that
a significant majority of attention scores, often more than 90%,
tend to concentrate on a mere 20% of the items in a sequence. By
incorporating the MSA, we distribute some of the CSAâ€™s function
of omitting less relevant items to this intermediate level, enhancing
the overall consistency of the LAP module and further narrowing
the item pool for the final attention level.In the MSA, we incorporate additional contextual information
about the items to perform a secondary attention search. It is impor-
tant to note that the contextual details used here, such as interaction
specifics like viewing duration, are consistent with the information
that will be utilized in the final level. This consistency is crucial, as
these contextual elements have been shown to significantly benefit
sequential modeling [5].
Formally, letÂ®ğ¿ğ¶ğ‘†ğ‘1={ğ‘™ğ‘ğ‘ 1,ğ‘™ğ‘ğ‘ 2,...,ğ‘™ğ‘ğ‘ ğ¾1}represents the contex-
tual information of the items provided by the CSA. The attention
scoreğ‘Ÿğ‘šğ‘ ğ‘
ğ‘˜at this level is calculated using the following formulas:
ğ‘Ÿğ‘šğ‘ ğ‘
ğ‘˜=ğ‘„ğ¾âŠ¤
âˆš
ğ‘‘, ğ‘¤â„ğ‘’ğ‘Ÿğ‘’ğ‘„ =ğ‘Šğ‘„ğ‘’ğ‘£
ğ‘–, ğ¾=ğ‘Šğ¾(ğ‘’â„
ğ‘˜||ğ‘’ğ‘
ğ‘˜), (9)
whereğ‘Šğ‘„andğ‘Šğ¾denote the attention weights, ğ‘‘represents the
inner dimension, ğ‘’ğ‘
ğ‘˜is the embedding of the contextual information
ğ‘™ğ‘ğ‘ ğ‘˜for itemğ‘™â„ğ‘ ğ‘˜, and||signifies the concatenation operation.
The interest representation within the MSA, denoted as ğ¼ğ‘…ğ‘€ğ‘†ğ´,
is then derived through a weighted average pooling, expressed as:
ğ¼ğ‘…ğ‘€ğ‘†ğ´ =ğ¾1âˆ‘ï¸
ğ‘˜=1ğ‘Ÿğ‘šğ‘ ğ‘
ğ‘˜âˆ—(ğ‘Šğ‘‰(ğ‘’â„
ğ‘˜||ğ‘’ğ‘
ğ‘˜)) (10)
whereğ‘Šğ‘‰is the projection matrix.
Following the first level, we form a sub-sequence Â®ğ¿ğ»ğ‘†ğ‘2by se-
lecting the top- ğ¾2items according to their ğ‘Ÿğ‘šğ‘ ğ‘
ğ‘˜rankings. These
selected items will then serve as the input for the final level.
4.2.3 The Focused-Scope Attention (FSA). The objective of the final
attention level mirrors that of the ESU, aiming to deliver a detailed
and targeted interest representation with respect to the candidate
item, based on the most relevant items filtered through the previous
attention levels. The Focused-Scope Attention (FSA) benefits from a
smaller set of items, enabling the use of a more advanced attention
technique to increase the non-linearity of the representation.
We employ an attention similar to the decoder of the multi-head
transformer [ 34] to extract interests from various perspectives.
Formally, for a candidate item ğ‘£ğ‘–and the sub-sequence Â®ğ¿ğ»ğ‘†ğ‘2, the
output of the â„-th head in the multi-head attention is computed as:
ğ»â„=ğ‘†ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘„â„ğ¾âŠ¤
â„âˆš
ğ‘‘)ğ‘‰â„, ğ‘¤â„ğ‘’ğ‘Ÿğ‘’
ğ‘„â„=ğ‘Šğ‘„
â„ğ‘’ğ‘£
ğ‘–, ğ¾â„=ğ‘Šğ¾
â„(ğ‘’â„
ğ‘˜||ğ‘’ğ‘
ğ‘˜), ğ‘‰â„=ğ‘Šğ‘‰
â„(ğ‘’â„
ğ‘˜||ğ‘’ğ‘
ğ‘˜)(11)
This attention process differs from the one used in MSA only in
the multi-head aspect to maintain consistency. Building upon this,
we integrate results of different head and use an additional feed-
forward layer to further enhance the non-linearity of the model:
ğ»=ğ‘…ğ‘’ğ¿ğ‘ˆ(ğ‘ğ‘œğ‘›ğ‘ğ‘ğ‘¡(ğ»1,...,ğ»ğ‘™)ğ‘¤1+ğ‘1)ğ‘¤2+ğ‘2 (12)
whereğ‘™is the number of attention heads, ğ‘¤1,ğ‘¤2,ğ‘1andğ‘2are the
weights and biases of the feed-forward layer, respectively. The final
interest representation, denoted as ğ¼ğ‘…ğ¹ğ‘†ğ´, is then obtained by:
ğ¼ğ‘…ğ¹ğ‘†ğ´=1
ğ¾2ğ¾2âˆ‘ï¸
ğ‘˜=1(ğ»ğ‘˜) (13)
At the end of the LAP module, we integrate the three interest rep-
resentations, ğ¼ğ‘…ğ¶ğ‘†ğ´,ğ¼ğ‘…ğ‘€ğ‘†ğ´ andğ¼ğ‘…ğ¹ğ‘†ğ´, from each attention level
to generate a representation that encapsulates a broad spectrum of
5120KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruijie Hou et al.
user interests as reflected in the lifelong sequence. This integration
also ensures full gradient propagation throughout the sequence,
potentially enhancing the consistency between the different atten-
tion levels. The implications and benefits of this approach will be
further explored and discussed in the experimental section.
The entire LCN, including the CRP module, is designed for end-
to-end training. The final loss function for LCN is a combination of
the CTR loss in Equation 2 and the CRP loss in Equation 6:
L=Lğ¶ğ‘‡ğ‘…+ğœ†ğ¶ğ‘…ğ‘ƒLğ¶ğ‘…ğ‘ƒ (14)
whereğœ†ğ¶ğ‘…ğ‘ƒ denotes the factor to control the importance of ğ¿ğ¶ğ‘…ğ‘ƒ.
5 EXPERIMENTS
To assess the performance of the proposed LCN, we carried out
extensive experiments and compared it against previous methods
using both a public dataset and an industrial dataset. Additionally,
we implemented online A/B testing to further validate the effec-
tiveness of LCN. The details of our experimental setup, along with
the results and discussions, are introduced in this section.
5.1 Experimental Settings
5.1.1 Datasets. Our experiments was conducted using two datasets:
one public dataset and one an industrial dataset.
Public Dataset. We utilizes the Taobao Dataset1, which consists
of traffic logs from Taobaoâ€™s recommendation system. This dataset
encompasses more than 2 million records from over 1 million users,
collected over a period of 7 days. We have split the items in the
the dataset into two distinct domains based on the â€œCategory IDâ€
associated with each item. Items with a â€œCategory IDâ€ below 2000
are allocated to the target domain, while those with a â€œCategory IDâ€
of 2000 or higher are allocated to the source domain. We consider
the latest 24 user actions in both the source and target domains to
construct short-term sequences. For lifelong sequences, we use the
most recent 500 user actions from the source domain. The dataset
is partitioned temporally, with the initial 6 daysâ€™ data reserved for
training and the data from the 7th day used as the test set.
Industrial Dataset. This dataset was collected from traffic logs
of the Wechat Channels platform, containing user behavior se-
quences related to both video and live content. For each user, we
collected his short-term behavior sequences for video and live items,
as well as lifelong behavior sequence up to a maximum length of
2,000 for video items. The video item sequences were designated
as the sequences in the source domain. The label of each sample
is the userâ€™s click action with live items. The dataset comprises a
collection of 2 billion records from 0.4 billion users, gathered over
a period of 7 days. We partitioned the dataset temporally, with the
data from the initial 6 days used for training and the data from the
7th day served as the test set.
5.1.2 Competitors. To evaluate the proposed LCN, we selected
an array of state-of-the-art (SOTA) methods in the field of LSM for
comparison. Our initial baseline was established using SIM Soft
[28]. Below is an overview of the competing methods:
â€¢SIM Soft [28]: An early work that proposes to segment LSM
into GSU and ESU stages.
1https://tianchi.aliyun.com/dataset/56Table 1: Results of the ablation study of the CRP module.
Components ofLğ¶ğ‘…ğ‘ƒ Metrics
Lğ‘ƒğ‘‡&Lğ‘ƒğ‘†Lğ‘ƒğ¶ AUC GAUC Logloss
Ã— Ã— 0.7237 0.6379 0.2330
âœ“Ã— 0.7250 0.6391 0.2290
âœ“ âœ“ 0.7294 0.6423 0.2223
â€¢ETA [8]: An approach for end-to-end lifelong sequential
modeling that incorporates SimHash [6] for efficient GSU.
â€¢SDIM [4]: Introduces a novel Hash Attention technique to
integrate GSU with ESU.
â€¢TWIN [5]: An approach that employs dimension compres-
sion of cross features to enhance the consistency between
GSU and ESU.
For training these models, we adhered to the parameter configu-
rations recommended in their respective original publications or
their open-source implementations.
5.1.3 Metrics. For offline evaluation, we employed the following
three key metrics: Area Under the Curve (AUC), Grouped Area
Under the Curve (GAUC) and the value of the Logarithmic Loss
(logloss) for the CTR prediction tasks.
For online A/B testing, the evaluation was standardized by using
the CTR and stay time of users on the items presented. We also
monitored the inference latency as a secondary metric.
5.1.4 Parameter Settings. The core architecture of our network
consists of a straightforward two-layer feed-forward neural net-
work. For the public dataset, the dimensions of the layers are con-
figured to 256 and 128, while for the industrial dataset, we scale
up to 512 and 256 to accommodate its larger size. The user profile
features{ğµ}comprises profile information such as age, gender,
and income level. We standardized the maximum length of the
short-term behavior sequence to 50 for both datasets. All features,
including item and user ids, are assigned distinct embedding spaces.
A uniform embedding size of 64 is applied across all feature types.
Model parameters are initialized using the Xavier Initialization
method [ 14], and the model is optimized with the Adam optimizer
[17] at a learning rate of 0.001. We set the batch size to 2048. Our
models are developed using TensorFlow [ 1]. We trained the model
using single A100 GPU for the public dataset, while 8 A100 GPUs
are used a distributed manner for the industrial dataset.
5.2 Module Analyses
We detail experiments designed to assess the efficiency of the two
major components of LCN. These experiments are carried out on
the industrial dataset, which is more appropriate for our topic given
its substantial data volume and extended sequence length.
5.2.1 Analyses of CRP. For the CRP module, we performed an
ablation study alongside an embedding analysis to quantitatively
and qualitatively assess its impact. Furthermore, we demonstrate
the effectiveness of the CRP module when being incorporated with
previous LSM frameworks.
Ablation Study. The outcomes of the experiments are presented
in Table 1. In the experiment where the contrastive loss for the
cross-domain sample pairs Lğ‘ƒğ¶was omitted, the process of sam-
pling cross-domain positive and negative pairs was also excluded.
5121Cross-Domain LifeLong Sequential Modeling for Online Click-Through Rate Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Figure 4: Visualization of the item embeddings from
ğ¿ğ¶ğ‘ ğ‘¤/ğ‘œğ¶ğ‘…ğ‘ƒ andğ¿ğ¶ğ‘.
Additionally, in the case where no loss components were applied,
the CRP module was entirely removed.
The results reveal that even without Lğ‘ƒğ¶, the CRP module con-
tributes to a considerable enhancement over the initial baseline.
This improvement suggests that the supervision provided by the
contrastive loss aids the model in more effectively capturing the re-
lationships between items within the embeddings, thereby refining
the search quality in the GSU.
The best performance was achieved when all three contrastive
losses were employed. This underscores the importance of incorpo-
rating an additional contrastive loss to learn the similarities between
items across the source and target domains, which is crucial for
cross-domain LSM. It appears that training the model solely with
the target domainâ€™s CTR loss is insufficient for aligning embeddings
across different domains. This misalignment is a primary factor
in the degraded performance of previous LSM methods in cross-
domain LSM, as the GSU struggles to deliver stable and precise
search results without embeddings that encapsulate cross-domain
information. The CRP module addresses this, significantly improv-
ing the efficiency of cross-domain LSM.
Representation Quality. To provide a clearer insight into the
quality improvement of the learned item embeddings, we visualized
the clustering of item embeddings, as depicted in Figure 4. Specif-
ically, we employed the T-SNE technique [ 33] to distill the first
two principal components from the learned embeddings, treating
these values as coordinates in a two-dimensional space. By plot-
ting these coordinates and color them according to item categories,
we created a visual map that illustrates the embeddingsâ€™ ability to
differentiate between item categories, which is a direct measure of
the embeddingsâ€™ capacity to pair similar items.
We can observe that while embeddings learned without the CRP
module can cluster items in the target domain with a quality com-
parable to those learned with the CRP module, there is a marked
difference in the source domain, where embeddings refined with
the CRP module exhibit superior clustering. This suggests that the
additional contrastive loss introduced by the CRP module signifi-
cantly enhances the quality of the embeddings in the source domain.Table 2: Performance comparisons for different LSM methods
when incorporating the CRP module.
Metho
ds AUC GAUC Logloss
SIM
Soft 0.7196
0.6342 0.2356
SIM Softğ¶ğ‘…ğ‘ƒ 0.7255
0.6375 0.2252
ET
A 0.7166
0.6328 0.2373
ETAğ¶ğ‘…ğ‘ƒ 0.7204
0.6365 0.2214
SDIM 0.7153
0.6330 0.2384
SDIMğ¶ğ‘…ğ‘ƒ 0.7192
0.6358 0.2191
T
WIN 0.7212
0.6355 0.2348
TWINğ¶ğ‘…ğ‘ƒ 0.7265
0.6391 0.2259
This enhancement is a key factor in the performance improvements
achieved by implementing the CRP module.
Sensitivity study. In this paper, we executed weight search
for the loss weight of CRP on both the production and industrial
datasets. We opted for a series of weight values for the search,
including [0.01, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0]. Our experiments
revealed that, among these weight values, 0.1 yielded the best per-
formance across both datasets, although the influence of the loss
weight was not particularly sensitive when training on the indus-
trial dataset. The model exhibited robust performance within the
weight range of 0.1 to 1.0. Regarding the nagative sampling set-
tings, we sampled 4096 (M=4096) nagative samples for each type of
negative samples. This parameter was optimized through a search
process, where we experimented with different values of M during
training, including [64, 128, 512, 1024, 2048, 4096]. As the number
of negative samples increased, the model performance improved,
and the best performance was achieved when M=4096. However,
due to machine performance limitations, we were unable to further
increase the value of M.
Backbone Substitution. We extended our evaluation of the
CRP module by integrating it into multiple LSM frameworks. In
these experiments, the CRP module was utilized to refine item
embeddings, which were then re-used in the GSU and ESU of the
respective frameworks. The results are summarized in Table 2.
The results indicate that the CRP module consistently enhances
the performance of all tested frameworks in managing cross-domain
LSM. This improvement is largely attributed to the superior qual-
ity of the item embeddings generated for search purposes. These
embeddings are proven to be beneficial regardless of variations in
the underlying framework architecture.
It is important to note that in all experiments, the CRP module
was trained jointly along with the main network. This means that
while CRP introduces additional losses during the training phase,
it does not impose any extra computational cost during inference.
5.2.2 Analyses of LAP. We carried out experiments to investigate
various factors influencing the performance of the LAP, focusing
on the consistency across different levels and the impact of level
sizes. Additionally, we evaluated LAP in a single-domain LSM to
demonstrate the applicability of the proposed LAP.
Ablation Study. A series of experiments was conducted to eval-
uate the influence of the LAP module, particularly examining its
performance in relation to the size of the item pools for MSA ( ğ¾1)
and FSA (ğ¾2). The results are summarized in Table 3. In the ab-
sence of both ğ¾1andğ¾2, we established our initial baseline with
5122KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruijie Hou et al.
Table 3: Comparison of model performance under different
MSA and FSA settings.
Size of the item pool Metrics
ğ¾1ğ¾2 AUC GAUC Logloss
- - 0.7255 0.6375 0.2252
50 - 0.7266 0.6388 0.2246
- 50 0.7297 0.6424 0.2222
100 30 0.7271 0.6396 0.2240
100 50 0.7279 0.6407 0.2234
200 30 0.7286 0.6415 0.2229
200 50 0.7294 0.6423 0.2223
200 100 0.7296 0.6424 0.2221
500 30 0.7288 0.6317 0.2228
500 50 0.7295 0.6424 0.2223
500 100 0.7297 0.6425 0.2220
the SIM Soft model. When either ğ¾1orğ¾2was not included, the
corresponding attention level was omitted from the LAP module.
The results indicate that LAP outperforms the initial baseline,
even with the removal of either MSA or FSA. This improvement is
largely attributed to the enhanced gradient flow across its attention
levels, which improves the learning efficiency of the model. The
performance further improves with the complete implementation
of both MSA and FSA.
Furthermore, it can be observed that the performance exhibits
minimal sensitivity to the specific values assigned to ğ¾1andğ¾2,
particularly once they exceed a quarter of the size of the previous
level. This confirms that the introduction of an intermediate MSA
level promotes greater consistency across the levels. Consequently,
the performance of the model remains stable, even with a reduced
number of items progressing to the advanced attention in the FSA,
which can contribute to decreased inference latency.
Consistency Analyses.We conducted a comparative analysis
to examine the consistency across different stages of LSM among
various LSM methods. For each method, we began by processing
the entire lifelong sequence using the parameter and attention
settings of the final LSM stage, ESU for previous methods and FSA
for our proposed LAP. From this, we extracted the top-50 items
based on their attention scores and used it as the real set. Similarly,
we identified the top-50 items using the parameter and attention
settings of the previous stages, GSU for previous methods and CSA,
MSA for LAP, to obtain the test set. The consistency of each method
was then evaluated by calculating the proportion of items in the
real set that were identified in the test set.
As depicted in Figure 5-(a), the LAP method, with ğ¾1andğ¾2
set to 200 and 50 respectively, demonstrated superior consistency
compared to other methods. This can be attributed to the presence
of the MSA level, which effectively bridges the CSA and FSA. It
is also worth noting that a significant enhancement was achieved
when integrating (concatenating) the results from all three attention
levels as the final output of LAP. This is mainly because that the
integration facilitates gradient flow throughout the sequence, which
is crucial for improving consistency across different levels.
We further conducted a set of experiments to assess the influence
ofğ¾1on consistency. The results, depicted in Figure 5-(b), reveal
that consistency is augmented with larger values of ğ¾1and tends
Figure 5: Comparisons of the consistencies between GSU &
ESU (a) of different LSM methods and (b) under different
settings of ğ¾1.
Table 4: Comparison of performance on single-domain LSM.
Methods AUC GAUC Logloss
SIM Soft 0.7036 0.6495 0.2669
ETA 0.7030 0.6485 0.2692
SDIM 0.7025 0.6485 0.2688
TWIN 0.7044 0.6506 0.2664
LCNğ‘¤/ğ‘œCRP 0.7076 0.6531 0.2648
to plateau once ğ¾1exceed a quarter of the maximum sequence
length, corroborating the model performance trends observed in
the previous section. This indicates that the interplay between MSA
and FSA is highly consistent, owing to the contextual information
included in MSA. This also highlights the value of MSA, which
is key to maintain consistency across levels while considerably
narrowing the item pool needed in the FSA.
Adaptability Test. We conducted experiments to assess the
adaptability of the proposed LAP in the context of single-domain
LSM. For these experiments, we omitted CRP module and relied on
user interactions within the original source domain (video content)
as the training labels. The results are summarized in Table 4.
The results indicate that LAP continues to outperform previ-
ous methods in the context of single-domain LSM, though with a
smaller margin of improvement compared to cross-domain LSM.
This reduced gain is likely due to the relative ease of modeling
lifelong sequences within a single domain, where the data distribu-
tion and behavioral patterns among items in the sequence and the
candidate items tend to be more consistent.
5.3 Overall Performance
The overall performance results of the proposed LCN alongside pre-
vious methods on both public and industrial datasets are presented
in Table 5. We denote different settings of ğ¾1andğ¾2as LCN-ğ¾1-ğ¾2.
Across all metrics and datasets, the proposed LCN consistently
outperforms the other methods. It is important to note, however,
that the margin of improvement on the public dataset is narrower
than that on the industrial dataset. This is largely due to the public
datasetâ€™s smaller sequence lengths and data volume. The perfor-
mance difference on the industrial dataset is likely a more accurate
reflection of the modelâ€™s true generalization capabilities and its
effectiveness in real-world recommendation scenarios.
5123Cross-Domain LifeLong Sequential Modeling for Online Click-Through Rate Prediction KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 5: Final performance comparisons on both the public
and the industrial datasets.
Metho
dsIndustrial. Public.
AUC
GAUC Logloss AUC GAUC Logloss
SIM
Soft 0.7196 0.6342 0.2356 0.6071 0.5762 0.1629
ETA 0.7166 0.6328 0.2373 0.6055 0.5748 0.1630
SDIM 0.7153 0.6330 0.2384 0.6038 0.5734 0.1631
TWIN 0.7212 0.6355 0.2348 0.6087 0.5776 0.1623
DSS[2]
0.7242 0.6386 0.2227 0.6107 0.5790 0.1617
BERT4Rec[20] 0.7253 0.6392 0.2224 0.6122 0.5797 0.1615
SQN[22] 0.7241 0.6381 0.2228 0.6100 0.5787 0.1618
SAC[22] 0.7242 0.6381 0.2228 0.6104 0.5790 0.1618
SSL[31] 0.7246 0.6386 0.2227 0.6111 0.5792 0.1617
CLRec[35] 0.7279 0.6398 0.2225 0.6123 0.5799 0.1614
AT4CTR[37] 0.7262 0.6385 0.2225 0.6117 0.5793 0.1616
CL4CTR[38] 0.7265 0.6386 0.2225 0.6115 0.5791 0.1616
CL4SRec[40] 0.7276 0.6395 0.2224 0.6122 0.5798 0.1615
LCN-200-50 ğ‘¤/ğ‘œCRP
0.7237 0.6379 0.2330 0.6098 0.5786 0.1619
LCNğ‘¤/ğ‘œLAP 0.7266 0.6401 0.2296 0.6128 0.5808 0.1615
LCN-200-50 0.7294 0.6423 0.2223 0.6143 0.5820 0.1610
LCN-500-100 0.7297 0.6425 0.2220 0.6145 0.5820 0.1610
5.4 Online Testing
To further validate the efficiency of the proposed LCN, we con-
ducted an online A/B test to assess the quality of its recommen-
dations. We utilized LCN-200-50 to maintain a balance between
computational efficiency and performance. Over a seven-day pe-
riod, we collected user feedback to calculate online metrics. The
results were significant, with group B achieving a relative increase
of+2.93% in CTR and +3.27% in stay time. Moreover, the inference
latency for group B was only 3 ms longer than that of group A,
which is a negligible trade-off considering the substantial gains in
user experience delivered.
6 CONCLUSIONS
In this paper, we propose the Lifelong Cross Network (LCN) for
cross-domain lifelong sequential modeling (LSM). LCN is composed
of two components: the Cross Representation Production (CRP)
module and the Lifelong Attention Pyramid (LAP) module. The
CRP module is a sub-network that is supervised by contrastive loss
to learn item embeddings that can bridge similar items across do-
mains. The LAP module is structured with three levels of cascading
attentions to extract interest representations from the lifelong se-
quence with respect to the candidate item. By integrating these two
modules, the proposed LCN can effectively identify relevant items
across domains, achieving a highly consistent and computational
efficient interest extraction process within the lifelong sequence in
the source and improving the CTR prediction in the target domain.
The results of experiments on public and industrial datasets
reveal that the proposed LCN significantly improves the modelâ€™s
capacity to handle cross-domain LSM. The results also indicate the
adaptability of the CRP and LAP modules for their effectiveness
when integrated with different LSM backbones or applied to LSM
within a single domain. As for future work, we aim to refine the in-
tegration of the CRP module with the main network and investigate
enhancements to the LAP moduleâ€™s inter-level connections.References
[1]MartÃ­n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
Craig Citro, Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et al .
2016. Tensorflow: Large-scale machine learning on heterogeneous distributed
systems. arXiv preprint arXiv:1603.04467 (2016).
[2]Jiangxia Cao, Xin Cong, Jiawei Sheng, Tingwen Liu, and Bin Wang. 2022. Con-
trastive Cross-Domain Sequential Recommendation. In Proceedings of the 31st
ACM International Conference on Information & Knowledge Management. 138â€“147.
[3]Jiangxia Cao, Jiawei Sheng, Xin Cong, Tingwen Liu, and Bin Wang. 2022. Cross-
Domain Recommendation to Cold-Start Users via Variational Information Bottle-
neck. arXiv:2203.16863 [cs.IR]
[4]Yue Cao, XiaoJiang Zhou, Jiaqi Feng, Peihao Huang, Yao Xiao, Dayao Chen, and
Sheng Chen. 2022. Sampling Is All You Need on Modeling Long-Term User
Behaviors for CTR Prediction. arXiv:2205.10249 [cs.IR]
[5]Jianxin Chang, Chenbin Zhang, Zhiyi Fu, Xiaoxue Zang, Lin Guan, Jing Lu, Yiqun
Hui, Dewei Leng, Yanan Niu, Yang Song, and Kun Gai. 2023. TWIN: TWo-stage
Interest Network for Lifelong User Behavior Modeling in CTR Prediction at
Kuaishou. arXiv:2302.02352 [cs.IR]
[6]Moses S Charikar. 2002. Similarity estimation techniques from rounding algo-
rithms. In Proceedings of the thiry-fourth annual ACM symposium on Theory of
computing. 380â€“388.
[7]Fengwen Chen, Shirui Pan, Jing Jiang, Huan Huo, and Guodong
Long. 2019. DAGCN: Dual Attention Graph Convolutional Networks.
arXiv:1904.02278 [cs.LG]
[8]Qiwei Chen, Changhua Pei, Shanshan Lv, Chao Li, Junfeng Ge, and Wenwu
Ou. 2021. End-to-End User Behavior Retrieval in Click-Through RatePrediction
Model. arXiv:2108.04468 [cs.IR]
[9]Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020.
A Simple Framework for Contrastive Learning of Visual Representations.
arXiv:2002.05709 [cs.LG]
[10] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020.
A Simple Framework for Contrastive Learning of Visual Representations.
arXiv:2002.05709 [cs.LG]
[11] Xinlei Chen and Kaiming He. 2020. Exploring Simple Siamese Representation
Learning. arXiv:2011.10566 [cs.CV]
[12] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,
Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan
Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah.
2016. Wide & Deep Learning for Recommender Systems. arXiv:1606.07792 [cs.LG]
[13] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding.
arXiv:1810.04805 [cs.CL]
[14] Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training
deep feedforward neural networks. In Proceedings of the thirteenth international
conference on artificial intelligence and statistics. JMLR Workshop and Conference
Proceedings, 249â€“256.
[15] Wei Guo, Can Zhang, Zhicheng He, Jiarui Qin, Huifeng Guo, Bo Chen, Ruiming
Tang, Xiuqiang He, and Rui Zhang. 2022. MISS: Multi-Interest Self-Supervised
Learning Framework for Click-Through Rate Prediction. arXiv:2111.15068 [cs.IR]
[16] Guangneng Hu, Yu Zhang, and Qiang Yang. 2018. CoNet: Collaborative Cross
Networks for Cross-Domain Recommendation. In Proceedings of the 27th ACM
International Conference on Information and Knowledge Management (CIKM â€™18).
ACM. https://doi.org/10.1145/3269206.3271684
[17] Diederik P. Kingma and Jimmy Ba. 2017. Adam: A Method for Stochastic Opti-
mization. arXiv:1412.6980 [cs.LG]
[18] Chenglin Li, Mingjun Zhao, Huanming Zhang, Chenyun Yu, Lei Cheng, Guo-
qiang Shu, BeiBei Kong, and Di Niu. 2022. RecGURU: Adversarial Learning of
Generalized User Representations for Cross-Domain Recommendation. In Pro-
ceedings of the Fifteenth ACM International Conference on Web Search and Data
Mining (WSDM â€™22). ACM. https://doi.org/10.1145/3488560.3498388
[19] Meng Liu, Jianjun Li, Guohui Li, and Peng Pan. 2020. Cross domain recom-
mendation via bi-directional transfer graph collaborative filtering networks. In
Proceedings of the 29th ACM international conference on information & knowledge
management. 885â€“894.
[20] Qi Liu, Xuyang Hou, Defu Lian, Zhe Wang, Haoran Jin, Jia Cheng, and Jun
Lei. 2023. AT4CTR: Auxiliary Match Tasks for Enhancing Click-Through Rate
Prediction. arXiv preprint arXiv:2312.06683 (2023).
[21] Weiming Liu, Xiaolin Zheng, Mengling Hu, and Chaochao Chen. 2022. Exploiting
Variational Domain-Invariant User Embedding for Partially Overlapped Cross
Domain Recommendation. arXiv:2205.06440 [cs.IR]
[22] Jianxin Ma, Chang Zhou, Hongxia Yang, Peng Cui, Xin Wang, and Wenwu Zhu.
2020. Disentangled self-supervision in sequential recommenders. In Proceedings
of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining. 483â€“491.
[23] Muyang Ma, Pengjie Ren, Yujie Lin, Zhumin Chen, Jun Ma, and Maarten de Rijke.
2019.ğœ‹-Net: A Parallel Information-Sharing Network for Shared-Account Cross-
Domain Sequential Recommendations. In Proceedings of the 42nd International
ACM SIGIR Conference on Research and Development in Information Retrieval
5124KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruijie Hou et al.
(Paris, France) (SIGIRâ€™19). Association for Computing Machinery, New York, NY,
USA, 685â€“694. https://doi.org/10.1145/3331184.3331200
[24] Wentao Ouyang, Xiuwu Zhang, Lei Zhao, Jinmei Luo, Yu Zhang, Heng Zou,
Zhaojie Liu, and Yanlong Du. 2021. Minet: Mixed interest network for cross-
domain click-through rate prediction. In CIKM. 2669â€“2676.
[25] Yujie Pan, Jiangchao Yao, Bo Han, Kunyang Jia, Ya Zhang, and Hongxia Yang.
2021. Click-through Rate Prediction with Auto-Quantized Contrastive Learning.
arXiv:2109.13921 [cs.IR]
[26] Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and
Alexei A. Efros. 2016. Context Encoders: Feature Learning by Inpainting.
arXiv:1604.07379 [cs.CV]
[27] Qi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Practice
on Long Sequential User Behavior Modeling for Click-Through Rate Prediction.
InProceedings of the 25th ACM SIGKDD International Conference on Knowledge
Discovery &amp; Data Mining (KDD â€™19). ACM. https://doi.org/10.1145/3292500.
3330666
[28] Pi Qi, Xiaoqiang Zhu, Guorui Zhou, Yujing Zhang, Zhe Wang, Lejian
Ren, Ying Fan, and Kun Gai. 2020. Search-based User Interest Modeling
with Lifelong Sequential Behavior Data for Click-Through Rate Prediction.
arXiv:2006.05639 [cs.IR]
[29] Jiarui Qin, Weinan Zhang, Xin Wu, Jiarui Jin, Yuchen Fang, and Yong Yu. 2020.
User Behavior Retrieval for Click-Through Rate Prediction. In Proceedings of
the 43rd International ACM SIGIR Conference on Research and Development in
Information Retrieval (SIGIR â€™20). ACM. https://doi.org/10.1145/3397271.3401440
[30] Aghiles Salah, Thanh Binh Tran, and Hady Lauw. 2021. Towards Source-Aligned
Variational Models for Cross-Domain Recommendation. In Proceedings of the 15th
ACM Conference on Recommender Systems (Amsterdam, Netherlands) (RecSys
â€™21). Association for Computing Machinery, New York, NY, USA, 176â€“186. https:
//doi.org/10.1145/3460231.3474265
[31] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.
2019. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Repre-
sentations from Transformer. arXiv:1904.06690 [cs.IR]
[32] Wenchao Sun, Muyang Ma, Pengjie Ren, Yujie Lin, Zhumin Chen, Zhaochun
Ren, Jun Ma, and Maarten de Rijke. 2021. Parallel Split-Join Networks for Shared-
account Cross-domain Sequential Recommendations. arXiv:1910.02448 [cs.IR]
[33] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.
Journal of machine learning research 9, 11 (2008).[34] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023. Attention Is All
You Need. arXiv:1706.03762 [cs.CL]
[35] Fangye Wang, Yingxu Wang, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, and
Ning Gu. 2023. CL4CTR: A Contrastive Learning Framework for CTR Prediction.
InProceedings of the Sixteenth ACM International Conference on Web Search and
Data Mining. 805â€“813.
[36] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong,
and Ed Chi. 2021. DCN V2: Improved Deep &amp; Cross Network and Practical
Lessons for Web-scale Learning to Rank Systems. In Proceedings of the Web
Conference 2021 (WWW â€™21). ACM. https://doi.org/10.1145/3442381.3450078
[37] Xin Xin, Alexandros Karatzoglou, Ioannis Arapakis, and Joemon M. Jose.
2020. Self-Supervised Reinforcement Learning for Recommender Systems.
arXiv:2006.05779 [cs.LG]
[38] Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, Felix Yu, Ting Chen,
Aditya Menon, Lichan Hong, Ed H. Chi, Steve Tjoa, Jieqi Kang, and Evan Et-
tinger. 2021. Self-supervised Learning for Large-scale Item Recommendations.
arXiv:2007.12865 [cs.LG]
[39] Li Zhang, Weichen Shen, Shijian Li, and Gang Pan. 2019. Field-aware Neural Fac-
torization Machine for Click-Through Rate Prediction. arXiv:1902.09096 [cs.LG]
[40] Chang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, and Hongxia Yang. 2021.
Contrastive Learning for Debiased Candidate Generation in Large-Scale Recom-
mender Systems. arXiv:2005.12964 [cs.IR]
[41] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu,
and Kun Gai. 2019. Deep Interest Evolution Network for Click-Through Rate
Prediction. arXiv:1809.03672 [stat.ML]
[42] Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Ying Fan, Han Zhu, Xiao Ma,
Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep Interest Network for
Click-Through Rate Prediction. arXiv:1706.06978 [stat.ML]
[43] Yongchun Zhu, Kaikai Ge, Fuzhen Zhuang, Ruobing Xie, Dongbo Xi, Xu Zhang,
Leyu Lin, and Qing He. 2021. Transfer-Meta Framework for Cross-domain
Recommendation to Cold-Start Users. In Proceedings of the 44th International
ACM SIGIR Conference on Research and Development in Information Retrieval
(SIGIR â€™21). ACM. https://doi.org/10.1145/3404835.3463010
[44] Yongchun Zhu, Zhenwei Tang, Yudan Liu, Fuzhen Zhuang, Ruobing Xie, Xu
Zhang, Leyu Lin, and Qing He. 2021. Personalized Transfer of User Preferences
for Cross-domain Recommendation. arXiv:2110.11154 [cs.IR]
5125