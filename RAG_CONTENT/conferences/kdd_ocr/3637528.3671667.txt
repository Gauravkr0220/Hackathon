Fast Multidimensional Partial Fourier Transform with
Automatic Hyperparameter Selection
Yong-chan Park
Seoul National University
Seoul, Republic of Korea
wjdakf3948@snu.ac.krJongjin Kim
Seoul National University
Seoul, Republic of Korea
j2kim99@snu.ac.krU Kang
Seoul National University
Seoul, Republic of Korea
ukang@snu.ac.kr
Abstract
Given a multidimensional array, how can we optimize the compu-
tation process for a part of Fourier coefficients? Discrete Fourier
transform plays an overarching role in various data mining tasks.
Recent interest has focused on efficiently calculating a small part
of Fourier coefficients, exploiting the energy compaction prop-
erty of real-world data. Current methods for partial Fourier trans-
form frequently encounter efficiency issues, yet the adoption of
pre-computation techniques within the PFT algorithm has shown
promising performance. However, PFT still faces limitations in
handling multidimensional data efficiently and requires manual
hyperparameter tuning, leading to additional costs.
In this paper, we propose Auto-MPFT (Automatic Multidimen-
sional Partial Fourier Transform), which efficiently computes a
subset of Fourier coefficients in multidimensional data without the
need for manual hyperparameter search. Auto-MPFT leverages mul-
tivariate polynomial approximation for trigonometric functions,
generalizing its domain to multidimensional Euclidean space. More-
over, we present a convex optimization-based algorithm for auto-
matically selecting the optimal hyperparameter of Auto-MPFT. We
provide a rigorous proof for the explicit reformulation of the origi-
nal optimization problem of Auto-MPFT, demonstrating the process
that converts it into a well-established unconstrained convex opti-
mization problem. Extensive experiments show that Auto-MPFT
surpasses existing partial Fourier transform methods and optimized
FFT libraries, achieving up to 7.6 Ã—increase in speed without sacri-
ficing accuracy. In addition, our optimization algorithm accurately
finds the optimal hyperparameter for Auto-MPFT, significantly
reducing the cost associated with hyperparameter search.
CCS Concepts
â€¢Theory of computation â†’Numeric approximation algo-
rithms.
Keywords
Partial Fourier transform; Fast Fourier transform
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671667ACM Reference Format:
Yong-chan Park, Jongjin Kim, and U Kang. 2024. Fast Multidimensional
Partial Fourier Transform with Automatic Hyperparameter Selection. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671667
1 Introduction
Discrete Fourier transform (DFT) is a central algorithm in many
data mining tasks, including anomaly detection [ 15,22,23,31], la-
tent pattern extraction [ 21,25,33], and image processing [ 8,18,27].
Recently, there has been a growing interest in efficiently calculating
only a part of Fourier coefficients by leveraging the energy com-
paction property of data. A majority of real-world data, such as
time series, image, and video, have a very compact representation
in the frequency domain. As an illustration, Figure 1 visualizes the
Fourier coefficients of natural images from ImageNet, where the
coefficients are mostly equal to zero except in a few low-frequency
parts. This indicates that one can gain significant computational
benefits by focusing only on the part of non-zero coefficients and
skipping the computation of unnecessary coefficients.
However, many existing methods for partial Fourier transform,
such as Goertzel algorithm [ 6,13], Subband DFT [ 14,26], and
Pruned FFT [ 2,16,17,28,30], suffer from low efficiency. Compared
to the classic fast Fourier transform (FFT) computing the full coeffi-
cients, these methods outperform FFT only when the output has a
much smaller size than the input, limiting their usage in practice. A
recent work [ 20] proposes PFT, which leverages pre-computation
techniques for partial Fourier transform, and raises the performance
to a level that it can replace FFT in practical applications. However,
the effectiveness of PFT is constrained by two major limitations.
First, PFT is specialized for one-dimensional data, so it does not op-
erate efficiently for multidimensional data. Although it is possible
to apply PFT to each axis of multidimensional data, we theoretically
and experimentally show that this approach is less efficient than
algorithms specifically designed for multidimensional data. Second,
PFT requires a manual hyperparameter tuning every time the size
of the input or output changes. This leads to an extra cost of the
method, especially when the data are multidimensional, because in
that case the search space of the hyperparameter is also huge.
In this paper, we propose Auto-MPFT (Automatic Multidimen-
sional Partial Fourier Transform), a fast and accurate algorithm
that computes partial Fourier coefficients of multidimensional data
without necessity for manual hyperparameter search. Auto-MPFT
approximates a set of trigonometric factors in DFT using multivari-
ate polynomials. Polynomial approximation enables Auto-MPFT to
significantly reduce the computational cost by efficiently processing
 
2328
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
Figure 1: Examples of input images and their Fourier maps,
where the Fourier coefficients are shown as log-amplitudes.
Except for a few low-frequency parts (around the center), the
Fourier coefficients are predominantly close to zero.
multidimensional data with matrix multiplications and multidimen-
sional FFTs. Furthermore, we propose a convex optimization-based
algorithm for automatically selecting the optimal hyperparame-
ter of Auto-MPFT. The key of our method is to approximate the
complicated constraint function in Auto-MPFT by deriving an ex-
plicit reformulation of the constraint function based on Chebyshev
approximation [ 7]. We prove that it leads to an unconstrained con-
vex optimization problem, which is efficiently solved by Newtonâ€™s
method. Extensive experiments show that Auto-MPFT outperforms
the state-of-the-art partial Fourier transform methods as well as op-
timized FFT libraries, Intel MKL and FFTW, achieving a remarkable
increase in speed without compromising accuracy. We also show
that our convex optimization-based algorithm successfully finds
the optimal hyperparameter of Auto-MPFT, significantly reducing
the extra cost due to the hyperparameter search.
We summarize our contributions as follows:
â€¢Algorithm. We present Auto-MPFT, an efficient method that
computes a part of Fourier coefficients of multidimensional data.
â€¢Automatic hyperparameter selection. We propose a convex
optimization-based algorithm for automatic selection of the opti-
mal hyperparameter of Auto-MPFT.
â€¢Performance. We experimentally show that Auto-MPFT outper-
forms the state-of-the-art baselines without sacrificing accuracy.
We provide the source code and datasets used in our paper at
https://github.com/snudatalab/Auto-MPFT/ .
2 Related Works
We present an overview of different methods for computing partial
Fourier coefficients, comparing them to our Auto-MPFT.
Fast Fourier transform. Fast Fourier transform (FFT) [ 5,9,19]
is an efficient algorithm for rapidly computing the discrete Fourier
transform (DFT), reducing the computational complexity from
ğ‘‚(ğ‘2)toğ‘‚(ğ‘logğ‘), whereğ‘is an input size. While there are
specialized algorithms for the partial Fourier transform, it is note-
worthy that the FFT, designed for computing full coefficients, often
proves to be a superior choice. This preference is due to the fact
that FFT is a well-established and highly optimized algorithm over
the years, making it not only straightforward to implement but alsofrequently outperforming specialized algorithms for partial Fourier
transform. We conduct comprehensive theoretical and experimental
comparisons between our proposed Auto-MPFT and FFT. Specifi-
cally, we show that Auto-MPFT significantly outperforms the FFT
by an order of magnitude of speedup with comparable accuracy.
Goertzel algorithm. Goertzel algorithm [ 6,13] is an early
method for computing partial Fourier coefficients. It essentially
mimics the process of computing individual coefficients one by one,
entailing a computational complexity of ğ‘‚(ğ‘€ğ‘)forğ‘€coefficients
in an input of size ğ‘. This indicates that Goertzel algorithm be-
comes advantageous over FFT only when the number of coefficients
ğ‘€is less than logğ‘. Although a few variants aimed at improving
the Goertzel algorithm have been proposed [ 4], their performance
gains are limited to a small constant factor. Consequently, these
improvements do not significantly alter the algorithmâ€™s overall effi-
ciency. Thus, the Goertzel algorithm is less favorable in scenarios
where a considerable number of coefficients is required.
Subband DFT. Subband DFT [ 14,26] breaks down the input
data into smaller sub-blocks and efficiently approximates a part
of Fourier coefficients by eliminating sub-blocks with low energy
contributions, resulting in ğ‘‚(ğ‘+ğ‘€logğ‘)time complexity. Despite
the computational advantages, Subband DFT suffers from low accu-
racy, consistently showing a large relative error of around 10âˆ’1[14].
While Subband DFT may offer computational benefits, its accuracy
limitation makes it less suitable for applications demanding precise
and reliable results. Note that Auto-MPFT enables the evaluation
of Fourier coefficients with arbitrary numerical precision.
Pruned FFT. Pruned FFT [ 2,16,17,28,30] is a modification
of the standard FFT, designed for computing a subset of Fourier
coefficients. In this method, operations in a flow graph are pruned
by removing those that do not influence the specified range in
the frequency domain, achieving ğ‘‚(ğ‘logğ‘€)time cost. However,
the pruning strategy does not result in significant computational
savings because it leads to increased complexity in maintaining the
accuracy of the desired frequency range. Moreover, it is noteworthy
that the standard FFT is significantly more optimized than Pruned
FFT. In comparison to Pruned FFT, our Auto-MPFT is highly efficient
as it directly leverages the standard FFT as a subroutine.
PFT. PFT [ 20] is the current state-of-the-art method for partial
Fourier transform. The method uses a polynomial approximation
technique for efficient computations of DFT, reducing the time
complexity to ğ‘‚(ğ‘+ğ‘€logğ‘€). However, there are two downsides to
the method. First, PFT is designed specifically for one-dimensional
inputs, making it less effective when applied to multidimensional
data. For example, Figure 2 compares the application of PFT and
Auto-MPFT to a two-dimensional input of size ğ‘†Ã—ğ‘†, where the goal
is to efficiently compute ğ‘‡Ã—ğ‘‡low-frequency coefficients. Because
a multidimensional DFT is equivalent to applying multiple one-
dimensional DFTs for each dimension, one can use multiple PFTs
for each axis as in Figure 2. However, this approach requires
ğ‘†Â·(ğ‘†+ğ‘‡logğ‘‡)+ğ‘‡Â·(ğ‘†+ğ‘‡logğ‘‡)âˆ¼ğ‘†2+ğ‘†ğ‘‡logğ‘‡
costs, while Auto-MPFT conducts the same computation with only
ğ‘†2+ğ‘‡2logğ‘‡2âˆ¼ğ‘†2+ğ‘‡2logğ‘‡
operations (see Section 3.3 for the proof), which is a significant
computational gain since ğ‘‡â‰ªğ‘†.
 
2329Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
PFT
axis=1PFT
axis=2
Auto-MPFT (proposed)
Figure 2: Comparison between PFT and Auto-MPFT for a
two-dimensional input. While PFT is applied for each axis,
Auto-MPFT is applied only once for the entire input and
therefore requires much fewer operations.
Another disadvantage of PFT is its reliance on a manual hyper-
parameter search. Given an input of size ğ‘, a user must choose
an appropriate divisor ğ‘ofğ‘to use the PFT algorithm. The over-
all performance of the algorithm varies greatly depending on the
value ofğ‘, making it crucial to choose the optimal ğ‘. However,
PFT does not provide an option to automatically find the optimal
value, so in the worst case, one may need to go through trial and
error for all divisors of ğ‘. The situation becomes even worse when
the input is multidimensional because the search space grows ex-
ponentially with dimension. Note that Auto-MPFT addresses this
problem by automatically finding the optimal value of ğ‘using a
convex optimization-based algorithm, significantly reducing the
extra cost due to the hyperparameter search.
3 Proposed Method
We propose Auto-MPFT, an efficient algorithm for partial Fourier
transform of multidimensional data with automatic hyperparameter
selection. The main challenges and our approaches are as follows:
(1)How can we efficiently compute partial Fourier coeffi-
cients in multidimensional DFT? We carefully modify the
Cooley-Tukey algorithm to find a set of smooth twiddle factors
in multidimensional DFT. We then approximate the twiddle
factors using multivariate polynomials. This technique decom-
poses the computation of partial Fourier coefficients into matrix
multiplications and multidimensional FFTs of small sub-blocks
of the input, achieving significantly less time cost (Section 3.1).
(2)How can we automatically find the optimal hyperparam-
eter of Auto-MPFT? The optimal hyperparameter is the value
that minimizes the time complexity of Auto-MPFT. However,
we find that the constraint function of such an optimization
problem cannot be expressed as an explicit form. We tackle this
issue by reformulating the constraint function via Chebyshev
approximation and deriving an unconstrained convex optimiza-
tion problem. This approach allows us to efficiently find the
optimal hyperparameter using well-established numerical anal-
ysis such as Newtonâ€™s method (Sections 3.2 and 3.3).
3.1 Multidimensional Partial Fourier Transform
We describe our proposed method in detail. The key ideas of Auto-
MPFT for efficient computation of partial Fourier coefficients areas follows: (1) in the configuration phase, Auto-MPFT uses pre-
computation techniques via multivariate polynomial approxima-
tion of trigonometric functions in DFT. Moreover, it automatically
finds the optimal hyperparameter and calculates the degree of the
approximation polynomial (Algorithm 1). (2) In the computation
phase, Auto-MPFT utilizes batch matrix multiplication and FFT
algorithms optimized for multidimensional data types, which al-
lows Auto-MPFT to yield theoretically and experimentally superior
results compared to existing methods (Algorithm 2).
For a positive integer ğœˆ, letğœ”ğœˆâ‰”ğ‘’âˆ’2ğœ‹ğ‘–/ğœˆbe theğœˆ-th primitive
root of unity and[ğœˆ]â‰”{0,1,Â·Â·Â·,ğœˆâˆ’1}. Given ağ·-dimensional
arrayğ“=(ğ‘ğ’)âˆˆCğ‘1Ã—Â·Â·Â·Ã—ğ‘ğ·, the DFT of it is defined as follows:
Ë†ğ‘ğ’=âˆ‘ï¸
ğ’âˆˆÃ
ğ‘‘[ğ‘ğ‘‘]ğ‘ğ’Ã–
ğ‘‘ğœ”ğ‘šğ‘‘ğ‘›ğ‘‘
ğ‘ğ‘‘(1â‰¤ğ‘‘â‰¤ğ·), (1)
where ğ’=(ğ‘›1,Â·Â·Â·,ğ‘›ğ·),ğ’=(ğ‘š1,Â·Â·Â·,ğ‘šğ·)âˆˆZğ·are input and
output indices, respectively. Our goal is to compute the Fourier
coefficients Ë†ğ‘ğ’forğ’belonging to the ğ·-dimensional box
Bğ,ğ‘´:=Ã–
ğ‘‘[ğœ‡ğ‘‘âˆ’ğ‘€ğ‘‘,ğœ‡ğ‘‘+ğ‘€ğ‘‘],
where ğ=(ğœ‡1,Â·Â·Â·,ğœ‡ğ·),ğ‘´=(ğ‘€1,Â·Â·Â·,ğ‘€ğ·)âˆˆZğ·are the center
and radii of the box, respectively. We call the ğ·-dimensional box
Bğ,ğ‘´a â€œtarget range.â€ Now assume that for each ğ‘‘=1,Â·Â·Â·,ğ·,
we haveğ‘ğ‘‘=ğ‘ğ‘‘ğ‘ğ‘‘, whereğ‘ğ‘‘,ğ‘ğ‘‘>1. Let ğ’‘=(ğ‘1,Â·Â·Â·,ğ‘ğ·)âˆˆ
Zğ·andğ’’=(ğ‘1,Â·Â·Â·,ğ‘ğ·) âˆˆZğ·. The Cooley-Tukey algorithm
[9] decomposes the summation (1) with ğ’=ğ’’âŠ™ğ’Œ+ğ’, where
ğ’ŒâˆˆÃ
ğ‘‘[ğ‘ğ‘‘],ğ’âˆˆÃ
ğ‘‘[ğ‘ğ‘‘], andâŠ™is the element-wise product:
Ë†ğ‘ğ’=âˆ‘ï¸
ğ’Œ,ğ’ğ‘ğ’’âŠ™ğ’Œ+ğ’Ã–
ğ‘‘ğœ”ğ‘šğ‘‘(ğ‘ğ‘‘ğ‘˜ğ‘‘+ğ‘™ğ‘‘)
ğ‘ğ‘‘
=âˆ‘ï¸
ğ’Œ,ğ’ğ‘ğ’’âŠ™ğ’Œ+ğ’Ã–
ğ‘‘ğœ”ğ‘šğ‘‘ğ‘™ğ‘‘
ğ‘ğ‘‘ğœ”ğ‘šğ‘‘ğ‘˜ğ‘‘ğ‘ğ‘‘.(2)
Following the trick ğœ”ğ‘šğ‘‘ğ‘™ğ‘‘
ğ‘ğ‘‘=ğœ”ğ‘šğ‘‘(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘Â·ğœ”ğ‘šğ‘‘
2ğ‘ğ‘‘from [ 20], we
rewrite (2) as follows:
Ë†ğ‘ğ’=âˆ‘ï¸
ğ’Œ,ğ’ğ‘ğ’’âŠ™ğ’Œ+ğ’Ã–
ğ‘‘ğœ”ğ‘šğ‘‘(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘ğœ”ğ‘šğ‘‘ğ‘˜ğ‘‘ğ‘ğ‘‘ğœ”ğ‘šğ‘‘
2ğ‘ğ‘‘. (3)
Note that|ğ‘™ğ‘‘|<ğ‘ğ‘‘and|ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2|<ğ‘ğ‘‘/2, so the twiddle factors
{ğœ”ğ‘šğ‘‘(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘}is less oscillatory compared to {ğœ”ğ‘šğ‘‘ğ‘™ğ‘‘
ğ‘ğ‘‘}, which
allows a more accurate approximation via polynomials. To apply
polynomial approximation for the set {ğœ”ğ‘šğ‘‘(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘}, we provide
the following definitions. Let âˆ¥Â·âˆ¥ğ‘…be the uniform norm restricted
to a setğ‘…âŠ†R, that is,âˆ¥ğ‘“âˆ¥ğ‘…â‰”sup{|ğ‘“(ğ‘¥)|:ğ‘¥âˆˆğ‘…}andğ‘ƒğ›¼be the
set of polynomials on Rof degree less than ğ›¼.
Definition 3.1. Given a positive integer ğ›¼and a non-zero real
numberğœ‰, we definePğ›¼,ğœ‰as the best polynomial approximation to
ğ‘’ğœ‹ğ‘–ğ‘¥of degree less than ğ›¼with the restriction |ğ‘¥|â‰¤|ğœ‰|:
Pğ›¼,ğœ‰:=arg min
ğ‘ƒâˆˆğ‘ƒğ›¼âˆ¥ğ‘ƒ(ğ‘¥)âˆ’ğ‘’ğœ‹ğ‘–ğ‘¥âˆ¥|ğ‘¥|â‰¤|ğœ‰|,
andPğ›¼,ğœ‰â‰”1whenğœ‰=0. â–¡
The uniqueness and existence of such polynomials are proved
in [29]. For the computation of the best polynomial approxima-
tion, we use the Chebyshev approximation algorithm [ 10]. We opt
to use the Chebyshev polynomials due to their solid theoretical
foundations, including their widespread application in achieving
optimal approximations with respect to the uniform norm and their
contribution to the derivation of an error bound of Auto-MPFT
 
2330KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
as we will describe in Section 3.2. Further investigation into other
types of orthogonal polynomials could provide valuable insights
and potentially improve the accuracy and efficiency of our proposed
method, which we leave as an interesting future work.
Definition 3.2. Given a tolerance ğœ–>0and a positive integer
ğ‘Ÿ, we defineğœ‰(ğœ–,ğ‘Ÿ)to be the scope about the origin such that the
exponential function ğ‘’ğœ‹ğ‘–ğ‘¥can be approximated by a polynomial of
degree less than ğ‘Ÿwith approximation bound ğœ–:
ğœ‰(ğœ–,ğ‘Ÿ):=sup{ğœ‰â‰¥0 :âˆ¥Pğ‘Ÿ,ğœ‰(ğ‘¥)âˆ’ğ‘’ğœ‹ğ‘–ğ‘¥âˆ¥|ğ‘¥|â‰¤ğœ‰â‰¤ğœ–}.
We express the best polynomial as Pğ‘Ÿ,ğœ‰(ğœ–,ğ‘Ÿ)(ğ‘¥)=Ã
ğ‘—âˆˆ[ğ‘Ÿ]ğ‘¤ğœ–,ğ‘Ÿ,ğ‘—ğ‘¥ğ‘—,
whereğ‘¤ğœ–,ğ‘Ÿ,ğ‘—is theğ‘—-th coefficient of the polynomial. â–¡
Given a tolerance ğœ–>0, assume that we found a positive integer
ğ‘Ÿğ‘‘that satisfies ğœ‰(ğœ–,ğ‘Ÿğ‘‘) â‰¥ğ‘€ğ‘‘/ğ‘ğ‘‘for eachğ‘‘(the algorithm for
findingğ‘Ÿğ‘‘is demonstrated in Section 3.2). Then, for ğœ‡ğ‘‘âˆ’ğ‘€ğ‘‘â‰¤
ğ‘šğ‘‘â‰¤ğœ‡ğ‘‘+ğ‘€ğ‘‘, we decompose the twiddle factor ğœ”ğ‘šğ‘‘(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘
intoğœ”ğœ‡ğ‘‘(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘ğœ”(ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘)(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘and approximate the second
term by the polynomial Pğ‘Ÿğ‘‘,ğœ‰(ğœ–,ğ‘Ÿğ‘‘)(âˆ’2(ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘)(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)/ğ‘ğ‘‘).
Becauseğœ‰(ğœ–,ğ‘Ÿğ‘‘)â‰¥ğ‘€ğ‘‘/ğ‘ğ‘‘, the approximation is valid for all ğ‘šğ‘‘
such that|ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘| â‰¤ |ğ‘ğ‘‘
2(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)Â·ğ‘€ğ‘‘
ğ‘ğ‘‘|=|ğ‘ğ‘‘
2ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘Â·ğ‘€ğ‘‘|, so in
particular,|ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘|â‰¤ğ‘€ğ‘‘. Thus, we approximate (3) as follows:
Ë†ğ‘ğ’â‰ˆâˆ‘ï¸
ğ’‹,ğ’Œ,ğ’ğ‘(ğ’Œ)
ğ’Ã–
ğ‘‘ğ‘(ğ‘‘)
ğ‘—ğ‘‘ğ‘™ğ‘‘ğœ”ğ‘šğ‘‘ğ‘˜ğ‘‘ğ‘ğ‘‘((ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘)/ğ‘ğ‘‘)ğ‘—ğ‘‘ğœ”ğ‘šğ‘‘
2ğ‘ğ‘‘,(4)
where ğ’‹âˆˆÃ
ğ‘‘[ğ‘Ÿğ‘‘],ğ’ŒâˆˆÃ
ğ‘‘[ğ‘ğ‘‘],ğ’âˆˆÃ
ğ‘‘[ğ‘ğ‘‘], and
ğ“(ğ’Œ):=(ğ‘(ğ’Œ)
ğ’=ğ‘ğ’’âŠ™ğ’Œ+ğ’)âˆˆCğ‘1Ã—Â·Â·Â·Ã—ğ‘ğ·,
ğµ(ğ‘‘):=(ğ‘(ğ‘‘)
ğ‘—ğ‘‘ğ‘™ğ‘‘=ğœ”ğœ‡ğ‘‘(ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘ğ‘¤ğœ–,ğ‘Ÿğ‘‘,ğ‘—ğ‘‘(1âˆ’2ğ‘™ğ‘‘/ğ‘ğ‘‘)ğ‘—ğ‘‘)âˆˆCğ‘Ÿğ‘‘Ã—ğ‘ğ‘‘.
In (4), the innermost summationÃ
ğ’ğ‘(ğ’Œ)
ğ’Ã
ğ‘‘ğ‘(ğ‘‘)
ğ‘—ğ‘‘ğ‘™ğ‘‘can be written
as a sequential ğ‘‘-mode product
ğ“(ğ’Œ)Ã—1ğµ(1)Ã—2Â·Â·Â·Ã—ğ·ğµ(ğ·). (5)
Note that there are a total of ğ·!parenthesizations to compute (5).
We precompute the optimal parenthesization in the configuration
phase when(ğ‘µ,ğ‘´,ğ,ğœ–)is given, so that we can bypass the paren-
thesization problem in the computation phase. Let us denote the
result of (5) by ğ“’(ğ’Œ):=(ğ‘(ğ’Œ)
ğ’‹)âˆˆCğ‘Ÿ1Ã—Â·Â·Â·Ã—ğ‘Ÿğ·. For each ğ’‹, the opera-
tionÃ
ğ’Œğ‘(ğ’Œ)
ğ’‹Ã
ğ‘‘ğœ”ğ‘šğ‘‘ğ‘˜ğ‘‘ğ‘ğ‘‘is ağ·-dimensional DFT of sizeÃ
ğ‘‘ğ‘ğ‘‘. Let
Ë†ğ‘(ğ’‹)
ğ’be the Fourier coefficients of ğ‘(ğ’Œ)
ğ’‹with respect to ğ’Œ. Then, we
obtain the following estimation of Ë†ğ‘ğ’:
Ë†ğ‘ğ’â‰ˆâˆ‘ï¸
ğ’‹Ë†ğ‘(ğ’‹)
ğ’Ã–
ğ‘‘((ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘)/ğ‘ğ‘‘)ğ‘—ğ‘‘ğœ”ğ‘šğ‘‘
2ğ‘ğ‘‘. (6)
The full computation is outlined in Algorithms 1 and 2.
3.2 Automatic Hyperparameter Selection
We propose a convex optimization-based algorithm for selecting the
optimal hyperparameter of Auto-MPFT. The key idea is to convert
the original optimization problem of Auto-MPFT (Problem 1) into
an unconstrained convex optimization problem (Problem 2) by
carefully approximating the constraint function.Algorithm 1: Configuration phase of Auto-MPFT
input : Input size ğ‘µ, output descriptors ğ‘´andğ, and
toleranceğœ–
output: Configuration results ğµ(ğ‘‘),ğ‘ğ‘‘,ğ‘ğ‘‘,ğ‘Ÿğ‘‘for allğ‘‘, and
optimal parenthesization
1forğ‘‘=1,2,Â·Â·Â·,ğ·do
2 Find the solution ğ‘Ÿğ‘‘of Problem 2 by Newtonâ€™s method
3 Find the nearest divisor ğ‘ğ‘‘ofğ‘ğ‘‘toğ‘(ğ‘Ÿğ‘‘)
4ğ‘ğ‘‘â†ğ‘ğ‘‘/ğ‘ğ‘‘
5ğ‘Ÿğ‘‘â†âŒŠğ‘Ÿğ‘‘âŒ‹
6ğµ(ğ‘‘)[ğ‘™,ğ‘—]â†ğœ”ğœ‡ğ‘‘(ğ‘™âˆ’ğ‘ğ‘‘/2)
ğ‘ğ‘‘ğ‘¤ğœ–,ğ‘Ÿğ‘‘,ğ‘—(1âˆ’2ğ‘™/ğ‘ğ‘‘)ğ‘—
7end
8Find the optimal parenthesization of Equation (5).
Algorithm 2: Computation phase of Auto-MPFT
input : Array ğ’‚of sizeÃ
ğ‘‘ğ‘ğ‘‘, output descriptors ğ‘´andğ,
and configuration results in Algorithm 1
output: Array Ë†ğ’‚of Fourier coefficients of ğ’‚forBğ,ğ‘´
1ğ´(ğ’Œ)[ğ’]â†ğ‘ğ’’âŠ™ğ’Œ+ğ’forğ’ŒâˆˆÃ
ğ‘‘[ğ‘ğ‘‘]andğ’âˆˆÃ
ğ‘‘[ğ‘ğ‘‘]
2ğ¶(ğ’Œ)â†ğ´(ğ’Œ)Ã—1ğµ(1)Ã—2Â·Â·Â·Ã—ğ·ğµ(ğ·)forğ’ŒâˆˆÃ
ğ‘‘[ğ‘ğ‘‘]
3Ë†ğ¶(ğ’‹)[Â·]â† FFT(ğ¶(Â·)[ğ’‹])forğ’‹âˆˆÃ
ğ‘‘[ğ‘Ÿğ‘‘]
4forğ’âˆˆBğ,ğ‘´do
5 Ë†ğ’‚[ğ’]â†Ã
ğ’‹Ë†ğ¶(ğ’‹)[ğ’]Ã
ğ‘‘((ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘)/ğ‘ğ‘‘)ğ‘—ğ‘‘ğœ”ğ‘šğ‘‘
2ğ‘ğ‘‘
6end
3.2.1 Building an Optimization Problem. Recall that the optimal
hyperparameter is given by the minimizer of the time complexity
of Auto-MPFT. Thus, we first need to derive the time cost function
of our proposed method. Following convention, we consider only
the computation phase for a time cost because the configuration
phase contains only data-independent processes. For simplicity,
we use the following notations: ğ‘=Ã
ğ‘‘ğ‘ğ‘‘, ğ‘€=Ã
ğ‘‘ğ‘€ğ‘‘, ğ‘=Ã
ğ‘‘ğ‘ğ‘‘, ğ‘=Ã
ğ‘‘ğ‘ğ‘‘, andğ‘Ÿ=Ã
ğ‘‘ğ‘Ÿğ‘‘,whereğ‘‘=1,2,Â·Â·Â·,ğ·.
The estimation (4) involves matrix multiplications (5) for each
ğ’ŒâˆˆÃ
ğ‘‘[ğ‘ğ‘‘]. Without loss of generality, we assume that the opti-
mal parenthesization is given in the order Ã—1,Ã—2,Â·Â·Â·,Ã—ğ·, which
requiresğ‘‚(ğ‘Ÿ1ğ‘1Â·Â·Â·ğ‘ğ·+ğ‘Ÿ1ğ‘Ÿ2ğ‘2Â·Â·Â·ğ‘ğ·+Â·Â·Â·+ğ‘Ÿ1Â·Â·Â·ğ‘Ÿğ·ğ‘ğ·)opera-
tions. Then, the total cost of computing ğ“’(ğ’Œ)for all ğ’Œis given by
ğ‘‚(ğ‘ğ‘ğ‘Ÿ)=ğ‘‚(ğ‘ğ‘Ÿ)since
ğ‘(ğ‘Ÿ1ğ‘1Â·Â·Â·ğ‘ğ·+ğ‘Ÿ1ğ‘Ÿ2ğ‘2Â·Â·Â·ğ‘ğ·+Â·Â·Â·+ğ‘Ÿ1Â·Â·Â·ğ‘Ÿğ·ğ‘ğ·)
=ğ‘ğ‘ğ‘Ÿ
ğ‘Ÿ2Â·Â·Â·ğ‘Ÿğ·+ğ‘ğ‘Ÿ
ğ‘1ğ‘Ÿ3Â·Â·Â·ğ‘Ÿğ·+Â·Â·Â·+ğ‘ğ‘Ÿ
ğ‘1Â·Â·Â·ğ‘ğ·âˆ’1
â‰¤ğ‘ğ‘ğ‘Ÿ(1+1/2+Â·Â·Â·+ 1/2ğ·âˆ’1)<2ğ‘ğ‘ğ‘Ÿ,
forğ‘Ÿğ‘‘â‰¥1andğ‘ğ‘‘â‰¥2. We next perform ğ‘ŸFFTs of size ğ‘to calculate
Ë†ğ‘(ğ’‹)
ğ’, which takes ğ‘‚(ğ‘Ÿğ‘logğ‘)time. The remaining computation (6)
requiresğ‘‚(ğ‘Ÿ)operations for each ğ’, giving anğ‘‚(ğ‘€ğ‘Ÿ)running time.
Hence, the time cost of Auto-MPFT can be written as
ğ‘‚((ğ‘+ğ‘logğ‘+ğ‘€)ğ‘Ÿ). (7)
 
2331Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Now let us consider the objective function (7) for each dimension
ğ‘‘=1,2,Â·Â·Â·,ğ·. Recall that ğ‘ğ‘‘andğ‘€ğ‘‘are input and output size
descriptors, respectively, ğ‘ğ‘‘is a positive divisor of ğ‘ğ‘‘, andğ‘Ÿğ‘‘is the
number of approximating terms depending on given tolerance ğœ–.
Unfortunately, the variables ğ‘ğ‘‘andğ‘Ÿğ‘‘take discrete integer values,
precluding directly using the continuous optimization methods.
Moreover, the constraint that ğ‘ğ‘‘dividesğ‘ğ‘‘results in an irregular
domain ofğ‘ğ‘‘depending on the value of ğ‘ğ‘‘. To tackle these prob-
lems, we slightly relax the constraints, extending the domain of
ğ‘ğ‘‘andğ‘Ÿğ‘‘to the positive real numbers and discarding the neces-
sity thatğ‘ğ‘‘dividesğ‘ğ‘‘. This leads to the following optimization
problem (from now on we omit the subscript ğ‘‘for brevity):
Problem 1. Givenğ‘,ğ‘€âˆˆN, andğœ–>0,
argmin
ğ‘,ğ‘Ÿ>0(ğ‘+ğ‘logğ‘+ğ‘€)ğ‘Ÿ
ğ‘ .ğ‘¡. ğœ‰(ğœ–,ğ‘Ÿ)â‰¥ğ‘€/ğ‘ â–¡
The challenge of this optimization problem is mainly due to the
functionğœ‰, which cannot be expressed in an explicit form. Thus, we
propose reformulating the problem into an unconstrained convex
optimization problem by approximating the constraint function.
3.2.2 Approximating Error. The main idea of our optimization pro-
cess is to approximate the constraint function ğœ‰(ğœ–,ğ‘Ÿ)in Problem 1
and derive an explicit reformulation of the optimization problem.
Given a tolerance 0<ğœ–<1, denote
ğ‘Ÿâˆ—=min{ğ‘ŸâˆˆN:ğœ‰(ğœ–,ğ‘Ÿ)â‰¥ğ‘€/ğ‘}, (8)
andğ‘=ğœ‰(ğœ–,ğ‘Ÿâˆ—) â‰¥ğ‘€/ğ‘. Consider the best polynomial approxi-
mation toğ‘’ğ‘ğœ‹ğ‘–ğ‘¥on|ğ‘¥|â‰¤1(this is equivalent to approximating
ğ‘’ğœ‹ğ‘–ğ‘¥on|ğ‘¥| â‰¤ğ‘), and its Taylor series ğ‘’ğ‘ğœ‹ğ‘–ğ‘¥=Ã
ğ‘›â‰¥0(ğ‘ğœ‹ğ‘–ğ‘¥)ğ‘›/ğ‘›!.
For a non-negative integer ğ‘›, theğ‘›-th power of ğ‘¥can be written
as follows [ 7]:ğ‘¥ğ‘›=1
2ğ‘›âˆ’1 ğ‘‡ğ‘›(ğ‘¥)+ ğ‘›
1ğ‘‡ğ‘›âˆ’2(ğ‘¥)+ ğ‘›
2ğ‘‡ğ‘›âˆ’4(ğ‘¥)+Â·Â·Â·,
whereğ‘‡ğ‘›(ğ‘¥)is the Chebyshev polynomial of degree ğ‘›(for evenğ‘›,
the coefficient of ğ‘‡0(ğ‘¥)is divided by 2). Then, we have
ğ‘’ğ‘ğœ‹ğ‘–ğ‘¥=âˆ‘ï¸
ğ‘›â‰¥0(ğ‘ğœ‹ğ‘–ğ‘¥)ğ‘›
ğ‘›!=âˆ‘ï¸
ğ‘›â‰¥0(ğ‘ğœ‹ğ‘–)ğ‘›
ğ‘›!1
2ğ‘›âˆ’1âŒŠğ‘›/2âŒ‹âˆ‘ï¸
ğ‘˜=0ğ‘›
ğ‘˜
ğ‘‡ğ‘›âˆ’2ğ‘˜(ğ‘¥).
Dropping the ğ‘‡ğ‘›âˆ’2ğ‘˜terms forğ‘›âˆ’2ğ‘˜â‰¥ğ‘Ÿgives the Chebyshev
approximation of degree less than ğ‘Ÿ. Letğœ‚(ğ‘Ÿ)be the maximum
error of the approximation, so that ğœ‰(ğœ‚(ğ‘Ÿ),ğ‘Ÿ)=ğ‘. Explicitly,
ğœ‚(ğ‘Ÿ)â‰”max
|ğ‘¥|â‰¤1âˆ‘ï¸
ğ‘›âˆ’2ğ‘˜â‰¥ğ‘Ÿ(ğ‘ğœ‹ğ‘–)ğ‘›
ğ‘›!1
2ğ‘›âˆ’1ğ‘›
ğ‘˜
ğ‘‡ğ‘›âˆ’2ğ‘˜(ğ‘¥).
Substituting ğ‘›â†ğ‘›+2ğ‘˜, we can rewrite this as
ğœ‚(ğ‘Ÿ)=max
|ğ‘¥|â‰¤1âˆ‘ï¸
ğ‘›â‰¥ğ‘Ÿâˆ‘ï¸
ğ‘˜â‰¥02ğ‘–ğ‘›ğ‘ğœ‹
2ğ‘›+2ğ‘˜(âˆ’1)ğ‘˜
ğ‘˜!(ğ‘›+ğ‘˜)!ğ‘‡ğ‘›(ğ‘¥).
We may express the involved terms using the Bessel function [ 1],
ğ½ğ‘›(ğ‘¤)=Ã
ğ‘˜â‰¥0(âˆ’1)ğ‘˜
ğ‘˜!(ğ‘›+ğ‘˜)! ğ‘¤
2ğ‘›+2ğ‘˜,whereğ‘›is a non-negative integer
andğ‘¤âˆˆR, which implies ğœ‚(ğ‘Ÿ)=max|ğ‘¥|â‰¤1Ã
ğ‘›â‰¥ğ‘Ÿ2ğ‘–ğ‘›ğ½ğ‘›(ğ‘ğœ‹)ğ‘‡ğ‘›(ğ‘¥).
We now assume that the number ğ‘Ÿof approximating terms has a
certain lower bound, namely ğ‘Ÿâ‰¥ğ‘ğœ‹âˆ’1. This is a reasonable
assumption due to the following lemma:
Lemma 1. Givenğ‘¤>0, the sequence ğ‘›â†¦â†’ğ½ğ‘›(ğ‘¤)is strictly
decreasing for ğ‘›â‰¥ğ‘¤âˆ’1and converges to zero as ğ‘›tends toâˆ.â–¡Proof. Letğœˆbe an integer such that ğœˆâ‰¥ğ‘¤âˆ’1. We should show
thatğ½ğœˆ+1(ğ‘¤)<ğ½ğœˆ(ğ‘¤)holds. Since the Bessel function satisfies the
recurrence relation
ğ½ğ‘›(ğ‘¤)=2(ğ‘›+1)
ğ‘¤ğ½ğ‘›+1(ğ‘¤)âˆ’ğ½ğ‘›+2(ğ‘¤),âˆ€ğ‘›â‰¥0, (9)
the inequality is equivalent to ğ½ğœˆ+1(ğ‘¤)<2(ğœˆ+1)
ğ‘¤ğ½ğœˆ+1(ğ‘¤)âˆ’ğ½ğœˆ+2(ğ‘¤),
or
ğ½ğœˆ+2(ğ‘¤)<2(ğœˆ+1)
ğ‘¤âˆ’1
ğ½ğœˆ+1(ğ‘¤).
Replacingğ½ğœˆ+1(ğ‘¤)using the recurrence relation again yields
ğ½ğœˆ+3(ğ‘¤)<2(ğœˆ+2)
ğ‘¤âˆ’1
2(ğœˆ+1)
ğ‘¤âˆ’1
ğ½ğœˆ+2(ğ‘¤).
In general, we obtain the following equivalent condition:
ğ½ğœˆ+ğ‘ +1(ğ‘¤)<ğ‘€ğ‘ Â·ğ½ğœˆ+ğ‘ (ğ‘¤),
whereğ‘€0=1andğ‘€ğ‘ =2(ğœˆ+ğ‘ )
ğ‘¤âˆ’1
ğ‘€ğ‘ âˆ’1forğ‘ â‰¥1. A simple induction
shows thatğ‘€ğ‘ â‰¥1for allğ‘ because
ğ‘€ğ‘ =2(ğœˆ+ğ‘ )
ğ‘¤âˆ’1
ğ‘€ğ‘ âˆ’1â‰¥2(ğœˆ+1)
ğ‘¤âˆ’1
ğ‘€ğ‘ âˆ’1â‰¥2âˆ’1
ğ‘€ğ‘ âˆ’1â‰¥1
provided that ğ‘€ğ‘ âˆ’1â‰¥1. Thus, it is sufficient to prove that there
exists an integer ğ‘ â‰¥0such thatğ½ğœˆ+ğ‘ +1(ğ‘¤)<ğ½ğœˆ+ğ‘ (ğ‘¤). Now
ğ½ğ‘›(ğ‘¤)=1
ğ‘›!ğ‘¤
2ğ‘›âˆ‘ï¸
ğ‘˜â‰¥0ğ‘›!
ğ‘˜!(ğ‘›+ğ‘˜)!
âˆ’ğ‘¤2
4ğ‘˜
âˆ¼1
ğ‘›!ğ‘¤
2ğ‘›
forğ‘›â‰«ğ‘¤2, hence
ğ½ğœˆ+ğ‘ +1(ğ‘¤)
ğ½ğœˆ+ğ‘ (ğ‘¤)âˆ¼1
ğœˆ+ğ‘ +1ğ‘¤
2
<1
for sufficiently large ğ‘ . This completes the proof. â–¡
In other words, the condition ğ‘Ÿâ‰¥ğ‘ğœ‹âˆ’1together with Lemma 1
ensures that the magnitude |2ğ‘–ğ‘›ğ½ğ‘›(ğ‘ğœ‹)|of coefficients in the Cheby-
shev approximation gap strictly decreases. Thus, we can estimate
the extreme points of the function ğ‘¥â†¦â†’Ã
ğ‘›â‰¥ğ‘Ÿ2ğ‘–ğ‘›ğ½ğ‘›(ğ‘ğœ‹)ğ‘‡ğ‘›(ğ‘¥)by
the extreme points ğ‘¥ğ‘˜of the dominant term ğ‘‡ğ‘Ÿ(ğ‘¥):
ğ‘¥ğ‘˜=cos(ğ‘˜ğœ‹/ğ‘Ÿ), ğ‘˜=0,1,Â·Â·Â·,ğ‘Ÿ.
Furthermore, it is easy to check that the magnitude of extrema
ofÃ
ğ‘›â‰¥ğ‘Ÿ2ğ‘–ğ‘›ğ½ğ‘›(ğ‘ğœ‹)ğ‘‡ğ‘›(ğ‘¥)peaks at around ğ‘¥=0, which implies
ğœ‚(ğ‘Ÿ)â‰ˆ|Ã
ğ‘›â‰¥ğ‘Ÿ2ğ‘–ğ‘›ğ½ğ‘›(ğ‘ğœ‹)ğ‘‡ğ‘›(ğ‘¥âŒŠğ‘Ÿ/2âŒ‹)|, or
ğœ‚(ğ‘Ÿ)â‰ˆ(Ã
ğ‘›â‰¥ğ‘Ÿ2ğ‘–ğ‘›ğ½ğ‘›(ğ‘ğœ‹)cos(ğœ‹ğ‘›/2)ğ‘Ÿ: evenÃ
ğ‘›â‰¥ğ‘Ÿ2ğ‘–ğ‘›ğ½ğ‘›(ğ‘ğœ‹)cos(ğœ‹ğ‘›(ğ‘Ÿâˆ’1)/2ğ‘Ÿ)ğ‘Ÿ: odd(10)
usingğ‘‡ğ‘›(cosğœƒ)=cos(ğ‘›ğœƒ). Our next goal is to prove that ğœ‚(ğ‘Ÿ)is
bounded above as in Lemma 2. We then use the upper bound to
derive an approximate relation between the parameters ğ‘andğ‘Ÿ.
Lemma 2. Ifğ‘Ÿâ‰¥2, the approximation error function ğœ‚(ğ‘Ÿ)satisfies
ğœ‚(ğ‘Ÿ)â‰¤ğ‘ˆ(ğ‘Ÿ)â‰”2âˆš
17
4âˆ’âˆšğ‘’ğ¶ğ‘Ÿ
ğ‘Ÿ!ğ‘’âˆ’ğ¶2
ğ‘Ÿ+1(ğ¶=ğ‘ğœ‹/2). â–¡
Proof. See Supplement A.1. â–¡
 
2332KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
3.2.3 Finding a Relation Between ğ‘andğ‘Ÿ.Assume that an integer
ğ‘Ÿ0â‰¥2satisfies the equation ğ‘ˆ(ğ‘Ÿ0)=ğœ–. Then
ğœ‚(ğ‘Ÿ0)â‰¤ğ‘ˆ(ğ‘Ÿ0)=ğœ–=ğœ‚(ğ‘Ÿâˆ—),
where the last equality holds since ğœ‰(ğœ–,ğ‘Ÿâˆ—)=ğ‘=ğœ‰(ğœ‚(ğ‘Ÿâˆ—),ğ‘Ÿâˆ—). Note
thatğœ‚(ğ‘Ÿ)is non-decreasing by definition, so ğ‘Ÿâˆ—â‰¤ğ‘Ÿ0. This implies
that solving the equation
ğ‘ˆ(ğ‘Ÿ)=ğœ– (11)
and rounding down the solution Ë†ğ‘ŸâˆˆRgives an estimate of ğ‘Ÿâˆ—âˆ¼âŒŠË†ğ‘ŸâŒ‹.
Unfortunately, (11) does not have an algebraic solution due to the
presence of factorial term. To address this problem, we employ the
fixed-point iteration method to compute an approximate solution of
the equation. Specifically, we consider ğ‘ˆto be a function of ğ¶and
find an implicit expression of ğ‘Ÿwith respect to ğ¶. By this technique,
we can derive an approximate relation ğ‘(ğ‘Ÿ)which denotes the value
ofğ‘depending on ğ‘Ÿ. Lettingğ›¼=4âˆ’âˆšğ‘’
2âˆš
17, we write (11) as follows:
ğ¶ğ‘Ÿ
ğ›¼ğ‘Ÿ!ğ‘’âˆ’ğ¶2
ğ‘Ÿ+1=ğœ–â‡â‡’ğ¶ğ‘Ÿ=ğ›¼ğœ–ğ‘Ÿ!Â·ğ‘’ğ¶2
ğ‘Ÿ+1â‡â‡’ğ¶=(ğ›¼ğœ–ğ‘Ÿ!)1
ğ‘Ÿğ‘’ğ¶2
ğ‘Ÿ(ğ‘Ÿ+1).
Defineğ‘“(ğ‘¥)â‰”(ğ›¼ğœ–ğ‘Ÿ!)1
ğ‘Ÿğ‘’ğ‘¥2
ğ‘Ÿ(ğ‘Ÿ+1)forğ‘¥âˆˆR. Then, the problem be-
comes computing a fixed point of ğ‘“. Sinceğ‘“â€²(ğ‘¥)=(ğ›¼ğœ–ğ‘Ÿ!)1/ğ‘Ÿ
ğ‘Ÿ(ğ‘Ÿ+1)2ğ‘¥ğ‘’ğ‘¥2
ğ‘Ÿ(ğ‘Ÿ+1),
we haveğ‘“â€²(0)=0. Moreover, ğ‘“â€²(ğ¶)=2ğ¶
ğ‘Ÿ(ğ‘Ÿ+1)ğ‘“(ğ¶)=2ğ¶2
ğ‘Ÿ(ğ‘Ÿ+1)pro-
vided thatğ¶is a fixed point of ğ‘“. It follows from ğ¶â‰¤(ğ‘Ÿ+1)/2and
ğ‘Ÿâ‰¥2thatğ‘“â€²(ğ¶)=2ğ¶2
ğ‘Ÿ(ğ‘Ÿ+1)â‰¤(ğ‘Ÿ+1)2
2ğ‘Ÿ(ğ‘Ÿ+1)=ğ‘Ÿ+1
2ğ‘Ÿâ‰¤3
4.Becauseğ‘“â€²(ğ‘¥)is
non-decreasing for ğ‘¥â‰¥0, there exist ğ¿<1andğ›¿>0such that
|ğ‘“â€²(ğ‘¥)|â‰¤ğ¿,âˆ€ğ‘¥âˆˆ(âˆ’ğ›¿,ğ¶+ğ›¿).This implies that ğ‘“is a contraction
mapping function on (âˆ’ğ›¿,ğ¶+ğ›¿), so the fixed-point iteration
ğ¶0âˆˆ(âˆ’ğ›¿,ğ¶+ğ›¿), ğ¶ğ‘›+1=ğ‘“(ğ¶ğ‘›), ğ‘›=0,1,2,Â·Â·Â·
converges to the unique fixed point ğ¶by the Banach fixed-point
theorem [ 3]. We setğ¶0=0and estimate ğ¶by the result of the
second iteration of the algorithm:
ğ¶âˆ¼ğ¶2=ğ‘“(ğ‘“(0))=ğ‘“((ğ›¼ğœ–ğ‘Ÿ!)1
ğ‘Ÿ)=(ğ›¼ğœ–ğ‘Ÿ!)1
ğ‘Ÿğ‘’1
ğ‘Ÿ(ğ‘Ÿ+1)(ğ›¼ğœ–ğ‘Ÿ!)2/ğ‘Ÿ
.
We now assume that ğ‘âˆ¼ğ‘€/ğ‘, which is reasonable due to the
definition of ğ‘Ÿâˆ—in (8). This leads to the following approximate
relation between the parameters ğ‘andğ‘Ÿ:
ğ‘âˆ¼ğ‘€
ğ‘=ğœ‹ğ‘€
2ğ¶âˆ’1âˆ¼ğœ‹ğ‘€
2(ğ›¼ğœ–ğ‘Ÿ!)âˆ’1
ğ‘Ÿğ‘’âˆ’1
ğ‘Ÿ(ğ‘Ÿ+1)(ğ›¼ğœ–ğ‘Ÿ!)2/ğ‘Ÿ
.
3.2.4 Convexity of the Objective Function. We have shown that the
parameterğ‘can be expressed in terms of ğ‘Ÿwith the relation,
ğ‘(ğ‘Ÿ)â‰”ğœ‹ğ‘€
2(ğ›¼ğœ–ğ‘Ÿ!)âˆ’1
ğ‘Ÿğ‘’âˆ’1
ğ‘Ÿ(ğ‘Ÿ+1)(ğ›¼ğœ–ğ‘Ÿ!)2/ğ‘Ÿ
, ğ›¼=4âˆ’âˆšğ‘’
2âˆš
17. (12)
By employing this relation, we reduce the objective function of
Problem 1 into a functional form dependent on only ğ‘Ÿ, removing
the inequality constraint:
Problem 2. Givenğ‘,ğ‘€âˆˆN, andğœ–>0,
argmin
ğ‘Ÿâ‰¥1(ğ‘+ğ‘(ğ‘Ÿ)logğ‘(ğ‘Ÿ)+ğ‘€)ğ‘Ÿ â–¡
In the following theorem, we prove that the objective function in
this problem is convex for ğ‘Ÿâ‰¥1. Consequently, Problem 2 becomes
an unconstrained convex optimization problem.Theorem 3. The objective function ğ‘Ÿâ†¦â†’(ğ‘+ğ‘(ğ‘Ÿ)logğ‘(ğ‘Ÿ)+ğ‘€)ğ‘Ÿ
of Problem 2 is convex for ğ‘Ÿâ‰¥1. â–¡
Proof. See Supplement A.2. â–¡
The convexity of the objective function guarantees the conver-
gence of second-order optimization techniques such as Newtonâ€™s
method. After the optimal solution ğ‘Ÿâˆ—that minimizes the objective
function is found, we use the function ğ‘(ğ‘Ÿ)to approximate the
optimalğ‘âˆ—=ğ‘(ğ‘Ÿâˆ—)and select the nearest divisor of ğ‘toğ‘âˆ—, which
replaces the manual selection process. The automatic configuration
phase of Auto-MPFT is outlined in Algorithm 1.
3.3 Theoretical Analysis
We present theoretical analysis on the time and space complexities
of Auto-MPFT and its approximation bound.
3.3.1 Time Complexity. In Section 3.2.1, we have already seen that
the time cost of Auto-MPFT can be expressed as ğ‘‚((ğ‘+ğ‘logğ‘+
ğ‘€)ğ‘Ÿ). Note that ğ‘=Ã
ğ‘‘ğ‘ğ‘‘is an input size, ğ‘€=Ã
ğ‘‘ğ‘€ğ‘‘is an
output size, ğ‘=Ã
ğ‘‘ğ‘ğ‘‘, andğ‘Ÿ=Ã
ğ‘‘ğ‘Ÿğ‘‘, whereğ‘ğ‘‘is a divisor of ğ‘ğ‘‘
andğ‘Ÿğ‘‘is an approximation order given a tolerance ğœ–. However, the
values ofğ‘andğ‘Ÿin the above time cost are internally determined
by the configuration phase (Algorithm 1). As a result, users cannot
directly find out these values, making it inconvenient to use the
time cost function. To address this limitation, we transform the
time cost into a functional form that depends only on ğ‘,ğ‘€, andğœ–,
which are the inputs of Auto-MPFT. We first present the following
two lemmas and employ them for the proof of Theorem 6.
Lemma 4. For eachğ‘‘=1,2,Â·Â·Â·,ğ·, we have the asymptotic equa-
tionğ‘Ÿğ‘‘=ğ‘‚(log(1/ğœ–)). â–¡
Proof. Recall that by Equation (11), we have the following as-
ymptotic equation between ğœ–andğ‘Ÿğ‘‘:
ğœ–âˆ¼ğ‘ˆ(ğ‘Ÿğ‘‘)=2âˆš
17
4âˆ’âˆšğ‘’ğ¶ğ‘Ÿğ‘‘
ğ‘Ÿğ‘‘!ğ‘’âˆ’ğ¶2
ğ‘Ÿğ‘‘+1.
Then there exist ğµ1,ğµ2>0such that for sufficiently large ğ‘Ÿğ‘‘,
ğœ–<ğµ1Â·ğ¶ğ‘Ÿğ‘‘
ğ‘Ÿğ‘‘!ğ‘’âˆ’ğ¶2
ğ‘Ÿğ‘‘+1<ğµ1Â·ğ¶ğ‘Ÿğ‘‘
ğ‘Ÿğ‘‘!<ğµ2
ğ‘’ğ‘Ÿğ‘‘.
It follows that ğ‘’ğ‘Ÿğ‘‘<ğµ2/ğœ–, and thusğ‘Ÿğ‘‘=ğ‘‚(log(1/ğœ–)). â–¡
Lemma 5. Ifğ‘ğ‘‘isğ‘ğ‘‘-smooth for some ğ‘ğ‘‘â‰¥2(that is, none of
prime factors of ğ‘ğ‘‘is greater than ğ‘ğ‘‘) and 1â‰¤ğ‘€ğ‘‘â‰¤ğ‘ğ‘‘, then there
exists a divisor ğ‘ğ‘‘ofğ‘ğ‘‘satisfyingğ‘ğ‘‘=Î˜(ğ‘€ğ‘‘). â–¡
Proof. Following the proof of Theorem 3 of [ 20], we prove that
there exists a divisor ğ‘ğ‘‘ofğ‘ğ‘‘such thatğ‘€ğ‘‘/âˆšï¸
ğ‘ğ‘‘â‰¤ğ‘ğ‘‘<âˆšï¸
ğ‘ğ‘‘ğ‘€ğ‘‘.
Suppose that none of ğ‘ğ‘‘â€™s divisors belongs to [ğ‘€ğ‘‘/âˆšï¸
ğ‘ğ‘‘,âˆšï¸
ğ‘ğ‘‘ğ‘€ğ‘‘).
Let1=ğ‘1<ğ‘2<Â·Â·Â·<ğ‘ğ‘›=ğ‘ğ‘‘be the enumeration of all
positive divisors of ğ‘ğ‘‘in increasing order. It is clear that ğ‘1<âˆšï¸
ğ‘ğ‘‘ğ‘€ğ‘‘andğ‘€ğ‘‘/âˆšï¸
ğ‘ğ‘‘<ğ‘ğ‘›sinceğ‘ğ‘‘â‰¥2and1â‰¤ğ‘€ğ‘‘â‰¤ğ‘ğ‘‘. Then,
there exists an ğ‘–âˆˆ {1,2,Â·Â·Â·,ğ‘›âˆ’1}so thatğ‘ğ‘–<ğ‘€ğ‘‘/âˆšï¸
ğ‘ğ‘‘and
ğ‘ğ‘–+1â‰¥âˆšï¸
ğ‘ğ‘‘ğ‘€ğ‘‘. Sinceğ‘ğ‘‘isğ‘ğ‘‘-smooth and ğ‘ğ‘–<ğ‘ğ‘‘, at least one
of2ğ‘ğ‘–,3ğ‘ğ‘–,Â·Â·Â·,ğ‘ğ‘‘ğ‘ğ‘–must be a divisor of ğ‘ğ‘‘. However, this is a
contradiction because we have ğ‘ğ‘–+1/ğ‘ğ‘–>(âˆšï¸
ğ‘ğ‘‘ğ‘€ğ‘‘)(ğ‘€ğ‘‘/âˆšï¸
ğ‘ğ‘‘)âˆ’1=
ğ‘ğ‘‘, so none of 2ğ‘ğ‘–,3ğ‘ğ‘–,Â·Â·Â·,ğ‘ğ‘‘ğ‘ğ‘–can be a divisor of ğ‘ğ‘‘, which
completes the proof. â–¡
 
2333Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Theorem 6. Forğ‘‘=1,2,Â·Â·Â·,ğ·, letğ‘ğ‘‘beğ‘ğ‘‘-smooth for some
ğ‘ğ‘‘â‰¥2. Then the time complexity of Auto-MPFT has an asymptotic
upper bound ğ‘‚((ğ‘+ğ‘€logğ‘€)(log(1/ğœ–))ğ·). â–¡
Proof. It follows that ğ‘Ÿğ‘‘=ğ‘‚(log(1/ğœ–))by Lemma 4, which
gives an upper bound for ğ‘Ÿ=Ã
ğ‘‘ğ‘Ÿğ‘‘=ğ‘‚((log(1/ğœ–))ğ·). Using
Lemma 5, we can find a divisor ğ‘ğ‘‘ofğ‘ğ‘‘such thatğ‘ğ‘‘=Î˜(ğ‘€ğ‘‘)for
allğ‘‘, resulting in ğ‘=Ã
ğ‘‘ğ‘ğ‘‘=Î˜(Ã
ğ‘‘ğ‘€ğ‘‘)=Î˜(ğ‘€). Replacing ğ‘
andğ‘Ÿin the original upper bound of the time complexity yields
ğ‘‚((ğ‘+ğ‘logğ‘+ğ‘€)ğ‘Ÿ)=ğ‘‚((ğ‘+ğ‘€logğ‘€)(log(1/ğœ–))ğ·),
hence the proof. â–¡
3.3.2 Space Complexity. DFT is frequently required to be deployed
on devices with limited performance capabilities. Thus, it is es-
sential to consider memory constraints when implementing the
algorithm in real-world applications. In Theorem 7, we prove that
the space complexity of Auto-MPFT is asymptotically bounded
by the sum of the input and output sizes, ğ‘+ğ‘€. This indicates
that Auto-MPFT is a space-optimal algorithm, requiring only the
minimum space necessary for input and output.
Theorem 7. Auto-MPFT is space-optimal, that is, the space com-
plexity of it has an asymptotic upper bound ğ‘‚(ğ‘+ğ‘€). â–¡
Proof. In the configuration phase (Algorithm 1), Auto-MPFT
stores matrices of size ğ‘Ÿğ‘‘Ã—ğ‘ğ‘‘(ğ‘‘=1,Â·Â·Â·,ğ·)for multivariate
polynomial approximation, which requires ğ‘‚(Ã
ğ‘‘ğ‘Ÿğ‘‘ğ‘ğ‘‘)space cost.
In the computation phase (Algorithm 2), we need ğ‘‚(ğ‘)space to
read an input data array (line 1 in Algorithm 2), ğ‘‚(ğ‘ğ‘Ÿ)space for
polynomial approximation results (line 2 in Algorithm 2), and ğ‘‚(ğ‘€)
space to save an output (lines 4-6 in Algorithm 2), which sum up
toğ‘‚(ğ‘+ğ‘ğ‘Ÿ+ğ‘€). Typically, the number ğ‘Ÿğ‘‘is much smaller than
ğ‘ğ‘‘andğ‘ğ‘‘ifğ‘ğ‘‘=ğ‘ğ‘‘ğ‘ğ‘‘is sufficiently large, so we may assume
that (1)ğ‘‚(Ã
ğ‘‘ğ‘Ÿğ‘‘ğ‘ğ‘‘)=ğ‘œ(Ã
ğ‘‘ğ‘ğ‘‘ğ‘ğ‘‘)=ğ‘œ(Ã
ğ‘‘ğ‘ğ‘‘)=ğ‘œ(ğ‘)and (2)
ğ‘‚(ğ‘ğ‘Ÿ)=ğ‘œ(ğ‘ğ‘)=ğ‘œ(ğ‘). These lead to a total of
ğ‘‚(Ã
ğ‘‘ğ‘Ÿğ‘‘ğ‘ğ‘‘+ğ‘+ğ‘ğ‘Ÿ+ğ‘€)=ğ‘‚(ğ‘+ğ‘€)
space complexity of Auto-MPFT. â–¡
3.3.3 Approximation Bound. We present a theoretical bound for
the approximation of the polynomial P. The estimated Fourier
coefficient of ğ’‚is denoted asE(Ë†ğ’‚). According to Theorem 8, the
approximation bound within the target range is contingent on the
data-specific total weight âˆ¥ğ’‚âˆ¥1of the original array and the given
toleranceğœ–, whereâˆ¥Â·âˆ¥ 1represents the â„“1norm. It is important to
note thatğœ–influences the number ğ‘Ÿof approximating terms (see
Lemma 4), consequently affecting the error bound âˆ¥Ë†ğ’‚âˆ’E( Ë†ğ’‚)âˆ¥Bğ,ğ‘´.
This shows that, by adjusting ğœ–accordingly, Fourier coefficients can
be computed with arbitrary numerical precision using Auto-MPFT.
Theorem 8. Given a sufficiently small tolerance ğœ–>0, the esti-
mated Fourier coefficient E(Ë†ğ’‚)in (4) satisfies
âˆ¥Ë†ğ’‚âˆ’E( Ë†ğ’‚)âˆ¥Bğ,ğ‘´â‰¤âˆ¥ğ’‚âˆ¥1Â·(2ğ·âˆ’1)ğœ–,
whereâˆ¥Â·âˆ¥ğ‘…denotes the uniform norm restricted to set ğ‘…âŠ†Rğ·.â–¡
Proof. See Supplement A.3. â–¡Table 1: Summary of datasets.
Dataset Type # of Images Size
{Sğ‘›}15
ğ‘›=8Synthetic 1K 2ğ‘›Ã—2ğ‘›
Cityscapes1Real-world 5K 2048Ã—1024
ADE20K2Real-world 20K 2048Ã—2048
DF2K3Real-world 3K 2040Ã—1536
RiceLeaf4Real-world 3.3K 3120Ã—3120
Bird5Real-world 306 6000Ã—4000
4 Experiments
Through experiments, we answer the following questions:
Q1Running time (Section 4.2). How rapidly does Auto-MPFT
compute a part of Fourier coefficients compared to baselines
without compromising accuracy?
Q2Automatic hyperparameter selection (Section 4.3). How
accurately and quickly does the optimization-based algorithm
find the optimal hyperparameter of Auto-MPFT?
Q3Impact of varying precision (Section 4.4). What impact does
varying precision settings have on the runtime of Auto-MPFT?
4.1 Experimental Setup
Machine. Our system utilizes an Intel Core i7-10700KF @ 3.80GHz
processor paired with 32GB of RAM.
Datasets. Although our proposed method can be applied to any
multidimensional data, we focus our experiments on two-dimensional
image datasets for clarity of presentation. Table 1 summarizes the
datasets used in our experiments. For ğ‘›=8,Â·Â·Â·,15,Sğ‘›contains
1,000 matrices of size 2ğ‘›Ã—2ğ‘›with elements being random real num-
bers ranging from 0to1. Cityscapes and ADE20K offer a wide range
of indoor and outdoor scene images with detailed scene segmenta-
tion labels, supporting semantic segmentation research. DF2K is
an image dataset for image super-resolution and restoration tasks
which is composed of around 3,000 2k resolution images. RiceLeaf
contains about 3,300 4k images of rice leaves for rice disease de-
tection. Bird is a dataset for bird species classification task and
contains 306 high-resolution images of birds. Note that the images
in each dataset were resized to the same resolution.
Baselines. We compare Auto-MPFT with PFT and Pruned FFT
as well as optimized FFT libraries, FFTW and Intel Math Kernel
Library. All of the methods are implemented using C++.
(1)FFTW: FFTW6[11,12] is among the fastest publicly available
FFT implementations with hardware-specific optimizations. We
employ the optimized version of FFTW 3.3.5, without including
the pre-processing for configuration as the run-time cost.
(2)MKL: Intel Math Kernel Library7(MKL), known for its opti-
mized mathematical functions such as FFT, often outperforms
FFTW in terms of running time. We conduct all the experiments
using an Intel processor to ensure optimal performance.
1https://www.cityscapes-dataset.com/
2https://groups.csail.mit.edu/vision/datasets/ADE20K/
3https://www.kaggle.com/datasets/thaihoa1476050/df2k-ost
4https://www.kaggle.com/datasets/shayanriyaz/riceleafs
5https://www.kaggle.com/datasets/akash2907/bird-species-classification
6http://www.fftw.org/index.html
7https://software.intel.com/mkl
 
2334KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
(3)Pruned FFT: Pruned FFT8[2,16,17,28,30] is a pruned variant
of FFT specialized for rapid computation of specific part of an
output, utilizing FFTW as a subroutine.
(4)PFT: PFT9[20] is the current state-of-the-art algorithm for one-
dimensional partial Fourier transform. For multidimensional
data, PFT is applied for each axis of the data.
Measure. We opt for single-precision floating-point format for all
experiments. The tolerance ğœ–is adjusted to maintain a relative â„“2
error below 10âˆ’6, thereby ensuring that the estimated coefficients
possess at least 6 significant figures across all methods. Explicitly,
Relativeâ„“2Error=âˆšï¸„Ã
ğ‘šâˆˆB|Ë†ğ‘ğ‘šâˆ’E( Ë†ğ‘)ğ‘š|2
Ã
ğ‘šâˆˆB|Ë†ğ‘ğ‘š|2<10âˆ’6,
where Ë†ğ’‚is the actual Fourier coefficient, E(Ë†ğ’‚)is the estimation of
Ë†ğ’‚, andBis the target range.
4.2 Running Time (Q1)
The running time of Auto-MPFT is measured across synthetic and
real-world datasets, with variations in input and output sizes.
4.2.1 Synthetic Datasets. We generate 1,000 random synthetic ma-
trices of size 2ğ‘›Ã—2ğ‘›for eachğ‘›=8,Â·Â·Â·,15, and evaluate the average
running time of Auto-MPFT and competitors for all the matrices
with different settings.
Running time vs. input size. We fix the target range to be
26Ã—26Fourier coefficients centered at the origin and evaluate the
average running time vs. input sizes 28Ã—28,Â·Â·Â·,215Ã—215. In Figure
3(a), the running time of the five algorithms is illustrated concerning
varying input sizes. We observe that Auto-MPFT outperforms the
baselines in most cases where the output has a sufficiently smaller
size than the input. As a result, Auto-MPFT achieves a speedup of
up to 4.7Ã—compared to the baselines. Note that when ğ‘€is very
close toğ‘, the time cost of Auto-MPFT tends to ğ‘‚(ğ‘+ğ‘logğ‘)
according to Theorem 6, thus it exhibits a slightly slower speed
than FFT that has an ğ‘‚(ğ‘logğ‘)time complexity.
Running time vs. output size. In the next setting, we fix the
input size to ğ‘=215Ã—215and evaluate the average running time
vs. output sizes 25Ã—25,Â·Â·Â·,213Ã—213. Figure 3(b) shows the results,
where Auto-MPFT consistently outperforms PFT and Pruned FFT,
achieving up to 3.3Ã—speedup. We also observe that the running
times of the full FFT methods (MKL and FFTW) do not benefit from
the information of output size.
4.2.2 Real-World Datasets. We evaluate Auto-MPFT on the five
real-world datasets with output sizes 24Ã—24,Â·Â·Â·,28Ã—28for
Cityscapes, ADE20K, and DF2K, and 24Ã—24,Â·Â·Â·,29Ã—29for Rice-
Leaf and Bird. As illustrated in Figure 4, Auto-MPFT outperforms
the competitors across all datasets, delivering speedups of up to
7.6Ã—. Notably, PFT shows low efficiency especially when the size
of the input is relatively small (Cityscapes, ADE20K, and DF2K),
which is not the case for Auto-MPFT. These results clearly show
the robustness of Auto-MPFT in diverse real-world settings.
8http://www.fftw.org/pruned.html
9https://github.com/snudatalab/PFT
2829210211212213214215
Data Points (log scale)101
100Performance (log scale)
Model Performance Comparison
Auto-MPFT (proposed) MKL FFTW PFT Pruned FFT
2829210211212213214215
Input size101
100101102103Running time (ms)
4.7x(
a) Running time vs. input size
2526272829210211212213
Output size272829210211212Running time (ms)
 3.3x (
b) Running time vs. output size
Figure 3: (a) Running time vs. input size for output size 26Ã—26,
and (b) running time vs. output size for input size 215Ã—215.
The x-axis is the length of one axis of data. To ensure the
same precision across all methods, we have standardized the
relative error to be strictly below 10âˆ’6. Auto-MPFT consis-
tently outperforms the partial Fourier transform methods,
PFT and Pruned FFT. In addition, the smaller the output size
is, Auto-MPFT becomes more efficient than MKL and FFTW.
4.3 Automatic Hyperparameter Selection (Q2)
4.3.1 Accuracy of Optimization Algorithm. To evaluate the accu-
racy of our optimization algorithm for automatic hyperparameter
selection, we find the ground-truth optimal value of ğ‘for the syn-
thetic datasets{Sğ‘›}15
ğ‘›=8with varying ğ‘€, and compare it with the
estimated Ë†ğ‘by our method. Table 2 shows that our algorithm accu-
rately finds the optimal value of ğ‘in the majority of cases, and in
instances where it deviates, the margin of error remains minimal.
It is evident from these results that our optimization algorithm can
effectively replace manual processes with little sacrifice in accuracy.
4.3.2 Running Time of Optimization Algorithm. We further validate
the efficacy of our optimization algorithm by comparing its time
cost for selecting the optimal hyperparameter to that of the manual
search process. To this end, we fix the output size to 28Ã—28and vary
the input size from 29Ã—29to215Ã—215. Table 3 demonstrates that
the automatic algorithm by Auto-MPFT achieves remarkably faster
processing times compared to the manual process. This discrep-
ancy arises because the manual process necessitates executing the
entire algorithm for each ğ‘to determine its optimal value, whereas
Auto-MPFT simplifies the process by efficiently solving a convex op-
timization problem. It is also worth mentioning that the discrepancy
becomes more significant with larger input sizes.
4.4 Impact of Varying Precision (Q3)
Recall that Auto-MPFT offers the flexibility to set any numerical pre-
cision (Theorem 8). We investigate the trade-off between precision
and running time of Auto-MPFT by adjusting the tolerance ğœ–. For a
fixed input size 215Ã—215, we vary the precision target from 10âˆ’6to
10âˆ’4or10âˆ’2across various output sizes. Table 4 shows the results,
with the improvement of running times for each setting enclosed
in parentheses. The reduction reaches up to 21.2% or 49.8% when
the precision is relaxed to 10âˆ’4or10âˆ’2, respectively. This indicates
that one could gain advantages from the compromise, particularly
when speed is crucial despite a slight trade-off in precision.
 
2335Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
2829210211212213214215
Data Points (log scale)101
100Performance (log scale)
Model Performance Comparison
Auto-MPFT (proposed) MKL FFTW PFT Pruned FFT
2425262728
Output size23
22
21
2021Running time (ms)
7.6x
(
a) Cityscapes
2425262728
Output size22
21
202122Running time (ms)
5.7x (
b) ADE20K
2425262728
Output size22
21
202122Running time (ms)
6.9x (
c) DF2K
242526272829
Output size20212223Running time (ms)
2.8x (
d) RiceLeaf
242526272829
Output size22232425Running time (ms)
2.6x (
e) Bird
Figure 4: Running time vs. output size for the real-world datasets, where the x-axis is the length of one axis of the target range.
We have standardized the relative error of all methods to be strictly below 10âˆ’6. Our proposed Auto-MPFT exhibits superior
performance across all datasets, especially in cases where the output has a sufficiently smaller size than the input.
Table 2: Validation of our optimization algorithm for auto-
matic hyperparameter search. Entries without parentheses
denote that our estimate Ë†ğ‘equals to the ground-truth ğ‘, and
those with parentheses show both values in the form Ë†ğ‘(ğ‘).
Auto-MPFT successfully detects the optimal value in most
scenarios, with minor errors occurring infrequently.
Output
sizeInput
size
28Ã—229Ã—2210Ã—2211Ã—2212Ã—2213Ã—2214Ã—2215Ã—2
26Ã—2624252526262728(27)29(28)
27Ã—2725252626272728(27) 29
28Ã—28- 26262627282829
29Ã—29-
- 272727282929
210Ã—210- - - 27(28) 28282929
211Ã—211- - - - 28(29) 2929210
212Ã—212- - - - - 29(210) 210210
213Ã—213- - - - - - 210(211) 211
Table 3: Comparison of running time ( ğs) for finding the
optimal hyperparameter ğ‘using our optimization algorithm
(Auto-MPFT) vs. manual search. Manual-best denotes finding
the optimal value in a single attempt, whereas Manual-worst
involves testing all divisors of 2ğ‘›except 1and 2ğ‘›. Auto-MPFT
significantly outperforms the manual search process.
2ğ‘›Ã—2ğ‘›A
uto-MPFT Manual-best Manual-worst
29Ã—293.596 63.30
860.9
210Ã—2103.431 70.39 1273.3
211Ã—2112.829 85.94 2083.7
212Ã—2122.225 60.13 3638.6
213Ã—2131.653 79.34 6707.4
214Ã—2141.626 116.27 12508.7
215Ã—2152.971 124.26 24113.0
5
Conclusions
We propose Auto-MPFT (Automatic Multidimensional Partial Fourier
Transform), an efficient and accurate method for computing a part
of Fourier coefficients with automatic hyperparameter selection.
Auto-MPFT decomposes the original DFT into small sub-blocks
and approximates some of trigonometric functions by ChebyshevTable 4: Average running time (ms) of Auto-MPFT with input
size 215Ã—215and different precision settings. Notably, we ob-
serve up to 49.8% improvement in running time when preci-
sion requirements are relaxed, offering a beneficial trade-off,
particularly when prioritizing fast evaluations.
Output
sizePr
ecision
10âˆ’610âˆ’410âˆ’2
25Ã—25133.7
131.0 (2.0%) 126.7 (5.2%)
26Ã—26135.1 132.3 (2.0%) 127.6 (5.6%)
27Ã—27140.8 138.3 (1.8%) 133.5 (5.2%)
28Ã—28142.3 139.6 (1.9%) 135.1 (5.1%)
29Ã—29169.5 161.3 (4.9%) 148.1 (12.6%)
210Ã—210208.3 188.1 (9.7%) 158.8 (23.8%)
211Ã—211369.1 290.9 (21.2%) 201.1 (45.5%)
212Ã—212905.9 732.5 (19.1%) 463.0 (48.9%)
213Ã—2133012.5 2465.8 (18.1%) 1510.9 (49.8%)
polynomials, reducing the arithmetic cost. Furthermore, we present
an efficient optimization algorithm for finding the optimal hyperpa-
rameter of Auto-MPFT. Experiments demonstrate that Auto-MPFT
outperforms the state-of-the-art baseline models, delivering up to
7.6Ã—speedup without compromising accuracy. We also illustrate
the efficacy of our convex optimization-based algorithm in select-
ing the optimal hyperparameter of Auto-MPFT, which leads to a
significant reduction in the additional cost attributed to hyperpa-
rameter search. Future tasks involve enhancing the execution of
Auto-MPFT through additional optimization.
Acknowledgments
This work was supported by the National Research Foundation
of Korea (NRF) funded by MSIT(2022R1A2C3007921), Institute of
Information & communications Technology Planning & Evaluation
(IITP) grant funded by the Korea government (MSIT) [No.2020-
0-00894, Flexible and Efficient Model Compression Method for
Various Applications and Environments], [No.RS-2021-II211343,
Artificial Intelligence Graduate School Program (Seoul National
University)], and [No.RS-2021-II212068, Artificial Intelligence Inno-
vation Hub (Artificial Intelligence Institute, Seoul National Univer-
sity)]. U Kang is the corresponding author.
 
2336KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
References
[1]Milton Abramowitz, Irene A Stegun, et al .1972. Handbook of mathematical
functions: with formulas, graphs, and mathematical tables. Vol. 55. National
bureau of standards Washington, DC.
[2]Nir Ailon and Edo Liberty. 2009. Fast dimension reduction using Rademacher
series on dual BCH codes. Discrete & Computational Geometry 42, 4 (2009), 615.
[3]Stefan Banach. 1922. Sur les opÃ©rations dans les ensembles abstraits et leur
application aux Ã©quations intÃ©grales. Fund. math 3, 1 (1922), 133â€“181.
[4]C Boncelet. 1986. A rearranged DFT algorithm requiring N 2/6 multiplications.
IEEE Trans. Acoust. Speech Signal Process. 34, 6 (1986).
[5]E Oran Brigham. 1988. The fast Fourier transform and its applications. Prentice-
Hall, Inc.
[6]C Sidney Burrus and TW Parks. 1985. DFT/FFT and Convolution Algorithms.
Citeseer.
[7] Neal L Carothers. 1998. A short course on approximation theory. (1998).
[8]Wen-Hsiung Chen, CH Smith, and Sam Fralick. 1977. A fast computational
algorithm for the discrete cosine transform. IEEE Transactions on communications
25, 9 (1977), 1004â€“1009.
[9]James W Cooley and John W Tukey. 1965. An algorithm for the machine calcula-
tion of complex Fourier series. Mathematics of computation 19, 90 (1965).
[10] W. Fraser. 1965. A Survey of Methods of Computing Minimax and Near-Minimax
Polynomial Approximations for Functions of a Single Independent Variable. J.
ACM 12, 3 (1965), 295â€“314.
[11] Matteo Frigo and Steven G Johnson. 1998. FFTW: An adaptive software archi-
tecture for the FFT. In Proceedings of the 1998 IEEE International Conference on
Acoustics, Speech and Signal Processing, ICASSPâ€™98 (Cat. No. 98CH36181), Vol. 3.
IEEE, 1381â€“1384.
[12] M. Frigo and S. G. Johnson. 2005. The Design and Implementation of FFTW3.
Proc. IEEE 93, 2 (2005), 216â€“231.
[13] Gerald Goertzel. 1958. An algorithm for the evaluation of finite trigonometric
series. The American Mathematical Monthly 65, 1 (1958), 34â€“35.
[14] AN Hossen, Ulrich Heute, OV Shentov, and SK Mitra. 1995. Subband DFT Part II:
accuracy, complexity and applications. Signal Processing 41, 3 (1995), 279â€“294.
[15] Xiaodi Hou and Liqing Zhang. 2007. Saliency Detection: A Spectral Residual
Approach. In CVPR. IEEE Computer Society.
[16] J Markel. 1971. FFT pruning. IEEE transactions on Audio and Electroacoustics 19,
4 (1971), 305â€“311.
[17] K Nagai. 1986. Pruning the decimation-in-time FFT algorithm with frequency
shift. IEEE Trans. Acoust. Speech Signal Process. 34, 4 (1986), 1008â€“1010.
[18] Humberto Ochoa-Dominguez and Kamisetty Ramamohan Rao. 2019. Discrete
Cosine Transform. CRC Press.
[19] Alan V Oppenheim. 1999. Discrete-time signal processing. Pearson Education
India.
[20] Yong-chan Park, Jun-Gi Jang, and U Kang. 2021. Fast and accurate partial fourier
transform for time series data. In Proceedings of the 27th ACM SIGKDD Conference
on Knowledge Discovery & Data Mining. 1309â€“1318.
[21] Peng Qi, Juan Cao, Tianyun Yang, Junbo Guo, and Jintao Li. 2019. Exploiting
multi-domain visual information for fake news detection. In ICDM. IEEE.
[22] Faraz Rasheed, Peter Peng, Reda Alhajj, and Jon G. Rokne. 2009. Fourier Trans-
form Based Spatial Outlier Mining. In IDEAL, Vol. 5788. Springer, 317â€“324.
[23] Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang, Xiaoyu Kou,
Tony Xing, Mao Yang, Jie Tong, and Qi Zhang. 2019. Time-Series Anomaly
Detection Service at Microsoft. In KDD. ACM, 3009â€“3017.
[24] Herbert Robbins. 1955. A remark on Stirlingâ€™s formula. The American mathemat-
ical monthly 62, 1 (1955), 26â€“29.
[25] Tim SchlÃ¼ter and Stefan Conrad. 2010. An Approach for Automatic Sleep Stage
Scoring and Apnea-Hypopnea Detection. In ICDM. IEEE, 1007â€“1012.
[26] OV Shentov, SK Mitra, Ulrich Heute, and AN Hossen. 1995. Subband DFT Part I:
Definition, interpretation and extensions. Signal Processing 41, 3 (1995), 261â€“277.
[27] Sheng Shi, Runkai Yang, and Haihang You. 2017. A new two-dimensional Fourier
transform algorithm based on image sparsity. In ICASSP. IEEE, 1373â€“1377.
[28] D Skinner. 1976. Pruning the decimation in-time FFT algorithm. IEEE Trans.
Acoust. Speech Signal Process. 24, 2 (1976), 193â€“194.
[29] Georgey S Smirnov and Roman G Smirnov. 1999. Best uniform approximation of
complex-valued functions by generalized polynomials having restricted ranges.
Journal of approximation theory 100, 2 (1999), 284â€“303.
[30] Henrik V Sorensen and C Sidney Burrus. 1993. Efficient computation of the
DFT with only a subset of input or output points. IEEE transactions on signal
processing 41, 3 (1993), 1184â€“1200.
[31] Ting Hei Wan, Chi Wai Tsang, King Hui, and Edward Chung. 2023. Anomaly
detection of train wheels utilizing short-time Fourier transform and unsupervised
learning algorithms. Engineering Applications of Artificial Intelligence 122 (2023),
106037.
[32] George Neville Watson. 1922. A treatise on the theory of Bessel functions. Vol. 3.
The University Press.
[33] Liheng Zhang, Charu Aggarwal, and Guo-Jun Qi. 2017. Stock price prediction
via discovering multi-frequency trading patterns. In KDD. ACM, 2141â€“2149.A Supplement
A.1 Proof of Lemma 2
Proof. We first show that for ğ‘Ÿâ‰¥2
ğœ‚(ğ‘Ÿ)â‰¤âˆš
17
2âˆ‘ï¸
ğ‘›â‰¥0ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹). (13)
For evenğ‘Ÿ, it is straightforward from (10) that
ğœ‚(ğ‘Ÿ)â‰¤âˆ‘ï¸
ğ‘›â‰¥0|2ğ‘–ğ‘Ÿ+ğ‘›ğ½ğ‘Ÿ+ğ‘›(ğ‘ğœ‹)cos(ğœ‹(ğ‘Ÿ+ğ‘›)/2)|
=2âˆ‘ï¸
ğ‘›â‰¥0ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹)â‰¤âˆš
17
2âˆ‘ï¸
ğ‘›â‰¥0ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹).
For oddğ‘Ÿ, letğœƒğ‘Ÿ=ğœ‹(ğ‘Ÿâˆ’1)/2ğ‘Ÿ. Using the recurrence relation (9),
we have
ğœ‚(ğ‘Ÿ)
2=âˆ‘ï¸
ğ‘›â‰¥ğ‘Ÿğ‘–ğ‘›ğ½ğ‘›(ğ‘ğœ‹)cosğ‘›ğœƒğ‘Ÿ
=âˆ‘ï¸
ğ‘›â‰¥0ğ‘–ğ‘›ğ½ğ‘Ÿ+ğ‘›(ğ‘ğœ‹)cos(ğ‘Ÿ+ğ‘›)ğœƒğ‘Ÿ
=âˆ‘ï¸
ğ‘›â‰¥0ğ‘–2ğ‘›ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹)cos(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ
+ğ‘–2ğ‘›+1ğ½ğ‘Ÿ+2ğ‘›+1(ğ‘ğœ‹)cos(ğ‘Ÿ+2ğ‘›+1)ğœƒğ‘Ÿ
=âˆ‘ï¸
ğ‘›â‰¥0ğ‘–2ğ‘›ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹)cos(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ
+ğ‘–2ğ‘›+1ğ¶ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹)+ğ½ğ‘Ÿ+2ğ‘›+2(ğ‘ğœ‹)
ğ‘Ÿ+2ğ‘›+1cos(ğ‘Ÿ+2ğ‘›+1)ğœƒğ‘Ÿ.
We separate the ğ½ğ‘Ÿ(ğ‘ğœ‹)term from the summand as follows:
ğœ‚(ğ‘Ÿ)
2=
cosğ‘Ÿğœƒğ‘Ÿ+ğ‘–ğ¶cos(ğ‘Ÿ+1)ğœƒğ‘Ÿ
ğ‘Ÿ+1
ğ½ğ‘Ÿ(ğ‘ğœ‹)
+âˆ‘ï¸
ğ‘›â‰¥1ğ‘–2ğ‘›
cos(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ+ğ‘–ğ¶cos(ğ‘Ÿ+2ğ‘›+1)ğœƒğ‘Ÿ
ğ‘Ÿ+2ğ‘›+1
âˆ’cos(ğ‘Ÿ+2ğ‘›âˆ’1)ğœƒğ‘Ÿ
ğ‘Ÿ+2ğ‘›âˆ’1
ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹).
Becauseğ‘Ÿâ‰¥2is odd andğ¶/(ğ‘Ÿ+1)â‰¤1/2, the magnitude of the
first coefficient satisfiescosğ‘Ÿğœƒğ‘Ÿ+ğ‘–ğ¶cos(ğ‘Ÿ+1)ğœƒğ‘Ÿ
ğ‘Ÿ+1=1+ğ‘–ğ¶
ğ‘Ÿ+1sinğœ‹
2ğ‘Ÿ
â‰¤1+ğ‘–
2sinğœ‹
6=1+ğ‘–
4=âˆš
17
4.
For the magnitude of remainder coefficients, we use the trigono-
metric identity
cos(ğ‘Ÿ+2ğ‘›Â±1)ğœƒğ‘Ÿ=cos(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿcosğœƒğ‘Ÿâˆ“sin(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿsinğœƒğ‘Ÿ,
which yields
cos(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ+ğ‘–ğ¶
ğ‘Ÿ+1
â„âˆ’(ğ‘›,ğ‘Ÿ)cos(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿcosğœƒğ‘Ÿ
âˆ’â„+(ğ‘›,ğ‘Ÿ)sin(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿsinğœƒğ‘Ÿ,(14)
 
2337Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
whereâ„Â±(ğ‘›,ğ‘Ÿ)â‰”ğ‘Ÿ+1
ğ‘Ÿ+2ğ‘›+1Â±ğ‘Ÿ+1
ğ‘Ÿ+2ğ‘›âˆ’1. Since|ğ‘cosğœƒğ‘Ÿ+ğ‘sinğœƒğ‘Ÿ| â‰¤âˆš
ğ‘2+ğ‘2forğ‘,ğ‘âˆˆR, (14) becomes

cos2(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ+ğ¶2
(ğ‘Ÿ+1)2
â„âˆ’(ğ‘›,ğ‘Ÿ)cos(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿcosğœƒğ‘Ÿ
âˆ’â„+(ğ‘›,ğ‘Ÿ)sin(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿsinğœƒğ‘Ÿ21/2
â‰¤maxğ‘›,ğ‘Ÿ
cos2(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ+ğ¶2
(ğ‘Ÿ+1)2
â„2
âˆ’(ğ‘›,ğ‘Ÿ)cos2(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ
+â„2
+(ğ‘›,ğ‘Ÿ)sin2(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ1/2
.
Forğ‘›â‰¥1,
|â„+(ğ‘›,ğ‘Ÿ)|â‰¤ 1+1=2,|â„âˆ’(ğ‘›,ğ‘Ÿ)|=2(ğ‘Ÿ+1)
ğ‘Ÿ2+4ğ‘›ğ‘Ÿ+4ğ‘›2âˆ’1â‰¤2
ğ‘Ÿ+3â‰¤1
2.
Thus, the magnitude of remainder coefficients is bounded by
maxğ‘›,ğ‘Ÿâˆšï¸„
1+1
42
cos2(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ+sin2(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿ
=maxğ‘›,ğ‘Ÿâˆšï¸‚
1+1
42cos2(ğ‘Ÿ+2ğ‘›)ğœƒğ‘Ÿâ‰¤âˆš
17
4.
This implies that
ğœ‚(ğ‘Ÿ)
2â‰¤âˆš
17
4ğ½ğ‘Ÿ(ğ‘ğœ‹)+âˆ‘ï¸
ğ‘›â‰¥1âˆš
17
4ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹),
so the ineqaulity (13). We now use the following inequality [ 32] to
complete the proof:
ğ½ğ‘›(2ğ‘¤)â‰¤ğ‘¤ğ‘›
ğ‘›!ğ‘’âˆ’ğ‘¤2
ğ‘›+1
for a non-negative integer ğ‘›andğ‘¤>0. From (13), we obtain
ğœ‚(ğ‘Ÿ)â‰¤âˆš
17
2âˆ‘ï¸
ğ‘›â‰¥0ğ½ğ‘Ÿ+2ğ‘›(ğ‘ğœ‹)
â‰¤âˆš
17
2âˆ‘ï¸
ğ‘›â‰¥0ğ¶ğ‘Ÿ+2ğ‘›
(ğ‘Ÿ+2ğ‘›)!ğ‘’âˆ’ğ¶2
ğ‘Ÿ+2ğ‘›+1
=âˆš
17
2ğ¶ğ‘Ÿ
ğ‘Ÿ!ğ‘’âˆ’ğ¶2
ğ‘Ÿ+1
1+ğ¶2
(ğ‘Ÿ+1)(ğ‘Ÿ+2)ğ‘’2ğ¶2
(ğ‘Ÿ+1)(ğ‘Ÿ+2)
+ğ¶4
(ğ‘Ÿ+1)(ğ‘Ÿ+2)(ğ‘Ÿ+3)(ğ‘Ÿ+4)ğ‘’4ğ¶2
(ğ‘Ÿ+1)(ğ‘Ÿ+5)+Â·Â·Â·
â‰¤âˆš
17
2ğ¶ğ‘Ÿ
ğ‘Ÿ!ğ‘’âˆ’ğ¶2
ğ‘Ÿ+1
1+ğ¶2
(ğ‘Ÿ+1)2ğ‘’2ğ¶2
(ğ‘Ÿ+1)2+ğ¶4
(ğ‘Ÿ+1)4ğ‘’4ğ¶2
(ğ‘Ÿ+1)2+Â·Â·Â·
=âˆš
17
2ğ¶ğ‘Ÿ
ğ‘Ÿ!ğ‘’âˆ’ğ¶2
ğ‘Ÿ+1
1âˆ’ğ¶2
(ğ‘Ÿ+1)2ğ‘’2ğ¶2
(ğ‘Ÿ+1)2âˆ’1
.
Thus, it follows from ğ¶2/(ğ‘Ÿ+1)2â‰¤1/4that
ğœ‚(ğ‘Ÿ)â‰¤âˆš
17
2ğ¶ğ‘Ÿ
ğ‘Ÿ!ğ‘’âˆ’ğ¶2
ğ‘Ÿ+1
1âˆ’1
4ğ‘’2
4âˆ’1
=2âˆš
17
4âˆ’âˆšğ‘’ğ¶ğ‘Ÿ
ğ‘Ÿ!ğ‘’âˆ’ğ¶2
ğ‘Ÿ+1,
hence the proof. â–¡A.2 Proof of Theorem 3
Proof. Note that(ğ‘+ğ‘logğ‘+ğ‘€)ğ‘Ÿis convex and non-decreasing
for eachğ‘,ğ‘Ÿâ‰¥1. Therefore, it is sufficient to show that ğ‘(ğ‘Ÿ)is a
convex function with respect to ğ‘Ÿ. Indeed, we prove that ğ‘(ğ‘Ÿ)is
logarithmically convex for ğ‘Ÿâ‰¥1, from which the convexity follows.
We first show that
ğ‘Ÿâ†¦â†’log(ğ›¼ğœ–ğ‘Ÿ!)âˆ’1
ğ‘Ÿ
is convex. It is easy to check that the function log(ğ›¼ğœ–)âˆ’1/ğ‘Ÿ=
âˆ’(logğ›¼ğœ–)/ğ‘Ÿis convex for ğ‘Ÿ>0since 0<ğ›¼,ğœ–<1. We can also
show that logğ‘Ÿ!âˆ’1/ğ‘Ÿ=âˆ’(logğ‘Ÿ!)/ğ‘Ÿis a convex function considering
its second derivative
ğ‘‘2
ğ‘‘ğ‘Ÿ2
âˆ’logğ‘Ÿ!
ğ‘Ÿ
=âˆ’2 logğ‘Ÿ!+2ğ‘Ÿğœ“(ğ‘Ÿ+1)âˆ’ğ‘Ÿ2ğœ“â€²(ğ‘Ÿ+1)
ğ‘Ÿ3, (15)
whereğœ“(ğ‘¥)=ğ‘‘
ğ‘‘ğ‘¥logÎ“(ğ‘¥)is the digamma function [ 1]. The follow-
ing property is often useful:
logğ‘¥â‰¤ğœ“(ğ‘¥+1)=âˆ’ğ›¾+âˆ‘ï¸
ğ‘˜â‰¥11
ğ‘˜âˆ’1
ğ‘¥+ğ‘˜
â‰¤log(ğ‘¥+1),âˆ€ğ‘¥>0,
whereğ›¾is the Euler-Mascheroni constant. We observe that the
numerator of (15) is non-negative on ğ‘Ÿâ‰¥0because it attains its
minimum value 0atğ‘Ÿ=0due to the following inequality:
ğ‘‘
ğ‘‘ğ‘Ÿ(âˆ’2 logğ‘Ÿ!+2ğ‘Ÿğœ“(ğ‘Ÿ+1)âˆ’ğ‘Ÿ2ğœ“â€²(ğ‘Ÿ+1))
=âˆ’ğ‘Ÿ2ğœ“â€²â€²(ğ‘Ÿ+1)=âˆ‘ï¸
ğ‘˜â‰¥12ğ‘Ÿ2
(ğ‘Ÿ+ğ‘˜)3â‰¥0
for allğ‘Ÿâ‰¥0. Since the product of two logarithmically convex func-
tions is also logarithmically convex, we conclude that (ğ›¼ğœ–ğ‘Ÿ!)âˆ’1/ğ‘Ÿ=
(ğ›¼ğœ–)âˆ’1/ğ‘ŸÃ—ğ‘Ÿ!âˆ’1/ğ‘Ÿis logarithmically convex for ğ‘Ÿ>0.
We use the above result to prove that ğ‘Ÿâ†¦â†’(ğ›¼ğœ–ğ‘Ÿ!)âˆ’1
ğ‘Ÿğ‘’âˆ’1
ğ‘Ÿ(ğ‘Ÿ+1)(ğ›¼ğœ–ğ‘Ÿ!)2/ğ‘Ÿ
is a convex function. Let ğ‘¢(ğ‘Ÿ)â‰”(ğ›¼ğœ–ğ‘Ÿ!)âˆ’1/ğ‘Ÿ. Our goal is to show
that the following function is convex:
ğ‘Ÿâ†¦â†’logğ‘¢(ğ‘Ÿ)âˆ’1
ğ‘Ÿ(ğ‘Ÿ+1)ğ‘¢(ğ‘Ÿ)2. (16)
A simple calculus shows that
ğ‘‘2
ğ‘‘ğ‘Ÿ2logğ‘¢(ğ‘Ÿ)=2ğ‘£(ğ‘Ÿ)âˆ’ğ‘Ÿğœ“â€²(ğ‘Ÿ+1)
ğ‘Ÿ2,
ğ‘‘2
ğ‘‘ğ‘Ÿ21
ğ‘Ÿ(ğ‘Ÿ+1)ğ‘¢(ğ‘Ÿ)2=2(3ğ‘Ÿ2+3ğ‘Ÿ+1)
ğ‘Ÿ2(ğ‘Ÿ+1)2+2ğœ“â€²(ğ‘Ÿ+1)
ğ‘Ÿ
âˆ’4(3ğ‘Ÿ+2)
ğ‘Ÿ2(ğ‘Ÿ+1)ğ‘£(ğ‘Ÿ)+4
ğ‘Ÿ2ğ‘£(ğ‘Ÿ)21
ğ‘Ÿ(ğ‘Ÿ+1)ğ‘¢(ğ‘Ÿ)2,
whereğ‘£(ğ‘Ÿ)â‰”logğ‘¢(ğ‘Ÿ)+ğœ“(ğ‘Ÿ+1). Since we have already shown that
ğ‘‘2
ğ‘‘ğ‘Ÿ2logğ‘¢(ğ‘Ÿ)â‰¥0, it is sufficient to consider only when ğ‘Ÿsatisfies
ğ‘‘2
ğ‘‘ğ‘Ÿ21
ğ‘Ÿ(ğ‘Ÿ+1)ğ‘¢(ğ‘Ÿ)2â‰¥0, otherwise the function (16) trivially has a non-
nagative second derivative. For ğ‘Ÿâ‰¥1, we have
ğ‘Ÿ(ğ‘Ÿ+1)ğ‘¢(ğ‘Ÿ)2â‰¥1+log(ğ‘Ÿ(ğ‘Ÿ+1)ğ‘¢(ğ‘Ÿ)2)
â‰¥log((ğ‘Ÿ+1)2ğ‘¢(ğ‘Ÿ)2)
=2(log(ğ‘Ÿ+1)+ logğ‘¢(ğ‘Ÿ))
â‰¥2(ğœ“(ğ‘Ÿ+1)+ logğ‘¢(ğ‘Ÿ))
=2ğ‘£(ğ‘Ÿ),
 
2338KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
soâˆ’1
ğ‘Ÿ(ğ‘Ÿ+1)ğ‘¢(ğ‘Ÿ)2â‰¥âˆ’1
2ğ‘£(ğ‘Ÿ). Also,
ğœ“â€²(ğ‘Ÿ+1)=âˆ‘ï¸
ğ‘˜â‰¥11
(ğ‘Ÿ+ğ‘˜)2â‰¤âˆ«âˆ
ğ‘Ÿğ‘‘ğ‘¥
ğ‘¥2=1
ğ‘Ÿ.
These inequalities imply that
ğ‘‘2
ğ‘‘ğ‘Ÿ2
logğ‘¢(ğ‘Ÿ)âˆ’1
ğ‘Ÿ(ğ‘Ÿ+1)ğ‘¢(ğ‘Ÿ)2
â‰¥2ğ‘£(ğ‘Ÿ)âˆ’ğ‘Ÿğœ“â€²(ğ‘Ÿ+1)
ğ‘Ÿ2âˆ’2(3ğ‘Ÿ2+3ğ‘Ÿ+1)
ğ‘Ÿ2(ğ‘Ÿ+1)2+2ğœ“â€²(ğ‘Ÿ+1)
ğ‘Ÿ
âˆ’4(3ğ‘Ÿ+2)
ğ‘Ÿ2(ğ‘Ÿ+1)ğ‘£(ğ‘Ÿ)+4
ğ‘Ÿ2ğ‘£(ğ‘Ÿ)21
2ğ‘£(ğ‘Ÿ)
â‰¥2ğ‘£(ğ‘Ÿ)âˆ’1
ğ‘Ÿ2âˆ’2(3ğ‘Ÿ2+3ğ‘Ÿ+1)
ğ‘Ÿ2(ğ‘Ÿ+1)2+2
ğ‘Ÿ2
âˆ’4(3ğ‘Ÿ+2)
ğ‘Ÿ2(ğ‘Ÿ+1)ğ‘£(ğ‘Ÿ)+4
ğ‘Ÿ2ğ‘£(ğ‘Ÿ)21
2ğ‘£(ğ‘Ÿ)
=âˆ’(4ğ‘Ÿ2+5ğ‘Ÿ+2)+ğ‘£(ğ‘Ÿ)(5ğ‘Ÿ2+8ğ‘Ÿ+3)
ğ‘£(ğ‘Ÿ)ğ‘Ÿ2(ğ‘Ÿ+1)2.
Thus, if we show that ğ‘£(ğ‘Ÿ)â‰¥4/5, thenğ‘£(ğ‘Ÿ)ğ‘Ÿ2(ğ‘Ÿ+1)2>0, and
âˆ’(4ğ‘Ÿ2+5ğ‘Ÿ+2)+ğ‘£(ğ‘Ÿ)(5ğ‘Ÿ2+8ğ‘Ÿ+3)
â‰¥âˆ’( 4ğ‘Ÿ2+5ğ‘Ÿ+2)+4
5(5ğ‘Ÿ2+8ğ‘Ÿ+3)=7ğ‘Ÿ+2
5â‰¥0,
which proves that (16) is convex. Now, Stirlingâ€™s formula [ 24] im-
plies that
ğ‘Ÿ!â‰¤âˆš
2ğœ‹ğ‘Ÿğ‘Ÿ
ğ‘’ğ‘Ÿ
ğ‘’1
12ğ‘Ÿ
for allğ‘Ÿâ‰¥1. Thus, it follows that
ğ‘Ÿ
ğ‘£(ğ‘Ÿ)âˆ’4
5
=ğ‘Ÿ
âˆ’1
ğ‘Ÿlog(ğ›¼ğœ–ğ‘Ÿ!)+ğœ“(ğ‘Ÿ+1)âˆ’4
5
â‰¥ğ‘Ÿ
âˆ’1
ğ‘Ÿlog(ğ›¼ğ‘Ÿ!)+logğ‘Ÿâˆ’4
5
=âˆ’log(ğ›¼ğ‘Ÿ!)+ğ‘Ÿlogğ‘Ÿâˆ’4
5ğ‘Ÿ
â‰¥âˆ’log
ğ›¼âˆš
2ğœ‹ğ‘Ÿğ‘Ÿ
ğ‘’ğ‘Ÿ
ğ‘’1
12ğ‘Ÿ
+ğ‘Ÿlogğ‘Ÿâˆ’4
5ğ‘Ÿ
=âˆ’logğ›¼âˆš
2ğœ‹ğ‘Ÿâˆ’ğ‘Ÿlogğ‘Ÿ+ğ‘Ÿâˆ’1
12ğ‘Ÿ+ğ‘Ÿlogğ‘Ÿâˆ’4
5ğ‘Ÿ
=âˆ’logğ›¼âˆš
2ğœ‹ğ‘Ÿ+1
5ğ‘Ÿâˆ’1
12ğ‘Ÿ
â‰¥âˆ’logğ›¼âˆš
2ğœ‹ğ‘Ÿ+1
5ğ‘Ÿâˆ’1
12.
Since
ğ‘‘
ğ‘‘ğ‘Ÿ
âˆ’logğ›¼âˆš
2ğœ‹ğ‘Ÿ+1
5ğ‘Ÿâˆ’1
12
=âˆ’1
2ğ‘Ÿ+1
5,
the function attains its minimum at ğ‘Ÿ=5/2, so
ğ‘Ÿ
ğ‘£(ğ‘Ÿ)âˆ’4
5
â‰¥âˆ’logğ›¼âˆš
5ğœ‹+5
12=0.294377Â·Â·Â·â‰¥ 0,
orğ‘£(ğ‘Ÿ)â‰¥4/5. This completes the proof. â–¡A.3 Proof of Theorem 8
Proof. Letğ‘£ğ‘‘=ğ‘™ğ‘‘âˆ’ğ‘ğ‘‘/2andPğ‘‘=Pğ‘Ÿğ‘‘,ğœ‰(ğœ–,ğ‘Ÿğ‘‘)forğ‘‘=1,2,Â·Â·Â·,ğ·,
andB=Bğ,ğ‘´. Then, it follows that
âˆ¥Ë†ğ’‚âˆ’E( Ë†ğ’‚)âˆ¥B
â‰¤âˆ‘ï¸ğ‘(ğ’Œ)
ğ’Ã–
ğ‘‘ğœ”ğ‘£ğ‘‘ğ‘šğ‘‘
ğ‘ğ‘‘âˆ’Ã–
ğ‘‘ğœ”ğ‘£ğ‘‘ğœ‡ğ‘‘
ğ‘ğ‘‘Pğ‘‘(âˆ’2ğ‘£ğ‘‘(ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘)/ğ‘ğ‘‘)B
=âˆ‘ï¸
|ğ‘(ğ’Œ)
ğ’|Ã–
ğ‘‘ğœ”ğ‘£ğ‘‘(ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘)
ğ‘ğ‘‘âˆ’Ã–
ğ‘‘Pğ‘‘(âˆ’2ğ‘£ğ‘‘(ğ‘šğ‘‘âˆ’ğœ‡ğ‘‘)/ğ‘ğ‘‘)B,
where the summations are over indices ğ’ŒâˆˆÃ
ğ‘‘[ğ‘ğ‘‘]andğ’âˆˆÃ
ğ‘‘[ğ‘Ÿğ‘‘]. Sinceğ‘™ğ‘‘ranges from 0toğ‘ğ‘‘âˆ’1, we have|2ğ‘£ğ‘‘/ğ‘ğ‘‘| â‰¤
2(ğ‘ğ‘‘/2)/ğ‘ğ‘‘=1/ğ‘ğ‘‘, and therefore ğ‘€ğ‘‘|2ğ‘£ğ‘‘/ğ‘ğ‘‘|â‰¤ğ‘€ğ‘‘/ğ‘ğ‘‘â‰¤ğœ‰(ğœ–,ğ‘Ÿğ‘‘).
We replaceâˆ’2ğ‘£ğ‘‘(ğ‘¥ğ‘‘âˆ’ğœ‡ğ‘‘)/ğ‘ğ‘‘withğ‘¥â€²
ğ‘‘:
âˆ¥Ë†ğ’‚âˆ’E( Ë†ğ’‚)âˆ¥B
â‰¤âˆ‘ï¸
|ğ‘(ğ’Œ)
ğ’|Ã–
ğ‘‘ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘âˆ’Ã–
ğ‘‘Pğ‘‘(ğ‘¥â€²
ğ‘‘)|ğ‘¥â€²
ğ‘‘|â‰¤ğ‘€ğ‘‘|2ğ‘£ğ‘‘/ğ‘ğ‘‘|,âˆ€ğ‘‘
â‰¤âˆ‘ï¸
|ğ‘(ğ’Œ)
ğ’|Ã–
ğ‘‘ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘âˆ’Ã–
ğ‘‘Pğ‘‘(ğ‘¥â€²
ğ‘‘)|ğ‘¥â€²
ğ‘‘|â‰¤ğœ‰(ğœ–,ğ‘Ÿğ‘‘),âˆ€ğ‘‘.
Now
Ã–
ğ‘‘ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘âˆ’Ã–
ğ‘‘Pğ‘‘(ğ‘¥â€²
ğ‘‘)=Ã–
ğ‘‘<ğ·ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘
(ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ·âˆ’Pğ·(ğ‘¥â€²
ğ·))
+Ã–
ğ‘‘<ğ·ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘âˆ’Ã–
ğ‘‘<ğ·Pğ‘‘(ğ‘¥â€²
ğ‘‘)
Pğ·(ğ‘¥â€²
ğ·).
Using the above equation recursively, we obtain
Ã–
ğ‘‘ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘âˆ’Ã–
ğ‘‘Pğ‘‘(ğ‘¥â€²
ğ‘‘)
=ğ·âˆ‘ï¸
ğ‘ =1Ã–
ğ‘‘<ğ‘ ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘
(ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘ âˆ’Pğ‘ (ğ‘¥â€²
ğ‘ ))Ã–
ğ‘ <ğ‘‘Pğ‘‘(ğ‘¥â€²
ğ‘‘)
.
Because|ğ‘¥â€²
ğ‘‘|â‰¤ğœ‰(ğœ–,ğ‘Ÿğ‘‘)for allğ‘‘, we have the following inequality:
Ã–
ğ‘‘ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘âˆ’Ã–
ğ‘‘Pğ‘‘(ğ‘¥â€²
ğ‘‘)
â‰¤ğ·âˆ‘ï¸
ğ‘ =1Ã–
ğ‘‘<ğ‘ ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘Â·|ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘ âˆ’Pğ‘ (ğ‘¥â€²
ğ‘ )|Â·Ã–
ğ‘ <ğ‘‘Pğ‘‘(ğ‘¥â€²
ğ‘‘)
â‰¤ğ·âˆ‘ï¸
ğ‘ =11ğ‘ âˆ’1Â·ğœ–Â·(ğœ–+1)ğ·âˆ’ğ‘ =(ğœ–+1)ğ·âˆ’1,
where the second inequality holds since |ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘|=1and|Pğ‘‘(ğ‘¥â€²
ğ‘‘)|â‰¤
|Pğ‘‘(ğ‘¥â€²
ğ‘‘)âˆ’ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘|+|ğ‘’ğœ‹ğ‘–ğ‘¥â€²
ğ‘‘|â‰¤ğœ–+1. We may assume that the tolerance
is sufficiently small so that ğœ–<2/ğ·2. Then it is easy to see that
(ğœ–+1)ğ·âˆ’1=ğ·âˆ‘ï¸
ğ‘‘=0ğ·
ğ‘‘
ğœ–ğ‘‘âˆ’1=ğ·ğœ–+ğ·âˆ‘ï¸
ğ‘‘=2ğ·
ğ‘‘
ğœ–ğ‘‘
â‰¤ğ·ğœ–+ğ·âˆ‘ï¸
ğ‘‘=2ğ·2
2ğ‘‘âˆ’1
ğœ–ğ‘‘
â‰¤ğ·ğœ–+ğ·âˆ‘ï¸
ğ‘‘=21
ğœ–ğ‘‘âˆ’1
ğœ–ğ‘‘=ğ·ğœ–+ğ·âˆ‘ï¸
ğ‘‘=2ğœ–=(2ğ·âˆ’1)ğœ–.
Thus, we obtain the desired approximation bound of Auto-MPFT:
âˆ¥Ë†ğ’‚âˆ’E( Ë†ğ’‚)âˆ¥Bâ‰¤Ã|ğ‘(ğ’Œ)
ğ’|Â·(2ğ·âˆ’1)ğœ–=âˆ¥ğ’‚âˆ¥1Â·(2ğ·âˆ’1)ğœ–. â–¡
 
2339