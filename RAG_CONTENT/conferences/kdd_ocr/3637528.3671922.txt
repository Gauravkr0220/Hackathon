STEMO: Early Spatio-temporal Forecasting with Multi-Objective
Reinforcement Learning
Wei Shaoâˆ—
Data61, CSIRO
Clayton, Victoria, Australia
phdweishao@gmail.comYufan Kangâˆ—
RMIT University
Melbourne, Victoria, Australia
yufan.kang@student.rmit.edu.auZiyan Peng
Xidian University
Xiâ€™an, China
Xiao Xiaoâ€ 
Xidian University
Xiâ€™an, China
xiaoxiao@xidian.edu.cnLei Wang
Zhejiang University
Hangzhou, ChinaYuhui Yang
Xidian University
Xiâ€™an, China
Flora D. Salim
University of New South Wales
Sydney, Australia
ABSTRACT
Accuracy and timeliness are indeed often conflicting goals in pre-
diction tasks. Premature predictions may yield a higher rate of
false alarms, whereas delaying predictions to gather more infor-
mation can render them too late to be useful. In applications such
as wildfires, crimes, and traffic jams, timely forecasting are vital
for safeguarding human life and property. Consequently, finding a
balance between accuracy and timeliness is crucial. In this paper,
we propose an early spatio-temporal forecasting model based on
Multi-Objective reinforcement learning that can either implement
an optimal policy given a preference or infer the preference based
on a small number of samples. The model addresses two primary
challenges: 1) enhancing the accuracy of early forecasting and 2)
providing the optimal policy for determining the most suitable
prediction time for each area. Our method demonstrates superior
performance on three large-scale real-world datasets, surpassing
existing methods in early spatio-temporal forecasting tasks.
CCS CONCEPTS
â€¢Computing methodologies â†’Neural networks; Spatial and
physical reasoning; â€¢Applied computing â†’Forecasting.
KEYWORDS
Spatio-Temporal Data, Graph Neural Network, Early Detection,
Responsible AI
âˆ—authors contributed equally to this research.
â€ Corresponding Author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671922ACM Reference Format:
Wei Shao, Yufan Kang, Ziyan Peng, Xiao Xiao, Lei Wang, Yuhui Yang,
and Flora D. Salim. 2024. STEMO: Early Spatio-temporal Forecasting with
Multi-Objective Reinforcement Learning. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD â€™24),
August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 10 pages.
https://doi.org/10.1145/3637528.3671922
1 INTRODUCTION
Spatio-temporal prediction, an innovative intersection of geographic
information systems, statistics, and data science, plays a pivotal
role in fields where spatial distribution and temporal progression
dictate outcomes. This predictive approach finds wide-ranging ap-
plications in domains such as meteorology, epidemiology, traffic
control, parking, and urban planning [15, 19, 27, 29, 33, 35].
Early spatio-temporal forecasting focuses on anticipating future
events by examining patterns that change over space and time as
early as possible, which is essential to many real-world applications
such as epidemiology, environmental studies, and public safety,
where early detection can lead to better management or prevention
outcomes. For instance, within the context of forecasting the spread
of diseases, the timeliness forecasting is considerably more critical
than their accuracy. Predictions that are accurate but delayed can
lead to the unnecessary loss of thousands of lives. On the other
hand, a prediction that is approximately accurate but made in a
timely manner can significantly reduce the impact, saving lives.
Figure 1 shows existing approaches to forecast spatio-temporal
events are categorised into three distinct strategies: Traditional,
Fixed, and Adaptive. For example, Hochreiter et al. [13] propose a
traditional method that considers the entire recorded data before
the forecasting. However, this approach can be time-consuming,
particularly with large datasets, and its requirement for complete
prior data collection often results in delays, which is unsuitable
for time-sensitive applications. Conversely, Liâ€™s approach operates
within a set observation period [ 20], facilitating fixed timely fore-
casts within a specific window. Although this strategy enhances
promptness, its fixed timing can result in inaccuracies if the ob-
servation window is not optimally selected. Moreover, its rigidity
 
2618
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Wei Shao, et al.
T radition Fixed Adaptive
Figure 1: Example of three methods for early spatio-temporal
forecasting. Each circle is a node (e.g. sensor) with recorded
value (such as speed) over time. The blue plane represents the
prediction time, and the recorded values after the blue plane
are not used for forecasting. The adaptive early forecasting
method adjusts data usage and dynamically determines the
prediction time for different nodes. The node colour at time
ğ‘‡indicates the accuracy, green indicates that the predicted
value matches the ground truth, and red indicates otherwise.
in adjusting to temporal data variations and the risk of selection
bias in determining the observation window could compromise its
precision. The third approach, named adaptive early forecasting,
dynamically adjusts the forecasting time based on data character-
istics. This idea is inspired by Hartvigsen, who applied this idea
in the time-series prediction area [ 11]. This innovative method
aims to strike an optimal balance between forecasting accuracy and
timeliness, thereby attempting to optimise both the timeliness and
accuracy. Its dynamic adaptability provides a significant edge in
handling changes over time.
Although Hartivigsen has tried to apply the concept of early
prediction in time-series area [ 11] and achieved some good results
in the medical diagnosis, many challenges remain, especially in
the spatio-temporal forecasting. (1) Real-time Bi-objective Bal-
ance in Highly Complex Environment: Spatio-temporal data
demand dynamic solutions, being more complex and subject to
rapid changes than time-series data. Traditional multi-objective
optimisation methods, which are static and computationally in-
tensive, fail to adapt efficiently across different environments. At
the same time, early forecasting necessitates immediate results, as
even a one-minute delay can lead to unfavourable outcomes. (2)
Spatio-temporal Comprehensive Dependency: Relying solely
on distance correlation for spatio-temporal forecasting may fall
short in quickly capturing essential data characteristics. Although
distance correlation effectively reflects spatial connections among
nodes, it overlooks the crucial temporal aspects embedded withinthe data, which are vital for precise forecasting. (3) Hidden Pref-
erences Discovery: The equilibrium between timeliness and accu-
racy varies across tasks, revealing diverse preferences. Identifying
these subtle preferences is a complex challenge that demands a
profound comprehension of the goals at hand and formulating an
ideal balance between promptness and precision for each scenario.
This highlights the necessity for refined and flexible strategies in
early spatio-temporal forecasting.
We address the aforementioned challenges by introducing a
early spatio-temporal forecasting model based on multi-objective
reinforcement learning (STEMO). The key contributions of our
study can be summarised as follows:
â€¢We present a multi-objective reinforcement learning frame-
work designed to optimise both the timeliness and accu-
racy of spatio-temporal forecasting. This approach enhances
adaptability to changing patterns through interactive learn-
ing from real-time feedback.
â€¢We introduce a multiple-step similarity matrix, enabling each
node to capture the trends from other upstream nodes so
that we can estimate the changes of such nodes earlier.
â€¢We develop a node embedding technique based on biased
random walks, increasing the likelihood of visiting nodes
with higher similarity and reaching the optimal time. To
address the issue of non-uniform object scales or units, we
devise a method to discover hidden preferences and employ
the entropy weight method.
2 RELATED WORK
2.1 Spatio-temporal Prediction
It is evident that spatio-temporal prediction is of paramount impor-
tance in numerous real-world applications [ 31], such as weather
prediction [ 2], traffic flow prediction [ 6], and earthquake predic-
tion [ 37]. Traditional time-series methods, including ARIMA [ 1],
have been extensively employed for prediction. With the evolution
of machine learning, deep learning methods such as Long Short
Term Memory (LSTM) [ 13] and Gate Recurrent Unit (GRU) [ 3] have
demonstrated superior capabilities in capturing temporal correla-
tions. Convolutional Neural Networks (CNNs) [ 18] are frequently
utilised to capture spatial correlations in Euclidean space, whereas
Graph Convolution Networks (GCNs) [ 17] serve to model non-
Euclidean relationships among nodes. Despite these advancements,
fixed observation windows limit the ability of these models to ad-
just their predictions in response to evolving data patterns, which
could compromise their timeliness and accuracy, especially when
dealing with rapidly changing data sources like traffic flow.
2.2 Early Prediction
Early prediction methods are techniques employed to make pre-
dictions based on specific identifiable characteristics or temporal
patterns within a dataset. These methods can be classified into two
categories: shapelet-based methods and predictor-based methods.
Shapelet-based methods [ 7,12] involve finding small sub-parts of
the time series data, known as shapelets [ 36], that can be utilised
for prediction. Predictor-based methods [ 8,22,23,28] involve com-
bining a set of predictors built at different points in time with one
or more conditions or trigger functions to evaluate the reliability of
 
2619STEMO: Early Spatio-temporal Forecasting with Multi-Objective Reinforcement Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
predictions and help determine whether they should be considered
or discarded. Most of these methods prioritise accuracy over time-
liness, inadvertently downplaying the role of prompt predictions.
Some methods [ 22,23,30] allow for adjusting the trade-off between
accuracy and timeliness with parameters, but these parameters can
be difficult to adjust in advance and may require executing the al-
gorithm multiple times to obtain solutions with different trade-offs.
In this paper, we propose a Spatio-Temporal Early Prediction model
that seeks to improve both the timeliness and accuracy of spatio-
temporal predictions, addressing some of the limitations inherent
in existing techniques.
3 PROBLEM DEFINITION
Consider a graphG={V,E}, where V={ğ‘£ğ‘–}ğ‘›
ğ‘–=1denotes the set
of nodes and E={ğ‘’ğ‘–ğ‘—}ğ‘›
ğ‘–,ğ‘—=1represents the set of edges. The adja-
cency matrix AâˆˆRğ‘›Ã—ğ‘›captures the relationships (e.g., distance)
between nodes. Recorded values Xğ‘¡={ğ‘¥ğ‘–
ğ‘¡}ğ‘›
ğ‘–=1refer to the mea-
surements obtained from the nodes at time ğ‘¡. forecasted values
bXğ‘‡={Ë†ğ‘¥ğ‘–
ğ‘‡}ğ‘›
ğ‘–=1are the estimates of the values at time ğ‘‡based on
the graph neural network model. For instance, in a traffic speed
forecasting scenario, ğ‘¥ğ‘–
ğ‘¡could be the speed at sensor ğ‘£ğ‘–at timeğ‘¡, and
Ë†ğ‘¥ğ‘–
ğ‘‡could be the forecasted speed at time ğ‘‡. The optimal time series
tâˆ—={ğ‘¡âˆ—
ğ‘–}ğ‘›
ğ‘–=1can guide the data observation process. For each node
ğ‘£ğ‘–, the corresponding optimal time ğ‘¡âˆ—
ğ‘–is the most appropriate that
the forecasting accuracy is maximised and the time cost minimises.
We aim to find the optimal time series that balances forecasting
accuracy and time cost. The optimal time for node ğ‘£ğ‘–is computed
using the following expression:
ğ‘¡âˆ—
ğ‘–=arg max
ğ‘¡
logğ‘ƒ
Ë†ğ‘¥ğ‘–
ğ‘‡|X0:ğ‘¡,G
âˆ’Cost(ğ‘¡)
.
s.t.ğ‘¡âˆˆ[0,ğ‘‡âˆ’1](1)
The objective function logğ‘ƒ(Ë†ğ‘¥ğ‘–
ğ‘‡|X0:ğ‘¡,G)denotes the log-likelihood
of the forecasted value given the past measurements and the graph
structure, which can be seen as a measure of the accuracy. The
function Cost(ğ‘¡)represents the time cost of collecting records up
to timeğ‘¡, and it is assumed to be monotonically increasing as more
data is often more expensive to obtain.
4 METHODOLOGY
As shown in Figure 2, the Early Spatio-Temporal Forecasting model
based on Multi-Objective reinforcement learning (STEMO) consists
of three main components: a spatio-temporal predictor, a state
generator, and optimal policies for determining the optimal time.
In addition, we also introduce how to find hidden preferences.
4.1 The Spatio-temporal Predictor
The main difference between traditional GCN and the Multi-Graph
Convolutional Neural network (MGCN) is the addition of multiple
time steps in the similarity matrix calculation in the latter. A stan-
dard GCN calculates similarity based on spatial proximity or a single
time-point temporal similarity, leading to a limitation in capturing
time-evolving trends. MGCN improves this by including multiple
time-step similarities, capturing more intricate time-evolving cor-
relations, and facilitating timeliness.
spatiotemporal predictor
state generator optimal policiesEncoder Decoder
Node
EmbeddingPolicywait
haltFigure 2: At time ğ‘¡, the encoder processes the recorded val-
uesX0:ğ‘¡to extract spatio-temporal features and generate the
hidden state Hğ‘¡. Using Hğ‘¡, the decoder generates a series of
forecasted values, focusing on bX(ğ‘¡)
ğ‘‡. The state generator con-
catenates the node embedding result and Hğ‘¡to generate the
state sğ‘¡. The policy utilises sğ‘¡to determine the optimal time
for each node ğ‘£ğ‘–âˆˆVvia the action set ağ‘¡={ğ‘ğ‘–
ğ‘¡}ğ‘›
ğ‘–=1(halt or
wait). â€™Waitâ€™ implies that further observation of recorded
values is necessary, while â€™Haltâ€™ implies that time ğ‘¡is the
optimal time ğ‘¡âˆ—
ğ‘–for nodeğ‘£ğ‘–, and the corresponding forecasted
value is recorded in bXğ‘‡.
(a) Time series of nodes ğ‘£ğ‘–andğ‘£ğ‘—. The dot-
ted line represents the series after the optimal
time.
0 0 2 2 1 3
2 2 0 0 1 1
1 1 1 1 0 2
1 1 1 1 0 2
1 1 1 1 0 2
3 3 1 1 2 01     1     3     3     2     4
1
3
2
2
2
4(b) DTW distance between the time
series of nodes ğ‘£ğ‘–andğ‘£ğ‘—
Figure 3: Figure (a) shows the time series of nodes ğ‘£ğ‘–and
ğ‘£ğ‘—. The dotted line represents the series after the optimal
time, and we only need to observe the solid line to make
forecasting. The two solid dots in Figure (a) correspond to
the two red circles in Figure (b). Take the red circle below
as an example, it corresponds to the DTW distance between
ğ‘¥ğ‘–
0:ğ‘¡andğ‘¥ğ‘—
0:ğ‘¡, which is calculated along the green grid path.
We anticipate that node ğ‘–will acquire feature ğ‘¥ğ‘—
ğ‘¡âˆ—
ğ‘—at timeğ‘¡
through MGCN, allowing it to make more precise forecasting
earlier.
Specifically, GCN collects equal-length time series of each node,
applies the DTW algorithm to each pair of time series data, and uses
dynamic time warping (DTW) distance [ 24] to create a similarity
matrix. DTW is a method that finds an optimal match between two
given sequences (e.g., time series) with certain restrictions, which
is particularly useful in our setting where we seek to find corre-
lations in temporal data. However, GCN has certain limitations.
 
2620KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Wei Shao, et al.
2
1 4
37
652
42
1 4
37
652
1
347
65
Figure 4: We assume node 1 (red) is the central node. The blue
nodes represent spatially close nodes, while the green nodes
represent temporally similar nodes. MGCN considers these
two kinds of nodes, where spatial and temporal similarities
are processed separately but in conjunction.
One limitation is that it does not consider the influence of other
nodes before time ğ‘¡. As shown in Figure 3, ğ‘¡represents a specific
time, andğ‘¡â€²is an arbitrary time. If ğ‘¡â€²<ğ‘¡andDTW(ğ‘¥ğ‘—
0:ğ‘¡â€²,ğ‘¥ğ‘–
ğ‘¡)=0,
this may result from node ğ‘£ğ‘—changing faster than the node ğ‘£ğ‘–. In
such cases, it would be advantageous for node ğ‘£ğ‘–to incorporate
the feature of node ğ‘£ğ‘—at timeğ‘¡â€², this would enable it to capture the
changing trend better and facilitate early forecasting. Moreover, if
ğ‘¡â€²=ğ‘¡âˆ—
ğ‘—<ğ‘¡, this would also allow node ğ‘–to reach the optimal time
more quickly. Another limitation of this approach is that it may pro-
duce inaccurate results when DTW(ğ‘¥ğ‘—
ğ‘¡âˆ—
ğ‘—,ğ‘¥ğ‘–
ğ‘¡âˆ—
ğ‘—)>0, indicating a weak
correlation between nodes ğ‘£ğ‘—andğ‘£ğ‘–. This may not always be true
and could lead to sub-optimal outcome. The MGCN addresses these
limitations, which is designed to optimize both forecasting accu-
racy and timeliness. As depicted in Figure 4, the multiple timesteps
similarity matrix allows the model to capture correlations better,
thus achieving more accurate outcome. In addition, MGCN can
incorporate the fast-changing trends from other nodes to make
forecasting earlier.
The distance matrix ASâˆˆRğ‘›Ã—ğ‘›is calculated according to the
geometric distance between nodes:
AS
ğ‘–,ğ‘—=ï£±ï£´ï£´ ï£²
ï£´ï£´ï£³exp
âˆ’ğ‘‘2
ğ‘– ğ‘—
ğœ‚2
, ğ‘–â‰ ğ‘—
0, ğ‘– =ğ‘—, (2)
whereğ‘‘ğ‘–ğ‘—represents the distance between ğ‘£ğ‘–andğ‘£ğ‘—, andğœ‚is the
parameter that controls the distribution of AS.
The multiple timesteps similarity matrix AT
ğ‘¡âˆˆR(ğ‘¡+1)Ã—ğ‘›Ã—ğ‘›is
computed according to the temporal similarity between nodes:
AT
ğ‘¡,ğ‘¡â€²,ğ‘–,ğ‘—=(
ğ‘’âˆ’ğœ…Ã—DTW(ğ‘¥ğ‘–
0:ğ‘¡,ğ‘¥ğ‘—
0:ğ‘¡â€²)ğ‘–â‰ ğ‘—
0 ğ‘–=ğ‘—, (3)
whereğœ…controls the range of DTW distance and should be set
based on the range of relevant conditions.Xâ€²
ğ‘¡=ğœ ğ‘¡âˆ‘ï¸
ğ‘¡â€²=0Ağ‘¡,ğ‘¡â€²Xğ‘¡â€²Wğ‘¡â€²!
Ağ‘¡,ğ‘¡â€²=(
AT
ğ‘¡,ğ‘¡â€² ğ‘¡â€²â‰¤ğ‘¡
(Ë†AS+AT
ğ‘¡,ğ‘¡)/2ğ‘¡â€²=ğ‘¡,(4)
where Ë†AS=ËœDâˆ’1
2ËœASËœDâˆ’1
2represents pre-processing step, ËœAS=
AS+Iis the matrix with added self-connections, Iis the identity
matrix, ËœD=Ã
ğ‘—ËœAS
ğ‘–,ğ‘—is degree matrix, ğœ(Â·)represents the sigmoid
function,Wğ‘¡â€²âˆˆR1Ã—â„is learnable parameters with number of
hidden unit â„.
The encoder-decoder structure is utilized for its capacity to cap-
ture temporal dependencies and handle variable length sequences,
as shown in Figure 2. In contrast to previous work, the variation
in the number of units (consisting of an MGCN and a GRU) allows
the model to dynamically adjust its focus to different parts of the
time sequence. At time ğ‘¡, the encoder has ğ‘¡+1units. The recorded
values Xğ‘¡are input into MGCN in the unit ğ‘¡+1, and the result of
graph convolution process Xâ€²
ğ‘¡is then used as input for the GRU.
Combining the hidden state Hğ‘¡âˆ’1of GRU output in the previous
unit, the GRU outputs hidden state Hğ‘¡. In practice, in the encoder,
only the last prediction unit at each time needs to be calculated. At
timeğ‘¡, the decoder has ğ‘‡âˆ’ğ‘¡âˆ’1units, and the last unit outputs the
candidate forecasting values bX(ğ‘¡)
ğ‘‡.
bX(ğ‘¡)
ğ‘‡=WH(ğ‘¡)
ğ‘‡+brepresents candidate forecasted values at time
ğ‘‡forecasted at time ğ‘¡, where Wandbare learnable parameters.
The spatio-temporal predictor is trained by minimizing the mean
absolute error between bXğ‘‡andXğ‘‡, where forecasted values bXğ‘‡=Ãğ‘‡âˆ’1
ğ‘¡=0ağ‘¡âŠ™bX(ğ‘¡)
ğ‘‡, andâŠ™denotes the Hadamard product calculation.
4.2 State Generator
The relationship between nodes is based on temporal similarity
and spatial similarity. In essence, if ğ‘¥ğ‘–
ğ‘¡âˆ—
ğ‘–andğ‘¥ğ‘—
ğ‘¡show similarity, it
suggests a possible temporal connection between node ğ‘–andğ‘—.
We propose to leverage this connection to help node ğ‘—reach its
optimal time more quickly by learning from node ğ‘–. We designed
an embedding function ğ‘“ğ‘¡(Â·)for each time ğ‘¡, which operates on
the features of the node and aims to create a representation of
each node at time ğ‘¡. The stateğ‘ ğ‘–
ğ‘¡captures the current information
status of node ğ‘–at timeğ‘¡. It combines the hidden state Hğ‘–
ğ‘¡âˆˆRâ„
outputted by the encoder and the node embedding ğ‘“ğ‘¡(ğ‘£ğ‘–)âˆˆRğ‘’. The
state is used to verify the optimal time by providing comprehensive
information for each node at each time.
The choice of objective function stems from the assumption
that a nodeâ€™s state is influenced by its neighboursâ€™ states, and the
optimisation goal is to maximise the probability of the appearance
of the nodeâ€™s neighbours given the node itself:
max
ğ‘“ğ‘¡âˆ‘ï¸
ğ‘£ğ‘–âˆˆVlogğ‘ƒğ‘Ÿ(ğ‘(ğ‘£ğ‘–)|ğ‘“ğ‘¡(ğ‘£ğ‘–)), (5)
whereğ‘(ğ‘£ğ‘–)represents the set of neighbors of ğ‘£ğ‘–obtained by biased
random walk sampling [9, 25].
 
2621STEMO: Early Spatio-temporal Forecasting with Multi-Objective Reinforcement Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Biased random walk sampling is used to select a nodeâ€™s neigh-
bours that contribute to its state. The bias term ğ›¼ğ‘ğ‘(ğ‘¡)and the transi-
tion probability minğ‘¡â€²AT
ğ‘¡,ğ‘¡â€²control the sampling process, favouring
nodes that are closer (in terms of reaching their optimal time) and
thus more relevant to the early forecasting task. Given the source
nodeğ‘£ğ‘–and the current node ğ‘£ğ‘—, the probability of accessing the
next nodeğ‘£ğ‘˜is represented by the bias term ğ›¼ğ‘ğ‘(ğ‘¡)multiplied by
the transition probability min
ğ‘¡â€²AT
ğ‘¡,ğ‘¡â€², whereğ›¼represent bias, and is
calculated as follows:
ğ›¼ğ‘ğ‘(ğ‘¡)=ï£±ï£´ï£´ï£´ ï£²
ï£´ï£´ï£´ï£³1
ğ‘ifğ‘£ğ‘˜=ğ‘£ğ‘–
1
ğ‘ifğ‘¡âˆ—
ğ‘˜â‰¤ğ‘¡
1else, (6)
whereğ‘controls the probability of revisiting the traversed node,
andğ‘controls the search program to distinguish whether the node
reaches the optimal time or not. After the random walk sampling,
the remaining steps are the same as in the DeepWalk [ 26] algorithm,
using the word2vec [ 4] method to learn the embedding function
ğ‘“ğ‘¡(Â·). In essence, nodes are treated as â€™wordsâ€™ and node sequences
sampled from random walks are treated as â€™sentencesâ€™. By feeding
these sequences into a word2vec model, we can learn an embedding
for each node that captures its context within the graph, i.e., its
neighbourhood structure.
4.3 Finding the Optimal Set of Policies
Since our goal is to induce a single model that can adapt to the
entire space of preferences Î©(a set of different ways decision-
makers can prioritise or value the various objectives involved in
an optimisation problem), we use a neural network to represent
the Q-valuesQâŠ†( Î©â†’R2)SÃ—Awith state spaceSand action
spaceA. The input to this neural network is a concatenation of
the states, actions, and user preferences. At time ğ‘¡, the network
takes the states sğ‘¡and preferences ğâˆˆÎ©as input. We estimate
the actions ağ‘¡that maximise the output of the network and verify
a series of optimal times according to the actions.
We useğœ€-greedy action selection to avoid abundant exploitation
as follows:
ağ‘¡=(
max ağğ‘‡Q(sğ‘¡,a,ğ;ğœƒ),w.p. 1âˆ’ğœ€
random, w.p.ğœ€, (7)
whereğœƒindeed refers to the parameters of the Q-network, which
are updated during training, action ağ‘¡={ğ‘ğ‘–
ğ‘¡}ğ‘›
ğ‘–=1is replaced by a
random action with probability ğœ€, andğœ€decreases exponentially
from 1 to 0 during training. For node ğ‘£ğ‘–,ğ‘ğ‘–
ğ‘¡=1indicates that ğ‘¡is
the optimal time ğ‘¡âˆ—
ğ‘–. Ifğ‘ğ‘–
ğ‘¡=0,ğ‘¡âˆˆ[0,ğ‘‡âˆ’1], timeğ‘‡âˆ’1is the optimal
time.
We designed reward rğ‘¡={ğ‘Ÿğ‘–
ğ‘¡,acc,ğ‘Ÿğ‘–
ğ‘¡,time}ğ‘›
ğ‘–=1includes accuracy
reward and temporal reward. The accuracy reward reflects how
well the current prediction and action align with the ground truth,
while the temporal reward encourages faster convergence to the
optimal time by penalising longer observation time. The specific
calculation is as follows:
ğ‘Ÿğ‘–
ğ‘¡,acc=âˆ’|bğ‘¥ğ‘–
ğ‘‡âˆ’ğ‘¥ğ‘–
ğ‘‡|, ğ‘Ÿğ‘–
ğ‘¡,time=âˆ’ğœŒğ‘¡, (8)
whereğœŒis the trade-off parameter.To train the deep neural network, we minimise the following
loss function at each step ğ‘˜:
ğ¿ğ´(ğœƒ)=Esğ‘¡,ağ‘¡,ğ
||yâˆ’Q(sğ‘¡,ağ‘¡,ğ;ğœƒ)||2
2
y=rğ‘¡+ğ›¾argğ‘„max
a,ğâ€²ğğ‘‡Q(sğ‘¡+1,a,ğâ€²;ğœƒğ‘˜). (9)
Thearg max operation is used to select the action and preference
that maximise the future expected total rewards. However, the
optimal frontier contains a large number of discrete policies, which
makes the landscape of the loss function non-smooth. To address
this problem, we use an auxiliary loss function:
ğ¿ğµ(ğœƒ)=Esğ‘¡,ağ‘¡,ğh
|ğğ‘‡yâˆ’ğğ‘‡Q(sğ‘¡,ağ‘¡,ğ;ğœƒ)|i
, (10)
The final loss function is ğ¿(ğœƒ)=(1âˆ’ğœ†)ğ¿ğ´(ğœƒ)+ğœ†ğ¿ğµ(ğœƒ), where
ğœ†is the weight that controls the trade off ğ¿ğ´andğ¿ğµ. The value of
ğœ†is increased gradually from 0 to 1 during training.
Algorithm 1 Training of STEMO.
Input: distance matrix AS, a preference sampling distribution D,
pathğ‘ğœ†for the weight ğœ†increasing from 0 to 1. Initialise encoder,
decoder, node embedding ğ‘“(ğ‘£ğ‘–)forğ‘£ğ‘–âˆˆV, network Q.
Parameter: corresponding learnable parameters ğœƒğ‘’,ğœƒğ‘‘,ğœƒğ‘“, andğœƒ.
Output: learned model
1:repeat
2: initialised Hâˆ’1for encoder. Sample a linear preference ğâˆ¼
D
3:forğ‘¡=0,...,ğ‘‡âˆ’1do
4: Observe recoded values Xğ‘¡.
5: Hğ‘¡=Encoder(Xğ‘¡,Hğ‘¡âˆ’1,AS;ğœƒğ‘’).
6: sğ‘–
ğ‘¡=Hğ‘¡||ğ‘“ğ‘¡(ğ‘£ğ‘–;ğœƒğ‘“), for allğ‘£ğ‘–inV.
7: ağ‘¡=(
maxağğ‘‡Q(sğ‘¡,a,ğ;ğœƒ),w.p. 1âˆ’ğœ€
random, w.p.ğœ€.
8: updateğœƒğ‘“according to equation 5.
9: initialised go symbol for the decoder.
10: bX(ğ‘¡)
ğ‘‡=Decoder(Hğ‘¡,AS;ğœƒğ‘‘).
11: ifupdate network then
12: Sampleğ‘ğpreferences{ğğ‘–âˆ¼D} .
13: Computeğ‘¦ğ‘–for all 1â‰¤ğ‘–â‰¤ğ‘ğaccording to equations
9.
14: update parameters ğœƒby descending its stochastic gradi-
entâˆ‡ğœƒğ¿(ğœƒ)according to equations 9 and 10:
15: Increaseğœ†along the path ğ‘ğœ†.
16: end if
17: end for
18:bXğ‘‡=Ãğ‘‡âˆ’1
ğ‘¡=0ağ‘¡âŠ™bX(ğ‘¡)
ğ‘‡
19: update parameters ğœƒğ‘’andğœƒğ‘‘by descending its stochastic
gradient according to MAE (Xğ‘‡,bXğ‘‡).
20:until stopping criteria is met.
4.4 Finding the Hidden Preference
Inspired by [ 34], we employ the hidden preference ğ, which can
greatly influence the policyâ€™s decisions. In the domain of Multi-
Objective Reinforcement Learning (MORL), the concept of hidden
 
2622KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Wei Shao, et al.
preferences refers to the underlying, often undisclosed preferences
that influence the prioritisation and weighting of multiple compet-
ing objectives within a decision-making process. These preferences
are deemed â€™hiddenâ€™ as they are not explicitly known a priori and
must be inferred from the interactions within the environment. The
elucidation of these preferences is pivotal for adapting and opti-
mising policies across diverse tasks where the relative importance
of objectives is not directly observable. This necessity arises from
the inherent complexity and variability of real-world scenarios,
where explicit preference delineation is impractical, thus requir-
ing algorithms capable of discerning and adapting to these latent
preferences effectively.
We search the hidden preferences with five steps, (1) The algo-
rithm learns a single parametric policy network that is optimised
over the entire space of preferences. This is significant because it
allows the system to adapt its policy based on any given prefer-
ence set, without needing to learn a new policy from scratch. (2)
Employing a generalised version of the Bellman equation, which
incorporates preferences into the decision-making process. This
adaptation enables the system to handle multiple objectives by ad-
justing the policy according to a set of linear preferences, which
can represent the relative importance of each objective. (3) The
algorithm uses hindsight experience replay to learn from past deci-
sions. (4) When provided with just scalar rewards and unknown
preferences, the algorithm utilises a combination of policy gradient
methods and stochastic search over the preference parameters. This
approach helps in estimating the hidden preferences that would
maximise the expected return, given the observed outcomes.
5 EXPERIMENT
In this section, we mainly introduce the datasets, baselines and spe-
cific parameter settings, etc. Experiments were conducted around
comparing the predicted performance of the Early Spatio-Temporal
Forecasting model based on Multi-Objective reinforcement learning
(STEMO) against baselines, analyzing the effect of each module,
and finding the hidden preference.
5.1 Experiment Settings
5.1.1 Datasets. We conduct experiments on three real-world large-
scale datasets: METR-LA [14] The dataset used in this study is
a collection of public transportation speed data from 207 sensors
on the Los Angeles Expressway. The data was collected using ring
detectors, and the sample rate is 5 minutes. The time range for the
data is from March 1, 2012 to June 30, 2012. EMS1The emergency
dataset used in this study is a collection of data from the New York
Fire Department. The dataset contains 145 areas based on postal
code and the sample rate is 1 hour. The recorded time range for the
data is from January 1, 2011 to November 30, 2011. NYPD2The
crime dataset used in this study is a collection of data from the
New York Police Department. The dataset is divided into 77 regions
based on administrative regions. The sample rate is 4 hours, and
the recording time range is from January 1, 2014 to December 31,
2015.
1https://data.cityofnewyork.us/Public-Safety/EMS-Incident-Dispatch-Data/76xm-
jjuj
2https://www.kaggle.com/datasets/mrmorj/new-york-city-police-crime-data-
historicTable 1: Statistics of datasets used in the experiments
Datasets Samples Nodes Interval
METR-LA 34272 207 5min
EMS 7992 145 1h
NYPD 4386 77 4h
Detailed statistics of the datasets are shown in Table 1. For NYPD,
we take the centroid of the crime site in the area as the location
coordinates of the area. For METR-LA, NYPD and EMS, 70% of
the data are used for training, 20% for testing, and the rest 10% for
verification. The proposed model is executed on a Windows system
with Nvidia GeForce RTX 3070Ti.
5.1.2 Parameters Settings. For our proposed model, we selected
parameters based on preliminary experiments and prior research.
Specifically, we adopted the Adam optimiser [ 16] with an initial
learning rate of 0.001, which proved to offer a stable and efficient
convergence in our preliminary experiments. We set the hidden
state dimension â„to 12 as it provided a good balance between
computational complexity and model performance. Similarly, the
batch size is set to 32. The number of preferences ğ‘ğœ”=16, the node
embedding dimension ğ‘’=4, the parameter ğœ…=0.005. In addition,
ğ‘=2,ğ‘=0.5,ğœŒ=0.5, andğ‘‡=12are all inspired by prior work. The
source code is available at https://github.com/coco0106/MO-STEP.
5.1.3 Baselines and Metrics. We compare STEMO with various
baselines for spatio-temporal prediction tasks and early prediction
tasks, including HA[21],LSTM [13],DCRNN [20],ASTGCN [10],
EARLIEST [11], Graph-WaveNet [32].
5.1.4 Metrics. We use three popular prediction indicators to eval-
uate the performance of all models, including mean absolute error
(MAE), root mean square error (RMSE), and mean absolute percent-
age error (MAPE), which are commonly used measures in regression
tasks to evaluate the average magnitude of prediction errors.
In addition, we computed the hypervolume (HV) [ 38] and the
spacing (S) [ 5] metrics, which are commonly used to evaluate the
performance of multi-objective optimization algorithms. The HV
metric measures the volume of the space dominated by the Pareto
front found by the algorithm up to a reference point. A higher HV
value means that the algorithm has found a set of solutions that
dominate a larger part of the target space, which is usually better. S
metric measures the distance between adjacent solutions in Pareto
frontier. A lower S value is usually better, because it shows that the
solutions are more evenly distributed and provide decision makers
with a wider range of trade-off options.
HV=Ã˜
ğœ™âˆˆÎ¦ğ‘‰(ğœ™,ğœ‘), (11)
whereğ‘‰(ğœ™,ğœ‘)represents the hyper volume of the space formed be-
tween the solution ğœ™and the reference point ğœ‘in the non-dominant
solution set Î¦, which is the volume of the hypercube constructed
with the connecting line between the solution ğœ™and the reference
pointğœ‘as the diagonal, and the solution with the lowest accuracy
 
2623STEMO: Early Spatio-temporal Forecasting with Multi-Objective Reinforcement Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Table 2: Performance comparison on the three datasets. The average used time percentage is calculated according to
100%
ğ‘›Ãğ‘›
ğ‘–=1ğ‘¡âˆ—
ğ‘–/ğ‘‡. The optimal time of LSTM, DCRNN, and ASTGCN is a fixed value set in advance, which means that the model is
not responsible for determining the optimal time.
DatasetsAverage used
time percentage100% 75% 50% 25%
MAE RMSE MAE RMSE MAE RMSE MAE RMSEMETR-LAHA 7.22 9.46 7.22 9.46 7.22 9.46 7.22 9.46
LSTM 4.99Â±0.07 7.48Â±0.07 7.17Â± 0.11 10.21Â± 0.10 7.50Â± 0.13 10.46Â±0.11 7.72Â±0.15 10.68Â±0.17
DCRNN 2.27Â±0.06 3.94Â±0.07 2.91Â±0.08 5.76Â±0.09 3.25Â±0.10 6.68Â±0.09 3.48Â±0.11 7.23Â±0.10
ASTGCN 3.54Â±0.16 7.39Â±0.17 5.05Â±0.18 6.48Â±0.18 6.65Â±0.20 12.70Â±0.21 7.64Â±0.23 14.40Â±0.25
EARLIEST 5.01Â±0.08 7.46Â±0.09 5.93Â±0.10 8.21Â±0.10 6.14Â±0.11 9.26Â±0.10 6.85Â±0.12 10.06Â±0.11
Graph-WaveNet 2.38Â±0.15 4.21Â±0.08 3.22Â±0.11 6.45Â±0.09 3.81Â±0.07 7.70Â±0.08 4.35Â±0.16 8.65Â±0.1
STEMO 2.23Â±0.07 3.96Â±0.06 2.37Â±0.08 4.45Â±0.08 3.23Â±0.08 5.69Â±0.09 3.49Â±0.09 6.15Â±0.09EMSHA 1.47 2.41 1.47 2.41 1.47 2.41 1.47 2.41
LSTM 1.61Â± 0.04 2.63Â±0.05 1.67Â± 0.04 2.78Â±0.06 1.67Â±0.07 2.79Â±0.08 1.68Â±0.08 2.78Â±0.09
DCRNN 1.45Â± 0.03 2.60Â±0.03 1.69Â±0.04 3.19Â±0.05 1.58Â±0.05 2.92Â±0.05 1.70Â±0.06 3.16Â±0.07
ASTGCN 1.49Â±0.04 1.95Â±0.03 1.78Â±0.04 2.49Â±0.05 1.85Â±0.05 2.84Â±0.06 2.01Â±0.07 3.12Â±0.08
EARLIEST 1.62Â± 0.05 2.63Â±0.06 1.64Â±0.05 2.67Â± 0.06 1.66Â±0.06 2.71Â±0.06 1.68Â± 0.06 2.79Â± 0.07
Graph-WaveNet 1.25Â±0.07 2.42Â±0.12 1.27Â±0.09 2.46Â±0.16 1.29Â±0.11 2.48Â±0.04 1.28Â±0.06 2.49Â±0.17
STEMO 1.29Â± 0.02 2.23Â±0.03 1.32Â± 0.03 2.32Â± 0.04 1.40Â± 0.03 2.41Â± 0.03 1.44Â± 0.03 2.49Â±0.05N
YPDHA 1.54 2.00 1.54 2.00 1.54 2.00 1.54 2.00
LSTM 1.52Â±0.04 2.16Â±0.04 1.61Â±0.05 2.29Â±0.06 1.73Â± 0.07 2.40Â± 0.07 1.72Â± 0.08 2.40Â±0.09
DCRNN 1.58Â±0.04 2.16Â±0.04 1.60Â±0.05 2.21Â±0.05 1.61Â±0.05 2.22Â± 0.06 1.66Â± 0.06 2.32Â± 0.07
ASTGCN 2.18Â±0.06 3.08Â±0.12 2.88Â±0.07 3.31Â± 0.13 2.99Â±0.08 3.42Â± 0.13 3.69Â±0.09 4.09Â±0.14
EARLIEST 1.52Â±0.05 2.17Â±0.05 1.59Â± 0.06 2.23Â± 0.07 1.64Â±0.07 2.36Â±0.07 1.65Â± 0.08 2.39Â± 0.09
Graph-WaveNet 1.48Â±0.08 2.05Â±0.11 1.5Â±0.06 2.08Â±0.11 1.54Â±0.15 2.14Â±0.05 1.58Â±0.08 2.18Â±0.02
STEMO 1.36Â± 0.03 1.82Â± 0.05 1.38Â± 0.04 1.97Â± 0.06 1.45Â± 0.06 2.12Â± 0.07 1.49Â± 0.07 2.27Â± 0.09
Table 3: Performance comparison on three datasets (HV and S metrics). â†‘means that the higher the metric value, the better the
model performance, and â†“means that the lower the metric value, the better the model performance.
DatasetsMETR-LA EMS NYPD
HVâ†‘ Sâ†“ HVâ†‘ Sâ†“ HVâ†‘ Sâ†“
HA 3.71 - 0.56 - 1.57 -
LSTM 2.96 1.25 0.28 0.34 1.30 0.35
DCRNN 5.88 1.33 0.12 0.55 1.38 0.34
ASTGCN 2.41 1.77 0.26 0.59 0.36 0.53
EARLIEST 3.91 1.08 0.33 0.34 1.32 0.33
Graph-WaveNet 4.68 0.81 0.26 0.35 0.36 0.38
STEMO 6.73 0.71 0.58 0.34 1.47 0.36
and the largest time used percentage in the corresponding data set
is used as the reference point.
S=vut
1
|Î¦|âˆ’1|Î¦|âˆ‘ï¸
ğ‘–=1(Â¯ğ‘‘âˆ’ğ‘‘ğ‘–)2, (12)
whereğ‘‘ğ‘–represents the minimum distance from the ğ‘–ğ‘¡â„solution to
other solutions in Î¦, and Â¯ğ‘‘represents the average value of all ğ‘‘ğ‘–.
5.2 Experiment Results
We evaluate the performance of STEMO against the chosen base-
line models in terms of the aforementioned metrics. The impact ofeach module is quantified through an ablation study, where we se-
quentially remove one module at a time and measure the change in
overall performance. In addition, we also reveal hidden preferences.
5.2.1 Performance Comparison. As shown in Table 2, we vary the
average used time percentage by adjusting the preference, where
the average usage time percentage, defined as the sum of the opti-
mal time instances ğ‘¡âˆ—
ğ‘–for allğ‘›nodes divided by the total time period
ğ‘‡and multiplied by 100%, represents the proportion of optimal time
in the total time. This approach allows us to explore different predic-
tion timeliness and assess the corresponding prediction accuracy,
where the accuracy is measured by the error between the ground
 
2624KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Wei Shao, et al.
Table 4: Some specific elements (the similarity matrix, node embedding, and policy) were excluded from the model and the
resulting modified modelâ€™s performance was compared to that of the complete STEMO model.
Average used
time percentage100% 75% 50% 25%
MAE RMSE MAPE MAE RMSE MAPE MAE RMSE MAPE MAE RMSE MAPE
w/o similarity matrix 1.38 1.98 5.21% 1.43 2.13 5.72% 1.50 2.28 6.32% 1.57 2.43 6.65%
w/o node embedding 1.36 1.84 4.92% 1.40 1.96 5.67% 1.49 2.06 5.74% 1.55 2.33 6.03%
w/o policy 1.36 1.83 4.91% 1.39 1.98 5.72% 1.52 2.74 6.43% 1.69 2.51 6.77%
STEMO 1.36 1.82 4.91% 1.38 1.97 5.01% 1.45 2.12 5.32% 1.49 2.27 5.84%
truth and the predicted values obtained by each node at their opti-
mal time. We observe that: (1)When considering the same average
used time percentage, the STEMO model exhibits higher accuracy
compared to LSTM, DCRNN, ASTGCN, and Graph-WaveNet. The
accuracy of the STEMO model shows a lesser decrease when the
average usage time percentage experiences an equivalent reduc-
tion. This suggests that the STEMO model, which determines the
optimal time based on the networkâ€™s dynamics, can adapt to di-
verse scenarios, striking a balance between timeliness and accuracy
in forecasting. In contrast, the fixed optimal time used by LSTM,
DCRNN, ASTGCN, and Graph-WaveNet might not adequately ac-
count for the dynamic nature of various scenarios. (2)When the
average used time percentage is the same, the STEMO model out-
performs EARLIEST in terms of accuracy. This improvement can
be attributed to the STEMO modelâ€™s consideration of spatial and
temporal characteristics, especially in scenarios like the METR-
LA dataset, where the nodes are densely distributed and exhibit
strong correlations. The STEMO model leverages a Multi-Graph
Convolutional Neural network (MGCN) that incorporates multi-
ple time-steps similarity matrices and the distance matrix. This
framework effectively captures and utilises the spatio-temporal cor-
relations among the nodes. Additionally, our experiments revealed
that ASTGCN exhibits poor performance on the NYPD dataset. This
outcome could be attributed to missing values within the dataset
and the limited representation ability of the model.
As depicted in Table 3, above-average HV and lower S metrics
for the STEMO model indicate its effectiveness in managing a trade-
off between accuracy and timeliness in predictions - our primary
objectives in this study. A higher HV, as observed in the STEMO
model, signifies not only better convergence, illustrating the prox-
imity of the solution set to the real Pareto frontier, but also greater
extensiveness, indicating a broad coverage of the solution set in the
objective space. Additionally, it implies better uniformity, showing
an even distribution of individual solutions in the set. This high HV
value affirms our assumption that the STEMO model can effectively
balance prediction accuracy while maintaining the timeliness of
predictions and offer a wide array of diverse solutions. On the other
hand, the S metric provides a measure of the dispersion or spread of
the solutions in the objective space. A lower S, as displayed by the
STEMO model, suggests that the solutions are evenly distributed.
This means that the STEMO model offers a variety of optimal times
for forecasting, and provides a robust and versatile model for vari-
ous scenarios. This aligns well with our goal of creating a model
that can cater to diverse situations with reliable results across a
range of forecasting times.5.2.2 Ablation Study. To assess the contribution of individual com-
ponents within our proposed STEMO model, we conducted an
ablation study using the NYPD dataset, the results of which are pre-
sented in Table 4. In the ablation study, we evaluated the following
variants of the STEMO model: w/o similarity matrix (without sim-
ilarity matrix), w/o node embedding (without node embedding),
w/o policy (without policy only use fixed value).
As seen from Table 4, the full STEMO model consistently outper-
forms all variants across different average used time percentages
in terms of MAE, RMSE, and MAPE. For instance, when the simi-
larity matrix is removed (â€™w/o similarity matrixâ€™), the performance
degrades, especially at lower average used time percentages. This
suggests the importance of the similarity matrix in capturing spatio-
temporal information to maintain the modelâ€™s performance even at
lower time percentages. The removal of the node embedding (â€™w/o
node embeddingâ€™) and the policy network (â€™w/o policyâ€™) also leads
to a decrease in performance. This emphasises the significance
of the node embedding in capturing the spatial dependencies and
the policy network in adaptively determining the optimal time for
predictions. Overall, these findings underline the importance of
each component and how they collectively contribute to the robust
performance of the STEMO model in balancing prediction accuracy
and timeliness.
5.2.3 Revealing hidden preferences. We modified the parameter ğœŒ
to provide vectorised rewards for encoding two different objects:
timeliness and accuracy. We used two different tasks (g1, g2) and
used only 100 episodes to learn the hidden preferences. The derived
hidden preferences are depicted in Table 5. The learned preferences
of the model are concentrated on the diagonal, indicating that
they are in good agreement with the actual potential preferences.
For variant g1, the model shows a strong preference (0.67) for
timeliness. This result is consistent with the primary goal of g1,
which emphasizes making predictions as quickly as possible. g2
primarily focuses on accuracy, as evidenced by the significantly
higher preference weight (0.97) for accuracy.
Table 5: Derived preferences for timeliness and accuracy in
the spatio-temporal early prediction model across two task
variants (g1 and g2).
timeliness accurancy
g1 0.67 0.33
g2 0.02 0.97
 
2625STEMO: Early Spatio-temporal Forecasting with Multi-Objective Reinforcement Learning KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
6 DISCUSSION
Although the STEMO model shows promise in handling early spatio-
temporal forecasting tasks, several areas merit further exploration.
First, the modelâ€™s performance might be restricted if it was primar-
ily validated on a limited set of real-world datasets, which brings
into question its generalizability to different scenarios or data types.
Future studies could benefit from testing the model on a more
diverse datasets from varying domains. Second, the modelâ€™s com-
plexity might pose challenges in interpretation and computational
efficiency. Third, future work should aim to simplify the model or
increase its interpretability without sacrificing performance. Ad-
ditionally, the modelâ€™s ability to learn hidden preferences requires
deeper investigation.
7 CONCLUSION
We propose the Early Spatio-Temporal Forecasting model based on
Multi-Objective reinforcement learning (STEMO) model, specifi-
cally designed to address challenges in early spatio-temporal fore-
casting. The STEMO model leverages the Multi-Graph Convolu-
tional Neural network (MGCN) and Gated Recurrent Unit (GRU)
to capture and analyze spatio-temporal correlations. Further, it uti-
lizes the hidden state from the encoderâ€™s output in conjunction
with node embeddings to adaptively determine the optimal time
for forecasting. Additionally, we also explore hidden preferences
within our model. Future work will focus on further refining our
model, exploring its application in other domains, and addressing
any limitations encountered in this study. We believe that our re-
search contributes significantly to the ongoing discourse in the
field of spatio-temporal forecasting and will serve as a foundation
for future advancements.
ACKNOWLEDGMENTS
We acknowledge the support of the Australian Research Council
(ARC) Centre of Excellence for Automated Decision-Making and
Society (ADM+S) (CE200100005). We also acknowledge the sup-
port of National Natural Science Foundation of China (U21A20446).
This research/project was undertaken with the assistance of com-
puting resources from RACE (RMIT AWS Cloud Supercomputing)
(RMAS00045). Flora Salim would also like to acknowledge edge the
support of Ciscoâ€™s National Industry Innovation Network (NIIN)
Research Chair Program.
REFERENCES
[1]Mohammed S Ahmed and Allen R Cook. 1979. Analysis of freeway traffic time-
series data by using Box-Jenkins techniques.
[2]Rafaela Castro, Yania M Souto, Eduardo Ogasawara, Fabio Porto, and Eduardo
Bezerra. 2021. Stconvs2s: Spatiotemporal convolutional sequence to sequence
network for weather forecasting. Neurocomputing 426 (2021), 285â€“298.
[3]Kyunghyun Cho, Bart Van MerriÃ«nboer, Dzmitry Bahdanau, and Yoshua Ben-
gio. 2014. On the properties of neural machine translation: Encoder-decoder
approaches. arXiv preprint arXiv:1409.1259 (2014).
[4]Kenneth Ward Church. 2017. Word2Vec. Natural Language Engineering 23, 1
(2017), 155â€“162.
[5]Kalyanmoy Deb and Sachin Jain. 2002. Running performance metrics for evolu-
tionary multi-objective optimization. (07 2002).
[6]Alireza Ermagun and David Levinson. 2018. Spatiotemporal traffic forecasting:
review and proposed directions. Transport Reviews 38, 6 (2018), 786â€“814.
[7]Mohamed F Ghalwash, Vladan Radosavljevic, and Zoran Obradovic. 2014. Utiliz-
ing temporal patterns for estimating uncertainty in interpretable early decision
making. In Proceedings of the 20th ACM SIGKDD international conference on
Knowledge discovery and data mining. 402â€“411.[8]Mohamed F Ghalwash, DuÅ¡an Ramljak, and Zoran ObradoviÄ‡. 2012. Early clas-
sification of multivariate time series using a hybrid HMM/SVM model. In 2012
IEEE International Conference on Bioinformatics and Biomedicine. IEEE, 1â€“6.
[9]Aditya Grover and J. Leskovec. 2016. node2vec: Scalable Feature Learning for
Networks. Proceedings of the 22nd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (2016). https://doi.org/10.1145/2939672.
2939754
[10] Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan. 2019.
Attention based spatial-temporal graph convolutional networks for traffic flow
forecasting. In Proceedings of the AAAI conference on artificial intelligence. AAAI
Press, Honolulu, Hawaii, USA, 922â€“929.
[11] Thomas Hartvigsen, Cansu Sen, Xiangnan Kong, and Elke Rundensteiner. 2019.
Adaptive-halting policy network for early classification. In Proceedings of the 25th
ACM SIGKDD International Conference on Knowledge Discovery & Data Mining.
101â€“110.
[12] Guoliang He, Yong Duan, Rong Peng, Xiaoyuan Jing, Tieyun Qian, and Lingling
Wang. 2015. Early classification on multivariate time series. Neurocomputing 149
(2015), 777â€“787.
[13] Sepp Hochreiter and JÃ¼rgen Schmidhuber. 1997. Long short-term memory. Neural
computation 9, 8 (1997), 1735â€“1780.
[14] Hosagrahar V Jagadish, Johannes Gehrke, Alexandros Labrinidis, Yannis Pa-
pakonstantinou, Jignesh M Patel, Raghu Ramakrishnan, and Cyrus Shahabi. 2014.
Big data and its technical challenges. Commun. ACM 57, 7 (2014), 86â€“94.
[15] Maxwell B Joseph, Matthew W Rossi, Nathan P Mietkiewicz, Adam L Mahood,
Megan E Cattau, Lise Ann St. Denis, R Chelsea Nagy, Virginia Iglesias, John T
Abatzoglou, and Jennifer K Balch. 2019. Spatiotemporal prediction of wildfire
size extremes with Bayesian finite sample maxima. Ecological Applications 29, 6
(2019), e01898.
[16] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[17] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph
convolutional networks. arXiv preprint arXiv:1609.02907 54, 4 (2016), 2645â€“2656.
[18] Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E
Howard, Wayne Hubbard, and Lawrence D Jackel. 1989. Backpropagation applied
to handwritten zip code recognition. Neural computation 1, 4 (1989), 541â€“551.
[19] Fuxian Li, Jie Feng, Huan Yan, Guangyin Jin, Fan Yang, Funing Sun, Depeng Jin,
and Yong Li. 2021. Dynamic graph convolutional recurrent network for traffic
prediction: Benchmark and solution. ACM Transactions on Knowledge Discovery
from Data (TKDD) (2021).
[20] Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2017. Diffusion convolu-
tional recurrent neural network: Data-driven traffic forecasting. arXiv preprint
arXiv:1707.01926 (2017).
[21] Jing Liu and Wei Guan. 2004. A summary of traffic flow forecasting methods [J].
Journal of highway and transportation research and development 3 (2004), 82â€“85.
[22] Usue Mori, Alexander Mendiburu, Sanjoy Dasgupta, and Jose A Lozano. 2017.
Early classification of time series by simultaneously optimizing the accuracy and
earliness. IEEE transactions on neural networks and learning systems 29, 10 (2017),
4569â€“4578.
[23] Usue Mori, Alexander Mendiburu, Eamonn Keogh, and Jose A Lozano. 2017.
Reliable early classification of time series based on discriminating the classes
over time. Data mining and knowledge discovery 31, 1 (2017), 233â€“263.
[24] Meinard MÃ¼ller. 2007. Dynamic time warping. Information retrieval for music
and motion (2007), 69â€“84.
[25] Duong Nguyen and Fragkiskos D. Malliaros. 2018. BiasedWalk: Biased Sampling
for Representation Learning on Graphs. 2018 IEEE International Conference on Big
Data (Big Data) (2018), 4045â€“4053. https://doi.org/10.1109/BigData.2018.8621872
[26] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning
of social representations. In Proceedings of the 20th ACM SIGKDD international
conference on Knowledge discovery and data mining. 701â€“710.
[27] Wei Shao, Zhiling Jin, Shuo Wang, Yufan Kang, Xiao Xiao, Hamid Menouar,
Zhaofeng Zhang, Junshan Zhang, and Flora Salim. 2022. Long-term Spatio-
Temporal Forecasting via Dynamic Multiple-Graph Attention. In 31st Interna-
tional Joint Conference on Artificial Intelligence, IJCAI 2022. International Joint
Conferences on Artificial Intelligence, 2225â€“2232.
[28] Wei Shao, Ziyan Peng, Yufan Kang, Xiao Xiao, and Zhiling Jin. 2023. Early
Spatiotemporal Event Prediction via Adaptive Controller and Spatiotemporal
Embedding. In 2023 IEEE International Conference on Data Mining (ICDM). IEEE,
1307â€“1312.
[29] Wei Shao, Yu Zhang, Pengfei Xiao, Kyle Kai Qin, Mohammad Saiedur Rahaman,
Jeffrey Chan, Bin Guo, Andy Song, and Flora D Salim. 2024. Transferrable
contextual feature clusters for parking occupancy prediction. Pervasive and
Mobile Computing 97 (2024), 101831.
[30] Romain Tavenard and Simon Malinowski. 2016. Cost-aware early classification
of time series. In Joint European conference on machine learning and knowledge
discovery in databases. Springer, 632â€“647.
[31] Senzhang Wang, Jiannong Cao, and Philip S. Yu. 2022. Deep Learning for Spatio-
Temporal Data Mining: A Survey. IEEE Transactions on Knowledge and Data
Engineering 34, 8 (2022), 3681â€“3700. https://doi.org/10.1109/TKDE.2020.3025580
 
2626KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Wei Shao, et al.
[32] Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang, and Chengqi
Zhang. 2019. Graph WaveNet for Deep Spatial-Temporal Graph Modeling. In
Proceedings of the 28th International Joint Conference on Artificial Intelligence.
AAAI Press, 1907â€“1913.
[33] Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Liefeng Bo, Xiyue Zhang, and
Tianyi Chen. 2021. Spatial-Temporal Sequential Hypergraph Network for Crime
Prediction with Dynamic Multiplex Relation Learning.. In IJCAI. International
Joint Conferences on Artificial Intelligence Organization, 1631â€“1637.
[34] Runzhe Yang, Xingyuan Sun, and Karthik Narasimhan. 2019. A generalized algo-
rithm for multi-objective reinforcement learning and policy adaptation. Advances
in neural information processing systems 32 (2019).[35] Suwei Yang, Massimo Lupascu, and Kuldeep S Meel. 2021. Predicting forest fire
using remote sensing data and machine learning. In Proceedings of the AAAI
Conference on Artificial Intelligence. arXiv, 14983â€“14990.
[36] Lexiang Ye and Eamonn Keogh. 2009. Time series shapelets: a new primitive for
data mining. In Proceedings of the 15th ACM SIGKDD international conference on
Knowledge discovery and data mining. 947â€“956.
[37] Daoye Zhu, Yi Yang, Fuhu Ren, Shunji Murai, Chengqi Cheng, and Min Huang.
2021. Novel Intelligent Spatiotemporal Grid Earthquake Early-Warning Model.
Remote Sensing 13, 17 (2021), 3426.
[38] E. Zitzler and L. Thiele. 1998. An evolutionary algorithm for multiobjective
optimization: the strength Pareto approach, Vol. 43.
 
2627