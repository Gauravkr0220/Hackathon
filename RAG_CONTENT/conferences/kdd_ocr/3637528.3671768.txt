Orthogonality Matters: Invariant Time Series Representation for
Out-of-distribution Classification
Ruize Shi
rzshi@hust.edu.cn
Huazhong University of Science and
Technology
Wuhan, ChinaHong Huangâˆ—
honghuang@hust.edu.cn
Huazhong University of Science and
Technology
Wuhan, ChinaKehan Yin
kehanyin@hust.edu.cn
Huazhong University of Science and
Technology
Wuhan, China
Wei Zhou
weizhou2021@hust.edu.cn
Huazhong University of Science and
Technology
Wuhan, ChinaHai Jin
hjin@hust.edu.cn
Huazhong University of Science and
Technology
Wuhan, China
ABSTRACT
Previous works for time series classification tend to assume that
both the training and testing sets originate from the same distri-
bution. This oversimplification deviates from the complexity of
reality and makes it challenging to generalize methods to out-of-
distribution (OOD) time series data. Currently, there are limited
works focusing on time series OOD generalization, and they typ-
ically disentangle time series into domain-agnostic and domain-
specific features and design tasks to intensify the distinction be-
tween the two. However, previous models purportedly yielding
domain-agnostic features continue to harbor domain-specific in-
formation, thereby diminishing their adaptability to OOD data. To
address this gap, we introduce a novel model called Invariant Time
Series Representation (ITSR). ITSR achieves a learnable orthogonal
decomposition of time series using two sets of orthogonal axes.
In detail, ITSR projects time series onto these two sets of axes
separately and obtains mutually orthogonal invariant features and
relevant features. ITSR theoretically ensures low similarity between
these two features and further incorporates various tasks to op-
timize them. Furthermore, we explore the benefits of preserving
orthogonality between invariant and relevant features for OOD
time series classification in theory. The results on four real-world
datasets underscore the superiority of ITSR over state-of-the-art
methods and demonstrate the critical role of maintaining orthogo-
nality between invariant and relevant features. Our code is available
at https://github.com/CGCL-codes/ITSR.
âˆ—Hong Huang is the corresponding author. Ruize Shi, Hong Huang, Kehan Yin, Wei
Zhou, and Hai Jin are afliated with the National Engineering Research Center for Big
Data Technology and System, Services Computing Technology and System Lab, Cluster
and Grid Computing Lab, School of Computer Science and Technology, Huazhong
University of Science and Technology.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.3671768CCS CONCEPTS
â€¢Information systems â†’Data stream mining.
KEYWORDS
Time Series Classification; Out-of-distribution; Invariant Feature
ACM Reference Format:
Ruize Shi, Hong Huang, Kehan Yin, Wei Zhou, and Hai Jin. 2024. Orthogo-
nality Matters: Invariant Time Series Representation for Out-of-distribution
Classification. In Proceedings of the 30th ACM SIGKDD Conference on Knowl-
edge Discovery and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona,
Spain. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.
3671768
1 INTRODUCTION
EEG data
Figure 1: The collection of EEG data is influenced by the
devices and individuals, leading to distribution shifts. Note
that the blue EEG signal is used as the benchmark.
Traditional works for time series classification heavily rely on
the assumption that the training data and testing data belong to
the same distribution, and they often suffer from substantial perfor-
mance degradation when analyzing out-of-distribution (OOD) data
[12]. Unfortunately, as illustrated in Figure 1, distribution shifts
are widespread in time series. Electroencephalogram (EEG) signals
find extensive use in healthcare and variations in collection devices
and individual characteristics may lead to distribution shifts, ren-
dering general methods unable to generalize to unknown devices
and populations. Indeed, different individuals and devices can be
considered as distinct domains, and there exist distribution shifts
between these domains, which is known as domain shift [48].
 
2674
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruize Shi et al.
UCIHARUniMiB SHAREMGOpportunity
Dataset020406080100Accuracy (%)Random Cross-domain
(a) Performance of GRU
UCIHARUniMiB SHAREMGOpportunity
Dataset0.00.20.40.6SimilarityCosine Pearson (b) Similarity of GILE
Figure 2: Figure (a) is the performance of GRU under random
and cross-domain settings. Figure (b) is the cosine similarity
and Pearson correlation coefficient between domain-agnostic
and domain-specific features obtained by GILE [ 33]. For the
cross-domain results in Figure (a) and all results in Figure (b),
we report the average results for each domain as a testing set.
Moreover, the results in Figure (b) are the average of the ab-
solute values of the similarity, to prevent the cancellation of
positive and negative similarities between different samples.
To vividly illustrate the urgency of time series OOD general-
ization and the presence of distribution shifts between domains,
we re-evaluate the representative method GRU [ 4] in the time se-
ries classification task. Specifically, we select four datasets with
multiple domains and split the datasets using both traditional ran-
dom setting and cross-domain setting (detailed information can
be found in Section 5.1 and Section 5.2). As shown in Figure 2 (a),
we can clearly observe that GRU experiences a catastrophic drop
in performance when facing cross-domain data, with a significant
decrease of over 20% in most cases. This indicates the presence
of distribution shifts in different domains and also highlights the
impracticality of treating the testing and training sets as the same
distribution. In other words, if we can extract representations from
time series that remain consistent across different domains, they
can also be used for robust classification of OOD time series data.
Conveniently, obtaining domain information (e.g., device, age) for
training data is straightforward since data collection is typically
anonymous, which alleviates respondentsâ€™ concerns.
Indeed, previous methods consistently address domain shifts,
either explicitly or implicitly, to facilitate OOD time series clas-
sification [ 28,33]. Typically, they map time series into domain-
agnostic and domain-specific features. The former features remain
constant across domains and play a crucial role in downstream
tasks, while the latter features indicate they vary with each domain.
These methods often design new tasks to minimize the similar-
ity between these two features and utilize the domain-agnostic
features for OOD generalization. Unfortunately, previous works
focus solely on optimizing domain-agnostic and domain-specific
features at the task level. Hence, the two features they generate
still exhibit high similarity, as illustrated in Figure 2 (b), indicating
that domain-specific information persists within their purportedly
domain-agnostic features, and is still affected by domain shifts.
To address this issue, we propose a simple yet effective method
called Invariant Time Series Representation (ITSR), designed to dis-
entangle time series into mutually orthogonal invariant featuresand relevant features, where the invariant features play a crucial
role in downstream tasks across different domains and the relevant
features imply variations between domains. Specifically, the key
to ITSR lies in two sets of orthogonal axes, namely the invariant
axes and the relevant axes, and subsequently projecting the time
series onto these axes to obtain invariant features and relevant
features, guaranteeing their minimal similarity in theory. Moreover,
we theoretically examine the benefits of maintaining orthogonality
between invariant features and relevant features for OOD time
series classification. Subsequently, ITSR employs multiple tasks
to optimize the invariant axes and relevant axes, allowing for the
extraction of high-quality invariant features from time series for
classification. During inference, for OOD testing data, projecting it
onto the invariant axes yields invariant features for downstream
tasks. The contributions of our work can be summarized as follows:
â€¢Our research delves into the OOD generalization for time series
classification. This is a frequently encountered challenge in the
real world, which yet remains underexplored.
â€¢We propose a novel model ITSR, which uses orthogonality to de-
compose time series into invariant features and relevant features,
ensuring their low similarity and offering theoretical insights.
â€¢Experiments on multiple OOD time series datasets demonstrate
the superiority of ITSR and underscore the importance of main-
taining orthogonality between invariant and relevant features.
2 RELATED WORK
2.1 Time Series Representation
Time series representation is a realistic research area that can be
applied to various fields such as human signal recognition, web
e-commerce, weather prediction, energy estimation. Traditional
time series analyses such as ARIMA [ 34] and Prophet [ 35] make
predictions by assuming and modeling the transformation patterns
of time series. However, real-world time series are usually more
complex, thus limiting the effectiveness of these methods. With the
development of deep learning techniques, deep models for temporal
modeling have been proposed, i.e., RNN-based [ 10] and TCN-based
[22] methods. There are many RNN-based methods [ 4,15,21], they
learn the contextual links between time steps with the help of
the recurrent structure. On the other hand, TCN-based methods
[8,11,17] use a convolutional kernel to extract features by sliding
in the time dimension. Recently, methods based on Transformer
[37] have attracted a lot of attention, and many models [ 18,40,
49] have appeared one after another, which achieve remarkable
results on various time series tasks. In addition, a meaningful work
[45] summarizes previous transformer-based methods and analyzes
the challenges faced in the field. Nonetheless, previous methods
overlook the distribution shift of time series, which is common in
reality. When traditional methods are applied to OOD data, their
performance significantly deteriorates.
2.2 OOD / Domain Generalization
OOD generalization, also known as domain generalization [ 43,48],
is a highly challenging task encountered in many fields [ 19,29].
It aims to build a robust model from a dataset encompassing var-
ious domains, ultimately delivering high performance on unseen
 
2675Orthogonality Matters: Invariant Time Series Representation for Out-of-distribution Classification KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
encoder featuresEncoder
Time series with 
distribution shiftLabel 
Classifier
Domain 
Classifier
Learnable Orthogonal Decomposition
Projectionencoder 
featuresLearnable 
Orthogonal 
DecompositionInvariant features
Relevant features
Invariant
space
Relevant
spaceOrthogonality Invariant
features
Relevant
featuresOrthogonality
lossaxes0Orthogonality Loss 
Invariant axes: 
Relevant axes: Relevant
space
Invariant 
Space90Â°Propagation of invariant features
Propagation of relevant features
Figure 3: Architecture of the proposed ITSR.
domains. OOD generalization depends entirely on training with
source domains without access to testing data, making it chal-
lenging yet realistic. In computer vision, a prevalent strategy in-
volves the extraction of domain-invariant features across multiple
source domains [ 24,30,41]. Domain adversarial learning [ 13] is
also commonly applied in OOD generalization. Moreover, some
works have tried to disentangle features to capture more stable
domain-invariant information. For example, FACT [ 42] employs
the Fourier transform to extract invariant features in the frequency
domain for OOD generalization. Inspired by causal learning, Sta-
bleNet [ 47] introduces a nonlinear feature decorrelation technique
for obtaining domain-invariant information. Research on OOD time
series classification remains limited. AdaRNN [ 9] divides the time
series into multiple slices to extract invariant features. Diversify
[28] identifies the â€™worst-caseâ€™ latent distribution scenario via adver-
sarial learning and then reduces the gap between time series slices.
GILE [33] extracts domain-invariant and domain-specific features
using the VAE [ 20]. However, these methods do not fully disen-
tangle domain-specific information from domain-agnostic features,
constraining their generalization to OOD time series data.
3 PRELIMINARY
Definition 2.1. Time Series. In this work, a time series dataset
is defined asT={X,D,Y}, whereX,D, andYdenote the
sets of time series, domains, and labels, respectively. Specifically,
X={ğ‘¥1,ğ‘¥2,Â·Â·Â·,ğ‘¥ğ‘ğ‘¥}indicatesğ‘ğ‘¥time series samples and âˆ€ğ‘¥ğ‘–âˆˆ
X,ğ‘–âˆˆ [1,ğ‘ğ‘¥]is a time series and can be further described as
ğ‘¥ğ‘–={ğ‘¥1
ğ‘–,ğ‘¥2
ğ‘–,Â·Â·Â·,ğ‘¥ğ‘š
ğ‘–}, whereğ‘šrepresents the length of the time se-
ries. In addition,D={ğ‘‘1,ğ‘‘2,Â·Â·Â·,ğ‘‘ğ‘ğ‘‘}andY={ğ‘¦1,ğ‘¦2,Â·Â·Â·,ğ‘¦ğ‘ğ‘¦},
whereğ‘ğ‘‘andğ‘ğ‘¦are the number of domains and the categories.As mentioned before, obtaining domain information for the train-
ing data is easily achievable since it is typically collected anony-
mously, preventing information leakage. However, note that the
domain of the testing data is unknown. Building upon this, we
define the distribution shift between training and testing data.
Definition 2.2. Distribution Shift. Given a time series dataset
T={X,D,Y}, we divideTinto the training data Tğ‘¡ğ‘Ÿ={Xğ‘¡ğ‘Ÿ,Dğ‘¡ğ‘Ÿ,
Yğ‘¡ğ‘Ÿ}and testing dataTğ‘¡ğ‘’={Xğ‘¡ğ‘’,Dğ‘¡ğ‘’,Yğ‘¡ğ‘’}. In this case, we de-
fine the distribution of training and testing data as P(Xğ‘¡ğ‘Ÿ,Yğ‘¡ğ‘Ÿ)and
P(Xğ‘¡ğ‘’,Yğ‘¡ğ‘’)respectively, traditional works simplistically assume
these two distributions to be the same. However, in the real world,
these two distributions often differ, implying the distribution shift,
i.e.,P(Xğ‘¡ğ‘Ÿ,Yğ‘¡ğ‘Ÿ)â‰ P(Xğ‘¡ğ‘’,Yğ‘¡ğ‘’). It is worth noting that there is also
distribution shift among data from different domains, that is to say
P(XDğ‘–,YDğ‘–)â‰ P(XDğ‘—,YDğ‘—),Dğ‘–â‰ Dğ‘—.
The most immediate consequence of distribution shifts is that
models trained on the training data cannot fit the testing data,
resulting in a sharp drop in performance. Therefore, our objective is
to extract features in time series classification that have a decisive
impact on labels, ensuring the robustness of the method when
dealing with OOD data. For clarity, we call these features invariant
features, signifying their resistance to distribution (domain) shifts.
Correspondingly, we term features influenced by distribution shifts
as relevant features, indicating their correlation with the domain.
Definition 2.3. Invariant Features and Relevant Features. Given
two different distributions P(X1,Y),P(X2,Y), andP(X1,Y)â‰ 
P(X2,Y). The invariant features and the relevant features in these
two distributions can be denoted as X1
ğ‘–,X1ğ‘Ÿ,X2
ğ‘–, andX2ğ‘Ÿ. Invariant
features imply that their distribution is not influenced by domain
shifts, i.e., P(X1
ğ‘–,Y)=P(X2
ğ‘–,Y), while for the relevant features,
P(X1ğ‘Ÿ,Y)â‰ P(X2ğ‘Ÿ,Y). In addition, invariant features and relevant
 
2676KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruize Shi et al.
features are mapped or decomposed from individual samples, and
both exist in the same space, with no correlation between them.
4 THE PROPOSED METHOD
We provide the design details of the proposed ITSR, as illustrated in
Figure 3. ITSR first utilizes an encoder to extract information from
the time series, and then disentangles it into invariant features and
relevant features. Invariant features remain unaffected by distribu-
tion shifts and determine the label of time series. Relevant features,
on the other hand, denote features that vary with distribution shifts.
The core concept of ITSR is ensuring low similarity between in-
variant features and relevant features through orthogonality. For
this purpose, ITSR maintains two sets of orthogonal axes (referred
to as invariant axes and relevant axes), and projects time series
onto these two sets of axes to obtain invariant features and relevant
features, theoretically ensuring their dissimilarity. Subsequently,
we employ these two features to make classifications for both labels
and domains and design corresponding loss functions to optimize
the model. Finally, we provide theoretical backing for preserving
the orthogonality between invariant features and relevant features.
4.1 Learnable Orthogonal Decomposition
Typically, collected time series data is influenced by various fac-
tors such as acquisition devices, environmental conditions, and
individual variations. Thus, data may contain information related
to these domains that can impact classification outcomes. In this
case, our goal is to remove domain-related information, referred
to as relevant features, from the data. This ensures the learning
of invariant time series representations, which are not affected by
domain variations and can thus be used in OOD generalization.
Logically, invariant and relevant features should exhibit low
similarity, and ITSR achieves this by performing an orthogonal
decomposition of time series. To facilitate subsequent processing,
we initially introduce an encoder to extract information from the
input time series while reducing dimension. For any given time
seriesğ‘¥={ğ‘¥1,ğ‘¥2,Â·Â·Â·,ğ‘¥ğ‘š}, the encoder is formally defined as:
Ë†ğ‘¥=ğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ(ğ‘¥), (1)
whereğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ(Â·)can represent various models traditionally used
for time series, in order to remain consistent with prevailing meth-
ods [ 28,33] in our field and facilitate comparisons, we leverage the
CNN [ 23] here. Furthermore, Ë†ğ‘¥âˆˆR1Ã—ğ‘indicates the encoded time
series andğ‘is the encoded dimension.
Following this, ITSR disentangles the encoded time series Ë†ğ‘¥into
mutually orthogonal invariant features and relevant features. To
make the orthogonal decomposition process trainable, we introduce
two sets of axes, referred to as the invariant axes and the relevant
axes. In finer detail, these two sets of axes are described as follows:
ğ‘ğ‘¥ğ‘’ğ‘  ğ‘–=ğ¸ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”(ğ‘,ğ‘), (2)
ğ‘ğ‘¥ğ‘’ğ‘  ğ‘Ÿ=ğ¸ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”(ğ‘,ğ‘), (3)
whereğ‘ğ‘¥ğ‘’ğ‘  ğ‘–âˆˆRğ‘Ã—ğ‘andğ‘ğ‘¥ğ‘’ğ‘  ğ‘ŸâˆˆRğ‘Ã—ğ‘denote the invariant axes
and relevant axes. Furthermore, each row of ğ‘ğ‘¥ğ‘’ğ‘  ğ‘–andğ‘ğ‘¥ğ‘’ğ‘  ğ‘Ÿrepre-
sents an axis, for example, ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—âˆˆR1Ã—ğ‘denotes the ğ‘—-th axis. It is
worth emphasizing that both ğ‘ğ‘¥ğ‘’ğ‘  ğ‘–andğ‘ğ‘¥ğ‘’ğ‘  ğ‘Ÿare optimized during
training. Subsequently, we project the encoded time series Ë†ğ‘¥ontoinvariant axes and relevant axes to obtain invariant features and
relevant features, which can be formally represented as:
Ë†ğ‘¥ğ‘–=ğ‘
âˆ¥
ğ‘—=1ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–Â·Ë†ğ‘¥T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2, (4)
Ë†ğ‘¥ğ‘Ÿ=ğ‘
âˆ¥
ğ‘—=1ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘ŸÂ·Ë†ğ‘¥T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿ
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2, (5)
where Ë†ğ‘¥ğ‘–and Ë†ğ‘¥ğ‘Ÿindividually indicate the invariant features and
relevant features. In addition, âˆ¥denotes the concatenation and âˆ¥Â·âˆ¥2
is the binary norm of a vector. Thus, the meaning of the above
equations is to project the encoded features Ë†ğ‘¥onto axes to obtain
projection vectors, which are then concatenated.
Clearly, performing the above decomposition does not guarantee
orthogonality between invariant features and relevant features.
Thus, we introduce an orthogonality loss Lğ‘œ, which is defined as:
Lğ‘œ=ğ‘âˆ‘ï¸
ğ‘—=1ğ‘âˆ‘ï¸
ğ‘˜=1ğ‘ğ‘ğ‘ (ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·(ğ‘ğ‘¥ğ‘’ğ‘ ğ‘˜ğ‘Ÿ)T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘˜ğ‘Ÿâˆ¥2), (6)
whereğ‘ğ‘ğ‘ (Â·)represents the absolute value to prevent negative
values during training and (Â·)Tstands for transpose. Moreover, we
provide the proof that the orthogonality loss ensures orthogonality
between the invariant features and relevant features.
Lemma 4.1. Minimizing the orthogonality loss between the in-
variant axes and relevant axes leads to orthogonality between the
invariant features and relevant features.
Lğ‘œâ†’0â‡’Ë†ğ‘¥ğ‘–Â·(Ë†ğ‘¥ğ‘Ÿ)Tâ†’0. (7)
Proof. Invariant features and relevant features are orthogonal,
meaning Ë†ğ‘¥ğ‘–Â·(Ë†ğ‘¥ğ‘Ÿ)T=0. From equations (4) and (5), we can derive:
Ë†ğ‘¥ğ‘–Â·
(Ë†ğ‘¥ğ‘Ÿ)T=(ğ‘
âˆ¥
ğ‘—=1ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–Â·Ë†ğ‘¥T
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2)Â·(ğ‘
âˆ¥
ğ‘—=1ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘ŸÂ·Ë†ğ‘¥T
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿ
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2)T
=ğ‘âˆ‘ï¸
ğ‘—=1(ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–Â·Ë†ğ‘¥T
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2)Â·(ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘ŸÂ·Ë†ğ‘¥T
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿ
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2)T
=ğ‘âˆ‘ï¸
ğ‘—=1ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–Â·Ë†ğ‘¥T
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘ŸÂ·Ë†ğ‘¥T
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2Â·(ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·(ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿ)T
âˆ¥ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2).
(8)
In the above derivation, bothğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–Â·Ë†ğ‘¥T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2andğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘ŸÂ·Ë†ğ‘¥T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2are scalars,
and therefore, the value of Ë†ğ‘¥ğ‘–Â·(Ë†ğ‘¥ğ‘Ÿ)Tdepends on(ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·(ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿ)T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2),
which happens to be the optimization objective in the orthogonality
lossLğ‘œ. WhenLğ‘œâ†’0during the training, Ë†ğ‘¥ğ‘–Â·(Ë†ğ‘¥ğ‘Ÿ)Tâ†’0, indi-
cating invariant features and relevant features are orthogonal. â–¡
ITSR maintains two sets of orthogonal axes to parametrically
learn the orthogonal decomposition, thereby theoretically ensuring
low similarity between the resulting invariant and relevant features.
 
2677Orthogonality Matters: Invariant Time Series Representation for Out-of-distribution Classification KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
4.2 Cross-Classification of Domain and Label
As previously defined, invariant features are domain-independent
yet play a crucial role in classification. On the contrary, its or-
thogonal features, namely the relevant features, should be strongly
domain-dependent but label-agnostic, allowing the label informa-
tion can be reserved to the greatest extent in the invariant fea-
tures. To achieve this goal, ITSR introduces a cross-classification
of domain and label. First, we need to map the invariant features
and relevant features using the multi-layer perceptron (MLP). Since
ITSR requires classification for both labels and domains, we use
two MLPs here to map the features to the dimensions required for
cross-classification, which can be formalized as follows:
ğ‘(ğ‘™)
ğ‘™=ğœ(ğ‘Š(ğ‘™)
ğ‘™(ğ‘(ğ‘™âˆ’1)
ğ‘™)), (9)
ğ‘(ğ‘™)
ğ‘‘=ğœ(ğ‘Š(ğ‘™)
ğ‘‘(ğ‘(ğ‘™âˆ’1)
ğ‘‘)), (10)
whereğ‘(ğ‘™)andğ‘(ğ‘™âˆ’1)are output and input of the ğ‘™-th layer, and
ğ‘Š(ğ‘™)is the learnable parameters. ğœ(Â·)denotes the activation func-
tion, andğ‘…ğ‘’ğ¿ğ‘¢(Â·)[14] is used here. Furthermore, ğ‘ğ‘™andğ‘ğ‘‘are
representations used for label classification and domain classifica-
tion, respectively. In addition, the representations of the final ( ğ¿-th)
layer areğ‘(ğ¿)
ğ‘™âˆˆR1Ã—ğ‘ğ‘¦andğ‘(ğ¿)
ğ‘‘âˆˆR1Ã—ğ‘ğ‘‘, whereğ‘ğ‘¦andğ‘ğ‘‘are
the previously defined numbers of categories and domains.
Based on this, we feed the invariant and relevant features into
these two MLPs, i.e., ğ‘(0)set as Ë†ğ‘¥ğ‘–and Ë†ğ‘¥ğ‘Ÿ. This yields four distinct
representations: predicting labels with invariant features ğ‘(ğ¿)
ğ‘™ğ‘–, pre-
dicting domains with invariant features ğ‘(ğ¿)
ğ‘‘ğ‘–, predicting labels with
relevant features ğ‘(ğ¿)
ğ‘™ğ‘Ÿ, and predicting domains with relevant fea-
turesğ‘(ğ¿)
ğ‘‘ğ‘Ÿ. The first letter in each subscript indicates whether it is
for labels (l) or domains (d), and the second letter indicates whether
it is mapping invariant (i) or relevant (r) features.
Finally, ITSR calculates losses for these four representations
using the Cross-entropy loss function. Note that we classify both
labels and domains, which can be formally represented as follows:
Lğ‘™Â·=ğ¶ğ‘Ÿğ‘œğ‘ ğ‘ ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦(ğ‘(ğ¿)
ğ‘™Â·,Y), (11)
Lğ‘‘Â·=ğ¶ğ‘Ÿğ‘œğ‘ ğ‘ ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦(ğ‘(ğ¿)
ğ‘‘Â·,D), (12)
whereYandDare sets of labels and domains, and we denote the
obtained losses asLğ‘™ğ‘–,Lğ‘‘ğ‘–,Lğ‘™ğ‘Ÿ, andLğ‘‘ğ‘Ÿ.
4.3 Model Summary
The purpose of ITSR is to decompose time series into reciprocally
orthogonal invariant features and relevant features, and use the
invariant features for OOD generalization. Therefore, for invariant
features, its prediction of labels should be as accurate as possible,
while the prediction of domains should be as incorrect as possi-
ble, indicating that invariant features have a decisive role in labels
across different domains and do not change with domain variations.
The relevant features, on the other hand, should predict labels in-
correctly and domains accurately. This further emphasizes that the
invariant features and relevant features should have low similarity,
which is why ITSR introduces the orthogonality loss Lğ‘œto theoret-
ically ensure their dissimilarity. Based on the above analysis, theAlgorithm 1: The Proposed ITSR
Input: Time series training set Tğ‘¡ğ‘Ÿ={Xğ‘¡ğ‘Ÿ,Dğ‘¡ğ‘Ÿ,Yğ‘¡ğ‘Ÿ};
Time series testing set Tğ‘¡ğ‘’={Xğ‘¡ğ‘’}; Number of
epochğ¸; Number of layers of MLP ğ¿;
Output: Representation of time series testing set ğ‘(ğ¿)
ğ‘™ğ‘–;
1Initializing invariant axes ğ‘ğ‘¥ğ‘’ğ‘  ğ‘–, relevant axes ğ‘ğ‘¥ğ‘’ğ‘  ğ‘Ÿ, weight
of the MLP used for label ğ‘Š(ğ‘™)
ğ‘™and weight of the MLP
used for domain ğ‘Š(ğ‘™)
ğ‘‘;
2\âˆ—Trainingâˆ—\
3forğ‘’ğ‘ğ‘œğ‘â„ =1Â·Â·Â·ğ¸do
4 forğ‘¥âˆˆXğ‘¡ğ‘Ÿdo
5 Ë†ğ‘¥â†ğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ(ğ‘¥)(Eq.1);
6 Ë†ğ‘¥ğ‘–=âˆ¥ğ‘
ğ‘—=1ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–Â·Ë†ğ‘¥T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2(Eq.4);
7 Ë†ğ‘¥ğ‘Ÿ=âˆ¥ğ‘
ğ‘—=1ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘ŸÂ·Ë†ğ‘¥T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿ
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘Ÿâˆ¥2(Eq.5);
8 end
9ğ‘(0)
ğ‘™ğ‘–â†Ë†Xğ‘–,ğ‘(0)
ğ‘‘ğ‘–â†Ë†Xğ‘–,ğ‘(0)
ğ‘™ğ‘Ÿâ†Ë†Xğ‘Ÿ,ğ‘(0)
ğ‘‘ğ‘Ÿâ†Ë†Xğ‘Ÿ;
10 forğ‘™=1Â·Â·Â·ğ¿do
11ğ‘(ğ‘™)â†ğœ(ğ‘Š(ğ‘™)(ğ‘(ğ‘™âˆ’1)));
12 end
13Lğ‘œ=Ãğ‘
ğ‘—=1Ãğ‘
ğ‘˜=1ğ‘ğ‘ğ‘ (ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·(ğ‘ğ‘¥ğ‘’ğ‘ ğ‘˜
ğ‘Ÿ)T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘˜ğ‘Ÿâˆ¥2)(Eq.6);
14 CalculatingLğ‘™ğ‘–,Lğ‘‘ğ‘–,Lğ‘™ğ‘ŸandLğ‘‘ğ‘Ÿ(Eq.11, Eq.12);
15L=Lğ‘œ+Lğ‘™ğ‘–+1
Lğ‘‘ğ‘–+1
Lğ‘™ğ‘Ÿ+Lğ‘‘ğ‘Ÿ;
16 Updatingğ‘ğ‘¥ğ‘’ğ‘  ğ‘–,ğ‘ğ‘¥ğ‘’ğ‘  ğ‘Ÿ,ğ‘Š(ğ‘™)
ğ‘™andğ‘Š(ğ‘™)
ğ‘‘through back
propagation based on the loss L;
17end
18\âˆ—Inferringâˆ—\
19forğ‘¥âˆˆXğ‘¡ğ‘’do
20 Ë†ğ‘¥â†ğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ(ğ‘¥)(Eq.1);
21 Ë†ğ‘¥ğ‘–=âˆ¥ğ‘
ğ‘—=1ğ‘
ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–Â·Ë†ğ‘¥T
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2Â·ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–
âˆ¥ğ‘ğ‘¥ğ‘’ğ‘ ğ‘—
ğ‘–âˆ¥2(Eq.4);
22end
23ğ‘(0)
ğ‘™ğ‘–â†Ë†Xğ‘–;
24forğ‘™=1Â·Â·Â·ğ¿do
25ğ‘(ğ‘™)
ğ‘™ğ‘–â†ğœ(ğ‘Š(ğ‘™)
ğ‘™(ğ‘(ğ‘™âˆ’1)
ğ‘™ğ‘–));
26end
27return Representation of time series testing set ğ‘(ğ¿)
ğ‘™ğ‘–
total lossLof ITSR can be defined as follows:
L=Lğ‘œ+Lğ‘™ğ‘–+1
Lğ‘‘ğ‘–+1
Lğ‘™ğ‘Ÿ+Lğ‘‘ğ‘Ÿ. (13)
We placeLğ‘‘ğ‘–andLğ‘™ğ‘Ÿin the denominator to ensure that these
two losses increase during training. Finally, we leverage the Adap-
tive Moment Estimation (Adam) to optimize the proposed ITSR.
Note that there is no need to execute all the techniques men-
tioned above during inference. Specifically, when ITSR is inferring,
it only needs to project the time series onto the invariant axes to
generate invariant features, and then use the MLP to obtain the final
representation ğ‘(ğ¿)
ğ‘™ğ‘–for downstream tasks. Moreover, we present
 
2678KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruize Shi et al.
the pseudo-code for the proposed ITSR, as shown in Algorithm 1.
Building on this, we analyze the time and space complexity of ITSR
and provide the efficiency study in the Supplement A.2.
Assuming an input time series of length ğ‘, the encoder utilizes
anğ¿-layer,ğ¾-kernel CNN, resulting in features of dimension ğ‘.
Both the label and domain classifiers are 3-layer MLPs, with ğ»
hidden layer dimensions. ğ‘ğ‘¦andğ‘ğ‘‘are the numbers of classes
and domains, respectively.
Time. The time complexity of encoding is ğ‘‚(ğ‘ğ¿ğ¾). After that, the
cost for projecting onto the invariant and relevant axes is 2ğ‘‚(ğ‘2).
Subsequently, the invariant and relevant features are predicted by
label and domain classifiers, with time complexity of 2ğ‘‚(ğ‘ğ»+ğ»ğ»+
ğ»ğ‘ğ‘¦)+2ğ‘‚(ğ‘ğ»+ğ»ğ»+ğ»ğ‘ğ‘‘). Thus, the overall time complexity is
approximately ğ‘‚(ğ‘ğ¿ğ¾)+2ğ‘‚(ğ‘2)+4ğ‘‚(ğ‘ğ»+ğ»ğ»).
Space. The space complexity of the input is ğ‘‚(ğ‘), and after encod-
ing, it becomes ğ‘‚(ğ‘). Thus, the total space cost for the invariant
and relevant features is 2ğ‘‚(ğ‘). Then, making predictions for labels
and domains using these two features requires 2ğ‘‚(ğ‘ğ‘¦)+2ğ‘‚(ğ‘ğ‘‘).
The overall space cost is ğ‘‚(ğ‘)+3ğ‘‚(ğ‘)+2ğ‘‚(ğ‘ğ‘¦)+2ğ‘‚(ğ‘ğ‘‘).
4.4 Theoretical Insights
We offer theoretical insights to underscore the foundation of our
proposed ITSR in theory, namely, that maintaining orthogonality
between invariant features and relevant features contributes to its
adaptation to OOD time series classification.
For analytical convenience, we omit the encoding of the time
series (Eq.1). In general, assuming that the invariant features and
relevant features extracted from any given time series ğ‘¥are denoted
asğ‘¥ğ‘–=(ğ‘¥1
ğ‘–,ğ‘¥2
ğ‘–,Â·Â·Â·,ğ‘¥ğ‘š
ğ‘–)ğ‘‡andğ‘¥ğ‘Ÿ=(ğ‘¥1ğ‘Ÿ,ğ‘¥2ğ‘Ÿ,Â·Â·Â·,ğ‘¥ğ‘šğ‘Ÿ)ğ‘‡, respectively.
ğ‘¥ğ‘–andğ‘¥ğ‘Ÿare orthogonal, and ğ‘‡denotes transpose, as the features
are in vector form. In this case, we provide other features, denoted
asğ‘¥ğ‘=(ğ‘¥1ğ‘,ğ‘¥2ğ‘,Â·Â·Â·,ğ‘¥ğ‘›ğ‘)ğ‘‡, which serves as their common segment.
That is to say, we utilize ğ‘¥ğ‘–||ğ‘¥ğ‘andğ‘¥ğ‘Ÿ||ğ‘¥ğ‘as the invariant features
and relevant features for subsequent analysis, with correlation
between the two, where ||denotes concatenation.
Afterward, these restructured invariant features and relevant
features are passed through the label classifier, where the label clas-
sifier is the MLP with shared parameters. Specifically, the parameter
matrix of the MLP is denoted as ğ‘Š. Hence, the predictions of labels
can be represented as follows:
Ë†ğ‘§ğ‘™Â·=ğ‘ŠÂ·(ğ‘¥Â·||ğ‘¥ğ‘)
=ğ‘ŠÂ·(ğ‘¥Â·||(ğ‘›
z     }|     {
0,0,Â·Â·Â·,0)ğ‘‡)+ğ‘ŠÂ·((ğ‘š
z     }|     {
0,0,Â·Â·Â·,0)ğ‘‡||ğ‘¥ğ‘)
=ğ‘ŠÂ·(ğ‘¥Â·||(0)ğ‘›)+ğ‘ŠÂ·((0)ğ‘š||ğ‘¥ğ‘),(14)
where the subscript of Ë†ğ‘§ğ‘™Â·andğ‘¥Â·can beğ‘–orğ‘Ÿ, as the mapping of in-
variant features and relevant features is unified. Moreover, (0)ğ‘›and
(0)ğ‘šare abbreviated for convenience in subsequent derivations.
Building upon this foundation, for an individual time series
sampleğ‘¥, substituting its prediction Ë†ğ‘§ğ‘™Â·and its true label ğ‘¦into
the Cross-entropy loss function yields:
Lğ‘™Â·=ğ¶ğ‘Ÿğ‘œğ‘ ğ‘ ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦(Ë†ğ‘§ğ‘™Â·,ğ‘¦)=âˆ’|ğ‘¦|âˆ‘ï¸
ğ‘–=1ğ‘¦ğ‘–Â·ğ‘™ğ‘œğ‘”(Ë†ğ‘§ğ‘–
ğ‘™Â·), (15)Table 1: Dataset statistics.
Dataset Sample Dimension Class Domain
UCIHAR 1,609 9 6 5
UniMiB SHAR 1,569 453 17 4
EMG 6,883 200 6 4
Opportunity 869,387 77 18 4
where|ğ‘¦|represents the number of classes. In this case, by combin-
ing Eq.14 with Eq.15, we can obtain:
Lğ‘™Â·=âˆ’|ğ‘¦|âˆ‘ï¸
ğ‘–=1ğ‘¦ğ‘–Â·ğ‘™
ğ‘œğ‘”(ğ‘Šğ‘–:Â·(ğ‘¥Â·||(0)ğ‘›)+ğ‘Šğ‘–:Â·((0)ğ‘š||ğ‘¥ğ‘))
=âˆ’|ğ‘¦|âˆ‘ï¸
ğ‘–=1ğ‘¦ğ‘–Â·ğ‘™ğ‘œğ‘”(ğ‘Šğ‘–:Â·(ğ‘¥Â·||(0)ğ‘›)âˆ’|ğ‘¦|âˆ‘ï¸
ğ‘–=1ğ‘¦ğ‘–Â·ğ‘™ğ‘œğ‘”(1+ğ‘Šğ‘–:Â·((0)ğ‘š||ğ‘¥ğ‘)
ğ‘Šğ‘–:Â·
(ğ‘¥Â·||(0)ğ‘›)),
(16)
wher
eğ‘Šğ‘–:denotes the parameters of the ğ‘–-th row ofğ‘Š.
As shown in Eq.16, when invariant features and relevant features
are correlated, forLğ‘™ğ‘–andLğ‘™ğ‘Ÿ, their optimization terms will both
include the part related to ğ‘¥ğ‘. Sinceğ‘™ğ‘œğ‘”(Â·)is a monotonic function
and ITSRâ€™s optimization terms are Lğ‘™ğ‘–and1
Lğ‘™ğ‘Ÿ, this will lead to
conflicts in the optimization process, causing a suboptimal model.
In addition,Lğ‘‘ğ‘Ÿand1
Lğ‘‘ğ‘–also face similar conflicts. Therefore, it
is essential to minimize the correlation between invariant features
and relevant features to ensure proper model convergence. In other
words, ensuring orthogonality between these features significantly
aids ITSR in adapting to OOD time series classification.
5 EXPERIMENTS
5.1 Experimental Setup
Datasets. To evaluate the proposed ITSR, we sample four real-
world time series datasets, each of which encompasses multiple
domains, to assess the OOD generalization capability of ITSR and
baselines. In more detail, the four datasets utilized are UCIHAR [ 1],
UniMiB SHAR [ 31], EMG [ 27], and Opportunity [ 2]. Their statistical
summaries are provided in Table 1, with detailed descriptions and
processing outlined in Supplement A.1.
Baselines. We evaluate the proposed ITSR with various significant
baselines, which can be divided into three categories:
â€¢General time series methods. We compare multiple representa-
tive time series methods to evaluate the proposed ITSR, including
traditional methods such as CNN [ 23], LSTM [ 16], GRU [ 4], Co-
DATS [ 39], ROCKET [ 6], and MINIROCKET [ 7], as well as recent
transformer-based models, TARNet [3] and PatchTST [32].
â€¢General OOD / domain generalization methods. We choose
three important baselines for OOD generalization from other
research domains, they are Mixup [ 46],Manifold Mixup (MM)
[38], HRM [25], KHRM [26], and SDL [44].
â€¢Time series OOD / domain generalization methods. Re-
search on OOD generalization for time series classification is
limited, and we select three important works, i.e., GILE [ 33],
AdaRNN [9], and Diversify [28].
 
2679Orthogonality Matters: Invariant Time Series Representation for Out-of-distribution Classification KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 2: OOD time series classification.
Dataset Sour
ce T
argetGeneral
time series General
OOD generalization Time
series OOD generalization Ours
CoD
ATS ROCKET TARNet PatchTST MM
KHRM SDL GILE
AdaRNN Diversify I
TSR
UCIHAR1,
2, 3, 4 0 80.81
77.38 74.21 72.26 75.50
74.72 75.93 79.68
78.87 83.17 83.61
0,
2, 3, 4 1 66.42
80.13 77.54 73.82 73.51
73.76 65.27 76.87
78.63 78.34 81.58
0,
1, 3, 4 2 79.71
92.67 59.65 70.70 81.23
86.19 86.87 85.67
91.00 92.35 93.26
0,
1, 2, 4 3 73.51
84.12 78.21 76.95 82.02
75.73 77.08 88.12
89.43 90.48 91.89
0,
1, 2, 3 4 64.14
89.84 78.67 67.18 70.16
79.03 79.82 84.68
89.77 89.79 92.87
A
vg. 72.92
84.83 73.66 72.18 76.48
77.89 76.99 83.00
85.54 86.83 88.64
UniMiB
SHAR2,
3, 5 1 40.64
51.04 48.43 50.26 46.88
50.11 51.82 45.48
48.21 50.38 52.91
1,
3, 5 2 44.71
46.48 38.02 45.11 33.10
48.75 49.47 46.14
48.51 52.95 57.12
1,
2, 5 3 61.32
65.46 46.61 66.79 58.55
63.48 63.19 61.25
64.57 65.42 67.27
1,
2, 3 5 33.28
39.93 41.92 35.78 38.93
38.30 40.27 37.81
37.16 41.60 43.07
A
vg. 44.99
50.73 43.75 49.49 44.37
50.16 51.19 47.67
49.61 52.59 55.09
EMG1,
2, 3 0 61.01
72.24 72.18 64.12 67.90
66.33 68.57 65.86
68.32 66.37 75.65
0,
2, 3 1 65.40
83.02 73.53 70.75 81.42
80.17 84.37 65.59
68.41 82.45 84.59
0,
1, 3 2 62.04
75.96 74.43 68.62 71.71
73.93 77.58 66.13
70.31 74.62 78.81
0,
1, 2 3 71.70
76.27 70.71 70.73 72.30
75.86 76.80 70.36
71.95 76.16 77.43
A
vg. 65.03
76.87 72.71 68.56 73.33
74.07 76.83 66.99
69.75 74.90 79.12
Opp
ortunityS2,
S3, S4 S1 79.62
78.27 78.77 81.40 81.65
78.15 81.03 81.70
82.13 81.93 82.45
S1,
S3, S4 S2 77.20
76.09 78.54 80.88 77.04
78.29 80.44 80.03
79.94 80.99 81.26
S1,
S2, S4 S3 74.26
76.31 75.95 75.41 73.99
72.63 76.53 76.50
75.96 76.87 77.19
S1,
S2, S3 S4 75.62
77.40 78.19 79.49 77.30
78.50 81.90 79.15
78.59 80.86 82.07
A
vg. 76.68
77.40 78.19 79.49 77.50
76.89 79.97 79.35
79.16 80.16 80.74
â€™Sourceâ€™ refers to training methods on these domains, followed by testing on the â€™Targetâ€™ domain. â€™Avg.â€™ is short for average and the best performance are
highlighted in bold. Due to space constraints, we only present partial results of state-of-the-art baselines, and the complete results are listed in the Supplement.
Experimental settings. We evaluate ITSR and the baselines on a
server equipped with an Intel Xeon Gold 5117 CPU and a Tesla V100
(32 GB) GPU, with 256 GB of memory. The server runs on Ubuntu
18.04 with CUDA 11.0, and the codes are implemented in PyTorch
1.10.11. To reduce randomness, we conducted each experiment 5
times and reported the average results.
For hyper-parameter settings, if baselines utilize the same dataset
as ours and provide hyper-parameters, we keep their settings. Oth-
erwise, we adjust the hyper-parameters to ensure a fair comparison
as much as possible. For ITSR, we leverage a 4-layer CNN with
max pooling as the encoder. Additionally, we employ two 3-layer
MLPs to transfer features, and the hidden dimension is set to 512
for UCIHAR and UniMiB SHAR datasets, and 1024 for EMG and
Opportunity datasets as they are more complex. If baselines have
these structures, we adopt the same settings. Finally, the learning
rate of ITSR is set to 0.0005, and the dropout is 0.4. More details
can be explored in our open-source repository (see Abstract).
5.2 OOD Time Series Classification
We compare the OOD generalization performance of ITSR with
baselines on four datasets. As previously introduced, each dataset
comprises multiple domains with distribution shifts among them.
Thus, we select one domain as the â€™target domainâ€™ for testing, while
the remaining domains are â€™source domainsâ€™ for training. In other
words, we train all methods on the source domains and subsequently
infer on the target domain. We use accuracy as the evaluation metric
1https://pytorch.org/and we report the average accuracy across different target domains
for each dataset, as shown in Table 2. In addition, the rationale for
selecting accuracy and the results of other metrics can be found in
the Supplement A.4.
Note that the table only presents results from a subset of powerful
baselines, while the rest can be found in the Supplement A.6. Fur-
thermore, we conduct general time series classification involving
randomly splitting the datasets, where the training and testing data
share similar distributions. As our focus lies on OOD classification,
the results are presented in the Supplement A.3.
We can see that all methods exhibit fluctuations in performance
when facing unseen data, indicating the presence of distribution
shifts among different domains. Particularly for general time series
methods, they exhibit larger fluctuations, highlighting that treating
the training and testing sets as the same distribution is unreasonable
and exacerbates the difficulty of generalization. Additionally, we
can observe that for the Opportunity dataset, the performance
variation is less compared to the other three datasets. We speculate
that this is because the individuals in this dataset are more similar
to each other, resulting in less distribution shift. We also observe
significant fluctuations in TARNetâ€™s performance on the UCIHAR
dataset, especially when the target domain is 2. This may be due
to its encoder is transformer, as transformer-based models like
PatchTST also exhibit a clear decrease in this scenario.
Furthermore, it is evident that our proposed ITSR outperforms
the state-of-the-art methods on all datasets, indicating that ITSR
can extract invariant representations that are not affected by do-
main shifts. This also demonstrates the importance of maintaining
 
2680KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruize Shi et al.
Table 3: Similarity between invariant and relevant features.
Dataset T
argetCosine Pearson
GILE
GILE ğ‘œ ITSR GILE
GILE ğ‘œ ITSR
UCIHAR0 0.3286
0.1503 0.067 0.3142
0.2801 0.0312
1 0.3305
0.1342 0.087 0.3155
0.2681 0.0381
2 0.3956
0.1574 0.092 0.3536
0.2046 0.0358
3 0.3115
0.1567 0.081 0.3543
0.2396 0.0413
4 0.3560
0.1793 0.095 0.2845
0.2398 0.0225
UniMiB
SHAR1 0.4108
0.1575 < 1e-4 0.3720
0.2989 0.0004
2 0.3407
0.1533 < 1e-4 0.3144
0.2788 0.0005
3 0.3421
0.1297 < 1e-4 0.3468
0.2838 0.0004
5 0.3291
0.1443 0.0001 0.3191
0.2953 0.0006
EMG0 0.4067
0.0328 < 1e-4 0.2660
0.2168 0.0005
1 0.4642
0.0379 < 1e-4 0.3369
0.1275 0.0007
2 0.3239
0.0309 < 1e-4 0.3042
0.1632 0.0001
3 0.3075
0.0228 < 1e-4 0.3408
0.1269 0.0006
Opp
ortunityS1 0.6690
0.1503 < 1e-4 0.5056
0.1779 0.0009
S2 0.6132
0.1342 < 1e-4 0.5215
0.3085 0.0011
S3 0.6899
0.1574 < 1e-4 0.4484
0.2001 0.0007
S4 0.6505
0.1567 < 1e-4 0.5015
0.1290 0.0009
The range of both cosine similarity and Pearson correlation coefficient is in [-1,
1], with closer to 0 indicating lower similarity. The results we provide are the
average of the absolute values of the similarity when methods achieve their
best performance. Taking the absolute value is done to prevent the cancellation
of positive and negative similarities between different samples.
orthogonality between invariant features and relevant features for
OOD generalization. Surprisingly, ROCKET also exhibits strong
performance, this is because it transforms data using multiple con-
volutional kernels before training, which enhances its adaptability
to unknown data. As expected, both general OOD methods and
OOD methods tailored for time series perform better than most of
the general models, indicating their robustness to unknown data
and their suitability for OOD generalization.
5.3 Orthogonality Study
We analyze whether the orthogonality between invariant features
and relevant features contributes to OOD generalization. To fit our
work, we first delve deeper into the impact of orthogonality on
time domain representations of time series. As time series are often
also utilized in frequency domain representations, we also analyze
the corresponding effects in the Supplement A.5.
We leverage the GILE [ 33] to assist in our analysis. GILE is
a representative work for OOD time series classification, which
extends the VAE [ 20] to time series and disentangles time series
into invariant features and relevant features. However, GILE does
not ensure the two extracted features are orthogonal. Therefore, we
make modifications to GILE, specifically, for the invariant features
and relevant features obtained in each batch, we calculate their
similarity by dot product and use it as a loss term to optimize. For
convenience, we refer to this variant of GILE as GILE ğ‘œ.
We evaluate GILE, GILE ğ‘œ, and the proposed ITSR on four datasets.
In addition to verifying the performance in time series classification,
we also provide the similarity between the invariant features and
relevant features obtained by these three methods. We use cosine
similarity and Pearson correlation coefficient [ 5] here, which are
two common metrics for measuring vector similarity.
0 1 2 3 4 Avg.020406080100GILE GILEo ITSR(a) UCIHAR
1 2 3 5 Avg.010203040506070GILE GILEo ITSR (b) UniMiB SHAR
0 1 2 3 Avg.020406080GILE GILEo ITSR
(c) EMG
S1 S2 S3 S4 Avg.6570758085GILE GILEo ITSR (d) Opportunity
Figure 4: Orthogonality study on four datasets. The X-axis
represents the target domain, and the Y-axis represents accu-
racy in time series classification.
The similarities obtained are shown in Table 3, from the results, it
can be observed that our proposed ITSR keeps the lowest similarity,
whether calculated using cosine similarity or Pearson correlation
coefficient. Specifically, the results on multiple datasets consistently
approach 0, demonstrating that the two features obtained by ITSR
are nearly orthogonal. As expected, GILE shows relatively high
similarity across all datasets, especially significantly higher on the
Opportunity dataset. On the other hand, GILE ğ‘œ, due to maintaining
orthogonality within each batch, falls between GILE and ITSR.
The results are shown in Figure 4, it is evident that across all
datasets, ITSR achieves the best performance, with GILE ğ‘œoutper-
forming GILE. Combined with Table 3, these results suggest that
maintaining orthogonality between invariant and relevant features
is beneficial for OOD time series classification. Essentially, invari-
ant features represent features that do not vary with domain shifts,
while relevant features represent those that do vary across domains.
It is unreasonable for features to remain unaffected by domain
shifts while also varying significantly across domains. Thus, main-
taining orthogonality between these two features aligns with our
motivation and can enhance the performance of downstream tasks.
5.4 Ablation Study
We further validate the importance of each technique of ITSR, as
shown in Table 4. Specifically, we introduce three variants to assess
the impact of the encoder, auxiliary classification tasks, and orthog-
onality on ITSR. It is important to note that ITSRâ€™s optimization
requires the synergistic effect of multiple losses. Therefore, our
proposed variants already cover almost all forms, and other vari-
ants may be inappropriate. For example, optimizing only ğ¿ğ‘œ+ğ¿ğ‘™ğ‘–or
ğ¿ğ‘™ğ‘–+ğ¿ğ‘‘ğ‘Ÿ, these two setups lack optimization for the relevant axes,
 
2681Orthogonality Matters: Invariant Time Series Representation for Out-of-distribution Classification KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 4: Ablation study on the UCIHAR and UniMiB SHAR datasets.
Mo
del UCIHAR UniMiB
SHAR
IDLğ‘œLğ‘™
ğ‘–1
Lğ‘‘
ğ‘–1
Lğ‘™
ğ‘ŸLğ‘‘ğ‘Ÿ 0
1 2 3 4 Avg. 1
2 3 5 Avg.
1âœ—
âœ“ âœ— âœ— âœ— 66.89
67.88 74.08 72.56 74.28 71.14 44.43
45.97 60.20 36.58 46.80
2âœ“
âœ“ âœ— âœ— âœ“ 78.35
74.20 86.51 89.59 88.78 83.49 50.52
51.63 55.01 39.21 49.09
3âœ—
âœ“ âœ“ âœ“ âœ“ 81.47
78.48 90.91 87.91 89.08 85.57 51.04
52.14 60.88 41.29 51.34
ITSR âœ“
âœ“ âœ“ âœ“ âœ“ 83.61
81.58 93.26 91.89 92.87 88.64 52.91
57.12 67.27 43.07 55.09
â€™IDâ€™
is an alias used for differentiation, and the â€™âœ“â€™ and â€™âœ—â€™ symbols indicate whether optimizing for the corresponding item.
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0
0
1
2
3
4
(a) GILE
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0
0
1
2
3
4 (b) Diversify
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0
0
1
2
3
4 (c) GILE ğ‘œ
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.00
1
2
3
4 (d) ITSR
Figure 5: t-SNE visualizations on the EMG dataset with the target domain as 0. Latent representations are scaled using min-max
normalization, and labels are distinguished by color.
and constraints of orthogonality loss, respectively. Thus, the results
are equivalent to optimizing only ğ¿ğ‘™ğ‘–, similar to the variant-1.
We can see that ITSR outperforms all its variants, indicating that
each component of ITSR contributes to extracting invariant repre-
sentations from time series. The significant performance decline
in variant 1 underscores the limitations of the general encoder for
OOD data, reaffirming the efficacy of the techniques employed on
ITSR. Additionally, we also observe poor performance in variant
2, suggesting that auxiliary classification tasks have a significant
impact on performance. This is because auxiliary tasks amplify
the differences between invariant features and relevant features,
further reducing the sensitivity of invariant features to domain
shifts, thus enhancing performance. As expected, we also notice
that without optimizing the orthogonality loss Lğ‘œ(variant 3) leads
to a decrease in accuracy, highlighting the importance of maintain-
ing low similarity between invariant features and relevant features,
which aligns with our original intention.
5.5 Visualization Study
To provide an intuitive performance of ITSR, we offer some visu-
alizations based on t-SNE [ 36], as shown in Figure 5. We select
three baselines for comparison, namely, GILE and Diversify, which
are representative methods for OOD time series classification, and
GILE ğ‘œ, which is a variant of GILE that we proposed earlier.
From the results, it can be observed that our proposed ITSR has
more compact latent representations, and the divisions between
different labels are clear. Furthermore, for Diversify, the divisions
between its labels are also relatively distinct, but the latent rep-
resentations are more scattered. Finally, we can see that GILE ğ‘œoutperforms GILE, especially in distinguishing label 1 (orange) and
label 2 (green). The latent embeddings obtained by GILE are quite
chaotic for these two classes, while GILE ğ‘œmakes a more distinct
classification, reiterating the benefits of maintaining orthogonality
between invariant and relevant features for model performance.
6 CONCLUSION
We investigate OOD time series classification and propose a novel
method ITSR. ITSR achieves learnable orthogonal decomposition
by maintaining two sets of orthogonal axes, and disentangles time
series into invariant features and relevant features, then uses invari-
ant features for OOD generalization. Additionally, we theoretically
and experimentally demonstrate that the obtained invariant fea-
tures and relevant features are orthogonal, and we also analyze the
impact of orthogonality on OOD generalization in time series. Ex-
tensive experiments on four datasets show that ITSR outperforms
the state-of-the-art methods and validate the superiority of ITSR.
Limitations & Discussions. Our proposed ITSR primarily focuses
on distribution shifts between different time series samples. Future
research could delve into whether there are temporal shifts within
individual time series at different time points. Additionally, more
powerful encoders could be employed to enhance the performance
of ITSR. Finally, exploring the application of ITSR principles to
other fields could be a promising direction.
ACKNOWLEDGEMENTS
The work is supported by the National Natural Science Foundation
of China (No.62127808).
 
2682KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruize Shi et al.
REFERENCES
[1]Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge L. Reyes-
Ortiz. 2012. Human activity recognition on smartphones using a multiclass
hardware-friendly support vector machine. In Proceedings of the IWAAL 2012.
Springer, 216â€“223.
[2]Ricardo Chavarriaga, Hesam Sagha, Alberto Calatroni, Sundara Tejaswi Digu-
marti, Gerhard TrÃ¶ster, JosÃ© del R. MillÃ¡n, and Daniel Roggen. 2013. The Op-
portunity challenge: A benchmark database for on-body sensor-based activity
recognition. Pattern Recognition Letters 34, 15 (2013), 2033â€“2042.
[3]Ranak Roy Chowdhury, Xiyuan Zhang, Jingbo Shang, Rajesh K. Gupta, and Dezhi
Hong. 2022. Tarnet: Task-aware reconstruction for time-series transformer. In
Proceedings of the SIGKDD 2022. 212â€“220.
[4]Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014.
Empirical evaluation of gated recurrent neural networks on sequence modeling.
InProceedings of the NIPS 2014 Workshop. 1â€“9.
[5]Israel Cohen, Yiteng Huang, Jingdong Chen, Jacob Benesty, Jacob Benesty, Jing-
dong Chen, Yiteng Huang, and Israel Cohen. 2009. Pearson correlation coefficient.
Noise Reduction in Speech Processing (2009), 1â€“4.
[6]Angus Dempster, FranÃ§ois Petitjean, and Geoffrey I. Webb. 2020. ROCKET: excep-
tionally fast and accurate time series classification using random convolutional
kernels. Data Mining and Knowledge Discovery 34, 5 (2020), 1454â€“1495.
[7]Angus Dempster, Daniel F. Schmidt, and Geoffrey I. Webb. 2021. MiniRocket: A
Very Fast (Almost) Deterministic Transform for Time Series Classification. In
Proceedings of the SIGKDD 2021. ACM, New York, 248â€“257.
[8]Shumin Deng, Ningyu Zhang, Wen Zhang, Jiaoyan Chen, Jeff Z. Pan, and Hua-
jun Chen. 2019. Knowledge-driven stock trend prediction and explanation via
temporal convolutional network. In Proceedings of the WWW 2019. 678â€“685.
[9]Yuntao Du, Jindong Wang, Wenjie Feng, Sinno Pan, Tao Qin, Renjun Xu, and
Chongjun Wang. 2021. Adarnn: Adaptive learning and forecasting of time series.
InProceedings of the CIKM 2021. 402â€“411.
[10] Jeffrey L. Elman. 1990. Finding structure in time. Cognitive Science 14, 2 (1990),
179â€“211.
[11] Jean-Yves Franceschi, Aymeric Dieuleveut, and Martin Jaggi. 2019. Unsupervised
scalable representation learning for multivariate time series. In Proceedings of
the NIPS 2019, Vol. 32. 1â€“12.
[12] Jean-Christophe Gagnon-Audet, Kartik Ahuja, Mohammad Javad Darvishi Bayazi,
Pooneh Mousavi, Guillaume Dumas, and Irina Rish. 2023. WOODS: Benchmarks
for Out-of-Distribution Generalization in Time Series. Transactions on Machine
Learning Research (2023), 1â€“47.
[13] Yaroslav Ganin and Victor Lempitsky. 2015. Unsupervised domain adaptation by
backpropagation. In Proceedings of the ICML. PMLR, 1180â€“1189.
[14] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Deep sparse rectifier
neural networks. In Proceedings of the AISTATS 2011. 315â€“323.
[15] Albert Gu, Karan Goel, and Christopher Re. 2022. Efficiently Modeling Long
Sequences with Structured State Spaces. In Proceedings of the ICLR 2022. 1â€“27.
[16] Sepp Hochreiter and JÃ¼rgen Schmidhuber. 1997. Long short-term memory. Neural
Computation 9, 8 (1997), 1735â€“1780.
[17] Min Hou, Chang Xu, Zhi Li, Yang Liu, Weiqing Liu, Enhong Chen, and Jiang
Bian. 2022. Multi-Granularity Residual Learning with Confidence Estimation for
Time Series Prediction. In Proceedings of the Web Conference 2022. 112â€“121.
[18] Qin Hua, Dingyu Yang, Shiyou Qian, Hanwen Hu, Jian Cao, and Guangtao Xue.
2023. KAE-Informer: A Knowledge Auto-Embedding Informer for Forecasting
Long-Term Workloads of Microservices. In Proceedings of the Web Conference
2023. 1551â€“1561.
[19] Zhong Ji, Jingwei Ni, Xiyao Liu, and Yanwei Pang. 2023. Teachers coopera-
tion: team-knowledge distillation for multiple cross-domain few-shot learning.
Frontiers of Computer Science 17, 2 (2023), 172312.
[20] Diederik P. Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. In
Proceedings of the ICLR 2014. 1â€“14.
[21] Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu. 2018. Modeling
long-and short-term temporal patterns with deep neural networks. In Proceedings
of the SIGIR 2018. 95â€“104.
[22] Colin Lea, Michael D. Flynn, Rene Vidal, Austin Reiter, and Gregory D. Hager.
2017. Temporal convolutional networks for action segmentation and detection.
InProceedings of the CVPR 2017. 156â€“165.
[23] Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-
based learning applied to document recognition. In Proceedings of the IEEE 1998 ,
Vol. 86. IEEE, 2278â€“2324.
[24] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C. Kot. 2018. Domain
generalization with adversarial feature learning. In Proceedings of the CVPR 2018.
5400â€“5409.
[25] Jiashuo Liu, Zheyuan Hu, Peng Cui, Bo Li, and Zheyan Shen. 2021. Heterogeneous
risk minimization. In Proceedings of the ICML 2021. PMLR, 6804â€“6814.
[26] Jiashuo Liu, Zheyuan Hu, Peng Cui, Bo Li, and Zheyan Shen. 2021. Kernelized
heterogeneous risk minimization. In Proceedings of the NIPS 2021. 1â€“17.
[27] Sergey Lobov, Nadia Krilova, Innokentiy Kastalskiy, Victor Kazantsev, and Va-
leri A. Makarov. 2018. Latent factors limiting the performance of sEMG-interfaces.Sensors 18, 4 (2018), 1122.
[28] Wang Lu, Jindong Wang, Xinwei Sun, Yiqiang Chen, and Xing Xie. 2023. Out-of-
distribution Representation Learning for Time Series Classification. In Proceedings
of the ICLR 2023.
[29] Zihan Luo, Hong Huang, Jianxun Lian, Xiran Song, Xing Xie, and Hai Jin. 2024.
Cross-links Matter for Link Prediction: Rethinking the Debiased GNN from a
Data Perspective. In Proceedings of the NeurIPS 2024, Vol. 36. 1â€“19.
[30] Divyat Mahajan, Shruti Tople, and Amit Sharma. 2021. Domain generalization
using causal matching. In Proceedings of the ICML 2021. PMLR, 7313â€“7324.
[31] Daniela Micucci, Marco Mobilio, and Paolo Napoletano. 2017. Unimib shar: A
dataset for human activity recognition using acceleration data from smartphones.
Applied Sciences 7, 10 (2017), 1101.
[32] Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2023.
A time series is worth 64 words: Long-term forecasting with transformers. In
Proceedings of the ICLR 2023. 1â€“23.
[33] Hangwei Qian, Sinno Jialin Pan, and Chunyan Miao. 2021. Latent independent
excitation for generalizable sensor-based cross-person activity recognition. In
Proceedings of the AAAI 2021, Vol. 35. 11921â€“11929.
[34] Sima Siami Namini, Neda Tavakoli, and Akbar Siami Namin. 2018. A comparison
of ARIMA and LSTM in forecasting time series. In Proceedings of the ICMLA 2018.
1394â€“1401.
[35] Sean J. Taylor and Benjamin Letham. 2018. Forecasting at scale. The American
Statistician 72, 1 (2018), 37â€“45.
[36] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.
Journal of Machine Learning Research 9, 11 (2008).
[37] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Proceedings of the NIPS 2017, Vol. 30.
[38] Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas,
David Lopez-Paz, and Yoshua Bengio. 2019. Manifold mixup: Better represen-
tations by interpolating hidden states. In Proceedings of the ICML 2019. PMLR,
6438â€“6447.
[39] Garrett Wilson, Janardhan Rao Doppa, and Diane J. Cook. 2020. Multi-Source
Deep Domain Adaptation with Weak Supervision for Time-Series Sensor Data.
InProceedings of the SIGKDD 2020. 1768â€“1778.
[40] Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. 2021. Autoformer: De-
composition transformers with auto-correlation for long-term series forecasting.
InProceedings of the NIPS 2021, Vol. 34. 22419â€“22430.
[41] Kunhong Wu, Fan Jia, and Yahong Han. 2023. Domain-specific feature elimination:
multi-source domain adaptation for image classification. Frontiers of Computer
Science 17, 4 (2023), 174705.
[42] Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, and Qi Tian. 2021. A
fourier-based framework for domain generalization. In Proceedings of the CVPR
2021. 14383â€“14392.
[43] Haotian Ye, Chuanlong Xie, Tianle Cai, Ruichen Li, Zhenguo Li, and Liwei Wang.
2021. Towards a theoretical framework of out-of-distribution generalization. In
Proceedings of the NIPS 2021, Vol. 34. 23519â€“23531.
[44] Nanyang Ye, Lin Zhu, Jia Wang, Zhaoyu Zeng, Jiayao Shao, Chensheng Peng,
Bikang Pan, Kaican Li, and Jun Zhu. 2023. Certifiable out-of-distribution gener-
alization. In Proceedings of the AAAI 2023, Vol. 37. 10927â€“10935.
[45] Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. 2023. Are transformers
effective for time series forecasting?. In Proceedings of the AAAI 2023, Vol. 37.
11121â€“11128.
[46] Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz. 2018.
mixup: Beyond Empirical Risk Minimization. In Proceedings of the ICLR 2018.
1â€“13.
[47] Xingxuan Zhang, Peng Cui, Renzhe Xu, Linjun Zhou, Yue He, and Zheyan Shen.
2021. Deep stable learning for out-of-distribution generalization. In Proceedings
of the CVPR 2021. 5372â€“5382.
[48] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. 2022.
Domain generalization: A survey. IEEE TPAMI 45, 4 (2022), 4396â€“4415.
[49] Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. 2022.
Fedformer: Frequency enhanced decomposed transformer for long-term series
forecasting. In Proceedings of the ICML 2022. PMLR, 27268â€“27286.
 
2683Orthogonality Matters: Invariant Time Series Representation for Out-of-distribution Classification KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
A SUPPLEMENT
A.1 Datasets
We provide a detailed introduction to the four datasets utilized in
our work.
â€¢UCIHAR [1] dataset collects the daily activities of 30 volunteers
aged 19 to 48 using sensors in mobile phones. The dataset has a
sampling frequency of 50 Hz and comprises a total of 1,318,272
time series samples, each with an initial feature dimension of 9.
The classification task for this dataset is identifying the activity
the user is engaged in, including 6 activities: walking, sitting,
lying down, standing, going upstairs, and going downstairs. This
dataset is divided into 5 domains based on the participant, with
each domain containing 6 volunteers.
â€¢UniMiB SHAR [31] dataset is collected from 3 sensors in mobile
phones with a sampling frequency of 50 Hz, and it comprises
activity data from 30 participants aged 18 to 60. These 30 par-
ticipants performed 17 fine-grained actions, including 9 daily
life activities and 8 fall actions. Similarly, we leverage 4 domains
commonly used in previous works [ 33] for evaluation, resulting
in a total of 1,569-time series data samples. Each data sample
includes features with 453 dimensions from the three sensors.
â€¢EMG [27] dataset is a collection of electromyographic signals,
which is a common bioelectric signal. During data collection,
electromyographic signals can be influenced by factors such as
the acquisition device, environment, and individual variations.
Therefore, it is well-suited for OOD generalization. The task
of this dataset is to classify electromyographic signals corre-
sponding to different gestures, encompassing a total of 6 distinct
gestures. This dataset is gathered from 36 volunteers and or-
ganized into 4 domains based on individual participants, with
each domain containing 9 individuals. In total, the EMG dataset
comprises 6,883 time-series samples, and each sample includes
electromyographic signals from 8 channels, and each channel
contains a feature of 200 dimensions.
â€¢Opportunity [2] dataset comprises data collected from 4 vol-
unteers performing 18 different daily activities in a home envi-
ronment. This dataset includes actions such as opening/closing
the dishwasher, refrigerator, drawers, and more. Additionally,
the Opportunity dataset leverages different inertial sensors, fur-
ther contributing to the generalization of OOD data. The time
series in this dataset is sampled at a frequency of 30 Hz and
includes a total of 869,387 samples. Each sample has a feature of
77 dimensions, and the dataset is organized into 4 domains.
A.2 Efficiency Study
Here, we compare the time cost of ITSR with several important base-
lines, as shown in Table A1. The experimental results demonstrate
that ITSR remains superior in efficiency, highlighting its simplicity
and excellence.
A.3 General Time Series Classification
We conduct experiments with a random splitting setting, meaning
the data distribution between the training and testing sets is nearly
identical. We compare our proposed method ITSR with two rep-
resentative methods (ROCKET [ 6], MINIROCKET [ 7]) under thisTable A1: Time cost on the EMG dataset.
Model GILE Diversify ITSR
Time (ms/epoch) 2,841 2,193 1,519
UCIHARUniMiB SHAREMGOpportunity
Dataset020406080100AccuracyMINIROCKET ROCKET ITSR
Figure A1: General time series classification on four datasets.
traditional experimental setup. However, in fact, the cross-domain
setting examined in our paperâ€™s main text better mirrors real-world
scenarios.
From Figure A1, we can see that compared to the cross-domain
results in the main text, all models exhibit significantly improved
performance under the random setting. Moreover, the results clearly
demonstrate that the overall performance of ITSR under random
splitting remains superior to ROCKET and MINIROCKET. Consid-
ering that ITSR is designed for OOD time series classification and
may eliminate information related to the testing data when facing
random splitting data, thus it is understandable that ITSR may not
exhibit optimal performance on certain datasets. Furthermore, we
believe greater emphasis should be placed on cross-domain results,
as this aligns more closely with reality.
A.4 Metric Study
We use accuracy as the evaluation metric since the datasets used
in our paper are balanced. Specifically, OOD task aims to obtain
features unaffected by domain shifts, hence data is typically parti-
tioned into multiple domains with balanced classes to ensure that
model performance is solely influenced by the data distribution.
To further enhance the credibility of the paper, we utilize addi-
tional metrics for evaluation. As shown in Table A2, we compare
ITSR with several important baselines, and the experimental results
still demonstrate the superiority of the proposed ITSR.
A.5 Impact of Different Representations on
Orthogonality
Although current methods for OOD time series classification pre-
dominantly focus on time domain representations, time series can
 
2684KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Ruize Shi et al.
Table A2: Additional metrics for OOD time series classification on the EMG dataset.
Metric Macro-F1 Precision Recall
Source Target GILE Diversify ITSR GILE Diversify ITSR GILE Diversify ITSR
1, 2, 3 0 66.56 68.25 73.99 65.30 68.72 74.13 66.48 71.07 73.83
0, 2, 3 1 71.67 80.36 85.46 67.60 82.14 86.88 69.75 80.49 86.77
0, 1, 3 2 70.11 72.11 78.07 70.83 74.94 81.28 72.43 74.40 80.98
0, 1, 2 3 70.72 75.46 78.84 70.78 74.01 76.26 71.36 77.05 77.32
Avg. 69.77 74.05 79.09 68.63 74.95 79.64 70.01 75.75 79.73
Table A3: Remaining OOD time series classification.
Dataset Source TargetGeneral time series General OOD generalization Ours
CNN LSTM GRU MINIROCKET Mixup HRM ITSR
UCIHAR1, 2, 3, 4 0 66.89 68.54 56.25 80.69 67.53 67.93 83.61
0, 2, 3, 4 1 67.88 70.73 58.21 80.46 63.40 63.24 81.58
0, 1, 3, 4 2 74.08 75.07 63.34 92.37 75.37 81.97 93.26
0, 1, 2, 4 3 72.56 54.20 63.85 83.60 70.50 75.08 91.89
0, 1, 2, 3 4 74.28 72.85 57.07 90.07 65.72 81.69 92.87
Avg. 71.14 68.28 59.74 85.56 68.50 73.98 88.64
UniMiB SHAR2, 3, 5 1 44.43 39.41 43.23 50.52 45.23 48.36 52.91
1, 3, 5 2 45.97 32.93 34.06 56.09 35.16 44.44 57.12
1, 2, 5 3 60.20 51.40 51.58 65.78 56.25 62.01 67.27
1, 2, 3 5 36.58 35.06 36.45 42.89 37.60 36.71 43.07
Avg. 46.80 39.70 41.33 54.32 43.56 47.88 55.09
EMG1, 2, 3 0 61.91 54.81 59.28 75.41 42.14 65.36 75.65
0, 2, 3 1 66.92 59.70 67.21 82.47 44.16 81.81 84.59
0, 1, 3 2 62.56 54.07 55.61 77.21 41.69 72.39 78.81
0, 1, 2 3 69.76 56.11 63.54 76.02 39.81 73.42 77.43
Avg. 65.29 56.17 61.41 77.77 41.95 73.25 79.12
OpportunityS2, S3, S4 S1 76.92 75.68 75.19 79.31 79.50 79.74 82.45
S1, S3, S4 S2 73.84 74.21 74.77 77.18 76.25 75.65 81.26
S1, S2, S4 S3 72.17 73.65 73.48 77.03 75.79 74.15 77.19
S1, S2, S3 S4 76.79 71.98 74.26 79.17 77.39 77.73 82.07
Avg. 74.93 73.88 74.43 78.17 77.23 76.82 80.74
â€™Sourceâ€™ refers to training methods on these domains, followed by testing on the â€™Targetâ€™ domain. â€™Avg.â€™ is short for
average and the best performance are highlighted in bold.
typically also be represented in the frequency domain (e.g., using
Fourier transform). In the case of frequency domain representa-
tion, specifically using Fourier transforms, Fourier transforms are
linear transformations, implying that they do not alter the inner
product relationships of vectors. Therefore, invariant and relevant
features in the frequency domain should still maintain relatively
low similarity, unaffected by the chosen representation.
To sum up, for time series, both time domain representations
and frequency domain representations should ensure orthogonality
between invariant features and relevant features.A.6 Remaining OOD Time Series Classification
Here, we present the remaining results of OOD time series classifi-
cation, as depicted in Table A3.
It is evident from the table that our proposed ITSR still outper-
forms these representative baselines. Additionally, the performance
of MINIROCKET is notable, akin to ROCKET, attributed to its use of
multiple convolutional kernels for mapping, implicitly conducting
data augmentation. Furthermore, the superiority of CNN over tra-
ditional time series methods like LSTM and GRU, consistent with
prior research findings [ 28,33], further justifies ITSRâ€™s adoption of
it as the encoder.
 
2685