RIGL: A Unified Reciprocal Approach for Tracing the
Independent and Group Learning Processes
Xiaoshan Yuâˆ—
School of Artificial Intelligence,
Anhui University
Hefei, Anhui, China
yxsleo@gmail.comChuan Qinâ€ 
Career Science Lab, BOSS Zhipin
PBC School of Finance,
Tsinghua University
Beijing, China
chuanqin0426@gmail.comDazhong Shen
Shanghai Artificial Intelligence
Laboratory
Shanghai, China
dazh.shen@gmail.com
Shangshang Yang
School of Artificial Intelligence,
Anhui University
Hefei, Anhui, China
yangshang0308@gmail.comHaiping Maâ€ 
Information Materials and Intelligent
Sensing Laboratory of Anhui
Province, Institutes of Physical
Science and Information Technology,
Anhui University
Hefei, Anhui, China
hpma@ahu.edu.cnHengshu Zhuâ€ 
Career Science Lab, BOSS Zhipin
Beijing, China
zhuhengshu@gmail.com
Xingyi Zhang
School of Computer Science and
Technology, Anhui University
Hefei, Anhui, China
xyzhanghust@gmail.com
Abstract
In the realm of education, both independent learning and group
learning are esteemed as the most classic paradigms. The former
allows learners to self-direct their studies, while the latter is typi-
cally characterized by teacher-directed scenarios. Recent studies
in the field of intelligent education have leveraged deep tempo-
ral models to trace the learning process, capturing the dynamics
of studentsâ€™ knowledge states, and have achieved remarkable per-
formance. However, existing approaches have primarily focused
on modeling the independent learning process, with the group
learning paradigm receiving less attention. Moreover, the recip-
rocal effect between the two learning processes, especially their
combined potential to foster holistic student development, remains
inadequately explored. To this end, in this paper, we propose RIGL,
a unified Reciprocal model to trace knowledge states at both the
individual and group levels, drawing from the Independent and
Group Learning processes. Specifically, we first introduce a time
âˆ—Work was done at Career Science Lab, BOSS Zhipin supervised by Chuan Qin.
â€ Corresponding authors.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671711frame-aware reciprocal embedding module to concurrently model
both student and group response interactions across various time
frames. Subsequently, we employ reciprocal enhanced learning
modeling to fully exploit the comprehensive and complementary
information between the two behaviors. Furthermore, we design a
relation-guided temporal attentive network, comprised of dynamic
graph modeling coupled with a temporal self-attention mechanism.
It is used to delve into the dynamic influence of individual and
group interactions throughout the learning processes, which is
crafted to explore the dynamic intricacies of both individual and
group interactions during the learning sequences. Conclusively,
we introduce a bias-aware contrastive learning module to bolster
the stability of the modelâ€™s training. Extensive experiments on
four real-world educational datasets clearly demonstrate the effec-
tiveness of the proposed RIGL model. Our codes are available at
https://github.com/LabyrinthineLeo/RIGL.
CCS Concepts
â€¢Information systems â†’Data mining; â€¢Applied computing
â†’Collaborative learning.
Keywords
Intelligent education, knowledge tracing, group learning, reciprocal
effect, dynamic graph neural network
ACM Reference Format:
Xiaoshan Yu, Chuan Qin, Dazhong Shen, Shangshang Yang, Haiping Ma,
Hengshu Zhu, and Xingyi Zhang. 2024. RIGL: A Unified Reciprocal Ap-
proach for Tracing the Independent and Group Learning Processes . In
4047
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Xiaoshan Yu et al.
Figure 1: An illustrative example of the holistic knowledge
tracing (HKT) task. The top and bottom halves indicate the
individual and group learning processes, respectively, which
are organized in time frames, and the radar chart in the
middle represents the knowledge proficiency levels of both.
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671711
1 Introduction
In the domain of education, both independent learning [ 24] and
group learning [ 41,50] are regarded as the most classic learning
paradigms. The former allows learners to self-direct their studies,
whereas the latter is typically characterized by scenarios that are
guided and structured by teachers. It is widely acknowledged that
exclusive reliance on a singular learning modality is insufficient to
promote continuous long-term development in students [6, 8].
In recent years, with the advancement of artificial intelligence
technology, the field of intelligent education has yielded notable
modeling paradigms conducive to understanding student learning
behaviors [ 1,16,23]. Among these, a foundational and potent para-
digm is knowledge tracing, which aims at dynamically monitoring
the evolving knowledge states of learners and predicting their fu-
ture performance by modeling the exercise-solving sequences [ 3].
However, most existing methods [ 7,22,25,29,45] mainly focus on
modeling independent learning behaviors, with the group learning
paradigm receiving less attention. Furthermore, the reciprocal effect
between independent and group learning, particularly their com-
bined potential to significantly drive holistic student development,
has yet to be thoroughly explored and investigated [6, 42, 44, 46].
To this end, in this paper, we introduce a new task called holis-
tic knowledge tracing (HKT), which refers to tracing knowledge
states at both the individual and group levels simultaneously, draw-
ing from independent and group learning processes. As shown in
Figure 1,RSandROindicate the interaction sequences for a stu-
dent and a group respectively, which are organized in time frames.
Each response interaction of a student and a group under each
time frame is represented by triples (ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘Ÿğ‘¡
ğ‘–)and(ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘¦ğ‘¡
ğ‘–), re-
spectively, where ğ‘’ğ‘¡
ğ‘–andğ‘ğ‘¡
ğ‘–denote the exercise and the knowledge
concept, and ğ‘Ÿğ‘¡
ğ‘–âˆˆ{0,1}as well asğ‘¦ğ‘¡
ğ‘–âˆˆ[0,1]indicates the studentâ€™s
response and the groupâ€™s answer accuracy rate. The goal of HKT is
to model both learning processes holistically.
However, HKT is not a trivial task and encompasses the follow-
ing technical challenges. Firstly, within the real-world educational
environment, there exists a notable absence of interactive behaviorsamong students spanning various learning scenarios, particularly
within group learning processes. This absence significantly ampli-
fies the challenge of tracing knowledge states at both individual and
group levels. For instance, missing data resulting from the absence
of a student from a class test can cause bias in the overall assess-
ment. Secondly, in contrast to traditional knowledge tracing that
only focuses on individuals, the HKT task requires simultaneously
and effectively modeling learning processes while exploring the
dynamic interactions between individuals and groups during the
learning journey, which is quite confronting.
To address these challenges, in this paper, we propose a unified
Reciprocal approach to trace the Independent and Group Learning
processes (RIGL), aimed at delivering a productive dynamic as-
sessment for both students and groups. Specifically, we first design
a time frame-aware reciprocal embedding module to simultane-
ously model studentsâ€™ and groupsâ€™ response interactions over time
frames and then used the reciprocal enhanced learning modeling to
fully exploit the comprehensive and complementary information
between the two behaviors. Subsequently, we propose a relation-
guided temporal attentive network comprised of dynamic graph
modeling and a temporal self-attentive mechanism for exploring
the dynamic complexity of individual and group interactions during
the learning processes. In particular, the relation-guided dynamic
graph is constructed by mining potential associations between stu-
dents and groups. Finally, a bias-aware contrastive learning module
is introduced to ensure the stability of training. Extensive experi-
ments on four real-world educational datasets clearly demonstrate
the effectiveness of the proposed RIGL model in the HKT task.
2 Related Work
2.1 Knowledge Tracing
Knowledge tracing (KT) [ 3] aims to monitor the changing knowl-
edge states of learners by modeling their exercise-solving sequences
as a sequence prediction task, which has been recognized as an
immensely crucial research task in the field of intelligent education.
Over the past decades, numerous effective KT models have been
proposed. Among these, the traditional KT approaches play an es-
sential role, which usually utilizes probabilistic models [ 3,21,53]
or logistic functions [ 27,28,43] to model the knowledge states of
students. In recent years, the rapid advancements of deep learning
have propelled neural network (NN)-based KT approaches into the
dominant paradigm [ 7,18,25,29,52]. These approaches leverage
the power of neural networks to dynamically mine the knowledge
acquisition process of students by solving the sequence prediction
task, by which performance improvement and personalized edu-
cational experiences are achieved. For instance, DKT [ 29] utilizes
a recurrent neural network (RNN) to model the studentâ€™s exercis-
ing sequence and represent student cognitive proficiency with the
hidden states. In particular, DKVMN [ 52] introduces the memory-
augmented neural network into KT, which defines two matrices
called keyandvalue to store and update studentâ€™s knowledge mas-
tery, respectively. Furthermore, SAKT [ 25] exploits the transformer
architecture [ 39] to explore long-term relations of interaction be-
haviors in studentsâ€™ learning history for the first time. Despite the
success of these approaches, they primarily focus on individual
assessment and thus leave a gap in the availability of a holistic
4048RIGL: A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
knowledge tracing framework that simultaneously models individ-
ual and group learning behaviors.
2.2 Dynamic Graph Representation Learning
Dynamic graph representation learning [ 11,51] is a rapidly evolving
field that focuses on effectively capturing temporal dependencies
and changing patterns within dynamic graph-structured data. In
recent years, many approaches have been proposed to effectively
model and learn the structural information and representation of
dynamic graphs in various research problems, such as link predic-
tion [ 30,31,37,55], knowledge retrieval [ 9,10], and career devel-
opment [ 4,32,48,54]. One classical category of approaches is to
conceptualize dynamic graphs by dividing them into multiple graph
snapshots with discrete time characteristics [ 2,26,34]. For example,
DySAT [ 34] employs a dual-dimension self-attention mechanism,
combining structural attention for local node features in graph
snapshots with temporal attention to track graph evolution, en-
hanced by multiple attention heads for diverse graph structure
analysis. EvolveGCN [ 26] introduces a dynamic adaptation of the
graph convolutional network (GCN) model across time, using an
RNN to evolve its parameters and capture the dynamics of graph
sequences, with two different architectures for parameter evolution.
Another avenue of exploration regards time as a continuous
feature, treating the dynamic graph as a stream of timestamped
events to derive node representations [ 33,38,55]. For instance,
DyRep [ 38] is a dynamic graph framework conceptualizing rep-
resentation learning as a latent mediation process bridging two
observed processes namelyâ€“dynamics of the network and dynam-
ics on the network, which leverages a two-time scale deep temporal
point process and a temporal-attentive network to intertwine net-
work topology and node activity dynamics. Moreover, dynamic
graph learning are also applied in intelligent tutoring systems (ITS),
e.g., TEGNN [ 15] presents a method that combines a heterogeneous
evolution network with a temporal extension graph neural network
to dynamically model entities and relations [ 4] in the intelligent tu-
toring system. Although these strategies behave well in many tasks,
how to introduce this idea into holistic knowledge tracing, where
the knowledge states of individuals and groups vary dynamically
over time and the associations and influences between them are
difficult to construct and capture directly, has not been explored.
3 Problem Formulation
In this section, we formally define the holistic knowledge trac-
ing (HKT) problem. Let O={ğ‘œ1,...,ğ‘œğ¼}be the set of ğ¼groups,
S={ğ‘ 1,...,ğ‘ ğ‘}be the set of ğ‘students,E={ğ‘’1,...,ğ‘’ğ‘€}be the
set ofğ‘€exercises, andC={ğ‘1,...,ğ‘ğ¾}be the set of ğ¾knowl-
edge concepts. The relationship between exercises and concepts
is denoted by ğ‘„-matrixğ‘„={ğ‘ğ‘–ğ‘—}ğ‘€Ã—ğ¾, whereğ‘ğ‘–ğ‘—=1if exercise
ğ‘’ğ‘–requires concept ğ‘ğ‘—and0otherwise. Each group consists of a
certain number of students, e.g., the ğ‘–-th groupğ‘œğ‘–={ğ‘ ğ‘–
1,...,ğ‘ ğ‘–
|ğ‘œğ‘–|},
whereğ‘ ğ‘–âˆ—âˆˆSand|ğ‘œğ‘–|is the size of group ğ‘œğ‘–.
Generally, students perform personalized learning activities un-
der time frames, i.e., answering a certain number of exercises
at specific time intervals. We denote the whole interaction se-
quence of a student with ğ‘‡time frames asRS={F1,...,Fğ‘‡},
whereFğ‘¡={(ğ‘’ğ‘¡
1,ğ‘ğ‘¡
1,ğ‘Ÿğ‘¡
1),...,(ğ‘’ğ‘¡
|Fğ‘¡|,ğ‘ğ‘¡
|Fğ‘¡|,ğ‘Ÿğ‘¡
|Fğ‘¡|)}stands for the in-
teraction sequence under ğ‘¡-th time frame; the triple (ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘Ÿğ‘¡
ğ‘–)refersğ‘–-th exercising record; ğ‘’ğ‘¡
ğ‘–âˆˆ E is the exercise; ğ‘ğ‘¡
ğ‘–âˆˆ C is
the concept associated with the exercise ğ‘’ğ‘¡
ğ‘–, which is obtained
from theğ‘„; andğ‘Ÿğ‘¡
ğ‘–âˆˆ{0,1}is the response score. Meanwhile, stu-
dents would engage in collective learning behaviors under time
frames, where all students in the group completed the same batch
of exercises. We denote the whole group interaction sequence
for a group with ğ‘‡time frames asRO={H1,...,Hğ‘‡}, where
Hğ‘¡={(ğ‘’ğ‘¡
1,ğ‘ğ‘¡
1,ğ‘¦ğ‘¡
1),...,(ğ‘’ğ‘¡
|Hğ‘¡|,ğ‘ğ‘¡
|Hğ‘¡|,ğ‘¦ğ‘¡
|Hğ‘¡|)}is the group-exercise
interaction sequence under ğ‘¡-th time frame; the triple (ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘¦ğ‘¡
ğ‘–)
denotesğ‘–-th interaction log; ğ‘’ğ‘¡
ğ‘–âˆˆE,ğ‘ğ‘¡
ğ‘–âˆˆCandğ‘¦ğ‘¡
ğ‘–âˆˆ[0,1]is the
correct rate that the group got.
Problem Definition. Given studentâ€™s interaction sequence RS=
{F1,...,Fğ‘‡}, whereFğ‘¡={(ğ‘’ğ‘¡
1,ğ‘ğ‘¡
1,ğ‘Ÿğ‘¡
1),...,(ğ‘’ğ‘¡
|Fğ‘¡|,ğ‘ğ‘¡
|Fğ‘¡|,ğ‘Ÿğ‘¡
|Fğ‘¡|)}and
groupâ€™s interaction sequence RO={H1,...,Hğ‘‡}, whereHğ‘¡=
{(ğ‘’ğ‘¡
1,ğ‘ğ‘¡
1,ğ‘¦ğ‘¡
1),...,(ğ‘’ğ‘¡
|Hğ‘¡|,ğ‘ğ‘¡
|Hğ‘¡|,ğ‘¦ğ‘¡
|Hğ‘¡|)}, the goal of holistic knowledge
tracing is twofold: (1) simultaneously diagnosing the knowledge state
of each student within a group and the group-level proficiency of the
corresponding group from time frame ğ‘¡1toğ‘¡ğ‘‡; and (2) simultane-
ously predicting studentsâ€™ performance scores as well as the groupâ€™s
correct rate on specific exercises at time frame ğ‘¡ğ‘‡+1.Notably, unlike
traditional KT task, the interaction elements (e.g., (ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘¦ğ‘¡
ğ‘–)âˆˆFğ‘¡)
under each current time frame in the HKT task are not used for
prediction to avoid information leakage.
4 Methodology
In this section, we present the RIGL model in detail. As illustrated in
Figure 2, the architecture of RIGL mainly consists of three compo-
nents, which are a time frame-aware reciprocal embedding module,
a relation-guided temporal attentive network, and a contrastive
learning module.
4.1 Time Frame-Aware Reciprocal Embedding
Module
Effectively representing student interaction and modeling knowl-
edge acquisition during the learning process has always been very
critical in traditional knowledge tracing task [ 36]. Similarly, to ef-
fectively model the learning process of students and groups under
each time frame in the HKT task, we carefully design three sub-
modules: the individual interaction modeling, the group interaction
modeling, and the reciprocal enhanced learning module, which are
detailed in the following.
4.1.1 Individual Interaction Modeling. As mentioned earlier, each
student typically solves multiple exercises under each time frame
Fğ‘¡. Each interaction behavior (ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘Ÿğ‘¡
ğ‘–)contains the interactive
exercises, the involved knowledge concept, and the corresponding
response, which are often rich in information [ 7]. We first encode
the question and response for each student interaction ğ‘–, as follows:
xğ‘¡
ğ‘–=[eğ‘¡
ğ‘–âŠ•cğ‘¡
ğ‘–] W 1+b1;zğ‘¡
ğ‘–=rğ‘¡
ğ‘–, (1)
where eğ‘¡
ğ‘–âˆˆRğ‘‘ğ‘’,cğ‘¡
ğ‘–âˆˆRğ‘‘ğ‘, and rğ‘¡
ğ‘–âˆˆRğ‘‘ğ‘Ÿdenote the latent represen-
tations ofğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–, andğ‘Ÿğ‘¡
ğ‘–respectively, W1âˆˆRğ‘‘ğ‘’Ã—ğ‘‘andb1âˆˆRğ‘‘are
the trainable parameters, and âŠ•refers to the element-wise addition
operator. Notably, ğ‘‘ğ‘’,ğ‘‘ğ‘, andğ‘‘ğ‘Ÿare the dimensions of the embed-
dings of exercise, concept, and response respectively, and here ğ‘‘ğ‘’
equals toğ‘‘ğ‘.
4049KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Xiaoshan Yu et al.
Figure 2: The overview architecture of our proposed RIGL model. (a) The time frame-aware reciprocal embedding module
includes both individual and group interaction modeling as well as reciprocal enhanced learning. (b) The relation-guided
temporal attentive network models the complex learning processes with dynamic changing knowledge, including the relation-
guided dynamic graph modeling and a temporal self-attentive network. (c) The contrastive learning module generates the
augmented student interactions by randomly flipping responses considering the learning bias during exercise solving, such as
carelessness or guessing, and promotes the training stability through this bias-aware contrastive learning. Best viewed in color.
After the student interaction encoding, we obtain a set of exercise
encoding xğ‘¡={xğ‘¡
1,xğ‘¡
2,..., xğ‘¡
|Fğ‘¡|}and a set of response encoding
zğ‘¡={zğ‘¡
1,zğ‘¡
2,..., zğ‘¡
|Fğ‘¡|}under the time frame Fğ‘¡. Considering that a
studentâ€™s capability is usually stable over a short period of time [ 35],
we utilize all of the studentâ€™s exercising behaviors under a time
frame to comprehensively model her knowledge acquisition. Specif-
ically, we leverage the average pooling operation as a knowledge
aggregator [ 35] to fuse all interactions thereby perceiving knowl-
edge gain during student learning as below:
xğ‘ 
ğ‘¡=1
|Fğ‘¡||Fğ‘¡|âˆ‘ï¸
ğ‘–=1xğ‘¡
ğ‘–;zğ‘ 
ğ‘¡=1
|Fğ‘¡||Fğ‘¡|âˆ‘ï¸
ğ‘–=1zğ‘¡
ğ‘–, (2)
where xğ‘ 
ğ‘¡âˆˆRğ‘‘andzğ‘ 
ğ‘¡âˆˆRğ‘‘denote the knowledge representation
and the performance representation of student ğ‘ underğ‘¡-th time
frame, respectively.
4.1.2 Group Interaction Modeling. Similar to the exercise-solving
process of students, there will be multiple group-exercise interac-
tion records under one time window. Given any one interaction
(ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘¦ğ‘¡
ğ‘–)under theğ‘¡-th time frameHğ‘¡of groupğ‘œ, it consists of
the question, the concept, and the percentage of correct responses.
We first encode the exercise traits and the collective response infor-
mation:
Ë†xğ‘¡
ğ‘–=[eğ‘¡
ğ‘–âŠ•cğ‘¡
ğ‘–] W 2+b2;Ë†zğ‘¡
ğ‘–=ğ‘¦ğ‘¡
ğ‘–h1+ğ‘1, (3)
where eğ‘¡
ğ‘–âˆˆRğ‘‘ğ‘’andcğ‘¡
ğ‘–âˆˆRğ‘‘ğ‘refer to the embeddings of ğ‘’ğ‘¡
ğ‘–and
ğ‘ğ‘¡
ğ‘–respectively, W2âˆˆRğ‘‘ğ‘’Ã—ğ‘‘,b2âˆˆRğ‘‘,h1âˆˆR, andğ‘1âˆˆRare
the trainable parameters. Note that we set the new parameters
W2andb2different from Eq. 1 to model the question embeddings
under the perspective of the student group. After acquiring the
group interaction encoding sets Ë†xğ‘¡={Ë†xğ‘¡
1,Ë†xğ‘¡
2,..., Ë†xğ‘¡
|Hğ‘¡|}andË†zğ‘¡={Ë†zğ‘¡
1,Ë†zğ‘¡
2,..., Ë†zğ‘¡
|Hğ‘¡|}, we further model the learning evolution of group
level within the time frame, similar to Eq.(2):
xğ‘œ
ğ‘¡=1
|Hğ‘¡||Hğ‘¡|âˆ‘ï¸
ğ‘–=1Ë†xğ‘¡
ğ‘–;zğ‘œ
ğ‘¡=1
|Hğ‘¡||Hğ‘¡|âˆ‘ï¸
ğ‘–=1Ë†zğ‘¡
ğ‘–. (4)
4.1.3 Reciprocal Enhanced Learning. Individual and group learn-
ing are always interrelated and complementary in organizations
(e.g., classes, teams [ 14]), where the collective activities in which
students participate contribute to the complementation of the stu-
dentsâ€™ knowledge proficiency, as well as the individualized learning
history of the students promotes the perception of the group-level
ability [ 8,20]. Inspired by this, we propose a reciprocal enhanced
learning module for tracing individual and group interaction si-
multaneously (as shown in Figure 2(a)). Specifically, we first utilize
group interaction information to enrich individual learning fea-
tures:
exğ‘ 
ğ‘¡=xğ‘ 
ğ‘¡âŠ•xğ‘œ
ğ‘¡;ezğ‘ 
ğ‘¡=zğ‘ 
ğ‘¡âŠ•zğ‘œ
ğ‘¡, (5)
whereexğ‘ 
ğ‘¡,ezğ‘ 
ğ‘¡âˆˆRğ‘‘stand for the enhanced student interaction encod-
ing. As well, we utilize personalized learning behaviors of students
within the same group to enhance the modeling of group-level learn-
ing interaction. In particular, to address the challenge of individual
absence in collective interaction, we elaborate an absence-perceived
attention aggregation module:
exğ‘œ
ğ‘¡=xğ‘œ
ğ‘¡âŠ•|ğ‘œ|âˆ‘ï¸
ğ‘–=1ğœ†ğ‘–xğ‘ ğ‘–
ğ‘¡;ezğ‘œ
ğ‘¡=zğ‘œ
ğ‘¡âŠ•|ğ‘œ|âˆ‘ï¸
ğ‘–=1ğœ†ğ‘–zğ‘ ğ‘–
ğ‘¡, (6)
where xğ‘ ğ‘–
ğ‘¡,zğ‘ ğ‘–
ğ‘¡âˆˆRğ‘‘are the interaction features of ğ‘–-th student ğ‘ ğ‘–
within group ğ‘œ, andğœ†ğ‘–denotes the absence-perceived contribution
4050RIGL: A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
weight, which is computed by,
Ë†ğœ†ğ‘–=ğ‘…ğ‘’ğ¿ğ‘ˆ([xğ‘ ğ‘–
ğ‘¡;zğ‘ ğ‘–
ğ‘¡]Wğ‘˜+[xğ‘œ
ğ‘¡;zğ‘œ
ğ‘¡]Wğ‘)h2,
ğœ†ğ‘–=ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(Ë†ğœ†ğ‘–)=ğ‘’ğ‘¥ğ‘(Ë†ğœ†ğ‘–)
Ã|ğ‘œ|
ğ‘—=1ğ‘’ğ‘¥ğ‘(Ë†ğœ†ğ‘—).(7)
where Wğ‘˜,Wğ‘âˆˆR2ğ‘‘Ã—ğ‘‘are the key and query matrices of the
attention layer, h2âˆˆRğ‘‘is the weight vector for projecting attention
scores, andğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(Â·)and[Â·;Â·]denote the softmax function and
the concatenation operation.
4.2 Relation-Guided Temporal Attentive
Network
Considering the dynamic complexity of the learning process of
students and groups and the information interaction between them,
in this section, we propose a relation-guided temporal attentive
network to model this complex learning process with dynamic
changing knowledge, which consists of the relation-guided dynamic
graph modeling and a temporal self-attentive network.
4.2.1 Relation-Guided Dynamic Graph Modeling. In this section,
we first describe how to construct the relation-guided dynamic
graph and then design a dynamic GCN module to enhance the
relation modeling. Referring to previous work [ 34], we consider the
global dynamic graph as a series of static graph snapshots, i.e., G=
{G1,G2,...,Gğ‘‡}, whereğ‘‡is the number of time frames. For time
frameğ‘¡âˆˆğ‘‡, with respect to the personalized learning behaviors
of the students in the group ğ‘œâˆˆO and the interactive response
behaviors of the group, we construct the corresponding group-
individual graphGğ‘œ
ğ‘¡=(ğ‘‰,ğ¸ğ‘¡)with a node set ğ‘‰={ğ‘œ,ğ‘ 1,...,ğ‘ |ğ‘œ|}
and a edge set ğ¸ğ‘¡=(ğ¸ğ‘œâ†”ğ‘ ,ğ¸ğ‘¡ğ‘ â†”ğ‘ ), whereğ¸ğ‘œâ†”ğ‘ denotes the set of
edges connecting the group node ğ‘œand all other student nodes, and
ğ¸ğ‘¡ğ‘ â†”ğ‘ denotes the set of connecting edges between students under
time stageğ‘¡, which is dynamically changing.
Specifically, a relation-guided approach is proposed to construct
the changing edges between students. We first incorporate the
above interaction encoding as node feature:
vğ‘¡
0=[exğ‘œ
ğ‘¡;ezğ‘œ
ğ‘¡];vğ‘¡
ğ‘–=[exğ‘ ğ‘–
ğ‘¡;ezğ‘ ğ‘–
ğ‘¡],ğ‘–âˆˆ{1,2,...,|ğ‘œ|}, (8)
where vğ‘¡
0,vğ‘¡
ğ‘–âˆˆR2ğ‘‘denote the feature vector of group node and
student nodes respectively. Then, we obtain the node feature matrix
Vğ‘¡âˆˆR(|ğ‘œ|+1)Ã—2ğ‘‘. For any two student nodes vğ‘¡
ğ‘–andvğ‘¡
ğ‘—in the time
frameğ‘¡, whereğ‘–,ğ‘—âˆˆ{1,2,...,|ğ‘œ|}, we acquire the relation distance
by calculate the exercise interaction similarity between them and
then obtain the relation matrix as follows:
Dğ‘¡=[ğ‘‘vğ‘¡
ğ‘–,vğ‘¡
ğ‘—]1â‰¤ğ‘–,ğ‘—â‰¤|ğ‘œ|,
ğ‘‘vğ‘¡
ğ‘–,vğ‘¡
ğ‘—=ğ‘ ğ‘–ğ‘š(vğ‘¡
ğ‘–,vğ‘¡
ğ‘—),(9)
where Dğ‘¡âˆˆR|ğ‘œ|Ã—|ğ‘œ|denotes the relation matrix, and ğ‘ ğ‘–ğ‘š(Â·)stands
for similarity function (e.g., cosine similarity). Subsequently, for
any student node vğ‘¡
ğ‘–, we select top-k other student nodes with the
highest potential associations to construct its first-order neighbors
according to Dğ‘¡
ğ‘–,ğ‘—,ğ‘—âˆˆ{1,...,|ğ‘œ|}\{ğ‘–}, and then we can get the
adjacency matrix Ağ‘¡âˆˆ {0,1}(|ğ‘œ|+1)Ã—(|ğ‘œ|+1), which includes the
connectivity between group node and student node, as shown in
upper part of Figure 2(b).After the construction of Gğ‘œ, we design a dynamic GCN module
composed of static GCN units to effectively model the deeper asso-
ciations between group and student as well as student and student
by introducing the GCN layers [ 12]. Given the node feature matrix
Vğ‘¡and the adjacency matrix Ağ‘¡, theğ‘™-layer GCN of the unit under
theğ‘¡-th time frame is defined as:
Vğ‘¡
(ğ‘™+1)=ğ›¼(Ë†Ağ‘¡Vğ‘¡
(ğ‘™)Wğ‘¡
(ğ‘™)+bğ‘¡
(ğ‘™)), (10)
where Vğ‘¡
0=Vğ‘¡,Wğ‘¡
(ğ‘™)âˆˆRğ‘‘ğ‘™Ã—ğ‘‘ğ‘™+1,bğ‘¡
(ğ‘™)âˆˆRğ‘‘ğ‘™are trainable param-
eters,ğ‘‘ğ‘™denotes the output node feature dimension for ğ‘™-th layer
andğ‘‘0=2ğ‘‘,ğ›¼(Â·)stands for the non-linear activation function (e.g.,
ReLU), and Ë†Ağ‘¡=(ËœUğ‘¡)âˆ’1
2ËœAğ‘¡(ËœUğ‘¡)âˆ’1
2)is the normalized symmetric
adjacency matrix. Here, ËœAğ‘¡=Ağ‘¡+I|ğ‘œ|+1, and ËœUğ‘¡is the degree
matrix. I|ğ‘œ|+1denotes an identity matrix with dimensions of |ğ‘œ|+1
and ËœUğ‘¡
ğ‘–ğ‘–=Ã
ğ‘—Ağ‘¡
ğ‘–ğ‘—.
4.2.2 Temporal Self-Attentive Network. To more effectively capture
the intricate temporal effects in the overall abilities and knowledge
states of groups and individual students during the learning process,
we introduce a temporal self-attentive network in this section. Fol-
lowing previous work [ 7,18], we define the temporal self-attention
module and obtain the retrieved knowledge states of the group and
student (i.e., the selection of Q,K,Vparameters is essentially a
knowledge retriever) as follows:
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£³hğ‘œ
ğ‘¡+1=ğ‘†ğ‘’ğ‘™ğ‘“ğ´ğ‘¡ğ‘¡(Qğ‘œ,Kğ‘œ,Vğ‘œ),
Qğ‘œ=mğ‘¡+1
0,Kğ‘œ={m1
0,..., mğ‘¡
0},Vğ‘œ={n1
0,..., nğ‘¡
0};
hğ‘ ğ‘–
ğ‘¡+1=ğ‘†ğ‘’ğ‘™ğ‘“ğ´ğ‘¡ğ‘¡(Qğ‘ ğ‘–,Kğ‘ ğ‘–,Vğ‘ ğ‘–),
Qğ‘ ğ‘–=mğ‘¡+1
ğ‘–,Kğ‘ ğ‘–={m1
ğ‘–,..., mğ‘¡
ğ‘–},Vğ‘ ğ‘–={n1
ğ‘–,..., nğ‘¡
ğ‘–},(11)
where mğ‘¡
0=Vğ‘¡
(ğ¿)[0,:ğ‘‘],nğ‘¡
0=Vğ‘¡
(ğ¿)[0,ğ‘‘:],mğ‘¡
ğ‘–=Vğ‘¡
(ğ¿)[ğ‘–,:ğ‘‘],nğ‘¡
ğ‘–=
Vğ‘¡
(ğ¿)[ğ‘–,ğ‘‘:]âˆˆRğ‘‘,1â‰¤ğ‘–â‰¤|ğ‘œ|are the interaction features of group
ğ‘œand student ğ‘ ğ‘–extracted from the learned ğ¿-th layer node rep-
resentations, ğ‘‘=ğ‘‘ğ¿
2is the dimension size of final representation
andğ‘†ğ‘’ğ‘™ğ‘“ğ´ğ‘¡ğ‘¡(Â·)denotes the Self-Attention module. Notably, similar
to AKT [ 7], we can only model current interaction with visible
historical learning behaviors to prevent information leakage (as
shown in the lower part of Figure 2(b)).
Finally, we construct a readout module consisting of a two-layer
fully connected network for the next time frame performance pre-
diction of the group and student (as shown in part (1) of Figure 2(c)).
Specifically:(Ë†ğ‘¦ğ‘–,ğ‘¡+1=ğ‘€ğ¿ğ‘ƒğ‘‚([hğ‘œ
ğ‘¡+1;eğ‘¡+1
ğ‘–]),
Ë†ğ‘Ÿğ‘–,ğ‘¡+1=ğ‘€ğ¿ğ‘ƒğ‘†([hğ‘ 
ğ‘¡+1;eğ‘¡+1
ğ‘–]),(12)
where Ë†ğ‘¦ğ‘–,ğ‘¡+1andË†ğ‘Ÿğ‘–,ğ‘¡+1denote the predicted responses of group ğ‘œ
and student ğ‘ onğ‘–-th exercise eğ‘¡+1
ğ‘–underğ‘¡+1-th time frame, and
ğ‘€ğ¿ğ‘ƒğ‘‚andğ‘€ğ¿ğ‘ƒğ‘†are two MLP networks.
4.3 Model Optimization
In this section, we describe the model training and parameter op-
timization. In particular, we design a contrastive learning module
in order to ensure the stability of the training process and the
effectiveness of the learning of representations.
4.3.1 Contrastive Learning Module. Inspired by [ 13,49], we argue
that a learner may have response biases, such as careless responses
or guessing responses, when performing questions over a period of
4051KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Xiaoshan Yu et al.
time. Along this line, we design a bias-aware contrastive learning
module for learning robust representations. Specifically, as shown
in part (2) of Figure 2(c), we randomly flip studentsâ€™ responses in the
time frames to generate the augmented interactions, and intuitively,
the augmented student state should remain similar to the original.
Following previous work [ 49], we calculate contrastive loss from a
single batch:
Lğ¶ğ¿
ğ‘ ğ‘–,ğ‘¡=âˆ’ğ‘™ğ‘œğ‘”ğ‘’ğ‘¥ğ‘(ğ‘ ğ‘–ğ‘š(hğ‘ ğ‘–
ğ‘¡,hğ‘ ğ‘–+
ğ‘¡)/ğœ)
Ã
ğ‘—â‰ ğ‘–ğ‘’ğ‘¥ğ‘(ğ‘ ğ‘–ğ‘š(hğ‘ ğ‘–
ğ‘¡,hğ‘ ğ‘—+
ğ‘¡)/ğœ), (13)
where hğ‘ ğ‘–+
ğ‘¡denotes the augmented student state of student ğ‘ ğ‘–under
theğ‘¡-th time frame, ğœis a temperature parameter (here set as 0.05),
andğ‘ ğ‘–ğ‘š(Â·)stands for the similarity function.
4.3.2 Loss Function. In the training phase, we jointly evaluate
the model performance by predicting the interaction of both the
group- and student-exercise responses. Specifically, for each student
ğ‘ within group ğ‘œ, we utilize the cross-entropy loss function for the
student performance prediction:
Lğ‘ ğ‘¡ğ‘¢
ğ‘œ=âˆ’âˆ‘ï¸
ğ‘ âˆ‘ï¸
ğ‘¡âˆ‘ï¸
ğ‘–ğ‘Ÿğ‘ 
ğ‘–,ğ‘¡logË†ğ‘Ÿğ‘ 
ğ‘–,ğ‘¡âˆ’(1âˆ’ğ‘Ÿğ‘ 
ğ‘–,ğ‘¡)log(1âˆ’Ë†ğ‘Ÿğ‘ 
ğ‘–,ğ‘¡).(14)
Then, we choose the mean square error loss (MSE) function for the
group-exercise interaction prediction:
Lğ‘”ğ‘Ÿğ‘
ğ‘œ=âˆ‘ï¸
ğ‘¡âˆ‘ï¸
ğ‘–(Ë†ğ‘¦ğ‘œ
ğ‘–,ğ‘¡âˆ’ğ‘¦ğ‘œ
ğ‘–,ğ‘¡)2.(15)
Meanwhile, we calculate the contrastive loss of all students in the
groupğ‘œaccording to Eq.(13):
Lğ¶ğ¿
ğ‘œ=âˆ‘ï¸
ğ‘ âˆ‘ï¸
ğ‘¡Lğ¶ğ¿
ğ‘ ,ğ‘¡.(16)
Finally, we obtain the complete optimization objective function
based on the above three loss objectives:
Lğ‘œ=Lğ‘”ğ‘Ÿğ‘
ğ‘œ+1
|ğ‘œ|Lğ‘ ğ‘¡ğ‘¢
ğ‘œ+ğ›¾Â·Lğ¶ğ¿
ğ‘œ. (17)
whereğ›¾is the weight coefficient to control the influence of con-
trastive signals. We can then train the whole model and optimize
the model parameters utilizing gradient descent.
5 Experiments
In this section, we conduct extensive experiments on four real-world
education datasets aiming at verifying the effectiveness and superi-
ority of our proposed RIGL model. Specifically, we will answer the
following research questions (RQs) to unfold the experiments:
â€¢RQ1: What about the effectiveness and superiority of the pro-
posed RIGL model on the holistic knowledge tracing task?
â€¢RQ2: Do the designed key components benefit our proposed
RIGL model in achieving performance improvement?
â€¢RQ3: How do the hyper-parameter settings influence the holistic
knowledge tracing performance of the RIGL model?
â€¢RQ4: How does RIGL facilitate tracing the evolution of knowl-
edge states in both individuals and groups and how does it help
to understand the progression of their relationships over time?
5.1 Experimental Setting
5.1.1 Datasets. We conduct experiments on four real-world edu-
cation datasets with diversity to evaluate the effectiveness of the
proposed RIGL on the holistic tracing task, which are ASSIST12 [ 5],Table 1: The statistics of all datasets.
Statistics
ASSIST12 NIPS-Edu SLP-Math SLP-Bio
#Students
2,281 1,138 1,488 1,727
#Groups 101 91 126 150
#Exercises 8,838 747 142 121
#Knowledge concepts 162 225 41 22
Avg. group size 22.79 12.51 11.80 11.51
Avg. responses per student 67.16 87.53 78.54 94.58
Avg. responses per group 55.33 67.46 79.93 97.84
Avg. responses per time frame 33.53 32.47 32.93 35.04
NIPS-Edu [ 40], SLP-Math [ 19] and SLP-Bio [ 19]. All datasets contain
the group labels (i.e., the class to which the students belong), and
students from the same group share the same label category. Table 1
shows the statistics of the datasets, and more details of the dataset
description and data preprocessing are available in Appendix A.2.
5.1.2 Baseline Approaches. The performance of RIGL is com-
pared with eight strong and commonly used baselines including
DKT [ 29], SAKT [ 25], AKT [ 7], LPKT [ 36], GIKT [ 47], simpleKT [ 18],
AT-DKT [ 17] and DTransformer [ 49]. Notably, these baselines are
individual-based knowledge tracing models, so we adapt them on
the HKT task. The introduction and implementation details can be
found in Appendix A.3.
5.1.3 Evaluation Metrics. To comprehensively evaluate the per-
formance of all methods on holistic knowledge tracing, we adopt
four evaluation metrics, including the area under the ROC curve
(AUC), accuracy (ACC), root mean square error (RMSE), and mean
absolute error (MAE). Specifically, the AUC and ACC are used to
evaluate the individual-level performance prediction, and RMSE
and MAE for the group-level performance on future exercises.
5.1.4 Parameter Settings. We performed 5-fold cross-validation
in the experiments. For each fold, 80% of samples are set as for
the training data, and others are for the test set. We implemented
all methods with PyTorch by Python. The dimension size of em-
beddings (i.e., ğ‘‘ğ‘’,ğ‘‘ğ‘,ğ‘‘ğ‘Ÿ) was set as 256. The number of the GCN
layersğ¿1was set to 2, where each layerâ€™s hidden size is 256, and
the number of self-attentive network layers ğ¿2is set to 4. We used
the Adam optimizer, where the learning rate was searched in [1e-4,
5e-4, 1e-3, 2e-3, 1e-2]. The coefficient ğ›¾of contrastive loss was set to
0.01. We adopted the cosine similarity as the similarity calculation
functionğ‘ ğ‘–ğ‘š(Â·)(Eq.9 and Eq.13).
5.2 Performance Comparison (RQ1)
Table 2 shows the performance of the proposed RIGL including
individual-level and group-level compared with the baseline models
on the four datasets. We highlighted the best results of all mod-
els in boldface and underlined the suboptimal results. According
to the results, there are several observations: (1) Our RIGL model
demonstrates significant improvements over the baselines across
all datasets. Specifically, it shows an average increase of 4.01% and
20.32% over the best baseline model at both the individual and
group levels, respectively, which underscores the effectiveness of
the RIGL. Especially, in comparison to the runner-up method on
the SLP-Bio dataset, our model achieves an average of 5.83% and
31.59% performance improvements in terms of individual-level and
group-level. (2) RIGL generally has a higher percentage of increased
performance in terms of the group-level than the individual-level,
demonstrating that personalized learning information is highly
4052RIGL: A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 2: Performance of RIGL and all baselines on all datasets on predicting future performance of individual-level and
group-level.â†‘(â†“) means the higher (lower) score the better performance. â€œ âˆ—â€ denotes the statistically significant improvement
of RIGL model compared to the best baseline method (i.e., two-sided t-test with p<0.05). Bold: the best, Underline : the runner-up.
DatasetsASSIST12 NIPS-Edu
Individual-le
vel Gr
oup-level Individual-le
vel Gr
oup-level
Metrics AUC
(â†‘) ACC (â†‘) RMSE
(â†“) MAE (â†“) AUC
(â†‘) ACC (â†‘) RMSE
(â†“) MAE (â†“)
DKT 0.6276Â±0.0282 0.7042Â±0.0174 0.2331Â±0.0164 0.1776Â±0.0120 0.6267Â±0.0144 0.6159Â±0.0219 0.2957Â±0.0034 0.2373Â±0.0026
SAKT 0.6075Â±0.0235 0.7183Â±0.0232 0.2302Â±0.0162 0.1693Â±0.0075 0.6295Â±0.0183 0.6207Â±0.0164 0.3060Â±0.0143 0.2470Â±0.0126
AKT 0.6188Â±0.0217 0.7259Â±0.0245 0.2288Â±0.0205 0.1750Â±0.0113 0.6448Â±0.0159 0.6284Â±0.0259 0.2768Â±0.0022 0.2275Â±0.0048
LPKT 0.6379Â±0.0287 0.7362Â±0.0300 0.2194Â±0.0205 0.1705Â±0.0111 0.6630Â±0.0135 0.6453Â±0.0129 0.2665Â±0.0073 0.2185Â±0.0074
GIKT 0.6268Â±0.0201 0.7271Â±0.0212 0.2259Â±0.0133 0.1759Â±0.0115 0.6547Â±0.0136 0.6410Â±0.0227 0.2744Â±0.0094 0.2431Â±0.0105
simpleKT 0.6161Â±0.0214 0.7295Â±0.0255 0.2226Â±0.0182 0.1654Â±0.0124 0.6402Â±0.0206 0.6268Â±0.0230 0.2736Â±0.0136 0.2179Â±0.0112
A
T-DKT 0.6414Â±0.0223 0.7395Â±0.0197 0.2212Â±0.0174 0.1728Â±0.0106 0.6678Â±0.0203 0.6525Â±0.0233 0.2683Â±0.0087 0.2232Â±0.0096
D
Transformer 0.6392Â±0.0237 0.7347Â±0.0216 0.2183Â±0.0157 0.1686Â±0.0097 0.6726Â±0.0113 0.6488Â±0.0137 0.2706Â±0.0074 0.2163Â±0.0122
LPKT
-Ind 0.7344Â±0.0039 0.7579Â±0.0067 -
- 0.6541Â±0.0061 0.6296Â±0.0138 -
-
simpleKT-Ind 0.6696Â±0.0073 0.7481Â±0.0074 -
- 0.6425Â±0.0032 0.6287Â±0.0076 -
-
RIGL 0.7394âˆ—
Â±0 .01410.7673âˆ—Â±0 .0126 0.2074âˆ—Â±0 .01030.1515âˆ—Â±0 .0109 0.7326âˆ—Â±0 .01150.6779âˆ—Â±0 .0144 0.2344âˆ—Â±0 .00930.1775âˆ—Â±0 .0072
DatasetsSLP-Math SLP-Bio
Individual-le
vel Gr
oup-level Individual-le
vel Gr
oup-level
Metrics AUC
(â†‘) ACC (â†‘) RMSE
(â†“) MAE (â†“) AUC
(â†‘) ACC (â†‘) RMSE
(â†“) MAE (â†“)
DKT 0.7765Â±0.0036 0.7636Â±0.0159 0.3136Â±0.0165 0.2439Â±0.0166 0.7152Â±0.0050 0.7147Â±0.0159 0.1975Â±0.0035 0.1580Â±0.0030
SAKT 0.7899Â±0.0033 0.7635Â±0.0102 0.2045Â±0.0098 0.1691Â±0.0089 0.7366Â±0.0043 0.7151Â±0.0094 0.2167Â±0.0050 0.1759Â±0.0048
AKT 0.7957Â±0.0060 0.7742Â±0.0110 0.1895Â±0.0072 0.1559Â±0.0074 0.6850Â±0.0097 0.6923Â±0.0131 0.2122Â±0.0037 0.1749Â±0.0055
LPKT 0.7844Â±0.0093 0.7249Â±0.0235 0.1947Â±0.0038 0.1569Â±0.0026 0.7210Â±0.0042 0.6754Â±0.0146 0.1966Â±0.0034 0.1561Â±0.0028
GIKT 0.7818Â±0.0087 0.7643Â±0.0154 0.2175Â±0.0069 0.1624Â±0.0065 0.7223Â±0.0073 0.7017Â±0.0048 0.2082Â±0.0051 0.1710Â±0.0066
simpleKT 0.7904Â±0.0084 0.7725Â±0.0095 0.2038Â±0.0129 0.1536Â±0.0133 0.6919Â±0.0051 0.6958Â±0.0117 0.2040Â±0.0029 0.1650Â±0.0032
A
T-DKT 0.7865Â±0.0047 0.7691Â±0.0081 0.1906Â±0.0113 0.1577Â±0.0085 0.7064Â±0.0118 0.6976Â±0.0085 0.2038Â±0.0063 0.1685Â±0.0049
D
Transformer 0.7919Â±0.0043 0.7757Â±0.0095 0.1874Â±0.0064 0.1546Â±0.0028 0.7367Â±0.0069 0.7173Â±0.0104 0.1981Â±0.0075 0.1597Â±0.0050
LPKT
-Ind 0.7762Â±0.0086 0.7387Â±0.0179 -
- 0.7375Â±0.0018 0.7149Â±0.0083 -
-
simpleKT-Ind 0.7816Â±0.0057 0.7566Â±0.0169 -
- 0.6961Â±0.0162 0.7099Â±0.0127 -
-
RIGL 0.8304âˆ—Â±0 .00490.7853âˆ—Â±0 .0102 0.1383âˆ—Â±0 .00480.1078âˆ—Â±0 .0113 0.7959âˆ—Â±0 .00800.7442âˆ—Â±0 .0085 0.1357âˆ—Â±0 .00420.1058âˆ—Â±0 .0039
effective and has a more pronounced impact on the group-level di-
agnosis during the reciprocal learning modeling. (3) In the baseline
methods, the DTransformer and LPKT models exhibit relatively
better performance compared to other baselines. This phenomenon
may be attributed to the gains from modeling forgetting behav-
iors in both group and individual learning processes in those two
models.
In particular, we also conducted experiments for baselinesâ€™ indi-
vidual version (i.e., traditional knowledge tracing model) utilizing
only individual interaction data and present the results of LPKT-Ind
and simpleKT-Ind in Table 2 (the complete results can be found in
Appendix A.4). As can be observed from the results, our RIGL re-
mains significantly superior in terms of individual-level proficiency
assessment. Specifically, it shows an average increase of 5.91% and3.48% over the best individual knowledge tracing baseline in terms
of AUC and ACC metrics, respectively, which demonstrates the
contribution of group learning behaviors to the modeling of inde-
pendent learning, and the effectiveness of the proposed reciprocal
learning modeling in our RIGL model. In addition, some of the base-
line models are less effective at the individual-level than modeling
the individual alone, suggesting that simple joint training may not
always work, and this is further evidence of the validity of RIGL.
An interesting phenomenon is that the advantage of RIGL over the
KTM-ind model behaves differently on different datasets, which
may be caused by the characteristics of the dataset. Since the RIGL
model requires tracing both individual and group ability changes,
its performance suffers when the group-exercise interactions are
relatively sparse in the dataset. Whereas KTM-ind (e.g., LPKT-ind)
4053KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Xiaoshan Yu et al.
w/o Att w/o RL w/o DG w/o CL RIGL
ASSIST120.73000.73250.73500.73750.7400
NIPS-Edu0.7200.7250.7300.735
SLP-math0.8100.8150.8200.8250.8300.835
SLP-biology0.7900.7920.7940.7960.798AUC ( )
ASSIST120.2000.2050.2100.2150.220
NIPS-Edu0.2300.2350.2400.245
SLP-math0.1300.1350.1400.1450.150
SLP-biology0.1300.1350.1400.1450.150RMSE ( )
ASSIST120.7600.7620.7640.7660.768
NIPS-Edu0.67000.67250.67500.67750.6800
SLP-math0.7700.7750.7800.7850.790
SLP-biology0.7300.7350.7400.7450.750ACC ( )
ASSIST120.15000.15250.15500.15750.1600
NIPS-Edu0.1700.1750.1800.1850.190
SLP-math0.1000.1050.1100.1150.120
SLP-biology0.100.110.120.13MAE ( )
Figure 3: Performance of ablation studies conducted on four datasets, where â€œw/oâ€ means removing the target module.
w/o Ind w/o Grp w/o Dual Ours
AUC ( )
0.7200.7250.7300.7350.740
ACC ( )
0.6700.6720.6740.6760.6780.680Individual-level
RMSE ( )
0.2300.2350.2400.2450.250
MAE ( )
0.1700.1750.1800.1850.190Group-level
Figure 4: Results of reciprocal effect study conducted on NIPS-
Edu dataset, where â€œw/oâ€ means removing the target feature.
as the primitive individual KT model is unable to model group
interactions (focusing on individual level modeling) and thus is less
affected by this sparsity.
5.3 Ablation Study (RQ2)
To answer RQ2, we first conducted a comprehensive ablation study
to investigate the impact of each module in the RIGL model by defin-
ing the following variations: 1) w/o Att: removing the absence-
perceived attention aggregation module in reciprocal enhanced
learning; 2) w/o RL: removing the reciprocal enhanced learning
module; 3) w/o DG: removing the dynamic graph modeling; 4) w/o
CL: removing the contrastive loss. As illustrated in Figure 3, the
results reveal insightful observations: (1) In comparison to RIGL, all
variants suffer relative performance degradation on four datasets
across various evaluation metrics, demonstrating the contribution
of the designed submodules to our proposed model. (2) The most
significant decrease in the model performance occurs after remov-
ing the reciprocal enhanced learning module, which exhibits that
jointly and interactively modeling the reciprocal learning process
of students and groups plays a crucial role in the HKT task, and
also confirms the soundness of our designed model. (3) The per-
formance degradation of removing the dynamic graph modeling
module is also quite noticeable, reflecting the fact that dynamic
graph modeling is important for capturing the evolving knowledge
states of groups and individuals.
In addition, we further conducted an ablation study to investi-
gate the effect brought by reciprocal learning on the performance
of holistic knowledge tracing by disassembling the reciprocal en-
hanced learning module in RIGL. Specifically, we removed the
1e-4 5e-4 1e-3 2e-3 1e-20.78500.78750.79000.79250.79500.79750.8000AUC
AUC
ACC
0.7350.7400.7450.750
ACC
(a) Individual-level1e-4 5e-4 1e-3 2e-3 1e-20.1300.1350.1400.1450.150RMSE
RMSE
MAE
0.1050.1100.1150.120
MAE
(b) Group-levelFigure 5: Sensitivity analysis of learning rate on SLP-Bio.
1e-4 1e-3 1e-2 5e-2 1e-10.7800.7850.7900.7950.800AUC
AUC
ACC
0.7400.7420.7440.746
ACC
(a) Individual-level1e-4 1e-3 1e-2 5e-2 1e-10.1300.1350.1400.1450.150RMSE
RMSE
MAE
0.1000.1050.1100.1150.120
MAE
(b) Group-level
Figure 6: Sensitivity analysis of coefficient ğ›¾on SLP-Bio.
individual-level features, the group-level features, and both features
in the reciprocal enhanced learning module (i.e., w/o Ind, w/o Grp,
andw/o Dual), respectively, and then inspected the performance
variations. Notably, the experiments in this section are completed
by removing the features of individual and group interactions in
the reciprocal module, respectively, within the framework of HKT,
which requires that the ablated RIGL is still capable of tracking both
the evolution of individual and group abilities. The experimental
results are shown in Figure 4. We have the following observations:
(1) The absence of individual-level and group-level features brings
about performance degradation, demonstrating the complementary
facilitation of individualsâ€™ and groupsâ€™ learning features in the HKT
task. (2) The performance degradation introduced when neither in-
dividual modeling nor group modeling utilizes each otherâ€™s features
during the information fusion process is very significant, which is
further evidence of the effectiveness of reciprocal learning.
5.4 Parameter Sensitivity Analysis (RQ3)
To answer RQ3, we conducted a parameter sensitivity analysis in
this section to investigate the effects of hyper-parameters, which
mainly include the learning rate and the weight coefficient ğ›¾of the
contrastive loss. Specifically, we set the list of learning rates to be
{1e-4, 5e-4, 1e-3, 2e-3, 1e-2}, as well as the ğ›¾values {1e-4, 1e-3, 1e-2,
5e-2, 1e-1}, and mainly show the experimental results on the SLP-
Bio dataset. As shown in Figure 5, we observe that 1e-3 is sufficient
for the learning rate, and the performance presents a trend of rising
4054RIGL: A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Figure 7: The evolution process of the individual-level and group-level knowledge proficiency on four concepts during the
holistic knowledge tracing traced by RIGL. The four knowledge concepts are depicted in different colors and the top line
represents the exercises answered by the learner and the group in each time frame (different colors denote corresponding to
different concepts). In addition, solid and hollow circles indicate correct and incorrect learner responses, respectively, as well
as circles with different spots denote different ranges of response values for the group.
0.690.690.740.74os1
s2
s30.710.710.770.77
0.750.750.840.84os1
s2
s3os1
s2
s3os1
s2
s3os1
s2
s3
t1 t2 t3 t4 t50.660.66 0.750.75 0.730.73 0.780.78 0.830.83
0.610.61 0.680.68 0.690.69 0.720.72 0.750.75
0.690.69 0.710.71 0.760.76 0.840.84 0.810.81
Figure 8: Case study of the dynamic relationship mining.
Different colored lines represent different relationships, and
dashed lines indicate connections below the threshold. The
learned edge weights denote the similarity, i.e., higher values
denote greater similarity between the two.
first and then falling with the increase of the rate. As shown in
Figure 6, the model reaches its best performance when the value of
ğ›¾is 1e-2 and the effect on the AUC metric is not very strong. An
interesting phenomenon here is that the trend of this coefficientâ€™s
impact on the performance of the individual-level and the group-
level is different as the ğ›¾value increments, which is perhaps due to
the different modeling effects of the fraction of contrastive loss on
group learning and individual learning behaviors.
5.5 Case Study (RQ4)
5.5.1 Visualization of Proficiency Evolution. To further un-
derstand how RIGL traces the evolution of the individual-level
and group-level knowledge states, in this case study, we demon-
strated the tracing process. Figure 7 illustrates the evolution of
both a learnerâ€™s and a groupâ€™s knowledge proficiency across five
time frames on four knowledge concepts, as traced by RIGL. From
the visualization, we can observe that the individualâ€™s mastery of
the corresponding concept of the exercise increases even if it is
answered incorrectly, which implies that wrongly responding to the
exercise also brings knowledge gain. In addition, it can be seen that
the knowledge gained from individual learning affects the groupâ€™s
knowledge level, yet the degree of impact varies under different
time frames, meaning that the effect of the individual on the group
varies over time, which is in line with the real scenario.
5.5.2 Dynamic Relationship Mining. Specifically, a case study
of relationship observations was conducted to explore the dynamic
relationships between individuals and the group, as well as among
individuals in the holistic knowledge tracing process. Figure 8shows the dynamic relationship graph across the group under five
time frames by presenting the correlation distances (as mentioned
in Section 4.2; for convenience of the display, three students under
one group were selected). It can be observed that the relationships
between students and groups and among students are dynamically
changing (e.g., the increasing similarity of both ğ‘ 1andğ‘œas well as
ğ‘ 1andğ‘ 3), justifying the exploitation and modeling of potential as-
sociations through our use of the dynamic graph. In addition, based
on the mined latent relationships, potential subgroups within the
group can be effectively identified, which will help us to perceive
the evolution of the internal structure of the group.
6 Conclusion
In this paper, we introduced a novel framework termed as RIGL (a
unified Reciprocal approach for Independent and Group Learning
processes), which aims to provide comprehensive and dynamic
modeling for both independent learning and group learning. Our
approach comprises several key components. Initially, we devised
a time frame-aware reciprocal embedding module to concurrently
capture the temporal interactions between students and groups dur-
ing the learning processes, followed by a reciprocal-enhanced learn-
ing mechanism that maximizes the synergistic insights from these
two learning behaviors. To further mine the intricate dynamics of
student-group associations, we proposed a relation-guided tempo-
ral attentive network encompassing dynamic graph modeling and
temporal self-attention mechanisms. Notably, the relation-guided
dynamic graph is formed by uncovering potential links between stu-
dents and groups. Finally, we incorporated a bias-aware contrastive
learning module to ensure model stability during training. Exten-
sive experiments were conducted on four real-world educational
datasets to substantiate the efficacy of our RIGL model, particularly
in addressing the HKT task. We hope this work could lead to further
studies on holistic knowledge tracing.
Acknowledgments
This work was supported in part by the National Natural Science
Foundation of China under Grant (No. U21A20512, No. 62107001,
and No.62302010), and in part by by China Postdoctoral Science
Foundation (No. 2023M740015).
4055KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Xiaoshan Yu et al.
References
[1]Lijia Chen, Pingping Chen, and Zhijian Lin. 2020. Artificial intelligence in
education: A review. Ieee Access 8 (2020), 75264â€“75278.
[2]Liyi Chen, Chuan Qin, Ying Sun, Xin Song, Tong Xu, Hengshu Zhu, and Hui
Xiong. 2024. Collaboration-Aware Hybrid Learning for Knowledge Development
Prediction. In Proceedings of the ACM on Web Conference 2024. 3976â€“3985.
[3]Albert T Corbett and John R Anderson. 1994. Knowledge tracing: Modeling the
acquisition of procedural knowledge. User modeling and user-adapted interaction
4 (1994), 253â€“278.
[4]Chuyu Fang, Chuan Qin, Qi Zhang, Kaichun Yao, Jingshuai Zhang, Hengshu Zhu,
Fuzhen Zhuang, and Hui Xiong. 2023. Recruitpro: A pretrained language model
with skill-aware prompt learning for intelligent recruitment. In Proceedings of
the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
3991â€“4002.
[5]Mingyu Feng, Neil Heffernan, and Kenneth Koedinger. 2009. Addressing the
assessment challenge with an online system that tutors as it assesses. User
modeling and user-adapted interaction 19, 3 (2009), 243â€“266.
[6]Tara Fenwick. 2008. Understanding relations of individualâ€”collective learning
in work: A review of research. Management learning 39, 3 (2008), 227â€“243.
[7]Aritra Ghosh, Neil Heffernan, and Andrew S Lan. 2020. Context-aware atten-
tive knowledge tracing. In Proceedings of the 26th ACM SIGKDD international
conference on knowledge discovery & data mining. 2330â€“2339.
[8]John Hayes and Christopher W Allinson. 1998. Cognitive style and the theory and
practice of individual and collective learning in organizations. Human relations
51, 7 (1998), 847â€“871.
[9]Feihu Jiang, Chuan Qin, Kaichun Yao, Chuyu Fang, Fuzhen Zhuang, Hengshu Zhu,
and Hui Xiong. 2024. Enhancing Question Answering for Enterprise Knowledge
Bases using Large Language Models. arXiv preprint arXiv:2404.08695 (2024).
[10] Feihu Jiang, Chuan Qin, Jingshuai Zhang, Kaichun Yao, Xi Chen, Dazhong Shen,
Chen Zhu, Hengshu Zhu, and Hui Xiong. 2024. Towards Efficient Resume
Understanding: A Multi-Granularity Multi-Modal Pre-Training Approach. arXiv
preprint arXiv:2404.13067 (2024).
[11] Seyed Mehran Kazemi, Rishab Goel, Kshitij Jain, Ivan Kobyzev, Akshay Sethi,
Peter Forsyth, and Pascal Poupart. 2020. Representation learning for dynamic
graphs: A survey. The Journal of Machine Learning Research 21, 1 (2020), 2648â€“
2720.
[12] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph
convolutional networks. arXiv preprint arXiv:1609.02907 (2016).
[13] Wonsung Lee, Jaeyoon Chun, Youngmin Lee, Kyoungsoo Park, and Sungrae Park.
2022. Contrastive learning for knowledge tracing. In Proceedings of the ACM Web
Conference 2022. 2330â€“2338.
[14] Hao Lin, Hengshu Zhu, Yuan Zuo, Chen Zhu, Junjie Wu, and Hui Xiong. 2017.
Collaborative company profiling: Insights from an employeeâ€™s perspective. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 31.
[15] Sannyuya Liu, Shengyingjie Liu, Zongkai Yang, Jianwen Sun, Xiaoxuan Shen,
Qing Li, Rui Zou, and Shangheng Du. 2023. Heterogeneous Evolution Network
Embedding with Temporal Extension for Intelligent Tutoring Systems. ACM
Transactions on Information Systems 42, 2 (2023), 1â€“28.
[16] Shuhuan Liu, Xiaoshan Yu, Haiping Ma, Ziwen Wang, Chuan Qin, and Xingyi
Zhang. 2023. Homogeneous Cohort-Aware Group Cognitive Diagnosis: A Multi-
grained Modeling Perspective. In Proceedings of the 32nd ACM International
Conference on Information and Knowledge Management. 4094â€“4098.
[17] Zitao Liu, Qiongqiong Liu, Jiahao Chen, Shuyan Huang, Boyu Gao, Weiqi Luo,
and Jian Weng. 2023. Enhancing deep knowledge tracing with auxiliary tasks. In
Proceedings of the ACM Web Conference 2023. 4178â€“4187.
[18] Zitao Liu, Qiongqiong Liu, Jiahao Chen, Shuyan Huang, and Weiqi Luo. 2022.
simpleKT: A Simple But Tough-to-Beat Baseline for Knowledge Tracing. In The
Eleventh International Conference on Learning Representations.
[19] Yu Lu, Yang Pian, Ziding SHEN, Penghe CHEN, and Xiaoqing Li. 2021. SLP: A
Multi-Dimensional and Consecutive Dataset from K-12 Education. In Proceedings
of the 29th International Conference on Computers in Education. 261â€“266.
[20] Haiping Ma, Siyu Song, Chuan Qin, Xiaoshan Yu, Limiao Zhang, Xingyi Zhang,
and Hengshu Zhu. 2024. DGCD: An Adaptive Denoising GNN for Group-level
Cognitive Diagnosis. In IJCAI.
[21] Haiping Ma, Jingyuan Wang, Hengshu Zhu, Xin Xia, Haifeng Zhang, Xingyi
Zhang, and Lei Zhang. 2022. Reconciling Cognitive Modeling with Knowledge
Forgetting: A Continuous Time-aware Neural Network Approach.. In IJCAI.
2174â€“2181.
[22] Haiping Ma, Yong Yang, Chuan Qin, Xiaoshan Yu, Shangshang Yang, Xingyi
Zhang, and Hengshu Zhu. 2024. HD-KT: Advancing Robust Knowledge Tracing
via Anomalous Learning Interaction Detection. In Proceedings of the ACM on Web
Conference 2024. 4479â€“4488.
[23] Haiping Ma, Jinwei Zhu, Shangshang Yang, Qi Liu, Haifeng Zhang, Xingyi Zhang,
Yunbo Cao, and Xuemin Zhao. 2022. A prerequisite attention model for knowl-
edge proficiency diagnosis of students. In Proceedings of the 31st ACM International
Conference on Information & Knowledge Management. 4304â€“4308.[24] Bill Meyer, Naomi Haywood, Darshan Sachdev, and Sally Faraday. 2008. What
is independent learning and what are the benefits for students. Department for
Children, Schools and Families Research Report 51 (2008), 1â€“6.
[25] Shalini Pandey and George Karypis. 2019. A self-attentive model for knowledge
tracing. In 12th International Conference on Educational Data Mining, EDM 2019.
International Educational Data Mining Society, 384â€“389.
[26] Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura,
Hiroki Kanezashi, Tim Kaler, Tao Schardl, and Charles Leiserson. 2020. Evolvegcn:
Evolving graph convolutional networks for dynamic graphs. In Proceedings of
the AAAI conference on artificial intelligence, Vol. 34. 5363â€“5370.
[27] Philip I Pavlik Jr, Hao Cen, and Kenneth R Koedinger. 2009. Performance Factors
Analysisâ€“A New Alternative to Knowledge Tracing. Online Submission (2009).
[28] Radek PelÃ¡nek. 2017. Bayesian knowledge tracing, logistic models, and beyond:
an overview of learner modeling techniques. User Modeling and User-Adapted
Interaction 27 (2017), 313â€“350.
[29] Chris Piech, Jonathan Bassen, Jonathan Huang, Surya Ganguli, Mehran Sahami,
Leonidas J Guibas, and Jascha Sohl-Dickstein. 2015. Deep knowledge tracing.
Advances in neural information processing systems 28 (2015).
[30] Chuan Qin, Le Zhang, Yihang Cheng, Rui Zha, Dazhong Shen, Qi Zhang, Xi
Chen, Ying Sun, Chen Zhu, Hengshu Zhu, and Hui Xiong. 2023. A comprehensive
survey of artificial intelligence techniques for talent analytics. arXiv preprint
arXiv:2307.03195 (2023).
[31] Chuan Qin, Hengshu Zhu, Dazhong Shen, Ying Sun, Kaichun Yao, Peng Wang,
and Hui Xiong. 2023. Automatic skill-oriented question generation and rec-
ommendation for intelligent job interviews. ACM Transactions on Information
Systems 42, 1 (2023), 1â€“32.
[32] Chuan Qin, Hengshu Zhu, Chen Zhu, Tong Xu, Fuzhen Zhuang, Chao Ma, Jing-
shuai Zhang, and Hui Xiong. 2019. DuerQuiz: A personalized question rec-
ommender system for intelligent job interview. In Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discovery & Data Mining. 2165â€“
2173.
[33] Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico
Monti, and Michael Bronstein. 2020. Temporal graph networks for deep learning
on dynamic graphs. arXiv preprint arXiv:2006.10637 (2020).
[34] Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. 2020.
Dysat: Deep neural representation learning on dynamic graphs via self-attention
networks. In Proceedings of the 13th international conference on web search and
data mining. 519â€“527.
[35] Shuanghong Shen, Enhong Chen, Bihan Xu, Qi Liu, Zhenya Huang, Linbo Zhu,
and Yu Su. 2023. Quiz-based Knowledge Tracing. arXiv preprint arXiv:2304.02413
(2023).
[36] Shuanghong Shen, Qi Liu, Enhong Chen, Zhenya Huang, Wei Huang, Yu Yin, Yu
Su, and Shijin Wang. 2021. Learning process-consistent knowledge tracing. In
Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data
mining. 1452â€“1460.
[37] Ying Sun, Fuzhen Zhuang, Hengshu Zhu, Qi Zhang, Qing He, and Hui Xiong.
2021. Market-oriented job skill valuation with cooperative composition neural
network. Nature communications 12, 1 (2021), 1992.
[38] Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, and Hongyuan Zha. 2019.
Dyrep: Learning representations over dynamic graphs. In International conference
on learning representations.
[39] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[40] Zichao Wang, Angus Lamb, Evgeny Saveliev, Pashmina Cameron, Yordan Za-
ykov, JosÃ© Miguel HernÃ¡ndez-Lobato, Richard E Turner, Richard G Baraniuk,
Craig Barton, Simon Peyton Jones, et al .2020. Instructions and Guide for Di-
agnostic Questions: The NeurIPS 2020 Education Challenge. arXiv preprint
arXiv:2007.12061 (2020).
[41] Jeanne M Wilson, Paul S Goodman, and Matthew A Cronin. 2007. Group learning.
Academy of management review 32, 4 (2007), 1041â€“1059.
[42] Shangshang Yang, Haiping Ma, Cheng Zhen, Ye Tian, Limiao Zhang, Yaochu Jin,
and Xingyi Zhang. 2023. Designing novel cognitive diagnosis models via evolu-
tionary multi-objective neural architecture search. arXiv preprint arXiv:2307.04429
(2023).
[43] Shangshang Yang, Linrui Qin, and Xiaoshan Yu. 2024. Endowing Interpretability
for Neural Cognitive Diagnosis by Efficient Kolmogorov-Arnold Networks. arXiv
preprint arXiv:2405.14399 (2024).
[44] Shangshang Yang, Haoyu Wei, Haiping Ma, Ye Tian, Xingyi Zhang, Yunbo Cao,
and Yaochu Jin. 2023. Cognitive diagnosis-based personalized exercise group
assembly via a multi-objective evolutionary algorithm. IEEE Transactions on
Emerging Topics in Computational Intelligence (2023).
[45] Shangshang Yang, Xiaoshan Yu, Ye Tian, Xueming Yan, Haiping Ma, and Xingyi
Zhang. 2023. Evolutionary Neural Architecture Search for Transformer in Knowl-
edge Tracing. In Thirty-seventh Conference on Neural Information Processing
Systems.
4056RIGL: A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
[46] Shangshang Yang, Cheng Zhen, Ye Tian, Haiping Ma, Yuanchao Liu, Panpan
Zhang, and Xingyi Zhang. 2023. Evolutionary Multi-Objective Neural Architec-
ture Search for Generalized Cognitive Diagnosis Models. In 2023 5th International
Conference on Data-driven Optimization of Complex Systems (DOCS). IEEE, 1â€“10.
[47] Yang Yang, Jian Shen, Yanru Qu, Yunfei Liu, Kerong Wang, Yaoming Zhu, Weinan
Zhang, and Yong Yu. 2021. GIKT: a graph-based interaction model for knowledge
tracing. In Machine Learning and Knowledge Discovery in Databases: European
Conference, ECML PKDD 2020, Ghent, Belgium, September 14â€“18, 2020, Proceedings,
Part I. Springer, 299â€“315.
[48] Kaichun Yao, Jingshuai Zhang, Chuan Qin, Xin Song, Peng Wang, Hengshu Zhu,
and Hui Xiong. 2023. Resuformer: Semantic structure understanding for resumes
via multi-modal pre-training. In 2023 IEEE 39th International Conference on Data
Engineering (ICDE). IEEE, 3154â€“3167.
[49] Yu Yin, Le Dai, Zhenya Huang, Shuanghong Shen, Fei Wang, Qi Liu, Enhong
Chen, and Xin Li. 2023. Tracing Knowledge Instead of Patterns: Stable Knowledge
Tracing with Diagnostic Transformer. In Proceedings of the ACM Web Conference
2023. 855â€“864.
[50] Xiaoshan Yu, Chuan Qin, Dazhong Shen, Haiping Ma, Le Zhang, Xingyi Zhang,
Hengshu Zhu, and Hui Xiong. 2024. RDGT: Enhancing Group Cognitive Diag-
nosis with Relation-Guided Dual-Side Graph Transformer. IEEE Transactions on
Knowledge and Data Engineering (2024).
[51] Rui Zha, Chuan Qin, Le Zhang, Dazhong Shen, Tong Xu, Hengshu Zhu, and
Enhong Chen. 2023. Career mobility analysis with uncertainty-aware graph au-
toencoders: A job title transition perspective. IEEE Transactions on Computational
Social Systems (2023).
[52] Jiani Zhang, Xingjian Shi, Irwin King, and Dit-Yan Yeung. 2017. Dynamic key-
value memory networks for knowledge tracing. In Proceedings of the 26th inter-
national conference on World Wide Web. 765â€“774.
[53] Yunfei Zhang, Chuan Qin, Dazhong Shen, Haiping Ma, Le Zhang, Xingyi Zhang,
and Hengshu Zhu. 2023. ReliCD: A Reliable Cognitive Diagnosis Framework with
Confidence Awareness. In 2023 IEEE International Conference on Data Mining
(ICDM). IEEE, 858â€“867.
[54] Zhi Zheng, Xiao Hu, Zhaopeng Qiu, Yuan Cheng, Shanshan Gao, Yang Song,
Hengshu Zhu, and Hui Xiong. 2024. Bilateral Multi-Behavior Modeling for Recip-
rocal Recommendation in Online Recruitment. IEEE Transactions on Knowledge
and Data Engineering (2024).
[55] Linhong Zhu, Dong Guo, Junming Yin, Greg Ver Steeg, and Aram Galstyan. 2016.
Scalable temporal latent space inference for link prediction in dynamic social
networks. IEEE Transactions on Knowledge and Data Engineering 28, 10 (2016),
2765â€“2777.
A APPENDICES
A.1 Notations
To ensure clarity and comprehension for readers, the import nota-
tions used in this paper are meticulously presented in Table S1.
A.2 Dataset Description and Preparation
A.2.1 Data Description. In the experiments, we use four real-
world education datasets to valid the effectiveness of our RIGL on
the holistic tracing task, and the details are described as follows:
â€¢ASSIST12 [5]: ASSIST12 is a dataset collected from the ASSIST-
ments online educational tutoring system and contains exten-
sive student exercise-solving data for the school year 2012-2013,
which has been widely utilized in knowledge tracing tasks.
â€¢NIPS-Edu [40]: NIPS-Edu dataset was collected from the NeurIPS
2020 Education Challenge and contains records of studentsâ€™ re-
sponses to math exercises which include timestamp information.
â€¢SLP-Math [19]: SLP is a public benchmark collected from an
online learning platform called Smart Learning Partner (SLP),
which intentionally records the learning data of secondary school
students about multiple subjects to provide wealthy contents.
SLP-Math is a sub-dataset of SLP on the subject of math.
â€¢SLP-Bio [19]: Similar to SLP-Math, SLP-Bio is also a sub-dataset
of SLP, which corresponds to the exercise-solving records of the
secondary school students in the subject of biology.Table S1: Summary of the primary notations.
Symbols Description
O,S,E,C,Q The set of groups, students, exercises,
knowledge concepts, and the Q-matrix, re-
spectively.
ğ‘œ,ğ‘ ,ğ‘’,ğ‘ The group, the student, the exercise, and
the knowledge concept.
Rğ‘†,Rğ‘‚The whole interaction sequence of the stu-
dent and the group, respectively.
Fğ‘¡,Hğ‘¡ The student-exercise and group-exercise
interaction sequence under ğ‘¡-th time
frame.
ğ‘Ÿğ‘¡
ğ‘–,ğ‘¦ğ‘¡
ğ‘–The score that the student got on the ğ‘–-th
log underğ‘¡-th time frame and the correct
rate that group got on the ğ‘–-th log under
ğ‘¡-th time frame.
xğ‘¡,zğ‘¡The set of exercise encoding and response
encoding, respectively.
Ë†xğ‘¡,Ë†zğ‘¡The set of interaction encodings of groups.
exğ‘œ
ğ‘¡,ezğ‘œ
ğ‘¡,exğ‘ 
ğ‘¡,ezğ‘ 
ğ‘¡ The enhanced interaction encoding of
group and student.
Gğ‘œ
ğ‘¡=(ğ‘‰,ğ¸ğ‘¡) The group-individual graph with a node
setğ‘‰and a edge set ğ¸ğ‘¡.
V={ğ‘œ,ğ‘ 1,...,ğ‘ |ğ‘œ|}The node set.
ğ¸ğ‘¡=(ğ¸ğ‘œâ†”ğ‘ ,ğ¸ğ‘¡ğ‘ â†”ğ‘ ) The edge set including the connecting
edges between students and groups.
Vğ‘¡,Dğ‘¡,Ağ‘¡The node feature matrix, the relation ma-
trix and the adjacency matrix in the ğ‘¡-th
time frame, respectively.
Qğ‘œ,Kğ‘œ,Vğ‘œ
Qğ‘ ,Kğ‘ ,Vğ‘  The query matrix, the key matrix, and the
value matrix of the self-attention module.
m,n The interaction feature of the group and
student extracted from the learned graph
layer.
hğ‘œ
ğ‘¡,hğ‘ 
ğ‘¡ The knowledge states of group ğ‘œand stu-
dentğ‘ underğ‘¡-the time frame, respec-
tively.
W,b The trainable matrix and parameters.
|Â·| The cardinality of a set.
ğœ,ğ›¾ The temperature parameter and the coef-
ficient weight parameter.
ğ¼,ğ‘,ğ‘€,ğ¾ The size of the group set O, the student
setS, the exercise setE, and the concept
setC, respectively.
ğ‘‘ğ‘’,ğ‘‘ğ‘,ğ‘‘ğ‘Ÿ,ğ‘‘ğ‘™,ğ‘‘ The dimension of exercise, the dimension
of concept, the dimension of response, the
dimension of ğ‘™-th graph layer, and the hid-
den dimension, respectively.
Lğ‘œ,Lğ‘”ğ‘Ÿğ‘
ğ‘œ,Lğ‘ ğ‘¡ğ‘¢ğ‘œ,Lğ¶ğ¿ğ‘œ The total loss, the group loss, the student
loss, and the contrastive loss, respectively.
A.2.2 Data Preprocessing. All datasets above contain group
labels (i.e., the class to which the students belong), and students
from the same group share the same group category. In particular, to
ensure the feasibility, we conducted preprocessing on the datasets.
Specifically, for each dataset, we first constructed two exercising
4057KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Xiaoshan Yu et al.
Table S2: Performance of RIGL and baselines (only using individual data) on all datasets on predicting individual-level
performance.â†‘(â†“) means the higher (lower) score the better performance. â€œ âˆ—â€ denotes the statistically significant improvement
of RIGL model compared to the best baseline method (i.e., two-sided t-test with p<0.05). Bold: the best, Underline : the runner-up.
Datasets ASSIST12 NIPS-Edu SLP-Math SLP-Bio
Metrics AUC
(â†‘) ACC (â†‘) AUC
(â†‘) ACC (â†‘) AUC
(â†‘) ACC (â†‘) AUC
(â†‘) ACC (â†‘)
DKT
-Ind 0.7191Â±0.0030 0.7440Â±0.0051 0.6448Â±0.0060 0.6228Â±0.0096 0.7975Â±0.0052 0.7689Â±0.0092 0.7141Â±0.0032 0.6678Â±0.0159
SAKT
-Ind 0.6996Â±0.0046 0.7489Â±0.0048 0.6526Â±0.0060 0.6304Â±0.0109 0.8060Â±0.0037 0.7763Â±0.0090 0.7373Â±0.0020 0.7157Â±0.0082
AKT
-Ind 0.6362Â±0.0047 0.7483Â±0.0054 0.6211Â±0.0046 0.6112Â±0.0059 0.7702Â±0.0094 0.7485Â±0.0173 0.6727Â±0.0191 0.6658Â±0.0115
LPKT
-Ind 0.7344Â±0.0039 0.7579Â±0.0067 0.6541Â±0.0061 0.6296Â±0.0138 0.7762Â±0.0086 0.7387Â±0.0179 0.7375Â±0.0018 0.7149Â±0.0083
simpleKT
-Ind 0.6696Â±0.0073 0.7481Â±0.0074 0.6425Â±0.0032 0.6287Â±0.0076 0.7816Â±0.0047 0.7566Â±0.0169 0.6961Â±0.0162 0.7099Â±0.0127
RIGL 0.7394âˆ—
Â±0 .01410.7673âˆ—Â±0 .0126 0.7326âˆ—Â±0 .01150.6779âˆ—Â±0 .0144 0.8304âˆ—Â±0 .00490.7853âˆ—Â±0 .0102 0.7959âˆ—Â±0 .00800.7442âˆ—Â±0 .0085
sequences of the individual and the group based on time period
divisions, where each time frame contains two types of interaction
data, i.e., student-exercise responses and group-exercise responses.
Particularly, for each group-exercise response under each time
frame, we calculated the correct rate of this group of students on
the exercise as the groupâ€™s response result. We screened out groups
with fewer than three students and students with less than three
response logs. Due to the different temporal characteristics of the
different datasets, each dataset is not divided over exactly the same
time span, where ASSIST12 and NIPS-Edu are divided in days, and
SLP-Math and SLP-Bio are divided in hours. Finally, since the group-
exercise interactions are very sparse under each time frame in the
raw data, i.e., the number of exercises answered by all students
within the same group is extremely limited, we set a threshold of
0.6 to prevent the group learning sequence from being empty.
A.3 Introduction and Implementation of
Baselines
A.3.1 Baselines. In this paper, we compare RIGL with eight base-
line approaches. The details of all the comparison methods are:
â€¢DKT [29]: DKT is one of the most classical knowledge tracing
methods, which utilizes a recurrent neural network (RNN) to
model the exercise interaction sequences and mine the cognitive
pattern between learners and exercises.
â€¢SAKT [25]: SAKT is the first knowledge tracing model intro-
ducing the self-attention mechanism [ 39], which exploits the
transformer structure to model long-range dependencies of in-
teraction behaviors in studentsâ€™ exercising sequences.
â€¢AKT [7]: AKT designs a novel monotonic attention module on
the basis of transformer architecture for effectively modeling the
forgetting behaviors of learners, which leverages an exponential
decay function that can perceive contextual distance information
to learn the attention weights.
â€¢LPKT [36]: LPKT proposes a learning process-consistent model
to explore the consistency of studentsâ€™ changing knowledge state
during the learning process, which consists of a learning module,
a forgetting module, and a predicting module.
â€¢GIKT [47]: GIKT is a graph-based Interaction model for Knowl-
edge Tracing that leverages a graph convolutional network (GCN)
to effectively integrate question-skill correlations and addresses
the challenge of dispersed relevant questions by consideringquestions and skills as different manifestations of knowledge in
predicting studentsâ€™ mastery levels.
â€¢simpleKT [18]: simpleKT is a simple but strong baseline method,
which explicitly models the question-specific variations to cap-
ture the individual differences and uses the ordinary dot-product
attention function to mine the time-aware behavior information.
â€¢AT-DKT [17]: AT-DKT is an novel knowledge tracing model
that enhances the original deep knowledge tracing model by
incorporating two auxiliary learning tasks.
â€¢DTransformer [49]: DTransformer introduces a Diagnostic
Transformer with a novel contrastive learning-based training
approach, designed to accurately diagnose and trace learnersâ€™
knowledge proficiency.
A.3.2 Implementation. To adapt these baselines that only focus
on individual-level knowledge tracing to the HKT task, we describe
the implementation details. Specifically, for the inputs including in-
dependent learning sequence RSand the group learning sequence
RO, the baseline first encodes their interaction behavior, respec-
tively, i.e.,(ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘Ÿğ‘¡
ğ‘–)and(ğ‘’ğ‘¡
ğ‘–,ğ‘ğ‘¡
ğ‘–,ğ‘¦ğ‘¡
ğ‘–)under each time frame Fğ‘¡and
Hğ‘¡. Subsequently, the baseline performs an average aggregation of
the interaction encodings under each time frame in each of the two
learning sequences. Furthermore, the obtained encoding sequences
are fed into the knowledge tracing module underlying the baseline
for modeling the changing knowledge states of the individual and
group. Finally, a joint loss function, comprising a cross-entropy loss
for predicting studentsâ€™ performance and a mean square error loss
for predicting the groupâ€™s performance, is used to train the model.
A.4 Complete Comparison Results of
Individual-based Baselines
As described in the Section 5.2, we also conducted experiments for
baselinesâ€™ individual version (i.e., traditional knowledge tracing
model) utilizing only individual interaction data. The complete
comparison results can are shown in Table S2. It can be observed
that in comparison to baseline models, the proposed RIGL remains
significantly superior. Specifically, it shows an average increase
of 5.91% and 3.48% over the best individual knowledge tracing
baseline in terms of AUC and ACC metrics, respectively, which
demonstrates the contribution of group learning behaviors to the
modeling of independent learning, and the effectiveness of the
proposed reciprocal learning modeling in our RIGL model.
4058