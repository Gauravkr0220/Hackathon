FUGNN: Harmonizing Fairness and Utility in Graph Neural
Networks
Renqiang Luo
Dalian University of Technology
Dalian, Liaoning, China
lrenqiang@outlook.comHuafei Huang
Dalian University of Technology
Dalian, Liaoning, China
hhuafei@outlook.comShuo Yu*
Dalian University of Technology
Dalian, Liaoning, China
shuo.yu@ieee.org
Zhuoyang Han
Dalian University of Technology
Dalian, Liaoning, China
42217022@mail.dlut.edu.cnEstrid He
RMIT University
Melbourne, Victoria, Australia
estrid.he@rmit.edu.auXiuzhen Zhang
RMIT University
Melbourne, Victoria, Australia
xiuzhen.zhang@rmit.edu.au
Feng Xia
RMIT University
Melbourne, Victoria, Australia
f.xia@ieee.org
Abstract
Fairness-aware Graph Neural Networks (GNNs) often face a chal-
lenging trade-off, where prioritizing fairness may require compro-
mising utility. In this work, we re-examine fairness through the
lens of spectral graph theory, aiming to reconcile fairness and util-
ity within the framework of spectral graph learning. We explore
the correlation between sensitive features and spectrum in GNNs,
using theoretical analysis to delineate the similarity between origi-
nal sensitive features and those after convolution under different
spectra. Our analysis reveals a reduction in the impact of similar-
ity when the eigenvectors associated with the largest magnitude
eigenvalue exhibit directional similarity. Based on these theoreti-
cal insights, we propose FUGNN, a novel spectral graph learning
approach that harmonizes the conflict between fairness and utility.
FUGNN ensures algorithmic fairness and utility by truncating the
spectrum and optimizing eigenvector distribution during the en-
coding process. The fairness-aware eigenvector selection reduces
the impact of convolution on sensitive features while concurrently
minimizing the sacrifice of utility. FUGNN further optimizes the
distribution of eigenvectors through a transformer architecture.
By incorporating the optimized spectrum into the graph convo-
lution network, FUGNN effectively learns node representations.
Experiments on six real-world datasets demonstrate the superior-
ity of FUGNN over baseline methods. The codes are available at
https://github.com/yushuowiki/FUGNN.
* Corresponding Author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671834CCS Concepts
â€¢Information systems â†’Data mining; â€¢Computing method-
ologiesâ†’Machine learning.
Keywords
algorithmic fairness, graph neural networks, utility, graph learning
ACM Reference Format:
Renqiang Luo, Huafei Huang, Shuo Yu*, Zhuoyang Han, Estrid He, Xiuzhen
Zhang, and Feng Xia. 2024. FUGNN: Harmonizing Fairness and Utility in
Graph Neural Networks. In Proceedings of the 30th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining (KDD â€™24), August 25â€“29, 2024,
Barcelona, Spain. ACM, New York, NY, USA, 10 pages. https://doi.org/10.
1145/3637528.3671834
1 Introduction
With the prevalence of graph-structured data in real-world appli-
cations, graph neural networks (GNNs) have shown promising
performance in high-stake domains [ 43,47], such as loan approval
[12], disaster response [ 48], criminal justice [ 19], and medical di-
agnoses [ 3]. In these applications, certain features (e.g., gender,
race, age, and region) are legally protected to prevent abuse and are
regarded as sensitive features [ 21]. However, GNNs may produce
biased predictions that discriminate against particular subgroups
characterized by these sensitive features [ 38]. For example, GNNs
may cause racial discrimination in underdiagnoses [ 11] or gender
discrimination in low-interest loans [ 29]. Hence, mitigating discrim-
ination induced by GNNs to achieve fairness remains as a critical
challenge in this domain.
Various efforts have been devoted to developing fairness-aware
GNNs, aiming to control the degree to which a model depends on
sensitive features, measured by independence criteria such as sta-
tistical parity and equality opportunity [ 40]. Different controlling
techniques have been proposed [ 30], including weighting pertur-
bation [ 27], embedding adjustment [ 31], pre-processing dataset
[1], and loss function regularization [ 15]. These methods aim to
promote the fairness but often come with a trade-off in utility, gen-
erally measured by predicting accuracy [ 16]. Figure 1 compares the
 
2072
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Renqiang Luo et al.
vanilla graph convolution network, a widely adopted graph neu-
ral architecture, and five fairness-aware GNNs in terms of utility
(accuracy) and fairness (independence on sensitive features, i.e.,
-Î”SP) on a real-world dataset (i.e., Pokec-z). Although these fairness-
aware GNNs reduce the dependence on sensitive features, utility is
generally compromised.
GCN Graphair NIFTY FairGNN BIND EDITS /s8722/s56 /s8722/s54 /s8722/s52 /s8722/s50 62 64 66  Accuracy  /s32 /s45/s8710 SP  
Figure 1: The sacrificed utility of fairness-aware GNNs. The
utility is measured by the prediction accuracy and the fair-
ness is measured by the - Î”SP.
In this paper, we study fairness in GNNs from a new perspective,
i.e., spectral theory, inspired by recent work on the expressive spec-
tral filters and spectrum analysis of the underlying graph matrix
(e.g., adjacency or Laplacian matrix and their normalized forms)
[5]. We ask the question: is it possible to harmonize the conflict be-
tween utility and fairness through graph spectral analysis? The key
to a fairness-aware spectral filter lies in revealing the relationship
between the fairness of a model and the graph spectrum. Therefore,
our first step is to perform theoretical analysis to quantify the extent
of a modelâ€™s protection over sensitive features, via comparing the
similarity between the original representations of sensitive features
at the input layer and their deep representations after convolution
using spectral theory.
Our theoretical analysis reveal two findings: (1) The similarity
between original sensitive features and their deep representations
after convolution is best captured by the eigenvector corresponding
to the largest eigenvalue. This motivates us to select principal eigen-
values as the spectrum for convolution, through which fairness in
prediction results can be maintained. This also ensures that model
utility can be preserved since spectral graph theory indicates that
the largest non-zero eigenvalues are linked to the geometry of the
graph (including algebraic connectivity and spectral radius) [ 35]; (2)
the impact of non-principal eigenvectors on the fairness of a model
diminishes exponentially with an increase in the number of convo-
lutional layers. This motivates us to remove these components to
guide the model to focus on those principal eigenvectors.
Based on the theoretical analysis, we present a novel approach,
FUGNN (harmonizing Fairness and Utility GNN), which promotes
fairness in graph learning at minimal cost to utility via spectrum
modification. Our spectrum modification strategy is designed based
on our two findings above, that is, harmonizing utility and fairness
through selecting the spectral component that has the highest im-
pact on utility and fairness. Specifically, FUGNN first computes ğ¾
largest magnitude eigenvalues along with corresponding eigenvec-
tors from the adjacency matrix. This subset of eigenvalues expresses
convolution corresponding to sensitive features while mitigating
the influence of non-principle eigenvectors. Then, FUGNN employsa transformer architecture to optimize the distribution of eigen-
vectors, ensuring the independence of sensitive features during
convolution. Finally, our method incorporates the optimized spec-
trum in graph convolution, and obtains fair node representations.
In summary, our contributions are outlined below:
â€¢A synergistic approach to fairness and utility. We present
FUGNN, a spectral graph learning method that harmonizes
the conflict between fairness and utility in fairness-aware
GNNs. FUGNN strategically mitigates the convolution im-
pact on sensitive features while achieving high utility.
â€¢Theoretical insights into sensitive feature expression.
We study the model fairness preservation from a spectral per-
spective through rigorous theoretical analysis. Our findings
provide insights about the correlation between the graph
spectrum and the deep representations of sensitive features
within a graph model, forming the foundation of the pro-
posed FUGNN.
â€¢A novel eigenvalue selection mechanism for preserv-
ing model fairness. Building on our theoretical findings,
we introduce an innovative eigenvalue selection mechanism
that can truncate the spectrum to ensure fairness without
compromising utility, providing a nuanced approach to miti-
gating fairness challenges within GNNs.
â€¢Empirical validation through extensive evaluations. To
verify the effectiveness of the proposed FUGNN approach,
we conduct comprehensive empirical evaluations on six real-
world datasets. The results demonstrate the superior per-
formance of FUGNN in achieving both fairness and utility
when compared to state-of-the-art fairness-aware GNNs.
2 Related Work
2.1 Spectral GNNs
Spectral GNNs process features through filters, including well-
known models like GCN [ 33], SGC [ 46], and S2GC [ 51], which rely
on eigenvectors of the (normalized) Laplacian for Graph Fourier
Transform. Polynomials are employed to approximate the spec-
tral graph convolution, and are optimized to enhance the utility
of GNNs. JacobiConv [ 44] uses the concept of an orthogonal ba-
sis, aligning its weight function with the graph signal density in
the spectrum, and improves GNN utility through a novel poly-
nomial coefficient decomposition technique. ChebNetII [ 24] is a
novel GNN model that utilizes Chebyshev interpolation, focus-
ing on the Chebyshev polynomials to achieve superior utility. In
terms of node features, it is incorporated into several spectral graph
learning. CSBM-G [ 45] imposes a Gaussian assumption on node
features to better capture nonlinear relations in graph-structured
data, which is significant when node features are more information
than the graph structure. FE-GNN [ 41] conducts a comprehensive
examination of the dominant feature space in representation learn-
ing based on spectral model, optimizing GNN utility through the
perspective of the dominant feature space. In conventional GNN
architectures, the interdependence between different channels of
the filter can impede the utility of more potent filters. To address
this, PDF [ 49] introduces a novel normalized adjacency matrix util-
ity capable of leveraging an expanded set of bases and learnable
filter coefficients, thereby enhancing responsiveness to the filter.
 
2073FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Specformer [ 6] further extends this methodology by broadening
its applicability to point-level tasks. However, these spectral fil-
ters do not explicitly consider algorithmic fairness. They disregard
the interdependence between sensitive features and other features,
potentially introducing bias into the filter.
2.2 Fairness-aware GNNs
The fairness of GNNs has gained substantial traction, primarily
focusing on examination of discrimination associated with spe-
cific sensitive features. Predominant fairness-aware GNNs revolve
around protecting the independence of sensitive features using pre-
processing and in-processing methods [ 9]. Some previous methods
improve fairness by pre-processing the dataset [ 22,37]. For instance,
Graphair [ 37] autonomously identifies fairness-aware augmenta-
tions from input graph data, aiming to circumventing sensitive fea-
tures while preserving the integrity of other valuable data. FairAC
[22] shows a fair feature completion approach to address infor-
mation gaps and acquire equitable node embeddings for graphs
lacking features. As an integral component of GNNs aimed at con-
verting networks into low-dimensional vectors, fair embeddings as
pre-processing methods play a crucial role in protecting sensitive
features [ 26]. DeBayes [ 7] decreases bias in the embeddings by
introducing biased information into the prior of the conditional
network embedding. To mitigate bias in node embeddings, Fair-
Sample [ 13] enhances fairness through a regularization objective.
Some in-processing methods use loss functions to constrain the
influence of algorithms on sensitive features [ 14,15]. EDITS [ 15]
devises a loss function targeting the node output aimed to mitigate
biases within the input feature network, fostering fairer GNN out-
comes. FairGNN [ 14] is designed to limit the influence of sensitive
features using an estimation function and adversarial debiasing loss
function. However, these algorithms often enhance fairness at the
expense of the utility of algorithms.
3 Preliminaries
3.1 Notations
Unless otherwise specified, we denote sets with copperplate upper-
case letters (i.e.,A), matrices with bold uppercase letters (i.e., A),
and vectors with bold lowercase letters (i.e., a).
We denote an undirected graph as G=(V,X), whereVis the
set ofğ‘›nodes in the graph, XâˆˆRğ‘›Ã—ğ‘‘is the node feature matrix,
andğ‘‘is the feature dimension. For the ğ‘™-th graph convolution layer,
denoting its output node utility as H(ğ‘™), we generalize spectral
graph convolution as follows [10, 34]:
H(ğ‘™)=(1âˆ’ğœƒ)SH(ğ‘™âˆ’1)+ğœƒH(0), (1)
whereğœƒâˆˆ (0,1),H(0)=ğ‘“Î˜(X), and Sis the adjacency matrix.
â„âˆˆR1Ã—ğ‘›is one channel in the filter that corresponds to one
dimension of H(0).
In particular, we denote the sensitive feature channel as â„ğ‘ ğ‘’ğ‘›.
Based on the generalized formulation in Equation (1), we conduct
fairness analysis on existing graph convolutions from the perspec-
tive of the graphâ€™s spectrum. Assume SâˆˆRğ‘›Ã—ğ‘›is a symmetric
matrix with real-valued entries. |ğœ†1|â‰¥|ğœ†2|â‰¥......â‰¥|ğœ†ğ‘›|areğ‘›real
eigenvalues, and pğ‘–(ğ‘–âˆˆ{1,2,......,ğ‘›}) are the corresponding eigen-
vectors. After one layer of convolution, â„ğ‘ ğ‘’ğ‘›is represented as Sâ„ğ‘ ğ‘’ğ‘›.
Afterğ‘™layers convolution, it is represented as Sğ‘™â„ğ‘ ğ‘’ğ‘›. The cosinesimilarity between Sğ‘™â„ğ‘ ğ‘’ğ‘›andâ„ğ‘ ğ‘’ğ‘›, denoted as ğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©),
reflects the similarity between original sensitive features and the
sensitive features after ğ‘™layers of convolution. A higher cosine
similarity indicates stronger protection of sensitive feature inde-
pendence, reflecting higher fairness in GNNs. Furthermore, we
measure the eigenvectorâ€™s influence on the sensitive features byÃğ¾
ğ‘–=1ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,pğ‘–âŸ©), whereğ¾is the number of selection eigenvec-
tors.
3.2 Fairness Evaluation Metrics
In this subsection, we present two definitions of fairness for the
binary label ğ‘¦âˆˆ{0,1}and sensitive features ğ‘ âˆˆ{0,1}. We use
Ë†ğ‘¦âˆˆ{0,1}to represent the predicted class label.
Definition 1. Statistical Parity (i.e., Demographic Parity, Indepen-
dence) [18]. Statistical parity requires the predictions to be indepen-
dent of the sensitive features ğ‘ . It can be formally written as:
P(Ë†ğ‘¦|ğ‘ =0)=P(Ë†ğ‘¦|ğ‘ =1). (2)
When both the predicted labels and sensitive features are binary,
the extent of statistical parity can be quantified by Î”SP, defined as
follows:
Î”ğ‘†ğ‘ƒ=|P(Ë†ğ‘¦=1|ğ‘ =0)âˆ’P(Ë†ğ‘¦=1|ğ‘ =1)|. (3)
TheÎ”SPmeasures the acceptance rate difference between the
two sensitive subgroups.
Definition 2. Equal Opportunity [23]. Equal opportunity necessi-
tates that the likelihood of an instance belonging to a positive class
leading to a positive outcome should be equitable for all members
within subgroups. For individuals with positive ground truth labels,
it is necessary for positive predictions to be devoid of any depen-
dence on sensitive features. This principle can be mathematically
expressed as follows:
P(Ë†ğ‘¦=1|ğ‘¦=1,ğ‘ =0)=P(Ë†ğ‘¦=1|ğ‘¦=1,ğ‘ =1). (4)
Fairness-aware GNNs prevent the allocation of unfavorable pre-
dictions to individuals who are eligible for advantageous ones solely
based on their sensitive subgroup affiliation. In particular, Î”EOquan-
tifies the extent of deviation in predictions from the ideal scenario
where equality of opportunity is satisfied. To quantitatively assess
euqal opportunity, we employ the following metric:
Î”ğ¸ğ‘‚=|P(Ë†ğ‘¦=1|ğ‘¦=1,ğ‘ =0)âˆ’P(Ë†ğ‘¦=1|ğ‘¦=1,ğ‘ =1)|. (5)
Both probabilities are evaluated on the test set.
4 FUGNN: Theoretical Discovery
In this section, we present our theoretical findings that underpin
FUGNN. We analyze the correlation between sensitive features and
the graph spectrum. The independence of a model on sensitive fea-
tures can be reflected by the cosine similarity between Sğ‘™â„ğ‘ ğ‘’ğ‘›and
â„ğ‘ ğ‘’ğ‘›, where a higher cosine similarity indicates stronger protection
of sensitive feature independence. Hence, we analyze the relation-
ship between the graph spectrum and the term ğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©).
We aim to identify the components from the entire graph spec-
trum that have the most significant impact on the fairness of a
model. We consider three different spectral components: (1) a single
eigenvector with the largest magnitude of eigenvalue; (2) multi-
ples eigenvectors with the (same) largest magnitude of eigenvalue;
and (3) non-principal eigenvectors (i.e., eigenvectors with small
eigenvalues).
 
2074KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Renqiang Luo et al.
4.1 Single Eigenvector Corresponding to the
Largest Magnitude Eigenvalue
Lemma 1. Assume SâˆˆRğ‘›Ã—ğ‘›is a symmetric matrix with real-valued
entries. The eigenvalue are ordered as |ğœ†1|>|ğœ†2|â‰¥......â‰¥|ğœ†ğ‘›|,
andpğ‘–(ğ‘–âˆˆ{1,2,......,ğ‘›}) are corresponding eigenvectors. Then the
following equation holds:
lim
ğ‘™â†’âˆğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)=ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,p1âŸ©). (6)
Proof. Since SâˆˆRğ‘›Ã—ğ‘›is a symmetric matrix, the eigendecompo-
sition of Scan be written as S=Pğ›¬PâŠ¤with P=(p1,p2,......, pğ‘›),
âˆ¥pğ‘–âˆ¥=1(ğ‘–âˆˆ{1,2,......,ğ‘›}) andğ›¬=ğ‘‘ğ‘–ğ‘ğ‘”(ğœ†1,ğœ†2,......,ğœ†ğ‘›). The co-
sine similarity can be expressed as:
ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,p1âŸ©)=â„âŠ¤ğ‘ ğ‘’ğ‘›p1
âˆ¥â„ğ‘ ğ‘’ğ‘›âˆ¥âˆ¥p1âˆ¥=â„âŠ¤ğ‘ ğ‘’ğ‘›p1
âˆ¥â„ğ‘ ğ‘’ğ‘›âˆ¥
=â„âŠ¤ğ‘ ğ‘’ğ‘›p1âˆšï¸
â„âŠ¤ğ‘ ğ‘’ğ‘›â„ğ‘ ğ‘’ğ‘›=â„âŠ¤ğ‘ ğ‘’ğ‘›p1âˆšï¸
(PâŠ¤â„ğ‘ ğ‘’ğ‘›)âŠ¤PâŠ¤â„ğ‘ ğ‘’ğ‘›
=â„âŠ¤ğ‘ ğ‘’ğ‘›p1âˆšï¸ƒÃğ‘›
ğ‘–=1(â„âŠ¤ğ‘ ğ‘’ğ‘›pğ‘–)2.
Assumingğ›¼ğ‘–=â„âŠ¤ğ‘ ğ‘’ğ‘›pğ‘–, the weight of â„ğ‘ ğ‘’ğ‘›onpğ‘–when represent-
ingâ„ğ‘ ğ‘’ğ‘›with the set of orthonormal bases pğ‘–(ğ‘–âˆˆ{1,2,......,ğ‘›}),
then:
ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,p1âŸ©)=ğ›¼1âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–.
Whenğ‘™â†’âˆ, we have:
lim
ğ‘™â†’âˆğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)
=lim
ğ‘™â†’âˆ(Sğ‘™â„ğ‘ ğ‘’ğ‘›)âŠ¤â„ğ‘ ğ‘’ğ‘›
âˆ¥Sğ‘™â„ğ‘ ğ‘’ğ‘›âˆ¥âˆ¥â„ğ‘ ğ‘’ğ‘›âˆ¥
=lim
ğ‘™â†’âˆ(Sğ‘™â„ğ‘ ğ‘’ğ‘›)âŠ¤â„ğ‘ ğ‘’ğ‘›âˆšï¸
(Sğ‘™â„ğ‘ ğ‘’ğ‘›)âŠ¤Sğ‘™â„ğ‘ ğ‘’ğ‘›âˆšï¸
â„âŠ¤ğ‘ ğ‘’ğ‘›â„ğ‘ ğ‘’ğ‘›
=lim
ğ‘™â†’âˆ(Pğ›¬ğ‘™PâŠ¤â„ğ‘ ğ‘’ğ‘›)âŠ¤â„ğ‘ ğ‘’ğ‘›âˆšï¸
(PÎ›ğ‘™PâŠ¤â„ğ‘ ğ‘’ğ‘›)âŠ¤(Pğ›¬ğ‘™PâŠ¤â„ğ‘ ğ‘’ğ‘›)âˆšï¸
â„âŠ¤ğ‘ ğ‘’ğ‘›â„ğ‘ ğ‘’ğ‘›
=lim
ğ‘™â†’âˆ(PâŠ¤â„ğ‘ ğ‘’ğ‘›)âŠ¤ğ›¬ğ‘™(PâŠ¤â„ğ‘ ğ‘’ğ‘›)âˆšï¸
(PâŠ¤â„ğ‘ ğ‘’ğ‘›)âŠ¤ğ›¬2ğ‘™(PâŠ¤â„ğ‘ ğ‘’ğ‘›)âˆšï¸
â„âŠ¤ğ‘ ğ‘’ğ‘›â„ğ‘ ğ‘’ğ‘›
=lim
ğ‘™â†’âˆÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–ğœ†ğ‘™
ğ‘–âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–ğœ†2ğ‘™
ğ‘–âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–
=lim
ğ‘™â†’âˆğ›¼2
1+Ãğ‘›
ğ‘–=2ğ›¼2
ğ‘–(ğœ†ğ‘–
ğœ†1)ğ‘™
âˆšï¸ƒ
ğ›¼2
1+Ãğ‘›
ğ‘–=2ğ›¼2
ğ‘–(ğœ†ğ‘–
ğœ†1)2ğ‘™âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–
=ğ›¼1âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–.
â–¡
The above theorem shows that the term ğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)is
well captured by the spectral component p1. This indicates that
the principal component carries the most information about the
fairness of a model.4.2 Multiple Eigenvectors Corresponding to the
Largest Magnitude Eigenvalue
The matrix Scan possess multiple eigenvectors associated with the
largest magnitude eigenvalue, and thus, Lemma 1 does not hold.
Next, we investigate such cases.
Lemma 2. Assume that there are multiple eigenvectors corre-
sponding to the largest magnitude eigenvalue in the real-valued
entries. The eigenvalues are ordered as |ğœ†1|=|ğœ†2|=......=|ğœ†ğ‘—|>
|ğœ†ğ‘—+1|â‰¥......â‰¥|ğœ†ğ‘›|, and pğ‘–âˆˆRğ‘›,ğ‘–âˆˆ{1,2,......,ğ‘›}are correspond-
ing eigenvectors. Then the following equation holds:
lim
ğ‘™â†’âˆğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)â‰¥1âˆšğ‘—ğ‘—âˆ‘ï¸
ğ‘–=1ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,pğ‘–âŸ©). (7)
Proof.
lim
ğ‘™â†’âˆğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)
=lim
ğ‘™â†’âˆÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–ğœ†ğ‘™
ğ‘–âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–ğœ†2ğ‘™
ğ‘–âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–
=lim
ğ‘™â†’âˆÃğ‘—
ğ‘–=1ğ›¼2
ğ‘–+Ãğ‘›
ğ‘–=ğ‘—+1ğ›¼2
ğ‘–(ğœ†ğ‘–
ğœ†1)ğ‘™
âˆšï¸ƒÃğ‘—
ğ‘–=1ğ›¼2
ğ‘–+Ãğ‘›
ğ‘–=ğ‘—+1ğ›¼2
ğ‘–(ğœ†ğ‘–
ğœ†1)2ğ‘™âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–
=âˆšï¸ƒÃğ‘—
ğ‘–=1ğ›¼2
ğ‘–âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–.
Then, considering ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,pğ‘–âŸ©)=ğ›¼ğ‘–âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–and the Cauchy-
Schwarz Inequality, we have:
lim
ğ‘™â†’âˆğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)
=1âˆšğ‘—âˆšï¸ƒ
ğ‘—âˆ—12Ãğ‘—
ğ‘–=1ğ›¼2
ğ‘–âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–
â‰¥1âˆšğ‘—Ãğ‘—
ğ‘–=1ğ›¼ğ‘–âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–
=1âˆšğ‘—âˆ‘ï¸ğ‘—
ğ‘–=1ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,pğ‘–âŸ©).
Especially, only if right-side terms ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,pğ‘–âŸ©)are equal, the
equation holds.
â–¡
Lemma 2 shows that the term ğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)is determined
by multiple principal components. The lower bound of the term
ğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)is a weighted sum of the multiple eigenvectors
corresponding to the largest magnitude eigenvalue. In particular,
the similarity is maximum when the directions of these eigenvectors
are similar.
4.3 Non-principal Eigenvectors
For an eigenvector of S, if the corresponding eigenvalue |ğœ†ğ‘–|<<|ğœ†1|,
the eigenvector is regarded as non-principal eigenvector.
 
2075FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Figure 2: The framework of FUGNN. The model applies spectral truncation via eigenvalue selection and eigenvector distribution
optimization with fairness considerations. The top and bottom illustrate the two stages from the perspective of feature-level
representations and feature channels, respectively.
Lemma 3. The influence of non-principal eigenvectors on sensi-
tive features decays exponentially.
Proof. Because
ğ‘ğ‘œğ‘ (âŸ¨â„ğ‘ ğ‘’ğ‘›,pğ‘–âŸ©)=ğ›¼ğ‘–âˆšï¸ƒÃğ‘›
ğ‘—=1ğ›¼2
ğ‘—,
and
ğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)=ğ›¼2
1+Ãğ‘›
ğ‘–=2ğ›¼2
ğ‘–(ğœ†ğ‘–
ğœ†1)ğ‘™
âˆšï¸ƒ
ğ›¼2
1+Ãğ‘›
ğ‘–=2ğ›¼2
ğ‘–(ğœ†ğ‘–
ğœ†1)2ğ‘™âˆšï¸ƒÃğ‘›
ğ‘–=1ğ›¼2
ğ‘–.
Hence, the correlation between pğ‘–andğ‘ğ‘œğ‘ (âŸ¨Sğ‘™â„ğ‘ ğ‘’ğ‘›,â„ğ‘ ğ‘’ğ‘›âŸ©)is pro-
portional to(ğœ†ğ‘–
ğœ†1)ğ‘™. Because of|ğœ†1|>>|ğœ†ğ‘–|, the correlation decays
exponentially. Itâ€™s even negligible with fewer layers.
â–¡
The above analysis proves that impact of non-principal eigen-
vectors on the deep representations of sensitive features (i.e., after
convolution) diminishes exponentially.
In conclusion, sensitive features, after ğ‘™layers of convolution,
are predominantly influenced by the eigenvector corresponding
to the largest magnitude eigenvalue (or multiple eigenvectors cor-
responding to the largest magnitude eigenvalue). Fortunately, as
shown in previous studies, these principal eigenvectors are also
most influential in the utility of a model [ 35]. Thus, we argue that
truncating the spectrum to include only principal eigenvectors can
enhance the fairness of a model without compromising utility.
5 FUGNN: Technical Details
In this section, we introduce the design details of FUGNN. Our ap-
proach involves three main components: fairness-aware eigenvalue
selection, optimization of eigenvector distribution, and graph con-
volution. Firstly, we compute the ğ¾largest magnitude eigenvalues
and their corresponding eigenvectors. These principal eigenvec-
tors are retained as they are shown to be effective in expressing
the structure of the graph and in preserving sensitive features, as
demonstrated by our theoretical analysis [ 35]. Secondly, we un-
dertake adjustments in the distribution of eigenvectors with the
transformer architecture, which further harmonizes and improves
the utility and fairness of the model. Lastly, we assign the optimiz-
ing spectrum into graph convolution. Figure 2 illustrates the model
architecture.5.1 Fairness-aware Eigenvalue Selection (FES)
In Section 4, we have shown that sensitive features, after ğ‘™layers
convolution, primarily correlate with the largest magnitude eigen-
value and their corresponding eigenvectors. Hence, keeping these
eigenvectors in the graph spectrum can promote the fairness of the
model. Meanwhile, according to Lemma 2 andLemma3, the impact
of a non-principal eigenvector on the model fairness is negligible
afterğ‘™layer of convolution. We hypothesize that removing these
non-principal eigenvectors can better guide the model to focus on
the principal eigenvectors.
Thus, we propose to modify the graph spectrum by selecting
those eigenvectors. We leverage the Arnoldi Package algorithm [ 36]
to obtain the eigenvalues of the adjacency matrix by computing a
subset ofğ¾eigenvalues and corresponding eigenvectors:
eğ¹ğ¸ğ‘†=(ğœ†1,ğœ†2,......,ğœ†ğ¾),
Pğ¹ğ¸ğ‘†=(p1,p2,......, pK).(8)
We choose Arnoldi Package due to its high computational efficiency
and its accuracy as empirically demonstrated in [8].
Here,ğ¾is a model hyperparameter representing the number of
principal eigenvectors that are kept in the graph spectrum. In our
empirical analysis in Section 6.5, we show that the effectiveness
of a model (i.e., fairness and utility) is influenced by the value ğ¾.
At lower range of ğ¾values (e.g., <10), a model maintains high
effectiveness with only slight fluctuations. However, when too
many non-principle eigenvectors are kept in the spectrum (e.g.,
ğ¾>100), the effectiveness of a model will decrease significantly.
5.2 Optimization of Eigenvectors Distribution
(OED)
ByLemma 2, the maximum similarity between â„ğ‘ ğ‘’ğ‘›andSğ‘™â„ğ‘ ğ‘’ğ‘›is
intrinsically tied to the eigenvectors corresponding to the largest
eigenvalue. That is, the model fairness is best preserved when the
variation in the distribution of eigenvectors is minimal. Thus, to de-
crease the influence of convolutional layers on sensitive features, we
optimize the eigenvalue distribution using Transformer. Although
the Transformer architecture has demonstrated effectiveness in
achieving high model utility [ 50], the purpose of introducing this
module to our proposed approach is different. We hope to achieve
high model utility, but more importantly, to optimize the eigenvec-
tor distribution for the purpose of preserving fairness.
 
2076KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Renqiang Luo et al.
More specifically, we encode the eigenvalues ğœ†2ğ‘–âˆˆeğ¹ğ¸ğ‘†and
ğœ†2ğ‘–+1âˆˆeğ¹ğ¸ğ‘†as follows:
ğœŒ(ğœ†2ğ‘–)=ğ‘ ğ‘–ğ‘›(ğœ†2ğ‘–/100002ğ‘–/ğ‘‘),
ğœŒ(ğœ†2ğ‘–+1)=ğ‘ğ‘œğ‘ (ğœ†2ğ‘–+1/100002ğ‘–/ğ‘‘).(9)
We denote eğ‘ƒğ‘‚ğ‘†=(ğœŒ(ğœ†1),ğœŒ(ğœ†2),......,ğœŒ(ğœ†ğ¾)). Then, the method
uses multi-head self-attention (MHA) with layer normalization (LN).
This modification facilitates the encoding of eigenvalues, enabling
the capture of their inter-dependencies and generating valuable util-
ity. This eigenvalue encoding serves to alter the similarity between
the eigenvector corresponding to the largest eigenvalue and other
eigenvectors, thereby effectively enhancing the utility of sensitive
features. The formal characterization of the eigenvalue adjustment
is provided as follows:
eğ‘€ğ»ğ´ =MHA(LN(eğ‘ƒğ‘‚ğ‘†))+eğ‘ƒğ‘‚ğ‘†. (10)
eğ‘‚ğ¸ğ·=FFN(LN(eğ‘€ğ»ğ´))+eğ‘€ğ»ğ´. (11)
5.3 Graph Convolution
Finally, we assign optimizing spectrum based on learned basis eğ‘‚ğ¸ğ·,
and transform H(ğ‘™âˆ’1)into:
Hâ€²(ğ‘™âˆ’1)=Pğ¹ğ¸ğ‘†Â·(ğ‘’ğ‘‚ğ¸ğ·âŠ™PâŠ¤
ğ¹ğ¸ğ‘†H(ğ‘™âˆ’1)). (12)
The graph convolution can be written as follows:
H(ğ‘™)=ğœ((H(ğ‘™âˆ’1)||Hâ€²(ğ‘™âˆ’1))W(ğ‘™âˆ’1)), (13)
where W(ğ‘™âˆ’1)is the transformation, and ğœis the activation function.
By stacking multiple graph convolutional layers, FUGNN could
learn node representation.
6 Experiments
6.1 Datasets
We show the effectiveness of our method on the node classification,
and adopt six real-world datasets for this task:
â€¢Income: Extracted from the Adult Data Set [ 4]. Each node
represents an individual, with connections established based
on criteria similar to [ 2]. The sensitive feature in this dataset
is race, and the task involves classifying whether an individ-
ualâ€™s salary exceeds 50,000annually.
â€¢Pokec-z andPokec-n: Both datasets are collected from
Pokec, a popular social network in Slovakia [ 42]. In both
datasets, users are represented as nodes, edges denoting
friendship. The locating region of users is the sensitive fea-
ture. The task is to classify usersâ€™ working fields.
â€¢Bail: This dataset represents defendants who were released
on bail at the U.S. state courts during 1990-2009 [ 28]. Nodes
represent clients within a bail bank, features are gender, loan
amount, and other account-related details. Edges connect
clients whose credit accounts share similarities. The objec-
tive is to categorize clientsâ€™ credit risk as either high or low,
with â€œgenderâ€ designated as the sensitive feature.
â€¢German: Extracted from the Adult Data Set [ 4]. Nodes rep-
resent defendants released in Germany from 1990 to 2009,
connected by edges based on shared past criminal recordsand demographics. The goal is predicting a defendantâ€™s like-
lihood of committing either a violent or nonviolent crime
post-release, with â€œraceâ€ as the sensitive feature.
â€¢Credit: Extracted from the Adult Data Set [ 4]. Comprising
individuals connected based on similarities in spending and
payment patterns. Age serves as the sensitive feature, while
the label feature denotes defaulting on credit card payments.
The statistics of these six datasets are shown in Table 2. For datasets
containing more than two classes of ground truth labels for the
node classification task, we retain the class labeled 0and1, and set
any class of labeled more than 1to1. We randomly select 25% of
nodes as the validation set and 25% as the test set, ensuring that
the proportion of nodes labeled with each category is balanced in
these sets. Additionally, we randomly select either 50% of nodes
or500nodes in each class of ground truth labels as the training
set, depending on which is a smaller. This partitioning strategy is
consistent with prior studies [ 2,15,17], which also serves as our
baselines.
Table 2: The statistics of the six real-world datasets.
Dataset # Nodes # Edges Sensitive Feature Label
Income 14,821 51,386 Race Income
Pokec-z 67,797 882,765 Region Field
Pokec-n 66,569 729,129 Region Field
German 1,000 24,970 Region German
Bail 18,876 403,977 Race Bail
Credit 30,000 200,526 Age Credit
6.2 Baselines
We compare our proposed method with three spectral convolutional
network methods: GCN [33],GCNII [10], and APPNP [34], as well
as the following representative and state-of-the-art fairness-aware
GNNs methods:
â€¢NIFTY [2] seeks to optimize the alignment between predic-
tions derived from perturbed sensitive features and those
generated using unperturbed features.
â€¢EDITS [15] preprocesses input graph data by feature and
structural debiasing methods to mitigate bias.
â€¢FairGNN [14] utilizes adversarial training to eliminate sen-
sitive feature information from node embeddings.
â€¢Graphair [37] focuses on acquiring equitable utility through
automated graph data augmentations.
â€¢BIND [17] effectively estimates the impact of each training
node on the disparity in probabilistic distributions.
The optimal hyperparameters for all methods are obtained by
grid search. We employ the released implementations of fairness-
aware GNN baselines, namely FairGNN, NIFTY, EDITS, BIND, and
Graphair, to ensure a fair and consistent comparison. All baselines
are implemented using the PyTorch framework [ 39]. Specifically,
FairGNN, NIFTY, BIND and Graphair are optimized with Adam opti-
mizer [ 32], while EDITS utilizes RMSprop [ 25] as recommended. For
each method, we conduct experiments with different seeds {0, 1,2,3,
4} and use the mean value and standardized covariance as the results.
All models are implemented using PyTorch and PyTorch-geometric
[20], executed on the Ubuntu 20.04.6 LTS operation system, with
hardware specifications including an Intel(R) Xeon(R) Silver 4114
CPU @ 2.20GHz and a Tesla V100S-PCIE-32G GPU.
 
2077FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 1: Comparison on accuracy and fairness ( Î”SPandÎ”EO) in percentage (%) with six real world datasets. â†‘denotes the larger,
the better;â†“denotes the opposite. The best results are bold-faced.
MethodsIncome Pokec-z Pokec-n
ACC(%)â†‘Î”SP(%)â†“ Î”EO(%)â†“ ACC(%)â†‘Î”SP(%)â†“Î”EO(%)â†“ ACC(%)â†‘Î”SP(%)â†“ Î”EO(%)â†“
GCN 74.73Â±2.54 25.90Â±0.44 32.30Â±2.78 66.24Â±2.12 7.32Â±1.48 7.60Â±1.87 66.53Â±2.84 6.57Â±1.48 5.33Â±0.42
GCNII 76.24Â±2.46 16.20Â±0.85 25.18Â±1.69 65.08Â±0.35 4.05Â±0.12 2.76Â±0.38 62.91Â±1.24 4.08Â±0.54 4.47Â±0.62
APPNP 76.79Â±1.84 12.50Â±0.49 16.60Â±2.34 65.24Â±1.26 4.52Â±1.02 1.78Â±0.34 67.45Â±1.18 2.15Â±0.23 4.35Â±0.76
FairGNN 69.12Â±0.31 12.40Â±0.70 15.60Â±1.00 64.04Â±0.90 4.95Â±0.21 4.29Â±0.20 60.29Â±0.64 5.30Â±0.20 1.67Â±0.17
NIFTY 70.76Â±1.27 23.26Â±1.35 24.85Â±1.00 65.34Â±0.43 2.34Â±0.26 1.46Â±0.27 61.12Â±0.07 6.55Â±0.55 1.83Â±0.07
EDITS 68.26Â±3.17 21.92Â±0.29 21.81Â±0.01 61.60Â±0.54 1.29Â±0.10 1.62Â±0.20 56.80Â±0.65 2.75Â±0.80 2.24Â±0.90
Graphair 71.49Â±1.00 10.68Â±1.56 12.72Â±2.08 64.17Â±0.08 2.10Â±0.17 2.76Â±0.19 62.43Â±0.25 2.02Â±0.40 1.62Â±0.47
BIND 71.69Â±1.89 14.37Â±2.62 16.79Â±3.14 63.50Â±0.20 6.75Â±0.40 5.41Â±0.57 60.60Â±0.15 5.85Â±0.39 1.15Â±0.44
FUGNN 80.18Â±1.09 1.43Â±0.88 1.78Â±1.14 68.38Â±0.43 0.53Â±0.27 1.32Â±0.95 68.48Â±0.07 0.80Â±0.31 1.03Â±0.59
MethodsGerman Bail Credit
ACC(%)â†‘Î”SP(%)â†“ Î”EO(%)â†“ ACC(%)â†‘Î”SP(%)â†“Î”EO(%)â†“ ACC(%)â†‘Î”SP(%)â†“ Î”EO(%)â†“
GCN 71.20Â±2.54 8.43Â±0.44 4.52Â±0.78 89.80Â±1.12 7.47Â±1.74 5.23Â±0.78 73.87Â±2.48 12.86Â±1.84 10.63Â±0.24
GCNII 70.43Â±1.64 2.78Â±0.54 2.52Â±0.87 92.43Â±2.37 5.67Â±0.89 3.94Â±0.27 74.03Â±1.97 16.85Â±2.54 10.58Â±1.68
APPNP 69.60Â±0.40 5.29Â±0.16 5.47Â±0.54 85.36Â±2.074.20Â±0.37 3.36Â±1.08 74.19Â±0.79 13.3Â±0.94 9.47Â±1.86
FairGNN 69.72Â±1.24 3.49Â±0.30 3.40Â±2.15 89.68Â±2.09 7.31Â±1.12 5.17Â±0.54 68.29Â±2.25 9.74Â±0.28 8.83Â±0.46
NIFTY 69.86Â±2.40 5.73Â±0.55 5.08Â±2.29 81.48Â±2.14 10.04Â±0.62 7.71Â±0.10 66.80Â±1.07 13.59Â±0.43 13.79Â±0.73
EDITS 70.60Â±0.89 4.05Â±1.48 3.89Â±0.23 89.57Â±0.46 5.02Â±0.81 2.89Â±0.27 69.60Â±0.56 9.13Â±1.38 7.88Â±1.90
Graphair 70.08Â±0.64 4.38Â±0.26 3.82Â±0.21 84.76Â±2.08 4.98Â±0.34 2.58Â±0.34 67.65Â±2.01 8.99Â±2.02 7.05Â±1.74
BIND 71.59Â±2.03 3.46Â±0.10 6.51Â±1.28 88.47Â±2.10 6.75Â±0.54 4.23Â±0.32 68.60Â±0.53 11.65Â±0.93 10.61Â±2.01
FUGNN 72.80Â±2.00 1.05Â±0.11 0.84Â±0.23 96.78Â±1.10 5.99Â±0.291.55Â±0.87 77.02Â±0.07 0.62Â±0.48 0.18Â±0.09
0 2 12 14 16 18 20 22 24 66 68 70 72 74 76 78 80 ACC(%) 
/s8710 SP (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Income 
0 1 2 3 4 5 6 7 8 60 62 64 66 68 70 ACC(%) 
/s8710 SP (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Pokec-z 
0 1 2 3 4 5 6 7 56 58 60 62 64 66 68 70 ACC(%) 
/s8710 SP (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Pokec-n 
0 1 2 3 4 5 6 7 8 66 68 70 72 74 76 ACC(%) 
/s8710 SP (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN German 
4 5 6 7 8 9 10 11 80 84 88 92 96 100 ACC(%) 
/s8710 SP (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Bail 
0 2 4 6 8 10 12 14 60 64 68 72 76 80 ACC(%) 
/s8710 SP (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Credit 
Figur
e 3: The accuracy and Î”SPtrade-off. Upper-left corner is preferable.
6.3 Comparison Results
For assessing utility, we adopt node classification accuracy as the
corresponding metric, while for assessing fairness, we adopt two
traditional metrics Î”SPandÎ”EO. Higher accuracy indicates better
utility, and lower values of fairness metrics indicate better fairness.
6.3.1 Fairness. Table 1 provides a comprehensive overview of the
fairness evaluation metrics for our proposed FUGNN method and
various baseline models across six real-world datasets. FUGNN
consistently demonstrates outstanding fairness utility, particularly
notable in terms of Î”SPandÎ”EOacross the evaluated datasets. An
exception is observed in the Î”SPfor the Bail dataset, which showspoor performance. This can be partly attributed to excessive ac-
curacy of the model. However, the lower Î”EOindicates that the
algorithm ensures fairness in predicting the correct samples, reaf-
firming its effectiveness in addressing fairness-related concerns
within graph-based learning algorithms.
6.3.2 Trade-off between accuracy and fairness. To confirm our pur-
suit of a comprehensive assessment in accuracy and fairness, we
aim to achieve the best fairness with the highest accuracy. From Ta-
ble 1, we observe that our proposed FUGNN improves both fairness
and utility simultaneously. The utility achieved is even higher than
the three spectral graph convolution network methods. To provide
a more visual representation of our effectiveness, we present the
 
2078KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Renqiang Luo et al.
0 2 12 14 16 18 20 22 24 26 28 66 68 70 72 74 76 78 80 ACC(%) 
/s8710 EO (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Income 
0 1 2 3 4 5 6 60 62 64 66 68 70 ACC(%) 
/s8710 EO (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Pokec-z 
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 56 58 60 62 64 66 68 70 ACC(%) 
/s8710 EO (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Pokec-n 
0 1 2 3 4 5 6 7 8 66 68 70 72 74 76 78 ACC(%) 
/s8710 EO (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN German 
0 1 2 3 4 5 6 7 8 80 84 88 92 96 100 ACC(%) 
/s8710 EO (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Bail 
0 2 4 6 8 10 12 14 60 64 68 72 76 80 ACC(%) 
/s8710 EO (%)  FairGNN  NIFTY 
 EDITS  Graphair 
 BIND  FUGNN Credit 
Figure 4: The accuracy and Î”EOtrade-off. Upper-left corner is preferable.
details in Figure 3 and Figure 4. For the fairness evaluation, we
employ the Î”SPandÎ”EOmetrics, respectively. Notably, the upper-
left corner point within these graphical utilities symbolizes the
optimal utility, characterized by the highest accuracy and the high-
est prediction fairness. This achievement aligns with the primary
objective of our approach, which aims to concurrently enhance
both the fairness and utility of GNNs.
6.4 Ablation Study
FUGNN, as an approach to harmonize the fairness and utility
in GNNs, achieves its objectives through two key components:
FUGNN FESandFUGNN OED. To comprehensively assess the contri-
butions of these two elements and the overall impact of FUGNN, we
conduct an ablation study. This study aims to discern whether both
FUGNN FESandFUGNN OED contribute to enhancing prediction
fairness and accuracy. In this part, we systematically remove each
component independently to assess their individual impacts.
We first focus on the contribution of eigenvalue calculation,
represented as FUGNN w/o FES (FUGNN without FUGNN FES).
Notably, when comparing FUGNN FESwith FUGNN, the latter con-
sistently outperforms them in terms of statistical parity, equal op-
portunity, and accuracy. The results, shown in Table 3, reinforce
the necessity of FUGNN FESwithin FUGNN. We then denote the
configuration without optimization of eigenvector distribution as
FUGNN w/o OED (FUGNN without FUGNN OED). The results, as
presented in Table 3, provide compelling evidence of the contribu-
tions of this component. When comparing FUGNN to the ablated
versions, FUGNN is consistently higher in terms of accuracy and
lower in terms of Î”SPandÎ”EO. This observation underscores that
FUGNN OED plays a crucial role in enhancing both the fairness of
GNN predictions and accuracy.
In summary, the ablation study collectively emphasizes the in-
tegral role played by FUGNN FESand FUGNN OED in improving
fairness and utility in GNNs.
6.5 Parameter Analysis
In this investigation, our primary aim is to scrutinize the impact of
parameterğ¾on our proposed FUGNN. Specifically, we conduct a
systematic parameter study that focuses on the variable denoted as
ğ¾across the six datasets. The parameter ğ¾assumes a pivotal roleas it governs how original information from the adjacency matrix
is retained. Moreover, it also plays a crucial role in representing
the similarity between original sensitive features and ones after ğ‘™
layers of convolution. According to our theoretical analysis, as ğ¾
increases, fairness initially hovers, followed by a subsequent decline.
The following experiment results verify our analysis.
Our analysis involves exploring ğ¾values spanning the range
of 1-10, 100, 500, 1,000, 5,000, and ğ‘›. To show how ğ¾affects Î”SP
andÎ”EO, we present the average results for multiple runs. The
outcomes of Income andCredit are shown in Table 4. Additional
results of the parameter analysis are shown in Table 5 and Table 6.
Given that the number of nodes in the German dataset is 1,000,
far below 5,000, there is no ğ¾=5,000result available for the
German dataset, and the ğ¾=1,000result is congruent with the
ğ¾=ğ‘›result. Additionally, we conduct eigedecomposition on the
adjacency matrices of Pokec-z andPokec-n, resulting in processed
eigenvalue and eigenvector files of approximately 18 GB in size.
When we applied these files for model training, we encountered
Out-Of-Memory (OOM) errors. The findings indicate that as ğ¾
varies in{1,2,...,10}, bothÎ”SPandÎ”EOexhibit relatively consistent
performance with moderate fluctuations. When ğ¾reaches >100,
the model performance shows a clear declination in accuracy and
fairness. This experiment observation aligns with the analysis of
ğ¾inLemma 3. After comparing both Î”SPandÎ”EO, we choose the
optimal result as our final selection for the parameter ğ¾. Specifically,
we selectğ¾=1forIncome,ğ¾=3forPokec-z,ğ¾=2forPokec-n,
ğ¾=10forGerman,ğ¾=3forBail, andğ¾=6forCredit.
It worths mentioning that the best number of principal eigenvec-
tors to be kept varies across datasets. Hence, conducting compre-
hensive hyperparameter search would be beneficial to run FUGNN
effectively on new datasets. This also suggests a potential direction
for further improving FUGNN via developing efficient strategies
for parameter refining.
6.6 Training Cost Comparison
The whole eigendecomposition causes cubic complexity in terms
of the number of nodes, resulting in a computational cost of ğ‘‚(ğ‘›3).
The eigenvector selection eliminates the need to rank the eigenvec-
tors following the entire eigendecomposition process. The Arnolodi
 
2079FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 3: Comparisons among different components in the FUGNN model. OOM denotes out-of-memory.
DatasetsFUGNN FUGNN w/o FES FUGNN w/o OED
ACC(%)â†‘ Î”SP(%)â†“ Î”EO(%)â†“ ACC(%)â†‘ Î”SP(%)â†“ Î”EO(%)â†“ ACC(%)â†‘ Î”SP(%)â†“ Î”EO(%)â†“
Income 80.18Â±1.09 1.43Â±0.88 1.78Â±1.14 76.75Â±1.87 3.79Â±0.96 5.78Â±1.90 79.98Â±0.60 2.29Â±0.34 3.26Â±0.59
Pokec-z 68.38Â±0.43 0.53Â±0.27 1.32Â±0.95 OOM OOM OOM 67.26Â±0.33 1.04Â±0.37 3.43Â±0.42
Pokec-n 68.48Â±0.07 0.80Â±0.31 1.03Â±0.59 OOM OOM OOM 67.97Â±0.27 2.37Â±0.39 2.97Â±1.16
German 72.80Â±2.00 1.05Â±0.11 0.84Â±0.23 69.20Â±0.40 5.07Â±1.23 4.83Â±0.94 68.90Â±1.15 2.20Â±0.62 4.60Â±1.13
Bail 96.78Â±1.10 5.99Â±0.29 1.55Â±0.87 96.39Â±0.14 6.51Â±0.16 2.35Â±0.53 96.59Â±0.27 6.53Â±0.23 1.86Â±0.23
Credit 77.02Â±0.07 0.62Â±0.48 0.18Â±0.09 74.39Â±1.58 3.05Â±0.36 3.35Â±0.74 75.91Â±1.11 2.82Â±0.40 1.99Â±0.61
Table 4: The accuracy, Î”SPandÎ”EOof FUGNN w.r.t. different
parameter ğ‘˜values.
KIncome Credit
ACC(%)â†‘Î”SP(%)â†“Î”EO(%)â†“ACC(%)â†‘Î”SP(%)â†“Î”EO(%)â†“
1 78.68 0.01 1.66 77.04 0.04 0.15
2 78.95 0.51 0.73 76.99 0.57 0.13
3 78.33 1.98 0.79 77.14 0.64 0.72
4 80.19 1.33 3.24 77.11 0.66 0.12
5 80.46 1.16 1.14 76.95 1.20 0.32
6 78.33 2.27 0.03 77.04 0.04 0.15
7 81.06 2.04 2.25 76.99 0.48 0.01
8 80.90 1.70 1.81 76.89 1.08 0.61
9 79.57 0.91 0.25 76.92 0.35 0.29
10 78.44 0.02 1.06 76.64 0.89 0.37
100 77.20 2.38 3.36 74.89 2.09 2.38
500 77.33 2.56 3.36 74.15 2.61 2.11
1,000 77.22 4.22 2.40 73.14 2.07 2.46
5,000 77.14 5.47 4.48 72.81 2.69 2.81
ğ‘› 76.75 3.79 5.78 74.39 3.05 3.35
Table 5: The accuracy, Î”SPandÎ”EOof FUGNN w.r.t. different
parameter ğ‘˜values. OOM denotes out-of-memory.
KPokec-z Pokec-n
ACC(%)â†‘Î”SP(%)â†“Î”EO(%)â†“ACC(%)â†‘Î”SP(%)â†“Î”EO(%)â†“
1 67.54 0.70 2.62 68.59 0.24 0.12
2 67.61 1.20 0.89 67.32 0.68 0.38
3 68.12 1.32 0.26 67.91 1.05 0.31
4 68.08 1.87 0.19 68.00 0.66 0.62
5 68.55 2.51 0.04 68.05 1.18 0.99
6 68.20 0.99 0.04 68.68 1.98 1.43
7 68.36 1.60 0.15 68.27 3.18 4.32
8 67.46 2.38 0.41 68.72 2.31 1.70
9 68.51 0.83 1.29 68.45 1.78 2.46
10 67.73 1.23 0.35 68.36 3.68 5.40
100 66.79 3.67 4.03 67.10 4.17 5.79
500 66.43 4.26 4.51 66.78 4.31 5.90
1,000 65.98 4.34 4.51 66.43 4.21 6.55
5,000 65.56 4.74 5.02 65.97 5.73 6.78
ğ‘› OOM OOM OOM OOM OOM OOM
Package algorithm, which FUGNN FESemploys, achieves a time
complexity of ğ‘‚(ğ‘›ğ¾2)for eigendecomposition. In particular, FUGNN
only chooses principal eigenvectors, ensuring that ğ¾remains con-
sistently below 10. We present the comparison results of whole
eigendecomposition (WE) and FUGNN FESis shown in Table 7.Table 6: The accuracy, Î”SPandÎ”EOof FUGNN w.r.t. different
parameter ğ‘˜values.
KGerman Bail
ACC(%)â†‘Î”SP(%)â†“Î”EO(%)â†“ACC(%)â†‘Î”SP(%)â†“Î”EO(%)â†“
1 71.20 1.94 3.36 97.32 6.15 1.41
2 71.20 0.23 3.36 97.64 6.15 1.60
3 72.80 1.05 0.84 98.23 6.13 1.35
4 71.60 0.85 0.84 97.65 6.10 1.73
5 71.60 1.27 0.84 97.18 6.25 1.50
6 68.80 0.67 5.78 97.77 5.73 0.88
7 70.80 0.85 1.68 97.35 6.26 1.56
8 70.00 0.42 0.84 97.94 6.26 1.49
9 70.00 0.85 1.68 97.25 6.47 1.91
10 71.60 0.45 1.58 98.11 6.26 1.81
100 70.80 3.01 6.72 97.89 6.22 2.07
500 69.20 3.45 5.67 96.89 6.30 2.09
1,000 69.20 5.07 4.83 96.21 6.24 2.45
5,000 - - - 96.91 6.48 2.51
ğ‘› 69.20 5.07 4.83 96.39 6.51 2.35
Table 7: Runtime (s) of WE and FUGNN FES.
Methods Income Pokec-z Pokec-n German Bail Credit
WE 107.81 3018.91 2987.16 0.46 198.89 774.91
FUGNN FES 0.84 10.00 8.84 0.36 3.29 0.84
According to the results, we observe greater time savings with
larger datasets. Especially for datasets where using the full decom-
position results in inference exceeding the available memory limits,
our method still works fine in such cases.
7 Conclusion
In this work, we examine the protection of sensitive features via
studying the similarity between the representations of those sen-
sitive features at the input layer and at deep latent space of the
model afterğ‘™layers of convolution operations. We establish a strong
correlation with the largest magnitude eigenvalue of the adjacency
matrix. Drawing inspiration from this finding, we have presented
FUGNN, an innovative approach dedicated to enhancing both the
fairness and utility of GNNs. FUGNN is built on two crucial com-
ponents: eigenvalue adjustment and optimization of eigenvector
distribution. These two components are designed based on our
theoretical findings, which simultaneously enhance the fairness
and utility of GNNs. The proposed FUGNN framework has demon-
strated significant improvements over strong baselines across di-
verse real-world scenarios. In future work, we plan to further refine
the efficiency of the FUGNN approach and extend its applicability
to situations with limited sensitive features.
 
2080KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Renqiang Luo et al.
References
[1]Mohamed Abdelrazek, Erasmo Purificato, Ludovico Boratto, and Ernesto.W.D
Luca. 2023. FairUP: A Framework for Fairness Analysis of Graph Neural Network-
Based User Profiling Models. In SIGIR. 3165â€“3169.
[2]Chirag Agarwal, Himabindu Lakkaraju, and Marinka Zitnik. 2021. Towards
a Unified Framework for Fair and Stable Graph Representation Learning. In
International Conference on Uncertainty in Artificial Intelligence. 2114â€“2124.
[3]AS Albahri, Ali M Duhaim, Mohammed A Fadhel, Alhamzah Alnoor, Noor S
Baqer, Laith Alzubaidi, OS Albahri, AH Alamoodi, Jinshuai Bai, Asma Salhi, et al .
2023. A Systematic Review of Trustworthy and Explainable Artificial Intelligence
in Healthcare: Assessment of Quality, Bias Risk, and Data Fusion. Information
Fusion 96 (2023), 156â€“191.
[4]Arthur Asuncion and David Newman. 2007. UCI Machine Learning Repository.
[5]Anson Bastos, Abhishek Nadgeri, Kuldeep Singh, Toyotaro Suzumura, and Man-
ish Singh. 2023. Learnable Spectral Wavelets on Dynamic Graphs to Capture
Global Interactions. In AAAI. 6779â€“7787.
[6]Deyu Bo, Chuan Shi, Lele Wang, and Renjie Liao. 2023. Specformer: Spectral
Graph Neural Networks Meet Transformer. In ICLR.
[7]Maarten Buyl and Tijl De Bie. 2020. Debayes: a bayesian method for debiasing
network embeddings. In ICML. 1220â€“1229.
[8]Yunfeng Cai, Guanhua Feng, and Peng Li. 2021. A Note on Sparse Generalized
Eigenvalue Problem. In NeurIPS. 23036â€“23048.
[9]Simon Caton and Christian Haas. 2020. Fairness in Machine Learning: A Survey.
ACM Computing Surveys (2020).
[10] Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, and Yaliang Li. 2020.
Simple and deep graph convolutional networks. In ICML. 1725â€“1735.
[11] Richard J Chen, Judy J Wang, Drew FK Williamson, Tiffany Y Chen, Jana Lipkova,
Ming Y Lu, Sharifa Sahai, and Faisal Mahmood. 2023. Algorithmic fairness in
artificial intelligence for medicine and healthcare. Nature Biomedical Engineering
7, 6 (2023), 719â€“742.
[12] Dewei Cheng, Zhibin Niu, Jie Li, and Changjun Jiang. 2023. Regulating Systemic
Crises: Stemming the Contagion Risk in Networked-Loans Through Deep Graph
Learning. IEEE Transactions on Knowledge and Data Engineering 35, 6 (2023),
6278â€“6289.
[13] Zicun Cong, Baoxu Shi, Shan Li, Jaewon Yang, Qi He, and Jian Pei. 2023. FairSam-
ple: Training Fair and Accurate Graph Convolutional Neural Networks Efficiently.
IEEE Transactions on Knowledge and Data Engineering (2023).
[14] Enyan Dai and Suhang Wang. 2023. Learning Fair Graph Neural Networks
with Limited and Private Sensitive Attribute Information. IEEE Transactions on
Knowledge and Data Engineering 35, 7 (2023), 7103â€“7117.
[15] Yushun Dong, Ninghao Liu, Brian Jalaian, and Jundong Li. 2022. EDITS: Modeling
and Mitigating Data Bias for Graph Neural Networks. In 2022 WWW. 1259â€“1269.
[16] Yushun Dong, Jing Ma, Song Wang, Chen Chen, and Jundong Li. 2023. Fairness
in graph mining: A survey. IEEE Transactions on Knowledge and Data Engineering
(2023).
[17] Yushun Dong, Song Wang, Jing Ma, Ninghao Liu, and Jundong Li. 2023. Inter-
preting Unfairness in Graph Neural Networks via Training Node Attribution. In
AAAI. 7441â€“7449.
[18] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard S.
Zemel. 2012. Fairness through Awareness. In Proceedings of Innovations in Theo-
retical Computer Science. 214â€“226.
[19] Geya Feng, Yongbin Qin, Ruizhang Huang, and Yanping Chen. 2023. Criminal
Action Graph: A Semantic Representation Model of Judgement Documents for
Legal Charge Prediction. Information Processing & Management 60, 5 (2023),
103421.
[20] Matthias Fey and Jan E. Lenssen. 2019. Fast Graph Representation Learning with
PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and
Manifolds.
[21] Tanmay Garg, Sarah Masud, Tharun Suresh, and Tanmoy Chakraborty. 2022.
Handling bias in toxic speech detection: A survey. ACM Computing Surveys 55,
13 (2022), 1â€“32.
[22] Dongliang Guo, Zhixuan Chu, and Sheng Li. 2023. Fair Attribute Completion on
Graph with Missing Attributes. In ICLR.
[23] Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of Opportunity in
Supervised Learning. In NeurIPS. 3315â€“3323.
[24] Mingguo He, Zhewei Wei, and Ji-Rong Wen. 2022. Convolutional Neural Net-
works on Graphs with Chebyshev Approximation, Revisited. In NeurIPS. 7264â€“
7276.
[25] Geoffrey Hinton, Nitish Srivastava, and Kevin Swersky. 2012. Neural Networks
for Machine Learning Lecture 6a Overview of Mini-batch Gradient Descent. Cited
on14, 8 (2012), 2.[26] Mingliang Hou, Jing Ren, Da Zhang, Xiangjie Kong, Dongyu Zhang, and Feng
Xia. 2020. Network Embedding: Taxonomies, Frameworks and Applications.
Computer Science Review 38 (2020), 100296.
[27] Zhimeng Jiang, Xiaotian Han, Hongye Jin, Guanchu Wang, Na Zou, and Xiaben
Hu. 2023. Chasing Fairness under Distribution Shift: a Model Weight Perturbation
Approach. In NeurIPS.
[28] Kareem L Jordan and Tina L Freiburger. 2015. The effect of race/ethnicity on
sentencing: Examining sentence type, jail length, and prison length. Journal of
Ethnicity in Criminal Justice 13, 3 (2015), 179â€“196.
[29] Nathan Kallus, Xiaojie Mao, and Angela Zhou. 2022. Assessing algorithmic
fairness with unobserved protected class using data combination. Management
Science 68, 3 (2022), 1959â€“1981.
[30] Jian Kang, Yan Zhu, Yinglong Xia, Jiebo Luo, and Hanghang Tong. 2022. Rawls-
GCN: Towards rawlsian difference principle on graph convolutional network. In
2022 WWW. 1214â€“1225.
[31] Ahmad Khajehnejad, Moein Khajehnejad, Mahmoudreza Babaei, Krishna P Gum-
madi, Adrian Weller, and Baharan Mirzasoleiman. 2022. CrossWalk: Fairness-
enhanced Node Representation Learning. In AAAI. 11963â€“11070.
[32] Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for Stochastic Opti-
mization. In ICLR.
[33] Thomas N Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In ICLR.
[34] Johannes Klicpera, Aleksandar Bojchevski, and Stephan Gunnemann. 2019. Pre-
dict then Propagate: Graph Neural Networks Meet Personalized PageRank. In
ICLR.
[35] Devin Kreuzer, Dominique Beaini, William L. Hamilton, Vincent Letourneau, and
Prudencio Tossou. 2021. Rethinking Graph Transformers with Spectral Attention.
InNeurIPS. 21618â€“21629.
[36] Richard B. Lehoucq, Danny C. Sorensen, and Chao Yang. 1998. ARPACK usersâ€™
guide - solution of large-scale eigenvalue problems with implicitly restarted Arnoldi
methods. SIAM.
[37] Hongyi Ling, Zhimeng Jiang, Youzhi Luo, Shuiwang Ji, and Na Zou. 2023. Learn-
ing Fair Graph Representations via Automated Data Augmentations. In ICLR.
[38] Renqiang Luo, Huafei Huang, Shuo Yu, Xiuzhen Zhang, and Feng Xia. 2024.
FairGT:A Fairness-aware Graph Transformer. In IJCAI.
[39] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al .2019.
Pytorch: An Imperative Style, High-performance Deep Learning Library. In
NeurIPS. 8024â€“8035.
[40] Dana Pessach and Erez Shmueli. 2022. A Review on Fairness in Machine Learning.
ACM Computing Surveys 55, 3 (2022), 1â€“44.
[41] Jiaqi Sun, Lin Zhang, Guangyi Chen, Peng Xu, Kun Zhang, and Yujiu Yang. 2023.
Feature Expansion for Graph Neural Networks. In ICML. 33156â€“33176.
[42] Lubos Takac and Zabovsky Michal. 2012. Data Analysis in Public Social Networks.
InProceedings of International Scientific Conference and International Workshop
Present Day Trends of Innovations.
[43] Huiling Tu, Shuo Yu, Vidya Saikrishna, Feng Xia, and Karin Verspoor. 2023. Deep
Outdated Fact Detection in Knowledge Graphs. In Proceedings of the 2023 IEEE
International Conference on Data Mining Workshops.
[44] Xiyuan Wang and Muhan Zhang. 2022. How Powerful are Spectral Graph Neural
Networks. In ICML. 23341â€“23362.
[45] Rongzhe Wei, Haoteng Yin, Junteng Jia, Austing R. Benson, and Pan Li. 2022.
Understanding Non-linearity in Graph Neural Networks from the Perspective of
Bayesian Inference. In NeurIPS. 34024â€“34038.
[46] Felix Wu, H.Souza Jr. Amauri, Tianyi Zhang, Christopher Fifty, Tao Yu, and
Killan Q. Weinberger. 2019. Simplifying Graph Convolutional Networks. In ICML.
6861â€“6871.
[47] Feng Xia, Xin Chen, Shuo Yu, Mingliang Hou, Mujie Liu, and Linlin You. 2024.
Coupled Attention Networks for Multivariate Time Series Anomaly Detection.
IEEE Transcations on Emerging Topics in Computing 12, 1 (2024), 240â€“253.
[48] Feng Xia, Lei Wang, Tao Tang, Xin Chen, Xiangjie Kong, Giles Oatley, and Irwin
King. 2023. CenGCN: Centralized Convolutional Networks with Vertex Imbalance
for Scale-Free Graphs. IEEE Transcations on Knowledge and Data Egineering 35, 5
(2023), 4555â€“4569.
[49] Mingqi Yang, Wenjie Feng, Yanming Shen, and Bryan Hooi. 2023. Towards Better
Graph Representation Learning with Parametererized Decomposition & Filtering.
InICML. 39234â€“39251.
[50] Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Yanming
Shen, and Tie-Yan Liu. 2021. Do Transformers Really Perform Badly for Graph
Representation?. In NeurIPS. 28877â€“28888.
[51] Hao Zhu and Piotr Koniusz. 2021. Simple Spectral Graph Convolution. In ICLR.
 
2081