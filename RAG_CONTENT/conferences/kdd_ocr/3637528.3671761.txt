Causal Estimation of Exposure Shifts with Neural Networks and
an Application to Inform Air Quality Standards in the US
Mauricio Tec
mauriciogtec@hsph.harvard.edu
Harvard University
Cambridge, MA, USAKevin Joseyâˆ—
kevin.josey@cuanschutz.edu
Colorado School of Public Health
Aurora, CO, USA
Oladimeji Mudele
omudele@hsph.harvard.edu
Harvard University
Cambridge, MA, USAFrancesca Dominici
fdominic@hsph.harvard.edu
Harvard University
Cambridge, MA, USA
ABSTRACT
A fundamental task in causal inference is estimating the effect
of a distribution shift in the treatment variable. We refer to this
problem as shift-response function (SRF) estimation. Existing neural
network methods for causal inference lack theoretical guarantees
and practical implementations for SRF estimation. In this paper, we
introduce Targeted Regularization for Exposure Shifts with Neural
Networks (tresnet), a method to estimate SRFs with robustness
and efficiency guarantees. Our contributions are twofold. First, we
propose a targeted regularization loss for neural networks with
theoretical properties that ensure double robustness and asymptotic
efficiency specific to SRF estimation. Second, we extend targeted
regularization to support loss functions from the exponential family
to accommodate non-continuous outcome distributions (e.g., dis-
crete counts). We conduct benchmark experiments demonstrating
tresnetâ€™s broad applicability and competitiveness. We then apply
our method to a key policy question in public health to estimate the
causal effect of revising the US National Ambient Air Quality Stan-
dards (NAAQS) for PM 2.5from 12ğœ‡ğ‘”/ğ‘š3to 9ğœ‡ğ‘”/ğ‘š3. This change
has been recently proposed by the US Environmental Protection
Agency (EPA). Our goal is to estimate the reduction in deaths that
would result from this anticipated revision using data consisting of
68 million individuals across the U.S.1
ACM Reference Format:
Mauricio Tec, Kevin Josey, Oladimeji Mudele, and Francesca Dominici.
2024. Causal Estimation of Exposure Shifts with Neural Networks and an
Application to Inform Air Quality Standards in the US. In Proceedings of
the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3637528.3671761
âˆ—Work conducted while at Harvard University
1The code is available at https://github.com/NSAPH-Projects/tresnet
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.36717611 INTRODUCTION
The field of causal inference has seen immense progress in the past
couple of decades with the development of targeted doubly-robust
methods yielding desirable theoretical efficiency guarantees on
estimates for various causal effects [ 15,30]. These advancements
have recently been incorporated into the neural network (NN)
literature for causal inference via targeted regularization (TR) [ 20,
26]. TR methods produce favorable properties for causal estimation
by incorporating a regularization term into a supervised neural
network model. However, it remains an open task to develop a NN
method that specifically targets the causal effect of a shift in the
distribution for a continuous exposure/treatment variable [ 18]. We
call this problem shift-response function (SRF) estimation. Many
scientific questions can be formulated as an SRF estimation task
[18]. Some notable examples in the literature include estimating
the health effects from shifts to the distribution of environmental,
socioeconomic, and behavioral variables (e.g., air pollution, income,
exercise habits) [7, 18, 27].
One of our objectives is to develop a neural network technique
that addresses a timely and highly prominent regulatory question.
Specifically, the EPA is currently considering whether or not to
revise the National Ambient Air Quality Standards (NAAQS), poten-
tially lowering the acceptable annual average PM2.5concentration
from 12 to 11, 10, or 9 Âµg/m3. We anticipate that the revision to
the NAAQS will ultimately result in a shift to the distribution of
PM2.5concentrations. Our goal is to estimate, for the first time, the
reduction in deaths that would result from this anticipated shift
using causal methods for SRFs.
Contributions. We develop a novel method, called Targeted
Regularization for Exposure Shifts with Neural Networks (tresnet),
which introduces two necessary and generalizable methodological
innovations to the TR literature. First, we use a TR loss targeting
SRFs, ensuring that our estimates retain the properties expected
from TR methods such as asymptotic efficiency and double robust-
ness [ 15]. Given standard regularity conditions, these properties
guarantee that the SRF is consistently estimated when either the
outcome model or a density-ratio model for the exposure shift is
correctly specified, achieving the best possible efficiency rate when
both models are consistently estimated. Second, tresnet accom-
modates non-continuous outcomes belonging to the exponential
family of distributions (such as mortality counts) that frequently
arise in real-world scenarios, including our motivating application.
 
2876
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Mauricio Tec, Kevin Josey, Oladimeji Mudele, and Francesca Dominici
6 8 10 12 14 16
 8
6
4
2
0 Mean
IQR
NAAQS cutoff (g/m3)
Reduction in deaths (%)
Figure 1: Estimated mortality reduction under a cutoff expo-
sure shift lowering the annual PM 2.5in all regions below a
given threshold. Uncertainty bands represent the interquar-
tile range from an ensemble of networks. Data source : US
Medicare claims from 2000â€“2016.
In addition to its suitability for our application, we evaluate the
performance of tresnet in a simulation study tailored for SRF esti-
mation, demonstrating improvements over neural network methods
not specifically designed for SRFs.
Our results contribute to the public debate informing the US
Environmental Protection Agency (EPA) on the effects of modify-
ing air quality standards. A preview of the results (fully developed
in Section 5) is presented in Figure 1. The figure presents the esti-
mated reduction in deaths (%) resulting from various shifts to the
distribution of PM2.5across every ZIP-code in the contiguous US
between 2000 and 2016. These shifts limit the maximum concentra-
tion of PM2.5to the cutoff value for every ZIP-code that exceeds the
cutoff, and otherwise leaves ZIP-codes that do not exceed the cutoff
unchanged. We vary the cutoff in this SRF between 6 Âµg/m3and
16Âµg/m3(x-axis). The y-axis represents the % reduction in deaths
that corresponds with each cutoff threshold. Notably, a NAAQS
threshold of 9 Âµg/m3, would have had the effect of decreasing elder
mortality by 4%. These findings present a data-driven perspective
on the potential health benefits of the EPAâ€™s proposal.
Related work. Neural network-specific methods in causal infer-
ence can broadly be categorized into those focusing on estimating
individualized effects (e.g., [ 3,34]) and those aimed at understand-
ing marginal effects from a population. Various articles in the latter
category â€“ to which our work belongs â€“ use semiparametric the-
ory to derive theoretical guarantees tied to a specific target causal
estimand. Such guarantees are generally focused on double robust-
ness and asymptotic efficiency [ 2,4,15,23]. The efficient influence
function (EIF) plays a pivotal role in this domain by characterizing
the best possible asymptotic efficiency of estimators. The EIF is
also recognized as Neyman orthogonal scores within the double
machine learning literature [16].
Targeted regularization (TR) has emerged as a tool to incorpo-
rate EIF-based methods within deep learning. Notably, the drag-
onnet [26] introduced TR in the context of binary treatment ef-
fects, demonstrating its potential for causal inference. Subsequently,
thevcnet [20] extended the application of TR to the estimation
of exposure-response functions (ERFs), showcasing its utility in
estimating dose-response curves for continuous treatments and
highlighting the adaptability of TR in addressing complex causalquestions. Our work builds on the TR literature recognizing its
unexplored potential for SRF estimation. Indeed, EIF methods have
been applied to scenarios closely related to SRFs outside the neural-
network literature under the stochastic intervention and modified
treatment policy frameworks [ 8,18]. However, their direct integra-
tion with targeted regularization has not been previously under-
taken in the literature â€“ a gap which we address in this work.
Relating to the application, recent studies have investigated the
causal effects of air pollution on mortality using ERFs [ 1,13,33]. Al-
though these methods inform policy regarding the marginal effects
of air pollution on mortality, they cannot adequately address ques-
tions suited for SRFs, which are crucial for analyzing the impact of
air quality regulation changes. The distinction between ERFs and
SRFs, and the significance of SRFs for our application and policy
implications, are elaborated in Sections 2 and 5.
2 PROBLEM STATEMENT: THE CAUSAL
EFFECT OF AN EXPOSURE SHIFT
We let(ğ´,ğ‘Œ, ğ‘¿)denote a unit from the target population, where
ğ´âˆˆA is a continuous exposure variable (also known as the treat-
ment),ğ‘ŒâˆˆY is the outcome of interest, and ğ‘¿âˆˆX are covariates.
We assume a sample of size ğ‘›and denote it as{ğ‘¿ğ‘–,ğ´ğ‘–,ğ‘Œğ‘–}ğ‘›
ğ‘–=1. For
instance, in the application of interest, which is described in detail
in Section 5, ğ‘–represents a zip code location in a given year, ğ´ğ‘–
represents its annual average concentration of PM2.5(ğœ‡ğ‘”/ğ‘š3),ğ‘Œğ‘–is
the number of deaths, and ğ‘¿ğ‘–includes demographic and socioeco-
nomic variables. For simplicity, we will omit the subscript ğ‘–unless
required for clarity or when describing statistical estimators from
samples.
We assume the following general non-parametric structural
causal model (SCM)[22]:
ğ‘Œ=ğ‘“ğ‘Œ(ğ‘¿,ğ´,ğ‘ˆğ‘Œ),
ğ´=ğ‘“ğ´(ğ‘¿,ğ‘ˆğ´),
ğ‘¿=ğ‘“ğ‘¿(ğ‘ˆğ‘¿),(1)
whereğ‘ˆğ‘Œ,ğ‘ˆğ´,ğ‘ˆğ‘¿are exogenous variables. The functions ğ‘“ğ‘Œ,ğ‘“ğ´,ğ‘“ğ‘¿
are deterministic and unknown. We will avoid measure-theoretic
formulations to keep the presentation simple.
The quantities ğ‘Œğ‘=ğ‘“ğ‘Œ(ğ‘¿,ğ‘,ğ‘ˆğ‘Œ)are known as potential out-
comes. Potential outcomes can be divided into two parts. The fac-
tual outcome corresponds with the observed outcome when ğ‘=ğ´.
The counterfactual outcomes are hypothetical results at any point
ğ‘âˆˆA whereğ‘â‰ ğ´. We will typically refer to ğ‘Œğ‘as the counterfac-
tual, as SRFs are tooled for predicting the potential outcome from
unobserved exposures (i.e. the counterfactuals), unless specifically
stated otherwise.
There are two functions that are pivotal in defining and estimat-
ing causal effects. First, the outcome function represents the expected
(counter)factual outcome conditional on covariates, expressed as
ğœ‡(ğ’™,ğ‘):=E[ğ‘Œ|ğ‘¿=ğ‘¥,ğ‘‘ğ‘œ(ğ´=ğ‘)]=E[ğ‘Œğ‘|ğ‘¿=ğ’™].
Unless otherwise specified, all expectations are taken from the
data distribution in Equation (1). The second key function, the
(generalized) propensity score, is the distribution of the exposure
conditional on the covariates, denoted as ğ‘(ğ‘|ğ’™):=ğ‘(ğ´=ğ‘|ğ‘¿=ğ’™).
 
2877Causal Estimation of Exposure Shifts with Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Note thatğ‘is also used generically to represent any density function
with the given arguments; the propensity score being a special case.
Exposure shifts. An exposure shift alters a unitâ€™s exposure from
its observed value ğ´to a modified value Ëœğ´. To help build some
intuition, one example of an exposure shift is a cutoff shift, defined
asËœğ´=min{ğ´,ğ‘}, which caps the exposure to a maximum threshold
ğ‘âˆˆR. Another example is a percent reduction shift Ëœğ´=ğ‘ğ´in which,
for instance, a value of ğ‘=0.9would signify a 10%reduction to
the observed exposures. These shifts are depicted in Figure 2. As
in our application of interest, developed in detail in Section 5, Ëœğ´
represents the (hypothetical) annual exposure to PM2.5that would
have occurred in a particular zip code and year if an alternate policy
(relative to the current NAAQS) had been implemented.
Formally, we define an exposure shift as a counterfactual expo-
sure distribution Ëœğ´âˆ¼Ëœğ‘(Ëœğ´|ğ‘¿), replacing the propensity score in
the observed data distribution. We do not assume any advanced
knowledge of the shifted distribution Ëœğ‘nor the analytical form
of the shift. Instead, we can observe samples from the shifted dis-
tribution, realized as pairs of unshifted-shifted exposures (ğ´,Ëœğ´).
An alternative representation is that of a modified treatment policy
[8], where the exposure shift can arise from a (possibly unknown)
stochastic or deterministic transform â€“ Ëœğ´=ğ‘‘(ğ´,ğ‘¿).
Importantly, while ğ´and Ëœğ´may seem like different objects due
to the notation, they in fact refer to the same data element â€“ the
exposure or treatment. The tilde notation â€œ âˆ¼" is helpful to em-
phasize whether itâ€™s being sampled from the shifted or unshifted
distributions.
The estimand of interest: the SRF. The quantity of interest ğœ“is
the expected counterfactual outcome induced by the exposure shift
after replacing ğ‘(ğ´|ğ‘¿)with Ëœğ‘(Ëœğ´|ğ‘¿):
ğœ“:=Eh
ğ‘ŒËœğ´i
=Eğ‘¿âˆ¼ğ‘(ğ‘¿)h
EËœğ´âˆ¼Ëœğ‘(Ëœğ´|ğ‘¿)
ğœ‡(ğ‘¿,Ëœğ´)|ğ‘¿i
.(2)
The SRF is a key estimand in the context of exposure shifts, as it
allows us to estimate the effect of a policy-relevant shift in the
distribution of a continuous exposure.
Under some regularity conditions, established later in this sec-
tion, the estimand can be rewritten using the importance sampling
formula as
ğœ“=E[ğœ‡(ğ‘¿,ğ´)ğ‘¤(ğ‘¿,ğ´)].
ğ‘¤(ğ’™,ğ‘):=Ëœğ‘(ğ‘|ğ’™)/ğ‘(ğ‘|ğ’™).(3)
We will derive estimators of ğœ“using estimators of ğœ‡andğ‘¤in
Section 3.
Comparison with traditional causal effects. Exposure-response
functions are the most common estimands in the causal infer-
ence literature for continuous exposures. Also known as a dose-
response curve, an ERF can be described as the mapping ğœ‰(ğ‘)=
Eğ‘¿âˆ¼ğ‘ğ‘¿[ğœ‡(ğ‘¿,ğ‘)].
One can consider ERFs as a special case of an SRF in which, for
each treatment value ğ‘âˆˆA, the quantity of interest is the average
counterfactual outcome where the exposure is assigned to ğ‘for
all units. That is, it can be seen as a limiting case of an SRF when
Ëœğ‘is a degenerate point-mass distribution at ğ‘for all units. This
observation is the primary reason why SRFs are better suited for our
motivating application as ERFs do not allow us to consider scenarios
where each unit is given a different exposure value shifted from itsobserved value. A visual example is shown in Figure 2c. At each
point of the curve, an ERF describes the average outcome when
allunits experience the same PM2.5value. By contrast, SRFs allow
us to estimate the average outcome when each unit experiences a
different PM2.5value, as would occur under the NAAQS revision.
Moreover, ERFs require extrapolating the outcome estimates to
regions where the positivity condition fails [ 11], that is, regions of
the joint exposure-covariate space where no data is available (see
Figure 2c). Extrapolation to such regions is unnecessary to estimate
SRFs efficiently. This insight is supported by our simulation and
experiment results in Section 4.
Causal identification. The target estimand ğœ“can be expressed
as a functional of the observable data distribution under standard
assumptions, which are:
Assumption 2.1 (Unconfoundedness). There are no backdoor paths
fromğ´toğ‘Œin the SCM in Equation (1), implying that ğ´âŠ¥ âŠ¥ğ‘Œğ‘|ğ‘¿
for allğ‘âˆˆA;
Assumption 2.2 (Positivity). There are constants ğ‘€1,ğ‘€2>0such
thatğ‘€1â‰¤ğ‘(ğ‘|ğ’™)/Ëœğ‘(ğ‘|ğ’™)â‰¤ğ‘€2for all(ğ‘,ğ’™)such that Ëœğ‘(ğ‘|ğ’™)>0.
The first assumption ensures that E[ğ‘Œğ‘|ğ‘¿=ğ’™]=E[ğ‘Œ|ğ‘¿=
ğ’™,ğ´=ğ‘]. This result is sometimes known as causal identification
since it allows us to express the causal effect of ğ´onğ‘Œas a function
of the observed data. A formal proof is given in the appendix. The
second assumption implies that the density ratio in Equation (3)
is well-defined and behaved. Notice that the notion of positivity
used here, as required by SRFs, is generally weaker than the typical
positivity assumption in the standard causal inference literature
requiringğ‘€1â‰¤ğ‘(ğ‘|ğ’™)â‰¤ğ‘€2for all(ğ’™,ğ‘)[18].
Multiple shifts. Under the framework outlined so far, it is possible
to estimate the effect of multiple exposure shifts simultaneously. We
simply let Ëœğ‘âˆˆËœPdenote the set of finite exposure shifts of interest
and adopt the vectorized notation ğ’˜=(ğ‘¤Ëœğ‘)Ëœğ‘âˆˆËœP,ğ=(ğœ“Ëœğ‘)Ëœğ‘âˆˆËœP,
and Ëœğ‘¨=(Ëœğ´Ëœğ‘)Ëœğ‘âˆˆËœP.
3 ESTIMATING SRFS WITH TARGETED
REGULARIZATION FOR NEURAL NETS
As we have suggested earlier, an estimator of the SRF can be derived
from estimators of the outcome and density ratio functions. Using
TR, we will obtain an estimator Ë†ğtrthat â€œconverges efficientlyâ€ to
the true ğat a rate in accordance with the prevailing semiparamet-
ric efficiency theory surrounding robust causal effect estimation
[16].
Additional notation. To describe the necessary theoretical re-
sults based on semiparametric theory, we require some additional
notation. Given a family of functions ğ‘“âˆˆ F , denoteâˆ¥Fâˆ¥âˆ=
supğ‘“âˆˆFâˆ¥ğ‘“âˆ¥âˆ. The sample Rademacher complexity is denoted as
Radğ‘›(F)=supğ‘“âˆˆF|1
ğ‘›Ãğ‘›
ğ‘–=1ğœğ‘–ğ‘“(ğ‘ˆğ‘–)|whereğœğ‘–are independent
and identically distributed Rademacher random variables satisfy-
ingğ‘(ğœğ‘–=1)=ğ‘(ğœğ‘–=âˆ’1)=1/2. The Rademacher complexity
measures the â€œdegrees of freedom" of an estimating class of func-
tions. We use ğ‘‚ğ‘andğ‘œğ‘to denote stochastic boundedness and
convergence in probability, respectively. Given a random variable
ğ‘ˆâˆ¼D, denote D(ğ‘“):=Eğ‘ˆâˆ¼D[ğ‘“(ğ‘ˆ)]. We also let Dğ‘›denote the
 
2878KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Mauricio Tec, Kevin Josey, Oladimeji Mudele, and Francesca Dominici
(a) Cutoff shift
 (b) Percent reduction shift
 (c) ERF
Figure 2: Two examples of exposure shifts with their implied counterfactuals and, for comparison, the implied counterfactuals
of an exposure-response function at a given treatment value.
empirical distribution of Dgiven an iid sample {ğ‘ˆğ‘–}ğ‘›
ğ‘–=1. It follows
thatDğ‘›(ğ‘“)=1
ğ‘›Ãğ‘›
ğ‘–=1ğ‘“(ğ‘ˆğ‘–). Lastly, let ğ‘¶=(ğ‘¿,ğ´,Ëœğ‘¨,ğ‘Œ)âˆ¼Pdenote
an element of the augmented data generating process.
The efficient influence function (EIF) The EIF is a fundamental
function in semiparametric theory [ 16]. It is denoted as the function
ğ‹for an observation ğ‘¶. The EIF characterizes the gradient of the
target estimand with respect to a small perturbation in the data
distribution. The form of the EIF is specific to the target estimand.
For the SRF in Equation (2), the EIF is given by
ğ‹(ğ‘¶;ğ,ğœ‡,ğ’˜):=ğ’˜(ğ‘¿,ğ´)(ğ‘Œâˆ’ğœ‡(ğ‘¿,ğ´))+ğœ‡(ğ‘¿,Ëœğ‘¨)âˆ’ğ.(4)
We provide a formal derivation in the appendix. The reader can
refer to Tsiatis [29] and Kennedy [16] for a more comprehensive
introduction to the nature and utility of influence functions. The
importance of EIFs for causal estimation relies on the following two
properties. First, the best possible variance among the family of
regular, asymptotically linear estimators of ğis bounded below by
P(ğ‹ğ‹âŠ¤). This lower bound is known as the efficiency rate. Second,
the EIF can be constructed as a function of (ğ,ğœ‡,ğ’˜). As it turns out,
if a tuple of estimators (Ë†ğ,Ë†ğœ‡,Ë†ğ’˜)satisfies the empirical estimating
equation (EEE) given by Pğ‘›(ğ‹(Ë†ğ,Ë†ğœ‡,Ë†ğ’˜))=0, then Ë†ğachieves the
efficiency rate asymptotically.
The following observation offers an interpretation to the EEE. If
(Ë†ğ,Ë†ğœ‡,Ë†ğ’˜)satisfy the EEE, then Ë†ğcan be decomposed in terms of a
debiasing component of the residual error and a plugin estimator
for the marginalized average of the mean response:
Ë†ğ=1
ğ‘›Ãğ‘›
ğ‘–=1Ë†ğ’˜(ğ‘¿ğ‘–,ğ´ğ‘–)(ğ‘Œğ‘–âˆ’Ë†ğœ‡(ğ‘¿ğ‘–,ğ´ğ‘–))
|                                      {z                                      }
debiasing term+1
ğ‘›Ãğ‘›
ğ‘–=1Ë†ğœ‡(ğ‘¿ğ‘–,Ëœğ‘¨ğ‘–)
|                {z                }
plugin estimator(5)
This heuristic is crucial for the development of the TR loss in the
next section.
3.1 Targeted Regularization for SRFs
An immediate approach to obtain a doubly-robust estimator satis-
fying the EEE would be to use the right-hand side of Equation (5)
as a definition of an estimator given nuisance function estimators Ë†ğœ‡
and Ë†ğ’˜. Such an estimator is called the augmented inverse-probability
weighting (AIPW) estimator for exposure shifts in analogy to the
AIPW estimators for traditional average causal effects (ATE andERF) [ 23,24]. However, itâ€™s been noted in the causal inference liter-
ature that, empirically, relying on the debiasing term of Equation (5)
causes AIPW-type estimators to have suboptimal performance in
finite samples [ 26,30]. Instead, targeted learning seeks an estimator
that, by construction, satisfies the EEE without requiring the debi-
asing term. TR achieves this goal by learning a perturbed outcome
model Ëœğœ‡using a special regularization loss.
Generalized TR for outcomes in the exponential family. We will
derive the TR loss for SRFs while also extending the TR framework
to accommodate non-continuous outcomes from the exponential
family of distributions.
First, we say that the outcome follows a conditional distribu-
tion from the exponential family if ğ‘(ğ‘Œ|ğ‘¿,ğ´)âˆexp(ğ‘Œğœ‚(ğ‘¿,ğ´)âˆ’
Î›(ğœ‚(ğ‘¿,ğ´))for some function ğœ‚:XÃ—Aâ†’ R. The familyâ€™s canon-
ical link function ğ‘”is defined by the identity ğ‘”(E[ğ‘Œ|ğ‘¿,ğ´])=
ğœ‚(ğ‘¿,ğ´). For all distributions in the exponential family, ğ‘”is invert-
ible [ 17]. Exponential families allow us to consider the usual mean-
squared error and logistic regression as special cases. They also
enable modeling count outcomes as in our motivating application.
In this setting, we set Î›(ğœ‚)=ğ‘’ğœ‚andğ‘”(ğœ‡)=log(ğœ‡)â€“ the canonical
environment for Poisson regression. The following theorem forms
the basis for the TR estimator.
Theorem 1. Letğdenote a perturbation parameter and define
Ltr(ğœ‡NN,ğ’˜NN,ğ)(ğ‘¶)=
Î›(ğ‘”(ğœ‡NN(ğ‘¿,ğ´))+ğ)âˆ’(ğ‘”(ğœ‡NN(ğ‘¿,ğ´))+ğ)ğ‘Œ.
Rtr(ğœ‡NN,ğ’˜NN,ğ)=Pğ‘›(Ltr(ğœ‡NN,ğ’˜NN,ğ)).(6)
Then(ğœ•Rtr
ğœ•ğ)(ğœ‡NN,ğ’˜NN,ğ)=0if and only if
1
ğ‘›Ãğ‘›
ğ‘–=1ğ’˜NN(ğ‘¿ğ‘–,ğ´ğ‘–)(ğ‘Œğ‘–âˆ’ğ‘”âˆ’1(ğ‘”(ğœ‡NN(ğ‘¿ğ‘–,ğ´ğ‘–))+ğ)))=0.
Proof. A key property of an exponential family is Î›â€²(ğœ‚)=
ğ‘‘
ğ‘‘ğœ‚Î›(ğœ‚)=ğ‘”âˆ’1(ğ¸[ğ‘Œ|ğœ‚])[17]. Noting thatğ‘‘
ğ‘‘ğğ‘”(Ëœğœ‡NN(ğ‘¿,ğ´))=ğ’˜NN(ğ‘¿,ğ´)
for allğœ‡NN,ğ’˜NNğ, and using the chain rule, we have:
 
2879Causal Estimation of Exposure Shifts with Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
0=ğ‘‘
ğ‘‘ğRtr(Ë†ğœ‡,Ë†ğ’˜,Ë†ğ)
=1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1d
dğğ=Ë†ğ{Î›(ğ‘”(Ëœğœ‡(ğ‘¿,ğ´)))âˆ’ğ‘Œğ‘”(Ëœğœ‡(ğ‘¿,ğ´))}
=1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1
ğ‘”âˆ’1(ğ‘”(Ëœğœ‡(ğ‘¿,ğ´)))Ë†ğ’˜(ğ‘¿,ğ´)âˆ’ğ‘ŒË†ğ’˜(ğ‘¿,ğ´)	
=1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1Ë†ğ’˜(ğ‘¿,ğ´)(Ëœğœ‡(ğ‘¿,ğ´)âˆ’ğ‘Œ).(7)
The fact that Ë†ğtr=1
ğ‘›Ãğ‘›
ğ‘–=1Ëœğœ‡(ğ‘¿ğ‘–,Ëœğ´ğ‘–)satisfies the empirical estimat-
ing equation follows trivially from the fact that Pğ‘›ğœ‘(Ë†ğtr,Ëœğœ‡,Ë†ğ’˜)=
1
ğ‘›Ãğ‘›
ğ‘–=1Ë†ğ’˜(ğ‘¿,ğ´)(ğ‘Œâˆ’Ëœğœ‡(ğ‘¿,ğ´))+1
ğ‘›Ãğ‘›
ğ‘–=1Ëœğœ‡(ğ‘¿ğ‘–,Ëœğ´ğ‘–)âˆ’Ë†ğtr. The first
term is zero because of the above results while the last two terms
cancel each other by definition. â–¡
Notice that the condition ğœ•Rtr/ğœ•ğ=0in the theorem is achieved
at the local minima of Rtr. Motivated by this observation, we next
define the total TR loss as
R(ğœ‡NN,ğ’˜NN,ğ):=Rğœ‡(ğœ‡NN)+ğ›¼Rğ’˜(ğ’˜NN)+ğ›½ğ‘›Rtr(ğœ‡NN,ğ’˜NN,ğ)
whereRğœ‡andRğ’˜are the empirical risk functions used to learn ğœ‡
andğ’˜(details in Section 3.2), ğ›¼>0is a hyperparameter, and ğ›½ğ‘›is
a regularization weight satisfying ğ›½ğ‘›â†’0. The latter condition is
needed to ensure statistical consistency, as first discussed by Nie
et al. [20] for ERF estimation.
Since ğonly appears in the regularization term, the full loss
in Equation (8) preserves the result thatğœ•Rtr
ğœ•ğ=0upon optimiza-
tion Then, the TR estimator Ë†ğtris defined as the solution of the
optimization problem:
(Ë†ğœ‡,Ë†ğ’˜,Ë†ğ)=arg min
ğœ‡NN,ğ’˜NN,ğR(ğœ‡NN,ğ’˜NN,ğ)
Ë†ğtr:=1
ğ‘›Ãğ‘›
ğ‘–=1ğ‘”âˆ’1(ğ‘”(Ë†ğœ‡(ğ‘¿,ğ´))+ Ë†ğ)).(8)
In the theorem below we introduce the main result establishing
thedouble robustness andconsistency properties of our TR estimator:
Theorem 2. LetMandWbe classes of functions such that
Ë†ğœ‡,ğœ‡âˆˆM and Ë†ğ’˜,ğ’˜âˆˆW . Suppose assumptions 2.1 and 2.2 hold,
and that the following regularity conditions hold: (i) âˆ¥Mâˆ¥âˆ<âˆ,
âˆ¥Wâˆ¥âˆ<âˆ,âˆ¥1/Wâˆ¥âˆ<âˆ; (ii) either one model is correctly spec-
ified ( Ë†ğœ‡=ğœ‡orË†ğ’˜=ğ’˜), or both function classes have a vanishing
complexity Radğ‘›(M)=ğ‘‚(ğ‘›âˆ’1/2)andRadğ‘›(W) =ğ‘‚(ğ‘›âˆ’1/2); (iii)
the loss function in Equation (6)is Lipschitz; (iv) Î›andğ‘”are twice
continuously differentiable. Then, the following statements are true:
(1)The outcome and density ratio estimators of TR are consistent.
That is,âˆ¥Ë†ğœ‡âˆ’ğœ‡âˆ¥2=ğ‘œğ‘(1)andâˆ¥Ë†ğ’˜âˆ’ğ’˜âˆ¥2=ğ‘œğ‘(1).
(2)The estimator Ë†ğtrsatisfiesâˆ¥Ë†ğtrâˆ’ğâˆ¥âˆ=ğ‘‚ğ‘(ğ‘›âˆ’1/2+ğ‘Ÿ1(ğ‘›)ğ‘Ÿ2(ğ‘›))
wheneverâˆ¥Ë†ğœ‡âˆ’ğœ‡âˆ¥âˆ=ğ‘‚ğ‘(ğ‘Ÿ1(ğ‘›))andâˆ¥Ë†ğ’˜âˆ’ğ’˜âˆ¥âˆ=ğ‘‚ğ‘(ğ‘Ÿ2(ğ‘›)).
Theorem 2 shows that the TR learner of the SRF achieves â€œop-
timalâ€ root- ğ‘›convergence when ğ‘Ÿ1(ğ‘›)=ğ‘Ÿ2(ğ‘›)=ğ‘›âˆ’1/4or when
eitherğ‘Ÿ1orğ‘Ÿ2vanishes. Using standard arguments involving con-
centration inequalities, the Lipschitz assumption placed on the loss
function can be relaxed by assuming that the loss function has a
vanishing Rademacher complexity [31].Proof. The proof strategy follows Nie et al . [20] but is tailored
to the SRF case and the more general exponential family of loss
functions. We proceed in two steps.
Step 1: showing consistency of the outcome and density ratio models.
Denote the population risk as
Râˆ—(ğœ‡NN,ğ’˜NN):=PL(ğœ‡NN,ğ’˜NN,0),
whereL(ğœ‡NN,ğ’˜NN,0)is the loss function in Equation (6) without
the targeted regularization. The minimizers of Râˆ—are denoted ğœ‡âˆ—
andğ’˜âˆ—. They are the estimators of (ğœ‡,ğ’˜)under infinite data. We will
now bound the risk loss, showing that the risk of the finite-sample
estimators(Ë†ğ,Ë†ğ’˜)minimizing Equation (6) is sufficiently close to
that of(ğœ‡âˆ—,ğ’˜âˆ—). Precisely, we shall show that
R(Ë†ğœ‡,Ë†ğ’˜)âˆ’R(ğœ‡âˆ—,ğ’˜âˆ—)=ğ‘œ(1)+ğ‘‚ğ‘(ğ‘›âˆ’1/2). (9)
To prove this fact, we first note that
0â‰¤Râˆ—(Ë†ğœ‡,Ë†ğ’˜)âˆ’Râˆ—(ğœ‡âˆ—,ğ’˜âˆ—)
=(R(Ë†ğœ‡,Ë†ğ’˜,0)âˆ’R(ğœ‡âˆ—,ğ’˜âˆ—,0))
(Pâˆ’Pğ‘›)L(Ë†ğœ‡,Ë†ğ’˜,0)+(Pğ‘›âˆ’P)L(ğœ‡âˆ—,ğ’˜âˆ—,0).(10)
The first inequality is because of the definition of the risk minimizer
and for the second one we added and subtracted the empirical risk
and rearranged the terms.
Observe that the second and third terms in the last expression
are empirical processes, suggesting we can use the uniform law of
large numbers (ULLN). Indeed, the regularity assumptions on the
Rademacher complexity provide a sufficient condition [ 31]. Addi-
tionally, the order of the Rademacher complexity is preserved under
Lipschitz transforms, then, using that the loss is Lipschitz, it follows
that the classF={L(ğœ‡NN,ğ’˜NN,0):ğœ‡NNâˆˆM,ğ’˜NNâˆˆW} has a
Rademacher complexity of order ğ‘‚(ğ‘›âˆ’1/2). Further, uniform bound-
edness is also preserved under Lispschitz transformations. Thus,
the uniform law of large numbers applies, implying that the last
two terms are ğ‘‚ğ‘(ğ‘›âˆ’1/2). Note that the Lipschitz condition can be
relaxed by the direct assumption that Lsatisfies the boundedness
and complexity conditions for the ULLN [31].
We now bound the first term. We begin by adding and subtracting
the regularization terms, and compute:
R(Ë†ğœ‡,Ë†ğ’˜,0)âˆ’R(ğœ‡âˆ—,ğ’˜âˆ—,0)
=R(Ë†ğœ‡,Ë†ğ’˜,Ë†ğ)âˆ’R(ğœ‡âˆ—,ğ’˜âˆ—,0)
+ğ›½ğ‘›(Rtr(ğœ‡âˆ—,ğ’˜âˆ—,0)âˆ’Rtr(Ë†ğœ‡,Ë†ğ’˜,Ë†ğ))
â‰¤(ğ‘)ğ›½ğ‘›(Rtr(ğœ‡âˆ—,ğ’˜âˆ—,0)âˆ’Rtr(Ë†ğœ‡,Ë†ğ’˜,Ë†ğ))
=(ğ‘)ğ›½ğ‘›Pğ‘›(Lğœ‡(ğœ‡âˆ—)+ğ‘‚(1)).
=ğ›½ğ‘›((Pğ‘›âˆ’P)Lğœ‡(ğœ‡âˆ—)+Rğœ‡(ğœ‡âˆ—)+ğ‘‚(1))
=(ğ‘)ğ›½ğ‘›(ğ‘‚ğ‘(ğ‘›âˆ’1/2))+ğ‘‚(1))
=(ğ‘‘)ğ‘‚ğ‘(ğ‘›âˆ’1/2)+ğ‘œ(1)(11)
Inequality (a) is due to (Ë†ğœ‡,Ë†ğ’˜,Ë†ğ)being a minimizer for the reg-
ularized risk; (b) is the result of Rtr(Ë†ğœ‡,Ë†ğ’˜,Ë†ğ)being bounded be-
low since the exponential family of distributions is log-concave
andRtr(ğœ‡âˆ—,ğ’˜âˆ—,0)=Pğ‘›Lğœ‡(ğ‘”(ğœ‡âˆ—)); (c) uses the uniform law of
large numbers from the Rademacher complexity and the uniform
boundedness, and the fact that Lis Lipschitz; (d) follows from
 
2880KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Mauricio Tec, Kevin Josey, Oladimeji Mudele, and Francesca Dominici
ğ›½ğ‘›â†’0. Combining Equation (10) and Equation (11), we get
Râˆ—(Ë†ğœ‡,Ë†ğ’˜)âˆ’Râˆ—(ğœ‡âˆ—,ğ’˜âˆ—)=ğ‘œğ‘(1).
The result now follows from observing that the population risk
has a unique minimizer up to the reparameterization of the network
weights. Hence,âˆ¥Ë†ğœ‡âˆ’ğœ‡âˆ¥2=ğ‘œğ‘(1)andâˆ¥Ë†ğ’˜âˆ’ğ’˜âˆ¥2=ğ‘œğ‘(1).
Step 2: Proving convergence and efficiency of Ë†ğtr. Direct compu-
tation gives
âˆ¥Ë†ğtrâˆ’ğâˆ¥
=âˆ¥1
ğ‘›Ãğ‘›
ğ‘–=1Ëœğœ‡(ğ‘¿ğ‘–,Ëœğ´ğ‘–)âˆ’ğâˆ¥
=(ğ‘)âˆ¥1
ğ‘›Ãğ‘›
ğ‘–=1{Ëœğœ‡(ğ‘¿ğ‘–,Ëœğ´ğ‘–)+Ë†ğ’˜(ğ‘¿ğ‘–,ğ´ğ‘–)(ğ‘Œğ‘–âˆ’Ëœğœ‡(ğ‘¿ğ‘–,ğ´ğ‘–))}âˆ’ ğâˆ¥
=(ğ‘)âˆ¥E[Ë†ğ’˜(ğ‘¿,ğ´)(ğ‘Œâˆ’Ëœğœ‡(ğ‘¿,ğ´))+ Ëœğœ‡(ğ‘¿,Ëœğ´)]âˆ’ğâˆ¥+ğ‘‚ğ‘(ğ‘›âˆ’1/2)
=(ğ‘)âˆ¥E[Ë†ğ’˜(ğ‘¿,ğ´)(ğœ‡(ğ‘¿,ğ´)âˆ’Ëœğœ‡(ğ‘¿,ğ´))+ Ëœğœ‡(ğ‘¿,Ëœğ´)]âˆ’ğâˆ¥+ğ‘‚ğ‘(ğ‘›âˆ’1/2)
=(ğ‘‘)âˆ¥E[(Ë†ğ’˜(ğ‘¿,ğ´)âˆ’ğ’˜(ğ‘¿,ğ´))(ğœ‡(ğ‘¿,ğ´)âˆ’Ëœğœ‡(ğ‘¿,ğ´))]âˆ¥+ğ‘‚ğ‘(ğ‘›âˆ’1/2),
(12)
where (a) is by the property of the targeted regularization, namely,
1
ğ‘›Ãğ‘›
ğ‘–=1Ë†ğ’˜(ğ‘¿ğ‘–,ğ´ğ‘–)(ğ‘Œğ‘–âˆ’Ëœğœ‡(ğ‘¿ğ‘–,ğ´ğ‘–))=0; (b) is because of the uniform
concentration of the empirical process, again using the vanishing
Rademacher complexity and uniform boundedness; (c) integrates
overğ‘¦; (d) uses the definition of ğœ“and the importance sampling
formula with ğ’˜. Since the link function ğ‘”is continuously differen-
tiable, invertible and strictly monotone, then by the mean value
theorem there exists ğâ€²âˆˆ(0,Ë†ğ)such that
Ëœğœ‡(ğ‘¿,ğ´)=ğ‘”âˆ’1(ğ‘”(Ë†ğœ‡(ğ‘¿,ğ´))+ Ë†ğ)
=Ë†ğœ‡(ğ‘¿,ğ´)+(ğ‘”âˆ’1)â€²(ğ‘”(Ë†ğœ‡(ğ‘¿,ğ´))+ğâ€²)Ë†ğ.
From the uniform boundedness and smoothness of the link function,
we have that Ë†ğ‘=(ğ‘”âˆ’1)â€²(ğ‘”(Ë†ğœ‡(ğ‘¿,ğ´)+ğâ€²)<ğ¶for some constant
ğ¶>0. Then, using the above result in the last term of Equation (12),
we obtain
âˆ¥E[(Ë†ğ’˜(ğ‘¿,ğ´)âˆ’ğ’˜(ğ‘¿,ğ´))(ğœ‡(ğ‘¿,ğ´)âˆ’Ëœğœ‡(ğ‘¿,ğ´))]âˆ¥
â‰¤E[(Ë†ğ’˜(ğ‘¿,ğ´)âˆ’ğ’˜(ğ‘¿,ğ´))(ğœ‡(ğ‘¿,ğ´)âˆ’Ë†ğœ‡(ğ‘¿,ğ´))]
+ğ¶âˆ¥(Ë†ğ’˜(ğ‘¿,ğ´)âˆ’ğ’˜(ğ‘¿,ğ´))Ë†ğâˆ¥
â‰¤ğ‘‚ğ‘(ğ‘Ÿ1(ğ‘›)ğ‘Ÿ2(ğ‘›))+ğ‘‚ğ‘(ğ‘Ÿ2(ğ‘›))âˆ¥Ë†ğâˆ¥(13)
To complete the proof, we will show that âˆ¥Ë†ğâˆ¥=ğ‘‚ğ‘(ğ‘Ÿ1(ğ‘›))+
ğ‘‚ğ‘(ğ‘›âˆ’1/2). Letting Ë†ğ‘ğ‘–be as in the Taylor expansion above, we can
re-arrange the targeted regularization condition such that
0=ğ‘‘
ğ‘‘ğRtr(Ë†ğœ‡,Ë†ğ’˜,Ë†ğ)
=1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1Ë†ğ’˜(ğ‘¿,ğ´)(Ë†ğœ‡(ğ‘¿,ğ´)âˆ’ğ‘Œ)+1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1Ë†ğ’˜(ğ‘¿ğ‘–,ğ´ğ‘–)Ë†ğ‘ğ‘–Ë†ğ.
Hence, we can write Ë†ğwith the closed-form expression
Ë†ğ=arg min
ğRtr(Ë†ğœ‡,Ë†ğ’˜,ğ)=ğ‘›âˆ’1Ãğ‘›
ğ‘–=1Ë†ğ’˜(ğ‘¿ğ‘–,ğ´ğ‘–)(ğ‘Œğ‘–âˆ’Ë†ğœ‡(ğ‘¿ğ‘–,ğ´ğ‘–))
ğ‘›âˆ’1Ãğ‘›
ğ‘–=1Ë†ğ‘ğ‘–Ë†ğ’˜(ğ‘¿ğ‘–,ğ´ğ‘–)2.
Observe now that Ë†ğ‘ğ‘–is uniformly lower bounded since the denomi-
nator is uniformly bounded in a neighborhood of the solution due
to the assumption âˆ¥1/Wâˆ¥âˆ<âˆ, andğ‘”is strictly monotone and
Figure 3: tresnet architecture using a head for the density
ratio model and a head for the outcome model.
continuously differentiable. Hence, there is ğ¶â€²>0such that
âˆ¥Ë†ğâˆ¥â‰¤ğ¶â€²âˆ¥ğ‘›âˆ’1Ãğ‘›
ğ‘–=1Ë†ğ’˜(ğ‘¿ğ‘–,ğ´ğ‘–)(ğ‘Œğ‘–âˆ’Ë†ğœ‡(ğ‘¿ğ‘–,ğ´ğ‘–))âˆ¥
â‰¤(ğ‘)ğ¶â€²âˆ¥E[Ë†ğ’˜(ğ‘¿,ğ´)(ğ‘Œâˆ’Ë†ğœ‡(ğ‘¿,ğ´))âˆ¥+ğ‘‚ğ‘(ğ‘›âˆ’1/2)
â‰¤(ğ‘)ğ‘‚ğ‘(ğ‘Ÿ1(ğ‘›))+ğ‘‚ğ‘(ğ‘›âˆ’1/2),(14)
where (a) uses the uniform concentration of the empirical process
and (b) again uses the uniform boundedness of Ë†ğ’˜. The proof now
follows from combining equations (12), (13), and (14). â–¡
3.2 Architectures for Estimating the Outcome
and Density Ratio Functions
Neural network architectures for nuisance function estimation have
been widely investigated in causal inference (see Farrell et al . [9]for
a review). We use the architectures proposed in the TR literature
as a building block, particularly for continuous treatments [ 20].
Nevertheless, previous work in TR has not yet investigated the
architectures required for SRF estimation. In particular, we require
a new architecture to estimate the density ratio ğ’˜. Rather, previ-
ous works have primarily focused on architectures for estimating
propensity scores as required by traditional causal effect estimation
(e.g. for estimating ATEs and ERFs).
We describe a simple yet effective architecture for estimating
ğœ‡andğ’˜. To keep the notation simple, we will write ğ‘“ğœƒto de-
note generic output from a neural network indexed by weights
ğœƒ. The architecture has three components, illustrated in Figure 3.
The first one maps the confounders ğ‘¿to a latent representation
ğ’=ğ‘“ğœƒğ‘(ğ‘¿)âˆˆRğ‘‘. This component will typically be a multi-layer
perception (MLP). The second and third components are the out-
come and density-ratio heads, which are functions of ğ’and the
treatment. We describe all three components in detail below.
Outcome model Recall that we assume the outcome ğ‘Œfollows
a conditional distribution from the exponential family. That is,
ğ‘(ğ‘Œ|ğ‘¿,ğ´)âˆ exp(ğ‘Œğœ‚(ğ‘¿,ğ´)âˆ’Î›(ğœ‚(ğ‘¿,ğ´))with an invertible link
functionğ‘”satisfyingğœ‡(ğ‘¿,ğ´)=ğ‘”âˆ’1(ğœ‚(ğ‘¿,ğ´)). We can identify the
canonical parameter ğœ‚with the output of the neural network and
learn Ë†ğœ‡by minimizing the empirical risk
Rğœ‡(ğœ‡NN)=1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1n
Î›(ğ‘”âˆ’1(ğœ‡NN(ğ’ğ‘–,ğ´ğ‘–))âˆ’ğ‘Œğ‘”âˆ’1(ğœ‡NN(ğ’ğ‘–,ğ´ğ‘–))o
.
(15)
 
2881Causal Estimation of Exposure Shifts with Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 1: Experiment results. The table shows theâˆšmise across 100 random seeds with 95% confidence intervals computed with
the asymptotic normal formula.
Spline-based varying coefficients Piecewise linear varying coefficients
Dataset aipw vc outcome vc tresnet vcâˆ—vcnet aipw pl drnet tresnet plâˆ—drnet+tr erf
ihdp 3.15 (0.37) 2.19 (0.06) 0.61 (0.03) 0.63 (0.03) 1.18 (0.14) 2.36 (0.06) 0.15 (0.02) 0.19 (0.02)
news 1.5 (0.19) 3.65 (0.04) 0.18 (0.02) 0.28 (0.03) 0.99 (0.12) 0.99 (0.1) 0.17 (0.01) 0.26 (0.03)
sim-B 4.1 (0.57) 0.5 (0.05) 0.26 (0.03) 0.29 (0.04) 1.46 (0.2) 1.6 (0.2) 0.14 (0.02) 0.16 (0.02)
sim-N 5.69 (0.64) 0.52 (0.05) 0.32 (0.02) 0.32 (0.03) 1.81 (0.25) 0.95 (0.06) 0.14 (0.01) 0.15 (0.01)
tcga-1 1.13 (0.08) 0.63 (0.02) 0.8 (0.01) 0.87 (0.03) 0.76 (0.05) 0.62 (0.02) 0.61 (0.02) 0.69 (0.03)
tcga-2 0.76 (0.09) 0.24 (0.02) 0.18 (0.01) 0.24 (0.02) 0.36 (0.05) 0.17 (0.01) 0.12 (0.0) 0.16 (0.01)
tcga-3 0.83 (0.11) 0.38 (0.03) 0.1 (0.01) 0.15 (0.02) 0.59 (0.06) 0.59 (0.04) 0.08 (0.01) 0.15 (0.02)
(a) Performance of tresnet in two varying-coefficient architectures.
experiment outcome vcw/poisson lossâˆ—outcome vcw/mse loss tresnet vcw/poisson lossâˆ—tresnet vcw/mse loss
ihdp 18.82 (3.18) 3726.92 (357.31) 2.04 (0.08) 10986.43 (211.99)
news 3.41 (0.25) 372.24 (52.02) 0.33 (0.05) 1187.94 (100.8)
sim-B 1222.61 (1269.53) 8433.98 (1327.22) 1113.58 (1270.49) 16902.41 (1233.54)
sim-N 50.72 (4.45) 2491.63 (310.36) 4.6 (0.22) 18062.85 (243.2)
tcga-1 184.89 (6.67) 6682.91 (474.32) 40.56 (19.2) 16307.15 (232.64)
tcga-2 48.3 (1.44) 5854.08 (483.41) 398.82 (143.96) 16112.02 (186.99)
tcga-3 18.27 (2.73) 14381.06 (516.25) 12.92 (2.3) 8565.17 (447.13)
(b) Performance of tresnet with and without the Poisson GLM formulation for count-based outcomes.
Next, we need to select a functional form for the neural network.
An MLP parameterization with the concatenated inputs of (ğ’,ğ´)â€“
the naÃ¯ve choiceâ€“would likely result in the effect of ğ´being lost in
intermediate computations. Instead, we adopt the varying coefficient
approach by setting ğœ‡NN(ğ‘¿,ğ´)=ğ‘”âˆ’1(ğ‘“ğœƒğœ‡(ğ´)(ğ’))[5,20]. With this
choice, the weights of each layer are dynamically computed as a
function ofğ´obtained from a linear combination of basis functions
spanning the set of admissible functions on ğ´. The weights of the
linear combination are themselves a learnable linear combination
of the hidden outputs from the previous layer. We refer the reader
to Nie et al . [20] for additional background on varying-coefficient
layers. Our experiments suggest TR is beneficial for different choices
of basis functions.
Estimation of ğ’˜via classification. The density ratio head ğ’˜NN=
(ğ‘¤NN
Ëœğ‘)Ëœğ‘âˆˆËœPis trained using an auxiliary classification task. For this
purpose, we use an auxiliary classification task where the positive
labels are assigned to the samples from Ëœğ´Ëœğ‘and the negative labels
to the samples with ğ´. This loss can be written as:
Rğ‘¤(ğ’˜NN)=1
2ğ‘›|ËœP|ğ‘›âˆ‘ï¸
ğ‘–=1âˆ‘ï¸
Ëœğ‘âˆˆËœPn
ğµ(ğœËœğ‘
1,ğ‘–,1)+ğµ(ğœ0,ğ‘–,0)o
ğœËœğ‘
1,ğ‘–=logğ‘¤NN
Ëœğ‘(ğ‘¿ğ‘–,Ëœğ´Ëœğ‘
ğ‘–)
ğœ0,ğ‘–=logğ‘¤NN
Ëœğ‘(ğ‘¿ğ‘–,ğ´ğ‘–)(16)
whereğµis the binary classification loss and ğœ0,ğ‘–,{ğœËœğ‘
1,ğ‘–}Ëœğ‘âˆˆËœPare the
label predictions on the logit scale, which coincide with the log-
density ratios [ 28]. To capture the effect of ğ´more effectively, we
propose parameterizing the network using the varying-coefficient
structure discussed in the previous section with logğ‘¤NN
Ëœğ‘(ğ‘¿,ğ´)=ğ‘“ğœƒËœğ‘
ğ‘¤(ğ´)(ğ’). To our knowledge, we are the first to consider a varying-
coefficient architecture for conditional density ratio estimation.
4 SIMULATION STUDY
We conducted simulation experiments to validate the design choices
oftresnet. The so-called fundamental problem of causal inference
is that the counterfactual responses are never observed in real
data. Thus, we must rely on widely used semi-synthetic datasets to
evaluate the validity of our proposed estimators. First, we consider
two datasets introduced by Nie et al . [20] , which are continuous-
treatment adaptions to the popular datasets ihdp [10] and news
[19]. We also apply our methods to [ 20]â€™s fully simulated data, sim-N.
In addition, we consider the fully simulated dataset described in [ 1],
which features a continuous treatment and has been previously
used for calibrating models in air pollution studies. Finally, we also
consider three variants of the tcga dataset presented in Bica et al .
[3]. The three variants consist of three different dose specifications
as treatment assignments and the corresponding dose-response as
the outcome.
The datasets described here have been employed without sub-
stantial modifications from the original source studies to facilitate
fair comparison. Note that for each of these synthetic and semi-
synthetic datasets, we have access to the true counterfactual out-
comes, which allows us to compute sample SRFs exactly. We will
consider the estimation task of 20 equally-spaced percent reduction
shifts between 0-50% from the current observed exposures. More
specifically, Ëœğ´=(1âˆ’ğ‘)ğ´for values of ğ‘in0âˆ’50%.
Evaluation metric and task. Given a semi-synthetic dataset D,
consider an algorithm that produces an estimator Ë†ğ(ğ‘ )
Ëœğ‘,Dofğ(ğ‘ )
Ëœğ‘,D
given an exposure shift Ëœğ‘and random seed ğ‘ . To evaluate the
 
2882KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Mauricio Tec, Kevin Josey, Oladimeji Mudele, and Francesca Dominici
quality of the estimator, we use the mean integrated squared er-
rormiseD=(ğ‘›seeds|ËœP|)âˆ’1Ã
ğ‘ Ã
Ëœğ‘|Ë†ğ(ğ‘ )
Ëœğ‘,Dâˆ’ğ(ğ‘ )
Ëœğ‘,D|2.This metric is a
natural adaption of an analogous metric commonly used in dose-
response curve estimation [3].
Experiment 1: Does targeting SRFs specifically improve their esti-
mation (compared to no targeting or standard ERF targeting?) We
evaluate two variants of tresnet against alternative SRF estima-
tors, including vcnet [20] and drnet [25], two prominent methods
used in causal TR estimation for continuous treatments. Since these
methods were not designed specifically for SRFs, we expect that
their performance for this task can be improved by adapting TR
through their baseline architectures.
The first variant of tresnet uses varying-coefficient layers based
on splinesâ€”see the discussion in Section 3.2 for background. We
compare this variant, named tresnet vc, with the following base-
lines:
(1)aipw vc, the AIPW-type estimator for SRFs discussed in Sec-
tion 3.1, wherein we fit separate outcome and density ratio
models which are then substituted into Equation (5);
(2)outcome vc, which uses the same outcome model as tres-
net vc, but without the TR and density ratio heads;
(3)vcnet, which uses a similar overall architecture as tres-
netvc, but with a TR designed for ERFs rather than for SRFs.
The second variant of tresnet uses varying coefficients based
on piecewise linear functions instead of splines. This variant, tres-
net pl, is compared against the following analogous baselines:
(1)aipw pl, which is the piecewise analogue to aipw vc;
(2)drnet, based on Schwab et al . [25] , functioning as the piece-
wise linear analogue to outcome vc;
(3)drnet+trerf, which is the analogue to vcnet that can be
constructed by adding a density ratio head and TR designed
for ERFs rather than SRFs.
Table 1a shows the results of this experiment. For both archi-
tectures, the tresnet variants achieve the best performance. tres-
net vcis somewhat better than vcnet , which have comparable
architectures although tresnet uses a different TR implementa-
tion specific for SRF estimation rather than ERF estimation. Like-
wise, tresnet ploutperforms drnet+trerf. These moderate but
consistent performance improvements suggest the importance of
SRF-specific forms of TR. We also see strong advantages against
outcome-based predictions and AIPW estimators, suggesting that
the TR loss and the shared learning architecture is a boon to per-
formance. These results are compatible with observations from
previous work in the TR literature [20, 26].
Experiment 2: Does TR improve estimation when count-valued
outcomes are observed? For these experiments, we used the spline-
based variant and evaluate whether tresnet with the Poisson-
specific TR, explained in Section 3, performs better than the mean-
squared error (MSE) loss variant when the true data follows a
Poisson distribution. This evaluation is important since our appli-
cation consists of count data requiring a Poisson model which are
widely used to investigate the effects of PM2.5on health [ 14,33].
We construct similar semi-synthetic datasets as in Experiment 1,
however in this experiment the outcome-generating mechanism
Figure 4: Fraction (%) of observed units remaining above
PM 2.5limit as a function of reduction (%) considering differ-
ent NAAQS (current NAAQS is set at 12 Âµg/m3).
samples from a Poisson distribution rather than a Gaussian distri-
bution. The results of this experiment are clearâ€“using the correct
exponential family for the outcome model is critical, regardless of
whether TR is implemented.
5 MAIN APPLICATION: THE EFFECTS OF
STRICTER AIR QUALITY STANDARDS
We implemented tresnet for count data to estimate the health
benefits caused by shifts to the distribution of PM2.5that would
result from lowering the NAAQSâ€”the regulatory threshold for the
annual-average concentration of PM 2.5enforced by the EPA.
Data. The dataset is comprised of Medicare recipients2from
2000â€“2016, involving 68 million unique individuals. The data in-
cludes measurements on participant race/ethnicity, sex, age, Med-
icaid eligibility, and date of death, which are subsequently aggre-
gated to the annual ZIP-code level. The PM2.5exposure measure-
ments are extracted from a previously fit ensemble prediction model
[6]. The confounders include measurements on meteorological in-
formation, demographics, and the socioeconomic status of each
ZIP-code. Calendar year and census region indicators are also in-
cluded to account for spatiotemporal trends. To compile our dataset,
we replicated the steps and variables outlined by Wu et al. [33].
Exposure shifts. We consider two types of PM2.5shifts, cutoff
shits andpercent reduction shift, each providing different perspec-
tives and insights. The counterfactuals implied from these scenarios
are illustrated in figures 2a and 2b, respectively. First, a cutoff shift,
parameterized by a threshold ğ‘‘, encapsulates scenarios in which
every ZIP-code year that exceeded some threshold are truncated to
that maximum threshold. Mathematically, the shift is defined by the
transformation Ëœğ´=min(ğ´,ğ‘). To be more succinct, the exposure
shift defines a counterfactual scenario. For this application, the
thresholdğ‘is evaluated at equally spaced points starting with 15
Âµg/m3moving down to 6 Âµg/m3. We expect that at 15 Âµg/m3there
2Access to Medicare data is restricted without authorization by the Centers for Medi-
care & Medicaid Services since it contains sensitive health information. The authors
have completed the required IRB and ethical training to handle these datasets.
 
2883Causal Estimation of Exposure Shifts with Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
0 10 20 30 40 50
 2.5
2
1.5
1
0.5
0 Mean
IQR
Reduction in PM2.5 (%)Reduction in Deaths (%)
Figure 5: Estimated SRF of the total deaths (%) for different
cutoffs.
will be little to no reduction in deaths since >99%of observations
fall below that range. We can contemplate the proposed NAAQS lev-
els through ğ‘‘assuming that full compliance to the new regulation
holds for incompliant ZIP-codes. The exposure shift should other-
wise not affect already compliant ZIP-codes. Second, we onsider
percent reduction shifts. This scenario assumes that all ZIP-code
years reduce their pollution levels proportionally from their ob-
served value. More precisely, the shift is defined as Ëœğ´=ğ´(1âˆ’ğ‘). We
considered a range of percent reduction shifts between ğ‘âˆˆ(0,50)%.
We can interpret these shifts in terms of the NAAQS by mapping
each percent reduction to a compliance percentile. For instance, Fig-
ure 4 shows that, under a 30% overall reduction in historical values,
approximately 82% would comply with a NAAQS of 9 Âµg/m3.
Implementation. We implement tresnet using varying-coefficient
splines as in Section 4. We select a NN architecture using the out-of-
sample prediction error from a 20/80% test-train split to choose the
number of hidden layers (1-3 layers) and hidden dimensions (16, 64,
256). We found no evidence of overfitting in the selected models. To
account for uncertainty in our estimations, we train the model on
100 bootstrap samples, each with random initializations, thereby
obtaining an approximate posterior distribution. Deep learning en-
sembles have been previously shown to approximate estimation
uncertainty well in deep learning tasks [12].
Results. Figure 1 in the introduction presents the effects of
shifting the PM2.5distribution at various cutoffs on the expected
reduction in deaths. The slope is steeper at stricter/lower cutoffs,
likely because lower cutoffs affect a larger fraction of the observed
population and reduce the overall PM2.5. For instance, figure Fig-
ure 1 shows that had no ZIP-code years exceeded 12 Âµg/m3, the
observed death counts would have decreased by around 1%. If the
cutoff is lowered to 9 Âµg/m3, then deaths could have fallen by
around 4%. The slope becomes increasingly steeper as the PM2.5
threshold is reduced, suggesting an increasing benefit from lower-
ing the standard concentration level. Another way to interpret this
result is to say that there is a greater gain to reducing mortality
caused by PM2.5from lowering the concentration level from 10 to
8Âµg/m3than there is from lowering it from 12 to 10 Âµg/m3, de-
spite the obvious observation that both contrasts examine a PM2.5
reduction of 2 Âµg/m3.The results of the percent-reduction shift are presented in Fig-
ure 5. The decrease in deaths is approximately linear with respect
to the percent decrease in PM2.5. As such, the SRF shows an ap-
proximate 0.5% decrease in deaths resulting from a 10% decrease
inPM2.5. This result is consistent with previous causal estimates
of the marginal effect of PM2.5exposure on elder mortality [ 33].
Percent reduction offers a complementary view to the cutoff shift
response function as it might pertain to policymakers decisions on
the future of the NAAQS.
6 DISCUSSION AND LIMITATIONS
The results of Section 5 demonstrate the significant need to estab-
lish proper estimators when addressing the pressing public health
question regarding the potential health benefits of lowering the
NAAQS in the United States. In response to this question, we intro-
duce the first causal inference method to utilize neural networks
for estimating SRFs. Furthermore, we have extended this method to
handle count data, which is crucial for our application in addition
to other public health and epidemiology contexts.
There are numerous opportunities to improve to our method-
ology. First, our uncertainty assessment of the SRF relies on the
bootstrap and ensembling of multiple random seeds. While these
methods are used often in practice, future research could explore the
integration of tresnet with Bayesian methods to enhance uncer-
tainty quantification. Second, our application of the methodology
focuses on exposure shifts representing complementary viewpoints
to the possible effects of the proposed EPA rules on the NAAQS.
However, it does not determine the most probable exposure shift
resulting from the new ruleâ€™s implementation, based on historical
responses to changes in the NAAQS. Subsequent investigations
should more carefully consider this aspect of the analysis. The as-
sessment of annual average PM2.5concentrations at the ZIP-code
level is based on predictions rather than on actual observable values,
introducing potential attenuation bias stemming from measurement
error. Nonetheless, previous studies on measurement error involv-
ing clustered air pollution exposures have demonstrated that such
attenuation tends to pull the causal effect towards a null result
[14, 32].
It is essential to recognize that the SRF framework places addi-
tional considerations on the analyst designing the exposure shift.
This newfound responsibility can be seen as both a disadvantage
and an advantage. However, it highlights the need for an explicit
and meticulous statement of the assumptions underlying the con-
sidered exposure shifts in order to mitigate the potential misuse of
SRF estimation techniques.
ACKNOWLEDGMENTS
The work was supported by the National Institutes of Health (R01-
AG066793, R01-ES030616, R01-ES034373), the Alfred P. Sloan Foun-
dation (G-2020-13946), and the Ren Che Foundation supporting
the climate-smart public health project in the Golden Lab. Com-
putations ran on the FASRC Cannon cluster supported by the FAS
Division of Science Research Computing Group at Harvard Univer-
sity.
 
2884KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Mauricio Tec, Kevin Josey, Oladimeji Mudele, and Francesca Dominici
REFERENCES
[1]Taha Bahadori, Eric Tchetgen Tchetgen, and David Heckerman. 2022. End-to-End
Balancing for Causal Continuous Treatment-Effect Estimation. In International
Conference on Machine Learning. 1313â€“1326.
[2]Heejung Bang and James M Robins. 2005. Doubly robust estimation in missing
data and causal inference models. Biometrics 61, 4 (2005), 962â€“973.
[3]Ioana Bica, James Jordon, and Mihaela van der Schaar. 2020. Estimating the
effects of continuous-valued interventions using generative adversarial networks.
Advances in Neural Information Processing Systems 33 (2020), 16434â€“16445.
[4]Peter J Bickel, Chris AJ Klaassen, Peter J Bickel, Yaâ€™acov Ritov, J Klaassen, Jon A
Wellner, and YAâ€™Acov Ritov. 1993. Efficient and adaptive estimation for semipara-
metric models. Vol. 4. Springer.
[5]Chin-Tsang Chiang, John A Rice, and Colin O Wu. 2001. Smoothing spline
estimation for varying coefficient models with repeatedly measured dependent
variables. J. Amer. Statist. Assoc. 96, 454 (2001), 605â€“619.
[6]Qian Di, Heresh Amini, Liuhua Shi, Itai Kloog, Rachel Silvern, James Kelly,
M Benjamin Sabath, Christine Choirat, Petros Koutrakis, Alexei Lyapustin, et al .
2019. An ensemble-based model of PM2. 5 concentration across the contiguous
United States with high spatiotemporal resolution. Environment international
130 (2019), 104909.
[7]IvÃ¡n DÃ­az and Nima S Hejazi. 2020. Causal mediation analysis for stochastic inter-
ventions. Journal of the Royal Statistical Society Series B: Statistical Methodology
82, 3 (2020).
[8]IvÃ¡n DÃ­az, Nicholas Williams, Katherine L Hoffman, and Edward J Schenck. 2021.
Nonparametric causal effects based on longitudinal modified treatment policies.
J. Amer. Statist. Assoc. (2021), 1â€“16.
[9]Max H Farrell, Tengyuan Liang, and Sanjog Misra. 2021. Deep neural networks
for estimation and inference. Econometrica 89, 1 (2021), 181â€“213.
[10] Jennifer L Hill. 2011. Bayesian nonparametric modeling for causal inference.
Journal of Computational and Graphical Statistics 20, 1 (2011), 217â€“240.
[11] Guido W. Imbens and Donald B. Rubin. 2015. Causal Inference for Statistics, Social,
and Biomedical Sciences: An Introduction. Cambridge University Press.
[12] Pavel Izmailov, Sharad Vikram, Matthew D Hoffman, and Andrew Gordon Gordon
Wilson. 2021. What are Bayesian neural network posteriors really like?. In
International conference on machine learning. 4629â€“4640.
[13] Kevin P Josey, Scott W Delaney, Xiao Wu, Rachel C Nethery, Priyanka DeSouza,
Danielle Braun, and Francesca Dominici. 2023. Air Pollution and Mortality at
the Intersection of Race and Social Class. New England Journal of Medicine 388,
15 (2023).
[14] Kevin P Josey, Priyanka DeSouza, Xiao Wu, Danielle Braun, and Rachel Nethery.
2022. Estimating a Causal Exposure Response Function with a Continuous Error-
Prone Exposure: A Study of Fine Particulate Matter and All-Cause Mortality.
Journal of Agricultural, Biological and Environmental Statistics (2022), 1â€“22.
[15] Edward H Kennedy. 2016. Semiparametric theory and empirical processes in
causal inference. Statistical causal inferences and their applications in public health
research (2016), 141â€“167.
[16] Edward H Kennedy. 2022. Semiparametric doubly robust targeted double machine
learning: a review. arXiv preprint arXiv:2203.06469 (2022).
[17] Peter McCullagh. 2019. Generalized linear models. Routledge.
[18] IvÃ¡n DÃ­az MuÃ±oz and Mark Van Der Laan. 2012. Population intervention causal
effects based on stochastic interventions. Biometrics 68, 2 (2012), 541â€“549.
[19] David Newman. 2008. Bag of words data set. UCI Machine Learning Respository
289 (2008).
[20] Lizhen Nie, Mao Ye, Dan Nicolae, et al .2021. VCNet and Functional Targeted
Regularization For Learning Causal Effects of Continuous Treatments. In Inter-
national Conference on Learning Representations.
[21] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al .2019.
Pytorch: An imperative style, high-performance deep learning library. Advances
in neural information processing systems 32 (2019).
[22] Judea Pearl. 2009. Causality. Cambridge university press.
[23] James M Robins. 2000. Robust estimation in sequentially ignorable missing data
and causal inference models. In Proceedings of the American Statistical Association,
Vol. 1999.
[24] James M Robins, Andrea Rotnitzky, and Mark van der Laan. 2000. On profile
likelihood: comment. J. Amer. Statist. Assoc. 95, 450 (2000), 477â€“482.
[25] Patrick Schwab, Lorenz Linhardt, Stefan Bauer, Joachim M Buhmann, and Walter
Karlen. 2020. Learning counterfactual representations for estimating individ-
ual dose-response curves. In Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 34. 5612â€“5619.
[26] Claudia Shi, David Blei, and Victor Veitch. 2019. Adapting neural networks for
the estimation of treatment effects. Advances in neural information processing
systems 32 (2019).
[27] Matthew J Smith, Rachael V Phillips, Miguel Angel Luque-Fernandez, and Camille
Maringe. 2023. Application of targeted maximum likelihood estimation in public
health and epidemiological studies: a systematic review. Annals of Epidemiology
(2023).[28] Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. 2012. Density ratio
estimation in machine learning. Cambridge University Press.
[29] Anastasios A Tsiatis. 2006. Semiparametric theory and missing data. (2006).
[30] Mark J Van der Laan, Sherri Rose, et al .2011. Targeted learning: causal inference
for observational and experimental data. Vol. 4. Springer.
[31] Martin J Wainwright. 2019. High-dimensional statistics: A non-asymptotic view-
point. Vol. 48. Cambridge university press.
[32] Yaguang Wei, Xinye Qiu, Mahdieh Danesh Yazdi, Alexandra Shtein, Liuhua Shi,
Jiabei Yang, Adjani A Peralta, Brent A Coull, and Joel D Schwartz. 2022. The
impact of exposure measurement error on the estimated concentrationâ€“response
relationship between long-term exposure to PM 2.5 and mortality. Environmental
Health Perspectives 130, 7 (2022), 077006.
[33] X Wu, D Braun, J Schwartz, MA Kioumourtzoglou, and F Dominici. 2020. Evalu-
ating the impact of long-term exposure to fine particulate matter on mortality
among the elderly. Science advances 6, 29 (2020), eaba5692.
[34] Jinsung Yoon, James Jordon, and Mihaela Van Der Schaar. 2018. GANITE: Esti-
mation of individualized treatment effects using generative adversarial nets. In
International conference on learning representations.
A ADDITIONAL PROOFS
Causal identification. We first show the identification result from
Section 2, which establishes that the outcome function ğœ‡is equal
to the conditional expectation of the outcome given the treatment
and covariates. As a corollary, the SRF estimand ğcan be estimated
from observed data.
Proposition 1. Suppose Assumption 2.1 holds. Then ğœ‡(ğ‘¿,ğ´)=
E[ğ‘Œ|ğ‘¿,ğ´].
Proof. The proof is fairly standard in the causal inference lit-
erature [ 11]. Since the treatment and potential outcomes are inde-
pendent conditional on ğ‘¿(unconfoundedness), properties of the
conditional expectation yield
ğœ‡(ğ’™,ğ‘)=E[ğ‘Œğ‘|ğ‘¿=ğ’™]
=(ğ‘)E[ğ‘Œğ‘|ğ‘¿=ğ’™,ğ´=ğ‘]
=E[ğ‘Œğ´|ğ‘¿=ğ’™,ğ´=ğ‘]=(ğ‘)E[ğ‘Œ|ğ‘¿=ğ’™,ğ´=ğ‘].
The (a) uses unconfoundedness (Assumption 2.1) and (b) ğ‘Œğ´=ğ‘Œ
by definition. â–¡
Corollary 3. The SRF ğis identified by the data distribution.
Proof. From the definitions and the importance sampling for-
mula, we have
ğ:=Eğ‘¿âˆ¼ğ‘(ğ‘¿)[EËœğ‘¨âˆ¼Ëœğ‘(Ëœğ‘¨|ğ‘¿)[ğœ‡(ğ‘¿,Ëœğ‘¨)|ğ‘¿]]
=Eğ‘¿âˆ¼ğ‘(ğ‘¿)[EËœğ‘¨âˆ¼Ëœğ‘(Ëœğ‘¨|ğ‘¿)[ğ¸[ğ‘Œ|ğ‘¿,ğ´=Ëœğ‘¨]|ğ‘¿,Ëœğ‘¨]]
which shows identification as the right-hand side only involves an
expectation over the observed data distribution by Proposition 1.
â–¡
Derivation of the EIF. When we fit a statistical model to a dataset,
each data point contributes to the estimated parameters of the
model. The efficient influence function (EIF) effectively measures
how sensitive an estimate is to the inclusion or exclusion of individ-
ual data points. In other words, it tells us how much a single data
point can influence the estimate of a causal effect. Formally, the EIF
is defined as the canonical gradient [ 30] of the targeted parameter.
Before defining it properly, we need to introduce a few objects
and notations. First, we let {Pğ‘¡:ğ‘¡âˆˆR}be a smooth parametric
 
2885Causal Estimation of Exposure Shifts with Neural Networks KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
submodel, that is, a parameterized family of distributions such that
P0=P. Next, we adopt the following notation convention
Ëœğ‘ğ‘¡(ğ’):=ğ‘ğ‘¡(ğ‘¦|ğ’™,Ëœğ’‚)Ëœğ‘ğ‘¡(Ëœğ’‚|ğ’™)ğ‘ğ‘¡(ğ’™)
ğ‘ğ‘¡(ğ’):=ğ‘ğ‘¡(ğ‘¦|ğ’™,ğ‘)ğ‘ğ‘¡(ğ‘|ğ’™)ğ‘ğ‘¡(ğ’™)
ğ‘¤ğ‘¡(ğ’™,ğ’‚):=Ëœğ‘ğ‘¡(ğ’‚|ğ’™)/ğ‘ğ‘¡(ğ‘|ğ’™)
where the subscript ğ‘¡indicates that the density is from the data
distribution is taken from Pğ‘¡. The score function for each member
of the submodel is defined as
ğ‘ ğ‘¡(ğ’):=d
dğ‘¡â„=0logËœğ‘ğ‘¡+â„(ğ’),
Similarly, we can define the SRF estimand at each member of the
submodel as
ğ(Pğ‘¡)=âˆ«
ğ‘¦Ëœğ‘ğ‘¡(ğ’)dğ’.
It follows that ğ(P0)=ğis the target SRF.
Under a slight abuse of notation to reduce clutter and avoid
multiple integrals, we denote here and in the proofs the integral
of the relevant variables (understood from context) using a single
operatorâˆ«
dğ’.
The EIF of the non-parametric model is the canonical gradient
of the SRF estimand, which is characterized by the equation
d
dğ‘¡ğ‘¡=0ğ(Pğ‘¡)=âˆ«
ğ‹(ğ’;ğœ“,ğœ‡,ğ’˜)ğ‘ 0(ğ’)Ëœğ‘(ğ’)dğ’ (17)
This condition is also known as pathwise differentiability.
The following results establish that the EIF of the SRF is given
byğ‹(ğ’;ğ,ğœ‡,ğ’˜).
Proposition 2. Suppose Assumptions 2.1 and 2.2 hold. Then the EIF
ofğis given by
ğ‹(ğ‘¶;ğ,ğœ‡,ğ’˜)=ğ’˜(ğ‘¿,ğ´)(ğ‘Œâˆ’ğœ‡(ğ‘¿,ğ´))+ğœ‡(ğ‘¿,Ëœğ‘¨)âˆ’ğ. (18)
Proof. We need to show that equation 17 holds. Starting on the
left hand side, and using properties of logarithms, we have
âˆ«
ğ‘¦ğ‘ ğ‘¡(ğ’)Ëœğ‘ğ‘¡(ğ’)dğ’=âˆ«
ğ‘¦dËœğ‘ğ‘¡(ğ’)/dğ‘¡
Ëœğ‘ğ‘¡(ğ’)ğ‘ğ‘¡(ğ’)dğ’
=d
dğ‘¡âˆ«
ğ‘¦Ëœğ‘ğ‘¡(ğ’)dğ’.(19)
Observe now that (also due to logarithmic properties) we can
factorizeğ‘ ğ‘¡(ğ’)into three parts:
ğ‘ ğ‘¡(ğ’)=ğ‘ 1,ğ‘¡(ğ‘¦|Ëœğ’‚,ğ’™)+ğ‘ 2,ğ‘¡(Ëœğ’‚|ğ’™)+ğ‘ 3,ğ‘¡(ğ’™), (20)
whereğ‘ 1,ğ‘¡(ğ‘¦|Ëœğ’‚,ğ’™),ğ‘ 2,ğ‘¡(Ëœğ’‚|ğ’™), andğ‘ 3,ğ‘¡(ğ’™)are the score functions for
the outcome, shifted exposure, and covariates, respectively. Com-
bining this decomposition with Equation (19), we can rewrite the
left-hand side of (17) as
d
dğ‘¡ğœ“(Pğ‘¡)=âˆ«
ğ‘¦ğ‘ ğ‘¡(o)Ëœğ‘ğ‘¡(ğ’)dğ’
=âˆ«
ğ‘¦(ğ‘ 1,ğ‘¡(ğ‘¦|Ëœğ’‚,ğ’™)+ğ‘ 2,ğ‘¡(Ëœğ’‚,|ğ’™)+ğ‘ 3,ğ‘¡(ğ’™))Ëœğ‘ğ‘¡(ğ’)dğ’
+âˆ«
ğ‘¦ğ‘ 2,ğ‘¡(Ëœğ’‚,|ğ’™)Ëœğ‘ğ‘¡(ğ’)dğ’+âˆ«
ğ‘¦ğ‘ 3,ğ‘¡(ğ’™)Ëœğ‘ğ‘¡(ğ’)dğ’.
(21)
For the next step of the proof, we will recursively use the two
following identities. For any arbitrary function ğ‘”(Â·), and for anytwo subsets of measurements ğ’1andğ’2(e.g.ğ’1=(ğ‘,ğ’™)andğ’2=ğ‘¦),
we have
âˆ«
ğ‘”(ğ’1)
ğ’2âˆ’âˆ«
ğ’2Ëœğ‘ğ‘¡(ğ’2|ğ’1)dğ’2
Ëœğ‘ğ‘¡(ğ’)dğ’=(ğ‘)0
âˆ«
ğ‘”(ğ’1)ğ‘ ğ‘¡(ğ’2|ğ’1)Ëœğ‘ğ‘¡(ğ’)dğ’=(ğ‘)0(22)
Using these identities and evaluating at ğ‘¡=0, we can manipulate
the first term in (21) as
âˆ«
ğ‘¦ğ‘ 1,ğ‘¡(ğ‘¦|Ëœğ’‚,ğ’™)dËœğ‘ğ‘¡(ğ’)dğ’ğ‘¡=0
=(ğ‘)âˆ«
{ğ‘¦âˆ’ğœ‡(ğ’™,Ëœğ’‚)}ğ‘ 1,0(ğ‘¦|Ëœğ’‚,ğ’™)ğ‘(ğ‘¦|Ëœğ’‚,ğ’™)Ëœğ‘(Ëœğ’‚|ğ’™)ğ‘(ğ’™)dğ’
=âˆ«
ğ’˜(ğ’™,ğ‘){ğ‘¦âˆ’ğœ‡(ğ’™,ğ‘)}ğ‘ 1,0(ğ‘¦|ğ‘,ğ’™)ğ‘(ğ‘¦|ğ‘,ğ’™)ğ‘(ğ‘|ğ’™)ğ‘(ğ’™)dğ’
=(ğ‘)âˆ«
ğ’˜(ğ’™,ğ‘)
Ã—{ğ‘¦âˆ’ğœ‡(ğ’™,ğ‘)}
ğ‘ 1,0(ğ‘¦|ğ‘,ğ’™)+ğ‘ 2,0(ğ‘|ğ’™)+ğ‘ 3,0(ğ’™)	
ğ‘(ğ’)dğ’
=âˆ«
ğ’˜(ğ’™,ğ‘){ğ‘¦âˆ’ğœ‡(ğ’™,ğ‘)}ğ‘ 0(ğ’)ğ‘(ğ’)dğ’.
where we used the importance sampling formula for the second
equality. Now, for the second term in (21), also evaluated at ğ‘¡=0,
we have
âˆ«
ğ‘¦ğ‘ 2,ğ‘¡(Ëœğ’‚|ğ’™)dËœğ‘ğ‘¡(ğ’)dğ’ğ‘¡=0
=âˆ«
ğœ‡(ğ’™,Ëœğ’‚)ğ‘ 2,0(Ëœğ’‚|ğ’™)Ëœğ‘(Ëœğ’‚|ğ’™)ğ‘(ğ’™)dğ’
=(ğ‘)âˆ«
ğœ‡(ğ’™,Ëœğ’‚)âˆ’âˆ«
ğœ‡(ğ’™,Ëœğ’‚)Ëœğ‘(Ëœğ’‚|ğ’™)dğ’
Ã—
ğ‘ 1,0(ğ‘¦|Ëœğ’‚,ğ’™)+ğ‘ 2,0(Ëœğ’‚|ğ’™)	Ëœğ‘(ğ’)dğ’
=(ğ‘)âˆ«
ğœ‡(ğ’™,Ëœğ’‚)âˆ’âˆ«
ğœ‡(ğ’™,Ëœğ’‚)Ëœğ‘(Ëœğ’‚|ğ’™)dËœğ’‚
Ã—
ğ‘ 1,0(ğ‘¦|Ëœğ’‚,ğ’™)+ğ‘ 2,0(Ëœğ’‚|ğ’™)+ğ‘ 3,0(ğ’™)	Ëœğ‘(ğ’)dğ’
=âˆ«
ğœ‡(ğ’™,Ëœğ’‚)âˆ’âˆ«
ğœ‡(ğ’™,Ëœğ’‚)Ëœğ‘(Ëœğ’‚|ğ’™)dËœğ’‚
ğ‘ 0(ğ’)Ëœğ‘(ğ’)dğ’
where we again center the integrand and recursively apply the
identities of (22). Finally, for the third term in (21) we have
âˆ«
ğ‘¦ğ‘ 3,ğ‘¡(x)dËœğ‘ğ‘¡(ğ’)dğ’ğ‘¡=0
=âˆ«
ğ‘¦ğ‘ 3,0(ğ’™)ğ‘(ğ‘¦|Ëœğ’‚,ğ’™)Ëœğ‘(Ëœğ’‚|ğ’™)ğ‘(ğ’™)dğ’
=âˆ«âˆ«
ğœ‡(ğ’™,Ëœğ’‚)Ëœğ‘(Ëœğ’‚|ğ’™)dËœğ’‚
ğ‘ 3,0(ğ’™)ğ‘(ğ’™)dğ’
=(ğ‘)âˆ«âˆ«
ğœ‡(ğ’™,Ëœğ’‚)Ëœğ‘(Ëœğ’‚|ğ’™)dËœğ’‚âˆ’ğ
Ã—
ğ‘ 1,0(ğ‘¦|Ëœğ’‚,ğ’™)+ğ‘ 2,0(Ëœğ’‚|ğ’™)+ğ‘ 3,0(ğ’™)	Ëœğ‘(ğ’)dğ’
=âˆ«âˆ«
ğœ‡(ğ’™,Ëœğ’‚)Ëœğ‘(Ëœğ’‚|ğ’™)dËœğ’‚âˆ’ğ
ğ‘ 0(ğ’)Ëœğ‘(ğ’)dğ’
Combining these three terms above proves the condition in (17)
holds, thus completing the proof. â–¡
 
2886KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Mauricio Tec, Kevin Josey, Oladimeji Mudele, and Francesca Dominici
B ANOTHER EXAMPLE OF SRF VS ERF
The following examples show a simple case where the SRF and
ERF estimands are different, thereby demonstrating why the ERF
is not a useful estimate of the effect of an exposure shift. Consider
a setting in which ğœ‡(ğ‘¿,ğ´)=ğ´ğ‘‹withğ‘‹âˆ¼ğ‘(0,1),ğ´âˆ¼ğ‘(ğ‘‹,1).
Now consider the exposure shift induced by Ëœğ´=ğ‘ğ´for some
ğ‘âˆˆR. Using the SRF formulation, we find that ğ=E[ğœ‡(ğ‘¿,Ëœğ´)]=
E[E[ğ‘¿(ğ‘ğ´)|ğ‘¿]]=ğ‘E[ğ‘¿2]=ğ‘. On the other hand, the ERF is
ğœ‰(ğ‘)=E[ğœ‡(ğ‘¿,ğ´)|ğ´=ğ‘]=ğ‘E[ğ‘¿]=0for allğ‘âˆˆR. Therefore,
estimators of the two estimands return two different estimates.
Moreover, the ERF is identically zero for every treatment value.
Thus, it cannot be used to approximate the value of the effect of
the exposure shift, even when ğis correctly specified.
C HARDWARE/SOFTWARE/DATA ACCESS
We ran all of our experiments both in the simulation study and
the application section using Pytorch [ 21] on a high-performancecomputing cluster equipped with Intel 8268 "Cascade Lake" pro-
cessors. Due to the relatively small size of the datasets, hardware
limitations, and the large number of simulations required, we did
not require the use of GPUs. Instead we found that using only CPUs
run in parallel sufficed. Reproducing the full set of experiments
takes approximately 12 hours with 100 parallel processes, each with
4 CPU cores and 8GB of RAM. Each process runs a different random
seed for the experiment configuration.
The code for reproducibility is provided on the submission repos-
itory along with the data sources for the simulation experiments.
The datasets for these experiments were obtained from the public
domain and were adapted from the GitHub repositories shared by
Nie et al . [20] and Bica et al . [3] as explained in the experiment
details section. The data for the application was purchased from
https://resdac.org/. Due to a data usage agreement and privacy
concerns, manipulation of these data requires IRB approval un-
der which the authors have completed the training and for which
reason the data cannot be shared with the public.
 
2887