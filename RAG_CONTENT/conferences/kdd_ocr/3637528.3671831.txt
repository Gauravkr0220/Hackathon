Unifying Evolution, Explanation, and Discernment: A Generative
Approach for Dynamic Graph Counterfactuals
Bardh Prenkajâˆ—
Technical University of Munich
Munich, GermanyMario VillaizÃ¡n-Vallelado
University of Valladolid
TelefÃ³nica Research and Development
Valladolid, Spain
Tobias Leemannâˆ—
University of TÃ¼bingen
TÃ¼bingen, GermanyGjergji Kasneci
Technical University of Munich
Munich, Germany
ABSTRACT
We present GRACIE (Graph Recalibration and Adaptive Counter-
factual Inspection and Explanation), a novel approach for gen-
erative classification and counterfactual explanations of dynami-
cally changing graph data. We study graph classification problems
through the lens of generative classifiers. We propose a dynamic,
self-supervised latent variable model that updates by identifying
plausible counterfactuals for input graphs and recalibrating de-
cision boundaries through contrastive optimization. Unlike prior
work, we do not rely on linear separability between the learned
graph representations to find plausible counterfactuals. Moreover,
GRACIE eliminates the need for stochastic sampling in latent spaces
and graph-matching heuristics. Our work distills the implicit link
between generative classification and loss functions in the latent
space, a key insight to understanding recent successes with this
architecture. We further observe the inherent trade-off between va-
lidity and pulling explainee instances towards the central region of
the latent space, empirically demonstrating our theoretical findings.
In extensive experiments on synthetic and real-world graph data,
we attain considerable improvements, reaching âˆ¼99%validity when
sampling sets of counterfactuals even in the challenging setting of
dynamic data landscapes.
CCS CONCEPTS
â€¢Computing methodologies â†’Knowledge representation
and reasoning; Semi-supervised learning settings; â€¢Mathe-
matics of computing â†’Computing most probable explanation ;â€¢
Computer systems organization â†’Neural networks.
KEYWORDS
Counterfactual Explainability; Dynamic Graphs; Graph Neural Net-
works; Graph Autoencoders
âˆ—These authors contributed equally. Corresponding: bardh.prenkaj@tum.de
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671831ACM Reference Format:
Bardh Prenkaj, Mario VillaizÃ¡n-Vallelado, Tobias Leemann, and Gjergji
Kasneci. 2024. Unifying Evolution, Explanation, and Discernment: A Gen-
erative Approach for Dynamic Graph Counterfactuals. In Proceedings of
the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3637528.3671831
1 INTRODUCTION
Graphs offer an intuitive framework to model the relationships,
interactions, and dependencies that govern modern society. Due
to their unique expressivity, they drive research in domains such
as recommendations in social networks [ 13] and transaction fraud
detection [ 20]. These are pressing problems. For instance, dam-
ages due to online fraud have more than doubled in the recent
two years and are expected to reach a record-high of 48bn$ this
year [ 37], such that better detection strategies are in high demand.
Graphs are most suitable to model relationships involving tangible
users, IP addresses, and other elements [ 8] that dictate this issueâ€™s
complexity.
However, progress in domains such as fraud detection is sub-
stantially complicated by the dynamic and adversarial nature of
the observed data: the application of fraud detection techniques
also triggers adaptations in fraud tactics aimed specifically at evad-
ing detection [ 20]. Such dynamic data landscapes require constant
updates of models.
Concurrently, the need for explainability has been widely ac-
knowledged for system safety [ 7], scientific discovery [ 22], and
even compliance with legal requirements [ 40], which is particularly
important in financial applications. Regulations like GDPR [ 9] and
the proposed AI Act [ 10] emphasize the demand for models that
perform well and provide interpretable and actionable insights into
their predictions. Counterfactual explanations [ 40] have emerged
as a key element in meeting these regulatory requirements, as they
shed light on model decisions by presenting alternative scenarios
that would result in different outcomes. In summary, a multitude
of pressing problems in both science and the economy (1)can be
modeled intuitively through graphs, (2)evolve dynamically over
time, and (3)require some form of explainability.
However, recent research [ 29] has highlighted a significant chal-
lenge when considering the dynamic and ever-changing nature of
the data that models interact with. Data continuously undergoes
changes and distribution shifts, which may warrant updates of
 
2420
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bardh Prenkaj, Mario VillaizÃ¡n-Vallelado, Tobias Leemann, and Gjergji Kasneci
the prediction models and can greatly impact the robustness, rele-
vance, and validity of counterfactual explanations [ 28,39]. Existing
solutions have yet to adequately address the complex interaction
between robust counterfactuals and the dynamic nature of data
landscapes, a recently overlooked problem. As this holds for graphs,
we present a powerful method for combining inference and coun-
terfactual explanation for constantly evolving graph data.
To cope with distributional shift, we leverage the capabilities
of generative classifiers, which have been attributed to increased
robustness in prior work [ 34]. These classifiers model the full class-
conditional probability, i.e., ğ‘(ğ’™|ğ‘¦)for an input ğ’™and each class ğ‘¦,
and predict the class with the highest likelihood using Bayesâ€™ The-
orem. Learning such a model with variational inference techniques
results in GRACIE (Graph Recalibration and Adaptive Counter-
factual Inspection and Explanation), a novel approach for genera-
tive classification and counterfactual explanations of dynamically
changing graph data. GRACIE learns to produce counterfactuals
from the underlying prediction model. Then, by exploiting its gen-
erative classification properties, decide how to discern between
factuals and counterfactuals. This drives the search for counter-
factual candidates in a self-supervised and principled manner. In
successive steps, factuals and counterfactuals are used to recalibrate
the decision boundary and to embody distribution shifts in time.
Unlike previous work, we do not assume that the learned graph
representations are linearly separable to produce valid counter-
factuals [ 33]. Additionally, we exploit the learned latent space to
search for counterfactuals, thus eliminating the need to sample
estimated edge probabilities on the embedded instances [ 25] and
graph-matching heuristics [ 24], known for their NP-hardness [ 23].
Specifically, we go beyond the related literature by making the
following contributions:
(1)Generative Classification For Graph Data. Drawing from
promising results of the robustness of generative classifiers,
we propose a novel model for the generative classification
of graph data.
(2)Theoretic Analysis and Insights. We formalize the prob-
lem and derive a proposition that links the generative classi-
fication objective to the reconstruction loss of autoencoders
and distances in the latent space. This allows for efficient
classification with latent variable models and serves as an
intuitive explanation for prior workâ€™s successes.
(3)Online Counterfactual Method. We propose GRACIE, a
novel, dynamic, and self-adapting approach for generative
classification and counterfactual generation of temporally
evolving graph data, leveraging the power of class-related
Variational Graph Autoencoders (VGAEs).
(4)Empirical Analysis. We conduct extensive experiments on
synthetic and real-world graph data, demonstrating GRA-
CIEâ€™s significant improvement in generative classification
and counterfactual generation, particularly under dataset
shifts. We will publicly release our code online.
2 RELATED WORK
Recently, deep learning relying on GNNs has been beneficial in
solving graph-based prediction tasks, such as anomaly detection,
link prediction [ 41], and protein-protein interaction predictions[35]. Despite their remarkable performance, GNNs are black boxes,
making them unsuitable for high-impact and high-risk scenarios.
The literature has proposed several post-hoc explainability methods
to understand what is happening under the hood of the prediction
models. Specifically, counterfactual explainability is useful to un-
derstand how modifications in the input lead to different outcomes.
Similarly, a recent field in Graph Counterfactual Explainability
(GCE) has emerged [ 32] that aims at producing counterfactuals for
graphs. We provide the reader with an example that helps clarify
a counterfactual example in graphs. Suppose we have a network
of cryptocurrency transactions where nodes are traders and con-
nections represent digital currency transfers from one trader to
another. Assume that trader ğ‘¢sends a large amount of crypto to
Ë†ğ‘¢, a high-risk and flagged trader. A fraud detection system might
alert a user ğ‘¢about restricting their account to minimal transfers
for a designated period due to possible fraud suspicion reasons.
A counterfactual explanation of ğ‘¢â€™s account flagging would be if
ğ‘¢had refrained from transferring cryptos to Ë†ğ‘¢â€™s account, then ğ‘¢â€™s
account would not have been flagged as suspicious. Generally, GCE
methods can be search- [ 1,11], heuristic- (among others, [ 4]), and
learning-based approaches (among others, [ 24,27,31]). While all
the above methods provide counterfactuals in graphs, none of them
is specialized to cope with evolving graphs in time, which adds
complexity to finding valid and time-adaptable counterfactuals.
The problem of aligning counterfactual explanations in the pres-
ence of distributional drifts has become a relevant subject of study
[14]. However, recent work has shown that counterfactuals are still
fragile and can become invalidated when data points are deleted
[29]. The authors identify influential data points whose deletion
at timeğ‘¡+ğ›¿ensures that previously generated counterfactuals at
timeğ‘¡become obsolete.
To the best of our knowledge, the only work that tackles the
problem of updating invalid counterfactuals in a timely fashion
is [33]. The authors represent graphs of the two opposite classes
by closely aligning graph representations of the same class while
pushing away those of the opposite. When drift distributions occur,
they update the learned representations by calibrating their model
and fitting a linear regressor, which also considers the similarity
of graphs, to separate the newly learned graph representations.
However, this work cannot tackle non-linearly separable represen-
tations, leading the explainer to fail to find valid counterfactuals. To
address this, we propose a novel generative graph counterfactual
explainer that separates the factual and counterfactual spaces while
maintaining faithful representations of both classes over time.
Here, we propose to learn robust class representations and lever-
age generative classification to determine the class of never-seen-
before graphs when the distributional drifts happen, and the deci-
sion boundary of the underlying predictor cannot be trusted. This
helps our method adapt its learned representations self-supervisedly.
3 PROBLEM STATEMENT AND MOTIVATION
Preliminary. A temporal graph ğºğ‘–can be defined as a sequence
of graphs{ğºğ‘¡0
ğ‘–,...,ğºğ‘¡ğ‘š
ğ‘–}whereğ‘‡={ğ‘¡0,...ğ‘¡ğ‘š}is a set of discrete
snapshots. Here ğºğ‘¡0
ğ‘–can be considered as the base graph structure
which mutates in time into ğºğ‘¡ğ‘—
ğ‘–âˆˆGâˆ€ğ‘—âˆˆ[1,ğ‘š]whereGis the
 
2421Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Graph at cur r ent timeGraph at pr e vious timeCor r e ct oracle de cision b oundar yOld oracle de cision b oundar yPotential counterfactual asso ciationCor r e ct counterfactual asso ciationOld counterfactual asso ciationGraph mo v ement fr om    to  Class 0Class 1
Class 0Class 1
Figure 1: Counterfactuals require updates in temporal graph
problems. (left) The decision boundary of the oracle Î¦trained
on the data at time ğ‘¡correctly associates graph ğºğ‘¡
2as the coun-
terfactual of ğºğ‘¡
1, satisfying Eq. 1. (right) As drifts occur, graph
ğºğ‘¡
1transitions to ğºğ‘¡+1
1, crossing the previous (dashed line)
decision boundary. Consequently, ğºğ‘¡+1
2cannot be a counter-
factual for ğºğ‘¡+1
1. A new decision boundary must reflect the
changes (bold full line) to maintain counterfactual validity.
dataset of all graphs. Each graph is generally a tuple (ğ‘¿,ğ‘¨)where
ğ‘¿âˆˆRğ‘›Ã—ğ‘‘represents the node feature vectors and ğ‘¨âˆˆRğ‘›Ã—ğ‘›is the
adjacency matrix s.t. ğ‘›is the node number.
Motivation. In this paper, we address the challenge of counterfac-
tual1validity amid data distributional shifts over time. We provide
the reader with an example in Fig. 1 to showcase how counter-
factuals get invalidated when distribution drifts happen [ 29]. We
illustrate six temporal graphs on two snapshots, ğ‘¡andğ‘¡+1. Let
us assume we have 2D representations of these graphs for visu-
alization clarity. Let us consider a specialized explainer, denoted
asÎ©. At snapshot, ğ‘¡,Î©needs to explain the underlying predictor
(oracle) Î¦, trained on data from the same snapshot. Î¦generally
has a specific decision boundary depicted by the bold separation
line. At this point, Î©successfully generates a valid counterfactual,
ğºğ‘¡
2, for the input ğºğ‘¡
1, instead ofğºğ‘¡
3since the distance between ğºğ‘¡
2
andğºğ‘¡
1is smaller than that of ğºğ‘¡
3andğºğ‘¡
1. As time progresses to
ğ‘¡+1, data distribution shifts may invalidate Î¦â€™s previous decision
boundary, indicated by the bold dashed line. Therefore, Î¦will fail to
accurately reflect the true data separation â€“ e.g., see how ğºğ‘¡+1
1gets
misclassified because it has altered its true class w.r.t. the previous
snapshotğ‘¡. At snapshot ğ‘¡+1, it is crucial to observe that the coun-
terfactual for ğº1cannot beğº2since they now belong to the same
true class. Instead, now, ğºğ‘¡+1
ğ‘˜would be a counterfactual for ğºğ‘¡+1
1,
since it crosses the â€œtrue decision boundaryâ€ â€“ bold separation line
â€“ unkown to Î¦. Recognizing the unreliability of Î¦â€™s predictions in
successive snapshots, we advocate for a robust mechanism that
dynamically updates counterfactuals, ensuring their validity amid
data distribution drifts.
1ğºâ€²is a counterfactual of ğºif their predictions are different according to an underlying
predictor (oracle) Î¦[40].Problem formalization. Given a black-box oracle Î¦:Gâ†’Y , a
counterfactual for ğºğ‘¡
ğ‘–is produced by maximizing the objective
EÎ¦ ğºğ‘¡
ğ‘–=arg max
ğºğ‘¡
ğ‘—âˆˆGğ‘ƒğ‘¡
ğ‘ğ‘“
ğºğ‘¡
ğ‘—ğºğ‘¡
ğ‘–,Î¦ ğºğ‘¡
ğ‘–,Â¬Î¦ ğºğ‘¡
ğ‘–
(1)
whereğ‘ƒğ‘ğ‘“denotes the probability of ğºğ‘¡
ğ‘—being a valid in-distribution
counterfactual for an adequate description of the original graph ğºğ‘¡
ğ‘–
and the class Î¦(ğºğ‘¡
ğ‘–), whereÂ¬Î¦(ğºğ‘¡
ğ‘–)indicates any other2class from
the one predicted for ğºğ‘¡
ğ‘–. Notice that the counterfactual produced
for each graph ğºğ‘¡
ğ‘–refers to the same snapshot ğ‘¡.
Within the probabilistic framework, expressed in Eq. 1, prior
work [ 33] focused on discriminative models leading to preliminary
promising results. In this work, we shift towards a generative classi-
fication perspective which allows us to dynamically update invalid
counterfactuals without relying on Î¦â€™s outdated classifications.
4 A GENERATIVE CLASSIFICATION
PERSPECTIVE
This section studies generative classifiers for robust inference under
distribution shifts. Moreover, we formally link the generative clas-
sification objective to the reconstruction loss and norms in latent
variable models, which allows for efficient inference using VGAEs.
Generative Classification. Generative classifiers (GCs, e.g., Ng
and Jordan [26]) are a form of probabilistic models that perform
classification through modeling the full joint distribution of features
ğ’™and class labels ğ‘¦. In contrast to discriminative models, which
only model ğ‘(ğ‘¦|ğ’™), they explicitly represent ğ‘(ğ’™|ğ‘¦)and predict
the most likely label Ë†ğ‘¦via the Chain (or Product) Rule, i.e.,
Ë†ğ‘¦=argmax
ğ‘¦âˆˆYğ‘(ğ’™,ğ‘¦)=argmax
ğ‘¦âˆˆYğ‘(ğ’™|ğ‘¦)ğ‘(ğ‘¦)=
=argmax
ğ‘¦âˆˆYlogğ‘(ğ’™|ğ‘¦)+logğ‘(ğ‘¦).(2)
In prior work, GCs have been attested to superior generalization ca-
pabilities over discriminative classifiers (DCs) under dataset shifts
[34,38], accurately calibrated posteriors [ 3], and increased adver-
sarial robustness [ 21]. A probabilistic model is required to model
the class conditional densities. In this work, we rely on Variational
Graph Autoencoders [17].
Variational Graph Autoencoders (VGAEs). We consider the fol-
lowing generative model where the graphs ğºare generated from
factored latent representation ğ’›=
ğ’›ğ‘£1,..., ğ’›ğ‘£ğ‘›
, and the true class
labelğ‘¦:
ğ‘(ğº|ğ‘¦)=âˆ«
ğ’›âˆˆZğ‘(ğº|ğ’›,ğ‘¦)ğ‘(ğ’›|ğ‘¦)ğ‘‘ğ‘§ (3)
To represent ğ‘(ğº|ğ‘¦), we use a single VGAE for each class ğ‘¦âˆˆY,
which is dependent on the class where each node has a latent vector
and then define
ğ‘ğœƒğ‘¦(ğº|ğ’›,ğ‘¦)=ğ‘ğœƒğ‘¦(ğ‘¨,ğ‘¿|ğ’›,ğ‘¦)
=ğ‘ğœƒğ‘¦(ğ‘¿|ğ‘¨,ğ’›,ğ‘¦)ğ‘ğœƒğ‘¦(ğ‘¨|ğ’›,ğ‘¦)(4)
where first the edges (or their probabilities) ğ‘¨are computed and
the node features ğ‘¿are reconstructed subsequently. Each decoder
2The provided formulation supports multi-class classification problems. For simplicity,
we concentrate on binary classification only.
 
2422KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bardh Prenkaj, Mario VillaizÃ¡n-Vallelado, Tobias Leemann, and Gjergji Kasneci
depends on parameters ğœƒğ‘¦for the respective class ğ‘¦. The respective
joint distributions are modeled through probabilistic neural net-
works. We discuss the full parametrization of the generative model
in Sec. A. We let
ğ‘(ğ’›)=Ã–
ğ‘£ğ‘–ğ‘ ğ’›ğ‘£ğ‘–=Ã–
ğ‘£ğ‘–N ğ’›ğ‘£ğ‘–;0,ğ‘°(5)
be an isotropic Gaussian prior. Such a latent variable model can be
learned using standard variational approximation techniques. In
variational techniques, the intractable inference density ğ‘(ğ’›|ğº,ğ‘¦)
required for optimization is approximated through a parametric
distribution family element. If this family is expressive enough, e.g.,
it contains the actual density of the data-generating process, the
variational model will converge to the true likelihood [ 16]. In the
graph setting, we let ğ‘(ğ’›|ğ‘¿,ğ‘¨,ğ‘¦)be a factorized representation,
ğ‘ğœ‘ğ‘¦(ğ’›|ğº,ğ‘¦)=Ã–
ğ‘£ğ‘–ğ‘ğœ‘ğ‘¦ ğ’›ğ‘£ğ‘–ğº,ğ‘¦(6)
and specifically model ğ‘ ğ‘§ğ‘£ğ‘–ğº,ğ‘¦=N ğ‘§ğ‘£ğ‘–ğğ‘£ğ‘–,ğ›¾2ğ‘°,
ğ=
ğğ‘£1,..., ğğ‘£ğ‘›
=GCNğœ‘ğ‘¦(ğº)is a matrix of mean vectors com-
puted by a Graph Convolutional Network (GCN) with parameters
ğœ‘ğ‘¦, whereğ›¾2>0is a fixed hyperparameter.
As in Kipf and Welling [17], we train VGAEs for each of the
classes by optimizing the parameters ğœƒandğœ‘in the objective
ELBOğ‘¦ ğœƒğ‘¦,ğœ‘ğ‘¦=E
ğ‘ğœ‘ğ‘¦(ğ’›|ğº,ğ‘¦)
logğ‘ğœƒğ‘¦(ğº|ğ’›,ğ‘¦)
âˆ’KLh
ğ‘ğœ‘ğ‘¦(ğ’›|ğº,ğ‘¦)ğ‘(ğ’›)i(7)
where KL[ğ‘(Â·)||ğ‘(Â·)]is the Kullback-Leibler divergence between
ğ‘(Â·)andğ‘(Â·). Through maximization of the ELBO, we obtain opti-
mal parameters, which we denote by

ğœƒâˆ—
ğ‘¦,ğœ‘âˆ—
ğ‘¦
=argmax
ğœƒğ‘¦,ğœ‘ğ‘¦ELBOğ‘¦ ğœƒğ‘¦,ğœ‘ğ‘¦âˆ€ğ‘¦âˆˆY (8)
Having obtained a generative latent variable model of a specific
classğ‘¦according to Eq. 8, we can now exploit its power to per-
form generative classification. If the variational family is expressive
enough, i.e., it actually covers the true data-generating distribution,
the ELBO converges to the logarithm of the true class-conditional
probability logğ‘(ğº|ğ‘¦). Therefore, we can use the generative mod-
els to compare different class probabilities and perform generative
classification. Instead of maximizing the ELBO, we can equivalently
minimize the negative ELBO, which has a surprisingly interpretable
form in the variational model supposed in this work, as distilled in
the following proposition:
Proposition 1 (Comparing Distance-Augmented Reconstruc-
tion Losses performs Implicit GC). If the density model in Eqs.
(4)-(6)is sufficiently expressive, i.e., it covers the true data generating
process, computing
Ë†ğ‘¦=argmin
ğ‘¦âˆˆY1
2
E
ğ‘ğœ‘âˆ—ğ‘¦(ğ’›|ğº,ğ‘¦)"âˆ¥ğ‘”ğœƒâˆ—ğ‘¦(ğ’›)âˆ’ğºâˆ¥2
2
ğœ2#
+âˆ¥ğ‘“ğœ‘âˆ—ğ‘¦(ğº)âˆ¥2
2
âˆ’logğ‘(ğ‘¦),
is equivalent to performing generative classification for an input graph
ğº, whereğ‘“ğœ‘âˆ—andğ‘”ğœ™âˆ—are graph encoding and decoding networks,
respectively.We provide the reformulation of the ELBO in Sec. A and proof
of the proposition in Sec. B. From the above proposition, we see
that adding the reconstruction loss3and the distance from the
origin of the latent representation while compensating for the prior
class probability implicitly performs generative classification. The
above result comes with several implications. First, once we have a
trained variational model, we can perform efficient classification by
simply embedding the samples with the respective autoencoders
and computing the reconstruction loss and latent norm. Second,
our proposition might explain prior workâ€™s [ 33] success in using
autoencoders to represent the data distributions and leveraging the
reconstruction loss. In the remainder of this work, we will show
that the performance can be substantially improved by continuing
on the path set out through our theoretic considerations.
5 METHOD
Here, we present GRACIE, namely Graph Recalibration and Adaptive
Counterfactual Inspection and Explanation. GRACIE4is a counter-
factual explanation method that leverages Î¦at the initial snapshot
ğ‘¡0to acquire insights into the underlying data distribution and iden-
tify valid counterfactual instances. Importantly, GRACIE achieves
this without relying on potentially outdated decision boundaries for
snapshotsğ‘¡ğ‘–+1>ğ‘¡ğ‘–. We omit the time superscript in the formulas
to enhance clarity, except when necessary.
Training. To untap the generative classification capabilities, we
need to obtain a latent variable model for a specific class ğ‘¦by op-
timizing the ELBO as in Eq. 8. In binary classification problems,
GRACIE relies on two VGAEs, Î©0,Î©1:Gâ†’G , corresponding to
the negative and positive classes. They are responsible for learn-
ing the representation of each class separately. In this way, each
VGAE intuitively constructs an embedding space that is limited to
instances that belong to the same input distribution since, at ğ‘¡0, we
feedğºğ‘–âˆˆGtoÎ©ğ‘¦s.t.ğ‘¦=Î¦(ğºğ‘–). The encoder of the VGAEs is a
2-layered GCN. Differently from [ 17], we rely on the Graph Atten-
tion Network decoder proposed in [ 15] to modelğ‘ğœƒğ‘¦(ğ‘¨|ğ’›,ğ‘¦), and
thus reconstruct the adjacency matrix. Note that the encoder and
the decoder have different parameters ğœƒğ‘¦,ğœ‘ğ‘¦, which depend on ğ‘¦.
Maximizing the ELBO in Eq. 8 can be equivalently expressed
as the minimization of the following objective function, assuming
that we have equal priors:
âˆ’ELBOğ‘¦ ğœƒğ‘¦,ğœ‘ğ‘¦âˆLğ‘Ÿğ‘’ğ‘+Lğ‘‘ğ‘–ğ‘ ğ‘¡
âˆ1
2
E
ğ‘ğœ‘ğ‘¦(ğ’›|ğº)||ğ‘”ğœƒğ‘¦(ğ’›)âˆ’ğº||2
2
ğœ2
+||ğ‘“ğœ‘ğ‘¦(ğº)||2
2(9)
We refer interested readers to the derivation of this term in Appen-
dix A. By optimizing Eq. 9 for each VGAE, we learn to correctly
reconstruct the input graphs via Lğ‘Ÿğ‘’ğ‘and maintain the embeddings
close to the center of the latent space via Lğ‘‘ğ‘–ğ‘ ğ‘¡.
Unlike other works in graph autoencoders [ 12,15], we recon-
struct the node features and the graph topology. Thus, we ensure
that the latent space of each VGAE correctly represents the distin-
guishing edges instead of just the node features of the graphs.
3We writeâˆ¥ğºâˆ’ğºâ€²âˆ¥2
2for graphsğº=(ğ‘¿,ğ‘¨),ğºâ€²=(ğ‘¿â€²,ğ‘¨â€²)as a shorthand for
âˆ¥ğ‘¨âˆ’ğ‘¨â€²âˆ¥2
2+âˆ¥ğ‘¿âˆ’ğ‘¿â€²âˆ¥2
2.
4https://github.com/bardhprenkaj/HANSEL
 
2423Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
123456712345671234567...1234567
D ata at time
Figure 2: Search for top- ğ‘˜counterfactual candidates at infer-
ence time. ğºğ‘¡âˆ—is mapped to ğ’›=ğ‘“ğœ‘âˆ—
1âˆ’Ë†ğ‘¦(ğºğ‘¡âˆ—)and pulled towards
the center ( ğ’›âˆ—=ğœ†ğ’›). Other graphs ğºğ‘¡
1,...,ğºğ‘¡ğ‘›also mapped to
the latent space of ğ‘“ğœ‘âˆ—
1âˆ’Ë†ğ‘¦. Based on prior learned embedding
(circles), class 1âˆ’Ë†ğ‘¦instances move closer to the center, while
the same class Ë†ğ‘¦instances shift away (rectangles). Triangles
denote counterfactual candidates closest to ğ’›âˆ—.
Inference and Counterfactual Generation. Having obtained the
latent variable model, we can perform inference according to Propo-
sition 1. For a never-seen-before instance, ğºğ‘¡âˆ—s.t.ğ‘¡>0, we first
compute the most likely class Ë†ğ‘¦by evaluating the reconstruction
loss and the latent norm for each class-specific VGAE. In this way,
we can assign ğºğ‘¡âˆ—to class Ë†ğ‘¦, and use Î©1âˆ’Ë†ğ‘¦as the VGAE to find
counterfactual candidates. In more detail, we use the encoder of
Î©1âˆ’Ë†ğ‘¦to compute ğ’›=ğ‘ğœ™âˆ—
1âˆ’Ë†ğ‘¦ ğºğ‘¡âˆ—, i.e., the latent representation for
ğºğ‘¡âˆ—. Now, since our goal is to pull the representations as close to the
center of the latent space as possible, we can go inside the learned
region by setting ğ’›âˆ—=ğœ†ğ’›, whereğœ†âˆˆ(0,1). Notice that as the prob-
ability for class 1âˆ’Ë†ğ‘¦increases as we approach the center, GRACIE
refines its search space for suitable counterfactuals. Now, we map
the rest of the instances in snapshot ğ‘¡into the same latent space
ofÎ©1âˆ’Ë†ğ‘¦and find the top- ğ‘˜closest representations to ğ’›âˆ—. Since ğ’›âˆ—
lies near the center of the latent space, the found counterfactuals
should also be close by. In this way, the top- ğ‘˜counterfactuals are
expected to be reliable since they share the same characteristics
of the instances in ğ‘¡âˆ’1thatÎ©1âˆ’Ë†ğ‘¦has learned to represent. Fig. 2
illustrates the search for counterfactuals.
Dynamic update. In snapshots ğ‘¡>ğ‘¡0, we do not rely on Î¦â€™s
predictions since they might not represent the reality of the new
data (see Fig. 1). Instead, we use the learned representation of the
VGAEs. As described above, at inference, for each graph ğºğ‘¡âˆ—, we find
ğ‘˜candidate counterfactuals close to the center of the Î©1âˆ’Ë†ğ‘¦with
the generatively predicted class Ë†ğ‘¦. We can use these counterfactuals
to update Î©1âˆ’Ë†ğ‘¦, andğºğ‘¡âˆ—to update Î©Ë†ğ‘¦. In this way, both VGAEs
reflect their representations according to the changes in the data.
In the next snapshots, GRACIE is fully unsupervised, relying only
on its generative classification power to search for counterfactuals
and recalibrate the VGAEs representations. We also update logğ‘(ğ‘¦)
according to the classifications in the current snapshot for each
graph and counterfactuals found, such that the classification in the
next snapshots can reflect potential shifts in the class priors.6 EXPERIMENTS
6.1 Datasets, hyperparameters, and evaluation
Datasets. We test GRACIE on a synthetic dataset, namely Dyn-
TreeCycles, generated according to [ 30], and four real datasets,
namely DBLP-Coauthors [ 5], BTCAlpha, BTC-OTC [ 19], and Bo-
nanza [ 6]. We extend TreeCycles [ 42] by introducing the time di-
mension, allowing graphs to evolve in time and potentially change
their class, and name it DynTreeCycles (DTC). DBLP-Coauthors
(DBLP) is a dataset of graphs representing coauthor relationships
where the edge weights indicate the number of collaborations be-
tween two authors in a particular year. We use BTCAlpha (BTC- ğ›¼)
to have an initial investigation for our fraud detection example.
The dataset is a network of who-trust-whom traders on the Bitcoin
Alpha platform, where each trader expresses a trust score ranging
from -10 to +10 on other platform members. BTC-OTC (BTC- ğ›½)
is a similar dataset to BTC- ğ›¼based on the Bitcoin OTC platform.
Bonanza (BNZ) is a marketplace where users can buy/sell goods.
After a purchase, buyers and sellers can rate each other (+1, 0, -1).
All datasets have binary classes. Sec. C provides more details.
Evaluation metrics. We use Validity and Graph Edit Distance
(GED) [32] as evaluation metrics. Since we return a list of counter-
factuals for each input graph, we evaluate GRACIE by reporting
values of these metrics @1,..., @ğ‘˜.
Given a graph ğºand a set of counterfactual candidates Gâ€², Va-
lidity@k measures the correctness of counterfactuals up to the k-th
position. Validity (i.e., Validity@1) assesses whether an individual
counterfactual graph ğºâ€²at position 1 inGâ€²is a correct counter-
factual of the input graph ğº(i.e., 1[Î¦(ğº)â‰ Î¦(ğºâ€²)]). Validity@k
extends this assessment, defined as in Eq. 10.
Validity(ğº,Gâ€²,ğ‘˜)=max
ğ‘–âˆˆ[1,ğ‘˜]1
Î¦(ğº)â‰ Î¦(Gâ€²
ğ‘–)
(10)
In simpler terms, Validity@k is 1 if at least one counterfactual up
to the k-th position in Gâ€²is a correct counterfactual of the input
graphğº. We expect the more counterfactuals we sample from the
latent space, the higher the Validity@k is (see Sec. 6.3).
GED measures the structural difference between ğºand its coun-
terfactualğºâ€². It calculates the distance based on a set of actions
ğ‘1,ğ‘2,...,ğ‘ğ‘›âˆˆP(ğº,ğºâ€²), representing paths to transform ğºinto
ğºâ€². These paths involve adding or removing vertices or edges, with
each actionğ‘ğ‘–associated with a cost ğœ”(ğ‘ğ‘–). We prefer the one closer
to the original instance ğºwhen comparing two counterfactual ex-
amples. Given ğºand a set of counterfactuals Gâ€², GED@k is the
average GED of all ğ‘˜counterfactual candidates, as shown in Eq. 11.
GED(ğº,Gâ€²,ğ‘˜)=1
ğ‘˜ğ‘˜âˆ‘ï¸
ğ‘—=1
min
{ğ‘1,...,ğ‘ ğ‘›}âˆˆP(ğº,Gâ€²
ğ‘—)ğ‘›âˆ‘ï¸
ğ‘–=1ğœ”(ğ‘ğ‘–)
(11)
Fair training/evaluation policy. We split the data using a 90:10
train-test ratio. For each method, we report averages on 10-fold
cross-validation. All methods share the same folds and portion of
the train-test sets on each fold. We use omniscient oracles for each
dataset to model the ground truth at each snapshot. This guarantees
that the methods are evaluated on the real classes.
Baselines. We compare against the only time-dependent approach
in the literature, namely DyGRACE [ 33]. For completeness, we
 
2424KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bardh Prenkaj, Mario VillaizÃ¡n-Vallelado, Tobias Leemann, and Gjergji Kasneci
Table 1: Average of Validity@1 (the higher, the better) on
10-fold cross-validations for all snapshots in each dataset.
Bold values indicate the best-performing approach; under-
lined is the second best; â€ indicates partial results due
to non-convergence on some time steps; Ã—indicates non-
convergence at alla.
D
TC DBLP BTC- ğ›¼BTC-ğ›½ BNZ
BDDS 0.465 0.381 0.360â€ 0.235
0.136
MEG 0.250 0.209Ã— 0.260
0.120â€ 
CLEAR 0.458 0.024 0.214 0.125 0.000
G-CounteRGAN 0.507 0.256 0.236Ã— 0.404
D
yGRACE 0.525
0.307 0.232 0.000â€ 0.232
GRA
CIE 0.600 0.442 0.440 0.284 0.441
aThe criterion of non-convergence is to fail to produce at least one counterfactual
within 14 days of execution on an HPC SGE Cluster of 6 nodes with 360 cumulative
cores, 1.2Tb of RAM, and two GPUs (i.e., one Nvidia A30 and one A100).
adapt CLEAR [ 24] and G-CounteRGAN [ 25], two recent genera-
tive and time-unaware graph counterfactual explainers. We also
compare against a heuristic- and a learning-based method, namely
BDDS [ 1] and MEG [ 27], respectively. We train the explainers5on
the first snapshot and use them to produce counterfactuals in the
other snapshot without further updates on their learned weights.
Hyperparameters. We obtain the best hyperparameters for GRA-
CIE via Bayesian optimization. We set the learning rate to 10âˆ’3; the
batch size to 64for DTC and DBLP, to 24for BTC-ğ›¼and BTC-ğ›½, and
1for BNZ;ğœ†=0.5; the replace rate for the autoencoder to 0.1; the
mask rate to 0.5; the number of attention heads to 16[15]. We set
the number of epochs for DTC to 200and100for the other datasets.
We setğ‘˜=50for DTC and ğ‘˜=10for the others. Sec. D shows the
hyperparameter search spaces and the best choice for all methods.
6.2 Results
Table 1 shows the average Validity@1 over 10-fold cross-validations
for all snapshots in each dataset. GRACIE is the best overall with
an average improvement of 14.3%, 16%, 22.2%, 9.23%, and 3.76%
on, respectively, DTC, DBLP, BTC- ğ›¼, BTC-ğ›½, and BNZ over the
second-best performing strategy. We first conduct a Friedman Test
to show that GRACIE has, statistically and significantly, the best
performance across the board. Here, we obtain a test statistic equal
to15.920with a p-value of .0071. Since the p-value is less than .05,
we can reject the null hypothesis that the average Validity@1 scores
across all datasets are the same for all methods. Then, we perform
a Bonferroni-Dunn post-hoc test where the control explainer is
GRACIE. The corrected p-value, according to Bonferroni, is .05/5=
.01, where 5is the number of comparisons (i.e., GRACIE vs. BDDS,
GRACIE vs. MEG, etc.). The test suggests that GRACIE is statistically
and significantly different (better) across the board (see Table 2).
Fig. 3 shows the Validity@1 and GED@1 of all methods in different
snapshots. GRACIE reaches an average improvement per snapshot
of as much as 23.1%, 73.3%, 120.6%, 36.2%, and 115.7% in DTC, DBLP,
BTC-ğ›¼, BTC-ğ›½, and BNZ, respectively, in Validity@1 over the SoA.
5BDDS is not trained. It perturbs the input graph until it finds a counterfactual.Table 2: P-values produced by the Dunn post-hoc test (with
and without the Bonferroni correction) where the control
explainer is GRACIE.
GRA
CIE
w/o
Bonferroni
(p-value.05)w/ Bonferroni
(p-value.01)
BDDS 2.472Ã—10âˆ’63.708Ã—10âˆ’5
MEG 1.784Ã—10âˆ’152.676Ã—10âˆ’14
G-CounteRGAN 1.090Ã—10âˆ’51.635Ã—10âˆ’4
CLEAR 9.354Ã—10âˆ’131.403Ã—10âˆ’11
D
yGRACE 2.014Ã—10âˆ’63.021Ã—10âˆ’5
Assessing counterfactuals in synthetic scenarios with subtle distri-
butional variations. DTC is a synthetic scenario where the distribu-
tional shifts are not evident. Here, GRACIE has better Validity@1
than the SoA on 3/4 snapshots. CLEAR and G-CounteRGAN sample
from the learned edge probabilities, and do not guarantee break-
ing cycles when going from a cyclic graph to a tree. They have a
Validity@1 ofâˆ¼0.5on all snapshots since they produce complete
stochastic graphs and valid counterfactuals when the input instance
is a tree. This inherent drawback of producing complete graphs
causes these methods to have large GED@1. Only MEG has oscilla-
tory Validity@1, which does not surpass the search-based baseline
BDDS. Lastly, as expected, BDDS has the lowest GED@1 since it
specifically optimizes to minimize it.
Counterfactual performance on real-world datasets. In DBLP, GRA-
CIE outperforms the second-best, BDDS, on 8/11 snapshots. Dy-
GRACE has compelling results for the first snapshot but cannot
discern factuals from counterfactuals in later stages, lacking be-
hind GRACIE of a factor of âˆ¼2in snapshots 7-10. Additionally,
while GRACIEâ€™s Validity@1 has a non-decreasing trend, DyGRACE
plummets, favoring closer counterfactuals to the original graph
despite this major drop. We argue that having valid counterfac-
tuals is more important than being closer to the original graph
without crossing the decision boundary. CLEAR fails to produce
valid counterfactuals, defaulting to returning the original instance,
which accounts for a GED@1 of zero. G-CounteRGAN has a high
standard error in Validity@1, making it the least reliable explainer.
We argue that image-based convolutional operations adopted as
in G-CounteRGAN make it unsuitable for real-world scenarios
with complex topologies. MEG shows drastically fluctuating per-
formances in Validity@1, suggesting that DBLP suffers extremely
from data distribution shifts. Additionally, with each passing snap-
shot, MEG overshoots on the other side of Î¦â€™s decision boundary,
translating into an increasing trend in terms of GED@1.
Interestingly, in BTC- ğ›¼and BTC-ğ›½, the edge directionality is a
challenging representation task for GCNs (also noticed in [ 36]). Nev-
ertheless, GRACIE can represent the edgesâ€™ directionality, reporting
the best Validity@1 on all snapshots. In BTC- ğ›¼, G-CounteRGAN
has a random zig-zag trend on Validity@1, attributed to spurious
learning of the edge probabilities on which counterfactuals are
sampled. CLEAR has the best GED@1 among the competitors, al-
though it is the worst in producing valid counterfactuals. Notice
that GRACIE becomes better at producing valid counterfactuals
(upward Validity@1 trend) and can also search for more similar
 
2425Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
GRA CI EG-CounteRGAND y GRA CEBDDSCLEARMEG0.001230.20.40.60.8V alidity@1D T C
401230.00.10.20.30.40.5BT C-
100123456789DBLP
0.00.10.20.30.40.50.6
1311120123456789100.00.10.20.30.40.50.6BT C-
01234Snapshot050100150200
012345678910Snapshot0100200300400500
3012GED@1Snapshot101210
012345678910111213Snapshot1012310100.00.20.40.60.8
01234BNZ
Snapshot0020040060080010001200
1234
Figure 3: Average Validity@1 (the higher, the better ) and GED@1 (the lower, the better ) on 10-fold cross-validation.
ones w.r.t. the original graph (non-increasing GED@1 trend). Notice
that BDDS does not produce results for all snapshots since it fails
to converge its search space. Lastly, G-CounteRGAN considers the
adjacency matrix a black-and-white image, which does not produce
valid results. Moreover, the plain image convolution operations do
not consider the real topology of the graph, which is node-invariant.
Rather, they consider each node as a fixed pixel in a grid, making
its GED@1 extremely high compared to the SoA.
BTC-ğ›½is the only dataset where DyGRACE cannot produce valid
counterfactuals in the first snapshot. On the other snapshots, it does
not converge within 14 days of execution. After careful examination,
we believe that the training set of the linear regression used to sepa-
rate the factual from counterfactuals is too resource-demanding (i.e.,
a Cartesian product on the learned graph representations), exceed-
ing 13 TB of memory. G-CounteRGAN exceeds 64 TB of memory
due to its flattened downstream linear layers after the convolution
operations. We invite the reader to appreciate this datasetâ€™s com-
plexity since SoA approaches cannot reach a Validity@1 of more
thanâˆ¼0.3in many snapshots. Nevertheless, GRACIEâ€™s Validity@1
trend leads us to believe that the two VGAEs tend to become ex-
perts in correctly representing the two classes after a while (e.g.,
cold-start). We will investigate this in future works.
In BNZ, GRACIE has the steadiest performance similar to the
second-best, G-CounteRGAN, outperforming it on all snapshots
and presenting half the GED@1. Interestingly, DyGRACE has the
best Validity@1 in the first snapshot â€“ better than GRACIE. Nev-
ertheless, it fails to adapt to the data distribution drift in the next
snapshots by not producing valid counterfactual candidates. No-
tice that DyGRACEâ€™s GED@1 is zero since its default behavior is
to return the original graph if it cannot return a counterfactual.
Moreover, by analyzing the Validity@1 and GED@1 trends for GRA-
CIE, DyGRACE, and G-CounteRGAN, as expected, we can state
that they are directly proportionate. For instance, when GED@1
increases, the Validity@1 does so for GRACIE (see snapshots 0-2).
Contrarily, when GED@1 decreases, the Validity@1 decreases for
G-CounteRGAN. MEG does not converge on many snapshots, and
CLEAR fails to explain Î¦, defaulting to produce the original graph.
0.33040506070
Pulling factorGED@1
0.50.70.90.30.20.30.40.5V alidity@1Pulling factor0.60.70.8
0.50.70.9Figure 4: Validity@1 and GED@1 vs. the pulling factor ğœ†.
6.3 Ablation studies
ğœ†â€™s impact on validity and recourse cost: unveiling counterfac-
tual trade-offs. Fig. 4 illustrates Validity@1 and GED@1 when the
pulling parameter ğœ†changes on DBLP. As expected from the the-
oretical observations in Sec. 5, the lower the pulling factor, the
better the chances of finding valid counterfactuals, but the farther
they are w.r.t. the original graph. Contrarily, the higher the pulling
factor, the lower the validity, and the nearer the counterfactuals
(see dashed lines). In other words, for a graph ğºâˆ—with generated
classification Ë†ğ‘¦and its latent representation ğ’›âˆ—=ğœ†ğ‘“ğœ‘âˆ—Â¬ğ‘¦(ğº), when
ğœ†â†’0the pulling factor makes ğ’›âˆ—go towards the center of the
space. This pulling phenomenon aids ğ’›âˆ—in finding neighboring
instances that have a high chance of being valid counterfactuals
sinceğ‘“ğœ‘âˆ—Â¬ğ‘¦is specialized for their representation. Contrarily, the
instances most distant to ğ’›âˆ—, which is now mapped near the center,
are likely to be invalid counterfactuals (cf. Proposition 1). Thus, they
get discarded in the â€œupdateâ€ policy. While we prefer to achieve
a higher validity in finding counterfactuals, ğœ†is a parameter that
permits users to define the trade-off between counterfactual-factual
discernment and generation cost (notice the upward Validity@1
and GED@1 trends when ğœ†â†’0).
Valid counterfactual sampling in the latent representation space.
Fig. 5 illustrates the trend of the Validity@k on 10-fold cross-
validations. Here, we illustrate box plots that indicate the distribu-
tion of the performances for a specific ğ‘˜aggregated for all snapshots.
 
2426KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bardh Prenkaj, Mario VillaizÃ¡n-Vallelado, Tobias Leemann, and Gjergji Kasneci
BT C-
12345678910Numb er of counterfactual candidates
12345678910D T CV alidity@k0.00.20.40.60.81.0
DBLP
12345678910Numb er of counterfactual candidatesNumb er of counterfactual candidates
Numb er of counterfactual candidates
BT C-
1234567891012345678910Numb er of counterfactual candidatesBNZ
Figure 5: Validity (averages on 10-fold cross-validations) trend over all snapshots grouped on the top- ğ‘˜counterfactual candidates.
Numb er of counterfactual candidatesBT C-
Numb er of counterfactual candidatesBT C-2010
2011
20132011V alidity@k
Figure 6: Validity trend on the top- ğ‘˜sampled counterfactuals
expanded for BTC- ğ›¼and BTC-ğ›½. The dashed lines illustrate
those snapshots representing the inliers in the box plots of
Fig. 5. The filled lines are outliers for a specific ğ‘˜.
The plots show that GRACIE benefits from sampling multiple coun-
terfactual candidates, thus leading to consistently better results.
The sampling trend indicates a clear improvement from Validity@1
to Validity@k. Interestingly, in BTC- ğ›¼and BTC-ğ›½, Validity@k is
influenced by outlier scores for particular snapshots, as illustrated
via diamonds. We noticed that the training set of several folds in
the first portions of the monitoring time contains ego networks
with similar structures but different edge weights labeled as fraud
and genuine users. In this way, these similar graphs were used to
train the two VGAEs, which learn a similar representation of both
classes, making it difficult to separate them and correctly update the
counterfactuals in successive snapshots. Fig. 6 expands the box-plot
view for BTC- ğ›¼and BTC-ğ›½of Fig. 5. Here, we show the average
Validity@k for each snapshot expressed in years. The dashed lines
illustrate those years where the average Validity is an inlier w.r.t. to
the box plots of Fig. 5. Meanwhile, full lines show those values for
eachğ‘˜that are outliers. Notice that there is a one-to-one correspon-
dence with the diamonds (outliers) in Fig. 5 and the highlighted lines
in Fig. 6 for BTC- ğ›¼and BTC-ğ›½. For instance, in BTC- ğ›¼, notice how
the Validity@ ğ‘˜in 2013 is normal until ğ‘˜âˆˆ{9,10}. Interestingly,
in BTC-ğ›½, 2011 is an outlier for ğ‘˜âˆˆ[3,10]. Verifying the validity
trend for 2011, we notice that it is the lowest across the board. This
makes us believe that the graphs of the two classes do not have
emphasizing and distinguishable topological characteristics w.r.t.
the other years (snapshots).
6.4 Qualitative Inspection
Fig. 7 illustrates the difference in adjacency matrices between 8
randomly chosen instances from the test set in DTC and their corre-
sponding valid counterfactuals in each snapshot. In each adjacency
10Snapshots
1232345678Figure 7: (best viewed in color) Valid counterfactuals pro-
duced by GRACIE on 8 randomly chosen graphs in the test
set (columns) in DTC for each snapshot.
matrix, we color with white if the edge is neither in the input in-
stance nor in the counterfactual candidate; with redthe removal
of the edge from the original input; with green an addition of the
edge in the counterfactual; and with black an edge both in the input
instance and the counterfactual. This pictorial briefly overviews the
most preeminent edge operations (i.e., adding or removing edges)
and the GED@1 between the original graph and its counterfactual.
For example, a method with a lower GED@1 exposes an overall
blacker image board since there are fewer perturbations on the
original graph. A green-dominated sub-block indicates generating
non-existing edges, while one dominated by red means many re-
moved edges. GRACIE exposes a mixture of the three colors, which
suggests that it supports all three edge perturbation operations. We
are aware that the counterfactuals shown here exhibit many edge
perturbation operations (also supported by the GED@1 in Fig. 3)
due to GRACIEâ€™s learning procedure. Recall from Sec. 5 that each
VGAE learns to represent graphs of the same class. At inference,
for a graphğºâˆ—with predicted class Ë†ğ‘¦(see Proposition. 1), GRACIE
searches for the counterfactuals in the latent space of the VGAE
responsible for representing the opposite class 1âˆ’Ë†ğ‘¦. As shown
in Fig. 2,ğºâˆ—gets mapped into ğ’›and then pulled inwards to ğ’›âˆ—,
shifting the real representation towards the center of the latent
space. Here, the nearest counterfactuals do not necessarily have the
lowest GED w.r.t. ğºâˆ—since we prioritize producing valid counter-
factuals ratherthan closer ones. Notice that one can use the pulling
factorğœ†to engender counterfactuals with lower GED@1 (see Fig.
4). We will investigate how to optimize for GED (a non-convex
and non-differentiable function) to jointly find valid and similar
counterfactuals for a given input graph in future works.
 
2427Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
GRA CI E v s BDDS
a)
e )
c)
d)
b )
0123
Figure 8: (best viewed in color) Qualitative illustration of the difference between the counterfactual candidates produced by
GRACIE and BDDS on all snapshots (rows) on 10%randomly chosen graphs of the test set (columns) in DTC. Each element in
the illustration represents the adjacency matrix of the graphs. We zoom in on three scenarios: a), c), and e) both explainers
produce valid counterfactuals, b) GRACIE fails, and d) BDDS fails.
Since GRACIE and BDDS expose the most similar behavior on
average on all datasets (see Table 1), we decided to directly com-
pare them to understand which is their generation behaviors. Fig.
8 showcases a comparative view of counterfactual candidates gen-
erated by GRACIE and BDDS on DTC. For visualization clarity, we
chose here to represent only 10%of randomly selected graphs from
the test set in the entire dataset. Each image sub-block represents
an adjacency matrix of the produced counterfactual candidate. The
visual encoding employs colors to highlight differences between
the counterfactual outputs of the two explainers. Common edges
shared by both counterfactuals are shaded in black, symbolizing
consensus between the methods. Additionally, edges exclusively
generated by BDDS and not by GRACIE are colored in orange. On
the other hand, edges solely engendered by GRACIE, but not BDDS,
are depicted in blue. The illustration also accounts for graphs where
neither explainer produces a valid counterfactual; these instances
remain blank image sub-blocks within the visualization. Further-
more, instances wherein only one explainer successfully generates
a counterfactual are represented by single-colour adjacency ma-
trices. For instance, a matrix entirely orange implies that GRACIE
fails to produce valid counterfactuals for that instance.
In contrast, a fully blue matrix shows that BDDS fails to gener-
ate viable counterfactuals. Note that GRACIE performs more edge
operations than BDDS (i.e., notice the higher concentration of blue
in the adjacency matrices, as supported by the GED trend in Fig. 3).
Oppositely, BDDS exposes fewer edges in total (i.e., the sum of black
and orange edges vs the sum of black and blue for GRACIE). This
phenomenon is due to BDDSâ€™s underlying oblivious bidirectional
search mechanism, which tries to add/remove edges at each itera-
tion until it reaches a valid counterfactual until a maximum number
of iterations is reached. This visualization effectively highlights thedifferences between GRACIE and BDDS in producing counterfac-
tual candidates across the specified datasets and instances, offering
insights into their strengths and weaknesses.
7 CONCLUSION
We presented GRACIE, one of the first generative approaches to
address dynamic counterfactual explainability in the context of
temporal graphs. GRACIE leverages VGAEs, self-supervisedly, to
learn class representations and adapt to data distribution shifts that
might invalidate counterfactuals in time. Unlike other approaches,
GRACIE does not assume linear separatability between the latent
representations. We performed extensive experiments on one syn-
thetic and four real-world dynamic graph datasets, with an im-
provement ofâˆ¼13.1%in producing more valid counterfactuals than
SoA approaches. We demonstrated that exploiting the pulling factor
aligns with our intuition that the center of the latent space of the
VGAEs should be used to find valid counterfactuals, maintaining
a good trade-off with the similarity with the input. We also illus-
trated that sampling more candidates near the latent representation
produces valid counterfactuals.
In the future, we will explore multi-class problems and the ability
of GRACIE to generalize, simultaneously producing valid never-
seen-before counterfactuals for multiple classes. Another avenue
for investigation is to improve the class representations via more
potent generative models. Lastly, we will incorporate uncertainty in
determining valid counterfactuals during their search in the latent
space. A possible direction could be to rely on hyperbolic spaces
and exploit their intrinsic uncertainty modeling.
 
2428KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bardh Prenkaj, Mario VillaizÃ¡n-Vallelado, Tobias Leemann, and Gjergji Kasneci
REFERENCES
[1]Carlo Abrate and Francesco Bonchi. 2021. Counterfactual graphs for explainable
classification of brain networks. In Proc. of the 27th ACM SIGKDD Conference on
Knowledge Discovery & Data Mining. 2495â€“2504.
[2]Uri Alon and Eran Yahav. 2021. On the Bottleneck of Graph Neural Networks
and its Practical Implications. In 9th International Conference on Learning Repre-
sentations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.
[3]Lynton Ardizzone, Radek Mackowiak, Carsten Rother, and Ullrich KÃ¶the. 2020.
Training normalizing flows with the information bottleneck for competitive
generative classification. Advances in Neural Information Processing Systems 33
(2020), 7828â€“7840.
[4]Mohit Bajaj, Lingyang Chu, Zi Yu Xue, Jian Pei, Lanjun Wang, Peter Cho-Ho
Lam, and Yong Zhang. 2021. Robust counterfactual explanations on graph neural
networks. Advances in Neural Information Processing Systems 34 (2021), 5644â€“
5655.
[5]Austin R Benson, Rediet Abebe, Michael T Schaub, Ali Jadbabaie, and Jon Klein-
berg. 2018. Simplicial closure and higher-order link prediction. Proc. of the
National Academy of Sciences 115, 48 (2018), E11221â€“E11230.
[6]Tyler Derr, Cassidy Johnson, Yi Chang, and Jiliang Tang. 2019. Balance in
signed bipartite networks. In Proc. of the 28th ACM International Conference on
Information and Knowledge Management. 1221â€“1230.
[7]Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of inter-
pretable machine learning. arXiv preprint arXiv:1702.08608 (2017).
[8]Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, and Philip S Yu. 2020.
Enhancing graph neural network-based fraud detectors against camouflaged
fraudsters. In Proc. of the 29th ACM international conference on information &
knowledge management. 315â€“324.
[9]European Union. 2016. Regulation (EU) 2016/679 of the European Parliament
and of the Council. Official Journal of the European Union (2016).
[10] European Union. 2023. Laying Down Harmonised Rules on Artificial Intelligence
(Artificial Intelligence Act) and Amending Certain Union Legislative Acts. Official
Journal of the European Union (2023).
[11] L. Faber, A. K. Moghaddam, and R. Wattenhofer. 2020. Contrastive Graph Neural
Network Explanation. In Proc. of the 37th Graph Repr. Learning and Beyond
Workshop at ICML 2020. Int. Conf. on Machine Learning, 28.
[12] Shaohua Fan, Xiao Wang, Chuan Shi, Emiao Lu, Ken Lin, and Bai Wang. 2020.
One2multi graph autoencoder for multi-view graph clustering. In proceedings of
the web conference 2020. 3070â€“3076.
[13] Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin.
2019. Graph neural networks for social recommendation. In The world wide web
conference. 417â€“426.
[14] Johannes Haug and Gjergji Kasneci. 2021. Learning parameter distributions to
detect concept drift in data streams. In 2020 25th International Conference on
Pattern Recognition (ICPR). IEEE, 9452â€“9459.
[15] Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang,
and Jie Tang. 2022. Graphmae: Self-supervised masked graph autoencoders.
InProc. of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data
Mining. 594â€“604.
[16] Diederik P Kingma, Max Welling, et al .2019. An introduction to variational
autoencoders. Foundations and TrendsÂ® in Machine Learning 12, 4 (2019), 307â€“392.
[17] Thomas N Kipf and Max Welling. 2016. Variational graph auto-encoders. In
NeurIPS Workshop on Bayesian Deep Learning.
[18] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In 5th International Conference on Learning
Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track
Proc. OpenReview.net.
[19] Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos Faloutsos, and
VS Subrahmanian. 2018. Rev2: Fraudulent user prediction in rating platforms.
InProc. of the Eleventh ACM International Conference on Web Search and Data
Mining. 333â€“341.
[20] Eren Kurshan and Hongda Shen. 2020. Graph computing for financial crime
and fraud detection: Trends, challenges and outlook. International Journal of
Semantic Computing 14, 04 (2020), 565â€“589.
[21] Yingzhen Li, John Bradshaw, and Yash Sharma. 2019. Are generative classi-
fiers more robust to adversarial attacks?. In International Conference on Machine
Learning. PMLR, 3804â€“3814.
[22] Zelong Li, Jianchao Ji, and Yongfeng Zhang. 2022. From Kepler to Newton:
Explainable AI for Science Discovery. In ICML 2022 2nd AI for Science Workshop .
[23] Lorenzo Livi and Antonello Rizzi. 2013. The graph matching problem. Pattern
Analysis and Applications 16 (2013), 253â€“283.
[24] Jing Ma, Ruocheng Guo, Saumitra Mishra, Aidong Zhang, and Jundong Li. 2022.
CLEAR: Generative Counterfactual Explanations on Graphs. In Advances in
Neural Information Processing Systems, Alice H. Oh, Alekh Agarwal, Danielle
Belgrave, and Kyunghyun Cho (Eds.).[25] Daniel Nemirovsky, Nicolas Thiebaut, Ye Xu, and Abhishek Gupta. 2022. Coun-
teRGAN: Generating counterfactuals for real-time recourse and interpretability
using residual GANs. In Proc. of the Thirty-Eighth Conference on Uncertainty
in Artificial Intelligence, UAI 2022, 1-5 August 2022, Eindhoven, The Netherlands ,
Vol. 180. PMLR, 1488â€“1497.
[26] Andrew Ng and Michael Jordan. 2001. On discriminative vs. generative classi-
fiers: A comparison of logistic regression and naive bayes. Advances in neural
information processing systems 14 (2001).
[27] Danilo Numeroso and Davide Bacciu. 2021. Meg: Generating molecular coun-
terfactual explanations for deep graph networks. In 2021 International Joint
Conference on Neural Networks (IJCNN). IEEE, 1â€“8.
[28] Martin Pawelczyk, Klaus Broelemann, and Gjergji. Kasneci. 2020. On Counter-
factual Explanations under Predictive Multiplicity. In Proc. of the 36th Conference
on Uncertainty in Artificial Intelligence (UAI). PMLR, 809â€“818.
[29] Martin Pawelczyk, Tobias Leemann, Asia Biega, and Gjergji Kasneci. 2023. On
the Trade-Off between Actionable Explanations and the Right to be Forgotten.
InProc. of the Eleventh International Conference on Learning Representations.
[30] Mario Alfonso Prado-Romero, Bardh Prenkaj, and Giovanni Stilo. 2023. Devel-
oping and Evaluating Graph Counterfactual Explanation with GRETEL. In Proc.
of the Sixteenth ACM International Conference on Web Search and Data Mining.
1180â€“1183.
[31] Mario Alfonso Prado-Romero, Bardh Prenkaj, and Giovanni Stilo. 2024. Robust
Stochastic Graph Generator for Counterfactual Explanations. In Proc. of the AAAI
Conference on Artificial Intelligence, Vol. 38. 21518â€“21526.
[32] Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo, and Fosca Giannotti.
2024. A Survey on Graph Counterfactual Explanations: Definitions, Methods,
Evaluation, and Research Challenges. ACM Comput. Surv. 56, 7 (apr 2024).
[33] Bardh Prenkaj, Mario Villaizan-Vallelado, Tobias Leemann, and Gjergji Kasneci.
2023. Adapting to Change: Robust Counterfactual Explanations in Dynamic Data
Landscapes. arXiv:2308.02353 [cs.LG]
[34] Christian Raymond and Giuseppe Riccardi. 2007. Generative and discriminative
algorithms for spoken language understanding. In Interspeech 2007-8th Annual
Conference of the International Speech Communication Association.
[35] Manon RÃ©au, Nicolas Renaud, Li C Xue, and Alexandre MJJ Bonvin. 2023.
DeepRank-GNN: a graph neural network framework to learn patterns in proteinâ€“
protein interfaces. Bioinformatics 39, 1 (2023), btac759.
[36] Emanuele Rossi, Bertrand Charpentier, Francesco Di Giovanni, Fabrizio Frasca,
Stephan GÃ¼nnemann, and Michael M Bronstein. 2024. Edge directionality im-
proves learning on heterophilic graphs. In Learning on Graphs Conference. PMLR,
25â€“1.
[37] Statista. 2023. Value of e-commerce losses to online payment fraud worldwide
from 2020 to 2023. https://www.statista.com/statistics/1273177/ecommerce-
payment-fraud-losses-globally/.
[38] Ilkay Ulusoy and Christopher M Bishop. 2006. Comparison of generative and
discriminative techniques for object detection and classification. In Toward
Category-Level Object Recognition. Springer, 173â€“195.
[39] Sohini Upadhyay, Shalmali Joshi, and Himabindu Lakkaraju. 2021. Towards
Robust and Reliable Algorithmic Recourse. In Advances in Neural Information
Processing Systems (NeurIPS), Vol. 34.
[40] Sandra Wachter, Brent Mittelstadt, and Chris Russell. 2017. Counterfactual
explanations without opening the black box: Automated decisions and the GDPR.
Harv. JL & Tech. 31 (2017), 841.
[41] Xuemei Wei, Yezheng Liu, Jianshan Sun, Yuanchun Jiang, Qifeng Tang, and Kun
Yuan. 2022. Dual subgraph-based graph neural network for friendship prediction
in location-based social networks. ACM Transactions on Knowledge Discovery
from Data (TKDD) (2022).
[42] Z. Ying, D. Bourgeois, J. You, M. Zitnik, and J. Leskovec. 2019. Gnnexplainer: Gen-
erating explanations for graph neural networks. Advances in neural information
processing systems 32 (2019).
A DECOMPOSITION OF THE ELBO
Letğº=(ğ‘¨,ğ‘¿)âˆˆAÃ—X , whereAâŠ‚Rğ‘›Ã—ğ‘›represents possible
adjacency matrices and XâŠ‚Rğ‘›represents possible node features.
Letğ’›âˆˆZâŠ‚ Rğ‘˜be a latent representation, where usually ğ‘›â‰«ğ‘˜.
Note that we can construct a mapping from graphs Gto a Euclidean
spaceX, so the above results also apply where ğºis a graph. Let ğ‘ğœƒ
be the distribution induces by the generative decoder ğ‘”ğœƒ:Zâ†’X
with parameters ğœƒandğ‘ğœ‘be the distribution induces by the encoder
ğ‘“ğœ‘:Xâ†’Z with parameters ğœ‘. We can derive the following lower
bound on the posterior probability, which is known as the evidence
 
2429Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
lower bound (ELBO)
logğ‘(ğº)=logâˆ«
Zğ‘ğœƒ(ğº,ğ’›)ğ‘‘ğ’›
=logâˆ«
Zğ‘ğœ‘(ğ’›|ğº)
ğ‘ğœ‘(ğ’›|ğº)ğ‘ğœƒ(ğº,ğ’›)ğ‘‘ğ’›
=logEğ‘ğœ‘(ğ’›|ğº)ğ‘ğœƒ(ğº,ğ’›)
ğ‘ğœ‘(ğ’›|ğº)
â‰¥Eğ‘ğœ‘(ğ’›|ğº)
logğ‘ğœƒ(ğº,ğ’›)
ğ‘ğœ‘(ğ’›|ğº)
=Eğ‘ğœ‘(ğ’›|ğº)
logğ‘ğœƒ(ğº|ğ’›)ğ‘ğœƒ(ğ’›)
ğ‘ğœ‘(ğ’›|ğº)
=Eğ‘ğœ‘(ğ’›|ğº)[logğ‘ğœƒ(ğº|ğ’›)]+Eğ‘ğœ‘(ğ’›|ğº)[logğ‘ğœƒ(ğ’›)]
âˆ’Eğ‘ğœ‘(ğ’›|ğº)
logğ‘ğœ‘(ğ’›|ğº)
BLğ‘Ÿğ‘’ğ‘+Lğ‘‘ğ‘–ğ‘ ğ‘¡âˆ’Lğ‘¢ğ‘›ğ‘ğ‘’ğ‘Ÿğ‘¡BELBOğœ™,ğœƒ(ğº)(12)
We now plug in the proposed parametric densities:
ğ‘ğœƒ(ğ’›)âˆ¼N( ğ’›;0,ğ‘°)
ğ‘ğœƒ(ğ‘¨|ğ’›)âˆ¼N( ğ‘¨;ğ‘”ğœƒ(ğ’›),ğœ2ğ‘°)
ğ‘ğœƒ(ğ‘¿|ğ‘¨,ğ’›)âˆ¼N( ğ‘¿;â„ğœƒ(ğ‘¨,ğ’›),ğœ2ğ‘°)
ğ‘ğœ‘(ğ’›|ğº)âˆ¼N( ğ’›;ğ‘“ğœ‘(ğº),ğ›¾2ğ‘°)(13)
In our problem setup, we specifically have
ğ‘“ğœ‘(ğº)=GCNğœ‘ğ‘¦(ğº) (14)
andğ‘”ğœƒis defined for each element (ğ‘£ğ‘–,ğ‘£ğ‘—)via
ğ‘”ğœƒ(ğ’›)ğ‘£ğ‘–,ğ‘£ğ‘—=ğ´ğœƒ(ğ‘§ğ‘–)âŠ¤ğ´ğœƒ(ğ‘§ğ‘—) (15)
whereğ´ğœƒis a mapping and â„ğœƒis again defined through a GCN (or
any NN), i.e.,
â„ğœƒ(ğ‘¨,ğ’›)=GCNğœƒ(ğ‘¨,ğ’›) (16)
We can condense
logğ‘ğœƒ(ğº|ğ’›)=logğ‘ğœƒ(ğ‘¨|ğ’›)+logğ‘ğœƒ(ğ‘¿|ğ‘¨,ğ’›)
=âˆ’1
2Eğ‘ğœ‘(ğ’›|ğº)"
âˆ¥ğ‘”ğœƒ(ğ’›)âˆ’ğ‘¨âˆ¥2
2
ğœ2#
âˆ’1
2Eğ‘ğœ‘(ğ’›|ğº)"
âˆ¥â„ğœƒ(ğ‘¨,ğ’›)âˆ’ğ‘¿âˆ¥2
2
ğœ2#
âˆ’ğ‘™+ğ‘š
2(log 2ğœ‹+logğœ2)
=âˆ’1
2Eğ‘ğœ‘(ğ’›|ğº)"
âˆ¥ğ‘”â€²
ğœƒ(ğ’›)âˆ’ğºâˆ¥2
2
ğœ2#
âˆ’ğ‘™+ğ‘š
2(log 2ğœ‹+logğœ2)(17)
Instead of writing the two-step decoding process, we will now
introduceğ‘”â€²
ğœƒ(ğ’›)which denotes the entire stochastic generating
process such that ğº=(ğ‘¨,ğ‘¿)=ğ‘”â€²
ğœƒ(ğ’›), and denote the sum of the
two error normsâˆ¥ğ‘”â€²
ğœƒ(ğ’›)âˆ’ğºâˆ¥2
2=âˆ¥ğ‘”ğœƒ(ğ’›)âˆ’ğ‘¨âˆ¥2
2+âˆ¥â„ğœƒ(ğ‘¨,ğ’›)âˆ’ğ‘¿âˆ¥2
2
This results in
Lğ‘Ÿğ‘’ğ‘=âˆ’1
2Eğ‘ğœ‘(ğ’›|ğº)"
âˆ¥ğ‘”â€²
ğœƒ(ğ’›)âˆ’ğºâˆ¥2
2
ğœ2#
âˆ’ğ‘™+ğ‘š
2(log 2ğœ‹+logğœ2)(18)
Lğ‘‘ğ‘–ğ‘ ğ‘¡=âˆ’CE[ğ‘ğœ‘(ğ’›|ğº)),ğ‘ğœƒ(ğ’›)]
=âˆ’DKL[ğ‘ğœ‘(ğ’›|ğº)),ğ‘ğœƒ(ğ’›)]âˆ’ğ»[ğ‘ğœ‘(ğ’›|ğº))]
=Eğ‘ğœ‘(ğ’›|ğº)"
âˆ¥ğ’›âˆ¥2
2
2#
âˆ’ğ‘˜
2log 2ğœ‹=âˆ’ğ‘˜
2
log 2ğœ‹+ğ›¾2
âˆ’1
2âˆ¥ğ‘“ğœ‘(ğº)âˆ¥2
2
(19)âˆ’Lğ‘¢ğ‘›ğ‘ğ‘’ğ‘Ÿğ‘¡ =Eğ‘ğœ‘(ğ’›|ğº)"
âˆ¥ğ’›âˆ’ğ‘“ğœ‘(ğº)âˆ¥2
2
2ğœ2#
+ğ‘˜
2log 2ğœ‹+1
2log|ğ›¾2I|
=ğ‘˜
2
log 2ğœ‹+1+logğ›¾2
=const.
(20)
In summary, the log probability can be approximated by
ELBOğœ™,ğœƒ(ğº)âˆLğ‘‘ğ‘–ğ‘ ğ‘¡+Lğ‘Ÿğ‘’ğ‘
âˆâˆ’1
2 
Eğ‘ğœ‘(ğ’›|ğº)"
âˆ¥ğ‘”ğœƒ(ğ’›)âˆ’ğºâˆ¥2
2
ğœ2#
+âˆ¥ğ‘“ğœ‘(ğº)âˆ¥2
2!
(21)
In summary, we assign a high likelihood to samples encoded close
to the center and have good reconstruction.
B GENERATIVE CLASSIFICATION WITH
VGAES
In classification problems, we attempt to predict the class Ë†ğ‘¦âˆˆY
with the highest posterior probability. If we have a class conditional
distribution model, we can reformulate the terms to arrive at the
following formulation:
Ë†ğ‘¦=argmax
ğ‘¦âˆˆYğ‘(ğ‘¦|ğº)=argmax
ğ‘¦âˆˆYğ‘(ğº|ğ‘¦)ğ‘(ğ‘¦)
ğ‘(ğº)
=argmax
ğ‘¦âˆˆYlogğ‘(ğº|ğ‘¦)+logğ‘(ğ‘¦)(22)
Suppose we now have a converged conditional density model with
class-dependent decoders ğ‘”ğœƒğ‘¦and encoders ğ‘“ğœ‘ğ‘¦such that we can
compute logğ‘(ğº|ğ‘¦)as in Eqn. 22 (we basically add the condition
onğ‘¦to all the terms). If the density model is expressive enough,
i.e., it covers the ground truth distribution, maximizing the ELBO
results in a likelihood that represents the true likelihood [ 16]. We
then have
ELBOğœ™âˆ—,ğœƒâˆ—(ğº|ğ‘¦)=logğ‘(ğº|ğ‘¦) (23)
whereğœ™âˆ—,ğœƒâˆ—are the maximizing parameters of the ELBO. Plugging
in the results, we obtain
Ë†ğ‘¦=argmax
ğ‘¦âˆˆYlogğ‘(ğº|ğ‘¦)+ğ‘=argmax
ğ‘¦âˆˆYELBOğœ™âˆ—,ğœƒâˆ—(ğº|ğ‘¦)+ğ‘
=argmax
ğ‘¦âˆˆYâˆ’1
2
E
ğ‘ğœ‘âˆ—(ğ’›|ğº,ğ‘¦)"âˆ¥ğ‘”ğœƒâˆ—ğ‘¦(ğ’›)âˆ’ğºâˆ¥2
2
ğœ2#
+âˆ¥ğ‘“ğœ‘âˆ—ğ‘¦(ğº)âˆ¥2
2
+ğ‘
=argmin
ğ‘¦âˆˆY1
2
E
ğ‘ğœ‘âˆ—(ğ’›|ğº,ğ‘¦)"âˆ¥ğ‘”ğœƒâˆ—ğ‘¦(ğ’›)âˆ’ğºâˆ¥2
2
ğœ2#
+âˆ¥ğ‘“ğœ‘âˆ—ğ‘¦(ğº)âˆ¥2
2
âˆ’ğ‘,
(24)
whereğ‘=logğ‘(ğ‘¦).
C DATASETS
Here, we provide details on the datasets used to assess the perfor-
mance of GRACIE. Table 3 illustrates the their characteristics.
DynTree-Cycles (DTC) contains cyclic (1) and acyclic (0) graphs, and
it is an established benchmark dataset for graph counterfactuals [ 4].
We extend this dataset by introducing the time dimension, allowing
graphs to evolve in time and potentially change their class, and
name it DynTree-Cycles (DTC). We repeat the dataset generation
in [32] at each time step. In this way, a particular graph ğºğ‘¡
ğ‘–can
change its structure in ğ‘¡+1and remain in the same class or move
to the opposite one. This emulates a synthetic process of tracing
the evolution of the graphs in the dataset according to time. Here,
 
2430KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Bardh Prenkaj, Mario VillaizÃ¡n-Vallelado, Tobias Leemann, and Gjergji Kasneci
Table 3: Statistics of the datasets.
D
TC DBLP BTC- ğ›¼ BTC-ğ›½ BNZ
#
of time steps 4 10 13 5 5
# of instances per time step 2,000 739 756 310 500
Avg # of nodes 28 13.54 82.29 12.38 39.86
Avg # of edges 27.62 41.91 152.12 27.09 251.42
Max # of nodes 28 148 278 349 382
Avg (out) node degree 1.97 4.12 3.62 2.46 5.19
# of classes 2 2 2 2 2
Class distribution at ğ‘¡0 46.5 : 53.5 75.5 : 24.5 78.2 : 21.8 81.7: 18.3 55.8 : 44.2
Graph type undirected undirected directed directed directed
we guarantee that the number of instances per snapshot is the
same. All the instances in the dataset contain the same number
of nodes and are connected graphs. Notice that the dataset has a
balanced distribution between its two classes, making it conducive
for learning-based explainers. However, its average node degree of
1.97suggests the graphs are sparsely connected, challenging GCNs
to capture intricate relationships between the nodes.
Additionally, notice that this dataset poses a difficult scenario
since explainers need to learn both edge additions/removal oper-
ations given the duality aspect of the instances. In other words,
explainers need to learn how to remove edges to pass from a cyclic
graph to an acyclic graph and how to add edges to pass from a tree
to a cyclic graph. Although the dataset poses a difficult scenario for
most learning-based approaches â€“ see Table 1 â€“ GRACIE does not
need to learn how to add or cut edges for an input graph. GRACIEâ€™s
two-class representations and its neighboring mechanism permits
us to search for counterfactual candidates entirely in the latent
space.
DBLP-Coauthors (DBLP) consists of graphs representing authors,
where edges denote co-authorship relationships and edge weights
signify the number of collaborations in a given year. We focus on
the time frame[2000,2010]and consider ego-networks of authors
with at least ten collaborations in 2000. To trace the ego-network
evolution from 2000 to2010, we propagate ego-networks from the
previous year whenever an author has no collaborations in a spe-
cific yearğ‘¡. Ego networks are labeled 1if the central node has an
impactful network in a particular year ğ‘¡w.r.t. the other instances;
otherwise, we assign a 0. Here the graphs exhibit a notably higher
average node degree of 4.12, implying denser interconnectivity
between nodes. This characteristic may present challenges in han-
dling the complexity of interrelated features and distinguishing
relevant patterns. Additionally, the graphs are, on average, big-
ger than in DTC which makes the GCNs harder to learn effective
node representations due to the â€œrepresentational clashâ€ of their
receptive field [2].
BTCAlpha (BTC- ğ›¼) and BTC-OTC (BTC- ğ›½)link to our initial fraud de-
tection example and consist of who-trust-whom networks of traders
on the Bitcoin Alpha and Bitcoin OTC platforms, respectively. Since
Bitcoin users are anonymous, there is a need to maintain a record
of usersâ€™ reputations to prevent transactions with fraudulent and
risky users. Members of the platforms rate others on a scale of -10
(total distrust) to +10 (total trust). For each year ğ‘¡in the dataset,
we trace the connected components of the graph at time step ğ‘¡and
label each one with 1if it contains more â€œfraudulent" ratings than
trustworthy ones; otherwise, with 0. It is interesting to notice thatthe graphs in this dataset are directed (i.e., asymmetric adjacency
matrices), which might hamper [ 18] the performances of the graph
convolution layers in the VGAEs (see BTC- ğ›½in Fig. 3 and 6).
Bonanza (BNZ). The Bonanza website is similar to eBay and Amazon
Marketplace in that users create an account to buy or sell various
goods. After a buyer purchases a product from a seller, both can
provide a rating about the other along with a short comment. At the
time of collection, Bonanza was using a rating scale of Positive (+1),
Neutral (0), and Negative (-1) to rate another user after a transaction.
For each year ğ‘¡in the dataset, we trace the connected components
of the ego-network of each seller and label with 1if it contains at
least ten good reviews (i.e., the ratingsâ€™ sum of its induced edges is
â‰¥10); otherwise, with 0.
D HYPERPARAMETER SETTINGS
We rely on Bayesian optimization to obtain the best parameters for
GRACIE and DyGRACE. We do the hyperparameter optimization
only on the first time step ğ‘¡0with objective function Validity@1.
For GRACIE, we use the search spaces in Table 4. For DyGRACE,
we use the hyperparameters in Table 5.
Table 4: The hyperparameter search spaces and best choice
for each dataset for GRACIE.
Hyp
erparameter Search spaceBest Choice
D
TC DBLP BTC- ğ›¼BTC-ğ›½BNZ
Learning
rate{10âˆ’4,10âˆ’3,10âˆ’2,10âˆ’1} 10âˆ’310âˆ’310âˆ’310âˆ’310âˆ’3
Batch size {1,2,4,8,16,24,32,64} 64 64 24 24 1
Epochs [50,350] with a step of 50 200 100 100 100 100
ğ‘˜ [10,100] with a step of 10 50 10 10 10 10
Table 5: The hyperparameter search spaces and best choice
for each dataset for DyGRACE.
Hyp
erparameter Search spaceBest Choice
D
TC DBLP BTC- ğ›¼BTC-ğ›½BNZ
Learning
rate{10âˆ’4,10âˆ’3,10âˆ’2,10âˆ’1} 10âˆ’310âˆ’410âˆ’110âˆ’110âˆ’3
Batch size {1,2,4,8,16,24,32,64} 24 24 4 4 1
Encoder out. dim. [1,8] 2 4 4 4 2
Epochs [10,300] with a step of 100 20 150 100 100 100
ğ‘˜ [5,50]with a step of 5 50 10 10 10 10
We follow the suggestion of [ 32] to set the hyperparameters for
the time-unrelated strategies (i.e., CLEAR, G-CounteRGAN, and
MEG). For CLEAR, we set the epochs to 50,ğ›¼=0, the dropout to
0.1,ğœ†ğ‘ğ‘“ğ‘’=0.1,ğœ†ğ‘˜ğ‘™=0.1,ğœ†ğ‘ ğ‘–ğ‘š=0.1, learning rate to 10âˆ’3, and
weight decay to 10âˆ’5. For G-CounteRGAN, we set the number of
training iterations to 250, the number of discriminator steps to 3, the
number of generator steps to 2, and the binarization threshold to 0.5.
For MEG, we set a maximum of 10steps to perturb the adjacency
matrix of the input graphs. We set the number of episodes to 10, the
learning rate to 10âˆ’4, the batch size to 1since it can only perturb
one graph at a time, ğ›¾=0.95, and polyak to 0.995. Finally, we derive
the input dimension MEG requires as ğ‘›2whereğ‘›is the maximum
number of nodes in a dataset.
 
2431