Personalized Product Assortment with Real-time 3D Perception
and Bayesian Payoff Estimation
Porter Jenkins
pjenkins@cs.byu.edu
Brigham Young University
Department of Computer Science
Provo, UT, United StatesMichael Selander
michael.selander@deliciousai.com
Delicious AI
Lehi, UT, United StatesJ. Stockton Jenkins
stockton.jenkins@deliciousai.com
Delicious AI
Lehi, UT, United States
Andrew Merrill
andrew.merrill@deliciousai.com
Delicious AI
Lehi, UT, United StatesKyle Armstrong
kyle.armstrong@deliciousai.com
Delicious AI
Lehi, UT, United States
Abstract
Product assortment selection is a critical challenge facing physi-
cal retailers. Effectively aligning inventory with the preferences
of shoppers can increase sales and decrease out-of-stocks. How-
ever, in real-world settings the problem is challenging due to the
combinatorial explosion of product assortment possibilities. Con-
sumer preferences are typically heterogeneous across space and
time, making inventory-preference alignment challenging. Addi-
tionally, existing strategies rely on syndicated data, which tends
to be aggregated, low resolution, and suffer from high latency. To
solve these challenges, we introduce a real-time recommendation
system, which we call EdgeRec3D . Our system utilizes recent ad-
vances in 3D computer vision for perception and automatic, fine
grained sales estimation. These perceptual components run on the
edge of the network and facilitate real-time reward signals. Addi-
tionally, we develop a Bayesian payoff model to account for noisy
estimates from 3D LIDAR data. We rely on spatial clustering to
allow the system to adapt to heterogeneous consumer preferences,
and a graph-based candidate generation algorithm to address the
combinatorial search problem. We test our system in real-world
stores across two, 6-8 week A/B tests with beverage products and
demonstrate a 35% and 27% increase in sales respectively. Finally,
we monitor the deployed system for a period of 28 weeks with an
observational study and show a 9.4% increase in sales.
CCS Concepts
â€¢Information systems â†’Personalization.
Keywords
Recommender Systems, Product Assortment, 3D Computer Vision,
Bayesian Reward Models
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671518ACM Reference Format:
Porter Jenkins, Michael Selander, J. Stockton Jenkins, Andrew Merrill,
and Kyle Armstrong. 2024. Personalized Product Assortment with Real-
time 3D Perception and Bayesian Payoff Estimation. In Proceedings of the
30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
11 pages. https://doi.org/10.1145/3637528.3671518
1 Introduction
The problem of effectively allocating shelf space is one of the most
critical decisions facing physical retailers [ 49]. Optimal placement
of physical product increases sales and decreases excess inventory.
Prior work has shown that good product allocation can call the
consumerâ€™s attention and encourage â€œimpulseâ€ purchases [ 5,24,35].
In most real-world scenarios, the number of available products
far exceeds the amount of available shelf space. Additionally, the
retailer must consider varying attributes of products such as price,
shape, and dynamic consumer preferences. As such, the product
assortment problem is a combinatorial decision problem.
A variety of previous work seeks to solve the shelf space allo-
cation problem. Classical optimization methods such as integer
[21,49] linear, and dynamic [ 52] programming, genetic algorithms
[11,47,51] and simulated annealing approaches [ 9] have been ex-
tensively studied. More recently, the Data Mining field has sought
to replace the formal space elasticity optimization problem with
association rule mining [ 10,15,38,46], and collaborative filtering
[39] as they can better leverage large-scale databases to generate
effective product sets. In practice, these methods typically rely on
syndicated data1as input. These datasets tend to be aggregated, of
low resolution, and can take weeks or months to assemble. In con-
trast, this work offers a solution to produce similar data instantly,
in the hand of the person who needs it. A real-time approach to the
problem is critical because it closes the feedback loop and facilitates
faster discovery and convergence to shopper preferences.
The problem of real-time product assortment recommendation
has four core challenges. First, obtaining sales estimates in real-time
is not possible under current methodologies. Second, the problem
is a special case of the knapsack problem [ 19,49], a well-known
combinatorial optimization problem, and is therefore NP-complete.
1Syndicated data refers to retail sales data that is aggregated across many stores and
sold by third parties
5161
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Porter Jenkins, Michael Selander, J. Stockton Jenkins, Andrew Merrill, and Kyle Armstrong
(a) Display states: before and after recommendation
 (b) Recommended Change #1
 (c) Recommended Change #2
Figure 1: The product assortment problem can be described as choosing the set of products, and corresponding quantities, that
will maximize expected payoff, subject to the total number of discrete locations (slots) within the product display. Our system
maximizes expected payoff, while accounting for uncertainty.
The number of possible combinations grows factorially, and follows
the equation:
ğ‘=ğ‘+ğ‘šâˆ’1
ğ‘š
=(ğ‘+ğ‘šâˆ’1)!
ğ‘š!(ğ‘âˆ’1)!(1)
forğ‘products and ğ‘šdiscrete product locations, or slots. Even
in somewhat small sub-problems comprised of a shelf with 20 slots
and 100 products the number of possible combinations is 2.5Ã—
1022. Second, most retail outlets are dynamical systems. The set of
products on display frequently changes to account for out-of-stocks
or supply chain constraints. Third, preferences are heterogeneous
across both time and space [ 1,2,25,42]. Limited time products are
periodically introduced into the market to satisfy seasonal demand.
Additionally, product space allocation should be targeted to meet
preferences that vary with respect to demographics. For example,
a store near a college campus might sell more energy drinks than a
store with an older population of customers. Classical methods are
unable to account for these issues.
To solve these challenges, we design a large-scale recommender
system, which we call EdgeRec3D . The system guides retail workers
and recommends the appropriate product set to put on display. A
key differentiator of our system is that we use on-edge, 3D computer
vision models [ 26] for real-time perception and automatic sales
estimation. This real-time perceptual layer is implemented at the
edge of the network, making it easy to implement the recommended
set quickly, and closes the feedback loop under changing market
dynamics. A major trade-off under this design is the introduction of
noise into estimates of sales. To quantify our uncertainty of product
sales due to this observation noise, we propose a Robust Bayesian
Payoff (RBP) reward model that learns the posterior distribution
of product payoff2. We address the combinatorial search problem
with intelligent candidate generation, along with a simple heuristic
search based on an uncertainty penalized ranking statistic, which
discounts uncertain recommendations. A novel spatial clustering
technique along with the hierarchical parameterization of RBP
allow for targeted recommendations and help solve the preference
heterogeneity problem.
2In this paper, we use the terms payoff andreward interchangeablyWe validate our recommender system by running both offline
and online experiments. Offline, EdgeRec3D outperforms classic
methods such as Linear Programming, Dynamic Programming, ğœ–-
greedy, Genetic algorithms and modern techniques such as deep
ensembles and model-based offline RL. Moreover, we perform two
real-world A/B tests, each lasting 6-8 weeks. In these two controlled
experiments, we demonstrate a 35% and 27% increase in product-
level sales, respectively. Finally, a 28 week deployment study results
in a 9.4% increase in product-level sales. Our key contributions can
be summarized by the following:
â€¢We propose EdgeRec3D , a real-time, 3D computer vision rec-
ommender system to solve the shelf space allocation problem.
The system implements 3D visual perception models embed-
ded in mobile devices to observe product display states and
reward (sales) in real-time.
â€¢EdgeRec3D uses a novel Robust Bayesian Payoff (RBP) model
to estimate action payoffs, and quantify uncertainty under
observation noise. This uncertainty quantification informs
a heuristic search algorithm to help solve combinatorial
explosion. Additionally, we devise a novel spatial cluster-
ing method, called SpAGMM, to produce store-level demo-
graphic profiles and solve the preference heterogeneity prob-
lem.
We believe this work will broadly be interesting to those working
in real-world recommender systems, brick and mortar commerce,
and data-driven marketing.
2 Preliminaries
The product assortment problem is a special case of the knapsack
problem [49].
Definition 1 (Product Assortment Problem). We consider
the problem of choosing from a set of ğ‘–=1,...,ğ‘ products with quanti-
ties,ğ‘ğ‘–âˆˆ{0,1,2,...}. The quantity, ğ‘ğ‘–, denotes the number of discrete
product locations (slots) occupied by product ğ‘–, on a product display
ğ‘‘ğ‘—. We letğ‘ğ‘–âˆˆ{0,1}be an indicator variable denoting the selection
status of product ğ‘–(also called the 0-1 knapsack [ 7]). Each store, ğ‘ ğ‘™, is
5162Personalized Product Assortment with Real-time 3D Perception and Bayesian Payoff Estimation KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
expected to contain multiple displays, ğ‘ ğ‘™={ğ‘‘(ğ‘™)
1,ğ‘‘(ğ‘™)
2,...ğ‘‘(ğ‘™)
ğ‘—}. Addi-
tionally, each display has a maximum capacity, ğ‘€(ğ‘™)
ğ‘—, denoting the
available product volume. We assume reward follows an unknown,
store-conditional distribution function, ğ‘Ÿğ‘–ğ‘—âˆ¼ğ‘(ğ‘Ÿğ‘–ğ‘—|ğ‘ ğ‘™,ğ‘ğ‘–ğ‘—)that varies
by quantity allocated. For example, one might expect diminishing
marginal returns for larger quantities of the same product. Therefore
our goal is to maximize expected reward for each display, ğ‘‘ğ‘—, at each
discrete time step, ğ‘¡
maximizeğ‘âˆ‘ï¸
ğ‘–E[ğ‘Ÿğ‘–ğ‘—|ğ‘ ğ‘™,ğ‘ğ‘–ğ‘—]ğ‘ğ‘–ğ‘— (2)
subject toğ‘âˆ‘ï¸
ğ‘–ğ‘ğ‘–ğ‘—ğ‘ğ‘–ğ‘—â‰¤ğ‘€ğ‘— (3)
One key challenge in the Product Assortment Problem is learning
the store-conditional reward function, ğ‘Ÿğ‘–âˆ¼ğ‘(ğ‘Ÿğ‘–ğ‘—|ğ‘ ğ‘™,ğ‘ğ‘–ğ‘—), since pref-
erences tend to be heterogeneous across locations. We tackle this
problem by learning demographic profiles for stores and clustering
them to estimate E[ğ‘Ÿğ‘–ğ‘—|ğ‘ ğ‘™,ğ‘ğ‘–ğ‘—].
Definition 2 (Demographic Spatial Clustering Problem).
Given a set of spatial areas, ğ›¼ğ‘§âˆˆ{ğ›¼ğ‘§: 1â‰¤ğ‘§â‰¤ğ‘}, each with a demo-
graphic vector, ğ‘¥ğ‘§âˆˆRğ‘and stores,ğ‘ ğ‘™âˆˆ{ğ‘ ğ‘™: 1â‰¤ğ‘™â‰¤ğ¿}, we have two
goals. First, match stores to a set of areas by constructing a neighbor-
hood around each store, ğ‘ ğ‘™:Nğ‘ ğ‘™({(ğ‘1,ğ‘¥1),(ğ‘2,ğ‘¥2),...}). Second within
each neighborhood, produce a store-level demographic profile by ag-
gregating over the demographic vectors, ğ‘‹ğ‘™=ğ‘”
Nğ‘ ğ‘™({(ğ‘1,ğ‘¥1),...})
.
The aggregation function, ğ‘”(Â·)could be any scalar-valued aggregation
(i.e., mean, median, weighted average). Finally, we cluster the set of ğ¿
store demographic profiles, ğ‘‹ğ‘™â€™s, intoğ¾different clusters. We expect
stores within each cluster to have similar preferences, making it easier
to estimate the store-conditional expectation, E[ğ‘Ÿğ‘–ğ‘—|ğ‘ ğ‘™,ğ‘ğ‘–ğ‘—].
3 Method
Our recommendation engine is comprised of the following modular
components: 3D data collection and sales inference, spatial cluster-
ing, candidate generation, value estimation, ranking and heuristic
search. The output is a recommended product set tailored to each
display location in a store,ğ‘‘ğ‘–ğ‘—, which a retail worker can choose to
physically implement.
3.1 3D Data Collection
The most important input to EdgeRec3D is fine-grained estimates
of product sales over time. Sales estimates need to be both high
resolution in time, and specific to each product. Historically, this
is done either by hand or by using point-of-sale (POS) data. Hand
collected sales data is expensive to collect, while POS is too low
resolution to understand how product sales vary by display location
within a store. In real-world retail, it is common for a product to be
displayed in many locations throughout a single store. Thus, POS
data alone does not facilitate targeted recommendations throughout
a store.
Instead, we train and deploy CountNet3D [ 26], a regression-
based 3D computer vision model to infer counts of densely spaced
objects. CountNet3D takes as input a set of images, and a LiDAR
point cloud, and outputs a set of fine-grained, product-level countestimates. This is especially important when the number of avail-
able products is in the hundreds or thousands. CountNet3D is only
trained to predict object counts in 3D space. In order to collect sales
data, CountNet3D is deployed to a mobile device where inference
on the images and point cloud data can occur on-edge. The user
is a front-line retail worker (i.e. merchandiser), and is the person
responsible for restocking the shelves with product, typically on a
daily basis. Prior to the restock, the user performs a pre-scan of the
shelf or product display. The pre-scan provides a current snapshot
of the available inventory on the display. Next, the user restocks
the display following a pre-specified plan (called a planogram or
schematic). Finally, upon completion of the restock the user per-
forms a post-scan, to capture the inventory when the display has
been replenished with product. Using these two inventory snap-
shots, we can difference the counts over time to estimate sales with
the following equation:
ğ‘ ğ‘ğ‘™ğ‘’ğ‘ ğ‘–ğ‘—ğ‘¡=Ë†ğ‘(ğ‘ğ‘œğ‘ ğ‘¡)
ğ‘–ğ‘—ğ‘¡âˆ’Ë†ğ‘(ğ‘ğ‘Ÿğ‘’)
ğ‘–ğ‘—(ğ‘¡âˆ’1)(4)
Where Ë†ğ‘(ğ‘ğ‘œğ‘ ğ‘¡)
ğ‘–ğ‘—ğ‘¡, is the post-scan and captures the count estimate
for product ğ‘–at displayğ‘—in the current timestamp, ğ‘¡. Moreover,
Ë†ğ‘(ğ‘ğ‘Ÿğ‘’)
ğ‘–ğ‘—(ğ‘¡âˆ’1)is the prescan in the current visit and captures the remain-
ing inventory at the previous time ğ‘¡âˆ’1. Intuitively, Equation 4
captures what product has been removed since the previous mer-
chandiser visit. We assume that all missing product has been sold.
More details about workflow and deployment can be found in the
supplement.
3.2 Spatial Clustering
After collecting a time series of product sales data, we segment the
data for recommendation using a novel, two-step spatial clustering
routine. Intuitively, we want to account for consumer preference
heterogeneity using demographic data, since a large body of litera-
ture has linked consumer preferences to observable demographic
variables [ 1,2,42]. Consistent with this literature, our expectation
is that product preferences vary across these demographic clusters.
However, it is typically challenging for retailers to estimate a demo-
graphic profile for shoppers as most consumers shop anonymously
and do not reveal their demographic attributes. We refer to this as
the Demographic Spatial Clustering problem.
To solve this problem we use readily accessible 2020 US census
data to create a demographic profile of each store. We are given
stores,ğ‘ ğ‘™âˆˆ{ğ‘ 1,ğ‘ 2,...}, and census areas, or tracts, ğ›¼ğ‘§âˆˆ{ğ›¼ 1,ğ›¼2,...}.
The census data consists of ğ‘=30demographic variables. Unfor-
tunately, matching stores to census tracts is not obvious. First, we
typically have an unequal number of stores and tracts. In rural
areas we might have more tracts than stores, and in urban areas we
might have more stores than tracts. Second, stores might lie on the
boundary of a census tract, making it difficult to simply apply the
demographics of the nearest tract. Third, shoppers from a nearby
census tract might visit multiple stores.
To resolve these issues we propose the Spatially Anchored Gauss-
ian Mixture Model (SpAGMM) to calculate spatially weighted de-
mographic profiles of stores using census tract data. Once a demo-
graphic vector of each store is obtained, grouping similar stores
together through K-means is straightforward and effective. We
detail both steps below.
5163KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Porter Jenkins, Michael Selander, J. Stockton Jenkins, Andrew Merrill, and Kyle Armstrong
P ost -scanPr e-scancpost - cpreSales 
Inf er enceCandidat e Gener ation3D Data CollectionSp A GMMK -means Clust eringDemogr aphic V ect ors
Spatial Clust eringR obust Ba y esian 
P a y off sStr atificationRanking and Sear chR ecommended 
Setk
k
k
x3x2
(a) Logical architecture of EdgeRec3D
Edge La y erCloud La y er
Clust ering
R obust Ba y esian Pa y off s
Candidat e Generation
3D P er ception:â€¨
Sales Captur e3D P er ception:
Stat e 
Obser v ation,
Heuristic Sear ch(b) Physical architecture of
EdgeRec3D
Figure 2: (a) Logical design of EdgeRec3D . The user performs successive 3D scans of a display to obtain product count predictions.
These predictions are differenced over time following Equation 4 to estimate sales. We train our two-stage spatial clustering
pipeline to group demographically similar stores. Within each cluster, we estimate a Robust Bayesian Payoff (RBP) model to
obtain a ranking statistic (PEPF) for each product. We generate candidates for each display, rank each candidate, and produce
recommendation sets with heuristic search. (b) Physical design of EdgeRec3D . 3D perception is implemented at the edge of
the network to facilitate real-time feedback. Data are aggregated across nodes for value estimation and candidate generation.
When recommendations are served, we observe the state of the display in real-time and apply heuristic search to improve it.
Algorithm 1 SpAGMM Estimation
Input: Store Coordinates, ğ‘†; Tract Coordinates, ğ¶;
Output:ğ¾xğ‘Probability Matrix, Î 
Initialize Likelihood history, ğ»=[]; Number of Clusters, ğ¾; Number of
Tracts,ğ‘; Weights,ğœ‹=1
ğ‘†ğ¼ğ‘†; Covariance Matrix, Î£= SPD Matrix; Length
of Each Data Vector (a âŸ¨lat, longâŸ©pair),ğ·=2
Normalizeğ‘†to get fixed cluster centers:
ğœ‡â†ğ‘†âˆ’Â¯ğ‘†
ğœ(ğ‘†)âŠ²Fixğœ‡. Donâ€™t update during training
Ë†ğ¶â†ğ¶âˆ’Â¯ğ¶
ğœ(ğ¶)
while True doâŠ²Estimate the probability that store ğ‘ belongs to tract ğ‘¡:
ğ¸âˆ¼L( Ë†ğ¶,ğœ‡,Î£) âŠ²Expectation Step
ğ‘™ğ‘–ğ‘˜â†Î£ğ‘
ğ‘¡Î£ğ¾
ğ‘˜ğ¸ğ‘¡ğ‘˜âŠ²Get sum of likelihood at step for convergence test
ğ».ğ‘ğ‘¢ğ‘ â„(ğ‘™ğ‘–ğ‘˜)
Î â†(ğ¾Ã—ğ‘) Array
forğ‘˜â†0:ğ¾do âŠ²Maximization Step
Î ğ‘˜â†ğ¸ğ‘˜âˆ—ğœ‹ğ‘˜
Î£ğ¾
ğ‘˜(ğ¸ğ‘˜âˆ—ğœ‹ğ‘˜)+ğœ–âŠ²Get weighted probability of store ğ‘ 
ğœ‹ğ‘˜â†Â¯Î ğ‘˜ âŠ²Update parameters ğœ‹andÎ£that maximize ğ¸
Update Î£using MAP estimation to handle CVP:
ğ‘Œ0â†1
ğ‘†1/ğ·ğ¼ğ·
ğ‘Œğ‘˜â†Î£ğ‘
ğ‘¡Î ğ‘¡ğ‘˜(Ë†ğ¶ğ‘¡âˆ’ğ‘†ğ‘˜)(Ë†ğ¶ğ‘§âˆ’ğ‘†ğ‘˜)ğ‘‡
ğ‘Ÿğ‘˜â†Î£ğ‘¡Î ğ‘¡ğ‘˜
Î£ğ‘˜â†ğ‘Œ0+ğ‘Œğ‘˜
ğ‘Ÿğ‘˜+2ğ·+4
end for
convergedâ†ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡â„(ğ»)>2andğ»[âˆ’2]âˆ’ğ»[âˆ’1]
ğ»[âˆ’2]â‰¤0.05
ifconverged then
break
end if
end while
return Î 
3.2.1 Step 1: SpAGMM Estimation. The core idea behind SpAGMM
is we can use a mixture of Gaussians to learn the probability that
shoppers from tract ğ›¼ğ‘§visits storeğ‘ ğ‘™. This probability is inversely
proportional to the distance between ğ›¼ğ‘§andğ‘ ğ‘™. For each store, ğ‘ ğ‘™,
we can then weight the demographic features of all other tracts,ğ›¼ğ‘§, by their respective probabilities to get a spatially weighted,
demographic profile. SpAGMM is a special case of the Gaussian
Mixture Model (GMM), a common clustering technique used to fit
ğ¾Gaussians to unlabelled data. Its output is a set of parameters,
{âŸ¨ğœ‡,Î£,ğœ‹âŸ©ğ‘˜}ğ¾
ğ‘˜=1, which define the cluster mean, covariance, and
membership weight.
We modify the standard GMM by setting the number of clusters
equal to the number of stores, ğ¾=ğ¿and anchoring the Gaussian
means at the latitude/longitude coordinates of the stores, ğœ‡ğ‘˜=
âŸ¨ğ‘™ğ‘ğ‘¡,ğ‘™ğ‘œğ‘›ğ‘”âŸ©ğ‘™. Consequently, we do not update ğœ‡ğ‘˜during training,
and only update Î£ğ‘˜andğœ‹ğ‘˜. We use Maximum A Posteriori (MAP)
estimation instead of Maximum Likelihood Estimation (MLE) for
numerical stability. When multiple stores and tracts lie in a small
neighborhood, the MLE forces the variance of some clusters to be
0, which leads to the Collapsing Variance Problem (CVP) [ 36]. To
tackle this problem, we put a Normal/Inverse Wishart (NIW) prior
overğœ‡ğ‘˜andÎ£ğ‘˜to derive the NIW conjugate model. We use the
Expectation-Maximization (EM) algorithm to learn Î£ğ‘˜, andğœ‹ğ‘˜. We
provide a formal definition in Algorithm 1.
Given the outputs of SpAGMM, we can calculate a demographic
profile for each store by weighting each tractâ€™s demographics by
the probability it belongs to ğ‘ ğ‘™â€™s cluster ,ğ‘‹ğ‘™=Ãğ‘
ğ‘§=1ğœ‹ğ‘™ğ‘§ğ‘¥ğ‘§
3.2.2 Step 2: K-means. Step 1 outputs a single demographic vector,
ğ‘‹ğ‘™for each store. To model preference heterogeneity, we cluster
stores intoğ¾groups. We use standard K-means to group similar
stores together.
3.3 Value estimation: Robust Bayesian Payoffs
(RBP)
After deriving the ğ¾clusters, our system learns the posterior pre-
dictive distribution of payoff for each product, within each cluster
using a Robust Bayesian Payoff (RBP) model. Since the use of a
computer vision system introduces noise into the sales data, it is
important to develop a technique that can make effective decisions
under such observation uncertainty, and therefore avoid costly
5164Personalized Product Assortment with Real-time 3D Perception and Bayesian Payoff Estimation KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
errors. In physical retail, errors are costly as there is significant
shipping and labor cost to merchandise each product.
RBP is a hierarchical Bayesian model, and has the following ad-
vantages over non-Bayesian reward models (i.e., linear regression
or deep learning): 1) RBP is more robust to outliers through the
use of regularizing priors. 2) RBP is able to pool information across
stores within a cluster, but is also able to discount irrelevant data
as more data is acquired within a store. This is due to the hierarchi-
cal structure of the model, where we learn store and cluster-level
parameters. 3) RBP explicitly quantifies uncertainty. In Figure 4 of
the supplement we analyze RBP on these three dimensions with a
synthetic dataset. The RBP model can be specified as follows:
ğ›½ğ‘–,ğ‘˜âˆ¼HalfNormal(ğœ‡0,ğœ0),ğ‘ğ‘–âˆ¼HalfNormal(ğœ‡1,ğœ1)
ğ›½ğ‘–,ğ‘™,ğ‘˜âˆ¼Laplace(ğ›½ğ‘–,ğ‘˜,ğ‘ğ‘–),ğœ(ğ‘–)
ğ‘Ÿâˆ¼HalfNormal(ğœ‡2,ğœ2)
ğ‘Ÿğ‘–,ğ‘™,ğ‘˜âˆ¼Î“(ğ‘¥(ğ‘–)
ğ‘âˆ—ğ›½ğ‘–,ğ‘™,ğ‘˜, ğœ(ğ‘–)
ğ‘Ÿ)(5)
whereğ‘–indexes product, ğ‘™indexes store, and ğ‘˜indexes cluster.
ğ›½ğ‘–,ğ‘˜andğ›½ğ‘–,ğ‘™.ğ‘˜denote the cluster- and store-level coefficients for
productğ‘ğ‘–. Moreover, ğ‘¥(ğ‘–)
ğ‘, is the allocated quantity of product, ğ‘ğ‘–.
Thus, theğ›½parameters describe how reward changes as a function
allocated space. We treat {ğœ‡0,ğœ0},{ğœ‡1,ğœ1}, and{ğœ‡2,ğœ2}as hyper-
parameters. Finally, ğ‘Ÿğ‘–,ğ‘™,ğ‘˜is the observed payoff (reward) and is
modelled with a Gamma likelihood, which has positive support
(ğ‘Ÿ>0), since product sales are non-negative. We use HalfNormal
priors to ensure that the upper-level coefficients are non-negative,
and a Laplace prior to encourage robustness to outliers. We visu-
alize the model with plate notation in Figure 5 of the supplement.
Since RBP is a fully probabilistic model its output is the posterior
predictive distribution, ğ‘(ğ‘Ÿğ‘–,ğ‘™,ğ‘˜|ğ‘¥(ğ‘–)
ğ‘), or our belief about reward
given the amount of space allocated to product, ğ‘ğ‘–. We train RBP
using PyMC [43] and the No U-Turn Sampler [23].
Intuitively, we can use ğ‘(ğ‘Ÿğ‘–,ğ‘™,ğ‘˜|ğ‘¥(ğ‘–)
ğ‘)to derive an uncertainty
penalized ranking statistic, Penalized Expected Payoff per Facing
(PEPF):
PEPF =E[ğ‘Ÿğ‘–,ğ‘™,ğ‘˜]âˆ’ğœ†ğœ(ğ‘Ÿğ‘–,ğ‘™,ğ‘˜) (6)
Where E[ğ‘Ÿğ‘–,ğ‘™,ğ‘˜]andğœ(ğ‘Ÿğ‘–,ğ‘™,ğ‘˜)are the mean and standard deviation
ofğ‘(ğ‘Ÿğ‘–,ğ‘™,ğ‘˜|ğ‘¥(ğ‘–)
ğ‘). We treat the penalty coefficient, ğœ†, as a user-chosen
hyperparameter. Larger ğœ†values correspond to more aggressive
discounting of uncertain product recommendations. Equation 6
takes a similar form to Upper Confidence Bound (UCB) estimators in
multi-armed bandit problems. UCB estimators [ 4] have been shown
to optimally manage the exploration-exploitation tradeoff. However,
they systematically take actions with high expected payoff and high
uncertainty. UCB policies take actions that might increase short-
term regret, but obtain more information about an actionâ€™s payoff
and therefore minimize long-term regret. Conversely, recent work
has shown that using an uncertainty penalized reward estimator
can encourage safe policies [ 27,50] in real-world reinforcement
learning. In this penalized regime, the policy tends to choose actions
with high expected payoff and low uncertainty. Additionally, Yu
et al. [ 50] prove that the penalized reward estimator maximizes
the lower bound of the true reward. We prefer the uncertainty
penalized estimator over UCB because it is both theoretically soundand useful in real-world problems where errors are costly. In our
experiments, we set ğœ†=1.
3.4 Candidate Generation
We generate candidates to reduce the search space of products. We
desire products that are physically and semantically compatible
with the observed state of the display. Our candidate generation is
comprised of three major steps: graph construction, sampling, and
pruning. The initial product set observed on each display is treated
as a â€œseed setâ€ to seed the candidate generator.
Graph Construction: Mining a live database of observed dis-
play states (a list of products on a display at a specific time) we
construct a weighted graph of products. Each node is a product and
each edge is the number of times that two products appear together
on the same display. Products that appear together frequently have
very large edge weights while products that appear together rarely
have small edge weights. Each product in our dataset is assigned
to one of 5 sub-categories (Sparkling, Water, Isotonic, Rejuvenate,
or Energy). We restrict our graph to only contain edges between
products of the same sub-category. This graph partitioning ensures
product consistency between the candidate set and the seed set.
The graph is updated on a weekly basis.
Sampling: To create the candidate set we first sample from
neighbors of the seed set, proportional to the edge weights. For
each seed product ğ‘ğ‘–, we sample ğœproducts without replacement
from its neighbors with respect to the edge weights. Each product
sampled is given one â€œvoteâ€, which are then summed and normalized
across all of the seed products. The output of this operation is an
initial candidate set.
Pruning: We prune the set of candidates based on known prod-
uct dimensions from a product database. We compare the maximum
height of any product in the â€œseedâ€ set against the initial candidate
set, and remove any products whose height exceeds that of the max
of the seed set. This step ensures candidates will physically fit on
the product display.
3.5 Heuristic Search
Using the candidates as input, we next perform a heuristic, com-
binatiorial search to produce a recommended product set. Due to
the high stakes nature of physical world recommendation systems,
we design a heuristic search algorithm that is relatively simple, in
order to avoid catastrophic failures and lost sales. The core principle
behind the search algorithm is to keep high payoff products, and
slowly trade low payoff products for better ones, while accounting
for uncertainty.
Our search algorithm is comprised of the following general steps.
First, we produce a PEPF score (Equation 6) for each product in the
candidate set,C, and the observed state set, S. Second, we sort the
candidate set and state set by PEPF. Third, we choose the lowest ğ‘‰
products by PEPF and reduce their quantities following the decay
scheduleğ›¿(ğ‘¡,ğ‘0)=âŒŠğ‘01
2ğ‘¡âŒ‹, whereğ‘0is the first observed product
quantity and ğ‘¡is the time step, or the ğ‘¡ğ‘¡â„time the product has
been selected. The floor term ensures that the output is a discrete
count, and that eventually, the decay will drop to zero. This decay
schedule will slowly remove poorly performing products until they
are completely removed. Fourth, we re-allocate the removed space
5165KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Porter Jenkins, Michael Selander, J. Stockton Jenkins, Andrew Merrill, and Kyle Armstrong
Algorithm 2 Heuristic Search
Input: Candidate set, C, Observed state set S, scoring function ğ‘“(Â·),
decay function ğ›¿(Â·), number of products to swap ğ‘‰, time stepsğ‘‡, epsilon-
greedy parameter ğœ–, maximum product facings ğ‘€, product-quantity
lookupğ‘„ğ‘ ;
Output: Recommended product-quantity lookup ğ‘…
ğµâ†ğ‘€, assign budget, ğµ
ğ‘…â†KeyValue[], Initialize recommendation lookup
forğ‘¡inğ‘‡do
C=ğ‘“(C) âŠ²score candidates, assign PEPF
S=ğ‘“(S) âŠ²score current state, assign PEPF
ËœC=sort(C) âŠ²sort candidates by PEPF ascending
ËœS=sort(S) âŠ²sort candidates by PEPF ascending
whileğµ>0do
forğ‘—inğ‘‰do âŠ²search for new products
ğ‘â†S[ 0] âŠ²select lowest PEPF product
ğ‘â†ğ‘„ğ‘ [ğ‘] âŠ²current quantity
ğ›¼âˆ¼Unif(0,1) âŠ²ğœ–-greedy action
ifğ›¼<ğœ–then
ğ‘â€²âˆ¼ËœC âŠ²choose random candidate
else
ğ‘â†ËœC.pop() âŠ²greedy selection (highest PEPF)
end if
ğ‘â€²=ğ›¿(ğ‘) âŠ²decay quantity
ğ‘…[ğ‘â€²]â†ğ‘â€²âŠ²assign recommendation
ğµ=ğµâˆ’ğ‘â€²
ğ‘„ğ‘ [ğ‘]=ğ‘âˆ’ğ‘â€²âŠ²update product quantity
end for
ğ‘â€²=ËœS.pop() âŠ²Collect existing, high PEPF products
ğ‘â€²=ğ‘„ğ‘ [ğ‘â€²]
ğ‘…[ğ‘â€²]â†ğ‘â€²
ğµ=ğµâˆ’ğ‘â€²
end while
end for
with new products following an ğœ–-greedy routine. With probability
ğœ–, we choose a random product from the candidate set, and with
probability 1âˆ’ğœ–we choose a greedy action, or the candidate with
the highest PEPF. Fifth, after we have ğ‘‰product swaps, we fill the
remaining budget with the high PEPF products already in the state,
S. We formally describe our search in Algorithm 2.
4 Experiments
In the following section we discuss our experimental setup to val-
idate that EdgeRec3D is an effective, real-world recommendation
system for shelf space allocation. We perform both offline and
online evaluation. Notably, we partner with a large beverage distri-
bution company and perform two real-world experiments over the
course of 2022. We then deploy the system to a larger set of users
and stores in 2023.
4.1 Offline Evaluation
We perform an offline comparison of EdgeRec3D to search algo-
rithms that have been applied to the product assortment problem in
prior work. Offline policy evaluation typical of reinforcement learn-
ing and bandit algorithms is notoriously difficult in part due to the
â€˜partial labelâ€™ problem [ 12,31â€“33]. We apply the evaluator proposed
by Li et al. [ 32]. To build a static dataset, we collect user logs fromAlgorithm Mean Reward â†‘Median Rewardâ†‘
Dynamic Program 1.001 (1.8) 0.0
Linear Program 0.718 (1.6) 0.0
ğœ–-greedy 1.790 (1.6) 1.864
Genetic 2.147 (1.8) 2.265
Deep Ensembles 1.895 (1.6) 2.452
MOPO 1.826 (1.6) 2.048
EdgeRec3D 2.466 (1.6) 2.496
Table 1: Offline Evaluation using a static dataset and the
offline policy evaluator algorithm from [32]
.
thecontrol group in experiment #2. This dataset is comprised of
33 stores, and covers approximately 8 weeks of time, and includes
14,830 transactions. It is important to note that the control data
is a fair comparison because no online intervention is ever made
by any of these search algorithms. The evaluator in [ 32] assumes
the logged actions are iid. We randomly sample 50% of our logged
interactions to reduce temporal dependency in the dataset.
We compare EdgeRec3D to a variety of classic and modern base-
lines. We run each algorithm 30 times, and report the mean, stan-
dard deviation (in parentheses) and median payoff in Table 1. Both
Deep Ensembles [ 29] and Model-based Offline Policy Optimization
(MOPO) [ 50] feature modern neural networks with predictive un-
certainty. For Deep Ensembles, we use the same heuristic search as
EdgeRec3D to measure the value of RBP. MOPO uses uncertainty
penalized offline reinforcement learning for action selection. We
observe that EdgeRec3D outperforms all existing baselines in both
mean and median payoff, indicating it can effectively take good
actions under uncertainty.
Additionally, we perform an ablation study of EdgeRec3D using
the same dataset and experimental setup described above. The
results are reported in Table 3. We carefully remove each of the
core components: clustering, Robust Bayesian Payoffs (RBP) and
heuristic search. When we remove clustering, we fit a single, global
reward model. When we remove RBP, the reward model is a non-
Bayesian, simple linear regression. When we remove the heuristic
search module, we apply a greedy search without the penalized
reward ranking statistic. Overall, the heuristic search and Bayesian
reward model have a large impact on performance and EdgeRec3D
outperforms all ablated variants.
4.2 Online Experimental Phase
4.2.1 Experimental Design. Controlled experiments in real-world
scenarios can be a challenging task due to the possibility of con-
founding, or omitted variables. To account for potential confounders,
we use a within-store Difference-in-Difference (DID) experimen-
tal design for both of our field experiments. DID estimation is a
commonly used experimental design technique in the Economet-
rics literature to assess causal relationships [ 3,18]. The key idea
behind the DID experimental design is to measure the change in a
response variable before and after an intervention for both the af-
fected and unaffected groups [ 8]. The difference of these changes is
the treatment effect. More formally, dDID=(post treatâˆ’pretreat)âˆ’
(post controlâˆ’precontrol), where preandpost are pre-treatment
and post-treatment periods respectively. Our controlled experi-
ments have the following design steps:
5166Personalized Product Assortment with Real-time 3D Perception and Bayesian Payoff Estimation KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Dates Pre/Post (Days) # Stores # Displays Group Avg Reco. Compliance DID ğ‘-val DID IQR
Exp. 1 5/17 - 6/30 25/20 2 22Store #1 100% +35.10%âˆ—âˆ—0.014 [23.65%, 46.08%]
Store #2 100% +32.04%âˆ—0.064 [15.24%, 44.27%]
All 100% +35.03%âˆ—âˆ—0.016 [23.42%, 42.78%]
Exp. 2 9/21 - 11/19 21/38 33 133All 61.64% +07.83% 0.222 [1.67%, 13.65%]
High 90.38% +27.78%âˆ—âˆ—0.003 [21.12%, 35.18%]
Table 2: Overall summary of our two field experiments based on the Difference-in-Difference (DID) experimental design. Where
recommended changes are adopted (high compliance), we see large increases in sales that are statistically meaningful. We use
âˆ—âˆ—to denote significance at ğ›¼=0.05, andâˆ—for significance at ğ›¼=0.1.
Exp. Clustering RBP Heuristic Search Reward
# 1 âœ— âœ— âœ— 0.866 (1.6)
# 2 âœ— âœ— âœ“ 2.020 (1.4)
# 3 âœ“ âœ— âœ— 0.585 (1.4)
# 4 âœ“ âœ— âœ“ 2.143 (1.4)
# 5 âœ— âœ“ âœ— 0.998 (1.7)
# 6 âœ— âœ“ âœ“ 2.308 (1.7)
# 7 âœ“ âœ“ âœ— 0.490 (1.2)
# 8 âœ“ âœ“ âœ“ 2.466 (1.6)
Table 3: Offline ablation study using a static dataset and the
offline policy evaluator algorithm from [32]
â€¢We mark a set of product displays in each store for observa-
tion. A product display is a shelf, cooler, end-rack or other
merchandising display. Each display is uniquely identified
via QR code.
â€¢Within each store, we randomly assign each display to either
treatment or control with 50% probability.
â€¢The control displays are merchandised according to current
industry best practices. Treatment displays are merchandised
with the recommended actions from EdgeRec3D.
â€¢For both treatment and control, the user (retail worker or
merchandiser) visits the display typically on a daily basis. A
QR code is scanned to uniquely identify that display. The user
replenishes the product, and uses a mobile app to observe
the state and record new sales.
â€¢Pre-treatment: Sales are recorded for both treatment and
control. For both groups, we monitor sales without making
recommendations for a fixed period to get a sales baseline.
â€¢Post-treatment: After the pre-treatment period has ended,
EdgeRec3D begins serving product recommendations for the
treatment group only.
â€¢At the conclusion of the post-treatment period, we calculate
the difference-in-difference estimator, dDID.
Note that recommendations are simply displayed to users (retail
workers or merchandisers); ultimately, each user has the autonomy
to accept or reject the EdgeRec3D suggestions. Some fail to accept
due to time constraints, while others are simply resistant to using
the system and prefer existing practice. We measure this acceptance
rate with a compliance statistic, the Jaccard index between the
recommended state, ğ‘…, and the observed state S:ğœŒ(ğ‘…,S)=ğ½(ğ‘…,S).
In our first experiment, we choose two stores in the Salt Lake
City, Utah, USA region and focus the test on cooler displays. We run
a six week experiment, from May 17 to June 30, 2022 using a DID
design. The treatment period begins on June 10, 2022. Our second
experiment is much larger and consists of 33 stores across the
mountain west region of the United States (Utah, Colorado, Arizona,
2023-02 2023-03 2023-04 2023-05 2023-06 2023-07 2023-086065707580859095Average Weekly Unit Sales
Low Comp.
High Comp.
DeploymentFigure 3: Deployment phase observational study. We split
stores into high a low compliance groups as in the experimen-
tal phase. We see that the two groups have roughly parallel
trends in the pre-deployment period. We deploy EdgeRec3D
on April 16, 2023. In the post-deployment period, the two
groups are still subject to the same seasonal trends, but the
high compliance group diverges from the low compliance
group. See Table 4 for full results.
etc...). We again focus on cooler displays. Experiment #2 runs from
September 21, 2022 to November 19, 2022, or approximately eight
weeks. The treatment period begins on October 21, 2022. Due to
the time and expense of online, controlled experiments we do not
compare EdgeRec3D to the benchmark search algorithms studied
in Section 4.1. Instead, during our online evaluation we compare
EdgeRec3D to current industry best practices.
4.2.2 Results. We provide an overall summary of our two field
experiments in Table 2. To obtain estimates of statistical confidence
we perform a non-parametric permutation test [ 22]. Across the two
experiments, we see a +27.78% and +35.03% increase in average daily
sales where recommendations are followed. These results are both
statistically significant ( ğ›¼=0.05) and provide strong evidence that
implementing and following the recommended product assortment
decisions prescribed by EdgeRec3D have a positive, causal impact
on daily average product sales.
Field Experiment #1. In the first experiment, we deploy EdgeRec3D
to only two stores with expert users. These users are able to take
their time, and the implementation of recommendations served by
EdgeRec3D is strictly enforced. Therefore, during experiment #1,
the average recommendation compliance is 100%. We see a very
high DID treatment effect of +35.03%.
Daily product sales in the treatment group increased by 0.95
units (+16.42%), while the control group saw a decrease of 1.0 units
per day (-18.61%). The difference between these two yields the total
5167KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Porter Jenkins, Michael Selander, J. Stockton Jenkins, Andrew Merrill, and Kyle Armstrong
treatment effect, 16.42%âˆ’(âˆ’ 18.62%)=35.03%. The control group
offers a counterfactual estimate of what would have happened in
the absence of the intervention ( EdgeRec3D ). This is known as
the parallel trend assumption of DID [ 3]. Had we not deployed
recommendations, itâ€™s likely that average daily sales would have
decreased at similar rates as the control group.
Field Experiment #2. In this experiment, our user base consists of
non-experts who have more time constraints (ie, other retail respon-
sibilities), which is reflective of the real-world product assortment
problem. Here, the user has the option to adopt the recommen-
dation from EdgeRec3D . Consequently, we see more variation in
recommendation compliance during experiment #2.
The DID treatment effect across all stores is +7.83%. While this
result is positive, our confidence is not high enough to conclude
statistical significance ( ğ‘-value = 0.222). However, the average rec-
ommendation compliance across all stores is only 61.64%. This
suggests that a large number of users are ignoring the recommenda-
tions served by EdgeRec3D . Filtering to stores where recommended
product sets are adopted (average compliance â‰¥80%), shows a dif-
ferent result. Among this high compliance group we see very strong,
positive results where the DID treatment effect is +27.78% and is
significant at ğ›¼=0.05. This leads us to conclude that high recom-
mendation compliance leads to a large treatment effect. This aligns
with our intuition because our system can only make recommenda-
tions, but it ultimately relies on a user to adopt and implement the
change in the physical world.
4.3 Deployment Phase
Following our two controlled experiments, we deploy EdgeRec3D to
83 stores and monitor the impact on store-level sales for a period of
28 weeks (11 weeks pre-deployment and 17 week post-deployment).
We again use a DID study design. However, this deployment phase
differs from Experiment #1 and #2 in the following ways. First,
recommendations are applied to all cooler displays; we do not
randomly assign displays to treatment and control. Instead of a con-
trolled experiment, we perform an observational study to monitor
the effectiveness. Second, while EdgeRec3D still uses 3D percep-
tion to estimate sales, here we measure performance using syndi-
cated point-of-sale (POS) data. POS data allows us to observe sales
prior to the deployment of our system, and quantify the impact of
EdgeRec3D post-deployment. The data contains sales information
for all products and all locations within the store. We filter the POS
data to products observed and tracked by EdgeRec3D in our study.
We are not able to disambiguate sale location in this data. Third,
the syndicated POS data is reported weekly, instead of daily.
Results of our deployment are reported in Table 4 and visually
depicted in Figure 3. Since we no longer have treatment and control
groups in our deployment phase, we use recommendation compli-
ance as a measure of adoption. We again split stores into high and
low compliance groups by calculating the average compliance over
the course of the 17 week deployment period. Crucially, we also
monitor average sales for these two groups prior to deployment to
get a baseline performance measurement.
High compliance stores averaged sales of 80.91 units sales prior
to the deployment date, and increased to an average of 88.01 post-
deployment date, a change of 7.1 units or 8.8%. In contrast, low
compliance stores averaged sales of 67.80 prior to the deploymentLow Comp. High Comp. Diff-in-Diff
Pre 67.80 80.91
Post 67.37 88.01
Change -0.43 (-0.6%) +7.1 (+8.8%) +7.53 (+9.4%)âˆ—âˆ—
Table 4: Observational study during the deployment phase
of EdgeRec3D. The DID treatment effect is 9.4% ( ğ‘=0.021)
date and stayed roughly the same, decreasing slightly, to 67.37 post-
deployment date. These figures indicate a 7.53 unit per-product,
per-week â€œtreatmentâ€ effect on sales for the high compliance stores,
which represents a 9.4% increase in weekly sales volume. This
treatment effect is statistically meaningful ( ğ‘=0.021).
The results in the deployment phase are positive and meaning-
ful, but lower in magnitude than the experimental phase. This is
likely explained by the use of controlled experiments, which enable
precise estimates of the treatment effect. In spite of this, we still
see positive and statistically meaningful results as EdgeRec3D is
deployed.
5 Related Work
Shelf Space Allocation The shelf space allocation problem has been
studied for many years in the Operations Research field [ 17]. Classic
optimization methods are commonly applied such as linear [ 21,
49], or dynamic [ 52] programming, and game theory [ 34]. More
computational methods such as genetic algorithms [ 11,24,47,51]
and simulated annealing approaches [ 9] have been proposed in
recent years. Others have sought to jointly optimize both product
assortment and price [ 37] via a branch-and-bound algorithm. [ 20]
performed a controlled field test and showed a 9% increase in profit
using a non-linear program to choose product assortment.
Offline Recommender Systems The majority of work in recom-
mender systems has been done online, in the e-commerce domain,
but systems for offline commerce are growing in popularity [ 16].
Early work [ 40,48] showed that recommender systems can posi-
tively impact offline product demand. Later work focused on collab-
orative filtering [ 39,45] and association rule mining [ 10,15,38,46].
Machine Learning techniques such as gradient-boosted trees [ 44],
K-nearest neighbors [ 30], ensemble techniques [ 6] and offline Rein-
forcement Learning [ 27] have been studied. Location-based systems
leverage customer location data from smartphones [ 13] or RFID
tags [ 14] within a store. In contrast, EdgeRec3D provides real-time
assortment recommendations based on fine-grained sales estimates
obtained via 3D computer vision, while also accounting for mea-
surement error and preference heterogeneity across stores.
6 Conclusion
We proposed EdgeRec3D to solve the product assortment problem
in physical retail. EdgeRec3D uses an edge-first architecture with
real-time 3D perception to estimate product sales and observe dis-
play states. Making recommendations at the edge of the network
closes the feedback loop and facilitates faster preference discovery.
Additionally, EdgeRec3D relies on a probabilistic reward model
(RBP) for uncertainty quantification, spatial clustering to account
for preference heterogeneity, and candidate generation with heuris-
tic search to tackle combinatoric explosion. Controlled experiments
and a 28 week observational study showed that EdgeRec3D has
meaningful, real-world impact.
5168Personalized Product Assortment with Real-time 3D Perception and Bayesian Payoff Estimation KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
References
[1]Greg M Allenby and Peter E Rossi. 1998. Marketing models of consumer hetero-
geneity. Journal of econometrics 89, 1-2 (1998), 57â€“78.
[2]Steffen Andersen, Glenn W Harrison, Morten Igel Lau, and E Elisabet RutstrÃ¶m.
2010. Preference heterogeneity in experiments: Comparing the field and labora-
tory. Journal of Economic Behavior & Organization 73, 2 (2010), 209â€“224.
[3]Joshua D Angrist and JÃ¶rn-Steffen Pischke. 2009. Mostly harmless econometrics:
An empiricistâ€™s companion. Princeton university press.
[4] Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. 2002. Finite-time analysis of
the multiarmed bandit problem. Machine learning 47 (2002), 235â€“256.
[5]Anant Jyoti Badgaiyan and Anshul Verma. 2015. Does urge to buy impulsively
differ from impulsive buying behaviour? Assessing the impact of situational
factors. Journal of Retailing and Consumer Services 22 (2015), 145â€“157.
[6]Jae Kwon Bae and Jinhwa Kim. 2010. Integration of heterogeneous models
to predict consumer behavior. Expert Systems with Applications 37, 3 (2010),
1821â€“1826.
[7]Egon Balas and Eitan Zemel. 1980. An algorithm for large zero-one knapsack
problems. operations Research 28, 5 (1980), 1130â€“1154.
[8]Marianne Bertrand, Esther Duflo, and Sendhil Mullainathan. 2004. How much
should we trust differences-in-differences estimates? The Quarterly journal of
economics 119, 1 (2004), 249â€“275.
[9]Norm Borin, Paul W Farris, and James R Freeland. 1994. A model for determining
retail product category assortment and shelf space allocation. Decision sciences
25, 3 (1994), 359â€“384.
[10] Tom Brijs, Gilbert Swinnen, Koen Vanhoof, and Geert Wets. 1999. Using asso-
ciation rules for product assortment decisions: A case study. In Proceedings of
the fifth ACM SIGKDD international conference on Knowledge discovery and data
mining. 254â€“260.
[11] Mauro Castelli and Leonardo Vanneschi. 2014. Genetic algorithm with vari-
able neighborhood search for the optimal allocation of goods in shop shelves.
Operations Research Letters 42, 5 (2014), 355â€“360.
[12] Pablo Castells and Alistair Moffat. 2022. Offline recommender system evaluation:
Challenges and new directions. AI Magazine 43, 2 (2022), 225â€“238.
[13] Thomas Chatzidimitris, Damianos Gavalas, Vlasios Kasapakis, Charalampos
Konstantopoulos, Damianos Kypriadis, Grammati Pantziou, and Christos Zaro-
liagis. 2020. A location history-aware recommender system for smart retail
environments. Personal and Ubiquitous Computing 24 (2020), 683â€“694.
[14] Chia-Chen Chen, Tien-Chi Huang, James J Park, and Neil Y Yen. 2015. Real-time
smartphone sensing and recommendations towards context-awareness shopping.
Multimedia systems 21 (2015), 61â€“72.
[15] Mu-Chen Chen and Chia-Ping Lin. 2007. A data mining approach to product
assortment and shelf space allocation. Expert Systems with Applications 32, 4
(2007), 976â€“986.
[16] Luis Omar Colombo-Mendoza, Mario AndrÃ©s Paredes-Valverde, MarÃ­a del Pilar
Salas-ZÃ¡rate, Maritza Bustos-LÃ³pez, JosÃ© Luis SÃ¡nchez-Cervantes, and Giner
Alor-HernÃ¡ndez. 2020. Recommender systems in the offline retailing domain:
a systematic literature review. Techniques, Tools and Methodologies Applied to
Global Supply Chain Ecosystems (2020), 383â€“409.
[17] Ronald C Curhan. 1973. Shelf space allocation and profit maximization in mass
retailing. Journal of Marketing 37, 3 (1973), 54â€“60.
[18] John DiNardo. 2010. Natural experiments and quasi-natural experiments. Mi-
croeconometrics (2010), 139â€“153.
[19] Krzysztof DudziÅ„ski and StanisÅ‚aw Walukiewicz. 1987. Exact methods for the
knapsack problem and its generalizations. European Journal of Operational
Research 28, 1 (1987), 3â€“21.
[20] Tobias DÃ¼sterhÃ¶ft, Alexander HÃ¼bner, and Kai Schaal. 2020. A practical approach
to the shelf-space allocation and replenishment problem with heterogeneously
sized shelves. European Journal of Operational Research 282, 1 (2020), 252â€“266.
[21] H Neil Geismar, Milind Dawande, BPS Murthi, and Chelliah Sriskandarajah. 2015.
Maximizing revenue through two-dimensional shelf-space allocation. Production
and Operations Management 24, 7 (2015), 1148â€“1163.
[22] Phillip Good. 2013. Permutation tests: a practical guide to resampling methods for
testing hypotheses. Springer Science & Business Media.
[23] Matthew D Hoffman, Andrew Gelman, et al .2014. The No-U-Turn sampler:
adaptively setting path lengths in Hamiltonian Monte Carlo. J. Mach. Learn. Res.
15, 1 (2014), 1593â€“1623.
[24] Hark Hwang, Bum Choi, and Min-Jin Lee. 2005. A model for shelf space allocation
and inventory control considering location and inventory level effects on demand.
International Journal of Production Economics 97, 2 (2005), 185â€“195.
[25] Kamel Jedidi, Harsharanjeet S Jagpal, and Wayne S DeSarbo. 1997. Finite-mixture
structural equation models for response-based segmentation and unobserved
heterogeneity. Marketing Science 16, 1 (1997), 39â€“59.
[26] Porter Jenkins, Kyle Armstrong, Stephen Nelson, Siddhesh Gotad, J. Stockton
Jenkins, Wade Wilkey, and Tanner Watts. 2023. CountNet3D: A 3D Computer
Vision Approach To Infer Counts of Occluded Objects. In Proceedings of the
IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). 3008â€“
3017.[27] Porter Jenkins, Hua Wei, J Stockton Jenkins, and Zhenhui Li. 2022. Bayesian
Model-Based Offline Reinforcement Learning for Product Allocation. In Proceed-
ings of the AAAI Conference on Artificial Intelligence, Vol. 36. 12531â€“12537.
[28] Glenn Jocher, Ayush Chaurasia, Alex Stoken, Jirka Borovec, NanoCode012,
Yonghye Kwon, Kalen Michael, TaoXie, Jiacong Fang, imyhxy, Lorna, (Zeng
Yifu), Colin Wong, Abhiram V, Diego Montes, Zhiqiang Wang, Cristi Fati, Je-
bastin Nadar, Laughing, UnglvKitDe, Victor Sonck, tkianai, yxNONG, Piotr
Skalski, Adam Hogan, Dhruv Nair, Max Strobel, and Mrinal Jain. 2022. ul-
tralytics/yolov5: v7.0 - YOLOv5 SOTA Realtime Instance Segmentation. https:
//doi.org/10.5281/zenodo.7347926
[29] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. 2017. Simple
and scalable predictive uncertainty estimation using deep ensembles. Advances
in neural information processing systems 30 (2017).
[30] Lisa Leininger, Johnny Gipson, Kito Patterson, and Brad Blanchard. 2020. Advanc-
ing performance of retail recommendation systems. SMU Data Science Review 3,
1 (2020), 6.
[31] Lihong Li, Wei Chu, John Langford, and Robert E Schapire. 2010. A contextual-
bandit approach to personalized news article recommendation. In Proceedings of
the 19th international conference on World wide web. 661â€“670.
[32] Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. 2011. Unbiased offline
evaluation of contextual-bandit-based news article recommendation algorithms.
InProceedings of the fourth ACM international conference on Web search and data
mining. 297â€“306.
[33] Travis Mandel, Yun-En Liu, Emma Brunskill, and Zoran PopoviÄ‡. 2016. Offline
evaluation of online reinforcement learning algorithms. In Proceedings of the
AAAI Conference on Artificial Intelligence, Vol. 30.
[34] Victor MartÃ­nez-de AlbÃ©niz and Guillaume Roels. 2011. Competing for shelf
space. Production and Operations Management 20, 1 (2011), 32â€“46.
[35] Anna Mattila and Jochen Wirtz. 2008. The role of store environmental stimulation
and social factors on impulse purchasing. Journal of Services Marketing (2008).
[36] Kevin P Murphy. 2012. Machine learning: a probabilistic perspective. MIT press.
[37] Chase C Murray, Debabrata Talukdar, and Abhijit Gosavi. 2010. Joint optimization
of product price, display orientation and shelf-space allocation in retail category
management. Journal of Retailing 86, 2 (2010), 125â€“136.
[38] Anala A Pandit, Jyot Talreja, Miloni Agrawal, Deepak Prasad, Swati Baheti,
and G Khalsa. 2010. Intelligent recommender system using shopperâ€™s path and
purchase analysis. In 2010 International Conference on Computational Intelligence
and Communication Networks. IEEE, 597â€“602.
[39] Jihoi Park and Kihwan Nam. 2019. Group recommender system for store product
placement. Data Mining and Knowledge Discovery 33, 1 (2019), 204â€“229.
[40] Bhavik Pathak, Robert Garfinkel, Ram D Gopal, Rajkumar Venkatesan, and Fang
Yin. 2010. Empirical analysis of the impact of recommender systems on sales.
Journal of Management Information Systems 27, 2 (2010), 159â€“188.
[41] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. 2017. Pointnet: Deep
learning on point sets for 3d classification and segmentation. In Proceedings of
the IEEE conference on computer vision and pattern recognition. 652â€“660.
[42] Peter E Rossi and Greg M Allenby. 2003. Bayesian statistics and marketing.
Marketing Science 22, 3 (2003), 304â€“328.
[43] John Salvatier, Thomas V Wiecki, and Christopher Fonnesbeck. 2016. Probabilistic
programming in Python using PyMC3. PeerJ Computer Science 2 (2016), e55.
[44] Xavier dos Santos Silva. 2020. Recommender Systems for Grocery Retail-A Machine
Learning Approach. Ph. D. Dissertation.
[45] Chen Sun, Rong Gao, and Hongsheng Xi. 2014. Big data based retail recommender
system of non E-commerce. In Fifth International Conference on Computing,
Communications and Networking Technologies (ICCCNT). IEEE, 1â€“7.
[46] Kutuzova Tatiana and Melnik Mikhail. 2018. Market basket analysis of heteroge-
neous data sources for recommendation system improvement. Procedia Computer
Science 136 (2018), 246â€“254.
[47] Timothy L Urban. 1998. An inventory-theoretic approach to product assortment
and shelf-space allocation. Journal of Retailing 74, 1 (1998), 15â€“35.
[48] Frank E Walter, Stefano Battiston, Mahir Yildirim, and Frank Schweitzer. 2012.
Moving recommender systems from on-line commerce to retail stores. Informa-
tion systems and e-business management 10 (2012), 367â€“393.
[49] Ming-Hsien Yang and Wen-Cher Chen. 1999. A study on shelf space allocation
and management. International journal of production economics 60 (1999), 309â€“
317.
[50] Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano Ermon, James Y Zou, Sergey
Levine, Chelsea Finn, and Tengyu Ma. 2020. Mopo: Model-based offline policy
optimization. Advances in Neural Information Processing Systems 33 (2020), 14129â€“
14142.
[51] Lanlan Zheng, Xin Liu, Feng Wu, and Zijun Zhang. 2023. A data-driven model
assisted hybrid genetic algorithm for a two-dimensional shelf space allocation
problem. Swarm and Evolutionary Computation 77 (2023), 101251. https://doi.
org/10.1016/j.swevo.2023.101251
[52] Fred S. Zufryden. 1986. A Dynamic Programming Approach for Product Selection
and Supermarket Shelf-Space Allocation. The Journal of Operational Research
Society (1986).
5169KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Porter Jenkins, Michael Selander, J. Stockton Jenkins, Andrew Merrill, and Kyle Armstrong
7 Appendix
7.1 EdgeRec3D parameter settings
During our experiments we set the number of product swaps per
iteration,ğ‘‰=2. At each iteration, we take the lowest ğ‘‰=2prod-
ucts by PEPF and choose 2 higher value product swaps, following
anğœ–-greedy routine. We set the ğœ–-greedy parameter to ğœ–=0.05.
We allow for a two week pre-treatment period to get a baseline for
sales, following which we deploy recommendations. We update rec-
ommendations on a weekly cadence. Finally, we set the uncertainty
coefficientğœ†=1.0
7.2 Complexity Analysis of EdgeRec3D
Equation 1 of the Introduction describes the number of assortment
possibilities for ğ‘products and ğ‘šdiscrete product locations. Since
this equation grows factorially in both ğ‘andğ‘š, exploring all as-
sortment possibilities is impossible in finite time for realistic ğ‘š
andğ‘. We design EdgeRec3D to address this combinatorial explo-
sion through two of its components: 1) candidate generation and 2)
heuristic search.
7.2.1 Complexity of Candidate Generator. The candidate generator
mines an active database to produce a graph representing the like-
lihood of product co-occurrences. We then sample from this graph
using a â€œseedâ€ set of products, which are the products observed on
the current display state. The complexity of candidate generation is
ğ‘‚(ğ‘›+ğ‘ ğ‘ğœ+ğœ) (7)
forğ‘›user logs,ğ‘ size of seed set ğœnumber of samples from
the graph. The algorithm steps through each of the ğ‘›logs and
increments a counter of pairwise-product co-occurence to produce
an adjacency list representing the graph. Once this is complete, we
sample the graph to produce ğ‘candidates. In the sampling step, for
each of theğ‘ products we sample from itâ€™s ğ‘neighborsğœtimes. In
the worst case, the number of adjacent products is ğ‘although it
practice it is usually much less. We then step through each of the ğœ
candidates in the pruning step.
7.2.2 Complexity of Heuristic Search. The heuristic search module
is run each time a new recommendation is generated. Itâ€™s complexity
is:
ğ‘‚(ğ‘+ğ‘ +ğ‘šğ‘£) (8)
forğ‘candidates,ğ‘šproduct slots and ğ‘£product swaps. We first
score each of the ğ‘candidates and ğ‘ seed products with the RBP
value function to produce a PEPF ranking statistic. Upon comple-
tion, for each of the available ğ‘šproduct slots, we search for ğ‘£
superior product swaps.
On the whole, EdgeRec3D is at worst linear in the number of
ğ‘products and ğ‘šproduct slots. From a complexity perspective,
this is far more efficient than the factorial growth of a brute force
approach described in Equation 1.
7.3 Wall-clock time of EdgeRec3D
Figure 2(b) provides a physical architecture diagram of EdgeRec3D.
The components that run on the edge layer (i.e., mobile device)
return results in real-time. Specifically, the sales capture and statemAP50-95 mAP50 Precision Recall
YoloV5 0.793 0.927 0.897 0.901
Table 5: YoloV5 training results on 567 finegrained classes.
MAE MSE MAPE
CountNet3D 1.280 5.672 0.077
Table 6: Object count regression results from CountNet3D.
We report Mean Absolute Error (MAE), Mean Squared Error
(MAE) and Median Absolute Percentage Error (MAPE).
observation are computed with CountNet3D on the Apple Neural
Engine and return results in 200ms. Additionally, once the candi-
dates are queried from a remote server, the heuristic search algo-
rithm is run in real-time and returns results in <100ms.
7.4 Training of Visual Layer
The visual perception layer of EdgeRec3D is built on top of Count-
Net3D [ 26], a regression-based neural network that processes im-
ages and LiDAR scans to predict finegrained object counts. Count-
Net3D uses a mature 2D object detector, such as YOLOv5 [ 28] to
propose 3D regions around known objects. It then uses a PointNet-
style architecture [ 41] to count objects to process the point cloud
within each region.
CountNet3D is trained in two stages. First, the YOLOv5 model
is trained on image data alone to detect finegrained beverage prod-
ucts. This model consists of 567 fine grained classes. Here, fine
grained class refers to a very specific product classification such as
coca_cola_20oz_bottle orcoca_cola_1L_bottle . Detection re-
sults are reported in Table 5. Second, the YOLOv5 weights are fixed
and the network processing the point cloud is trained to regress
object counts in a focused sub-volume of the scene. The predictions
are aggregated across sub-volumes to the class-level to output a
count estimate for each product. The object count regression results
are reported in Table 6.
The visual layer is trained with a proprietary dataset comprised
annotated of images and point clouds. Each point cloud is densely
labelled; small regions are annotated with the product type and
ground truth object counts. The dataset construction is very similar
to the open source version in [26].
8 Additional Experiments and Results
8.1 Details of Offline Experiments
8.1.1 Dataset Construction. As discussed in the paper, we use the
offline policy evaluator proposed by [ 32] to benchmark different
search algorithms against a static dataset. The dataset is collected
from user logs taken from the control group in experiment #1.
The control group saw no recommendations during the A/B test is
therefore unbiased w.r.t the search algorithms benchmarked.
For all offline and online experiments, we use data collected
by our system. The datasets in our offline experiments and online
deployment studies are all comprised of longitudinal data describing
daily sales for each product on display. The datasets all have the
following schema:
â€¢store id: identifier of the store
â€¢display id: identifier of the product display
5170Personalized Product Assortment with Real-time 3D Perception and Bayesian Payoff Estimation KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
0.0 0.1 0.2 0.3 0.4 0.5 0.6
Noise Pct0123456MSE (Preference Parameter)
Linear Regression
RBP (sigma=2.0)
RBP (sigma=1.0)
0.0 0.1 0.2 0.3 0.4 0.5 0.6
Store data (Pct of Cluster)0.00.10.20.30.40.50.6Store-level Error
RBP
Linear Regression
0 50 100 150 200 250
Sample Size0.20.40.60.81.0Posterior Uncertainity (std)
(a) Robustness to Outliers (b) Sample size of store-level error (c) Sample size on Uncertainty
Figure 4: Evaluation of the Robust Bayesian Payoff (RBP) model on a toy dataset. We demonstrate that RBP has three attractive
properties over non-Bayesian approaches: (a) RBP is more robust to outliers. As the data noise is increased, RBP is more robust
than linear regression; robustness increases as the prior strength increases (smaller ğœ). (b) As more data is acquired within
a store, RBP discounts information from other stores in the cluster. Linear Regression equally weights all data, increasing
store-level error. (c) In general, posterior uncertainty decreases as more data is acquired.
Figure 5: Representation of the Robust Bayesian Payoff (RBP)
model using plate notation. ğ‘–indexes product, ğ‘˜indexes clus-
ter, andğ‘™indexes store. Circles indicate random variables and
squares indicate hyperparameters. The ğ›½parameters describe
how expected payoff changes as allocated product quantity
increases and have hierarchical structure. This hierarchy fa-
cilitates store- and cluster-level preference estimation.
â€¢scanned datetime: timestamp of the userâ€™s interaction with
the display
â€¢product id: identifier of observed product
â€¢timedelta: difference (in hours) since previous interaction
with the display
â€¢sales: estimated numbers of units sales (from CountNet3D)
8.1.2 Benchmarks. For theğœ–-greedy implementation, we set ğœ–=
0.1. For the genetic algorithm we randomly marry 70% of pairs
together to form a new configuration, and choose a random action
30% of the time.
Both Deep Ensembles and MOPO rely on ensembles of neural
networks to learn a probabilistic model of the environment. In each
case, we train 5 fully connected neural networks with three hidden
layers with dimensions [256,256,256]and 135 input features. The
input features include a one hot vector for each product, the number
of observed product facings, and day of the week features. Eachnetwork is randomly initialized and trained for 1000 epochs to
minimize Gaussian negative log likelihood loss. In the case of the
Deep Ensemble we use the same heuristic search algorithm desribed
in Algorithm 2. For MOPO, we perform 5 rollouts with the dynamics
ensemble at each step, and update a tabular policy with a buffer of
real observations and rollouts.
8.2 Details of Online Experiments
8.2.1 Users. The core user in our online experiments is referred
to in the industry as a merchandiser. His or her primary function is
to ensure that shelves are replenished with product. In some cases,
they are asked to make decisions about which products to place on
shelves to improve sales. However, this process is usually driven
by intuition, and most merchandisers lack concrete data to inform
their decisions. Typically, the merchandiser surveys and restocks
each display in a store on a daily basis.
Users interact with EdgeRec3D through a mobile application
while they are merchandising a store. As the user replenishes prod-
uct each day, the merchandiser is instructed to view the mobile app
to get suggested, or recommended, product restock decisions. The
output of EdgeRec3D is a set of products and their quantities to put
on the shelf. One important aspect of this real-world recommen-
dation problem is that the merchandiser has the option to execute
or skip the recommendation. For example, a merchandiser may be
rushed to fill a large number of shelves and skip the recommended
action all together. This motivates our use of a compliance statistics
ğœŒ.
8.2.2 User Workflow. The user workflow is fairly straightforward
and integrates into their existing merchandising responsibilities.
Prior to restocking the shelf, the user performs the pre-scan to get
an updated inventory measurement and capture the current state,
S. The user then views the app, and queries the latest recommenda-
tions. At this point the user chooses whether or not to implement
the recommendations and restocks the display. Finally the user
completes the task by performing a post-scan and setting a baseline
inventory.
5171