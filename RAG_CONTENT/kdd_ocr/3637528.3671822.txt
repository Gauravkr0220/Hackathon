Fast Computation for the Forest Matrix of an Evolving Graph
Haoxin Sun
Fudan University
Shanghai, China
21210240097@m.fudan.edu.cnXiaotian Zhou
Fudan University
Shanghai, China
22110240080@m.fudan.edu.cnZhongzhi Zhangâˆ—
Fudan University
Shanghai, China
zhangzz@fudan.edu.cn
ABSTRACT
The forest matrix plays a crucial role in network science, opinion
dynamics, and machine learning, offering deep insights into the
structure of and dynamics on networks. In this paper, we study
the problem of querying entries of the forest matrix in evolving
graphs, which more accurately represent the dynamic nature of
real-world networks compared to static graphs. To address the
unique challenges posed by evolving graphs, we first introduce two
approximation algorithms, SFQandSFQPlus, for static graphs. SFQ
employs a probabilistic interpretation of the forest matrix, while
SFQPlus incorporates a novel variance reduction technique and is
theoretically proven to offer enhanced accuracy. Based on these two
algorithms, we further devise two dynamic algorithms centered
around efficiently maintaining a list of spanning converging forests.
This approach ensures ğ‘‚(1)runtime complexity for updates, in-
cluding edge additions and deletions, as well as for querying matrix
elements, and provides an unbiased estimation of forest matrix en-
tries. Finally, through extensive experiments on various real-world
networks, we demonstrate the efficiency and effectiveness of our
algorithms. Particularly, our algorithms are scalable to massive
graphs with more than forty million nodes.
CCS CONCEPTS
â€¢Networksâ†’Network algorithms; â€¢Theory of computation
â†’Randomness, geometry and discrete structures; â€¢Informa-
tion systemsâ†’Data mining.
KEYWORDS
Forest matrix, evolving graph, Wilsonâ€™s algorithm, spanning con-
verging forest, variance reduction
ACM Reference Format:
Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang. 2024. Fast Computation
for the Forest Matrix of an Evolving Graph. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD â€™24),
August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 10 pages.
https://doi.org/10.1145/3637528.3671822
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08. . . $15.00
https://doi.org/10.1145/3637528.36718221 INTRODUCTION
As a fundamental representation of a graph, the Laplacian matrix
Lencapsulates a wealth of structural and dynamical information
of the graph [ 34]. The forest matrix, denoted as â„¦=(I+L)âˆ’1, also
plays a pivotal role in the field of network science. This matrix,
along with its variants, is recognized as a foundational matrix in
numerous applications across various domains, such as Markov
processes [ 4,5], opinion dynamics [ 21,42,50], graph signal process-
ing [ 37,38], game theory [ 6,20], and multi-label classification [ 17].
The entries of the forest matrix notably reflect the structural prop-
erties of the graph due to their close relationship with the spanning
rooted forests within the graph [ 12,13]. In particular, the diagonal
entries of â„¦are associated with the concept of forest closeness
centrality [ 26,46] in graph mining and determinantal point pro-
cesses [ 29] in machine learning, and find applications in electrical
interpretations for multi-agent and network-based challenges [ 40].
The off-diagonal elements, ğœ”ğ‘– ğ‘—, serve as a measure of the proximity
of nodeğ‘–and nodeğ‘—, with a lower ğœ”ğ‘– ğ‘—indicating a greater â€œdistanceâ€
between the two nodes [ 13]. These elements are also instrumental
in calculating the personalized PageRank centrality between two
nodes [25, 47].
Due to the broad applications of the forest matrix, querying
its elements is of significant importance. In order to query the
entries of â„¦for a graph with ğ‘›nodes, a direct inversion of the
matrix I+Lcostsğ‘‚(ğ‘›3)operations and ğ‘‚(ğ‘›2)memories and thus
is prohibitive for relatively large graphs. In previous work, some fast
Laplacian solver [ 16] based algorithms were proposed to compute
the diagonal of the forest matrix [ 26,46]. Besides, some forest
sampling algorithms were proposed to compute the trace of the
forest matrix [8, 39] and the column sum of the forest matrix [42].
A majority of existing algorithms are designed for static graphs,
despite the fact that many real-life networks typically evolve dy-
namically. To query the elements of the forest matrix in evolving
graphs, we need to repeatedly run these algorithms as the graph
structure changes, which is very inefficient. Recognizing this limi-
tation, there is a pressing need for a dynamic approach to querying
elements of the forest matrix in evolving graphs. Such a dynamic so-
lution should be able to be updated easily whenever edges are added
or removed from the network, offering query results significantly
faster than recalculating from the beginning. Furthermore, it is
equally crucial to ensure that the solution has guaranteed accuracy.
In this paper, we delve deep into the problem of efficiently com-
puting the entries of the forest matrix in an evolving digraph, in
order to overcome the challenges and limitations of existing algo-
rithms. The main contributions of this work are summarized as
follows:
*Corresponding author. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang are with
Shanghai Key Laboratory of Intelligent Information Processing, School of Computer
Science, Fudan University, Shanghai 200433, China.
 
2755
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
(i) For static graphs, we introduce an algorithm SFQ to query for-
est matrix entries through a probabilistic interpretation. To enhance
accuracy and reduce variance, we develop innovative variance-
reduction techniques and present an algorithm SFQPlus, alongside
a theoretical guarantee for its performance.
(ii) In the context of evolving graphs, we focus on two edge oper-
ations: edge insertions and deletions, by devising an update strategy
to maintain a list of spanning converging forests. We demonstrate
that our algorithm provides an unbiased estimate of the forest ma-
trix entries and maintains an ğ‘‚(1)runtime complexity for both
querying and updating.
(iii) Comprehensive experiments on diverse real-world undi-
rected and directed networks show that SFQPlus consistently de-
livers superior estimation accuracy compared to SFQ, which returns
results close to the ground truth. Furthermore, our algorithms are
efficient and scalable, even on massive graphs with more than forty
million nodes.
2 RELATED WORK
In this section, we briefly review the existing work related to ours.
The investigation into forest matrix entries has garnered sig-
nificant attention in recent years, leading to the development of
two main categories of algorithms for addressing related problems:
solver-based algorithms and sampling-based algorithms. Solver-
based algorithms primarily operate on undirected graphs, lever-
aging the fast Laplacian solver [ 16]. In works such as [ 26,46], the
authors utilized the fast Laplacian solver for fast calculation of
the diagonal of forest matrix. In [ 50], the authors combined the
Johnson-Lindenstrauss lemma [ 2,27] with the fast Laplacian solver
to compute relevant quantities related to the forest matrix. Another
application in [ 51] utilizes a similar method for addressing opti-
mization issues in social dynamics, fundamentally relying on the
forest matrix.
In addition to solver-based algorithms, many algorithms are
sampling-based, inspired by the matrix-forest theorem that estab-
lishes a link between spanning forests and the forest matrix [ 12,13].
Wilsonâ€™s algorithm plays a pivotal role in these sampling-based
algorithms. Wilsonâ€™s algorithm and its variants have found applica-
tions across various domains, such as computing the trace of the
forest matrix [ 8,39], estimating the diagonal of forest matrix [ 43],
computing the column sum of the forest matrix to solve optimiza-
tion problems in opinion dynamics [ 42], and solving linear systems
in graph signal processing related to the forest matrix [37, 38].
For many realistic large graphs like social networks and the In-
ternet, their structures often change over time, posing challenges
in maintaining up-to-date information. For example, as the graphâ€™s
structure evolves, it becomes necessary to repeatedly run previously
mentioned algorithms, whether solver-based or sampling-based, to
obtain newly queried forest matrix data. Researchers have devel-
oped many special tools called dynamic graph algorithms, which
help solve problems faster. These tools have been used for vari-
ous problems that involve edge sparsifiers [ 22,23,28,44], as well
important variants of edge sparsifiers themselves, including mini-
mum spanning trees [ 24,35,36,49], spanners [ 9], spectral sparsi-
fiers [ 1,18,45], and low-stretch spanning trees [ 19]. However, mostof these advancements have been more theoretical than practical
and may not be suitable for the forest matrix query problem.
Our work takes a step further by applying Wilsonâ€™s algorithm
and providing novel techniques to reduce variance, for quickly
updating and querying any entry in the forest matrix in a graph as
it changes.
3 PRELIMINARIES
In this section, we introduce some useful notations and tools for
the convenience of description and analysis.
3.1 Graph and Laplacian Matrix
LetG=(ğ‘‰,ğ¸)denote an unweighted simple directed graph (di-
graph), which consists of ğ‘›=|ğ‘‰|nodes (vertices) and ğ‘š=|ğ¸|
directed edges (arcs). Here, ğ‘‰={ğ‘£1,ğ‘£2,...,ğ‘£ ğ‘›}denotes the set of
nodes, andğ¸represents the set of directed edges. An directed edge
(ğ‘£ğ‘–,ğ‘£ğ‘—)âˆˆğ¸indicates an edge pointing from node ğ‘£ğ‘–to nodeğ‘£ğ‘—. In
what follows, ğ‘£ğ‘–andğ‘–are used interchangeably to represent node
ğ‘£ğ‘–if incurring no confusion.
The structure of digraph G=(ğ‘‰,ğ¸)is captured by its adjacency
matrix A=(ğ‘ğ‘– ğ‘—)ğ‘›Ã—ğ‘›, whereğ‘ğ‘– ğ‘—=1if there is a directed edge from
nodeğ‘£ğ‘–to nodeğ‘£ğ‘—andğ‘ğ‘– ğ‘—=0otherwise. The in-degree ğ‘‘âˆ’
ğ‘–and
out-degreeğ‘‘+
ğ‘–of any node ğ‘–are defined by ğ‘‘âˆ’
ğ‘–=Ãğ‘›
ğ‘—=1ğ‘ğ‘—ğ‘–andğ‘‘+
ğ‘–=Ãğ‘›
ğ‘—=1ğ‘ğ‘– ğ‘—, respectively. In the sequel, we use ğ‘‘ğ‘–to represent the out-
degreeğ‘‘+
ğ‘–. The diagonal degree matrix representing the out-degrees
of digraphGisD=diag(ğ‘‘1,ğ‘‘2,...,ğ‘‘ ğ‘›), and the Laplacian matrix
isL=Dâˆ’A. For any given node ğ‘–,ğ‘+
ğ‘–andğ‘âˆ’
ğ‘–denote the sets of
its out-neighbors and in-neighbors, meaning ğ‘+
ğ‘–={ğ‘—:(ğ‘–,ğ‘—)âˆˆğ¸}
andğ‘âˆ’
ğ‘–={ğ‘—:(ğ‘—,ğ‘–)âˆˆğ¸}, respectively. Let Ibe theğ‘›-dimensional
identity matrix, and eğ‘–be theğ‘–-th standard basis column vector,
withğ‘–-th element being 1 and other elements being 0.
A pathğ‘ƒfrom nodeğ‘£1toğ‘£ğ‘—is a sequence of alternating nodes
and arcsğ‘£1,(ğ‘£1,ğ‘£2),ğ‘£2,Â·Â·Â·,ğ‘£ğ‘—âˆ’1,(ğ‘£ğ‘—âˆ’1,ğ‘£ğ‘—),ğ‘£ğ‘—where each node is
unique and every arc connects ğ‘£ğ‘–directly toğ‘£ğ‘–+1. A loop is a path
plus an arc from the ending node to the starting node. A digraph
is (strongly) connected if there exists a path from one node ğ‘£ğ‘¥
to another node ğ‘£ğ‘¦, and vice versa. A digraph is called weakly
connected if it is connected when one replaces any directed edge
(ğ‘–,ğ‘—)with two directed edges (ğ‘–,ğ‘—)and(ğ‘—,ğ‘–)in opposite directions.
A tree is a weakly connected graph with no loops, and an isolated
node is considered as a tree. A forest is a particular graph that is a
disjoint union of trees.
3.2 Spanning Converging Forests and Forest
Matrix
In a directed graph G=(ğ‘‰,ğ¸), a spanning subgraph contains all
the nodes from ğ‘‰and a subset of edges from ğ¸. A rooted converging
tree is a weakly connected digraph, where one node, called the root
node, has an out-degree of 0, and all other nodes have an out-degree
of 1. An isolated node is considered as a converging tree with the
root being itself. A spanning converging forest of digraph Gthat
includes all nodes in ğ‘‰and whose weakly connected components
are rooted converging trees. Such a forest aligns with the concept
of in-forest as described in [3, 11].
The forest matrix [ 13,14] is defined as â„¦=(I+L)âˆ’1=(ğœ”ğ‘– ğ‘—)ğ‘›Ã—ğ‘›.
In the context of digraphs, the forest matrix Î©is row stochastic,
 
2756Fast Computation for the Forest Matrix of an Evolving Graph KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
with all its components in the interval [0,1]. Moreover, for each
column, the diagonal elements surpass the other elements, that is
0â‰¤ğœ”ğ‘—ğ‘–<ğœ”ğ‘–ğ‘–â‰¤1for any pair of different nodes ğ‘–andğ‘—, and the
diagonal element ğœ”ğ‘–ğ‘–of matrix â„¦satisfies1
1+ğ‘‘ğ‘–â‰¤ğœ”ğ‘–ğ‘–â‰¤2
2+ğ‘‘ğ‘–[42].
For an unweighted digraph G=(ğ‘‰,ğ¸), letFdenote the set of all
its spanning converging forests. For a given spanning converging
forestğœ™âˆˆF, define the root set R(ğœ™)ofğœ™as the collection of
roots from all converging trees that constitute ğœ™, that is,R(ğœ™)=
{ğ‘–:(ğ‘–,ğ‘—)âˆ‰ğœ™,âˆ€ğ‘—âˆˆğ‘‰}. Since each node ğ‘–inğœ™is part of a specific
converging tree, we define a function ğ‘Ÿğœ™(ğ‘–):ğ‘‰â†’R(ğœ™)mapping
nodeğ‘–to the root of its associated converging tree. Thus, if ğ‘Ÿğœ™(ğ‘–)=ğ‘—,
it implies that ğ‘—is inR(ğœ™), and both nodes ğ‘–andğ‘—are part of
the same converging tree in ğœ™. DefineFğ‘– ğ‘—as the set of spanning
converging forests in which nodes ğ‘–andğ‘—are within the same
converging tree, rooted at node ğ‘—. Formally,Fğ‘– ğ‘—={ğœ™:ğ‘Ÿğœ™(ğ‘–)=
ğ‘—,ğœ™âˆˆF} . It follows thatFğ‘–ğ‘–={ğœ™:ğ‘–âˆˆR(ğœ™),ğœ™âˆˆF} . For two
nodesğ‘–andğ‘—and a spanning converging forest ğœ™, define I{ğ‘Ÿğœ™(ğ‘–)=ğ‘—}
as an indicator function, which is 1 if the input statement is true
and 0 otherwise. For example, if ğ‘Ÿğœ™(ğ‘–)=ğ‘—,I{ğ‘Ÿğœ™(ğ‘–)=ğ‘—}=1, and
I{ğ‘Ÿğœ™(ğ‘–)=ğ‘—}=0otherwise.
4 FAST QUERY OF ENTRIES IN FOREST
MATRIX FOR DIGRAPHS
In this section, we propose sampling-based algorithms and novel
variance reduction techniques, designed to enable fast querying of
entries for the forest matrix.
4.1 Extension of Wilsonâ€™s Algorithm
As mentioned above, the entries of the forest matrix are closely
related to the spanning converging forests. In this subsection, we
briefly introduce the method for uniformly generating spanning
converging forest in graphs, utilizing an extension of Wilsonâ€™s
algorithm.
Wilson proposed an algorithm based on a loop-erased random
walk to get a spanning tree rooted at a given node [ 48]. The loop-
erasure technique, pivotal to this algorithm, is a process derived
from the random walk by performing an erasure operation on its
loops in chronological order [ 31,32]. For a digraphG=(ğ‘‰,ğ¸),
we can also apply an extension of Wilsonâ€™s algorithm to get a
spanning converging forest ğœ™âˆˆF, by using the method similar
to that in [ 5,38,42], which includes the following three steps: (i)
Construct an augmented digraph Gâ€²ofG, which is obtained from
Gby adding one new node Î”toG, and adding a new edge (ğ‘–,Î”)for
each nodeğ‘–inG. (ii) Apply Wilsonâ€™s algorithm to Gâ€², designating
Î”as the root, to produce a rooted spanning tree. (iii) Remove node
Î”and its connected edges, and define the root set Ras the nodes
with an out-degree of 0, thereby obtaining a spanning converging
forest inG.
Since Wilsonâ€™s algorithm returns a uniform rooted spanning
tree [ 48], the spanning converging forest obtained using the above
steps is also uniformly selected from F. According to [ 42], the
expected time complexity for generating a uniform spanning con-
verging forest in a digraph G=(ğ‘‰,ğ¸)isğ‘‚(ğ‘›), making this method
efficient and practical for large-scale graphs.4.2 Probabilistic Interpretation and Unbiased
Estimators of Entries in Forest Matrix
In this subsection, we present a probabilistic interpretation of the
entries in the forest matrix and propose unbiased estimators for
these entries.
Using the approach in [ 10,12,13], for any pair of nodes ğ‘–,ğ‘—âˆˆğ‘‰,
the entryğœ”ğ‘– ğ‘—of the forest matrix â„¦can be expressed as ğœ”ğ‘– ğ‘—=
|Fğ‘– ğ‘—|/|F| . This suggests a probabilistic interpretation of the entry
ğœ”ğ‘– ğ‘—of the forest matrix which represents the probability of the root
of nodeğ‘–being nodeğ‘—in a uniformly sampled spanning converging
forestğœ™âˆˆF. For a spanning converging forest ğœ™âˆˆF, We define
an estimator bğœ”ğ‘– ğ‘—(ğœ™)forğœ”ğ‘– ğ‘—asbğœ”ğ‘– ğ‘—(ğœ™)=I{ğ‘Ÿğœ™(ğ‘–)=ğ‘—}. The estimator
bğœ”ğ‘– ğ‘—(ğœ™)takes the value 1if the root of ğ‘–isğ‘—, and 0otherwise. This
estimator is unbiased if ğœ™is uniformly selected from F, satisfying
E(bğœ”ğ‘– ğ‘—(ğœ™))=P(ğ‘Ÿğœ™(ğ‘–)=ğ‘—)=|Fğ‘–ğ‘—|
|F|=ğœ”ğ‘– ğ‘—. Moreover, the variance of
bğœ”ğ‘– ğ‘—isVar(bğœ”ğ‘– ğ‘—)=ğœ”ğ‘– ğ‘—âˆ’ğœ”2
ğ‘– ğ‘—.
Algorithm 1: SFQ(G,F0,ğ‘™,ğ‘–,ğ‘—)
Input : A digraphG, a list ofğ‘™uniformly sampled
spanning converging forest F0, a pair of querying
idğ‘–,ğ‘—
Output : bğœ”ğ‘– ğ‘—: an estimator of ğœ”ğ‘– ğ‘—
1Initialize :bğœ”ğ‘– ğ‘—â†0
2forğœ™inF0do
3ğ‘˜â†ğ‘Ÿğœ™(ğ‘–)
4 ifğ‘˜=ğ‘—then
5 bğœ”ğ‘– ğ‘—â†bğœ”ğ‘– ğ‘—+1/ğ‘™
6return bğœ”ğ‘– ğ‘—
As previously established, we employ the extension of Wilsonâ€™s
algorithm to generate ğ‘™spanning converging forests ğœ™1,Â·Â·Â·,ğœ™ğ‘™.
Then we can approximate ğœ”ğ‘– ğ‘—using the mean value1
ğ‘™Ãğ‘™
ğ‘˜=1bğœ”ğ‘– ğ‘—(ğœ™ğ‘˜).
We detailed this in Algorithm 1, named as Spanning Forest Query
(SFQ). The time complexity of Algorithm 1 is ğ‘‚(ğ‘™), whereğ‘™is the
number of the pre-sampled spanning converging forests.
4.3 Enhanced Estimators with Reduced
Variance
In the preceding subsection, we defined an unbiased estimator
bğœ”ğ‘– ğ‘—(ğœ™)forğœ”ğ‘– ğ‘—. In this subsection, we introduce enhanced estimators
that not only maintain the unbiased property, but also achieve
reduced variance, thus providing more accurate estimations.
We begin with the cases ğ‘–â‰ ğ‘—. For a spanning converging forest
ğœ™âˆˆF, the initial estimator bğœ”ğ‘– ğ‘—(ğœ™)assigns a value of 1 if a path
exists from ğ‘–toğ‘—inğœ™, and 0 otherwise. However, this approach
overlooks the case where a node ğ‘˜âˆˆğ‘âˆ’
ğ‘—(indicating an edge (ğ‘˜,ğ‘—)âˆˆ
ğ¸) is the root for node ğ‘–in the forest ğœ™. This situation suggests that
nodeğ‘–might be rooted at node ğ‘—in other forests due to the possible
existence of a path from ğ‘–toğ‘—, which is a concatenation of a path
fromğ‘–toğ‘˜and an edge(ğ‘˜,ğ‘—). Our new approach aims to incorporate
these overlooked instances by aggregating information from forests
where node ğ‘–is rooted in the in-neighbors of node ğ‘—.
Specifically, for nodes ğ‘˜âˆˆğ‘âˆ’(ğ‘—),ğœ”ğ‘–ğ‘˜denotes the probability
of nodeğ‘–rooted atğ‘˜. When performing the loop-erased random
 
2757KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
walk in the extension of Wilsonâ€™s algorithm, if the walk is currently
at nodeğ‘–, it has a probability of1
1+ğ‘‘ğ‘–moving to a random out-
neighbor or becoming a root (moving to the extended node Î”in the
augmented graphGâ€²). Letâ€™s consider a loop-erased random walk
that starts at node ğ‘–and ends at node ğ‘˜, creating a path ğ‘ƒfromğ‘–to
ğ‘˜and then terminating. Now, imagine a walking path ğ‘ƒâ€²slightly
different from path ğ‘ƒ, where the walker does not ending at ğ‘˜, but
continues to jump to node ğ‘—and then terminates. The probability
of pathğ‘ƒâ€²occurring is1
1+ğ‘‘ğ‘—times that of ğ‘ƒ. Since any path from
ğ‘–toğ‘—must pass through a node ğ‘˜âˆˆğ‘âˆ’(ğ‘—)before reaching ğ‘—, we
define a new estimator eğœ”ğ‘– ğ‘—(ğœ™)for different nodes ğ‘–,ğ‘—, and spanning
converging forest ğœ™âˆˆF aseğœ”ğ‘– ğ‘—(ğœ™)=1
1+ğ‘‘ğ‘—Ã
ğ‘˜âˆˆğ‘âˆ’(ğ‘—)bğœ”ğ‘–ğ‘˜(ğœ™).
The following lemma shows that eğœ”ğ‘– ğ‘—is an unbiased estimator of
ğœ”ğ‘– ğ‘—and has a reduced variance compared to bğœ”ğ‘– ğ‘—:
Lemma 4.1. For two different nodes ğ‘–andğ‘—in graphGand a
uniformly chosen spanning converging forest ğœ™âˆˆ F ,eğœ”ğ‘– ğ‘—(ğœ™)=
1
1+ğ‘‘ğ‘—Ã
ğ‘˜âˆˆğ‘âˆ’(ğ‘—)bğœ”ğ‘–ğ‘˜(ğœ™)is an unbiased estimator of ğœ”ğ‘– ğ‘—. The vari-
ance of this estimator is given by Var(eğœ”ğ‘– ğ‘—)=ğœ”ğ‘–ğ‘—
1+ğ‘‘ğ‘—âˆ’ğœ”2
ğ‘– ğ‘—, which is
always less than or equal to the variance of the estimator bğœ”ğ‘– ğ‘—.
Proof. Using the relationship â„¦(I+L)=I, it follows that
eâŠ¤
ğ‘–â„¦(I+L)eğ‘—=0. This implies(1+ğ‘‘ğ‘—)ğœ”ğ‘– ğ‘—âˆ’Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘—ğœ”ğ‘–ğ‘˜=0,
leading toğœ”ğ‘– ğ‘—=1
1+ğ‘‘ğ‘—Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘—ğœ”ğ‘–ğ‘˜.Since E(bğœ”ğ‘–ğ‘˜)=ğœ”ğ‘–ğ‘˜, we have
E(eğœ”ğ‘– ğ‘—)=1
1+ğ‘‘ğ‘—Ã
ğ‘˜âˆˆğ‘âˆ’(ğ‘—)E(bğœ”ğ‘–ğ‘˜)=1
1+ğ‘‘ğ‘—Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘—ğœ”ğ‘–ğ‘˜=ğœ”ğ‘– ğ‘—,which
shows that eğœ”ğ‘– ğ‘—is an unbiased estimator of ğœ”ğ‘– ğ‘—.
Next, we calculate the variance of eğœ”ğ‘– ğ‘—. Considering E(bğœ”2
ğ‘–ğ‘˜)=
ğœ”ğ‘–ğ‘˜andE(bğœ”ğ‘– ğ‘—bğœ”ğ‘–ğ‘˜)=0forğ‘—â‰ ğ‘˜, we have Var(eğœ”ğ‘– ğ‘—)=E(eğœ”2
ğ‘– ğ‘—)âˆ’
(E(eğœ”ğ‘– ğ‘—))2=E(1
(1+ğ‘‘ğ‘—)2(Ã
ğ‘˜âˆˆğ‘âˆ’(ğ‘—)bğœ”ğ‘–ğ‘˜)2)âˆ’ğœ”2
ğ‘– ğ‘—=Ã
ğ‘˜âˆˆğ‘âˆ’(ğ‘—)bğœ”ğ‘–ğ‘˜
(1+ğ‘‘ğ‘—)2âˆ’
ğœ”2
ğ‘– ğ‘—=ğœ”ğ‘–ğ‘—
1+ğ‘‘ğ‘—âˆ’ğœ”2
ğ‘– ğ‘—, which finishes the proof. â–¡
Lemma 4.1 demonstrates that eğœ”ğ‘– ğ‘—is an unbiased estimator with
a lower variance compared to bğœ”ğ‘– ğ‘—. The reduction in variance is
attributed to eğœ”ğ‘– ğ‘—accounting for instances where node ğ‘–is rooted
at the in-neighbors of node ğ‘—, a scenario that bğœ”ğ‘– ğ‘—fails to consider.
Specifically, if ğœ™âˆˆFğ‘–ğ‘˜withğ‘˜âˆˆğ‘âˆ’
ğ‘—, theneğœ”ğ‘– ğ‘—(ğœ™)equals1
1+ğ‘‘ğ‘–, while
bğœ”ğ‘– ğ‘—(ğœ™)is 0. Conversely, for ğœ™âˆˆFğ‘– ğ‘—,bğœ”ğ‘– ğ‘—(ğœ™)is 1, but eğœ”ğ‘– ğ‘—(ğœ™)is 0.
This indicates that eğœ”ğ‘– ğ‘—partially disregards instances where ğ‘–is
directly rooted at ğ‘—.
To address this issue, we introduce an estimator ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼), which
is a linear combination of eğœ”ğ‘– ğ‘—andbğœ”ğ‘– ğ‘—, defined as ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼)=
ğ›¼bğœ”ğ‘– ğ‘—(ğœ™)+(1âˆ’ğ›¼)eğœ”ğ‘– ğ‘—(ğœ™). The parameter ğ›¼is chosen to minimize
the variance of the estimator, as explained in the following lemma:
Lemma 4.2. For two distinct nodes ğ‘–andğ‘—inğ‘‰, a parameter ğ›¼âˆˆR,
and a uniformly chosen spanning converging forest ğœ™âˆˆF, the estima-
torğœ”ğ‘– ğ‘—(ğœ™,ğ›¼)=ğ›¼bğœ”ğ‘– ğ‘—(ğœ™)+(1âˆ’ğ›¼)eğœ”ğ‘– ğ‘—(ğœ™)is an unbiased estimator for
ğœ”ğ‘– ğ‘—. The variance of estimator ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼)is minimized when ğ›¼=1
2+ğ‘‘ğ‘—.
Definingğœ”ğ‘– ğ‘—(ğœ™)asğœ”ğ‘– ğ‘—(ğœ™,1
2+ğ‘‘ğ‘—)=1
2+ğ‘‘ğ‘—(bğœ”ğ‘– ğ‘—(ğœ™)+Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘—bğœ”ğ‘–ğ‘˜(ğœ™)),
the variance of ğœ”ğ‘– ğ‘—(ğœ™)is given by Var(eğœ”ğ‘– ğ‘—)=ğœ”ğ‘–ğ‘—
2+ğ‘‘ğ‘—âˆ’ğœ”2
ğ‘– ğ‘—, which
is smaller than that of both bğœ”ğ‘– ğ‘—(ğœ™)andeğœ”ğ‘– ğ‘—(ğœ™). Moreover, the non-
negativity of variance implies ğœ”ğ‘– ğ‘—â‰¤1
2+ğ‘‘ğ‘—.
Proof. Since both bğœ”ğ‘– ğ‘—andeğœ”ğ‘– ğ‘—are unbiased estimators for ğœ”ğ‘– ğ‘—,
it follows that E(ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼))=ğ›¼E(bğœ”ğ‘– ğ‘—(ğœ™))+( 1âˆ’ğ›¼)E(eğœ”ğ‘– ğ‘—(ğœ™))=ğœ”ğ‘– ğ‘—, indicating the estimator ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼)is also unbiased for ğœ”ğ‘– ğ‘—. We
proceed to calculate the variance of ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼)as
Var(ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼))=E(ğœ”2
ğ‘– ğ‘—(ğœ™,ğ›¼))âˆ’(E(ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼))2
=ğœ”ğ‘– ğ‘—(2+ğ‘‘ğ‘—)
1+ğ‘‘ğ‘—
ğ›¼âˆ’1
2+ğ‘‘ğ‘—2
+ğœ”ğ‘– ğ‘—
2+ğ‘‘ğ‘—âˆ’ğœ”2
ğ‘– ğ‘—.
The variance of the estimator ğœ”ğ‘– ğ‘—(ğœ™,ğ›¼)is minimized when ğ›¼=
1
2+ğ‘‘ğ‘—, resulting inğœ”ğ‘–ğ‘—
2+ğ‘‘ğ‘—âˆ’ğœ”2
ğ‘– ğ‘—, which finishes the proof. â–¡
Lemma 4.2 indicates that the newly formulated estimator ğœ”ğ‘– ğ‘—(ğœ™)=
1
2+ğ‘‘ğ‘—(bğœ”ğ‘– ğ‘—(ğœ™)+Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘—bğœ”ğ‘–ğ‘˜(ğœ™))has a lower variance than the pre-
vious two estimators by incorporating their respective information.
Having established the improved estimator ğœ”ğ‘– ğ‘—for the scenario
ğ‘–â‰ ğ‘—, we next focus on the situation that ğ‘–is equal toğ‘—.
For the case ğ‘–=ğ‘—, we consider a similar approach of aggregating
information from the in-neighbors of node ğ‘–. This leads to a new
estimator with reduced variance compared to bğœ”ğ‘–ğ‘–. We define the new
estimatorğœ”ğ‘–ğ‘–(ğœ™)asğœ”ğ‘–ğ‘–(ğœ™)=1
1+ğ‘‘ğ‘–(1+Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–bğœ”ğ‘–ğ‘˜(ğœ™)). Lemma 4.3
demonstrates that ğœ”ğ‘–ğ‘–(ğœ™)is an unbiased estimator for ğœ”ğ‘–ğ‘–with
reduced variance.
Lemma 4.3. For nodeğ‘–âˆˆğ‘‰and a uniformly chosen spanning con-
verging forest ğœ™âˆˆF,ğœ”ğ‘–ğ‘–(ğœ™)=1
1+ğ‘‘ğ‘–(1+Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–bğœ”ğ‘–ğ‘˜(ğœ™))is an unbi-
ased estimator for ğœ”ğ‘–ğ‘–. The variance of this estimator is Var(ğœ”ğ‘–ğ‘–)=
3ğœ”ğ‘–ğ‘–
1+ğ‘‘ğ‘–âˆ’2
(1+ğ‘‘ğ‘–)2âˆ’ğœ”2
ğ‘–ğ‘–, which is always less than or equal to the variance
of the estimator bğœ”ğ‘–ğ‘–.
Proof. Since â„¦(I+L)=I, it follows that eâŠ¤
ğ‘–â„¦(I+L)eğ‘–=1.
This implies(1+ğ‘‘ğ‘–)ğœ”ğ‘–ğ‘–âˆ’Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–ğœ”ğ‘–ğ‘˜=1, that is,ğœ”ğ‘–ğ‘–=1
1+ğ‘‘ğ‘–(1+
Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–ğœ”ğ‘–ğ‘˜).Since E(bğœ”ğ‘–ğ‘˜)=ğœ”ğ‘–ğ‘˜, we have E(ğœ”ğ‘–ğ‘–)=1
1+ğ‘‘ğ‘–(1+
Ã
ğ‘˜âˆˆğ‘âˆ’(ğ‘–)E(bğœ”ğ‘–ğ‘˜))=1
1+ğ‘‘ğ‘–(1+Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–ğœ”ğ‘–ğ‘˜)=ğœ”ğ‘–ğ‘–,which shows
thateğœ”ğ‘– ğ‘—is an unbiased estimator for ğœ”ğ‘– ğ‘—. The variance of ğœ”ğ‘–ğ‘–can be
derived as follows: Var(ğœ”ğ‘–ğ‘–)=E(ğœ”ğ‘–ğ‘–)2âˆ’(E(ğœ”ğ‘–ğ‘–))2=1
(1+ğ‘‘ğ‘–)2E((1+
Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–bğœ”ğ‘–ğ‘˜)2)âˆ’ğœ”2
ğ‘–ğ‘–=1
(1+ğ‘‘ğ‘–)2E(1+2Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–bğœ”ğ‘–ğ‘˜+(Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–bğœ”ğ‘–ğ‘˜)2)âˆ’
ğœ”2
ğ‘–ğ‘–=1+3Ã
ğ‘˜âˆˆğ‘âˆ’
ğ‘–ğœ”ğ‘–ğ‘˜
(1+ğ‘‘ğ‘–)2âˆ’ğœ”2
ğ‘–ğ‘–=1+3((1+ğ‘‘ğ‘–)ğœ”ğ‘–ğ‘–âˆ’1)
(1+ğ‘‘ğ‘–)2âˆ’ğœ”2
ğ‘–ğ‘–=3ğœ”ğ‘–ğ‘–
1+ğ‘‘ğ‘–âˆ’2
(1+ğ‘‘ğ‘–)2âˆ’
ğœ”2
ğ‘–ğ‘–.Then we get the following relation Var{bğœ”ğ‘–ğ‘–}âˆ’Var{ğœ”ğ‘–ğ‘–}=
2(1âˆ’ğœ”ğ‘–ğ‘–)
(1+ğ‘‘ğ‘–)2+ğ‘‘ğ‘–(ğ‘‘ğ‘–âˆ’1)ğœ”ğ‘–ğ‘–
(1+ğ‘‘ğ‘–)2â‰¥0.This inequality shows that the variance
ofğœ”ğ‘–ğ‘–is no more than the variance of the estimator bğœ”ğ‘–ğ‘–, which
completes the proof. â–¡
In the above, we have proposed enhanced estimators ğœ”ğ‘–ğ‘–and
ğœ”ğ‘– ğ‘—for the diagonal ğœ”ğ‘–ğ‘–and non-diagonal entries ğœ”ğ‘– ğ‘—. Suppose
that we already have used the extension of Wilsonâ€™s algorithm to
generateğ‘™spanning converging forests ğœ™1,Â·Â·Â·,ğœ™ğ‘™. Then we can
approximate ğœ”ğ‘–ğ‘–andğœ”ğ‘– ğ‘—using1
ğ‘™Ãğ‘™
ğ‘˜=1ğœ”ğ‘–ğ‘–(ğœ™ğ‘˜)and1
ğ‘™Ãğ‘™
ğ‘˜=1ğœ”ğ‘– ğ‘—(ğœ™ğ‘˜).
We detailed this in Algorithm 2, named as Spanning Forest Query
Plus (SFQPlus).
The time complexity of Algorithm 2 is ğ‘‚(ğ‘™), whereğ‘™is the num-
ber of the pre-sampled spanning converging forests. As we increase
the number of pre-sampled forest ğ‘™, we observe a corresponding
decrease in the estimation error between ğœ”ğ‘– ğ‘—and the actual value
ğœ”ğ‘– ğ‘—. To quantify this relationship, we introduce Theorem 4.5, which
specifies the necessary size of ğ‘™to achieve a necessary error guaran-
tee with a high probability. Before giving Theorem 4.5, we introduce
the following lemma.
 
2758Fast Computation for the Forest Matrix of an Evolving Graph KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Algorithm 2: SFQPlus(G,F0,ğ‘™,ğ‘–,ğ‘—)
Input : A digraphG=(ğ‘‰,ğ¸), a list ofğ‘™uniformly
sampled spanning converging forest F0, a pair of
querying id ğ‘–,ğ‘—
Output :ğœ”ğ‘– ğ‘—: an estimator of ğœ”ğ‘– ğ‘—
1ifğ‘–=ğ‘—then
2 Initialize :ğœ”ğ‘– ğ‘—â†1
1+ğ‘‘ğ‘–
3else
4 Initialize :ğœ”ğ‘– ğ‘—â†0
5forğœ™inF0do
6ğ‘˜â†ğ‘Ÿğœ™(ğ‘–)
7 ifğ‘˜=ğ‘—&ğ‘–â‰ ğ‘—then
8ğœ”ğ‘– ğ‘—â†ğœ”ğ‘– ğ‘—+1
(2+ğ‘‘ğ‘—)ğ‘™
9 else if edge(ğ‘˜,ğ‘—)âˆˆğ¸then
10 ifğ‘–=ğ‘—then
11 ğœ”ğ‘– ğ‘—â†ğœ”ğ‘– ğ‘—+1
(1+ğ‘‘ğ‘—)ğ‘™
12 else
13 ğœ”ğ‘– ğ‘—â†ğœ”ğ‘– ğ‘—+1
(2+ğ‘‘ğ‘—)ğ‘™
14returnğœ”ğ‘– ğ‘—
Lemma 4.4. (Chernoff bound [ 15]) Letğ‘¥ğ‘–(1â‰¤ğ‘–â‰¤ğ‘™)be indepen-
dent random variables satisfying |ğ‘¥ğ‘–âˆ’E{ğ‘¥ğ‘–}|â‰¤ğ‘€for all 1â‰¤ğ‘–â‰¤ğ‘™.
Letğ‘¥=1
ğ‘™Ãğ‘™
ğ‘–=1ğ‘¥ğ‘–. Then we have
P(|ğ‘¥âˆ’E{ğ‘¥}|â‰¤ğœ–)â‰¥1âˆ’2 exp
âˆ’ğ‘™ğœ–2
2(Var{ğ‘¥}ğ‘™+ğ‘€ğœ–/3)
.(1)
Theorem 4.5. For any pair of nodes ğ‘–â‰ ğ‘—, and parameters ğœ–,ğœ,ğ›¿âˆˆ
(0,1), ifğ‘™is chosen obeying ğ‘™=l
1
(2+ğ‘‘ğ‘—)2(1
2ğœ–2+2
3ğœ–)log(2
ğ›¿)m
, then
the approximation ğœ”ğ‘– ğ‘—ofğœ”ğ‘– ğ‘—returned by Algorithm 2 satisfies the
following relation with probability of at least 1âˆ’ğ›¿:
ğœ”ğ‘– ğ‘—âˆ’ğœ–â‰¤ğœ”ğ‘– ğ‘—â‰¤ğœ”ğ‘– ğ‘—+ğœ–. (2)
For the case that ğ‘–=ğ‘—, and for parameters ğœ–,ğ›¿âˆˆ(0,1), ifğ‘™is cho-
sen obeying ğ‘™=l
(2
3ğœ–+1
4ğœ–2)log(2
ğ›¿)m
, then the approximation ğœ”ğ‘–ğ‘–
ofğœ”ğ‘–ğ‘–returned by Algorithm 2 satisfies the following relation with
probability of at least 1âˆ’ğ›¿:
(1âˆ’ğœ–)ğœ”ğ‘–ğ‘–â‰¤ğœ”ğ‘–ğ‘–â‰¤(1+ğœ–)ğœ”ğ‘–ğ‘–. (3)
Proof. For the case that ğ‘–â‰ ğ‘—, the output ğœ”ğ‘– ğ‘—of Algorithm 2
isğœ”ğ‘– ğ‘—=1
ğ‘™Ãğ‘™
ğ‘˜=1ğœ”ğ‘– ğ‘—(ğœ™ğ‘˜). Since the variance of ğœ”ğ‘– ğ‘—(ğœ™ğ‘˜)isğœ”ğ‘–ğ‘—
2+ğ‘‘ğ‘—âˆ’
ğœ”2
ğ‘– ğ‘—forğ‘˜=1,Â·Â·Â·,ğ‘™, and theğ‘™variables are independent, we can
compute the variance of ğœ”ğ‘– ğ‘—asVar(ğœ”ğ‘– ğ‘—)=1
ğ‘™(ğœ”ğ‘–ğ‘—
2+ğ‘‘ğ‘—âˆ’ğœ”2
ğ‘– ğ‘—). To obtain
the absolute error bound given by (2), ğœ”ğ‘– ğ‘—needs to satisfy
P(|ğœ”ğ‘– ğ‘—âˆ’ğœ”ğ‘– ğ‘—|â‰¥ğœ–)â‰¤ğ›¿.
We now show that the above relation holds true. To this end, we
designateğ‘¥ğ‘—=ğœ”ğ‘– ğ‘—(ğœ™ğ‘˜)for1â‰¤ğ‘˜â‰¤ğ‘™andğ‘¥=ğœ”ğ‘– ğ‘—, and invoke the
Chernoff bound in Lemma 4.4. Then, in order to prove (2), we only
need to show that the following inequality holds:
2 exp
âˆ’ğ‘™ğœ–2
2(Var{ğœ”ğ‘– ğ‘—}ğ‘™+ğ‘€ğœ–ğœ” ğ‘– ğ‘—/3)
â‰¤ğ›¿,which leads to
ğ‘™â‰¥log(2
ğ›¿)2Var{ğœ”ğ‘– ğ‘—}ğ‘™
ğœ–2+2ğ‘€ğœ”ğ‘– ğ‘—
3ğœ–
. (4)
Since|bğœ”ğ‘– ğ‘—âˆ’ğœ”ğ‘– ğ‘—|â‰¤1
2+ğ‘‘ğ‘—, we can set ğ‘€=1
2+ğ‘‘ğ‘—. Considering that
Var{ğœ”ğ‘– ğ‘—(ğœ™ğ‘—)}=1
ğ‘™(ğœ”ğ‘–ğ‘—
2+ğ‘‘ğ‘—âˆ’ğœ”2
ğ‘– ğ‘—), inequality (4) is reduced to:
ğ‘™â‰¥log(2
ğ›¿) 
2ğœ”ğ‘– ğ‘—
ğœ–2(2+ğ‘‘ğ‘—)+2ğœ”ğ‘– ğ‘—
3ğœ–(2+ğ‘‘ğ‘—)âˆ’2ğœ”2
ğ‘– ğ‘—
ğœ–2!
. (5)
Thus, for any pair of nodes ğ‘–â‰ ğ‘—, since 0â‰¤ğœ”ğ‘– ğ‘—â‰¤1
2+ğ‘‘ğ‘—, selecting
ğ‘™=
1
2ğœ–2+2
3ğœ–log2
ğ›¿
(2+ğ‘‘ğ‘—)2
ensures the required inequality (4)always
holds. This completes the proof.
For the case that ğ‘–=ğ‘—, the output ğœ”ğ‘–ğ‘–of Algorithm 2 is ğœ”ğ‘–ğ‘–=
1
ğ‘™Ãğ‘™
ğ‘˜=1ğœ”ğ‘–ğ‘–(ğœ™ğ‘˜). For a spanning converging forest ğœ™âˆˆF,ğœ”ğ‘–ğ‘–(ğœ™)
is either1
1+ğ‘‘ğ‘–or2
1+ğ‘‘ğ‘–. Considering1
1+ğ‘‘ğ‘–â‰¤ğœ”ğ‘–ğ‘–â‰¤2
2+ğ‘‘ğ‘–, it follows
that|ğœ”ğ‘–ğ‘–âˆ’ğœ”ğ‘–ğ‘–|â‰¤1
1+ğ‘‘ğ‘–. Then we can set the bound ğ‘€asğ‘€=1
1+ğ‘‘ğ‘–.
Employing a similar analytical approach as above, the number of ğ‘™
needs to satisfy the following inequality:
ğ‘™â‰¥log(2
ğ›¿) 
2Var{ğœ”ğ‘–ğ‘–}ğ‘™
ğœ–2ğœ”2
ğ‘–ğ‘–+2
3(1+ğ‘‘ğ‘–)ğœ–ğœ”ğ‘–ğ‘–!
. (6)
Given thatğœ”ğ‘–ğ‘–=1
ğ‘™(3ğœ”ğ‘–ğ‘–
1+ğ‘‘ğ‘–âˆ’2
(1+ğ‘‘ğ‘–)2âˆ’ğœ”2
ğ‘–ğ‘–), we derive that
Var(ğœ”ğ‘–ğ‘–)ğ‘™
ğœ”2
ğ‘–ğ‘–=3
(1+ğ‘‘ğ‘–)ğœ”ğ‘–ğ‘–âˆ’2
(1+ğ‘‘ğ‘–)2ğœ”2
ğ‘–ğ‘–âˆ’1
=âˆ’2
(1+ğ‘‘ğ‘–)2(1
ğœ”ğ‘–ğ‘–âˆ’3(1+ğ‘‘ğ‘–)
4)2+1
8â‰¤1
8(7)
Thus, withVar(ğœ”ğ‘–ğ‘–)ğ‘™
ğœ”2
ğ‘–ğ‘–â‰¤1
8and(1+ğ‘‘ğ‘–)ğœ”ğ‘–ğ‘–â‰¤1, choosing ğ‘™=
l
(2
3ğœ–+1
4ğœ–2)log
2
ğ›¿m
ensures that inequality (6)is always satisfied,
which completes the proof. â–¡
Based on Theorem 4.5, when the parameters ğœ–,ğœ, andğ›¿are fixed
constants, the number of spanning converging forests ğ‘™required
by Algorithm 2 to achieve an ğœ–absolute error for non-diagonal
entries and relative error for diagonal entries does not increase
with the expansion of the graph. Therefore, the time complexity of
Algorithm 2 can be considered as ğ‘‚(1)for achieving a satisfactory
error guarantee, regardless of the graph size.
5 FAST QUERY OF ENTRIES OF FOREST
MATRIX FOR EVOLVING GRAPHS
In the previous section, we developed estimators approximating
the entries of the forest matrix in static directed graphs. However,
real-world graphs often evolve dynamically. This section addresses
evolving graphs, focusing on two types of updates: edge insertion
and edge deletion.
5.1 Problem Statement
Consider an initial graph G0=(ğ‘‰0,ğ¸0)and a corresponding list
ğ¿0ofğ‘™0spanning converging forests, which is uniformly sampled
using an extension of Wilsonâ€™s algorithm. In this dynamic context,
there are two possible requests: updates and queries. For the request
of updates, we restrict our focus to edge insertions and deletions.
 
2759KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
Other updates such as nodes insertions/deletions can be easily
converted to a sequence of edges insertion/deletions. For the ğ‘˜-
th edge update, let ğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜)denote the edge being modified,
resulting in an updated graph Gğ‘˜=(ğ‘‰ğ‘˜,ğ¸ğ‘˜). Specifically, for edge
insertions,ğ¸ğ‘˜=ğ¸ğ‘˜âˆ’1âˆª{ğ‘’ğ‘˜}, and for deletions, ğ¸ğ‘˜=ğ¸ğ‘˜âˆ’1\{ğ‘’ğ‘˜}.
Query requests involve asking for specific values of the forest
matrix entries ofGğ‘˜, denoted by â„¦ğ‘˜. LetF(G ğ‘˜)denote the set of
all spanning converging forests of graph Gğ‘˜. Utilizing the methods
described earlier, if we have spanning converging forests uniformly
sampled fromF(G ğ‘˜), Algorithm SFQPlus can provide an estima-
tion. However, resampling these forests after every update requires
time complexity of ğ‘‚(ğ‘™ğ‘›)[42], which is inefficient. This naturally
leads to the following question. Suppose that ğ¿ğ‘˜âˆ’1is a spanning con-
verging forest list with ğ‘™ğ‘˜âˆ’1spanning converging forests uniformly
sampled from the set F(G ğ‘˜âˆ’1). When an update ğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜)oc-
curs, can we develop an efficient method to adapt the list ğ¿ğ‘˜âˆ’1into
ğ¿ğ‘˜, ensuring that each spanning converging forest in set F(G ğ‘˜)
has an equal probability appearing in the updated forest list ğ¿ğ‘˜?
In the following, we address this challenge by proposing a method
with an expected cost of ğ‘‚(1)for updating the forest list, while
preserving the uniform property of the sampling.
5.2 Edge Insertion
In this subsection, we delve into the edge insertion update. Consider
theğ‘˜-th update involving the insertion of an edge ğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜)
to the graphGğ‘˜âˆ’1. We start with a spanning converging forest
listğ¿ğ‘˜âˆ’1={ğœ™1,Â·Â·Â·,ğœ™ğ‘™ğ‘˜âˆ’1}withğ‘™ğ‘˜âˆ’1spanning converging forests.
Each forest from the set F(G ğ‘˜âˆ’1)is equally likely to be included in
listğ¿ğ‘˜âˆ’1. Our goal is to modify ğ¿ğ‘˜âˆ’1intoğ¿ğ‘˜such that the forests
inğ¿ğ‘˜are uniformly sampled from the updated set F(G ğ‘˜).
Given thatğ¸ğ‘˜=ğ¸ğ‘˜âˆ’1âˆª{ğ‘’ğ‘˜}, it follows thatF(G ğ‘˜âˆ’1)is a subset
ofF(G ğ‘˜), indicating that all forests in F(G ğ‘˜âˆ’1)are also contained
inF(G ğ‘˜). We now focus on those spanning converging forests that
are inF(G ğ‘˜)but not inF(G ğ‘˜âˆ’1). Define Î”Fğ‘˜asF(G ğ‘˜)\F(G ğ‘˜âˆ’1).
Itâ€™s clear that Î”Fğ‘˜is non-empty, and all its forests include the newly
added edgeğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜). We define a subset F(Gâ€²
ğ‘˜âˆ’1)âŠ‚F(G ğ‘˜âˆ’1),
whereF(Gâ€²
ğ‘˜âˆ’1)={ğœ™:ğœ™âˆˆF(G ğ‘˜âˆ’1),ğ‘Ÿğœ™(ğ‘¢ğ‘˜)=ğ‘¢ğ‘˜,ğ‘Ÿğœ™(ğ‘£ğ‘˜)â‰ ğ‘¢ğ‘˜}.
Lemma 5.1 establishes a bijection between F(Gâ€²
ğ‘˜âˆ’1)andÎ”Fğ‘˜.
Lemma 5.1. For any spanning converging forest ğœ™âˆˆÎ”Fğ‘˜, the
forestğœ™â€²=ğœ™\{ğ‘’ğ‘˜}belongs toF(Gâ€²
ğ‘˜âˆ’1). This mapping constitutes a
bijection betweenF(Gâ€²
ğ‘˜âˆ’1)andÎ”Fğ‘˜.
Proof. Consider a spanning converging forest ğœ™âˆˆÎ”Fğ‘˜, which
includes the newly added edge ğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜). By removing this
edge, we obtain the forest ğœ™â€²=ğœ™\{ğ‘’ğ‘˜}. Since all edges of ğœ™â€²are
part of the graphGğ‘˜âˆ’1, it is evident that ğœ™â€²belongs toF(G ğ‘˜âˆ’1).
Moreover, given that ğ‘Ÿğœ™â€²(ğ‘¢ğ‘˜)=ğ‘¢ğ‘˜andğ‘Ÿğœ™â€²(ğ‘£ğ‘˜)â‰ ğ‘¢ğ‘˜,ğœ™â€²is also a
part ofF(Gâ€²
ğ‘˜âˆ’1).
Moreover, for any two distinct spanning converging forests
ğœ™1,ğœ™2âˆˆÎ”Fğ‘˜, their corresponding forests ğœ™â€²
1andğœ™â€²
2obtained by
deleting edge ğ‘’ğ‘˜are also distinct. Additionally, for any spanning
forestğœ™â€²âˆˆF(Gâ€²
ğ‘˜âˆ’1), we consider the forest ğœ™=ğœ™â€²âˆª{ğ‘’ğ‘˜}. The
conditionsğ‘Ÿğœ™â€²(ğ‘¢ğ‘˜)=ğ‘¢ğ‘˜andğ‘Ÿğœ™â€²(ğ‘£ğ‘˜)â‰ ğ‘¢ğ‘˜guarantee that ğœ™is
well-defined and belongs to ğ¿ğ‘˜, which finishes the proof. â–¡
With Lemma 5.1, we propose the edge insertion update Algo-
rithm 3 to update the forest list ğ¿ğ‘˜âˆ’1toğ¿ğ‘˜.Algorithm 3: Insert-Update(Gğ‘˜âˆ’1,ğ¿ğ‘˜âˆ’1,ğ‘™ğ‘˜âˆ’1,ğ‘’ğ‘˜)
Input : A digraphGğ‘˜âˆ’1=(ğ‘‰ğ‘˜âˆ’1,ğ¸ğ‘˜âˆ’1), a list ofğ‘™ğ‘˜âˆ’1
spanning converging forest ğ¿ğ‘˜âˆ’1uniformly
sampled fromF(G ğ‘˜âˆ’1), an edgeğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜)to
be inserted
Output : An updated spanning converging forest list ğ¿ğ‘˜
1Initialize :ğ¿ğ‘˜â†ğ¿ğ‘˜âˆ’1
2forğœ™inğ¿ğ‘˜âˆ’1do
3 ifğ‘Ÿğœ™(ğ‘¢ğ‘˜)=ğ‘¢ğ‘˜&ğ‘Ÿğœ™(ğ‘£ğ‘˜)â‰ ğ‘¢ğ‘˜then
4 bğœ™â†ğœ™âˆª{ğ‘’ğ‘˜}
5 Addbğœ™toğ¿ğ‘˜
6returnğ¿ğ‘˜
Theorem 5.2. For a spanning converging forest list ğ¿ğ‘˜âˆ’1with
ğ‘™ğ‘˜âˆ’1forests uniformly sampled from F(G ğ‘˜âˆ’1), and the insertion
edgeğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜), all forests in the updated set F(G ğ‘˜)have the
same probability to be included in the list returned by Algorithm 3.
Proof. We partitionF(G ğ‘˜)into two disjoint subsets: F(G ğ‘˜âˆ’1)
andÎ”Fğ‘˜, with Î”Fğ‘˜=F(G ğ‘˜)\F(G ğ‘˜âˆ’1). In order to prove the
theorem, we distinguish four cases: (i) ğœ™1âˆˆF(G ğ‘˜âˆ’1)andğœ™2âˆˆ
F(G ğ‘˜âˆ’1), (ii)ğœ™1âˆˆÎ”Fğ‘˜andğœ™2âˆˆÎ”Fğ‘˜, (iii)ğœ™1âˆˆÎ”F(G ğ‘˜âˆ’1)and
ğœ™2âˆˆÎ”Fğ‘˜, and (iv)ğœ™1âˆˆÎ”Fğ‘˜andğœ™2âˆˆÎ”F(G ğ‘˜âˆ’1). Moreover, for
the convenience of description, let P(ğœ™1âˆˆğ¿ğ‘˜)denote the proba-
bility that forest ğœ™1is inğ¿ğ‘˜. In a similar way, we can define other
probabilities. Note that all forests in ğ¿ğ‘˜âˆ’1are uniformly sampled
fromF(G ğ‘˜âˆ’1). Then, the theorem can be proved as follows.
For the first case that ğœ™1âˆˆF(G ğ‘˜âˆ’1)andğœ™2âˆˆF(G ğ‘˜âˆ’1), we
haveP(ğœ™1âˆˆğ¿ğ‘˜)=P(ğœ™1âˆˆğ¿ğ‘˜âˆ’1)=P(ğœ™2âˆˆğ¿ğ‘˜âˆ’1)=P(ğœ™2âˆˆğ¿ğ‘˜).
For the second case that ğœ™1âˆˆÎ”Fğ‘˜andğœ™2âˆˆÎ”Fğ‘˜, defineğœ™â€²
1=
ğœ™1\{ğ‘’ğ‘˜}andğœ™â€²
2=ğœ™2\{ğ‘’ğ‘˜}. Then we have that P(ğœ™1âˆˆğ¿ğ‘˜)=
P(ğœ™â€²
1âˆˆğ¿ğ‘˜âˆ’1)=P(ğœ™â€²
2âˆˆğ¿ğ‘˜âˆ’1)=P(ğœ™2âˆˆğ¿ğ‘˜).
For the third case that ğœ™1âˆˆÎ”F(G ğ‘˜âˆ’1)andğœ™2âˆˆÎ”Fğ‘˜, define
ğœ™â€²
2=ğœ™2\{ğ‘’ğ‘˜}. Then we have P(ğœ™1âˆˆğ¿ğ‘˜)=P(ğœ™1âˆˆğ¿ğ‘˜âˆ’1)=P(ğœ™â€²
2âˆˆ
ğ¿ğ‘˜âˆ’1)=P(ğœ™2âˆˆğ¿ğ‘˜).
For the fourth case that ğœ™1âˆˆÎ”Fğ‘˜andğœ™2âˆˆÎ”F(G ğ‘˜âˆ’1), using
the same approach as the third case, we obtain P(ğœ™1âˆˆğ¿ğ‘˜)=P(ğœ™2âˆˆ
ğ¿ğ‘˜).
Thus, for two distinct forests ğœ™1,ğœ™2âˆˆF(G ğ‘˜), they have equal
probability to appear in ğ¿ğ‘˜. which finishes the proof. â–¡
Theorem 5.2 demonstrates that the list ğ¿ğ‘˜, generated by Algo-
rithm 3, achieves uniform sampling from the updated set F(G ğ‘˜).
Additionally, the time complexity of Algorithm 3 is ğ‘‚(ğ‘™ğ‘˜âˆ’1), where
ğ‘™ğ‘˜âˆ’1is the number of forests in the initial list ğ¿ğ‘˜âˆ’1.
Example 5.3. Consider a simple graph G0in Figure 1, which has
3nodes and 3edges. GraphG0comprises 7 spanning converging
forests, highlighted in the first row of Figure 1. After the inser-
tion of edge ğ‘’=(1,3), the graph updates to G1, which contains 9
spanning converging forests forming F(G 1), as demonstrated in
the second row of Figure 1. Suppose that we have a forest list ğ¿0
uniformly sampled from F(G 0). A straightforward interpretation
of Algorithm 3 for updating the list ğ¿0toğ¿1involves two steps: first
creating a copy of ğ¿0, and then attempting to add the new edge into
each forest in the list ğ¿0. For the 7 forests in ğ¿0, only two forests ğœ™1
 
2760Fast Computation for the Forest Matrix of an Evolving Graph KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
andğœ™2, distinguished by a yellow background, evolve into the valid
forests bğœ™1andbğœ™2with the incorporation of the edge ğ‘’=(1,3). The
addition of edge ğ‘’to other forests either generates a cycle or results
in a node with an out-degree of 2, both of which contradict the
definition of spanning converging forests. Lemma 5.1 theoretically
validates that there is a bijection between the sets {ğœ™1,ğœ™2}and
{bğœ™1,bğœ™2}, which validates that each forest in F(G 1)has the same
probability to appear in ğ¿1.
1 23
1 23G0
G1Ï†1 Ï†2
/hatwideÏ†1/hatwideÏ†2
1
Figure 1: A toy digraph G0and updated graph G1with their
spanning converging forests. Blue nodes are roots.
5.3 Edge Deletion
In this subsection, we consider the edge deletion update. Specifi-
cally, we consider the deletion of an edge ğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜)from the
graphGğ‘˜âˆ’1, resulting in the updated graph Gğ‘˜=Gğ‘˜âˆ’1\{ğ‘’ğ‘˜}. Our
objective is to adapt the initial forest list ğ¿ğ‘˜âˆ’1intoğ¿ğ‘˜, ensuring the
uniformity property of the sampling is preserved.
Given that the updated edge set ğ¸ğ‘˜is defined as ğ¸ğ‘˜=ğ¸ğ‘˜âˆ’1\{ğ‘’ğ‘˜},
it is evident thatF(G ğ‘˜)is a subset ofF(G ğ‘˜âˆ’1). A straightforward
approach comes to our mind: for the forests in ğ¿ğ‘˜âˆ’1, we can define
the updated list ğ¿ğ‘˜={ğœ™:ğœ™âˆˆğ¿ğ‘˜âˆ’1,ğ‘’ğ‘˜âˆ‰ğœ™}. That is,ğ¿ğ‘˜is the
subset ofğ¿ğ‘˜âˆ’1excluding any forests that contain the edge ğ‘’ğ‘˜. This
method ensures that all forests in F(G ğ‘˜)are equally likely to be
included in ğ¿ğ‘˜, under the assumption that all forests in ğ¿ğ‘˜âˆ’1are
uniformly sampled from F(G ğ‘˜âˆ’1).
However, this method poses a challenge. The number of forests
ğ‘™ğ‘˜in the updated list ğ¿ğ‘˜will always be less than or equal to ğ‘™ğ‘˜âˆ’1.
Consequently, if all updates are edge deletions, the size of our
sampling forest lists will continually diminish. This reduction in
sampling size could result in decreased accuracy when responding
to query requests. Therefore, the challenge arises: can we devise an
alternative method that maintains the uniformity property without
leading to a reduction in the number of sampling forests?
To address the challenge, we define Î”F(G ğ‘˜)=F(G ğ‘˜âˆ’1)\
F(G ğ‘˜). The solution lies in not merely discarding the forests in
Î”F(G ğ‘˜)but effectively utilizing them. Define F(Gâ€²
ğ‘˜)={ğœ™:ğœ™âˆˆ
F(G ğ‘˜),ğ‘Ÿğœ™(ğ‘¢ğ‘˜)=ğ‘¢ğ‘˜,ğ‘Ÿğœ™(ğ‘£ğ‘˜)â‰ ğ‘¢ğ‘˜}. Considering that edge inser-
tion and deletion are inverse operations, Lemma 5.1 establishes a
bijection between Î”F(G ğ‘˜)andF(Gâ€²
ğ‘˜). Specifically, for a forest ğœ™
inÎ”F(G ğ‘˜), the forestğœ™\{ğ‘’ğ‘˜}is included inF(Gâ€²
ğ‘˜). This insight
provides a method to utilize forests in Î”F(G ğ‘˜)without discard-
ing them. We then introduce an edge deletion update method, the
pseudocode of which is described in Algorithm 4.
Theorem 5.4. For a spanning converging forest list ğ¿ğ‘˜âˆ’1with
ğ‘™ğ‘˜âˆ’1forests uniformly sampled from F(G ğ‘˜âˆ’1), and the deletion edge
ğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜), all forests in the updated set F(G ğ‘˜)have the same
probability to be included in the list returned by Algorithm 4.Algorithm 4: Delete-Update(Gğ‘˜âˆ’1,ğ¿ğ‘˜âˆ’1,ğ‘™ğ‘˜âˆ’1,ğ‘’ğ‘˜)
Input : A digraphGğ‘˜âˆ’1=(ğ‘‰ğ‘˜âˆ’1,ğ¸ğ‘˜âˆ’1), a list ofğ‘™ğ‘˜âˆ’1
spanning converging forest ğ¿ğ‘˜âˆ’1uniformly
sampled fromF(G ğ‘˜âˆ’1), an edgeğ‘’ğ‘˜=(ğ‘¢ğ‘˜,ğ‘£ğ‘˜)to
be deleted
Output : An updated spanning converging forest list ğ¿ğ‘˜
1Initialize :ğ¿ğ‘˜â†âˆ…
2forğœ™inğ¿ğ‘˜âˆ’1do
3 ifğ‘’ğ‘˜âˆˆğœ™then
4ğœ™â†ğœ™\{ğ‘’ğ‘˜}
5 Addğœ™toğ¿ğ‘˜
6 else ifğ‘Ÿğœ™(ğ‘¢ğ‘˜)=ğ‘¢ğ‘˜&ğ‘Ÿğœ™(ğ‘£ğ‘˜)â‰ ğ‘¢ğ‘˜then
7 Addğœ™toğ¿ğ‘˜
8 else
9 Addğœ™toğ¿ğ‘˜twice
10returnğ¿ğ‘˜
The proof of Theorem 5.4 is similar to that of Theorem 5.2. The-
orem 5.4 demonstrates that the list ğ¿ğ‘˜, generated by Algorithm 4,
ensures uniform sampling from the updated set F(G ğ‘˜).
Example 5.5. For a better understanding of Algorithm 4, we
present an example depicted in Figure 2. In this example, we re-
move the edge ğ‘’=(3,1)from graphG0, resulting in graph G1. Set
F(G 0)contains 7 spanning converging forests, shown in the first
row of Figure 2, while the set F(G 1)comprises 4 spanning con-
verging forests, illustrated in the second row of Figure 2. Assuming
a forest list ğ¿0is uniformly sampled from F(G 0), a straightfor-
ward approach might suggest discarding the forests ğœ™5,ğœ™6,ğœ™7inğ¿0
to formğ¿1. However, this strategy will unfortunately reduce the
sampling size, as mentioned earlier.
Algorithm 4 addresses this challenge by utilizing the forests
ğœ™5,ğœ™6,ğœ™7. Lemma 5.1 suggests a bijection between {bğœ™1,bğœ™2,bğœ™3}and
{ğœ™5,ğœ™6,ğœ™7}. According to Algorithm 4, for a forest in ğ¿0, if it belongs
to the set{ğœ™1,ğœ™2,ğœ™3}, it is directly added to ğ¿1. If a forest is part
of the set{ğœ™4,ğœ™5,ğœ™6}, we first remove the edge ğ‘’=(3,1)and then
include the modified forest in ğ¿1. This procedure ensures that bğœ™1is
derived from ğœ™1andğœ™5,bğœ™2fromğœ™2andğœ™6, andbğœ™3fromğœ™3andğœ™7.
To maintain balanced probabilities, Algorithm 4 adds ğœ™4toğ¿1twice,
which is highlighted with a yellow background, thereby ensuring
uniformity in the sampling process from the updated forest set.
1 23
1 23G0
G1Ï†1 Ï†2 Ï†3 Ï†4 Ï†5 Ï†6 Ï†7 Ï†3
/hatwideÏ†1/hatwideÏ†2/hatwideÏ†3/hatwideÏ†4
1
Figure 2: A toy digraph G0and updated graph G1with their
spanning converging forests.
 
2761KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
5.4 Prune Technique and Algorithm Details
In this subsection, we introduce the prune technique as well as
some details of our algorithms.
Prune Technique. The time complexity of Algorithm 3 and
Algorithm 4 is ğ‘‚(ğ‘™ğ‘˜âˆ’1), whereğ‘™ğ‘˜âˆ’1is the number of spanning
converging forests in the input list ğ¿ğ‘˜âˆ’1. As illustrated previously,
the number ğ‘™ğ‘˜of spanning converging forests in the updated list
ğ¿ğ‘˜either equals or exceeds ğ‘™ğ‘˜âˆ’1, irrespective of the update being
an edge insertion or deletion. Given ğ‘˜updates, with the number of
spanning converging forests incrementally rising as ğ‘™0â‰¤ğ‘™1â‰¤...â‰¤
ğ‘™ğ‘˜, it becomes essential to mitigate the potential for exponential
growth. To this end, we introduce the pruning technique, which
involves setting a threshold ğ‘™â€², for instance, ğ‘™â€²=5ğ‘™0. Ifğ‘™ğ‘˜surpasses
ğ‘™â€², a pruning action is undertaken to uniformly select ğ‘™â€²forests from
ğ¿ğ‘˜, thereby constituting ğ¿â€²
ğ‘˜. This pruning strategy aims to ensure
that the time taken for updates and queries remains manageable,
avoiding significant increases as the number of updates grows.
Algorithm Details. For every spanning converging forest, our
algorithms retain information on the next node for each node in
the forest and its root node. This setup results in a space complexity
ofğ‘‚(ğ‘™ğ‘›), withğ‘™representing the required number of spanning
converging forests. Upon an update, when either Algorithm 3 or
Algorithm 4 is activated, we avoid directly replicating forests to
avoid theğ‘‚(ğ‘›)cost in copying a single forest. Instead, we only
record the updated edge (in the case of insertion) or the adjusted
weight (in the case of deletion). This method, combined with the
pruning approach, guarantees that our algorithms achieve an ğ‘‚(1)
complexity for both query and update operations, enhancing its
efficiency and scalability for large-scale network analyses.
6 EXPERIMENTS
In this section, we conduct extensive experiments on various real-
life networks in order to evaluate the performance of our algorithms,
in terms of accuracy and efficiency.
6.1 Setup
Datasets and Equipment. The datasets of selected real networks
are publicly available in the KONECT [ 30] and SNAP [ 33]. Our
experiments are conducted on a diverse range of undirected and
directed networks. The details of these datasets are presented in
Table 1. All experiments are conducted using the Julia program-
ming language. We conduct all experiments in a computational
environment featuring a 2.5 GHz Intel E5-2682v4 CPU with 512GB
of primary memory.
Table 1: Datasets used in experiments.
Network Type Nodes Edges
Web-Stanford directed 281,903 2,312,497
Delicious undirected 536,108 1,375,961
Web-Google directed 875,713 5,105,039
Youtube undirected 1,134,890 2,987,624
Livejournal undirected 10,690,276 112,307,385
Twitter directed 41,652,230 1,468,365,182Algorithms and Parameters. In the evaluation of forest matrix
entry queries, we compare our two algorithms SFQ andSFQPlus
with the fast linear equation solvers, since direct matrix inversion
is computationally infeasible. For undirected graphs, we consider
the fast Laplacian solver [ 16], which is widely used in computation
and optimization problems [ 7,46,51]. For directed graphs, the fast
Laplacian solver no longer applies. Thus, we choose the GMRES
algorithm [ 41] to get the ground truth with a tolerance set to 10âˆ’9.
According to Theorem 4.5, we set ğ›¿=0.01,ğœ–=0.03, and the num-
ber of spanning converging forest ğ‘™is given byğ‘™=l
(2
3ğœ–+1
4ğœ–2)log(2
ğ›¿)m
.
We set the prune threshold to be ğ‘™â€²=5ğ‘™. Given that Wilsonâ€™s algo-
rithm can be parallelized efficiently, we use 32 computing cores to
speed up the process.
6.2 Accuracy
In this subsection, we evaluate the accuracy of our algorithms SFQ
andSFQPlus with the ground truth. For both SFQ andSFQPlus,
we consider an undirected graph as a special directed graph, given
that an edge between two nodes in an undirected graph can be con-
sidered as two directed edges between the two nodes in a directed
graph setting.
Our initial evaluation focuses on the performance of our algo-
rithms in estimating the diagonal of the forest matrix, which has
broad applications. In our experiments, for a graph G=(ğ‘‰,ğ¸),
we randomly select a node ğ‘–âˆˆğ‘‰. We then obtain the ground
truth by employing the fast Laplacian solver for undirected graphs
and GMRES for directed graphs to solve the linear equation ğœ”ğ‘–ğ‘–=
eâŠ¤
ğ‘–(I+L)âˆ’1eğ‘–. Here we choose four graphs: web-Web-Stanford
(a), Delicious (b), web-Google (c), Youtube (d), since the solver was
unable to process the two large graphs, Livejournal and Twitter, con-
strained by time and memory. Then we apply algorithms SFQ and
SFQPlus to get the estimation values bğœ”ğ‘–ğ‘–andğœ”ğ‘–ğ‘–, respectively. This
procedure is repeated 100 times to calculate the average relative er-
rors. In addition to the static graphs, we explore the scenarios where
the graph evolves with 50 edges inserted and 50 edges deleted. We
repeat the node selection procedure for these updated graphs and
calculate the average relative errors. The results for these settings
are reported in Figure 3.
(a) (b) (c) (d)Average Relative Errors0.000.050.100.15SFQ-D SFQ-S SFQPlus-D  SFQPlus-S 
Figure 3: Comparison of average relative errors of the diago-
nals for algorithms SFQ andSFQPlus on four graphs: web-
Web-Stanford (a), Delicious (b), web-Google (c), Youtube(d),
where suffix -S indicates the results on static graphs and -D
denotes results on the updated graphs.
 
2762Fast Computation for the Forest Matrix of an Evolving Graph KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Figure 3 illustrates that, compared to static graphs, the accuracy
of both algorithms experiences varying degrees of decline on up-
dated graphs, confirming our earlier analysis. Specifically, SFQâ€™s
accuracy significantly decreases, rendering its results less reliable,
while SFQPlus consistently delivers satisfactory outcomes. This
highlights the effectiveness of our variance reduction technique in
enhancing accuracy.
We then conduct experiments to estimate the forest distance ğœŒğ‘– ğ‘—
between two distinct nodes ğ‘–andğ‘—. The forest distance ğœŒğ‘– ğ‘—is defined
asğœŒğ‘– ğ‘—=ğœ”ğ‘–ğ‘–+ğœ”ğ‘— ğ‘—âˆ’ğœ”ğ‘– ğ‘—âˆ’ğœ”ğ‘—ğ‘–, which was applied in [ 26] to measure
the proximity between nodes ğ‘–andğ‘—. It has been shown that the
forest distance based node centrality measure is more discriminat-
ing than other frequently used metrics for node importance [ 7].
We obtain the ground truth of ğœŒğ‘– ğ‘—by solving the linear equations
ğœŒğ‘– ğ‘—=(eâŠ¤
ğ‘–âˆ’eâŠ¤
ğ‘—)(I+L)âˆ’1eğ‘–+(eâŠ¤
ğ‘—âˆ’eâŠ¤
ğ‘–)(I+L)âˆ’1eğ‘—. We then derive
the estimations of ğœŒğ‘– ğ‘—by executing algorithms SFQ andSFQPlus
four times each. We randomly select 400 pairs of distinct nodes and
calculate their forest closeness centrality. The settings for these
experiments are consistent with those previously mentioned. The
results are displayed in Figure 4. From these results, it is evident
that the SFQPlus algorithm achieves better accuracy than SFQ in
both static and updated graphs.
(a) (b) (c) (d)Average Relative Errors0.000.050.100.15SFQ-D SFQ-S SFQPlus-D  SFQPlus-S
Figure 4: Comparison of average relative errors of the for-
est closeness centrality measures for algorithms SFQ and
SFQPlus on four graphs: web-Web-Stanford (a), Delicious (b),
web-Google (c), Livejournal(d), where suffix -S indicates the
results on static graphs and -D denotes results on the updated
graphs.
6.3 Efficiency and Scalability
As illustrated above, the SFQPlus algorithm achieves satisfactory
accuracy in comparison to the ground truth. In this subsection, we
show the efficiency and scalability of our query algorithms and
update strategies on various networks. The results, summarized
in Table 2, provide a clear indication of these findings. For each
network, the SFQ andSFQPlus algorithms are initially executed
100 times, yielding an average time denoted as SFQ-S andSFQPlus-
S, respectively, in the table. Subsequently, the graph undergoes
100 updates, comprising 50 random edge insertions and 50 random
edge deletions. The update time is calculated as the average of 100
executions, 50 executions of the Insert-Update algorithm and 50
executions of the Delete-Update algorithm. After the updates,
theSFQ andSFQPlus algorithms are run another 100 times on the
updated graph, with the average runtime recorded as SFQ-D andSFQPlus-D. To obtain the ground truth, a fast Laplacian solver for
undirected graphs and GMRES for directed graphs are used, with
the execution time noted in the Solver column of the table.
From these results, it is observable that under identical condi-
tions, the SFQPlus algorithm typically requires a slightly longer
time than SFQ. Moreover, the execution time for both algorithms
marginally increases after the updates. Importantly, the time for
queries and updates shows insensitivity to the size of the network.
This supports the prior analysis that the query and update times
areğ‘‚(1), significantly less than the time required by the linear
solver to determine the ground truth. Remarkably, for two mas-
sive networks, Livejournal and Twitter, both of which contain over
10 million nodes, the solver fails to run due to time and memory
constraints, whereas our algorithms still perform effectively. Our
algorithms consistently return results for a single query operation
within one second, demonstrating their efficiency and scalability
for large-scale network analysis.
Table 2: The running time(seconds) of the linear solver and
SFQ andSFQPlus algorithms, as well as the update time,
where suffix -S indicates the results on static graphs and -D
denotes results on the updated graphs.
NetworkRunning Time(seconds)
SFQ-S SFQ-D SFQPlus-S SFQPlus-D Update Solver
Stanford 0.0008 0.027 0.0013 0.028 0.097 22.17
Delicious 0.0008 0.097 0.0012 0.098 0.429 50.06
Google 0.0007 0.153 0.0013 0.157 0.485 81.61
Youtube 0.0009 0.252 0.0014 0.256 0.885 255.64
Livejournal 0.0009 0.314 0.0014 0.362 1.121 -
Twitter 0.0011 0.421 0.0021 0.489 1.893 -
7 CONCLUSIONS
In this paper, we addressed the problem of efficiently querying
the entries of the forest matrix of a dynamically evolving graph.
Leveraging an extension of Wilsonâ€™s algorithm, we presented an
algorithm SFQ as our foundational approach. We further enhanced
this foundation and developed SFQPlus, an advanced algorithm
that incorporates an innovative variance reduction technique to
improve the accuracy of estimations for the entries of forest matrix.
Additionally, we proposed innovative forest updating techniques
to manage evolving graphs, including edge additions and deletions.
Our methods maintains ğ‘‚(1)time complexity for both updates
and queries, while ensuring unbiased estimates of the entries of
the forest matrix entries. Extensive experimentation on various
real-world networks validates the effectiveness and efficiency of
our algorithms. Moreover, our algorithms are scalable to massive
graphs with over forty million nodes.
In future work, we plan to extend our algorithms to other prob-
lems on evolving graphs, such as dynamically solving linear sys-
tems associated with the forest matrix, thereby broadening their
applicability in network analysis.
ACKNOWLEDGEMENTS
This work was supported by the National Natural Science Founda-
tion of China (Nos. 62372112, U20B2051, and 61872093).
 
2763KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
REFERENCES
[1]Ittai Abraham, David Durfee, Ioannis Koutis, Sebastian Krinninger, and Richard
Peng. 2016. On fully dynamic graph sparsifiers. In 2016 IEEE 57th Annual Sympo-
sium on Foundations of Computer Science. IEEE, 335â€“344.
[2]Dimitris Achlioptas. 2003. Database-friendly random projections: Johnson-
Lindenstrauss with binary coins. J. Comput. System Sci. 66, 4 (2003), 671â€“687.
[3]Rafig Pashaevich Agaev and P Yu Chebotarev. 2001. Spanning forests of a digraph
and their applications. Automation and Remote Control 62, 3 (2001), 443â€“466.
[4]Luca Avena, Fabienne Castell, Alexandre GaudilliÃ¨re, and Clothilde MÃ©lot. 2018.
Random forests and networks analysis. Journal of Statistical Physics 173 (2018),
985â€“1027.
[5]Luca Avena and Alexandre GaudilliÃ¨re. 2018. Two applications of random span-
ning forests. Journal of Theoretical Probability 31, 4 (2018), 1975â€“2004.
[6]Coralio Ballester, Antoni CalvÃ³-Armengol, and Yves Zenou. 2006. Whoâ€™s who in
networks. Wanted: The key player. Econometrica 74, 5 (2006), 1403â€“1417.
[7]Qi Bao and Zhongzhi Zhang. 2022. Discriminating Power of centrality measures
in complex networks. IEEE Transactions on Cybernetics 52, 11 (2022), 12583â€“
12593.
[8]Simon BarthelmÃ©, Nicolas Tremblay, Alexandre Gaudilliere, Luca Avena, and
Pierre-Olivier Amblard. 2019. Estimating the inverse trace using random forests
on graphs. arXiv preprint arXiv:1905.02086 (2019).
[9]Surender Baswana, Sumeet Khurana, and Soumojit Sarkar. 2012. Fully dynamic
randomized algorithms for graph spanners. ACM Transactions on Algorithms 8, 4
(2012), 1â€“51.
[10] Seth Chaiken. 1982. A combinatorial proof of the all minors matrix tree theorem.
SIAM J. Alg. Disc. Meth. 3, 3 (Sep. 1982), 319â€“329.
[11] Pavel Chebotarev and Rafig Agaev. 2002. Forest matrices around the Laplacian
matrix. Linear Algebra Appl. 356, 1-3 (2002), 253â€“274.
[12] Pavel Yu. Chebotarev and Elena Shamis. 2006. Matrix-Forest Theorems. ArXiv
abs/math/0602575 (2006).
[13] P. Yu Chebotarev and E. V. Shamis. 1997. The matrix-forest theorem and measur-
ing relations in small social groups. Automation and Remote Control 58, 9 (1997),
1505â€“1514.
[14] P. Yu Chebotarev and E. V. Shamis. 1998. On proximity measures for graph
vertices. Automation and Remote Control 59, 10 (1998), 1443â€“1459.
[15] Fan Chung and Linyuan Lu. 2006. Concentration inequalities and martingale
inequalities: a survey. Internet mathematics 3, 1 (2006), 79â€“127.
[16] Michael B Cohen, Rasmus Kyng, Gary L Miller, Jakub W Pachocki, Richard Peng,
Anup B Rao, and Shen Chen Xu. 2014. Solving SDD linear systems in nearly
ğ‘šlog1/2ğ‘›time. In Proceedings of the Forty-Sixth Annual ACM Symposium on
Theory of Computing. ACM, 343â€“352.
[17] Jaydeep De, Xiaowei Zhang, Feng Lin, and Li Cheng. 2017. Transduction on di-
rected graphs via absorbing random walks. IEEE Transactions on Pattern Analysis
and Machine Intelligence 40, 7 (2017), 1770â€“1784.
[18] David Durfee, Yu Gao, Gramoz Goranci, and Richard Peng. 2019. Fully dynamic
spectral vertex sparsifiers and applications. In Proceedings of the 51st Annual ACM
SIGACT Symposium on Theory of Computing. 914â€“925.
[19] Sebastian Forster and Gramoz Goranci. 2019. Dynamic low-stretch trees via
dynamic low-diameter decompositions. In Proceedings of the 51st Annual ACM
SIGACT Symposium on Theory of Computing. 377â€“388.
[20] Andrea Galeotti, Benjamin Golub, and Sanjeev Goyal. 2020. Targeting interven-
tions in networks. Econometrica 88, 6 (2020), 2445â€“2471.
[21] Aristides Gionis, Evimaria Terzi, and Panayiotis Tsaparas. 2013. Opinion maxi-
mization in social networks. In Proceedings of the 2013 SIAM International Confer-
ence on Data Mining. SIAM, 387â€“395.
[22] Gramoz Goranci, Monika Henzinger, and Mikkel Thorup. 2018. Incremental
exact min-cut in polylogarithmic amortized update time. ACM Transactions on
Algorithms 14, 2 (2018), 1â€“21.
[23] Jacob Holm, Kristian De Lichtenberg, and Mikkel Thorup. 2001. Poly-logarithmic
deterministic fully-dynamic algorithms for connectivity, minimum spanning tree,
2-edge, and biconnectivity. J. ACM 48, 4 (2001), 723â€“760.
[24] Jacob Holm, Eva Rotenberg, and Christian Wulff-Nilsen. 2015. Faster fully-
dynamic minimum spanning forest. In Algorithms-ESA 2015: 23rd Annual Euro-
pean Symposium. Springer, 742â€“753.
[25] Glen Jeh and Jennifer Widom. 2003. Scaling personalized web search. In Proceed-
ings of the 12th International Conference on World Wide Web. 271â€“279.
[26] Yujia Jin, Qi Bao, and Zhongzhi Zhang. 2019. Forest distance closeness centrality
in disconnected graphs. In 2018 IEEE International Conference on Data Mining.
IEEE, 339â€“348.
[27] William B Johnson and Joram Lindenstrauss. 1984. Extensions of Lipschitz
mappings into a Hilbert space. Contemp. Math. 26 (1984), 189â€“206.[28] Bruce M Kapron, Valerie King, and Ben Mountjoy. 2013. Dynamic graph con-
nectivity in polylogarithmic worst case time. In Proceedings of the twenty-fourth
annual ACM-SIAM symposium on Discrete algorithms. SIAM, 1131â€“1142.
[29] Alex Kulesza, Ben Taskar, et al .2012. Determinantal point processes for machine
learning. Foundations and TrendsÂ® in Machine Learning 5, 2â€“3 (2012), 123â€“286.
[30] JÃ©rÃ´me Kunegis. 2013. Konect: the koblenz network collection. In Proceedings of
the 22nd International World Wide Web Conference. ACM, 1343â€“1350.
[31] Lawler and F. Gregory. 1980. A self-avoiding random walk. Duke Mathematical
Journal 47, 3 (1980), 655â€“693.
[32] Gregory Francis Lawler. 1979. A self-avoiding random walk. Ph.D. Dissertation.
Princeton University.
[33] Jure Leskovec and Rok SosiÄ. 2016. SNAP: A general-purpose network analysis
and graph-mining library. ACM Transactions on Intelligent Systems and Technology
8, 1 (2016), 1.
[34] Russell Merris. 1994. Laplacian matrices of graphs: A survey. Linear Algebra
Appl. 197 (1994), 143â€“176.
[35] Danupon Nanongkai and Thatchaphol Saranurak. 2017. Dynamic spanning
forest with worst-case update time: adaptive, las vegas, and o (n1/2- ğœ€)-time. In
Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing.
1122â€“1129.
[36] Danupon Nanongkai, Thatchaphol Saranurak, and Christian Wulff-Nilsen. 2017.
Dynamic minimum spanning forest with subpolynomial worst-case update time.
In2017 IEEE 58th Annual Symposium on Foundations of Computer Science . IEEE,
950â€“961.
[37] Yusuf Y Pilavci, Pierre-Olivier Amblard, Simon Barthelme, and Nicolas Tremblay.
2020. Smoothing graph signals via random spanning forests. In Proceedings of
IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE,
5630â€“5634.
[38] Yusuf YiÄŸit PilavcÄ±, Pierre-Olivier Amblard, Simon Barthelme, and Nicolas Trem-
blay. 2021. Graph Tikhonov regularization and interpolation via random spanning
forests. IEEE Transactions on Signal and Information Processing over Networks 7
(2021), 359â€“374.
[39] Yusuf Yigit Pilavci, Pierre-Olivier Amblard, Simon Barthelme, and Nicolas Trem-
blay. 2022. Variance reduction for inverse trace estimation via random spanning
forests. arXiv preprint arXiv:2206.07421 (2022).
[40] Wilbert Samuel Rossi, Paolo Frasca, and Fabio Fagnani. 2017. Distributed estima-
tion from relative and absolute measurements. IEEE Trans. Automat. Control 62,
12 (2017), 6385â€“6391.
[41] Youcef Saad and Martin H Schultz. 1986. GMRES: A generalized minimal residual
algorithm for solving nonsymmetric linear systems. SIAM J. Sci. Statist. Comput.
7, 3 (1986), 856â€“869.
[42] Haoxin Sun and Zhongzhi Zhang. 2023. Opinion optimization in directed social
networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 37.
4623â€“4632.
[43] Haoxin Sun and Zhongzhi Zhang. 2024. Efficient computation for diagonal of
forest matrix via variance-reduced forest sampling. In Proceedings of the ACM
Web Conference 2024. 792â€“802.
[44] Mikkel Thorup. 2007. Fully-dynamic min-cut. Combinatorica 27, 1 (2007), 91â€“127.
[45] Jan van den Brand, Yu Gao, Arun Jambulapati, Yin Tat Lee, Yang P Liu, Richard
Peng, and Aaron Sidford. 2022. Faster maxflow via improved dynamic spectral
vertex sparsifiers. In Proceedings of the 54th Annual ACM SIGACT Symposium on
Theory of Computing. 543â€“556.
[46] Alexander van der Grinten, Eugenio Angriman, Maria Predari, and Henning Mey-
erhenke. 2021. New approximation algorithms for forest closeness centralityâ€“for
individual vertices and vertex groups. In Proceedings of the 2021 SIAM Interna-
tional Conference on Data Mining. SIAM, 136â€“144.
[47] Sibo Wang, Renchi Yang, Xiaokui Xiao, Zhewei Wei, and Yin Yang. 2017. FORA:
simple and effective approximate single-source personalized PageRank. In Pro-
ceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining. 505â€“514.
[48] David Bruce Wilson. 1996. Generating random spanning trees more quickly than
the cover time. In Proceedings of the Twenty-Eighth Annual ACM Symposium on
Theory of Computing. 296â€“303.
[49] Christian Wulff-Nilsen. 2017. Fully-dynamic minimum spanning forest with
improved worst-case update time. In Proceedings of the 49th Annual ACM SIGACT
Symposium on Theory of Computing. 1130â€“1143.
[50] Wanyue Xu, Qi Bao, and Zhongzhi Zhang. 2021. Fast evaluation for relevant
quantities of opinion dynamics. In Proceedings of The Web Conference. ACM,
2037â€“2045.
[51] Liwang Zhu and Zhongzhi Zhang. 2022. A nearly-linear time algorithm for
minimizing risk of conflict in social networks. In Proceedings of the 28th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining. 2648â€“2656.
 
2764