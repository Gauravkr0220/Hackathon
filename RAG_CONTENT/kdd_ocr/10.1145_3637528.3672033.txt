Semi-Supervised Learning for Time Series
Collected at a Low Sampling Rate
Minyoung Bae
KAIST
Daejeon, Republic of Korea
mybae@kaist.ac.krYooju Shin
KAIST
Daejeon, Republic of Korea
yooju.shin@kaist.ac.krYoungeun Nam
KAIST
Daejeon, Republic of Korea
youngeun.nam@kaist.ac.kr
Young Seop Lee
Samsung Electronics Co., Ltd.
Suwon, Republic of Korea
yseop.lee@samsung.comJae-Gil Leeâˆ—
KAIST
Daejeon, Republic of Korea
jaegil@kaist.ac.kr
Abstract
Although time-series classification has many applications in health-
care and manufacturing, the high cost of data collection and la-
beling hinders its widespread use. To reduce data collection and
labeling costs while maintaining high classification accuracy, we
propose a novel problem setting, called semi-supervised learning
with low-sampling-rate time series, in which the majority of time se-
ries are collected at a low sampling rate and are unlabeled whereas
the minority of time series are collected at a high sampling rate
and are labeled. For this novel problem scenario, we develop the
SemiTSR framework equipped with the super-resolution module
and the semi-supervised learning module. Here, low-sampling-rate
time series are upsampled precisely, taking periodicity and trend
at each timestamp into account, and both labeled and unlabeled
high-sampling-rate time series are utilized for training. In particular,
consistency regularization between artificially downsampled time
series derived from an original high-sampling-rate time series is ef-
fective at overcoming limited sampling rates. We demonstrate that
SemiTSR significantly outperforms conventional semi-supervised
learning techniques by assuring high classification accuracy with
low-sampling-rate time series.
CCS Concepts
â€¢Mathematics of computing â†’Time series analysis; â€¢Theory
of computationâ†’Semi-supervised learning .
Keywords
time series, semi-supervised learning, classification, sampling rate
ACM Reference Format:
Minyoung Bae, Yooju Shin, Youngeun Nam, Young Seop Lee, and Jae-Gil Lee.
2024. Semi-Supervised Learning for Time Series Collected at a Low Sam-
pling Rate. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain.
ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3672033
âˆ—Corresponding author.
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672033
0.830.850.870.890.910.93
1 1/2 1/4 1/8 1/16Accuracy
Sampling RateDataset: HAR
TCN
GRU+MLP
0.620.640.660.680.700.72
1 1/2 1/4 1/8 1/16Sampling RateDataset: OPPOR
TCN
GRU+MLP
0.450.510.570.630.690.75
1 1/2 1/4 1/8 1/16Sampling RateDataset: ED
TCN
GRU+MLPFigure 1: Negative impact of reduced sampling rates on clas-
sification accuracy in three datasets [2, 10, 35].
1 Introduction
1.1 Background
The success of time-series classification requires a sufficient amount
of high-resolution data and high-quality labels [ 26]. However, these
requirements are not always easily met. Despite advancements
in sensor technology, the sampling rate for time series may not
be high enough due to limitations in storage space [ 21], transfer
speed [ 1], and battery capacity [ 17], particularly in mobile devices.
Moreover, due to the complicated temporal dynamics and high-
dimensional data structure of time series [ 30,36,59], data labeling
typically requires domain experts at a high cost.
Insufficient resolution of a time series, determined by its sampling
rate, naturally leads to a deterioration in classification accuracy. Fig-
ure 1 demonstrates, using the TCN and GRU+MLP methods [ 3,13]
on the HAR, OPPOR, and ED datasets [ 2,10,35], that the classifica-
tion accuracy decreases rapidly as the sampling rate decreasesâ€”by
at least 20% when it is decreased to1
16. Thus, there is a trade-off be-
tween the cost of data collection and the accuracy of classification,
which cannot be attained concurrently.
The deterioration depicted in Figure 1 is primarily attributed to
(i)periodicity blur and (ii) phase shift. First, in Figure 2, consider
two time series whose frequency has been reduced to1
8of their
original frequency by downsampling. At the original frequency,
these two time series from the â€˜Joggingâ€™ and â€˜Walkingâ€™ classes are
easily distinguishable; however, at the1
8frequency, the unique
periodicity in each class has been obscured by the downsampling.
Second, in Figure 3, consider two time series whose frequency has
been reduced to1
16of their original frequency. Due to the difference
in the phase of each data point in the two time series that have
been downsampled differently, where the phase indicates a position
 
59
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Minyoung Bae, Yooju Shin, Youngeun Nam, Young Seop Lee, and Jae-Gil Lee
Similar1/8Jogging
WalkingDissimilar
1/8
Figure 2: Example of periodicity blur while reducing the sam-
pling rate in the WISDM human activity dataset [57].
UpstairsUpstairs
1/16
1/16Similar DissimilarFigure 3: Example of phase shift while reducing the sampling
rate in the WISDM human activity dataset [57].
within each period, the two time series appear very distinct despite
belonging to the same class â€˜Upstairs.â€™
1.2 Main Contributions
To achieve high classification accuracy while keeping low data
collection cost, in this paper, we formulate a novel problem, called
semi-supervised learning with low-sampling-rate time series. In this
problem setting, a majority of time series are collected at a low
sampling rate and unlabeled, while a minority of time series are
collected at a high sampling rate and labeled. The overall cost of
data collection remains low because the proportion of the high-
sampling-rate time series is small (e.g., 10%), and labeling for this
small portion is considered feasible as confirmed in active learn-
ing [46]. In addition, both high and low sampling rates can coexist
because the sampling rate is adjustable in most data gathering en-
vironments [ 24,29,38]. Overall, the problem setting is practically
feasible and obviously satisfies low data collection cost.
The remaining challenge is to accomplish high classification ac-
curacy with limited availability of labeled high-sampling-rate time
series. To this end, we propose the framework, Semi-supervised
Time-series Super Resolution (SemiTSR ), for addressing the novel
problem. The SemiTSR framework consists of (i) the super-resolution
module that upsamples low-sampling-rate time series into high-
sampling-rate time series and (ii) the semi-supervised learning mod-
ule that trains a classifier using both labeled and unlabeled high-
sampling-rate time series. These two modulesâ€”upsampler and
classifierâ€”are trained in an end-to-end fashion.
The unique contributions for accomplishing high classification
accuracy are two fold, addressing the aforementioned two problems.
Handling of the Periodicity Blur: We integrate the inherent char-
acteristics of time series into the design of the upsampler. Without
loss of generality, we assume that a time series is the sum of trend,
periodicity, and random error [ 42]. When the upsampler estimates
missing values at unsampled timestamps, it takes account of other
sampled values that have a similar phase within a similar periodic-
ity as well as a similar trend, instead of simply using adjacent values.
Accordingly, we propose a context-aware attention technique based
on temporal embedding to focus on the other timestamps with
a similar context (i.e., periodicity and trend). As a result, unsam-
pled values are restored closer to their true values, which aids in
resolving the periodicity blur issue depicted in Figure 2.
Handling of the Phase Shift: We take fulladvantage of a small
amount of labeled high-sampling-rate time series in both the re-
constructor and classifier. Using the high sampling rates, the recon-
structor is trained to recover the original high-sampling-rate timeseries from two phase-shifted, downsampled low-sampling-rate
time series. In addition, the classifier is trained to generate con-
sistent output for the two reconstructed high-sampling-rate time
series by shift consistency regularization, which is very effective to
relieve the phase shift issue depicted in Figure 3. Using the available
labels, the classifier is further trained to predict the correct label
for the two reconstructed high-sampling-rate time series.
In conclusion, to achieve both high classification accuracy and
low data collection cost, we newly introduce semi-supervised learn-
ing with low-sampling-rate time series and develop the SemiTSR
framework for the problem. In particular, SemiTSR effectively ad-
dresses periodicity blur and phase shift caused by limited sampling
rates in time series by employing the context-aware attention tech-
nique and the shift consistency regularization, respectively. Accord-
ing to our extensive experiments, when only 10% of the data is
labeled and the sampling rate is decreased to1
8of the labeled set,
SemiTSR significantly outperforms conventional semi-supervised
learning methods by 2.9â€“29.5%.
Potential Application Scenario: We would like to wrap up this
section with discussing an application scenario to emphasize the
usefulness of the framework. Most clinical electrocardiogram (ECG)
databases encompass time series data with sampling rates of 500â€“
1000Hz, following a practice endorsed by American Heart Associa-
tion [ 9,45]. These databases are meticulously annotated by cardiol-
ogists, incurring significant costs. Conversely, widely-used wireless
ambulatory ECG devices produce unlabeled time series data at
sampling rates below 250Hz [ 22], which are insufficient to detect
long QT syndrome and hypocalcemia [ 5,18], due to their power
constraint. These wireless ECG devices generate large amounts of
data in order to track the patientsâ€™ twenty-four-hour daily activities.
This discrepancy aligns perfectly with our novel problem. SemiTSR
leverages a substantial volume of unlabeled low-sampling-rate data
alongside a smaller volume of labeled high-sampling-rate data. This
approach enhances the contribution of the unlabeled, lower-quality
data to the diagnosis of sudden cardiac events outside of hospi-
tal settings. Please see Section 4.6 for the empirical results of this
application scenario.
2 Related Work
2.1 Semi-Supervised Learning
Semi-supervised learning (SSL) leverages large amounts of unlabeled
data to enhance deep learning when the labeled data is scarce. The
key SSL methods include consistency regularization, which man-
dates consistency in the modelâ€™s predictions across augmented in-
stances. This approach facilitates the modelâ€™s comprehension of the
 
60Semi-Supervised Learning for Time Series Collected at a Low Sampling Rate KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
ğ¹=3ğ‘‡=7ğ‘‡âˆ—ğ‘=7âˆ—4
ğ¹âˆ—ğ‘=3âˆ—4ğ¹=3ConvPixel 
Shuffle
â€¦â€¦ğ‘‡=7
ğ‘=4
Figure 4: Limitation of upsampling convolution [ 47].ğ‘‡,ğ¹,ğ‘
is the number of timestamps at a low sampling rate, the num-
ber of features, and the number of kernels for convolution
which is same as the upscaling factor.
unlabeled data distribution. In FixMatch [ 52], a strongly-augmented
instance is assigned to predict a weakly-augmented instance as a
pseudo-label. FreeMatch [ 56], an extension of FixMatch [ 52], con-
trols the confidence threshold for pseudo-labeling based on the
learning status in order to ensure the consistency with the correct
pseudo-label.
Another pivotal SSL strategy is the entropy minimization which
operates under the premise that the classification decision bound-
ary should evade regions populated densely by data points. The
techniques such as Pseudo-Label [ 32] and MixMatch [ 7] implic-
itly achieve entropy reduction by refining the sharpness of the
modelâ€™s predictions. Furthermore, ReMixMatch [ 8], building upon
MixMatch [ 7], endeavors to synchronize the marginal distribution
of unlabeled data predictions with the ground-truth labels, thus
enhancing model reliability and prediction accuracy.
Recently, a few semi-supervised learning techniques have
been introduced explicitly for time-series data [ 15,19,27,55].
SemiTime [ 19] employs the pretext task, predicting whether two
segments have past and future relationships, to capture the neces-
sary temporal relations for classification. CrossMatch [ 48] proposes
context attachment as the time-series augmentation strategy in
consistency regularization, but does not address periodic features
of time series or the challenges presented by varying sampling
rates. SSGAN [ 40] utilizes labeled data to improve the imputation
of missing values in time series. The classifier is self-trained using
the pseudo-labels inferred from the imputed time series, while the
imputation module is supervised using the reconstruction and ad-
versarial losses. However, the goal of this work is mostly imputation,
and the classifier primarily serves for the purpose of imputation,
which does not suit our problem.
In summary, none of the existing SSL works consider the high
costs of time-series collection and labeling at the same time. Com-
pared with these methods, we reduce data collection and labeling
costs while leveraging high-sampling-rate time-series data to en-
sure classification accuracy.
2.2 Single-Image Super-Resolution
Single-image super-resolution models [ 12,33,34] aim to recon-
struct high-resolution images given low-resolution counterparts.
SwinIR [ 34] uses convolution and attention modules to capture long-
range dependencies within varying contents and simultaneously
remove border artifacts. Several recent methods utilize implicit
neural representation [ 12,33,39,51] to represent a high-resolution
image as a combination of its low-resolution counterpart and a
neural network. For example, LIFF [ 12] employs an MLP to pre-
dict the RGB value of a target coordinate based on the nearest
low-resolution latent code. LTE [ 33] reconstructs high-frequency
Classifier, â„³ğ’„ğ’ğ’”
Reconstructor, â„³ğ’“ğ’†ğ’„ğ’ğ’â„’ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡_ğ‘¢â„’ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›â„’ğ‘ğ‘™ğ‘  â„’ğ‘ğ‘™ğ‘ 
â„’ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡_ğ‘™
ğ‘¥â„ğ‘–ğ‘”â„ğ‘¢ğ‘™ğ‘œğ‘¤
Down -sampling Labeled
Data point Reconstructedâ„’ğ‘ğ‘™ğ‘ 
à·¤ğ‘¢ğ‘™ğ‘œğ‘¤ğ‘¥ğ‘™ğ‘œğ‘¤à·¤ğ‘¥ğ‘™ğ‘œğ‘¤Figure 5: Overview of the training SemiTSR framework
for labeled high-sampling-rate data and unlabeled low-
sampling-rate data. While testing, SemiTSR uses unlabeled
low-sampling-rate data as input.
components by mapping the target coordinate and the nearest
low-resolution latent code to locally dominant frequency terms.
However, none of these existing methods have been applied to
time-series data, where both temporal dependencies and periodic
features should be modeled [ 20,59]. Particularly in the upscaling
stage, methods using implicit neural networks do not consider tem-
poral dependencies as they estimate high-resolution values based
on a single coordinate and its corresponding feature. A convolution-
based upscaling approach [ 47] also neglects the sequential relation
in the high resolution. As depicted in Figure 4, a low-sampling-
rate time series with three features is upsampled by a factor of 4.
The first four high-sampling-rate timestamps are generated using
different convolution kernels (blue, red, yellow, and green). How-
ever, since independent convolution kernels are used to reconstruct
the values of adjacent high-resolution coordinates, the sequential
relation is disconnected during the upsampling process.
3 Methodology
3.1 Problem Definition
We formally define the problem of learning a classification model
that operates on low-sampling-rate instances by leveraging high-
sampling-rate instances for training. Let (ğ’™â„ğ‘–ğ‘”â„âˆˆRğ‘‘Ã—ğ‘‡,ğ‘¦)be a
labeled high-sampling-rate instance and ğ’–ğ‘™ğ‘œğ‘¤âˆˆRğ‘‘Ã—ğ›¾ğ‘‡be an unla-
beled low-sampling-rate instance. ğ‘‘,ğ‘‡, andğ›¾denote the number
of features, the number of timestamps within a time series col-
lected in the original sampling rate, and the low sampling rate,
respectively. The goal of this work is building a classification model
M(ğ’–;Î˜ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›,Î˜ğ‘ğ‘™ğ‘ )that returns the probability of each class given
an unlabeled low-sampling-rate instance ğ’–âˆˆRğ‘‘Ã—ğ›¾ğ‘‡. The model
Mis parameterized by Î˜ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›andÎ˜ğ‘ğ‘™ğ‘ referring to reconstruction
and classification modules.
3.2 The Overall Framework of SemiTSR
Figure 5 illustrates the overall procedure of SemiTSR framework,
which consists of the two neural network modules: reconstructor
 
61KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Minyoung Bae, Yooju Shin, Youngeun Nam, Young Seop Lee, and Jae-Gil Lee
Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘› and classifierMğ‘ğ‘™ğ‘ . To recover class-discriminative peri-
odic features,Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘› increases the resolution of a low-sampling-
rate time series to match the sampling rate of ğ’™â„ğ‘–ğ‘”â„. Subsequently,
the synthesized high-sampling-rate time series is fed into the Mğ‘ğ‘™ğ‘ 
to obtain the probability distribution for each class.
During training, the labeled high-sampling-rate data ğ’™â„ğ‘–ğ‘”â„pro-
vides supervision for both Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘› andMğ‘ğ‘™ğ‘ as shown in the left
flow of Figure 5. First, ğ’™â„ğ‘–ğ‘”â„is downsampled at the rate of ğ›¾to syn-
thesize two low-sampling-rate instances of different phases, ğ’™ğ‘™ğ‘œğ‘¤
andeğ’™ğ‘™ğ‘œğ‘¤. Then, each ğ’™ğ‘™ğ‘œğ‘¤andeğ’™ğ‘™ğ‘œğ‘¤are processed byMğ‘Ÿğ‘’ğ‘ğ‘œğ‘›
andMğ‘ğ‘™ğ‘ sequentially. The supervised loss for the labeled high-
sampling-rate data consists of a classification loss Lğ‘ğ‘™ğ‘ and a re-
construction lossLğ‘Ÿğ‘’ğ‘ğ‘œğ‘› =ğœ†ğ‘¡ğ‘–ğ‘šğ‘’Lğ‘¡ğ‘–ğ‘šğ‘’+ğœ†ğ‘“ğ‘Ÿğ‘’ğ‘Lğ‘“ğ‘Ÿğ‘’ğ‘ which are
formulated by
Lğ‘ğ‘™ğ‘ (ğ’™â„ğ‘–ğ‘”â„,ğ‘¦)=1
2âˆ‘ï¸
ğ’™âˆˆğ‘‹ğ»[ğ‘¦,Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ’™))]
+ğ»[ğ‘¦,Mğ‘ğ‘™ğ‘ (ğ‘¦|ğ’™â„ğ‘–ğ‘”â„)],
Lğ‘¡ğ‘–ğ‘šğ‘’(ğ’™â„ğ‘–ğ‘”â„)=1
2âˆ‘ï¸
ğ’™âˆˆğ‘‹âˆ¥ğ’™â„ğ‘–ğ‘”â„âˆ’Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ’™)âˆ¥2
2
Lğ‘“ğ‘Ÿğ‘’ğ‘(ğ’™â„ğ‘–ğ‘”â„)=1
2âˆ‘ï¸
ğ’™âˆˆğ‘‹âˆ¥F(ğ’™â„ğ‘–ğ‘”â„)âˆ’F(Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ’™))âˆ¥1,(1)
whereğ‘‹is a set of downsampled instances {ğ’™ğ‘™ğ‘œğ‘¤,eğ’™ğ‘™ğ‘œğ‘¤}and
ğ»[ğ‘,ğ‘]is the cross-entropy between two probability distributions
ğ‘andğ‘, whileFdenotes the fast Fourier transform. The classi-
fication lossLğ‘ğ‘™ğ‘ supervisesMğ‘Ÿğ‘’ğ‘ğ‘œğ‘› andMğ‘ğ‘™ğ‘ , using a limited
quantity of labeled data. Recent studies in the filed of time-series
analysis [ 20,59] have emphasized the significance of modeling both
temporal and frequency domains for accurate time-series forecast-
ing and classification tasks. Hence, the reconstruction errors on
both the original time series and Fourier transformed time series,
Lğ‘¡ğ‘–ğ‘šğ‘’ andLğ‘“ğ‘Ÿğ‘’ğ‘, are minimized to improve the classification by
recovering temporal dependency as well as periodic features.
Now, to resolve the phase shift, we use a consistency regulariza-
tion between the instances of different phases. The regularization
enforces similarity between the classification result of ğ’™ğ‘™ğ‘œğ‘¤and
eğ’™ğ‘™ğ‘œğ‘¤, which have different phases derived from a labeled high-
sampling-rate instance ğ’™â„ğ‘–ğ‘”â„, by minimizing the mean squared er-
ror. The consistency regularization term for labeled high-sampling-
rate data, denoted as Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™in the top left of Figure 5, serves
theconsistency purpose. Since ğ’™ğ‘™ğ‘œğ‘¤andeğ’™ğ‘™ğ‘œğ‘¤are supervised using
ground-truth labels via Lğ‘ğ‘™ğ‘ , minimizing the cross-entropy between
the results of the shifted instances can be redundant. Therefore, we
minimize the mean squared error as a loss term to facilitate a more
fine-grained consistency [31].
For consistency regularization of the unlabeled low-sampling-
rate instance ğ’–ğ‘™ğ‘œğ‘¤, a synthesized counterpart eğ’–ğ‘™ğ‘œğ‘¤is generated,
which exhibits a different phase compared to ğ’–ğ‘™ğ‘œğ‘¤. This synthesis is
achieved by downsampling from Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ’–ğ‘™ğ‘œğ‘¤), since the ground-
truth shifted instance is not available. Then, the classification result
ofğ’–ğ‘™ğ‘œğ‘¤serves as a pseudo-label for eğ’–ğ‘™ğ‘œğ‘¤if the prediction for ğ’–ğ‘™ğ‘œğ‘¤
is confident. Self-training limited to confident instances prevents
Mğ‘ğ‘™ğ‘ learning from mis-classified uncertain instances [ 52]. The loss
flow for the unlabeled low-sampling-rate data is shown in the rightAlgorithm 1 SemiTSR
Input: Labeled batchDğ¿, unlabeled batchDğ‘ˆ, confidence thresh-
oldğœ, labeled batch size ğµ, unlabeled batch size ratio ğœ‡, loss
weights(ğœ†ğ‘¡ğ‘–ğ‘šğ‘’,ğœ†ğ‘“ğ‘Ÿğ‘’ğ‘,ğœ†ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡), the number of original times-
tampsğ‘‡, low-sampling-rate ğ›¾
1:Lğ‘ğ‘™ğ‘ ,Lğ‘Ÿğ‘’ğ‘ğ‘œğ‘›,Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™,Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘¢=0,0,0,0
2:/* Labeled data flow */
3:forğ’™â„ğ‘–ğ‘”â„inDğ¿do
4: ğ’™ğ‘™ğ‘œğ‘¤=ğ·ğ‘œğ‘¤ğ‘›ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’(ğ’™â„ğ‘–ğ‘”â„;ğ›¾)
5:eğ’™ğ‘™ğ‘œğ‘¤=ğ·ğ‘œğ‘¤ğ‘›ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’(ğ’™â„ğ‘–ğ‘”â„
ğ‘;ğ›¾)
6:Lğ‘ğ‘™ğ‘ +=1
2(ğ»[ğ‘¦,Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ’™ğ‘™ğ‘œğ‘¤))]
+ğ»[ğ‘¦,Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(eğ’™ğ‘™ğ‘œğ‘¤))])
7:Lğ‘Ÿğ‘’ğ‘ğ‘œğ‘›+=ğœ†ğ‘¡ğ‘–ğ‘šğ‘’Lğ‘¡ğ‘–ğ‘šğ‘’+ğœ†ğ‘“ğ‘Ÿğ‘’ğ‘Lğ‘“ğ‘Ÿğ‘’ğ‘ /* Eq. (1) */
8:Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™+=âˆ¥Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ’™ğ‘™ğ‘œğ‘¤))
âˆ’Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(eğ’™ğ‘™ğ‘œğ‘¤))âˆ¥2
2
9:end for
10:/* Unlabeled data flow */
11:forğ’–ğ‘™ğ‘œğ‘¤inDğ‘ˆdo
12: ğ’–â„ğ‘–ğ‘”â„=Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ’–ğ‘™ğ‘œğ‘¤)
13:eğ’–ğ‘™ğ‘œğ‘¤=ğ›¾Ã1
ğ›¾
1ğ·ğ‘œğ‘¤ğ‘›ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’(ğ’–â„ğ‘–ğ‘”â„;ğ›¾)
14:ğ‘=Mğ‘ğ‘™ğ‘ (ğ‘¦|ğ’–â„ğ‘–ğ‘”â„)
15:Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘¢+=1(ğ‘šğ‘ğ‘¥(ğ‘)â‰¥ğœ)
Â·ğ»[ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥ğ‘¦(ğ‘),Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(eğ’–ğ‘™ğ‘œğ‘¤))]
16:end for
17:returnLğ‘ğ‘™ğ‘ 
ğµ+Lğ‘Ÿğ‘’ğ‘ğ‘œğ‘›
ğµ+ğœ†ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡(Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™
ğµ+Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘¢
ğœ‡ğµ)
flow of Figure 5. Overall, the consistency loss is formulated by
Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™(ğ‘¥ğ‘™ğ‘œğ‘¤,eğ‘¥ğ‘™ğ‘œğ‘¤)=âˆ¥Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ‘¥ğ‘™ğ‘œğ‘¤))
âˆ’Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(eğ‘¥ğ‘™ğ‘œğ‘¤))âˆ¥2
2,
Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘¢(ğ‘¢ğ‘™ğ‘œğ‘¤,eğ‘¢ğ‘™ğ‘œğ‘¤)=1(ğ‘šğ‘ğ‘¥(ğ‘)â‰¥ğœ)
Â·ğ»[Ë†ğ‘,Mğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(eğ‘¢ğ‘™ğ‘œğ‘¤))],(2)
whereğ‘isMğ‘ğ‘™ğ‘ (ğ‘¦|Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘›(ğ’–ğ‘™ğ‘œğ‘¤)),Ë†ğ‘isğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥(ğ‘), andğœis the
confidence threshold for making a pseudo-label.
The final loss is defined as L=Lğ‘ğ‘™ğ‘ + Lğ‘Ÿğ‘’ğ‘ğ‘œğ‘›+
ğœ†ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡(Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™+Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘¢). Here,ğœ†ğ‘¡ğ‘–ğ‘šğ‘’,ğœ†ğ‘“ğ‘Ÿğ‘’ğ‘, andğœ†ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡
are scalar hyperparameters that determine the relative weights of
Lğ‘¡ğ‘–ğ‘šğ‘’,Lğ‘“ğ‘Ÿğ‘’ğ‘, andLğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™+Lğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘¢, respectively. The pseudo-
code implementation of the proposed SemiTSR framework is pro-
vided in Algorithm 1.
3.3 Reconstructor
As we have emphasized in Introduction, the restoration of class-
discriminative local periodicity is crucial for enhancing the clas-
sification of low-sampling-rate time series. For this purpose, an
upsampler within the resconstructor Mğ‘Ÿğ‘’ğ‘ğ‘œğ‘› plays a vital role
in restoring the periodicity that has been smoothed out. The re-
constructor mainly consists of two components: an encoder and
a temporal upsampler. Inspired by image super-resolution tech-
niques [ 12,33,34], the low-sampling-rate time series {ğ’™ğ‘¡;ğ‘¡âˆˆ
(ğ‘,ğ‘+1
ğ›¾,...,ğ‘+ğ›¾ğ‘‡âˆ’1
ğ›¾),ğ‘âˆˆ (1,2,...,1
ğ›¾)}is first encoded by a
 
62Semi-Supervised Learning for Time Series Collected at a Low Sampling Rate KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Encoder
+
Ã—ğ‘€ğ‘§ğ‘™ğ‘œğ‘¤
Conv
ğ‘¥ğ‘™ğ‘œğ‘¤ğ‘¢ğ‘™ğ‘œğ‘¤
Linear Interpolation
ğ‘§âˆ—
ğ‘“ğ‘¡,ğ‘§tâˆ—
Linear
Q
 K
V
Attention
Conv
+
Upsampler
ğ‘¥â„ğ‘–ğ‘”â„ğ‘¢â„ğ‘–ğ‘”â„AttentionAttentionAttentionConv+
Ã—ğ‘RSTB
Figure 6: Overall architecture of high-sampling-rate recon-
structorMğ‘Ÿğ‘’ğ‘ğ‘œğ‘› consisting of a deep feature encoder and a
temporal upsampler.
deep feature encoder. Then, the latent feature map at a low sam-
pling rate,{ğ’›ğ‘¡;ğ‘¡âˆˆ(ğ‘,ğ‘+1
ğ›¾,...,ğ‘+ğ›¾ğ‘‡âˆ’1
ğ›¾),ğ‘âˆˆ(1,2,...,1
ğ›¾)}, is
upsampled at the end of the reconstruction as shown in Figure 6.
3.3.1 Encoder. We modify Residual Swin Transformer
Block (RSTB) [ 34] to create a deep feature encoder capable
of processing 1-D input. As shown in the left part of Figure 6, the
deep feature encoder consists of ğ‘€RSTBs and a convolution layer.
Each RSTB consists of stacked attention modules, repeated ğ‘
times, and culminates with a convolution layer that includes a skip
connection. Both a long skip connection and attention modules
enable modeling the long-range dependency within the input time
series. While we compose an encoder with RSTB, which is used
in state-of-the-art image super-resolution methods, an arbitrary
time-series encoder can be used as an encoder.
3.3.2 Temporal Upsampler. Meanwhile, for an upsampler that in-
creases the temporal resolution in effect from the low-sampling-
rate of ğ’–ğ‘™ğ‘œğ‘¤to the high-sampling-rate of ğ’™â„ğ‘–ğ‘”â„, it is impor-
tant to accurately restore local periodic patterns that have been
smoothed out. However, techniques widely employed in image
super-resolution [ 12,47] are inappropriate for time series due to
their inability to effectively model temporal dependencies and peri-
odic features. For example, as depicted in in Figure 7(a), sub-pixel
convolution applies a fixed kernel of size three to the adjacent
observed points, without considering the periodicity and relative
phase of the target timestamp. Consequently, the reconstructed
value significantly deviates from the ground-truth peak point. That
is, upsampling with the observed timestamps should consider the
relative phase and periodicity of the target timestamp. To this end,
we propose a novel periodic time embedding-based attention.
3.3.3 Context-Aware Periodic Time Embedding. To achieve accurate
upsampling, the model should learn the periodicity and relative
phase associated with each timestamp. For this purpose, we propose
a time embedding which captures the local periodicity and trend
within a given local context corresponding to each timestamp. Let us
denote the output of the encoder on a low-sampling-rate time series
Original time series Low Target timestamp â˜…Reconstructed Weight
(a) Sub-pixel Convolution. (b) Temporal Upsampler.
Figure 7: Visualization of the two upsampling methods. The
gray line is the original time series at a high sampling rate,
and the black points are the observed time series at a low
sampling rate. Red stars are the reconstructed values given
black observed points.
as{ğ’›ğ‘¡âˆˆRğ‘‘ğ‘§:ğ‘¡âˆˆ(ğ‘,ğ‘+1
ğ›¾,...,ğ‘+ğ›¾ğ‘‡âˆ’1
ğ›¾),ğ‘âˆˆ(1,2,...,1
ğ›¾)}. By
applying linear interpolation to ğ’›ğ‘¡, we generate a latent feature map
with a high sampling rate denoted as {ğ’›âˆ—
ğ‘¡âˆˆRğ‘‘ğ‘§:ğ‘¡âˆˆ(1,2,...,ğ‘‡)}.
Using the interpolated latent feature map, the time embedding
ğ‘“(ğ‘¡,ğ’›âˆ—
ğ‘¡)âˆˆRğ‘‘ğ‘¡at timeğ‘¡occurring with the high sampling rate is
formulated by
ğ‘“(ğ‘¡,ğ’›âˆ—
ğ‘¡)=ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°ğ‘Š0ğ‘¡+ğ‘0
ğ‘ ğ‘–ğ‘›(ğ¹1(ğ’›âˆ—
ğ‘¡)ğ‘¡+ğ‘ƒ1(ğ’›âˆ—
ğ‘¡))
...
ğ‘ ğ‘–ğ‘›(ğ¹ğ‘‘ğ‘¡âˆ’1(ğ’›âˆ—
ğ‘¡)ğ‘¡+ğ‘ƒğ‘‘ğ‘¡âˆ’1(ğ’›âˆ—
ğ‘¡))ï£¹ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£», (3)
whereğ‘Š0andğ‘0are learnable parameters, and ğ¹ğ‘–andğ‘ƒğ‘–are the
MLPs that estimate frequency and phase, respectively, for a dimen-
sionğ‘–âˆˆ (1,2,...,ğ‘‘ğ‘¡âˆ’1). In Equation (3), a local trend and the
periodicities flowing at time ğ‘¡are embedded in each dimension of
the time embedding.
3.3.4 Time Embedding-Based Attention. Based on the time embed-
ding, which represents the local periodicity and trend associated
with each timestamp, a comparative analysis of the relative phase
and period of these timestamps becomes feasible. By employing the
time embedding as the query andkeyand an interpolated latent
feature as the value, an attention module [ 54] can effectively learn
the most relevant timestamps and assign appropriate weights to
their corresponding values. Specifically, for a given query times-
tampğ‘¡ğ‘ğ‘¢ğ‘’ğ‘Ÿğ‘¦ , the attention score for each keytimestamp is com-
puted by evaluating the similarity between ğ‘“(ğ‘¡ğ‘ğ‘¢ğ‘’ğ‘Ÿğ‘¦,ğ’›âˆ—
ğ‘¡ğ‘ğ‘¢ğ‘’ğ‘Ÿğ‘¦)and
{ğ‘“(ğ‘¡ğ‘˜ğ‘’ğ‘¦,ğ’›âˆ—
ğ‘¡ğ‘˜ğ‘’ğ‘¦):ğ‘¡ğ‘˜ğ‘’ğ‘¦âˆˆ(1,...,ğ‘¡ğ‘ğ‘¢ğ‘’ğ‘Ÿğ‘¦,...,ğ‘‡)}as follows:
MultiHead(ğ‘„,ğ¾,ğ‘‰)=Concat(â„ğ‘’ğ‘ğ‘‘ 1,...,â„ğ‘’ğ‘ğ‘‘â„)ğ‘Šğ‘‚
whereâ„ğ‘’ğ‘ğ‘‘ğ‘–=Attention(f(t,ğ’›âˆ—
t)WQ,f(t,ğ’›âˆ—
t)WK,ğ’›âˆ—
tWV)
andAttention(ğ‘„,ğ¾,ğ‘‰)=Softmax(ğ‘„ğ¾âŠ¤
âˆšğ‘‘ğ‘¡)ğ‘‰.(4)
Here,ğ‘Šğ‘„,ğ‘Šğ¾âˆˆRğ‘‘ğ‘¡Ã—ğ‘‘ğ‘¡
â„andğ‘Šğ‘‰âˆˆRğ‘‘ğ‘§Ã—ğ‘‘ğ‘§
â„are learnable parame-
ters, andâ„is the number of heads. Finally, the attention result is
combined with a shortcut connection and subsequently subjected to
convolutions with dilation sizes of 1,1
2ğ›¾, and3
2ğ›¾. This formulation
ensures that the receptive fields cover values beyond the sampling
 
63KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Minyoung Bae, Yooju Shin, Youngeun Nam, Young Seop Lee, and Jae-Gil Lee
Value
Value
Time Time0 100 200 300 400 500 600 0 100 200 300 400 500 600
(a) Quinx (female). (b) Stigma (male).
Figure 8: Insect Sound dataset [ 11] visualization of different
species and sex.
Table 1: Benchmark dataset statistics.
Datasets
Applications Window size # Class # Train # Test # Feature
Opp
ortunity Human Activity 64 17 5907 1604 77
InsectSound Audio 600 10 10000 5000 1
mHealth Human Activity 200 12 2281 948 23
SAMSUNG Server Monitoring 120 12 6000 3000 4
rate. As the high-sampling-rate time series prediction, the average
of the three convolution outputs is used.
Through the mapping of a latent feature to the frequency and
phase components associated with the corresponding timestamp,
the time embedding ğ‘“(ğ‘¡,ğ’›âˆ—
ğ‘¡)captures the local periodicity, allowing
it to effectively model time-varying periodic patterns. Figure 8 vi-
sualizes how the frequency and amplitude change over time within
a given time series. Simultaneously, the first dimension of ğ‘“(ğ‘¡,ğ’›âˆ—
ğ‘¡)
represents the trend component of the time series by means of
learned linear transformation. The time embedding-based attention
then assigns appropriate weights to the values of contextually and
periodically relevant timestamps, as depicted in Figure 7(b).
4 Experiments
4.1 Experiment Setting
Datasets: Table 1 provides a summary of four benchmark datasets
used in the experiment: Opportunity, InsectSound, mHealth, and
SAMSUNG. For more detail of each dataset, see Appendix A. We
also conducted experiment on ten datasets from the UCR time-series
classification archive1. The ten datasets were chosen based on three
specific criteria: a large amount of data, with at least 1000 instances
in the training and test sets; a long original window length, of at
least 96; and a high level of classification difficulty, with at least
seven classes.
Instances from the original dataset were used as high-sampling-
rate time series. Low-sampling-rate instances are downsampled
from the original time series at a fixed sampling rate of ğ›¾. In our
experiment, ğ›¾varies from1
2to1
16.
Evaluation Metrics: We report the evaluation based on accuracy,
which is defined by
ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦(%)=#ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ 
#ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ Ã—100. (5)
We repeated each evaluation fivetimes using random seeds and
distinct validation sets, and then report the mean and standard
deviation for each result.
Baselines: We compare our method with the state-of-the-art semi-
supervised learning methods based on consistency regularization:
1https://www.cs.ucr.edu/~eamonn/time_series_data_2018/FixMatch [ 52], FreeMatch [ 56], and ReMixMatch [ 8]. For the aug-
mentation strategy used in each method, see Appendix B.
For the classifier backbone Mğ‘ğ‘™ğ‘ of the semi-supervised learning,
we used TCN [ 3] and Transformer [ 54] for their popularity in time-
series classification [ 25,58].Mğ‘ğ‘™ğ‘ trained with 100% labeled high-
sampling-rate data is the performance upper bound, while Mğ‘ğ‘™ğ‘ 
trained with ğ‘™% labeled low-sampling-rate data is the performance
lower bound. Our evaluation is conducted on ğ‘™=20andğ‘™=10and,
we randomly sampled ğ‘™%from the fully-labeled original dataset to
make unlabeled data.
Model Configurations: A deep feature encoder in SemiTSR con-
sists of four RSTBs2, and each RSTB consists of four attention layers
with four heads. For the time embedding-based attention, ğ¹ğ‘–(Â·)and
ğ‘ƒğ‘–(Â·)are three layer MLPs with 256 hidden dimensions. (ğœ†ğ‘¡ğ‘–ğ‘šğ‘’,
ğœ†ğ‘“ğ‘Ÿğ‘’ğ‘,ğœ†ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡)is(2,0.1,1)forOpportunity and(1,2,1)for the oth-
ers since Opportunity exhibits a weak periodicity. ğ‘‘ğ‘§is 256, andğ‘‘ğ‘¡
is set to 64 for mHealth and 32 for the others.
For the classifier backbone Mğ‘ğ‘™ğ‘ , TCN is composed of eight
temporal blocks whose hidden dimensionality is 128 and kernel
size is seven. Transformer is composed of two transformer layers
with two heads followed by a linear layer.
Implementations Details: The batch size of the labeled data is 32,
and the number of epochs is 400, except for the InsectSound dataset
where we set 16 and 150 due to its data size. The unlabeled batch
size ratio is 3. Train and validation data are split by 9:1.
For semi-supervised learning baselines, we use SGD with a mo-
mentum of 0.9 for the optimizer following [ 52]. The learning rate
is initialized as 0.03 and decayed using a cosine scheduler [ 37] to
ğœ‚ğ‘ğ‘œğ‘ (7ğœ‹ğ‘˜
16ğ¾), whereğœ‚is the initial learning rate, ğ‘˜is the current train-
ing step, and ğ¾is the total number of training steps. All the other
hyperparameters are set to default values in each paper. According
to [52], semi-supervised learning performance heavily depends on
an optimizer, a regularization, and a training scheduler as well as
a semi-supervised learning algorithm. We found that Adam [ 28]
works better than SGD [ 53] inSemiTSR ; the learning rate is initial-
ized to 0.001 and decayed by 0.5 every 50 epochs.
We conducted our experiment using Pytorch 1.12.1 on an
NVIDIA RTX 3090Ti-equipped server. The source code is avail-
able at https://github.com/kaist-dmlab/SemiTSR.
4.2 Overall Performances
Tables 2 and 3 compare the classification accuracy of SemiTSR
and semi-supervsied learning baselines as well as fully supervised
learning whenMğ‘ğ‘™ğ‘ is TCN. SemiTSR performs best in almost all
combinations of the low-sampling-rates and the labeled data ratios.
Specifically in the lowest sampling rate when the labeled ratio is
10%, SemiTSR outperforms the other semi-supervised methods by
4.00â€“22.74% average performance margin. This result confirms that
recovering high-frequency terms is crucial for improving the low-
sampling-rate time-series classification. It is noteworthy that our
method mostly caught up 100% fully supervised learning of each
sampling rate. Existing semi-supervised learning baselines occa-
sionally beat SemiTSR in arelatively high low-sampling-rate (e.g.,
1/2). In these cases, we conjecture that the low-sampling-rate data
2https://github.com/JingyunLiang/SwinIR
 
64Semi-Supervised Learning for Time Series Collected at a Low Sampling Rate KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Table 2: Accuracy comparison of semi-supervised learning methods with 20%labeled data when the classifier backbone is TCN.
Metho
dOpp
ortunity Inse
ctSound mHealth SAMSUNG
1/2
1/4 1/8 1/16 1/2
1/4 1/8 1/2
1/4 1/8 1/2
1/4 1/8
Fully-Sup
ervised(100%)67.24
66.66 64.83 63.37 70.26
64.74 51.01 93.08
92.51 90.57 92.86
91.38 89.81
(
Â±1.93) (Â±1.59) (Â±2.20) (Â±1.77)(
Â±0.39) (Â±0.66) (Â±1.14)(
Â±3.54) (Â±3.67) (Â±2.73)(
Â±0.43) (Â±0.20) (Â±0.44)
Fully-Supervised(20%)63.90
57.72 57.36 53.37 60.48
54.20 39.58 92.57
91.12 86.43 88.05
85.39 84.03
(
Â±1.99) (Â±1.94) (Â±0.88) (Â±1.40)(
Â±0.81) (Â±1.11) (Â±0.59)(
Â±3.03) (Â±2.92) (Â±1.67)(
Â±0.50) (Â±0.86) (Â±0.75)
FixMatch69.43
67.42 66.20 65.07 65.83
59.51 42.81 86.79
84.14 85.91 91.65
89.88 88.85
(
Â±2.86) (Â±2.02) (Â±2.29) (Â±1.79)(
Â±1.00) (Â±0.56) (Â±0.60)(
Â±3.93) (Â±5.67) (Â±3.67)(
Â±0.67) )Â± 0.70) (Â±0.57)
FreeMatch66.28
65.11 65.51 64.04 66.15
60.39 43.37 88.75
91.50 88.59 92.44
89.90 88.95
(
Â±1.52) (Â±2.16) (Â±1.56) (Â±0.77)(
Â±0.93) (Â±0.83) (Â±0.28)(
Â±3.47) (Â±3.68) (Â±3.27)(
Â±0.14) (Â±0.32) (Â±0.45)
ReMixMatch69.40
66.72 65.12 64.93 67.54 59.46
43.11 94.05 91.65
90.08 87.20
86.57 86.83
(
Â±1.31) (Â±1.98) (Â±0.40) (Â±1.07)(
Â±0.91) (Â±0.63) (Â±0.87)(
Â±1.89) (Â±4.35) (Â±2.70)(
Â±1.06) (Â±0.85) (Â±0.71)
SemiTSR71.59
69.85 71.15 66.69 65.32 62.43
50.99 93.76 94.77
93.10 93.20
92.50 91.64
(
Â±2.09) (Â±.39) (Â±1.88) (Â±2.44)(
Â±0.98) (Â±0.77) (Â±0.61)(
Â±1.18) (Â±2.45) (Â±1.81)(
Â±0.54) (Â±0.57) (Â±0.89)
Table 3: Accuracy comparison of semi-supervised learning methods with 10%labeled data when the classifier backbone is TCN.
Metho
dOpp
ortunity Inse
ctSound mHealth SAMSUNG
1/2
1/4 1/8 1/16 1/2
1/4 1/8 1/2
1/4 1/8 1/2
1/4 1/8
Fully-Sup
ervised(100%)67.24
66.66 64.83 63.37 70.26
64.74 51.01 93.08
92.51 90.57 92.86
91.38 89.81
(
Â±1.93) (Â±1.59) (Â±2.20) (Â±1.77)(
Â±0.39) (Â±0.66) (Â±1.14)(
Â±3.54) (Â±3.67) (Â±2.73)(
Â±0.43) (Â±0.20) (Â±0.44)
Fully-Supervised(10%)56.66
54.15 53.98 49.35 55.18
48.79 34.16 86.92
83.78 77.07 85.06
83.77 81.23
(
Â±1.98) (Â±1.02) (Â±1.41) (Â±2.63)(
Â±0.83) (Â±1.96) (Â±0.39)(
Â±2.33) (Â±2.90) (Â±4.00)(
Â±0.66) (Â±0.99) (Â±0.67)
FixMatch64.89
64.20 62.42 61.22 61.24
55.76 37.38 89.64
83.82 83.14 88.50
87.98 86.71
(
Â±1.75) (Â±3.32) (Â±0.87) (Â±1.25)(
Â±1.14) (Â±1.05) (Â±0.82)(
Â±2.68) (Â±2.70) (Â±2.77)(
Â±0.66) (Â±0.63) (Â±0.36)
FreeMatch64.66
61.25 63.23 58.73 64.10 56.78
41.22 87.34
87.89 83.25 89.45
88.79 86.81
(
Â±1.62) (Â±2.84) (Â±1.59) (Â±2.09)(
Â±1.14) (Â±0.96) (Â±1.31)(
Â±6.67) (Â±5.45) (Â±3.85)(
Â±0.58) (Â±0.72) (Â±0.80)
ReMixMatch66.52
63.75 61.66 61.22 63.95
53.42 36.30 90.49 87.91
82.91 85.99
84.24 84.27
(
Â±1.86) (Â±1.80) (Â±1.70) (Â±1.74)(
Â±1.45) (Â±1.85) (Â±1.01)(
Â±4.20) (Â±5.63) (Â±3.66)(
Â±0.96) (Â±1.06) (Â±0.42)
SemiTSR67.39
66.25 65.33 64.59 61.34 58.04
47.01 90.41 90.34
89.42 90.21
90.40 89.69
(
Â±1.21) (Â±2.95) (Â±3.43) (Â±0.97)(
Â±1.65) (Â±0.78) (Â±0.36)(
Â±3.12) (Â±1.93) (Â±4.04)(
Â±0.75) (Â±0.74) (Â±0.74)
already contains enough information, eliminating the necessity for
reconstruction into a high sampling rate.
The results for the UCR datasets are shown in Table 4. For all
datasets, SemiTSR outperforms the semi-supervised learning base-
lines. In particular, the Mallat and NonInvasiveFetalECGThorax1
datasets, which were down-sampled at much lower rates than the
other datasets, exhibited substantial performance enhancements. In
the absence of a sophisticated upsampling method like SemiTSR , it
would be difficult to recover the ground-truth time series in harsh
down-sampling environments.
4.3 Effectiveness of Temporal Upsampler
4.3.1 Quantitative Analysis. To show the effectiveness of the tem-
poral upsampler, we compare the classification performance with
the existing upsampling methods: sub-pixel convolution [ 47] and
LTE3[33]. Model configurations except the upsampler are all iden-
tically set. According to Table 5, the temporal upsampler performs
better than the other upsampling methods in most combinations.
Wide performance gap at the lowest sampling rate implies that our
method learns temporal patterns better than the other upsamplers
even if a small amount of information is available. In cases where
data exhibits clear periodicity (e.g., mHealth ), we observe that LTE
3https://github.com/jaewon-lee-b/lteoutperforms sub-pixel convolution. We hypothesize that it is be-
cause LTE aims to restore the local periodicity accurately. Further
analysis on the reconstruction quality including MSE comparison
is presented in Appendix D.
4.3.2 Qualitative Analysis. As shown in Figures 9 and 10, the tem-
poral upsampler reconstructs high-sampling-rate time series better
than the other upsamplers in effect. In Figure 9, the first column
demonstrates that the local periodicity is precisely estimated by
the temporal upsampler, whereas the periodicity reconstructed by
sub-pixel convolution is shifted in time relative to the ground-truth
periodicity. LTE neither precisely estimates frequency nor ampli-
tude. The second column shows that our method better estimates
the amplitude of the changing periodicity. For Figure 10, the tem-
poral upsampler restores the meaningful periodicity, whereas the
others generate false noisy peaks. Especially in the second column,
sub-pixel convolution generates false periodicities and LTE gener-
ates overly smoothed time series, whereas the temporal upsampler
effectively recovers the periodicity.
4.4 Ablation Study
In order to demonstrate the contribution of each loss term in
SemiTSR , we train the model without a specific loss term. That
is, each weight parameter ğœ†ğ‘¡ğ‘–ğ‘šğ‘’,ğœ†ğ‘“ğ‘Ÿğ‘’ğ‘,ğœ†ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘¢, andğœ†ğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™
 
65KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Minyoung Bae, Yooju Shin, Youngeun Nam, Young Seop Lee, and Jae-Gil Lee
Table 4: Accuracy comparison of semi-supervised learning methods on ten UCR time-series classification datasets.
Data Lab
el Ratio Sampling
Rate Fully-Sup
(Label Ratio%) Fully-Sup (100%) FixMatch
FreeMatch ReMixMatch SemiTSR
Ele
ctricDevices10 1/2 55.01
(Â±0.83) 64.67 (Â±0.60) 58.93
(Â±1.04) 57.56 (Â±1 .13) 58.31 (Â±1 .02) 60.17
(Â±1.02)
10 1/4 52.89
(Â±1.86) 59.53 (Â±1.05) 54.41
(Â±1.74) 53.36 (Â±0 .98) 55.52 (Â±0 .64) 55.95
(Â±1.34)
10 1/8 49.17
(Â±1.15) 57.67 (Â±0.87) 51.41
(Â±1.92) 51.88 (Â±1 .64) 52.32 (Â±0 .89) 53.29
(Â±1.42)
Sw
edishLeaf 20 1/8 59.26
(Â±0.91) 76.74 (Â±1.11) 66.96
(Â±1.27) 61.93 (Â±1 .51) 52.74 (Â±3 .02) 76.15
(Â±2.19)
FacesUCR 10 1/8 61.67
(Â±2.01) 86.67 (Â±3.70) 66.50
(Â±5.35) 65.17 (Â±3 .68) 69.33 (Â±1 .03) 73.33
(Â±1.25)
Face
All 10 1/8 50.96
(Â±2.63) 81.38 (Â±1.22) 56.30
(Â±1.26) 55.85 (Â±1 .15) 56.89 (Â±2 .10) 65.90
(Â±0.72)
Mallat 10 1/32 91.48
(Â±0.85) 96.02 (Â±0.56) 92.82
(Â±0.68) 94.54 (Â±0 .36) 86.06 (Â±2 .52) 95.37
(Â±0.42)
NonInvasiv
eFetalECGThorax1 10 1/25 40.56
(Â±2.26) 79.25 (Â±0.44) 39.68
(Â±2.37) 42.95 (Â±1 .10) 33.76 (Â±0 .27) 58.59
(Â±3.17)
Me
dicalImages 10 1/8 49.43
(Â±2.37) 63.69 (Â±1.82) 55.03
(Â±1.61) 54.16 (Â±0 .25) 53.63 (Â±0 .62) 55.29
(Â±1.60)
Shap
esAll 10 1/16 30.78
(Â±5.85) 73.78 (Â±0.91) 30.00
(Â±4.77) 28.28 (Â±4 .11) 32.17 (Â±2 .23) 33.64
(Â±2.37)
U
WaveGestureLibraryAll 10 1/8 83.34
(Â±1.65) 96.27 (Â±0.23) 84.71
(Â±1.82) 84.12 (Â±1 .26) 61.60 (Â±10 .08) 87.98
(Â±0.47)
P
honeme 10 1/8 12.62
(Â±1.01) 23.21 (Â±0.88) 13.55
(Â±2.38) 12.15 (Â±0 .38) 13.24 (Â±0 .79) 16.28
(Â±1.67)
Table 5: Accuracy comparison of our temporal upsampler and the others based on the same deep feature encoder.
Lab
eled Ratio UpsmaplerOpp
ortunity Inse
ctSound mHealth SAMSUNG
1/2
1/4 1/8 1/16 1/2
1/4 1/8 1/2
1/4 1/8 1/2
1/4 1/8
20%Sub-Pixel
Conv71.54 71.98 70.22
65.12 65.54 62.40
50.29 93.49
92.87 90.65 93.07
92.41 91.72
(
Â±1.46) (Â±1.52) (Â±2.58) (Â±1.50)(
Â±0.54) (Â±1.67) (Â±0.77)(
Â±0.97) (Â±1.16) (Â±2.60)(
Â±0.23) (Â±0.84) (Â±0.60)
LTE67.15
68.58 67.23 63.40 64.89
61.33 48.31 92.82
94.41 92.63 92.84
91.85 90.84
(
Â±2.31) (Â±1.22) (Â±1.95) (Â±1.28)(
Â±1.17) (Â±0.84) (Â±0.49)(
Â±2.82) (Â±3.62) (Â±1.54)(
Â±0.18) (Â±0.19) (Â±0.47)
SemiTSR71.59 69.85 71.15
66.69 65.32 62.43
50.99 93.76
94.77 93.10 93.20
92.50 91.64
(
Â±2.09) (Â±2.39) (Â±1.88) (Â±2.44)(
Â±0.98) (Â±0.77) (Â±0.61)(
Â±1.18) (Â±2.4) (Â±1.81)(
Â±0.54) (Â±0.57) (Â±0.89)
10%Sub-Pixel
Conv66.92
66.22 65.22 62.86 58.88
55.82 45.72 87.05
89.27 86.22 89.53
89.48 89.49
(
Â±2.88) (Â±2.20) (Â±2.49) (Â±1.71)(
Â±1.76) (Â±1.07) (Â±1.15)(
Â±3.10) (Â±2.02) (Â±2.03)(
Â±0.80) (Â±0.69) (Â±0.72)
LTE60.05
63.29 62.68 59.80 60.29
56.01 44.46 90.36
89.30 88.11 90.16
89.53 89.13
(
Â±2.64) (Â±1.86) (Â±2.32) (Â±1.48)(
Â±0.37) (Â±0.49) (Â±0.99)(
Â±3.88) (Â±2.18) (Â±3.56)(
Â±0.64) (Â±0.65) (Â±0.44)
SemiTSR67.39
66.25 65.33 64.59 61.34
58.04 47.01 90.41
90.34 89.42 90.21
90.40 89.69
(
Â±1.21) (Â±2.95) (Â±3.43) (Â±0.97)(
Â±1.65) (Â±0.78) (Â±0.36)(
Â±3.12) (Â±1.93) (Â±4.04)(
Â±0.75) (Â±0.74) (Â±0.74)
Reconstruction Ground Truth
Sub-Pixel Convolution
LTE
Temporal Upsampler
Figure 9: Visualization of InsectSound reconstruction using
different upsampling methods. ğ›¾is1
8andğ‘™is 20% . The two
columns are different instances.
Reconstruction Ground Truth
Sub-Pixel Convolution
LTE
Temporal UpsamplerFigure 10: Visualization of mHealth reconstruction using
different upsampling methods. ğ›¾is1
8andğ‘™is 10% . The two
columns are different instances.
was set to zero in (i)â€“(iv) respectively. Table 6 shows the result.
Performance gain by shift consistency regularization verifies that
learning various phases from the distribution of unlabeled data
improves generalization. Depending on the dataset, the effect ofreconstruction loss on Fourier-transformed time series varies. It
will be the future work to adaptively adjust the weight on frequency
domain reconstruction considering the periodicity of the data. To
further demonstrate the contribution of an attention layer, we con-
 
66Semi-Supervised Learning for Time Series Collected at a Low Sampling Rate KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Table 6: Ablation study on each loss term where 10% of the
data is labeled and the low sampling rate is1
8except for
Opportunity (1
16).
Opp
ortunity Inse
ctSound mHealth SAMSUNG
(i)
w/oLğ‘¡ğ‘–ğ‘šğ‘’ 59.65(
Â±1.35) 45.00(
Â±1.83) 88.21(
Â±4.84) 83.60(
Â±4.38)
(ii) w/oLğ‘“ğ‘Ÿğ‘’ğ‘ 60.49(
Â±2.25) 42.68(
Â±1.08) 89.72(
Â±3.22) 89.07(
Â±0.60)
(iii) w/oLğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘¢57.54(
Â±0.50) 46.39(
Â±0.78) 88.99(
Â±2.95) 89.23(
Â±0.95)
(iv) w/oLğ‘ğ‘œğ‘›ğ‘ ğ‘–ğ‘ ğ‘¡ _ğ‘™62.22(
Â±3.92) 40.15(
Â±0.96) 87.58(
Â±3.27) 88.09(
Â±0.41)
(
v) w/oğ‘ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘› 61.82(
Â±2.03) 46.63(
Â±0.60) 87.09(
Â±3.61) 89.22(
Â±0.49)
SemiTSR 64.59(
Â±0.97) 47.01(
Â±0.36) 89.42(
Â±4.04) 89.37(
Â±0.78)
Table 7: Classification accuracy compared to imputation
methods when ğ‘™is 10% andğ›¾is1
8except for Opportunity (1
16).
Opp
ortunity Inse
ctSound mHealth SAMSUNG
mT
AND 58.70(
Â±3.03) 25.26(
Â±0.91) 89.24(
Â±3.32) 86.95(
Â±1.22)
HetVAE 62.73(
Â±1.63) 10.18(
Â±0.48) 66.56(
Â±2.39) 83.34(
Â±0.51)
SemiTSR 64.59(
Â±0.97) 47.01(
Â±0.36) 89.42(
Â±4.04) 89.37(
Â±0.78)
duct an ablation study where interpolated latent features directly
go through the convolution layer. As shown in (v) of Table 6, at-
tention mechanism based on the time embedding improves the
classification accuracy in all datasets.
4.5 Comparison with Imputation Methods
To further show the effectiveness of SemiTSR , we compare it with
existing imputation methods [ 49,50] followed by a classifier. To
be specific, an imputation model is pre-trained using both the low-
sampling-rate and high-sampling-rate data, while the classification
loss on the labeled high-sampling-rate data supervises the classi-
fier and the imputation model. Then, the pre-trained imputation
model replaces SemiTSR â€™s reconstructor for semi-supervised learn-
ing. For mTAND4[50], we follow their setting which uses the en-
coder output as the classifier input. For HetVAE5[49], we use the
imputed data at a high sampling rate as the classifier input. Table 7
shows that SemiTSR with our reconstructor performs better than
the imputation-based semi-supervised learning. It demonstrates
that the fixed-rate upsampler resolves semi-supervised learning at
a low sampling rate more effectively than the imputation methods
which assume irregular input time series. In other words, impu-
tation methods followed by a classifier are not optimal for our
problem setting.
4.6 A Case Study on an ECG Dataset with
Heterogeneous Sampling Rates
Extensive healthcare data has been generated as a result of recent
developments in wearable medical devices, albeit at heterogeneous
sampling rates [ 60]. This challenge directly fits our novel prob-
lem, semi-supervised learning with low-sampling-rate time series,
so we conducted a case study on an ECG dataset [ 23,43,44] of
mixed sampling rates. We specifically used a dataset at 500Hz and
1000Hz, segmented into three-second intervals. The dataset com-
prises 12 features, 7 categories, 4000 training instances, and 1000
4https://github.com/reml-lab/mTAN
5https://github.com/reml-lab/hetvaeTable 8: Result of the case study. Classification accuracy on
500Hz ECG data compared to semi-supervised learning base-
lines and other upsamplers.
Metho
d A
ccuracy
Fully-Sup
ervisedT
CN(100%) 71.90
T
CN(30%) 69.70
Semi-Sup
ervisedFixMatch 74.00
Fr
eeMatch 71.70
ReMixMatch 74.40
Upsampler
VariationSub-Pixel
Conv 73.10
LTE 73.50
SemiTSR (
ours) 75.20
test instances for each sampling rate. According to Table 8, SemiTSR
outperforms semi-supervised learning baselines as well as other
upsampler methods on the inference of the 500Hz data by utilizing
the 30% of the labeled 1000Hz data. It demonstrates that SemiTSR
is extendable not only in situations where the sampling rate of a
single device is varied but also in situations where data is generated
from multiple devices with various sampling rates.
More Results in the Appendix: Appendix C reports (i) the clas-
sification accuracy on a different classifier backbone, Transformer,
(ii) the computation efficiency of SemiTSR , and (iii) the classifi-
cation accuracy of high-sampling-rate data. Further analysis of
reconstruction quality is conducted in Appendix D.
5 Conclusion
This paper introduces SemiTSR , a semi-supervised learning frame-
work for the low-sampling-rate time series. It aims to recover the
lost information caused by reducing the sampling rate by recon-
structing the time series at its original sampling rate and performing
classification. In particular, our temporal upsampler considers rela-
tive phase and periodicity of the target timestamp by comparing
the time embedding that reflects local context. Furthermore, con-
sistency regularization on the instances of different phases enables
to reconstruct and classify within a class more accurately. Exper-
iments demonstrate improved classification accuracy for various
low-sampling-rates and labeled ratios than prior semi-supervised
learning methods. We anticipate that our work will contribute to
time-series modeling where labels are scarce and sampling rate
must be reduced due to practical constraints.
We expect that our novel upsampler can be transferred to en-
hance any time-series analysis tasks on low sampling rates. Nev-
ertheless, the current design of phase consistency regularization
is tailored for classification but is difficult to apply to forecasting.
Extending the upsampler for low-sampling-rate forecasting would
be a meaningful direction of future work.
Acknowledgments
This work was partly supported by Mobile eXperience Business,
Samsung Electronics Co., Ltd. (Few-shot Anomaly Detection and
Root Cause Estimation Development) and the National Research
Foundation of Korea (NRF) grant funded by the Korea government
(Ministry of Science and ICT) (No. 2023R1A2C2003690).
 
67KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Minyoung Bae, Yooju Shin, Youngeun Nam, Young Seop Lee, and Jae-Gil Lee
References
[1]Richard Andersson et al .2010. Sampling frequency and eye-tracking measures:
how speed affects durations, latencies, and more. Journal of Eye Movement
Research 3, 3 (2010).
[2]Davide Anguita et al .2013. A public domain dataset for human activity recogni-
tion using smartphones.. In ESANN. 437â€“442.
[3]Shaojie Bai et al .2018. An empirical evaluation of generic convolutional and
recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271
(2018).
[4]Oresti Banos et al .2014. mHealthDroid: A novel framework for agile development
of mobile health applications. In IWAAL. 91â€“98.
[5]Mathias Baumert et al .2016. Effects of ECG sampling rate on QT interval
variability measurement. Biomedical Signal Processing and Control 25 (2016),
159â€“164.
[6]Yoshua Bengio et al .2011. Deep learners benefit more from out-of-distribution
examples. In AISTATS. 164â€“172.
[7]David Berthelot et al .2019. Mixmatch: A holistic approach to semi-supervised
learning. In NeurIPS. 5049â€“5059.
[8]David Berthelot et al .2019. Remixmatch: Semi-supervised learning with distri-
bution alignment and augmentation anchoring. arXiv preprint arXiv:1911.09785
(2019).
[9]Joel S Burma et al .2021. Insufficient sampling frequencies skew heart rate variabil-
ity estimates: Implications for extracting heart rate metrics from neuroimaging
and physiological data. Journal of Biomedical Informatics 123 (2021), 103934.
[10] Ricardo Chavarriaga et al .2013. The Opportunity challenge: A benchmark
database for on-body sensor-based activity recognition. Pattern Recognition
Letters 34, 15 (2013), 2033â€“2042.
[11] Yanping Chen et al .2014. Flying insect classification with inexpensive sensors.
Journal of Insect Behavior 27 (2014), 657â€“677.
[12] Yinbo Chen et al .2021. Learning continuous image representation with local
implicit image function. In CVPR. 8628â€“8638.
[13] Kyunghyun Cho et al .2014. Learning phrase representations using RNN encoder-
decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014).
[14] Ekin D Cubuk et al .2020. Randaugment: Practical automated data augmentation
with a reduced search space. In CVPR Workshop. 702â€“703.
[15] Lucas de Carvalho Pagliosa and Rodrigo Fernandes de Mello. 2018. Semi-
supervised time series classification on positive and unlabeled problems using
cross-recurrence quantification analysis. Pattern Recognition 80 (2018), 53â€“63.
[16] Terrance DeVries and Graham W Taylor. 2017. Improved regularization of
convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552
(2017).
[17] William R Dieter et al .2005. Power reduction by varying sampling rate. In ISLPED.
227â€“232.
[18] NamÄ±k Kemal Eryol et al .2003. Effects of calcium treatment on QT interval and
QT dispersion in hypocalcemia. American Journal of Cardiology 91, 6 (2003),
750â€“2.
[19] Haoyi Fan et al .2021. Semi-supervised time series classification by temporal
relation prediction. In ICASSP. 3545â€“3549.
[20] Wei Fan et al .2022. DEPTS: Deep Expansion Learning for Periodic Time Series
Forecasting. In ICLR.
[21] Scott Fazackerley et al .2021. Efficient Flash Indexing for Time Series Data on
Memory-constrained Embedded Sensor Devices. In SENSORNETS. 92â€“99.
[22] Erik Fung et al .2015. Electrocardiographic patch devices and contemporary
wireless cardiac monitoring. Frontiers in Physiology 6 (2015).
[23] Ary L Goldberger et al .2000. PhysioBank, PhysioToolkit, and PhysioNet: compo-
nents of a new research resource for complex physiologic signals. Circulation
101, 23 (2000), e215â€“e220.
[24] Lukas Gorzelniak et al .2013. Does the low power mode of the actigraph GT3X+
accelerometer influence the device output in sleep research in healthy subjects?.
InMedInfo. 1172.
[25] Hassan Ismail Fawaz et al .2019. Deep learning for time series classification: a
review. Data Mining and Knowledge Discovery 33 (2019), 917â€“963.
[26] Brian Kenji Iwana and Seiichi Uchida. 2021. An empirical survey of data augmen-
tation for time series classification with neural networks. Plos One 16, 7 (2021),
e0254841.
[27] Shayan Jawed et al .2020. Self-supervised learning for semi-supervised time
series classification. In PAKDD. 499â€“511.
[28] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).[29] T Kurp et al .2012. Adaptive sensing for energy-efficient manufacturing system
and process monitoring. CIRP Journal of Manufacturing Science and Technology
5, 4 (2012), 328â€“336.
[30] Guokun Lai et al .2018. Modeling long-and short-term temporal patterns with
deep neural networks. In SIGIR. 95â€“104.
[31] Samuli Laine and Timo Aila. 2016. Temporal ensembling for semi-supervised
learning. arXiv preprint arXiv:1610.02242 (2016).
[32] Dong-Hyun Lee et al .2013. Pseudo-label: The simple and efficient semi-
supervised learning method for deep neural networks. In ICML Workshop.
[33] Jaewon Lee and Kyong Hwan Jin. 2022. Local texture estimator for implicit
representation function. In CVPR. 1929â€“1938.
[34] Jingyun Liang et al .2021. Swinir: Image restoration using swin transformer. In
ICCV. 1833â€“1844.
[35] Jason Lines and Anthony Bagnall. 2014. Ensembles of elastic distance measures
for time series classification. In SDM. 524â€“532.
[36] Shizhan Liu et al .2021. Pyraformer: Low-complexity pyramidal attention for
long-range time series modeling and forecasting. In ICLR.
[37] Ilya Loshchilov and Frank Hutter. 2016. SGDR: Stochastic gradient descent with
warm restarts. arXiv preprint arXiv:1608.03983 (2016).
[38] Ping Lou et al .2020. A data-driven adaptive sampling method based on edge
computing. Sensors 20, 8 (2020), 2174.
[39] Lars Mescheder et al .2019. Occupancy networks: Learning 3d reconstruction in
function space. In CVPR. 4460â€“4470.
[40] Xiaoye Miao et al .2021. Generative semi-supervised learning for multivariate
time series imputation. In AAAI. 8983â€“8991.
[41] Hangwei Qian et al .2021. Latent independent excitation for generalizable sensor-
based cross-person activity recognition. In AAAI. 11921â€“11929.
[42] Jinwen Qiu et al .2018. Multivariate Bayesian Structural Time Series Model.
Journal of Machine Learning Research 19, 1 (2018), 1â€“33.
[43] Matthew A Reyna et al .2021. Will two do? Varying dimensions in electrocar-
diography: the PhysioNet/Computing in Cardiology Challenge 2021. In 2021
Computing in Cardiology (CinC), Vol. 48. 1â€“4.
[44] Matthew A Reyna et al .2022. Issues in the automated classification of multilead
ECGs using heterogeneous labels and populations. Physiological Measurement
43, 8 (2022), 084001.
[45] Peter R Rijnbeek et al .2001. Minimum bandwidth requirements for recording of
pediatric electrocardiograms. Circulation 104, 25 (2001), 3087â€“3090.
[46] Burr Settles. 2009. Active learning literature survey. Technical Report 1648.
University of Wisconsin-Madison.
[47] Wenzhe Shi et al .2016. Real-time single image and video super-resolution using
an efficient sub-pixel convolutional neural network. In CVPR. 1874â€“1883.
[48] Yooju Shin et al .2023. Context consistency regularization for label sparsity in
time series. In ICML. 31579â€“31595.
[49] Satya Narayan Shukla and Benjamin M Marlin. 2021. Heteroscedastic Temporal
Variational Autoencoder For Irregularly Sampled Time Series. arXiv preprint
arXiv:2107.11350 (2021).
[50] Satya Narayan Shukla and Benjamin M Marlin. 2021. Multi-time attention
networks for irregularly sampled time series. arXiv preprint arXiv:2101.10318
(2021).
[51] Vincent Sitzmann et al .2020. Implicit neural representations with periodic
activation functions. In NeurIPS. 7462â€“7473.
[52] Kihyuk Sohn et al .2020. Fixmatch: Simplifying semi-supervised learning with
consistency and confidence. In NeurIPS. 596â€“608.
[53] Ilya Sutskever et al .2013. On the importance of initialization and momentum in
deep learning. In ICML. 1139â€“1147.
[54] Ashish Vaswani et al. 2017. Attention is all you need. In NeurIPS. 6000â€“6010.
[55] Haishuai Wang et al .2019. Time series feature learning with labeled and unlabeled
data. Pattern Recognition 89 (2019), 55â€“66.
[56] Yidong Wang et al .2022. Freematch: Self-adaptive thresholding for semi-
supervised learning. arXiv preprint arXiv:2205.07246 (2022).
[57] Gary M Weiss et al .2019. Smartphone and Smartwatch-Based Biometrics Using
Activities of Daily Living. IEEE Access 7 (2019), 133190â€“133202.
[58] Qingsong Wen et al .2022. Transformers in time series: A survey. arXiv preprint
arXiv:2202.07125 (2022).
[59] Gerald Woo et al .2022. CoST: Contrastive Learning of Disentangled Seasonal-
Trend Representations for Time Series Forecasting. In ICLR.
[60] Qiao Xiao et al .2023. Deep Learning-Based ECG Arrhythmia Classification: A
Systematic Review. Applied Sciences 13, 8 (2023), 4964.
 
68Semi-Supervised Learning for Time Series Collected at a Low Sampling Rate KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
A Datasets
Opportunity, InsectSound, and mHealth are widely-used public
datasets in time-series classification, while SAMSUNG is a pro-
prietary dataset obtained from a server monitoring system.
Opportunity [10] is a human activity recognition dataset measured
by wearable, object, and ambient sensors at a sampling rate of
30Hz. We preprocessed the dataset [ 41] and removed Null class
from the 18 original gesture classes: Open / Close Dishwasher /
Fridge / Drawer1(2,3) / Door1(2), Drink from Cup, Clean Table,
Toggle Switch, and Null.
InsectSound [11] consists of audio time-series data derived from
insect wingbeat to classify the species and determine the sex. It is
collected at a sampling rate of 6000Hz.
mHealth [4] records body motions and vital signs measured from
3D accelerometers, 3D gyroscopes, 3D magnetometers, and elec-
trocardiograms, sampled at a rate of 50Hz. It is categorized into 12
distinct activity classes: Stand, Sit, Lie, Walk, Upstairs, Waist Bend,
Raise Arms, Crouch, Cycle, Jog, Run, and Jump.
SAMSUNG consists of time-series data obtained from a server
monitoring system, collected every two minutes. The dataset is
labeled by the modules to which the servers belong.
B Details on Semi-Supervised Learning
Baselines
For augmentation strategies, FixMatch and FreeMatch utilize Ran-
dAugment [ 14], and ReMixMatch proposes CTAugment. However,
a time series is vulnerable to arbitrary augmentations due to its
diverse and unstationary distributions. Also, forcing invariances
which are appropriate to the image domain decreases downstream
task performance depending on the dataset [ 26]. Accordingly, we
selected the augmentation [ 6,16] that works well for each dataset,
as described in Table 9. Since unlabeled and labeled data share the
window size in typical semi-supervised learning, we downsample
the labeled high-sampling-rate data to have the same window size
with the unlabeled low-sampling-rate data.
Table 9: Augmentation strategy for semi-supervised learning
baselines.ğœ–is a Gaussian noise variable, ğ‘ is a scale factor,
andğ‘›,â„are the number of holes and the relative length of
the hole to the window.
Datasets W
eak Augmentation Str
ong Augmentation
Opp
ortunity jitterğœ–âˆ¼ğ‘(0,0.3) scaleğ‘ âˆ¼ğ‘(1.1,0.8)
Inse
ctSound cutoutğ‘›=1,
â„=0.1 cutout(
ğ‘›=2,
â„=0.1ğ›¾=1
2
ğ‘›=1,
â„=0.2ğ›¾âˆˆ(1
4,1
8)
mHealth jitterğœ–âˆ¼ğ‘(0,0.3) scaleğ‘ âˆ¼ğ‘(1.1,0.8)
SAMSUNG cutoutğ‘›=1,
â„=0.1 cutoutğ‘›=2,
â„=0.1
C Additional Experiments
Classification Accuracy on Different Classifier Backbones:
Table 10 compares the classification accuracy of SemiTSR and semi-
supervsied learning baselines as well as fully supervised learning
when the classifier backbone Mğ‘ğ‘™ğ‘ is Transformer. SemiTSR out-
performs the other semi-supervised learning baselines in various
datasets, low-sampling-rates, and labeled ratios.Table 10: Accuracy comparison of semi-supervised learning
methods when the classifier backbone is Transformer.
Metho
dOpp
ortunity mHealth
1/8
1/16 1/4
1/8
Fully-Sup
ervised(100%)65.06
62.59 91.35
92.68
(
Â±1.11) (Â±1.08)(
Â±1.40) (Â±1.82)
Fully-Supervised(20%)59.09
55.91 85.23
85.19
(
Â±2.74) (Â±1.61)(
Â±3.25) (Â±1.43)
FixMatch(20%)67.96
64.61 91.60
89.26
(
Â±2.55) (Â±0.91)(
Â±2.33) (Â±1.85)
FreeMatch(20%)67.71
65.50 92.43
89.85
(
Â±1.94) (Â±1.33)(
Â±4.57) (Â±1.84)
ReMixMatch(20%)68.72
66.13 94.79
94.26
(
Â±0.72) (Â±1.20)(
Â±1.14) (Â±2.41)
SemiTSR (20%)69.43
68.30 96.34
94.45
(
Â±2.02) (Â±1.29)(
Â±2.17) (Â±1.12)
Fully-Sup
ervised(10%)54.33
51.50 79.85
76.58
(
Â±2.70) (Â±1.09)(
Â±3.41) (Â±4.37)
FixMatch(10%)63.94
61.36 84.64
81.03
(
Â±2.29) (Â±1.83)(
Â±3.04) (Â±5.59)
FreeMatch(10%)65.10
62.93 88.04
84.01
(
Â±1.19) (Â±1.50)(
Â±2.84) (Â±5.40)
ReMixMatch(10%)68.32
64.70 88.29
86.22
(
Â±1.22) (Â±1.09)(
Â±3.58) (Â±6.16)
SemiTSR (10%)67.20 64.69 92.90
90.77
(
Â±1.13) (Â±1.00)(
Â±2.69) (Â±3.76)
Table 11: Inference time in seconds of low-sampling-rate data
classification and SemiTSR (reconstruction+classification).
Metho
d\Datasets Opp
ortunity(1/8) mHealth(1/8)
T
CN 0.00313
0.00409
SemiTSR 0.01161
0.01412
Table 12: Classification accuracy on high-sampling-rate data.
Metho
dLab
eled Ratio Sampling
Rate Opp
ortunity mHealth
T
CN 20% 1/165.01
92.26
(
Â±2.00) (Â±4 .80)
SemiTSR 20% 1/471.80
95.25
(
Â±1.50) (Â±2 .77)
SemiTSR 20% 1/871.41
93.21
(
Â±1.54) (Â±2 .72)
T
CN 10% 1/159.20
87.64
(
Â±1.80) (Â±3 .35)
SemiTSR 10% 1/466.22
90.93
(
Â±3.14) (Â±2 .32)
SemiTSR 10% 1/865.41
91.24
(
Â±3.20) (Â±3 .30)
Computation Efficiency: We evaluated the inference time, in
seconds, for the classification model and SemiTSR , which involves
the classification model subsequent to the reconstruction model.
Both the classification model and SemiTSR use the low-sampling-
rate data as their input. We used Opportunity andmHealth due to
their largest feature dimensionality and sequence length. Table 11
shows the results. When the sampling rate is 1/8, SemiTSR took
 
69KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Minyoung Bae, Yooju Shin, Youngeun Nam, Young Seop Lee, and Jae-Gil Lee
Table 13: MSE comparison of our temporal upsampler and the others based on the same deep feature encoder.
Lab
eled Ratio UpsmaplerOpp
ortunity Inse
ctSound mHealth SAMSUNG
1/2
1/4 1/8 1/16 1/2
1/4 1/8 1/2
1/4 1/8 1/2
1/4 1/8
20%Sub-Pixel
Conv0.1296
0.3035 0.5124 0.6799 0.1364
0.5431 1.1083 0.1735
0.2893 0.4140 0.0147
0.0228 0.0300
(
Â±0.0046) (Â±0 .0009) (Â±0 .0063) (Â±0 .0057)(
Â±0.0024) (Â±0 .0132) (Â±0 .0362)(
Â±0.0130) (Â±0 .0034) (Â±0 .0206)(
Â±0.0003) (Â±0 .0002) (Â±0 .0007)
LTE0.1072
0.2792 0.5185 0.8056 0.1487
0.5328 0.9469 0.1674
0.3045 0.4567 0.0150
0.0232 0.0300
(
Â±0.0000) (Â±0 .0004) (Â±0 .0005) (Â±0 .0019)(
Â±0.0009) (Â±0 .0023) (Â±0 .0408)(
Â±0.0054) (Â±0 .0038) (Â±0 .0110)(
Â±0.0008) (Â±0 .0009) (Â±0 .0008)
SemiTSR0.1179
0.2811 0.4795 0.6290 0.1352
0.5288 1.0023 0.1659
0.2836 0.3930 0.0147 0.0249
0.0307
(
Â±0.0006) (Â±0 .0017) (Â±0 .0082) (Â±0 .0025)(
Â±0.0005) (Â±0 .0083) (Â±0 .0225)(
Â±0.0066) (Â±0 .0044) (Â±0 .0039)(
Â±0.0007) (Â±0 .0010) (Â±0 .0013)
10%Sub-Pixel
Conv0.1414
0.3308 0.5444 0.7132 0.1573
0.5494 1.1530 0.1833
0.3062 0.4257 0.0150
0.0241 0.0305
(
Â±0.0074) (Â±0 .0159) (Â±0 .0057) (Â±0 .0039)(
Â±0.0409) (Â±0 .0125) (Â±0 .0176)(
Â±0.0170) (Â±0 .0043) (Â±0 .0062)(
Â±0.0002) (Â±0 .0001) (Â±0 .0005)
LTE0.1072
0.2792 0.5186 0.8057 0.1503 0.5341 1.0233 0.1684 0.3066
0.4609 0.0156 0.0231
0.0304
(
Â±0.0000) (Â±0 .0004) (Â±0 .0005) (Â±0 .0019)(
Â±0.0009) (Â±0 .0028) (Â±0 .0442)(
Â±0.0065) (Â±0 .0035) (Â±0 .0115)(
Â±0.0008) (Â±0 .0005) (Â±0 .0006)
SemiTSR0.1225
0.3030 0.5028 0.6971 0.1357 0.5368 0.9588 0.1724 0.2905
0.3599 0.0149 0.0258
0.0316
(
Â±0.0030) (Â±0 .0090) (Â±0 .0066) (Â±0 .0449)(
Â±0.0005) (Â±0 .0122) (Â±0 .0329)(
Â±0.0101) (Â±0 .0044) (Â±0 .0439)(
Â±0.0007) (Â±0 .0011) (Â±0 .0009)
Reconstruction Ground Truth Lowest MSE
Sub-Pixel Convolution
LTE
Temporal Upsampler
Figure 11: Visualization of InsectSound reconstruction using
different upsampling methods. ğ›¾is1
8andğ‘™is 10%. The two
columns are different instances.
Reconstruction Ground Truth Lowest MSE
Sub-Pixel Convolution
LTE
Temporal UpsamplerFigure 12: Visualization of mHealth reconstruction using dif-
ferent upsampling methods. ğ›¾is1
8andğ‘™is 10% . The two
columns are different instances.
3.45â€“3.71 times longer than the classification model only with low-
sampling-rate data. Because the inference time per batch takes
8.5â€“10ms longer, it is worthwhile to incur the additional cost for
saving storage and network load while simultaneously increasing
accuracy. The train time is also linear to the inference time.
Classification Accuracy on High-Sampling-Rate Data: While
our primary focus is on classifying low-sampling-rate data to reduce
the costs associated with data gathering and labeling, our approach
can also be applied in the mixed sampling-rates inference. We
additionally conducted inference on high-sampling-rate data using
the classification module of SemiTSR , which is trained with both
the low-sampling-rate and high-sampling-rate data. As evident in
Table 12, the performance of inference on high-sampling-rate data,
when trained using SemiTSR , surpasses that of fully-supervised
learning across all labeled ratios.D Additional Analysis on Reconstruction
Quality
Table 13 shows the mean squared error of the reconstructed and
ground-truth high-sampling-rate time series using various upsam-
plers. The temporal upsampler exhibited lower reconstruction error
than the other methods in more than half of the combinations. It
is obvious that the high classification accuracy in Table 5 is partly
attributed to the high reconstruction quality in Table 13. In the
meantime, the temporal upsampler was unable to achieve the low-
est reconstruction error despite having the highest classification
accuracy in certain combinations. We conjecture that this incon-
sistency is due to the fact that a low reconstruction error does not
always guarantee a high reconstruction quality. In the first column
of Figure 11, LTE exhibits the lowest reconstruction MSE despite
predicting the frequency incorrectly. The second column of Figure
12 also shows that overly smoothed reconstruction of LTE has the
lowest reconstruction MSE, while the temporal upsampler restores
the meaningful periodicity.
 
70