Communication-efficient Multi-service Mobile Traffic Prediction
by Leveraging Cross-service Correlations
Zhiying Feng
School of Computer Science and
Engineering
Sun Yat-sen University
Guangzhou, China
fengzhy26@mail2.sysu.edu.cnQiong Wu
Department of Electronic and
Computer Engineering
Hong Kong University of Science and
Technology
Hong Kong, China
eeqiongwu@ust.hkXu Chenâˆ—
School of Computer Science and
Engineering
Sun Yat-sen University
Guangzhou, China
chenxu35@mail.sysu.edu.cn
Abstract
Mobile traffic prediction plays a crucial role in enabling efficient
network management and service provisioning. Traditional predic-
tion approaches treat different mobile application services (such
as Uber, Facebook, Twitter, etc) as isolated entities, neglecting po-
tential correlation among them. Moreover, such isolated prediction
methods necessitate the uploading of historical traffic data from
all regions to forecast city-wide traffic, resulting in consuming
substantial bandwidth resources and risking prediction failure in
the event of data loss in specific regions. To address these chal-
lenges, we propose a novel Cross-service Attention-based Spatial-
Temporal Graph Convolutional Network (CsASTGCN) for precise
and communication-efficient multi-service mobile traffic prediction.
Our methodology allows each mobile service to transmit the traffic
data of only a fraction of regions for city-wide traffic prediction of
all mobile services, which reduces the resource consumption caused
by data transmission. Specifically, the sparse traffic data are initially
transmitted to the cloud server and the masked graph autoencoder
is utilized to roughly reconstruct the traffic volume for regions with
missing data. Subsequently, a cross-service attention-based predic-
tor is designed to calculate the data correlation among different
mobile services within the same region. Considering the constantly
emerging mobile services, we incorporate a novel model-based
adaptive transfer learning scheme to extract valuable knowledge
from the existing models and expedite the training of a new model
for a new service without training from scratch, thereby enhancing
the scalability of our framework. Extensive experiments conducted
on a large-scale real-world mobile traffic dataset demonstrate that
our model greatly outperforms the existing schemes, enhancing
both the communication-efficiency and robustness of large-scale
multi-service traffic prediction.
âˆ—Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671730CCS Concepts
â€¢Computing methodologies â†’Neural networks; Cooperation
and coordination ;â€¢Mathematics of computing â†’Time series
analysis.
Keywords
mobile traffic prediction; cross-service fusion; transfer learning;
attention-based mechanism; graph convolutional network.
ACM Reference Format:
Zhiying Feng, Qiong Wu, and Xu Chen. 2024. Communication-efficient
Multi-service Mobile Traffic Prediction by Leveraging Cross-service Corre-
lations. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain.
ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671730
1 Introduction
With the enhancement of mobile device hardware performance and
the evolution of new-generation communication technology, mo-
bile services installed on these devices have become more diverse
and intricately integrated into the daily lives of ordinary people.
Accurately predicting the traffic volume of mobile services is par-
ticularly crucial for both efficient business management and city
management. Firstly, precise mobile traffic prediction aids service
providers in gaining a better understanding of user demands and
behavioral habits. Analyzing data such as the number of users,
frequency of use, and usage time of mobile services allows ser-
vice providers to glean insights into usersâ€™ lifestyles, consumption
habits, and hobbies in different regions. This information, in turn,
enables providers to allocate resources more effectively and en-
hance the quality of service (QoS) [ 12]. Secondly, mobile service
traffic prediction assists city management departments in obtain-
ing a clearer picture of the cityâ€™s operational status and providing
a scientific basis by estimating socio-economic indicators, urban
traffic conditions, public safety and so on.
The traffic patterns of mobile services display periodic, inter-
mittent, regional, and dynamic characteristics over time. Some re-
searchers capture the above characteristics and propose prediction
methods for a single mobile service [ 8,12,29,39]. Different from
the above research, some researchers consider the multi-service
prediction scenarios by utilizing the complex relationship of the
traffic patterns of different services [ 22,32,37]. Regardless of single-
service or multi-service scenario, these methods rely on the funda-
mental assumption that all historical data are complete and readily
available. Based on the above assumption, the previous methods
 
794
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Zhiying Feng, Qiong Wu, and Xu Chen
allow each mobile service to make predictions using its own histor-
ical data during model inference stage, which ignores the benefits
of inherent correlation among various mobile services for model
inference. However, the assumption of data integrity would not
be fully satisfied in reality, due to occasional data loss during the
data transmission. For a specific mobile service, when the assump-
tion of data integrity cannot be guaranteed, the previous methods
fail to obtain additional information from other mobile services to
compensate for prediction errors caused by missing data, leading
to predictive performance degradation or even prediction failures.
Even if data loss does not occur, collecting and transmitting histor-
ical traffic data of all regions across the entire city to the remote
cloud server in real time requires significantly large amount of ex-
pensive communication bandwidth and the transmission overhead
is further magnified due to the long transmission delay of Wide
Area Network (WAN) and potential network congestion [36].
In this work, we aim to address the following fundamental issue:
can we leverage the data correlations among different mobile
services to reduce the amount of data transmission while
achieving accurate multi-service traffic prediction? To this
end, we delve into a solution capable of integrating predictions from
various mobile services within a unified framework and propose
a novel cross-service traffic prediction scheme, which is shown in
Figure 1. We break the basic assumption of data integrity mentioned
above and propose a novel method to handle the situation of incom-
plete data, no matter passive data loss or active data abandonment.
To address this challenge, we consider the cross-service correlation
during both the model training and inference stages to achieve
information exchange and fusion among different mobile services.
Specifically, we devise the Cross-service Attention-based Spatial-
Temporal Graph Convolutional Network (CsASTGCN), which si-
multaneously integrates temporal correlation, spatial correlation,
and cross-service correlation of the traffic data in a unified manner.
Temporal convolution is leveraged to capture time-dependent pat-
terns of the historical traffic trends. Graph Convolutional Network
(GCN) is employed to handle spatial correlations, considering the in-
terconnected relationships among different regions within the same
mobile service. To incorporate cross-service correlations, attention
mechanism allows the model to adaptively weigh the influence
of various mobile services on the prediction. This comprehensive
approach addresses the challenges posed by missing historical data
in specific regions, achieving precise and communication-efficient
traffic prediction. Within this framework, diverse mobile services
can efficiently transmit and complement information, leading to
benefits such as reduced data transmission volume and enhanced
training efficiency without sacrificing prediction accuracy.
Furthermore, in order to improve the scalability and training
efficiency of the proposed framework, we further propose a novel
model-based adaptive personalized transfer learning scheme to
extract valuable knowledge from the models of existing mobile
services and expedite the training of the model of a newly-operated
mobile service without training from scratch. The model for the new
mobile service seamlessly integrates into the original CsASTGCN
framework without requiring alterations to the model structure or
parameters of existing mobile services.
In summary, the major contributions of this paper are as follows:
Remote 
Server 2Remote 
Server 2
Remote 
Server SRemote 
Server SRemote 
Server 1Remote 
Server 1
Mobile Service 1
Mobile Service 2
Mobile Service  S
City Topology
Mask
Mask
MaskFigure 1: The illustration of the proposed cross-service traffic
prediction scheme.
â€¢We propose a novel cross-service traffic prediction model
CsASTGCN that integrates the traffic prediction of multiple
mobile services into a unified framework, achieving efficient
information transmission and fusion among different mobile
services.
â€¢We jointly integrates temporal correlation, spatial correla-
tion, and cross-service correlation in a holistic manner into
the proposed CsASTGCN model to reduce data transmission
volume without sacrificing prediction accuracy.
â€¢We propose a novel model-based adaptive personalized trans-
fer learning scheme to extract valuable knowledge from the
existing models and expedite the training of a new model
without starting from scratch, thereby enhancing the train-
ing efficiency and the scalability of our framework.
â€¢Extensive experiments conducted on a large-scale realistic
dataset reveal that our CsASTGCN model significantly out-
performs the baseline methods, proving that our proposed
framework can achieve superior prediction performance
with high communication efficiency (e.g., over 40% trans-
mission cost reduction and lower prediction error than the
baselines).
The rest of this paper is organized as follows. Section 2 gives a
detailed description of multi-service traffic dataset and the problem
formulation of cross-service mobile traffic prediction. Section 3
presents the details of our proposed CsASTGCN model. Based on
our prediction model, we design the model-based adaptive person-
alized transfer learning scheme in Section 4. Section 5 shows the
extensive experiments. We finally conclude the paper in Section 6.
2 Data Analysis and Problem Formulation
In this section, we first give the data description and detailed anal-
ysis of mobile traffic datasets of different mobile services, and then
elaborate the problem formulation of multi-service traffic predic-
tion.
 
795Communication-efficient Multi-service Mobile Traffic Prediction by Leveraging Cross-service Correlations KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
2.1 Multi-service Traffic Dataset Description
The multi-service traffic dataset we study in this paper is provided
by the renowned network operator Orange [ 18], which encom-
passes records of spatio-temporal consumption for 68 popular mo-
bile services across 20 cities in France. The geographical area of
each city in France is partitioned into several regions in the form
of a grid structure, each measuring 100m Ã—100m. The sampling
frequency is set as 15 minutes per sampling point. The dataset spans
77 consecutive days from March 16, 2019, to May 31, 2019.
Diversity and similarity coexist in mobile service traffic pattern
among different regions. For example, in Figure 2, we plot the
Twitter download traffic of four regions in Paris from 00:00 to 24:00
on April 1, 2019, where Tile 103950 and Tile 103951 are adjacent
regions, and so are Tile 81451 and Tile 81105. The traffic volume
and trends of adjacent regions exhibit similarity. The trend of traffic
changes in regions that are far apart can also be similar, but there
may be notable differences in traffic volume. It can be seen that for
the same mobile service, its traffic changes have similar periodicity,
but due to differences in population density in different regions and
other reasons, the traffic volume often have large differences.
00:00 02:00 04:00 06:00 08:00 10:00 12:00 14:00 16:00 18:00 20:00 22:00 24:00
Time (h)104105106Netflix Mobile T raffic (MB)Tile 103950 Tile 103951 Tile 81451 Tile 81105
Figure 2: The download traffic of Twitter of different regions
on April 1, 2019.
As depicted in Figure 3(a), the traffic series of four mobile ser-
vices, including Twitter, Uber, Facebook Like, and Spotify, display
similar periodicity. To quantify this correlation among different
service traffic, we introduce the widely used correlation coefficient
defined as shown in Eq. (1). The values of correlation coefficient in
Figure 3(b) indicate a significant difference in correlation among
various mobile services, ranging from a maximum of 0.8 to a mini-
mum of only 0.22. It can be clearly told that the correlation indeed
exists among different mobile services. The degree of cross-service
correlation depends, to a certain extent, on the similarity of types
of mobile services, For example, both Facebook Live and Twitter
belong to social media services, so they have a high correlation.
On the contrary, Uber and Spotify are respectively car-hailing apps
and streaming music service platforms, so they have a low correla-
tion. This differentiated correlation can be utilized for mobile traffic
prediction.
ğ‘Ÿğ‘¥ğ‘¦=Ã
ğ‘–(ğ‘¥ğ‘–âˆ’Â¯ğ‘¥)(ğ‘¦ğ‘–âˆ’Â¯ğ‘¦)âˆšï¸Ã
ğ‘–(ğ‘¥ğ‘–âˆ’Â¯ğ‘¥)2Ã(ğ‘¦ğ‘–âˆ’Â¯ğ‘¦)2. (1)
0 20 40 60 80 100 120 140
Time(h)0.00.20.40.60.81.01.21.4Normalized Mobile TrafficTwitter
Uber
Facebook_Live
Spotify(a)
T witterUber
F acebook_LiveSpotifyT witter
Uber
F acebook_Live
Spotify1 0.4 0.8 0.51
0.4 1 0.38 0.22
0.8 0.38 1 0.62
0.51 0.22 0.62 1
0.30.40.50.60.70.80.91.0 (b)
Figure 3: Traffic data (a) and correlation coefficient heat map
(b) of different mobile services in a given region in Paris.
2.2 Problem Formulation
The geographical area of a city can be divided into ğ‘€regions,
and these regions are denoted as M={1,2,...,ğ‘€}. The set of
mobile services are denoted as S={1,2,...,ğ‘†}. For each region
ğ‘£âˆˆM , the traffic volume of mobile service ğ‘ âˆˆS at time slot ğ‘¡
can be represented as ğ‘¦ğ‘¡ğ‘£,ğ‘ . We aim to predict the traffic demand of
mobile service ğ‘ in regionğ‘£at time slotğ‘¡+1given 1) the previous
ğ‘ƒobserved traffic data of service ğ‘ in regionğ‘£,yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡ğ‘£,ğ‘  ; 2) the
previousğ‘ƒobserved traffic data of other relative services in region
ğ‘£,yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘£,ğ‘ŸâˆˆS\ğ‘ ; 3) the previous ğ‘ƒobserved traffic data of service ğ‘ in
other regions, yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ ; and 4) the previous ğ‘ƒobserved traffic
data of other relative services in other regions, yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ŸâˆˆS\ğ‘ . The
mobile service traffic prediction problem can be formulated as
ğ‘¦ğ‘¡+1
ğ‘£,ğ‘ =F(yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘£,ğ‘ ,yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘£,ğ‘ŸâˆˆS\ğ‘ ,yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ ,yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ŸâˆˆS\ğ‘ ).(2)
However, in real-world scenarios, collecting traffic data for all
mobile services in each region and transmitting it to the remote
server is costly, and ensuring data integrity is often a challenge.
Based on the above considerations, we aim to achieve accurate and
robust prediction of mobile service traffic data when input data is
sparse. Therefore, the problem of Eq. (2) can be further expressed
as
ğ‘¦ğ‘¡+1
ğ‘£,ğ‘ =F(eyğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘£,ğ‘ ,eyğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘£,ğ‘ŸâˆˆS\ğ‘ ,eyğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ ,eyğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ŸâˆˆS\ğ‘ ),(3)
whereeyğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡ğ‘£,ğ‘  =yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡ğ‘£,ğ‘ âŠ™Mask ğ‘ ,eyğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘£,ğ‘ŸâˆˆS\ğ‘ =yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘£,ğ‘ŸâˆˆS\ğ‘ âŠ™Mask ğ‘ŸâˆˆS\ğ‘ ,
eyğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ =yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ âŠ™Mask ğ‘ ,eyğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ŸâˆˆS\ğ‘ =yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘¢âˆˆM\ ğ‘£,ğ‘ŸâˆˆS\ğ‘ âŠ™
Mask ğ‘ŸâˆˆS\ğ‘ .Mask ğ‘ andMask ğ‘ŸâˆˆS\ğ‘ denotes the random mask ma-
trix of mobile service ğ‘ and mobile service ğ‘Ÿ, which contain the infor-
mation about the region with missing data and âŠ™is the Hadamard
product.
3 CsASTGCN Framework For Cross-service
Traffic Prediction
In this section, we introduce the proposed cross-service traffic pre-
diction scheme, CsASTGCN. Initially, we discuss the construction
of the spatial relation graph. Subsequently, we provide an overview
of the CsASTGCN framework. Then, we present the detailed design
 
796KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Zhiying Feng, Qiong Wu, and Xu Chen
of the masked graph feature reconstruction module and the cross-
service attention based predictor. Finally, we provide the detail of
the adaptive masking strategy.
3.1 Construction of Spatial Relation Graph
The grid structure of the city divides the city into several regions
from a geographical perspective. For a given region, the grid struc-
ture can only obtain information from surrounding regions, and
cannot obtain information from regions that are far apart but have
similar traffic patterns. Therefore, the cityâ€™s grid structure must
undergo transformation into a graph structure based on specific
criteria to achieve more effective information transmission among
different regions. In this research, we consider two criteria: 1) the
distance of geographical location; 2) the similarity of historical traf-
fic series, to transform the grid structure into graph structure. For
ğ‘£âˆˆM , theğ¾geoclosest regions to ğ‘£will be established edge with ğ‘£.
Besides, by calculating the cosine similarity [ 30] of historical traffic
series data of different regions, the ğ¾simregions with the highest
similarity to ğ‘£are obtained, and then they are established edge with
ğ‘£. Therefore, each region will be connected to at most ğ¾geo+ğ¾sim
other regions. This relation graph can reflect the spatial relationship
among regions considering both the geographical distance and the
data similarity. Based on the above graph construction method, we
construct the spatial relation graph of each mobile service. For each
mobile service ğ‘ , we derive the adjacency matrix Ağ‘ and the degree
matrix eDğ‘ .
3.2 Overview of CsASTGCN Framework
Given the spatial relation graphs of all mobile services, we propose
CsASTGCN framework for precise multi-service traffic prediction,
which consists of two key module, the masked feature reconstruc-
tion module and the cross-service attention based predictor. The
graph data with some nodes (e.g., regions) masked are first fed into
the masked feature reconstruction module. Then the features of
masked nodes are reconstructed, forming a reconstructed graph.
Following masked feature reconstruction, the reconstructed graph
is fed into the cross-service attention based predictor, which consist
of the spatial-temporal feature extractor and attention-based coor-
dinator. Each mobile service utilizes the spatial-temporal feature
extractor to obtain their node embedding synchronously. In order
to improve the prediction performance by leveraging cross-service
correlations, each mobile service exchanges its own node embed-
ding with other mobile services, and achieves cross-service fusion
and collaboration under the attention-based coordinator. Finally,
the final prediction results are obtained through a fully connected
layer. The diagram of the CsASTGCN framework is illustrated in
Figure 4.
3.3 Masked Feature Reconstruction
In this context, we consider historical traffic data as the nodesâ€™
features to form the feature matrix H(0)
ğ‘ . Considering the issues of
data loss and high transmission overhead, we opt for transmitting
a sparse graph instead of a complete graph for further processing.
Nevertheless, directly inputting this sparse graph into the predictor
can lead to substantial errors. Hence, it is crucial to reconstruct the
masked features initially. Inspired by the approach presented in [ 13],we first mask the features of randomly selected nodes in the feature
matrix H(0)
ğ‘ and then incorporate a masked graph autoencoder to
address the reconstruction of masked features. This autoencoder
comprises an encoder and a decoder. The process of generating
reconstructed features can be represented as follows:
Hğ‘ ,mask=ğ‘“encoder(H(0)
ğ‘ ,mask,eAğ‘ ), (4)
Zğ‘ ,mask=ğ‘“decoder(Hğ‘ ,mask,eAğ‘ ), (5)
where H(0)
ğ‘ ,mask=H(0)
ğ‘ âŠ™Mask ğ‘ is original masked features, eAğ‘ =
Ağ‘ +Iğ‘€, and Iğ‘€is theğ‘€-dimensional identity matrix.
The object of masked feature reconstruction is to minimize the
mean squared error (MSE) between the original features H(0)
ğ‘ and
the reconstructed features Zğ‘ ,mask. The backbones of the encoder
and the decoder can be any type of GNNs, such as GCN[ 2], GAT[ 28],
or GIN[ 31]. In this research, we use GCN as the backbones of both
the encoder and the decoder. The total layers of encoder and decoder
areğ¿MFR, Eq. (4) and Eq. (5) can be transffered into Eq. (6) and Eq.
(7).
H(ğ‘™+1)
ğ‘ ,mask=ğœ(eDâˆ’1
2
ğ‘ ,maskeAğ‘ eDâˆ’1
2
ğ‘ ,maskH(ğ‘™)
ğ‘ ,maskW(ğ‘™)
ğ‘ ,mask), (6)
Zğ‘ ,mask=H(ğ¿MFR)
ğ‘ ,mask, (7)
where H(ğ‘™)
ğ‘ ,maskis theğ‘™th layer output of mobile serivce ğ‘ â€™s masked
graph autoencoer, and W(ğ‘™)
ğ‘ ,maskis the trainable matrix of the ğ‘™th
layer of mobile service ğ‘ â€™s masked graph autoencoder.
3.4 Cross-service Attention based Predictor
In this section, we propose a novel predictor that can jointly inte-
grates temporal correlation, spatial correlation, and cross-service
correlation in a holistic manner and introduce the spatial-temporal
feature extractor and attention-based coordinator separately below.
By regarding time series data as a one-channel and one-dimensional
image, we first use the temporal convolutional layers to extract the
temporal features of nodes. Inspired by [ 34], we combine three tem-
poral convolutional layers as a whole to form a temporal-convolutional
block. Specifically, for the service ğ‘ in regionğ‘£, given the input xğ‘£,ğ‘ ,
the output of temporal convolutional block can be formulated as:
ğ‘œTC1
ğ‘£,ğ‘ =ğ‘“TC1 xğ‘£,ğ‘ ;ğœƒTC1, (8)
ğ‘œTC2
ğ‘£,ğ‘ =ğ‘“TC2 xğ‘£,ğ‘ ;ğœƒTC2, (9)
ğ‘œTC3
ğ‘£,ğ‘ =ğ‘“TC3
ğ‘œTC1
ğ‘£,ğ‘ +ğœsigmoid
ğ‘œTC2
ğ‘£,ğ‘ 
;ğœƒTC3
, (10)
ğ‘œTC
ğ‘£,ğ‘ =ğœrelu
ğ‘œTC3
ğ‘£,ğ‘ 
, (11)
whereğœƒTC1,ğœƒTC2andğœƒTC3are the trainable parameters of these
three temporal convolutional layers, ğœreluandğœsigmoid are the relu
and sigmoid activation function.
After the above processing, all nodes form a new graph O(TC)
ğ‘ ,
containing the temporal features. We use a graph convolutional
layer to extract the spatial features of nodes. For service ğ‘ , given the
 
797Communication-efficient Multi-service Mobile Traffic Prediction by Leveraging Cross-service Correlations KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
â€¦â€¦Node 1 Node 2
Node M
Attention -based 
Coordinator
Attention -based 
Coordinator
Graph ConstructionSpatial -temporal Feature 
Extracto nCross-service Fusion
The nodes with real 
featuresThe nodes without dataThe nodes with 
reconstructed features
Figure 4: The proposed CsASTGCN framework.
adjacency matrix eAğ‘ , the feature extraction formula of the graph
convolutional layer is calculated as follows:
Eğ‘ =ğœ(eDâˆ’1
2ğ‘ eAğ‘ eDâˆ’1
2ğ‘ O(TC)
ğ‘ Wğ‘ ), (12)
where Eğ‘ is the output of the graph convolutional layer, Wğ‘ is the
trainable parameters of the graph convolutional layer. The feature
of serviceğ‘ in regionğ‘£ofEğ‘ can be expressed as eğ‘£,ğ‘ . We combine
a graph convolution layer with a temporal convolutional block to
create a spatio-temporal block. We stack several spatio-temporal
blocks as a spatial-temporal feature extractor to extract the node
embedding.
The masked feature reconstruction module outlined above effec-
tively addresses the majority of missing data by relying on infor-
mation from the adjacent nodes and the nodes with similar traffic
pattern within the same service, which are often not completely
consistent with the real data. To enhance prediction accuracy, we
further propose cross-service attention based predictor to utilize
the correlation among different mobile services, because the traffic
data of distinct mobile services in the same region is correlated,
as illustrated in in Figure 3. Therefore, we introduce the attention
mechanism [27] to automatically learn this correlation and utilize
it to enhance prediction accuracy. As far as we know, we are the
first to exploit cross-service correlations to handle multi-service
mobile traffic prediction. It is worth noting that the methodology
introduced in our paper is distinct from the approach described in
[11], where attention mechanism is used to capture the dynamic
spatial-temporal correlations in traffic data. Specifically, for mobile
serviceğ‘ in regionğ‘£, the query vector, the key vector, and the value
vector are calculated as follows:
qğ‘£,ğ‘ =W(ğ‘ )
query eğ‘£,ğ‘ , (13)
kğ‘£,ğ‘ =W(ğ‘ )
keyeğ‘£,ğ‘ . (14)
vğ‘£,ğ‘ =W(ğ‘ )
valueeğ‘£,ğ‘ , (15)
where W(ğ‘ )
query ,W(ğ‘ )
key, and W(ğ‘ )
valueâˆˆRğ‘‘Ã—ğ‘ƒare trainable matrix, eğ‘£,ğ‘ 
is the node embedding of service ğ‘ in regionğ‘£after the extraction
of spatial-temporal feature extractor.For the mobile service ğ‘Ÿ, we multiplies its own W(ğ‘Ÿ)
keyand the
node embedding eğ‘£,ğ‘Ÿto obtain the key vector kğ‘£,ğ‘Ÿ=W(ğ‘Ÿ)
keyeğ‘£,ğ‘Ÿ. The
attention coefficient of service ğ‘Ÿtowards service ğ‘ is calculated as
the inner product of qğ‘£,ğ‘ andkğ‘£,ğ‘Ÿ:
ğ›¼ğ‘¡
ğ‘£,ğ‘ ,ğ‘Ÿ=qTğ‘£,ğ‘ kğ‘£,ğ‘Ÿâˆš
ğ‘‘. (16)
In addition to considering the correlation of data between the
target service and other collaborative services, we take into account
the proportion of real nodes and reconstructed nodes of the mobile
services. For a specific node ğ‘£of mobile service ğ‘ , the higher the
proportion of real data of itself and its adjacent nodes, the greater
weight we should assign to this service. Therefore, we define ğ›½ğ‘¡ğ‘£,ğ‘Ÿ
as the proportion of real data in region ğ‘£with its adjacent regions
of mobile service ğ‘Ÿ. The normalized attention coefficient of service
ğ‘Ÿtowards service ğ‘ is calculated using softmax function as follows:
Ë†ğ›¼ğ‘¡
ğ‘£,ğ‘ ,ğ‘Ÿ=exp(ğœsigmoid(ğ›¼ğ‘¡ğ‘£,ğ‘ ,ğ‘Ÿ)ğ›½ğ‘¡ğ‘£,ğ‘Ÿ)
Ã
ğ‘–âˆˆSexp(ğœsigmoid(ğ›¼ğ‘¡
ğ‘£,ğ‘ ,ğ‘–)ğ›½ğ‘¡
ğ‘£,ğ‘–). (17)
The impact of all other mobile services on a specific service ğ‘ is
calculated by weighted aggregation as follows:
Ë†eğ‘£,ğ‘ =âˆ‘ï¸
ğ‘ŸâˆˆSË†ğ›¼ğ‘¡
ğ‘£,ğ‘ ,ğ‘Ÿvğ‘£,ğ‘Ÿ,(18)
where Ë†eğ‘£,ğ‘ is the collaborative embedding of other services towards
serviceğ‘ . For the service ğ‘ in regionğ‘£, the collaborative embedding
Ë†eğ‘£,ğ‘ is fed into the MLP to predict the mobile traffic demand ğ‘¦ğ‘¡+1ğ‘£,ğ‘ 
as shown in Eq. (19).
ğ‘¦ğ‘¡+1
ğ‘£,ğ‘ =MLP(Ë†eğ‘£,ğ‘ ). (19)
3.5 Adaptive Masking Strategy
In our quest to enhance the robustness and efficiency of the training
process, we employ a dynamic approach to adjust the composition
ofMask ğ‘ by leveraging the loss values associated with each trained
node. Specifically, with a given mask rate ğ›¾ğ‘ , we selectively mask
out theğ›¾ğ‘ of nodes displaying the lowest training loss values, which
helps mitigate their influence on subsequent iterations. Conversely,
 
798KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Zhiying Feng, Qiong Wu, and Xu Chen
the remaining 1âˆ’ğ›¾ğ‘ of nodes with the highest training loss val-
ues are retained, prioritizing their contributions to the modelâ€™s
parameter updates.
This strategy is grounded in the idea that nodes with higher
training losses may contain more valuable information for model
performance improvement. It introduces an adaptive element to
the optimization process, to refine the modelâ€™s focus on nodes with
potentially richer gradients, which contributes to overall training
efficiency and enhances the modelâ€™s ability to capture intricate pat-
terns in the data. Moreover, considering nodes with higher training
losses as more challenging to converge, providing raw data for their
training becomes essential. The proposed methodology embodies
a data-driven paradigm for updating Mask ğ‘ , utilizing the inherent
information within individual nodesâ€™ loss values to guide the model
towards more effective convergence. The training process of our
proposed CsASTGCN framework is summarized in Algorithm 1.
Algorithm 1: The training process of CsASTGCN
Input:
â€¢The training dataset yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡ğ‘£,ğ‘  ,âˆ€ğ‘ âˆˆS, ğ‘£âˆˆM .
â€¢The learning rate ğœ‚.
â€¢The mask rate ğ›¾ğ‘ .
â€¢The total training rounds ğ‘‡.
â€¢The mask matrix update cycle ğ‘¡mask.
forğ‘ âˆˆS in parallel do
Initialize the CsASTGCN model W(0)
ğ‘ .
Initialize the mask matrix Mask(0)
ğ‘ with the mask rate ğ›¾ğ‘ .
end
forğ‘¡=0,1, ...,ğ‘‡âˆ’1do
forğ‘ âˆˆS in parallel do
Obtain the node embedding by feeding the training
samples into the spatial-temporal feature extractor:
Eğ‘¡ğ‘ ={eğ‘¡ğ‘£,ğ‘ |âˆ€ğ‘£âˆˆM }
end
Mobile service ğ‘ performs model training W(ğ‘¡+1)
ğ‘  =
W(ğ‘¡)
ğ‘ âˆ’ğœ‚âˆ‡W(ğ‘¡)
ğ‘ Lğ‘¡
yğ‘¡âˆ’ğ‘ƒ+1:ğ‘¡
ğ‘£âˆˆM,ğ‘ âˆˆS,Mask(ğ‘¡)
ğ‘ ,Eğ‘¡
ğ‘ŸâˆˆS\ğ‘ ;W(ğ‘¡)
ğ‘ 
ifğ‘¡%ğ‘¡mask==0then
Mobile service ğ‘ performs model training and get the
training loss of all nodes loss(ğ‘¡).
Sort the loss(ğ‘¡)in ascending order and get the sorted list
Id(ğ‘¡)
sortedof nodes id.
forğ‘–ğ‘‘=Id(ğ‘¡)
sorted[0 :ğ‘€âˆ—ğ›¾ğ‘ ]do
Mask(ğ‘¡)
ğ‘ [ğ‘–ğ‘‘]=1
end
forğ‘–ğ‘‘=Id(ğ‘¡)
sorted[ğ‘€âˆ—ğ›¾ğ‘ :]do
Mask(ğ‘¡)
ğ‘ [ğ‘–ğ‘‘]=0
end
end
else
Mask(ğ‘¡)
ğ‘ =Mask(ğ‘¡âˆ’1)
ğ‘ 
end
end
Output: Mask(ğ‘‡)
ğ‘ ,Ws(ğ‘‡)4 Model-based Adaptive Personalized Transfer
Learning Scheme
When tasked with training a new model for a fresh mobile service,
transfer learning allows us to glean valuable knowledge from sev-
eral existing local models, thereby avoiding the need to start train-
ing from scratch and significantly enhancing training efficiency.
Through transfer learning, we hope to achieve the following three
goals: 1) A higher starting point: before fine-tuning, the initial per-
formance of the transfer model is higher than training from scratch.
2) Faster convergence speed: the model for a new service conver-
gences faster by fine-tuning the transferred model of an existing
service. 3) Better final model: the convergence performance of the
final model after fine-tuning is better than that without transfer
learning. As shown in Figure 3, there are significant differences in
the correlation among different mobile services. The importance
of knowledge transferred for the new models varies among the
existing models. In alignment with these objectives, we design a
novel model-based adaptive personalized transfer learning scheme.
This proposed transfer learning approach calculates the correlation
between different source services and the target service through
exploratory training. It then utilizes gradient descent to adjust the
transfer weights of different source services for different layers.
The detailed training process of the proposed adaptive transfer
learning scheme is elaborated in Figure 5, which contains three
main steps.
Step 1. Transfer model aggregation. The source model of
mobile service ğ‘–is denoted as Wğ‘–. The transfer strategy can be
expressed as Î˜ğ‘¡=
Î˜ğ‘¡
1,...,Î˜ğ‘¡
ğ‘–,...,Î˜ğ‘¡
ğ‘†
, where Î˜ğ‘¡
ğ‘–is the matrix with
the same size of Wğ‘–. The transfer model can be calculated as
Wğ‘¡
ğ‘†+1=ğ‘†âˆ‘ï¸
ğ‘–=1Î˜ğ‘¡
ğ‘–âŠ™Wğ‘–, (20)
where the elements of Î˜ğ‘¡
ğ‘–are all initialized as1
ğ‘†,âˆ€ğ‘–.
Step 2. Loss calculation. Use the local dataset Dğ‘†+1of mobile
serviceğ‘†+1 to calculate the loss value Lğ‘¡(Î˜ğ‘¡;W1,...,Wğ‘†)of the
current transfer model.
Step 3. Transfer strategy update. The parameters of source
models Wğ‘¡
1,Wğ‘¡
2,...,Wğ‘¡
ğ‘†are frozen. The transfer strategy is updated
as
Ë†Î˜ğ‘¡
ğ‘–=Î˜ğ‘¡
ğ‘–âˆ’ğœ‚âˆ‡Î˜ğ‘¡
ğ‘–Lğ‘¡
=Î˜ğ‘¡
ğ‘–âˆ’ğœ‚Wğ‘–âŠ™âˆ‡Wğ‘¡
ğ‘†+1Lğ‘¡.(21)
Step 4. Normalization. The transfer strategy is normalized
using softmax function:
Î˜ğ‘¡+1
ğ‘–,ğ‘™=exp(Ë†Î˜ğ‘¡
ğ‘–,ğ‘™)
Ãğ‘†
ğ‘–=1exp(Ë†Î˜ğ‘¡
ğ‘–,ğ‘™),âˆ€ğ‘–,ğ‘™, (22)
where Ë†Î˜ğ‘¡
ğ‘–,ğ‘™is theğ‘™th layer of Ë†Î˜ğ‘¡
ğ‘–.
The above steps are executed repeatedly until the target number
of training rounds is reached. It is worth noting that the total num-
ber of the exploratory training rounds is limited compared with
the following fine-tuning.
The suggested adaptive transfer learning method provides a
flexible means to expand the scale of the CsASTGCN framework.
 
799Communication-efficient Multi-service Mobile Traffic Prediction by Leveraging Cross-service Correlations KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Source 
Service 1Source 
Service 2Source 
Service S
Server...Transfer 
ModelNew 
Service ...
Transfer
Masked Feature 
Reconstruct ionGround 
Truth
Predictor
Masked Feature 
Reconstruct ionPredictor
Source 
Service 1
Source 
Service 2
Source 
Service S
Figure 5: The workflow of model-based adaptive personalized
transfer learning scheme.
Expanding on the principles of transfer learning for a single mo-
bile service, we introduce a progressive transfer learning scheme
tailored for multiple mobile services. Assume the original CsAST-
GCN framework comprises ğ‘†mobile services, with ğ‘†newupcoming
mobile services awaiting integration into the CsASTGCN frame-
work. We transfer the knowledge of ğ‘†models under the original
CsASTGCN framework to one new mobile service, creating a cor-
responding new model, and subsequently integrating it into the
updated CsASTGCN framework. Following this analogy, we iter-
ate through the transfer of new models one by one until all ğ‘†new
services are successfully assimilated into the CsASTGCN frame-
work. The comparison between our proposed progressive transfer
learning method and the traditional transfer learning method is
shown in Figure 6. The advantage of our progressive transfer learn-
ing method is that it can gradually expand the diversity of mobile
services within the CsASTGCN framework, thereby enriching the
potential knowledge learned by subsequent mobile services that re-
quire knowledge transfer and accelerating the subsequent training
process.
5 Experiments
5.1 Experimental Settings
Due to computing resource limitations in our research lab, we opt
to use data from 01/04/2019 to 30/04/2019 (30 days) for training
and testing. In the experiment, the first 80% and the last 20% of
the dataset are designated as the training set and testing set, re-
spectively. For the performance evaluation, we choose 4 mobile
services including Twitter, Uber, Facebook Live, Spotify in two city
including Paris and Bordeaux, for the collaborative learning. Be-
sides, we select Twitter, Uber, Facebook Live, Spotify as the source
domain and Facebook Messenger as the target domain to evaluate
the performance of the proposed adaptive transfer learning method.
Baselines. We compare our proposed method with the following
widely used methods:
â€¢Historical average (HA): HA predicts the value using the
average of previous mobile traffic demand of the given region
in the same relative time interval (i.e., the same time of the
day) [33].
TransferOriginal CsASTGCN 
Framework(a)
TransferOriginal CsASTGCN 
Framework
(b)
Figure 6: The workflow of progressive transfer learning
scheme (a) and traditional transfer learning scheme (b),
where each circle represents a mobile service.
â€¢STGCN: STGCN is a time series prediction method that con-
siders the graph structure. This method does not consider
the correlation among different mobile services [34].
â€¢LSTM: Long Short-Term Memory (LSTM) is a type of re-
current neural network architecture designed to effectively
capture and retain long-range dependencies in sequential
data, making it well-suited for tasks such as time series pre-
diction and natural language processing [26].
â€¢CNN-LSTM: CNN and LSTM are integrated into a model to
capture spatial dependency and temporal relationship in a
holistic manner [14].
Evaluation Metrics. We evaluate our model with Mean Absolute
Error (MAE) and Root Mean Squared Error (RMSE), which are
defined as follows:
ğ‘€ğ´ğ¸ =1
ğ‘§ğ‘§âˆ‘ï¸
ğ‘–=1|Ë†ğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–|, (23)
ğ‘…ğ‘€ğ´ğ¸ =vt
1
ğ‘§ğ‘§âˆ‘ï¸
ğ‘–=1(Ë†ğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–)2, (24)
where Ë†ğ‘¦ğ‘–is the predicted value, ğ‘¦ğ‘–is the ground truth, and ğ‘§is the
total number of predicted samples.
5.2 Prediction Results
Performance Comparison. We standardized the transmission cost of
all baselines at 100%, implying that the baselines can make predic-
tions using the complete data. In our CsASTGCN scheme, we vary
the data integrity rates (e.g., transmission cost) to 60%, 70%, and
80%, respectively. As depicted in Figure 7(a), CsASTGCN consis-
tently outperforms all baselines with significantly lower transmis-
sion costs, achieving the lowest average MAE (3,999) and average
RMAE (6,696) in Paris. Illustrated in Figure 7(b), CsASTGCN also
outperforms all baselines with notably reduced transmission costs,
resulting in the lowest average MAE (288) and average RMAE (378)
 
800KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Zhiying Feng, Qiong Wu, and Xu Chen
in Bordeaux. Although the MAE and RMAE of STGCN are compa-
rable to CsASTGCN in both Paris and Bordeaux, the transmission
cost is considerably higher than that of CsASTGCN.
Furthermore, for visual illustration, we plot the ground truth and
predicted values of a given region in Paris in Figure 8. It shows that
most predicted values generated by CsASTGCN are much closer
to the corresponding ground truth throughout the time period
compared to other baselines.
HA
LSTM
CNN-LSTMSTGCN
CsASTGCN CsASTGCN CsASTGCN020004000600080001000012000MAE/RMAEMAE
RMAE
6065707580859095100
T ransmission  Costs(%)T ransmission Costs
(a) Paris
HA
LSTM
CNN-LSTMSTGCN
CsASTGCN CsASTGCN CsASTGCN0100200300400500MAE/RMAEMAE
RMAE
6065707580859095100
T ransmission  Costs(%)T ransmission Costs (b) Bordeaux
Figure 7: The prediction performance and tranmisssion cost
comparison with different baselines.
Robust analysis. To clearly demonstrate the superiority of CsAST-
GCN, we delve into a robust analysis of various prediction methods.
In this section, we assess how the prediction error of different
methods changes as the proportion of uploaded data decreases.
Specifically, we randomly selected 0%, 20%, 30%, and 40% of the
nodes in the testing set, respectively, as the missing/failure nodes,
by setting the historical traffic data of these nodes to 0. Figure 9
and Figure 10 illustrate that the MAE and RMAE of CsASTGCN
remain relatively stable and even slightly decrease as the mask rate
increases, while the performance of other baselines generally dete-
riorates. This verifies that CsASTGCN possesses the nice property
of robustness.
5.3 Effect of Attention Mechanism
To validate the effectiveness of the attention mechanism, we com-
pare the prediction results of our CsASTGCN model with and with-
out the attention mechanism. As shown in Table 1 and Table 2, the
CsASTGCN model exhibited significant improvements in predic-
tion accuracy and performance metrics when attention mechanisms
were incorporated. Specifically, CsASTGCN achieved an average
performance gain of more than 9% and 5% over CsASTGCN without
attention in terms of MAE and RMAE under different mask rates.
Table 1: Comparison With Different Baselines in Paris.
Mask rate
training/testingMethod MAE RMAE
30%/20%CsASTGCN w/o attention 4398 7080
CsASTGCN 3808 6486
40%/30%CsASTGCN w/o attention 4381 7066
CsASTGCN 3729 6484
50%/40%CsASTGCN w/o attention 4416 7125
CsASTGCN 3774 6536Table 2: Comparison With Different Baselines in Bordeaux.
Mask rate
training/testingMethod MAE RMAE
30%/20%CsASTGCN w/o attention 312 391
CsASTGCN 250 330
40%/30%CsASTGCN w/o attention 322 403
CsASTGCN 250 330
50%/40%CsASTGCN w/o attention 327 406
CsASTGCN 256 336
5.4 Performance of Transfer Learning
In Figure 11 and Figure 12, we depict the training loss for masked
graph autoencoder and he proposed predictor under various trans-
fer methods, where the global model is obtained by taking a simple
average of the model parameters from the source domain models.
The adaptive model is obtained from our proposed model-based
adaptive personalized transfer learning scheme. It is clear that our
adaptive transfer learning method can let the target model better
learn the useful knowledge from different models in a personalized
way.
To verify the effectiveness of the proposed progressive tranfer
learning method, we select Twitter, Uber, Facebook Live, and Spotify
as the source services, and select Facebook Messenger, Netflix, and
YouTube as the target services. We compare the number of train-
ing rounds required for progressive transfer and non-progressive
transfer to reduce to the same training error. Table 3 and Table 4
show that as the number of mobile services incorporated into the
CsASTGCN framework increases, the number of rounds required
for subsequent model training to reach the target training error
decreases.
The experimental results highlight the effectiveness of trans-
ferring knowledge from our model-based adaptive personalized
transfer learning scheme to enhance the performance of the new
mobile service. This approach not only streamlines the learning
process for the new mobile service but also underscores the sig-
nificance of leveraging pre-existing knowledge to achieve optimal
results. The above results demonstrate the scalability of the method
proposed in this paper. Through adaptive transfer learning, the
scale of mobile services for collaborative training and inference can
be rapidly expanded.
Table 3: The training rounds of masked graph autoencoder
request for training to target training loss (0.6 for the first
service, 0.4 for the second service, 0.3 for the third service).
MethodsRequired Training Rounds
The 1st Service The 2nd Service The 3rd Service
Progressive 17 5 2
Non-Progressive 17 14 9
6 Conclusion
The proposed Cross-service Attention-based Spatial-Temporal Graph
Convolutional Network (CsASTGCN) integrates multiple mobile
services into a unified prediction framework. The information fu-
sion among mobile services and implementing adaptive transfer
 
801Communication-efficient Multi-service Mobile Traffic Prediction by Leveraging Cross-service Correlations KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
0 100 200 300 400 500
Time05000100001500020000250003000035000Mobile TrafficGround truth
HA
CsASTGCN
(a)
0 100 200 300 400 500
Time05000100001500020000250003000035000Mobile T rafficGround truth
LSTM
CsASTGCN (b)
0 100 200 300 400 500
Time05000100001500020000250003000035000Mobile T rafficGround truth
CNN-LSTM
CsASTGCN (c)
0 100 200 300 400 500
Time05000100001500020000250003000035000Mobile T rafficGround truth
STGCN
CsASTGCN (d)
Figure 8: The ground truth and predicted values for all methods of a given region, where our CsASTGCN only transmits 60%
data, and other baselines transmit 100% data.
0 10 20 30 40
Mask Rate(%)400060008000100001200014000MAEHA
STGCN
LSTM
CNN-LSTM
CsASTGCN
(a)
0 10 20 30 40
Mask Rate(%)6000800010000120001400016000RMAEHA
STGCN
LSTM
CNN-LSTM
CsASTGCN (b)
Figure 9: The Robust analysis with different baselines of
Paris.
0 10 20 30 40
Mask Rate(%)300400500600700MAEHA
STGCN
LSTM
CNN-LSTM
CsASTGCN
(a)
0 10 20 30 40
Mask Rate(%)400500600700RMAEHA
STGCN
LSTM
CNN-LSTM
CsASTGCN (b)
Figure 10: The Robust analysis with different baselines of
Bordeaux.
0 2 4 6 8 10 12 14 16 18 20
R ounds0.650.700.750.800.850.900.951.00T raining lossT raining from random initialization
T ransfer from global model
T ransfer from adaptive model
(a) Paris
0 2 4 6 8 10 12 14 16 18 20
R ounds0.500.550.600.650.700.750.800.850.90T raining lossT raining from random initialization
T ransfer from global model
T ransfer from adaptive model (b) Bordeaux
Figure 11: The masked graph autoencoderâ€™s training loss of
a new mobile service under different transfer method.
learning provides a promising solution to communication chal-
lenges in multi-service traffic prediction and improve the scalability
of the proposed framework. Our model demonstrates superior ac-
curacy and real-time performance compared to traditional methods.
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
R ounds300320340360380400T raining lossT raining from random initialization
T ransfer from global model
T ransfer from adaptive model(a) Paris
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
R ounds240260280300320340T raining lossT raining from random initialization
T ransfer from global model
T ransfer from adaptive model (b) Bordeaux
Figure 12: The predictorâ€™s training loss of a new mobile ser-
vice under different transfer method.
Table 4: The training rounds of the predictor request for
training to target training loss (330 for the first service, 280
for the second service, 200 for the third service)
.
MethodsRequired Training Rounds
The 1st Service The 2nd Service The 3rd Service
Progressive 6 3 2
Non-Progressive 6 4 3
The incorporation of a masked graph autoencoder, cross-service
attention based predictor, and a novel transfer learning scheme
contributes to its effectiveness. Our extensive experiments on a
real-world dataset showcase the modelâ€™s robustness and scalability,
making CsASTGCN a valuable advancement in large-scale cross-
service traffic prediction for information-based cities. Future re-
search directions could focus on further optimizing the structure
and algorithms of the CsASTGCN model by integrating the latest
deep learning techniques, such as Transformer, federated learn-
ing, etc., to enhance its computational efficiency and prediction
accuracy.
7 Acknowledge
This research was performed using data made available by Or-
ange within the NetMob 2023 Data Challenge. This work was sup-
ported in part by the National Science Foundation of China (No.
U20A20159); Guangdong Basic and Applied Basic Research Foun-
dation (No. 2023B1515120058, No. 2021B151520008); Guangzhou
Basic and Applied Basic Research Program (No. 2024A04J6367).
 
802KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Zhiying Feng, Qiong Wu, and Xu Chen
References
[1]Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez,
Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam
Santoro, Ryan Faulkner, et al. 2018. Relational Inductive Biases, Deep Learning,
and Graph Networks. arXiv preprint arXiv:1806.01261 (2018).
[2]Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, and Yaliang Li. 2020.
Simple and Deep Graph Convolutional Networks. In Proceedings of International
Conference on Machine Learning (ICML). PMLR, 1725â€“1735.
[3]Yitian Chen, Yanfei Kang, Yixiong Chen, and Zizhuo Wang. 2020. Probabilistic
Forecasting with Temporal Convolutional Neural Network. Neurocomputing 399
(2020), 491â€“501.
[4]Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and Yong Yu. 2007. Co-clustering
based Classification for Out-of-domain Documents. In Proceedings of the 13th
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
(KDD). 210â€“219.
[5]Wenyuan Dai, Qiang Yang, Gui-Rong Xue, and Yong Yu. 2007. Boosting for
Transfer Learning. In Proceedings of International Conference on Machine learning
(ICML). 193â€“200.
[6]Shimin Di, Yanyan Shen, and Lei Chen. 2019. Relation Extraction via Domain-
aware Transfer Learning. In Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining (KDD). 1348â€“1357.
[7]Lixin Duan, Dong Xu, and Ivor Wai-Hung Tsang. 2012. Domain Adaptation
from Multiple Sources: A Domain-dependent Regularization Approach. IEEE
Transactions on Neural Networks and Learning Systems 23, 3 (2012), 504â€“518.
[8]Luoyang Fang, Xiang Cheng, Haonan Wang, and Liuqing Yang. 2018. Mobile
Demand Forecasting via Deep Graph-sequence Spatiotemporal Modeling in
Cellular Networks. IEEE Internet of Things Journal 5, 4 (2018), 3091â€“3101.
[9]Jie Feng, Xinlei Chen, Rundong Gao, Ming Zeng, and Yong Li. 2018. Deeptp: An
End-to-end Neural Network for Mobile Cellular Traffic Prediction. IEEE Network
32, 6 (2018), 108â€“115.
[10] Jing Gao, Wei Fan, Jing Jiang, and Jiawei Han. 2008. Knowledge Transfer via
Multiple Model Local Structure Mapping. In Proceedings of the 14th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining (KDD). 283â€“
291.
[11] Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan. 2019.
Attention based Spatial-temporal Graph Convolutional Networks for Traffic
Flow Forecasting. In Proceedings of the AAAI Conference on Artificial Intelligence
(AAAI). 922â€“929.
[12] Kaiwen He, Xu Chen, Qiong Wu, Shuai Yu, and Zhi Zhou. 2020. Graph Attention
Spatial-temporal Network with Collaborative Global-local Learning for Citywide
Mobile Traffic Prediction. IEEE Transactions on Mobile Computing 21, 4 (2020),
1244â€“1256.
[13] Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang,
and Jie Tang. 2022. Graphmae: Self-supervised Masked Graph Autoencoders. In
Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining (KDD). 594â€“604.
[14] Chih-Wei Huang, Chiu-Ti Chiang, and Qiuhui Li. 2017. A Study of Deep Learning
Networks on Mobile Traffic Forecasting. In Proceedings of IEEE 28th Annual
International Symposium on Personal, Indoor, and Mobile Radio Communications
(PIMRC). 1â€“6.
[15] Hyun-Woo Kim, Jun-Hui Lee, Yong-Hoon Choi, Young-Uk Chung, and Hyukjoon
Lee. 2011. Dynamic Bandwidth Provisioning using ARIMA-based Traffic Fore-
casting for Mobile WiMAX. Computer Communications 34, 1 (2011), 99â€“106.
[16] Colin Lea, Michael D Flynn, Rene Vidal, Austin Reiter, and Gregory D Hager.
2017. Temporal Convolutional Networks for Action Segmentation and Detection.
InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
(CVPR). 156â€“165.
[17] Yu Li, Ziang Ma, Zhiwen Pan, Nan Liu, and Xiaohu You. 2020. Prophet Model and
Gaussian Process Regression based User Traffic Prediction in Wireless Networks.
Science China Information Sciences 63 (2020), 1â€“8.
[18] Orlando E MartÃ­nez-Durive, Sachit Mishra, Cezary Ziemlicki, Stefania Rubrichi,
Zbigniew Smoreda, and Marco Fiore. 2023. The NetMob23 Dataset: A High-
resolution Multi-region Service-level Mobile Data Traffic Cartography. arXiv
preprint arXiv:2305.06933 (2023).
[19] Lilyana Mihalkova, Tuyen Huynh, and Raymond J Mooney. 2007. Mapping and
Revising Markov Logic Networks for Transfer Learning. In Proceedings of AAAI
Conference on Artificial Intelligence (AAAI). 608â€“614.
[20] Lilyana Mihalkova and Raymond J Mooney. 2008. Transfer Learning by Mapping
with Minimal Target Data. In Proceedings of the AAAI Workshop on Transfer
Learning for Complex Tasks. 31â€“36.
[21] Sinno Jialin Pan and Qiang Yang. 2009. A Survey on Transfer Learning. IEEE
Transactions on Knowledge and Data Engineering 22, 10 (2009), 1345â€“1359.
[22] Arcangela Rago, Giuseppe Piro, Gennaro Boggia, and Paolo Dini. 2020. Multi-Task
Learning at the Mobile Edge: An Effective Way to Combine Traffic Classification
and Prediction. IEEE Transactions on Vehicular Technology 69, 9 (2020), 10362â€“
10374.
[23] Qian Sun, Rita Chattopadhyay, Sethuraman Panchanathan, and Jieping Ye. 2011.
A Two-stage Weighting Framework for Multi-source Domain Adaptation. Pro-
ceedings of Advances in Neural Information Processing Systems (NeurIPS), 505â€“513.[24] Chuanqi Tan, Fuchun Sun, Tao Kong, Wenchang Zhang, Chao Yang, and Chun-
fang Liu. 2018. A Survey on Deep Transfer Learning. In International Conference
on Artificial Neural Networks (ICANN). Springer, 270â€“279.
[25] Denis Tikunov and Toshikazu Nishimura. 2007. Traffic Prediction for Mobile Net-
work using Holt-Winterâ€™s Exponential Smoothing. In Proceedings of International
Conference on Software, Telecommunications and Computer Networks (SoftCOM).
IEEE, 1â€“5.
[26] Hoang Duy Trinh, Lorenza Giupponi, and Paolo Dini. 2018. Mobile Traffic Pre-
diction from Raw Data using LSTM Networks. In Proceedings of IEEE 29th Annual
International Symposium on Personal, Indoor and Mobile Radio Communications
(PIMRC). IEEE, 1827â€“1832.
[27] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is All
You Need. In Proceedings of Advances in Neural Information Processing Systems
(NeurIPS). 5998â€“6008.
[28] Petar VeliÄkoviÄ‡, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Lio, and Yoshua Bengio. 2017. Graph Attention Networks. arXiv preprint
arXiv:1710.10903 (2017).
[29] Zi Wang, Jia Hu, Geyong Min, Zhiwei Zhao, Zheng Chang, and Zhe Wang. 2022.
Spatial-temporal Cellular Traffic Prediction for 5G and Beyond: A Graph Neural
Networks-based Approach. IEEE Transactions on Industrial Informatics 19, 4
(2022), 5722â€“5731.
[30] Peipei Xia, Li Zhang, and Fanzhang Li. 2015. Learning Similarity with Cosine
Similarity Ensemble. Information sciences 307 (2015), 39â€“52.
[31] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How Powerful
Are Graph Neural Networks? arXiv preprint arXiv:1810.00826 (2018).
[32] Luyang Xu, Haoyu Liu, Junping Song, Rui Li, Yahui Hu, Xu Zhou, and Paul
Patras. 2023. TransMUSE: Transferable Traffic Prediction in Multi-service Edge
Networks. Computer Networks 221 (2023), 109518.
[33] Huaxiu Yao, Fei Wu, Jintao Ke, Xianfeng Tang, Yitian Jia, Siyu Lu, Pinghua Gong,
Jieping Ye, and Zhenhui Li. 2018. Deep Multi-view Spatial-temporal Network
for Taxi Demand Prediction. In Proceedings of the AAAI Conference on Artificial
Intelligence (AAAI). 2588â€“2595.
[34] Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-temporal Graph Con-
volutional Networks: A Deep Learning Framework for Traffic Forecasting. In
Proceedings of International Joint Conference on Artificial Intelligence (IJCAI).
3634â€“3640.
[35] Yanhua Yu, Jun Wang, Meina Song, and Junde Song. 2010. Network Traffic
Prediction and Result Analysis based on Seasonal ARIMA and Correlation Co-
efficient. In Proceedings of International Conference on Intelligent System Design
and Engineering Application (ISDA). IEEE, 980â€“983.
[36] Liekang Zeng, Xu Chen, Peng Huang, Ke Luo, Xiaoxi Zhang, and Zhi Zhou. 2023.
Serving Graph Neural Networks With Distributed Fog Servers for Smart IoT
Services. IEEE/ACM Transactions on Networking (2023), 1â€“16.
[37] Chaoyun Zhang, Marco Fiore, and Paul Patras. 2019. Multi-Service Mobile Traffic
Forecasting via Convolutional Long Short-Term Memories. In Proceedings of IEEE
International Symposium on Measurements & Networking (M&N). 1â€“6.
[38] Chuanting Zhang, Haixia Zhang, Dongfeng Yuan, and Minggao Zhang. 2018.
Citywide Cellular Traffic Prediction based on Densely Connected Convolutional
Neural Networks. IEEE Communications Letters 22, 8 (2018), 1656â€“1659.
[39] Nan Zhao, Zhiyang Ye, Yiyang Pei, Ying-Chang Liang, and Dusit Niyato. 2020.
Spatial-temporal Attention-convolution Network for Citywide Cellular Traffic
Prediction. IEEE Communications Letters 24, 11 (2020), 2532â€“2536.
8 Appendices
A Pseudo Code
We summarize details of the model-based adaptive personalized
transfer learning scheme in Algorithm 2.
B Related Works
B.1 Mobile Traffic Prediction
Initially, researchers utilized traditional time series prediction meth-
ods to mobile traffic prediction, such as ARIMA [ 15,35], Holt [ 25],
Prophet [ 17]. However, these conventional time series prediction
methods rely on classic statistical principles, making it challenging
to capture the nonlinear and intricate dependencies within mobile
service traffic data. Recent advances in deep learning models have
become strong competitors to classic statistical models in traffic
prediction [ 38]. Mobile service traffic prediction methods based
 
803Communication-efficient Multi-service Mobile Traffic Prediction by Leveraging Cross-service Correlations KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Algorithm 2: Model-based Adaptive Personalized Transfer
Learning Scheme
Input:
â€¢The local model of the source mobile services W1, ...,Wğ‘.
â€¢The learning rate ğœ‚.
â€¢The total training rounds ğ‘‡transfer.
â€¢The number of new mobile services ğ‘new.
Initialize: ğ‘current =ğ‘
forğ‘—=1,2, ..., ğ‘ newdo
Initialize the transfer strategy Î˜0with each element equal to
1
ğ‘current,âˆ€ğ‘–.
forğ‘¡=0,1, ...,ğ‘‡transferâˆ’1do
Calculate the transfer model:
Wğ‘¡
ğ‘current+1=Ãğ‘current
ğ‘–=1Î˜ğ‘¡âŠ™Wğ‘–.
Calculate the lossLğ‘¡(Î˜ğ‘¡;W1, ...,Wğ‘)based on the
current transfer strategy Î˜ğ‘¡.
forğ‘–=1,2, ..., ğ‘ current do
Update the transfer strategy as:
Ë†Î˜ğ‘¡
ğ‘–=Î˜ğ‘¡
ğ‘–âˆ’ğœ‚Wğ‘–âŠ™âˆ‡Wğ‘¡
ğ‘current+1Lğ‘¡.
end
forğ‘–=1,2, ..., ğ‘ current do
foreach layer ldo
Normalization: Î˜ğ‘¡+1
ğ‘–,ğ‘™=exp(Ë†Î˜ğ‘¡
ğ‘–,ğ‘™)
Ãğ‘
ğ‘–=1exp(Ë†Î˜ğ‘¡
ğ‘–,ğ‘™).
end
end
end
Fine-tune Wğ‘‡transfer
ğ‘current+1toË†Wğ‘current+1.
Expand the source domain:
Wğ‘current+1=Ë†Wğ‘current+1.
ğ‘current =ğ‘current+1,
end
Output: Ë†Wğ‘+1,Ë†Wğ‘+2,...,Ë†Wğ‘+ğ‘new
on deep learning can be roughly divided into RNN-based methods
[9,26] and CNN-based ones [ 38,39]. In [ 26], Trinh et al. employed
LSTM to predict the mobile traffic of an LTE base station. Feng et
al.introduced an end-to-end model to predict traffic demands from
spatial-dependent and long-period cellular traffic [ 9]. Most RNN
framework are autoregressive generative models, where a predic-
tion is generated by using the past observations, and the generated
result is then fed back as the ground truth to make further predic-
tion [ 3]. Consequently, RNN encounters challenges in large-scale
parallel processing. To improve the efficiency of time series predic-
tion, Lea et al. first proposed Temporal Convolutional Networks,
employing a hierarchy of temporal convolutions to handle time
series [ 16]. Inspired by [ 16], some researchers delve into the CNN-
based mobile service traffic prediction. Zhang et al. introduced a
densely connected CNN to learn spatial dependence and augment
feature propagation [ 38]. Zhao et al. proposed a spatial-temporal at-
tention convolution network to predict the citywide cellular traffic
[39]. Some researchers further leverage GNN to extract correlations
in mobile traffic across different regions [ 8,12,29]. Fang et al. pro-
posed to model the spatial relevancy among cells by a dependency
graph based on spatial distances among cells and applied GCN and
LSTM to model the spatial and temporal aspects, respectively [ 8].
Heet al. introduced Graph Attention Spatial-Temporal Networkfor precise mobile traffic prediction, where they built a spatial re-
lation graph based on the time series similarity of traffic demand
using the Dynamic Time Warping algorithm [ 12]. Wang et al. pro-
posed a TSGAN model, incorporating a time-series similarity-based
spatial information integration and graph attention networks for
cellular traffic prediction [ 29]. Different from the above research
that conducts mobile traffic prediction for a single service, some
researchers consider the multi-service prediction scenarios by uti-
lizing the complex relationship of the traffic patterns of different
services. For example, Zhang et al. combine sequence-to-sequence
(S2S) learning paradigm and convolutional long short-term memo-
ries (ConvLSTMs) to handle multi-service mobile traffic forecasting
[37]. Rago et al. combine multi-service traffic classification and
prediction into a whole task and use autoencoders as key building
blocks for common feature representations, shared by both classifi-
cation and prediction tasks [ 22]. Xu et al. divide different mobile
services into several clusters and employ a single model for each
service cluster, which can learn specific patterns corresponding to
the unique cluster features [32].
B.2 Transfer Learning
Transfer learning stands out as a crucial tool in machine learning for
addressing the fundamental issue of limited training data [ 24]. The
primary concept of transfer learning involves utilizing knowledge
from a pre-trained model on a source domain to aid in learning in
a different, but related, target domain. Transfer learning encom-
passes instance transfer, feature representation transfer, parameter
transfer, and relational knowledge transfer [ 21]. Instance transfer
involves directly assigning varying weights to different instances.
Daiet al. introduced TrAdaBoost, a method that re-weights source
domain instances to amplify the impact of favorable instances and
diminish the influence of unfavorable ones [ 5]. Sun et al. proposed
a two-stage weighting framework for multi-source domain adapta-
tion, involving re-weighting source domain instances based on both
instance and domain weights [ 23]. Feature representation transfer
maps data from diverse domains to a specific feature space, reduc-
ing domain divergence and model errors. Tzeng et al. introduced
an adaptation layer and an additional domain confusion loss to a
traditional CNN model, facilitating the learning of a representation
that is both semantically meaningful and domain-invariant. Dai
et al. advocated Co-Clustering-Based Classification for document
classification, incorporating a co-clustering algorithm to propagate
label information from the source to the target domain [ 4]. Parame-
ter transfer involves reusing model parameters from existing source
domain models to enhance performance in the target domain. Gao
et al. proposed a locally weighted ensemble learning framework to
combine multiple models of source domain, where the weights are
assigned based on a modelâ€™s predictive power on each test sample
in the target domain, rather than a global weighting for each model
[10]. Duan et al. presented a Domain Adaptation Machine frame-
work to construct a robust classifier for the target domain to ensure
similarity in decision values between the target classifier and rele-
vant base classifiers on unlabeled instances from the target domain
[7]. Relational knowledge transfer aims to transfer the relationships
among data from a source domain to a target domain. Mihalkova
et al. proposed a complete Markov Logic Networks transfer system
 
804KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Zhiying Feng, Qiong Wu, and Xu Chen
that transfers relational knowledge across relational domains as-
suming that the learner has access to information from the entire
graph [ 19] or only the bold relations are known to the learner [ 20].
DIet al. proposed Relation Extraction via Domain-aware Transfer
Learning, to extract relation mentions from a given text corpus byleveraging knowledge from existing databases [ 6]. Battaglia et al.
explored the integration of graph networks to capture relational
dependencies, underscoring the potential of relational approaches
in enhancing transfer learning [1].
 
805