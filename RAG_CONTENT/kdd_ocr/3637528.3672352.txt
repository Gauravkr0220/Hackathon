STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for
Variance Reduction in Online Controlled Experiments
Hao Zhouâˆ—
State Key Laboratory for Novel
Software Technology
Nanjing University
Nanjing, China
Meituan
Beijing, China
zhouhao29@meituan.comKun Sunâˆ—â€ 
Meituan
Beijing, China
sunkun07@meituan.comShaoming Li
Meituan
Beijing, China
shaoming.li@outlook.com
Yangfeng Fan
Meituan
Beijing, China
fanyangfeng@meituan.comGuibin Jiang
Meituan
Beijing, China
jiangguibin@meituan.comJiaqi Zheng
State Key Laboratory for Novel
Software Technology
Nanjing University
Nanjing, China
jzheng@nju.edu.cn
Tao Li
Meituan
Beijing, China
litao19@meituan.com
Abstract
Online controlled experiments play a crucial role in enabling data-
driven decisions across a wide range of companies. Variance re-
duction is an effective technique to improve the sensitivity of ex-
periments, achieving higher statistical power while using fewer
samples and shorter experimental periods. However, typical vari-
ance reduction methods (e.g., regression-adjusted estimators) are
built upon the intuitional assumption of Gaussian distributions and
cannot properly characterize the real business metrics with heavy-
tailed distributions. Furthermore, outliers diminish the correlation
between pre-experiment covariates and outcome metrics, greatly
limiting the effectiveness of variance reduction.
In this paper, we develop a novel framework that integrates the
Studentâ€™sğ‘¡-distribution with machine learning tools to fit heavy-
tailed metrics and construct a robust average treatment effect es-
timator in online controlled experiments, which we call STATE.
By adopting a variational EM method to optimize the loglikehood
function, we can infer a robust solution that greatly eliminates the
âˆ—Both authors contributed equally to this research.
â€ Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672352negative impact of outliers and achieves significant variance reduc-
tion. Moreover, we extend the STATE method from count metrics
to ratio metrics by utilizing linear transformation that preserves
unbiased estimation, whose variance reduction is more complex
but less investigated in existing works. Finally, both simulations
on synthetic data and long-term empirical results on Meituan ex-
periment platform demonstrate the effectiveness of our method.
Compared with the state-of-the-art estimators (CUPAC/MLRATE),
STATE achieves over 50% variance reduction, indicating it can reach
the same statistical power with only half of the observations, or
half the experimental duration.
CCS Concepts
â€¢Mathematics of computing â†’Probability and statistics ;â€¢Gen-
eral and reference â†’Experimentation .
Keywords
Controlled Experiments, Variance Reduction, Heavy-Tailed, Robust
Estimation, Causal Inference
ACM Reference Format:
Hao Zhou, Kun Sun, Shaoming Li, Yangfeng Fan, Guibin Jiang, Jiaqi Zheng,
and Tao Li. 2024. STATE: A Robust ATE Estimator of Heavy-Tailed Metrics
for Variance Reduction in Online Controlled Experiments. In Proceedings of
the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
10 pages. https://doi.org/10.1145/3637528.3672352
1 Introduction
Online controlled experiments (also known as A/B tests) are the
most widely adopted method for measuring causal effects, and
6380
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Hao Zhou et al.
play a crucial role in enabling data-driven decisions across a wide
range of companies, including Facebook [ 3,13], Airbnb [ 8,10],
Google [ 14], Microsoft [ 9] and LinkedIn [ 15,26]. These experiments
are critical for businesses, as even small differences detected in key
metrics can have significant implications for the total revenue [ 9].
For example, a strategy that increases one userâ€™s revenue by $0.1
can result in millions of dollars in the total revenue for ten million
users.
In the typical settings of controlled experiments, online traffic
is randomly partitioned into two groups: a treatment group and a
control group. They keep almost the same configuration except that
the treatment group receives an additional intervention (e.g., a new
production version or a promotion email). The average treatment
effect (ATE) measures the causal effect of a treatment or interven-
tion, but its groundtruth is unknown. Thanks to the central limit
theorem, the difference-in-means estimator (DIM) produces an un-
biased estimation of ATE, which is calculated by the difference
between the treatment and control group outcomes.
Although DIM offers unbiased estimates, it still suffers from
high variance, further leading to poor sensitivity and low statisti-
cal power. For online businesses, the sensitivity of experiments is
particularly important. With thousands of experiments run each
year, any benefits of increased sensitivity will be amplified due to
economies of scale. On the other hand, the improvement in sensi-
tivity allows experiments to be run on a smaller user population or
for shorter durations while achieving the same statistical power. It
is significant for improving the product feedback cycle and agility.
In mathematics, variance reduction techniques are used to ob-
tain higher precision for the metric of interest and have been in-
troduced to online controlled experiments recently. For examples,
CUPED [ 9] utilizes pre-experiment covariates to reduce metric vari-
ability between the treatment and control groups, constructing an
unbiased estimator with lower variance. However, the effectiveness
is limited by the linear assumption and the correlation between
the covariates and outcome metrics. Hence, to develop a nonlinear
multi-covariate proxy that is highly correlated with the outcome
metric, several machine learning (ML) based estimators have been
explored [ 2,13,15,24,25]. CUPAC [ 23] and MLRATE [ 13] are two
state-of-the-art (SOTA) estimators in this class, both of which are
based on the regression-adjusted method. To tackle the optimal-
ity, Yin [ 15] has demonstrated that if ML predicators converge to
the conditional mean function, the asymptotic variance of ATE
estimators can reach the semi-parametric variance lower bound.
Notably, the discussion on optimality is conducted under the
assumption that the regression residuals follow a Gaussian distri-
bution. However the business metrics of interest are often heavy-
tailed (e.g., watch time on video sites, user Gross Merchandise Vol-
ume(GMV) on e-commerce platforms, the amount of live broadcast
rewards, etc.). The observations for these metrics usually contain
some outliers (observations far away from the bulk of the probabil-
ity density). The significant impact of outliers on the squared loss
may lead to bias and high variance in the ATE estimates. As shown
in Fig. 1, the residuals of user GMV on the Meituan food delivery
platform exhibit a heavy-tailed distribution due to the presence of
users with extremely high-priced orders. In the Gaussian distribu-
tion, the probability of observations falling beyond six standarddeviations should be extremely small (less than 0.0000002%). How-
ever, it is obvious that a larger portion of the observations exceeds
six standard deviation in Fig. 1. Therefore, the Gaussian distribution
does not properly characterize heavy-tailed metrics.
Gaussian distribution fit
Student s t distribution fit
Real distribution
0.25% observations locate in [+6,+)
Figure 1: The distribution of residuals for user GMV on the
Meituan food delivery platform. The Y-axis represents the
sample count. The X-axis represents the residuals between
the real value and the model predicted value, where the ex-
tremely large values are clipped to the upper bound.
To address this problem, we introduce the Studentâ€™s ğ‘¡-distribution
to variance reduction. The Gaussian distribution is a special case of
theğ‘¡-distribution, corresponding to the situation where the degree
of freedom tend to infinity. As the degree of freedom decreases,
theğ‘¡-distribution has heavier tails, giving non-zero probability to
observations that fall outside the bulk of the density. This char-
acteristic endows the ğ‘¡-distribution with an important property
called robustness. As is shown in Fig. 1, the GMV metric can be
better characterized when the regression residuals are modeled as
a generalized ğ‘¡-distribution.
In this paper, we mainly focus on the variance reduction of
ATE estimation of heavy-tailed metrics, and propose an easy-to-
implement robust ATE estimator, called STATE. Specifically, our
work has the following key contributions.
â€¢We integrate the machine learning regression adjustment
method with the Studentâ€™s ğ‘¡-distribution to estimate ATE for
count metrics and derive a variational EM framework to infer
parameters. The estimation procedure takes full advantage
of both the powerful fitting ability of machine learning tools
and the robustness of the ğ‘¡-distribution to outliers, thereby
significantly reducing the variance of ATE estimation in
online controlled experiments.
â€¢We extend this method to ratio metrics, which are more
complex but less investigated. We introduce linear transfor-
mation for ratio metrics while preserve unbiased estimation
and consistent variance, under which regression-adjusted
methods and the Studentâ€™s ğ‘¡-distribution can be introduced
to reduce variance and improve sensitivity.
â€¢We conduct large-scale experiments on synthetic data and
real business data on the Meituan food delivery platform to
6381STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for Variance Reduction in Online Controlled Experiments KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
verify the effectiveness of our method in this paper. Exten-
sive experimental results demonstrate that when the met-
rics follow Gaussian distribution, the STATE method per-
forms equivalently to the state-of-the-art estimators (CU-
PAC/MLRATE). When the metric is a heavy-tailed distri-
bution, our method can reduce the variance by about 50%
compared to the CUPAC and MLRATE. This indicates that we
can achieve the same statistical power in online controlled
experiments with only half of the observations, or half the
experimental duration.
2 Setup and Related Work
2.1 Setup
Letğ‘‹be the pre-experiment covariates, ğ‘‡be the binary treat-
ment variable, and ğ‘Œ,ğ‘ be two outcome variables. In an online
controlled experiment, suppose that there are ğ‘samples denoted
by(ğ‘‹ğ‘–,ğ‘‡ğ‘–,ğ‘Œğ‘–,ğ‘ğ‘–), which are drawn independently from an identical
distribution. The treatment ğ‘‡âˆˆ{0,1}is assigned randomly and
independently of the covariates ğ‘‹, whereğ‘‡ğ‘–=1represents that the
ğ‘–-th sample receives the treatment. Denote the number of samples
withğ‘‡ğ‘–=1andğ‘‡ğ‘–=0byğ‘ğ‘¡andğ‘ğ‘, repectively. Following the
Rubin Causal Model (RCM) [ 21], letğ‘Œğ‘–(1),ğ‘ğ‘–(1),ğ‘Œğ‘–(0),ğ‘ğ‘–(0)be the
corresponding potential outcome when the sample is assigned with
the treatment or not.
The count metrics are defined as the sample means (e.g.,Ã
ğ‘‡ğ‘–=1ğ‘Œğ‘–
ğ‘ğ‘¡),
whose analysis unit is exactly the randomization unit in experi-
ments. The average treatment effect (ATE) for count metrics is
ğœğ‘=ğ¸[ğ‘Œğ‘–(1)]âˆ’ğ¸[ğ‘Œğ‘–(0)].
The common difference-in-mean (DIM) estimator is taken as
Î”ğ‘Œ=Ã
ğ‘‡ğ‘–=1ğ‘Œğ‘–
ğ‘ğ‘¡âˆ’Ã
ğ‘‡ğ‘–=0ğ‘Œğ‘–
ğ‘ğ‘. (1)
According to the central limit theorem, it gives an unbiased estima-
tion ofğœğ‘with the variance ğ·[Î”ğ‘Œ]=ğœ2
ğ‘¡/ğ‘ğ‘¡+ğœ2ğ‘/ğ‘ğ‘, whereğœ2
ğ‘¡,ğœ2ğ‘
are the variance of samples in the treatment group and control
group respectively.
The ratio metrics are usually regarded as the ratio of two count
metrics, e.g.,Ã
ğ‘‡ğ‘–=1ğ‘Œğ‘–Ã
ğ‘‡ğ‘–=1ğ‘ğ‘–. For ratio metrics, ATE is defined as
ğœğ‘Ÿ=ğ¸[ğ‘Œğ‘–(1)]
ğ¸[ğ‘ğ‘–(1)]âˆ’ğ¸[ğ‘Œğ‘–(0)]
ğ¸[ğ‘ğ‘–(0)].
The corresponding DIM estimator is
Î”ğ‘…=Ã
ğ‘‡ğ‘–=1ğ‘Œğ‘–Ã
ğ‘‡ğ‘–=1ğ‘ğ‘–âˆ’Ã
ğ‘‡ğ‘–=0ğ‘Œğ‘–Ã
ğ‘‡ğ‘–=0ğ‘ğ‘–. (2)
Notice that DIM is not an unbiased estimator because
ğ¸[Î”ğ‘…]â‰ ğœğ‘Ÿ.
Fortunately, it gives a consistent estimation for ğœğ‘Ÿaccording to the
delta method [7].
2.2 Related Work
Variance reduction is a key technology and a longstanding chal-
lenge to improve the sensitivity of online control experiments. The
original literatures mainly discuss the univariate linear adjustment
method [ 9,12,17,27]. For instance, the CUPED [ 9] estimator, whichis widely applied in industry, utilizes relevant covariate from the
pre-experiment period to reduce the variability of the outcome met-
ric, and shows that the higher correlation between covariate and
outcome, the better the performance of variance reduction. Alter-
natively, an equivalent technique to CUPED is the linear regression
method,ğ‘Œğ‘–=ğ‘0+ğ‘1ğ‘‡ğ‘–+ğ‘2ğ‘‹ğ‘–+ğœ–ğ‘–, which assumes the outcome is a
linear combination of the treatment effect and the covariate term.
To overcome the limitations of the linear model, researchers
have explored multivariate adjustment methods [ 2,13,15,23â€“25]
by introducing the cross-fitting technique [ 6,28] and â€œagnosticâ€
regression [ 12,17]. Typically, they utilize many covariates in a ma-
chine learning(ML) model ğ‘”predictingğ‘Œfromğ‘‹to develop a proxy
variableğ‘”(ğ‘‹). Subsequently, estimate the ATE in a linear regression
modelğ‘Œğ‘–=ğ‘0+ğ‘1ğ‘‡ğ‘–+ğ‘2ğ‘”(ğ‘‹ğ‘–)+ğœ–ğ‘–. Since the proxy incorporates
more prior information about the outcome, it generates further
variance reduction gains.
However, the regression-adjusted methods assume that the resid-
ualğœ–follows a Gaussian distribution, which is not applicable to
the heavy-tailed metrics in online businesses. If outliers are not
properly dealt with, they may lead to bias and high variance in
parameter estimation.
Furthermore, the majority of variance reduction methods focus
on count metrics. In fact, ratio metrics are equally important in prac-
tice, and are more complex but less investigated. Existing solutions
for ratio metric are mostly extensions to those of count metrics.
For examples, researchers utilize the delta method to extend the
CUPED estimator to the variance reduction of ratio metrics. The
study conducted by [ 15] focuses on ratio metrics by separately
minimizing the variances of the numerator and denominator, but
disregards their correlation. A novel work proposed in [ 4] is the
consistent transformation, which transforms ratio metrics into user-
level linear metrics. However, it is based on a strong hypothesis
where the denominator in ratio metrics is extremely large and can
be approximatively taken as a constant.
In this paper, we develop more efficient estimators for count met-
rics and ratio metrics respectively. For count metrics, we propose a
robust estimator called STATE by modeling the regression residual
as a Studentâ€™s ğ‘¡-distribution which was put forth and adopted as a ro-
bust building block, for clustering [ 20,22] and robust projections[ 1].
The heavy-tailed nature of the ğ‘¡-distribution makes it much less sen-
sitive to outliers compared to the Gaussian distribution, resulting in
a substantial reduction in the variance of the ATE estimate. For ratio
metrics, we adopt the main idea of the transformation method [ 4]
while relaxing its assumptions, and introduce STATE method for
ratio metrics to decrease the negative influence of outliers.
3 Robust Estimation for Count Metrics with
STATE
3.1 Robust Modeling
Following the framework of typical regression adjustment tech-
niques, our proposed ATE estimation procedure can be summarized
in two stages: machine learning stage and linear regression stage.
Machine learning stage: utilize machine learning tools ğ‘”to cap-
ture the relationship between the outcome metric ğ‘Œand the covari-
atesğ‘‹. Then, we can obtain a proxy variable Ë†ğ‘Œğ‘–[13,23] composed
6382KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Hao Zhou et al.
of ML predictions ğ‘”(ğ‘¥ğ‘–). Notably, we employ the cross-fitting tech-
nique [ 6,28] here to ensure that the proxy Ë†ğ‘Œğ‘–and treatment ğ‘‡ğ‘–are
independent.
Linear regression stage: include the proxy Ë†ğ‘Œğ‘–as a regressor in
the linear regression step. The ATE estimation is the estimate of ğ‘1.
ğ‘Œğ‘–=ğ‘0+ğ‘1ğ‘‡ğ‘–+ğ‘2Ë†ğ‘Œğ‘–+ğœ–ğ‘– (3)
for simplicity, we denote the Eq. (3)asğ‘Œğ‘–=ğ‘ğ‘‡ğ‘¥ğ‘–+ğœ–ğ‘–, where
ğ‘=(ğ‘0,ğ‘1,ğ‘2)ğ‘‡, andğ‘¥ğ‘–=(1,ğ‘‡ğ‘–,Ë†ğ‘Œğ‘–)ğ‘‡.
To capture the structure of the typical observations while deal-
ing with outliers automatically, we model the residuals using the
Studentâ€™sğ‘¡-distribution instead of the Gaussian distribution, here.
ğœ–ğ‘–âˆ¼ğ‘†ğ‘¡(ğœ–|ğ‘¢,ğœ2,ğ‘£) (4)
As noted in [ 18], theğ‘¡-distribution can be re-written as a convo-
lution of a Gaussian distribution with a Gamma distribution placed
on its precisions by introducing a latent variable ğœ‚ğ‘–.
ğ‘†ğ‘¡(ğœ–|ğ‘¢,ğœ2,ğ‘£)=âˆ«âˆ
0N(ğœ–|ğ‘¢,ğœ2
ğœ‚ğ‘–)G(ğœ‚ğ‘–|ğ‘£
2,ğ‘£
2)ğ‘‘ğœ‚ğ‘– (5)
without loss of generality, the expectation ğ‘¢of the residuals is set
to 0.Gis the Gamma density, G(ğœ‚|ğ‘,ğ‘)=ğ‘ğ‘
Î“(ğ‘)ğœ‚ğ‘âˆ’1ğ‘’âˆ’ğ‘ğœ‚, andÎ“(Â·)
represents the Gamma function.
It should be noted that the maximum likelihood estimate of
ğ‘1based on Eq. (3),(4)is the ATE estimation. Now we derive the
log-likelihood function of the observations in the following form.
L=lnğ‘Ã–
ğ‘–=1ğ‘ƒ(ğ‘Œğ‘–|ğ‘¥ğ‘–,ğœƒ)
=ğ‘âˆ‘ï¸
ğ‘–=1lnğ‘†ğ‘¡(ğ‘Œğ‘–|ğ‘ğ‘‡ğ‘¥ğ‘–,ğœ2,ğ‘£)
=ğ‘âˆ‘ï¸
ğ‘–=1lnâˆ«âˆ
0N(ğ‘Œğ‘–|ğ‘ğ‘‡ğ‘¥ğ‘–,ğœ2
ğœ‚ğ‘–)G(ğœ‚ğ‘–|ğ‘£
2,ğ‘£
2)ğ‘‘ğœ‚ğ‘–
â‰¥ğ‘âˆ‘ï¸
ğ‘–=1âˆ«âˆ
0ğ‘(ğœ‚ğ‘–)lnN(ğ‘Œğ‘–|ğ‘ğ‘‡ğ‘¥ğ‘–,ğœ2
ğœ‚ğ‘–)G(ğœ‚ğ‘–|ğ‘£
2,ğ‘£
2)
ğ‘(ğœ‚ğ‘–)ğ‘‘ğœ‚ğ‘–
â‰¡F(ğ‘Œ|ğ‘¥,ğœƒ,ğ‘)(6)
whereğ‘(ğœ‚ğ‘–)is the posterior of latent variable ğœ‚ğ‘–,ğœƒ={ğ‘ğ‘‡,ğœ2,ğ‘£}is
the set of parameters of the model. Fis called the variational free
energy function. The inequality holds due to Jensen Inequality.
3.2 The Variational Likelihood Bound
The variational free energy F, which is also called the Evidence
Lower Bound(ELBO) of the likelihood function. Optimizing the like-
lihood functionLdirectly is intractable, we can optimize the ELBO
instead by the EM algorithm according to Minorize-Maximization
optimization[16, 19]. Fcan be evaluated as follows:
F(ğ‘Œ|ğ‘¥,ğœƒ,ğ‘)=ğ‘âˆ‘ï¸
ğ‘–=1(âŸ¨lnN(ğ‘Œğ‘–|ğ‘ğ‘‡ğ‘¥ğ‘–,ğœ2
ğœ‚ğ‘–)âŸ©+âŸ¨lnG(ğœ‚ğ‘–|ğ‘£
2,ğ‘£
2)âŸ©âˆ’âŸ¨lnğ‘(ğœ‚ğ‘–)âŸ©)
(7)where
âŸ¨lnN(ğ‘Œğ‘–|ğ‘ğ‘‡ğ‘¥ğ‘–,ğœ2
ğœ‚ğ‘–)âŸ©=âˆ’1
2ln 2ğœ‹ğœ2+1
2âŸ¨lnğœ‚ğ‘–âŸ©âˆ’âŸ¨ğœ‚ğ‘–âŸ©
2ğœ2(ğ‘Œğ‘–âˆ’ğ‘ğ‘‡ğ‘¥ğ‘–)2
(8)
âŸ¨lnG(ğœ‚ğ‘–|ğ‘£
2,ğ‘£
2)âŸ©=ğ‘£
2lnğ‘£
2âˆ’lnÎ“(ğ‘£
2)+(ğ‘£
2âˆ’1)âŸ¨lnğœ‚ğ‘–âŸ©âˆ’ğ‘£
2âŸ¨ğœ‚ğ‘–âŸ©(9)
âŸ¨lnğ‘(ğœ‚ğ‘–)âŸ©=ğœ‰ğ‘–lnğœğ‘–âˆ’lnÎ“(ğœ‰ğ‘–)+(ğœ‰ğ‘–âˆ’1)âŸ¨lnğœ‚ğ‘–âŸ©âˆ’ğœ‰ğ‘– (10)
whereâŸ¨Â·âŸ©represents the expectation of the term conditional on the
posterior distribution ğ‘(ğœ‚ğ‘–),âŸ¨lnğœ‚ğ‘–âŸ©=Î¨(ğœ‰ğ‘–)âˆ’lnğœğ‘–andÎ¨(Â·)is the
di-gamma function.
In the E-step of the (ğ‘˜+1)-th iteration of EM algorithm, we
maximizeFw.r.t the variational distribution ğ‘while fixing the
parameters in the ğ‘˜-th iteration, ğœƒğ‘˜:
ğ‘ğ‘˜+1(ğœ‚ğ‘–)=ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥ğ‘F(ğ‘Œğ‘–|ğ‘¥ğ‘–,ğœƒğ‘˜,ğ‘)
In the M-step, we maximize Fw.r.t the parameters ğœƒto obtain
the new parameter values ğœƒğ‘˜+1
ğœƒğ‘˜+1=ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥ğœƒF(ğ‘Œğ‘–|ğ‘¥ğ‘–,ğœƒ,ğ‘ğ‘˜+1)
3.3 Deriving the EM Algorithm
3.3.1 Variational E-step.
The posterior distribution of latent variable ğœ‚ğ‘–can be derived
by taking functional derivative of F(ğ‘Œğ‘–|ğ‘¥ğ‘–,ğœƒ,ğ‘(ğœ‚ğ‘–))w.r.t. the term
ofğ‘(ğœ‚ğ‘–),
ğ‘(ğœ‚ğ‘–)=ğ‘’ğ‘¥ğ‘âŸ¨lnN(ğ‘Œğ‘–|ğ‘ğ‘‡ğ‘¥ğ‘–,ğœ2
ğœ‚ğ‘–)G(ğœ‚ğ‘–|ğ‘£
2,ğ‘£
2)âŸ©
âˆ«âˆ
0ğ‘’ğ‘¥ğ‘âŸ¨lnN(ğ‘Œğ‘–|ğ‘ğ‘‡ğ‘¥ğ‘–,ğœ2
ğœ‚ğ‘–)G(ğœ‚ğ‘–|ğ‘£
2,ğ‘£
2)âŸ©ğ‘‘ğœ‚ğ‘–
After simplification, we can find ğ‘(ğœ‚ğ‘–)is Gamma density.
ğ‘(ğœ‚ğ‘–)=G(ğœ‚ğ‘–|ğœ‰ğ‘–,ğœğ‘–)
where
ğœ‰ğ‘–=ğ‘£
2+1
2,ğœğ‘–=ğ‘£
2+(ğ‘Œğ‘–âˆ’ğ‘ğ‘‡ğ‘¥ğ‘–)2
2ğœ2,âŸ¨ğœ‚ğ‘–âŸ©=ğœ‰ğ‘–
ğœğ‘–(11)
3.3.2 M-step.
The parameter ğœƒ={ğ‘ğ‘‡,ğœ2,ğ‘£}are obtained by solving the sta-
tionary equations of Fw.r.tğ‘ğ‘‡={ğ‘0,ğ‘1,ğ‘2},ğœ2,ğ‘£respectively,
ğ‘0=Ãğ‘
ğ‘–=1(ğ‘Œğ‘–âˆ’ğ‘1ğ‘‡ğ‘–âˆ’ğ‘2Ë†ğ‘Œğ‘–)âŸ¨ğœ‚ğ‘–âŸ©
Ãğ‘
ğ‘–=1âŸ¨ğœ‚ğ‘–âŸ©(12)
ğ‘1=Ãğ‘
ğ‘–=1(ğ‘Œğ‘–âˆ’ğ‘0âˆ’ğ‘2Ë†ğ‘Œğ‘–)ğ‘‡ğ‘–âŸ¨ğœ‚ğ‘–âŸ©
Ãğ‘
ğ‘–=1âŸ¨ğœ‚ğ‘–âŸ©ğ‘‡2
ğ‘–(13)
ğ‘2=Ãğ‘
ğ‘–=1(ğ‘Œğ‘–âˆ’ğ‘0âˆ’ğ‘1ğ‘‡ğ‘–)Ë†ğ‘Œğ‘–âŸ¨ğœ‚ğ‘–âŸ©
Ãğ‘
ğ‘–=1âŸ¨ğœ‚ğ‘–âŸ©Ë†ğ‘Œ2
ğ‘–(14)
ğœ2=1
ğ‘ğ‘âˆ‘ï¸
ğ‘–=1(ğ‘Œğ‘–âˆ’ğ‘0âˆ’ğ‘1ğ‘‡ğ‘–âˆ’ğ‘2Ë†ğ‘Œğ‘–)2âŸ¨ğœ‚ğ‘–âŸ© (15)
ğ‘£is the solution of the following non-linear equation.
ğ‘âˆ‘ï¸
ğ‘–=1(lnğ‘£
2+1+âŸ¨lnğœ‚ğ‘–âŸ©âˆ’âŸ¨ğœ‚ğ‘–âŸ©âˆ’Î¨(ğ‘£
2))=0 (16)
6383STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for Variance Reduction in Online Controlled Experiments KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
In summary, the inference procedure of the STATE method for
count metrics is shown in Algorithm 1.
Algorithm 1 Variational EM Inference with STATE
1:Input: Data(ğ‘‹ğ‘–,ğ‘‡ğ‘–,ğ‘Œğ‘–)ğ‘
ğ‘–=1.
2:Output: STATE Ë†ğ‘1
3:ML stage: train a model ğ‘”(ğ‘¥)to predictğ¸[ğ‘Œ|ğ‘‹]by cross-fitting.
4:EM stage: estimate Ë†ğ‘1as the ATE estimation.
ğ‘Œğ‘–=ğ‘0+ğ‘1ğ‘‡ğ‘–+ğ‘2Ë†ğ‘Œğ‘–+ğœ–ğ‘–
initialize:(ğ‘0,ğ‘1,ğ‘2,ğœ2,ğ‘£)â†(ğ‘(0)
0,ğ‘(0)
1,ğ‘(0)
2,ğœ2(0),ğ‘£(0)).
5:while Free energyFnot converged do
6: E-step obtain the optimal posterior distribution of ğœ‚ğ‘–:
ğ‘(ğ‘˜+1)(ğœ‚ğ‘–)=G(ğœ‚ğ‘–|ğœ‰(ğ‘˜+1)
ğ‘–,ğœ(ğ‘˜+1)
ğ‘–)
7: whereğœ‰(ğ‘˜+1)
ğ‘–,ğœ(ğ‘˜+1)
ğ‘–are computed by Eq. (11).
8: M-step estimate the model parameters ğ‘ğ‘˜+1
0,ğ‘ğ‘˜+1
1,ğ‘ğ‘˜+1
2,
9:ğœ2(ğ‘˜+1),ğ‘£(ğ‘˜+1)by Eq. (12)-(16).
10: EvaluateFby Eq. (7)-(10)
11:end while
12:return STATE: Ë†ğ‘1
3.4 Computational Complexity
Compared to the CUPAC and MLRATE estimators, STATE incurs
extra computational costs, primarily due to the implementation of
the EM algorithm. Specifically, in each iteration, calculating the
posterior distribution parameters {ğœ‰ğ‘–,ğœğ‘–}ğ‘›
ğ‘–=1and model parameters
ğœƒ={ğ‘ğ‘‡,ğœ2,ğ‘£}each takesğ‘‚(ğ‘)operations. Consequently, the
overall computational complexity of EM algorithm amounts to
ğ‘‚(ğ¾ğ‘), whereğ¾denotes the number of iterations. According to
the empirical experience on the Meituan experimental platform,
the EM procedure typically requires 30 to 60 seconds to process
500,000 observations.
4 Consistent Transformation of Ratio Metrics
The ratio metrics are also common in the industry, which can be
regarded as the ratio of two count metrics. For example, the click-
through rate is a ratio metric, which is a ratio of the click number
and the pageview number. Addressing the variance reduction of
ratio metrics is more complex but much less investigated in existing
works. In this section, we will introduce consistent transformation
so that STATE can be utilized to reduce variance of ratio metrics.
Following the notations in Sec. 2.1, let ğ‘Œğ‘¡,ğ‘Œğ‘,ğ‘ğ‘¡,ğ‘ğ‘be the corre-
sponding count metrics, i.e.,
ğ‘Œğ‘¡=Ã
ğ‘‡ğ‘–=1ğ‘Œğ‘–
ğ‘ğ‘¡,ğ‘Œğ‘=Ã
ğ‘‡ğ‘–=0ğ‘Œğ‘–
ğ‘ğ‘,ğ‘ğ‘¡=Ã
ğ‘‡ğ‘–=1ğ‘ğ‘–
ğ‘ğ‘¡,ğ‘ğ‘=Ã
ğ‘‡ğ‘–=0ğ‘ğ‘–
ğ‘ğ‘.
Letğ‘…ğ‘¡andğ‘…ğ‘be the ratio metrics of the treatment group and the
control group respectively, i.e.,
ğ‘…ğ‘¡=Ã
ğ‘‡ğ‘–=1ğ‘Œğ‘–Ã
ğ‘‡ğ‘–=1ğ‘ğ‘–=ğ‘Œğ‘¡
ğ‘ğ‘¡, ğ‘…ğ‘=Ã
ğ‘‡ğ‘–=0ğ‘Œğ‘–Ã
ğ‘‡ğ‘–=0ğ‘ğ‘–=ğ‘Œğ‘
ğ‘ğ‘.According to the delta method [ 7], the variance of ratio metrics can
be approximately computed by
ğ·ğ‘…ğ‘¡=1
[ğ¸ğ‘ğ‘¡]2ğ·ğ‘Œğ‘¡+[ğ¸ğ‘Œğ‘¡]2
[ğ¸ğ‘ğ‘¡]4ğ·ğ‘ğ‘¡âˆ’2ğ¸ğ‘Œğ‘¡
[ğ¸ğ‘ğ‘¡]3cov(ğ‘Œğ‘¡,ğ‘ğ‘¡) (17)
=ğ·[ğ‘Œğ‘¡âˆ’ğ›¼ğ‘¡ğ‘ğ‘¡]
[ğ¸ğ‘ğ‘¡]2,
whereğ›¼ğ‘¡=ğ¸ğ‘Œğ‘¡/ğ¸ğ‘ğ‘¡. Therefore, we have
ğ·[Î”ğ‘…]=ğ·[ğ‘…ğ‘¡âˆ’ğ‘…ğ‘]
=ğ·ğ‘…ğ‘¡+ğ·ğ‘…ğ‘
=ğ·[ğ‘Œğ‘¡âˆ’ğ›¼ğ‘¡ğ‘ğ‘¡]
[ğ¸ğ‘ğ‘¡]2+ğ·[ğ‘Œğ‘âˆ’ğ›¼ğ‘ğ‘ğ‘]
[ğ¸ğ‘ğ‘]2,
whereğ›¼ğ‘=ğ¸ğ‘Œğ‘/ğ¸ğ‘ğ‘and the second equality holds due to ğ‘…ğ‘¡âŠ¥ğ‘…ğ‘.
Since the analysis unit in ratio metrics does not match the ran-
domization unit, the common regression-adjusted method and ro-
bust estimation cannot directly perform variance reduction for ratio
metrics [ 15]. The work [ 4] transformed ratio metrics ğ‘…ğ‘¡=ğ‘Œğ‘¡/ğ‘ğ‘¡
to linear metrics ğ¿ğ‘¡=ğ‘Œğ‘¡âˆ’ğœ…ğ‘ğ‘¡, whereğœ…=(1âˆ’ğœ‚)ğ‘…ğ‘¡+ğœ‚ğ‘…ğ‘. After
such linear transformation, regression adjustment can be applied
for variance reduction of Î”ğ¿=ğ¿ğ‘¡âˆ’ğ¿ğ‘, and the significance level of
Î”ğ‘…can be obtained by performing student t test for Î”ğ¿. However,
there are two crucial defects in this work. Firstly, it is showed that
Î”ğ¿=((1âˆ’ğœ‚)ğ‘ğ‘+ğœ‚ğ‘ğ‘¡)Î”ğ‘…. The coefficient(1âˆ’ğœ‚)ğ‘ğ‘+ğœ‚ğ‘ğ‘¡is not
a constant and thus the significance level of Î”ğ¿is not equivalent
to that of Î”ğ‘…. Secondly, the analysis for the variance of Î”ğ¿in this
work is based on the hypothesis where the parameter ğœ…is taken as
a constant, but it actually consists of random variables ğ‘…ğ‘¡andğ‘…ğ‘.
In this section, we follow the main idea in [ 4] (transforming
ratio metrics to linear metrics), but mitigate the above two defects
simultaneously. Specifically, we construct a new linear metric Î”ğ‘ƒ
and let Î”ğ‘ˆ=Î”ğ‘ƒ
ğ¸ğ‘ğ‘¡ğ¸ğ‘ğ‘, which preserves both unbiased estimation
and consistent variance, i.e.,
Property 1. Unbiased estimation: ğ¸[Î”ğ‘ˆ]=ğœğ‘Ÿ,
Property 2. Consistent variance: ğ·[Î”ğ‘ˆ]â‰ˆğ·[Î”ğ‘…],
whereğœğ‘Ÿ=ğ¸[ğ‘Œğ‘–(1)]
ğ¸[ğ‘ğ‘–(1)]âˆ’ğ¸[ğ‘Œğ‘–(0)]
ğ¸[ğ‘ğ‘–(0)]is ATE of ratio metrics. Since ğ¸ğ‘ğ‘¡ğ¸ğ‘ğ‘
is a constant, Property 1 guarantees that the significance level of
Î”ğ‘ƒis equivalent to that of ğœğ‘Ÿ. Although the value of ğ¸ğ‘ğ‘¡ğ¸ğ‘ğ‘is
unknown in practice, we can obtain the significance level of ğœğ‘Ÿby
making hypothesis testing for Î”ğ‘ƒ. Based on Property 2, performing
regression adjustment for Î”ğ‘ƒwill result in a consistent estimator of
Î”ğ‘ˆwith smaller variance than Î”ğ‘…. Furthermore, robust estimation
can be introduced and eliminate the influence of the atypical and
outlying observations.
Construction of Î”ğ‘ƒ.For each sample, construct the new label
asğ‘ƒğ‘–=ğœ…1ğ‘Œğ‘–âˆ’ğœ…2ğ‘ğ‘–. Hence, we have ğ‘ƒğ‘¡=Ã
ğ‘‡ğ‘–=1ğ‘ƒğ‘–
ğ‘ğ‘¡=ğœ…1ğ‘Œğ‘¡âˆ’ğœ…2ğ‘ğ‘¡,
ğ‘ƒğ‘=Ã
ğ‘‡ğ‘–=0ğ‘ƒğ‘–
ğ‘ğ‘=ğœ…1ğ‘Œğ‘âˆ’ğœ…2ğ‘ğ‘andÎ”ğ‘ƒ=ğ‘ƒğ‘¡âˆ’ğ‘ƒğ‘=ğœ…1Î”ğ‘Œâˆ’ğœ…2Î”ğ‘.
6384KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Hao Zhou et al.
Proof of Property 1. Follow the above construction of Î”ğ‘ƒand
setğœ…1=ğ‘ğ‘andğœ…2=ğ‘Œğ‘. We further have Î”ğ‘ƒ=ğ‘Œğ‘¡ğ‘ğ‘âˆ’ğ‘ğ‘¡ğ‘Œğ‘and
ğ¸[Î”ğ‘ˆ]=ğ¸[ğ‘Œğ‘¡ğ‘ğ‘âˆ’ğ‘ğ‘¡ğ‘Œğ‘]
ğ¸ğ‘ğ‘¡ğ¸ğ‘ğ‘
=ğ¸ğ‘Œğ‘¡ğ¸ğ‘ğ‘âˆ’ğ¸ğ‘ğ‘¡ğ¸ğ‘Œğ‘
ğ¸ğ‘ğ‘¡ğ¸ğ‘ğ‘
=ğ¸ğ‘Œğ‘¡
ğ¸ğ‘ğ‘¡âˆ’ğ¸ğ‘Œğ‘
ğ¸ğ‘ğ‘
=ğ¸[ğ‘Œğ‘–(1)]
ğ¸[ğ‘ğ‘–(1)]âˆ’ğ¸[ğ‘Œğ‘–(0)]
ğ¸[ğ‘ğ‘–(0)]
=ğœğ‘Ÿ,
where the second equality holds due to ğ‘Œğ‘¡,ğ‘ğ‘¡âŠ¥ğ‘Œğ‘,ğ‘ğ‘.
Proof of Property 2. Defineğ‘”(ğ‘Œğ‘¡,ğ‘ğ‘¡,ğ‘Œğ‘,ğ‘ğ‘)=ğ‘Œğ‘¡ğ‘ğ‘âˆ’ğ‘ğ‘¡ğ‘Œğ‘.
According to the delta method, the variance of Î”ğ‘ˆcan be rewritten
as
ğ·[Î”ğ‘ˆ]=ğ·[ğ‘Œğ‘¡ğ‘ğ‘âˆ’ğ‘ğ‘¡ğ‘Œğ‘]
[ğ¸ğ‘ğ‘¡ğ¸ğ‘ğ‘]2
=âˆ‡ğ‘‡ğ‘”(ğœ‡)Ãâˆ‡ğ‘”(ğœ‡)
[ğ¸ğ‘ğ‘¡ğ¸ğ‘ğ‘]2,
whereğœ‡=(ğ¸ğ‘Œğ‘¡,ğ¸ğ‘ğ‘¡,ğ¸ğ‘Œğ‘,ğ¸ğ‘ğ‘),âˆ‡ğ‘‡ğ‘”(ğœ‡)=(ğ¸ğ‘ğ‘,âˆ’ğ¸ğ‘Œğ‘,âˆ’ğ¸ğ‘ğ‘¡,ğ¸ğ‘Œğ‘¡)
is the Jacobian and
âˆ‘ï¸
=Â©Â­Â­Â­
Â«ğ·ğ‘Œğ‘¡ cov(ğ‘Œğ‘¡,ğ‘ğ‘¡) 0 0
cov(ğ‘Œğ‘¡,ğ‘ğ‘¡)ğ·ğ‘ğ‘¡ 0 0
0 0 ğ·ğ‘Œğ‘ cov(ğ‘Œğ‘,ğ‘ğ‘)
0 0 cov (ğ‘Œğ‘,ğ‘ğ‘)ğ·ğ‘ğ‘ÂªÂ®Â®Â®
Â¬
is the covariance matrix. Therefore, we further have
ğ·[Î”ğ‘ˆ]=âˆ‡ğ‘‡ğ‘”(ğœ‡)Ãâˆ‡ğ‘”(ğœ‡)
[ğ¸ğ‘ğ‘¡ğ¸ğ‘ğ‘]2
=1
[ğ¸ğ‘ğ‘¡]2
ğ·ğ‘Œğ‘¡+[ğ¸ğ‘Œğ‘]2
[ğ¸ğ‘ğ‘]2ğ·ğ‘ğ‘¡âˆ’2ğ¸ğ‘Œğ‘
ğ¸ğ‘ğ‘cov(ğ‘Œğ‘¡,ğ‘ğ‘¡)
+
1
[ğ¸ğ‘ğ‘]2
ğ·ğ‘Œğ‘+[ğ¸ğ‘Œğ‘¡]2
[ğ¸ğ‘ğ‘¡]2ğ·ğ‘ğ‘âˆ’2ğ¸ğ‘Œğ‘¡
ğ¸ğ‘ğ‘¡cov(ğ‘Œğ‘,ğ‘ğ‘)
=ğ·[ğ‘Œğ‘¡âˆ’ğ›¼ğ‘ğ‘ğ‘¡]
[ğ¸ğ‘ğ‘¡]2+ğ·[ğ‘Œğ‘âˆ’ğ›¼ğ‘¡ğ‘ğ‘]
[ğ¸ğ‘ğ‘]2,
whereğ›¼ğ‘¡=ğ¸ğ‘Œğ‘¡/ğ¸ğ‘ğ‘¡andğ›¼ğ‘=ğ¸ğ‘Œğ‘/ğ¸ğ‘ğ‘. As stated in [ 4], in the real
online experiments of the industry, the increment in ratio metrics
of the treatment group is usually small and is tightly bounded
with deviation of several percents. Hence, we have ğ›¼ğ‘¡â‰ˆğ›¼ğ‘, which
indicates that ğ·[Î”ğ‘ˆ]â‰ˆğ·[Î”ğ‘…]holds.
5 Experimental Evaluation
In this section, we construct large-scale experiments to demonstrate
the effectiveness of STATE using both simulated data and real user
data from the Meituan food delivery platform. Firstly, we validate
the performance of various methods in reducing the variance of
count metrics and ratio metrics in simulation data. For complete-
ness, we also investigate the impact of the proportion of outliers in
the data set on STATE. Secondly, to show the magnitude of vari-
ance reduction that can be achieved in practice, we perform a series
of A/A tests on key metrics of interest for Meituan food delivery
business. Finally, we discuss limitations of the STATE estimator.5.1 Experimental Setup
Simulation data. The generating process is almost the same as [ 13].
Denote each sample by (ğ‘‹ğ‘–,ğ‘‡ğ‘–,ğ‘Œğ‘–,ğ‘ğ‘–). The covariates ğ‘‹ğ‘–is dis-
tributed asğ‘‹ğ‘–âˆ¼N(ğ‘¢,ğ¼5Ã—5), whereğ‘¢is generated from a uniform
distribution ğ‘ˆ(0,10). The outcome variables ğ‘Œğ‘–andğ‘ğ‘–are con-
structed byğ‘Œğ‘–=ğ‘(ğ‘‹ğ‘–)+ğ‘‡ğ‘–âˆ—ğœğ‘¦(ğ‘‹ğ‘–)+ğœ–ğ‘–andğ‘ğ‘–=ğ‘(ğ‘‹ğ‘–)+ğ‘‡ğ‘–âˆ—ğœğ‘§(ğ‘‹ğ‘–)+ğœ‚ğ‘–
respectively, where ğœ–ğ‘–andğœ‚ğ‘–are the error terms distributed as
ğœ–ğ‘–âˆ¼N( 0,252),ğœ‚ğ‘–âˆ¼N( 0,102). Letğ‘(ğ‘‹ğ‘–)andğ‘(ğ‘‹ğ‘–)be nonlinear
functions with the forms(
ğ‘(ğ‘‹ğ‘–)=10 sin(ğœ‹ğ‘‹ğ‘–1ğ‘‹ğ‘–2)+6ğ‘‹2
ğ‘–3+10|ğ‘‹ğ‘–4|+5|ğ‘‹ğ‘–5|+50,
ğ‘(ğ‘‹ğ‘–)=10 sin(ğœ‹ğ‘‹ğ‘–4)ğ‘‹ğ‘–5+15(ğ‘‹ğ‘–2+ğ‘‹ğ‘–3)2+5|ğ‘‹ğ‘–1|+30.
The treatment effect is also given by a nonlinear form as
(
ğœğ‘¦(ğ‘‹ğ‘–)=ğ‘‹ğ‘–1ğ‘‹ğ‘–3+log(1+ğ‘’ğ‘‹ğ‘–2),
ğœğ‘§(ğ‘‹ğ‘–)=ğ‘‹2
ğ‘–2+3 log(1+ğ‘’ğ‘‹ğ‘–4+|ğ‘‹ğ‘–5|).
Additionally, in order to validate the performance of our STATE
estimator in dealing with heavy-tailed metrics, we also add a certain
proportion of outliers to the simulation data set. The outliers are
randomly generated from two uniform distributions ğ‘ˆ(ğ‘Œ+4ğœğ‘¦,ğ‘Œ+
20ğœğ‘¦)andğ‘ˆ(ğ‘+4ğœğ‘§,ğ‘+20ğœğ‘§), whereğœğ‘¦andğœğ‘§are the standard
deviation of ğ‘Œğ‘–andğ‘ğ‘–respectively.
We generate 200K samples in total and perform 1000 simulation
experiments. In each simulation, we randomly choose 20K samples
and divide them equally into the treatment group and the control
group according to the treatment indicator ğ‘‡ğ‘–which follows ğ‘‡ğ‘–âˆ¼
Bernoulli(0.5). Finally, we compare the variance of different ATE
estimators in all the simulations.
Real user data. The real user data is collected from Meituan food
delivery platform, which contains over 2.3 million samples and
58 covariates. Each sample records all the transaction information
for a user during an experiment in this platform. To show the
effectiveness of the STATE estimator, we select two count metrics,
the count of orders per user (orders in short) and GMV per user,
and a ratio metric, the average price per order (AvgOrdPrice). Here,
GMV refers to the total price paid by each user on the food delivery
platform during the trial period. The average price per order is
calculated by dividing the sum of GMV of all users by the total
number of orders of all users.
For each metric, we perform A/A tests by selecting 200k users
randomly and assigning the treatment indicator ğ‘‡ğ‘–âˆ¼Bernoulli(0.5)
for each user. Similarly, the A/A test is also repeated 1000 times.
Notice that the A/A test is a controlled experiment where treatment
is identical to control, hence the ground truth of ATE is 0.
Benchmark. For both count and ratio metrics, multiple methods for
variance reduction are implemented and taken as the benchmarks.
â€¢Count metrics
â€“DIM. The difference-in-mean estimator that computes
ATE by Eq. (1) for count metrics.
â€“CUPED. The state-of-the-art linear method proposed in [ 9],
which reduces variance of count metrics by utilizing the
pre-experiment covariates and gives an unbiased estima-
tion of ATE.
â€“CUPAC. Similar to CUPED, but replace the pre-experiment
covariates with a proxy highly correlated with the out-
come variable [23].
6385STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for Variance Reduction in Online Controlled Experiments KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
â€“MLRATE. The machine learning regression-adjusted esti-
mator proposed in [13].
â€“STATE. The robust regression-adjusted estimator for vari-
ance reduction proposed in this paper.
â€¢Ratio metrics
â€“DIM. The difference-in-mean estimator that computes
ATE of ratio metrics by Eq. (2).
â€“CUPED. The generalization to ratio metrics proposed in
Appendix B of [9].
â€“CTRM. The consistent transformation method of ratio
metrics proposed in [4].
â€“STATE. The robust regression-adjusted estimator for ratio
metrics after consistent transformation.
Evaluation Metrics. We compare various variance reduction tech-
niques on two primary evaluation metrics: bias and variance. Con-
sistent with previous studies[ 13,15], we assess the bias by utilizing
the empirical coverage rate of the 95% confidence intervals (CI).
The closer the empirical coverage rate is to the nominal cover-
age rate(95%), the smaller the bias of the estimator. On the other
hand, for the variance metric, the smaller the value, the shorter the
confidence interval and the higher the efficiency of the estimator.
â€¢Empirical coverage. The empirical coverage represents the
proportion of 1000 simulations in which the 95% confidence
interval covers the ground truth.
â€¢Variance. The variance of ATE estimates across 1000 simula-
tion experiments.
5.2 Simulation Experiment
In this section, we utilize simulation experiments to validate the
effectiveness of the algorithms proposed in this paper. First of all,
Table 1, 2 and Fig. 2 show the simulation results for count metrics
and ratio metrics on the dataset with 0.5% outliers. Furthermore,
we investigate the impact of the proportion of outliers on vari-
ous variance reduction techniques. "Var.Red%" displays the vari-
ance reduction gains for each method compared to DIM estimator.
"Emp.Cov%" displays the empirical coverage of the 95% CIs.
Table 1: Simulation Results for count metric
Methods DIM CUPED CUPAC MLRATE STATE
Emp.Cov% 94.6 94.6 94.2 94.0 95.6
Var.Red% 0 28.7 32.6 32.4 84.1
Table 2: Simulation results for ratio metric
Methods DIM CUPED CTRM STATE
Emp.Cov% 95.1 94.3 94.6 94.8
Var.Red% 0 6.7 55.7 90.1
5.2.1 Count Metrics.
As shown in Table 1, the empirical coverage of all count metric
estimators closely approximates the nominal coverage (95%), indi-
cating that the biases associated with these estimators are minimal.Fig. 2(a) depicts the probability density of ATE estimates, reveal-
ing that STATEâ€™s ATE distribution is markedly more compact, with
its variance being substantially reduced compared to that of other
methods. Specifically, the CUPED method reduces the variance
by 28.7% compared to the DIM estimator; CUPAC and MLRATE
perform similarly and deliver additional gains relative to CUPED.
It indicates that the proxy variable constructed by the ML model
has a superior correlation with the outcome than a single covariate.
In contrast, the performance of the STATE estimator is remarkable,
achieving an over 80% variance reduction compared to the DIM
estimator and significantly enhancing the precision of ATE estima-
tion. Considering both the empirical coverage rate and estimator
variance, STATE clearly emerges as the preferred ATE estimator.
5.2.2 Ratio Metrics.
Fig. 2(b) and Table 2 present the detailed experimental results of
variance reduction for ratio metrics in simulation data. As is shown
by Table 2, the empirical coverage of all the estimators are close
to the nominal coverage, in which STATE achieves the best per-
formance on variance reduction. Specifically, CUPED only reduces
6.7% of variance compared to DIM duo to the weak correlation
between the pre-experiment covariates and the ratio metric. CTRM
performs much better, which achieves over 55.7% variance reduc-
tion compared with DIM. However, the effectiveness of CTRM is
also limited by the correlation between the ML-based predictors
and the outcome metrics, which is easily influenced by big outliers.
As a robust estimator, STATE can significantly decrease the neg-
ative effects for variance caused by outliers, which contributes to
over 90.1% variance reduction relative to DIM.
5.2.3 Factors Affecting STATE Effectiveness.
Now letâ€™s look at the factors that affect the performance of STATE.
Here, we discuss the problem from a general setting to specific
settings by constructing a Gaussian distribution dataset and adding
different proportions of outliers from 0 to 1%. Fig. 3(a) and Fig. 3(b)
display the results of empirical coverage and variance reduction
respectively.
From the Fig. 3(b), we can see that when the dataset does not
contain outliers, more precisely, the metrics follow a Gaussian distri-
bution, STATE, CUPAC, and MLRATE perform similarly in variance
reduction. As the proportion of outliers increases, STATE and base-
line methods exhibit drastically different performance. The reason
is that the degree of variance reduction of typical methods such as
CUPED, CUPAC and MLRATE depends on the correlation between
the constructed covariates or proxy variables and business metrics.
12 13 14 15 16 17 18 19
ATE0.00.20.40.60.81.0Probability DensityDIM
CUPED
CUPAC
MLRATE
STATE
(a) PDF of ATE for count metric
0.00 0.01 0.02 0.03 0.04 0.05 0.06
ATE020406080100120140160Probability DensityDIM
CUPED
CTRM
STATE (b) PDF of ATE for ratio metric
Figure 2: Simulation results of ATE estimation
6386KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Hao Zhou et al.
Table 3: Summary of A/A test results for count metrics
MetricDIM CUPED CUPAC MLRATE STATE
Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov%
orders 94.9 47.2 94.9 54.6 94.5 54.6 94.5 70.5 95.1
GMV 94.8 33.3 93.9 44.3 94.5 44.4 94.4 80.7 95.2
Table 4: Summary of winsorized results at the 99.9th percentile threshold
MetricWinsorized DIM Winsorized CUPED Winsorized CUPAC Winsorized MLRATE Huber Regression
Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov%
orders 1.1 94.7 49.0 94.5 55.9 94.4 55.9 94.3 54.9 95.0
GMV 12.4 94.7 38.3 93.9 57.3 94.3 54.6 94.4 47.3 94.5
Table 5: Summary of winsorized results at the 99th percentile threshold
MetricWinsorized DIM Winsorized CUPED Winsorized CUPAC Winsorized MLRATE Huber Regression
Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov%
orders 9.76 94.1 53.0 94.0 60.4 94.1 60.5 94.0 54.9 95.0
GMV 21.7 94.5 49.8 93.5 71.0 94.0 67.7 93.8 47.3 94.5
0.0% 0.2% 0.4% 0.6% 0.8% 1.0%
Proportion of outliers91%92%93%94%95%96%97%Emp.Cov%
Nor_Cov
DIM
CUPEDCUPAC
MLRATE
STATE
(a) Empirical coverage for all estimators
0.0% 0.2% 0.4% 0.6% 0.8% 1.0%
Proportion of outliers0%20%40%60%80%100%Var.Red%
CUPED
CUPACMLRATE
STATE (b) Variance reduction compared to DIM
Figure 3: Impact of proportions of outliers
However, with the existence of outliers, correlation learning be-
comes increasingly difficult. The result is that the performance of
these typical techniques deteriorates gradually, degrading to the
variance scale of the DIM method. The STATE estimator we pro-
posed is designed to address such challenges by modeling the noise
as a Studentâ€™s ğ‘¡-distribution. Because of the excellent robustness
of the T estimate, the rate of variance increase of STATE is signifi-
cantly slower than the DIM method with the increase of outliers.
Consequently, the more pronounced the heavy tail phenomenon of
business metrics, the more apparent the advantage of the STATE
method in variance reduction.
5.3 Empirical Results
In this section, we perform two real experiments on the Meituan
food delivery platform, analyzing the count metrics and ratio met-
rics, respectively. Here, we focus on the A/A tests, not the A/B
tests running in production. This is because the true effect of the
A/B tests is unknown, which makes it impossible to evaluate theempirical coverage rate of the confidence interval. Since the aver-
age treatment effect (ATE) in online experiments is typically small
and unlikely to significantly change the relationship between the
outcomes and covariates, the reduction in variance in A/B tests
should be very similar to that in A/A tests.
-0.15 -0.10 -0.05 0.00 0.05 0.10 0.15
ATE0.02.55.07.510.012.515.017.520.0Probability DensityDIM
CUPED
CUPAC
MLRATE
STATE
(a) PDF of ATE for orders
-6 -4 -2 0 2 4 6
ATE0.00.10.20.30.40.5Probability DensityDIM
CUPED
CUPAC
MLRATE
STATE (b) PDF of ATE for GMV
-0.75 -0.50 -0.25 0.00 0.25 0.50 0.75
ATE0123456Probability DensityDIM
CUPED
CTRM
STATE
(c) PDF of ATE for AvgOrdPrice
Figure 4: Empirical results of ATE estimation
5.3.1 Count metrics.
On the food delivery platform, business metrics with a heavy-
tailed distribution are quiet common. This is typically caused by
6387STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for Variance Reduction in Online Controlled Experiments KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Table 6: Summary of A/A test results for ratio metrics
MetricDIM CUPED CTRM STATE
Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov% Var.Red% Emp.Cov%
AvgOrdPrice 95.0 6.4 95.6 21.8 94.9 91.6 95.7
usersâ€™ accidental consumption behavior. For example, a user orders
takeaway to treat friends to dinner, the consumption price of her
order may be a extremely large value relative to her historical
consumption pattern. These sample points that fall on the tail (also
known as outliers) are not affected by treatment, but has great
impact on the sensitivity of measuring ATE.
To get a better sense of the magnitudes of variance reduction
that the STATE method might achieve in practice, we select two
key count metrics: orders per user and GMV per user, both of which
have heavy-tail distributions. For each metric, we construct A/A
tests. Table 3 and Fig. 4 show the empirical results. It indicates
that the STATE performs substantially better than the CUPED,
CUPAC and MLRATE estimators on both orders metric and GMV
metric. On average, the STATE estimator reduces the variance of
the order metric and GMV metric by 70.5% and 80.7% respectively
compared to the DIM method, whereas the analogous figures for the
state-of-the-art methods are about 54.6% and 44.4%. It demonstrates
that STATE can indeed considerably improve the sensitivity of
real business metrics, which is of great significance for increasing
business profits and reducing the cost of experimental time.
Furthermore, we compare STATE method with the typical win-
sorization [ 11] method and Huber regression [ 5] for dealing with
heavy-tailed metrics. Table 4 and 5 display the results of Winsoriza-
tion at different thresholds(99% and 99.9% quantiles of the observa-
tions). It is observed that estimation is sensitive to the threshold.
A lower threshold results in more observations beyond threshold
being restrained, which consequently yields a reduced variance in
parameter estimation. However, there is a concomitant decline in
the empirical coverage rate, suggesting an incremental increase in
bias. Consequently, employing the Winsorization process necessi-
tates a meticulous balance between the impact of bias and variance.
As shown in Table 3 and 4, the variance of the parameters estimated
by the Huber regression method is slightly smaller than that of
the CUPAC and MLRATE methods (without winsorization). This is
because Huber regression transforms the mean square loss function
of extreme observations into a linear form, thereby partially reduc-
ing the impact of outliers. However, the results also show that the
robustness of the Huber regression method is limited, exhibiting a
considerable disparity when compared to the STATE method.
5.3.2 Ratio metrics.
Fig. 4(c) and Table 6 present the results for ratio metric named
AvgOrdPrice in real user data, which is calculated by dividing the
sum of GMV of all users by the total number of orders. As is shown
by Table 6, the empirical coverage of all the estimators converges
to 95%, and STATE still performs the best because of the strong
capacity of resisting disturbance for outliers that exactly exists in
real data. In summary, the variance reduction of STATE is about91.6% relative to DIM, relative to CUPED is 91.0%, relative to CTRM
is 89.3%.
5.4 Limitations
In the preceding discussions, STATE has achieved notable success
in the application of variance reduction for both count metrics
and ratio metrics. Now letâ€™s discuss the applicability of the STATE
method. Inspired by section 5.2.3, we find the effectiveness of the
STATE method varies from metric to metric, depending on whether
the distribution of the metric has a heavy tail. When metric follows
a Gaussian distribution, the STATE method is comparable with the
state-of-the-art methods, but introduces extra computational cost.
If the metric exhibits a heavy tail distribution, the STATE method
demonstrates a strong advantage.
6 Conclusion
Variance reduction is the common technology to improve the sensi-
tivity in online controlled experiments, which contributes to smaller
user population and shorter experimental period. However, typical
methods cannot characterize the heavy-tailed distributions in real
business metrics, whose efficiency is greatly limited by the outlying
observations. In this paper, we proposed a machine-learning-based
regression adjustment method with Studentâ€™s ğ‘¡-distributed errors
to reduce the impact of outliers in variance reduction for count
metrics. Furthermore, we transform ratio metrics into a linear com-
bination but preserve unbiased estimation and consistent variance,
and apply the above method to the variance reduction of ratio
metrics. Both synthetic and real data demonstrate a significant
decrease in variance for both count and ratio metrics compared
to state-of-the-art methods. It benefits from our robust estimator
that is stronger to resist disturbance of outliers. We recommend to
use the method especially in the experiments where the treatment
effect is not very significant. In this case, the influence of outliers
is relative larger but can be effectively mitigated by our method.
As the method significantly improves the robustness of con-
trolled experiment results, we would like to expand it to the esti-
mation of individual treatment effects (ITE) in future works, which
also suffers from the negative effects of outliers.
Acknowledgments
This work was supported in part by National Key R&D Program
of China (2022YFB290180), the NSF of China (62172206), and the
Xiaomi Foundation.
References
[1]CÃ©dric Archambeau, Nicolas Delannay, and Michel Verleysen. 2006. Robust
Probabilistic Projections. In ACM International Conference on Machine Learning
(ICML). 33â€“40.
6388KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Hao Zhou et al.
[2]Peter M Aronow and Joel A Middleton. 2013. A Class of Unbiased Estimators
of the Average Treatment Effect in Randomized Experiments. Journal of Causal
Inference 1, 1 (2013), 135â€“154.
[3]Eytan Bakshy and Dean Eckles. 2013. Uncertainty in Online Experiments with
Dependent Data: An Evaluation of Bootstrap Methods. In ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Mining (KDD). 1303â€“1311.
[4]Roman Budylin, Alexey Drutsa, Ilya Katsev, and Valeriya Tsoy. 2018. Consistent
Transformation of Ratio Metrics for Efficient Online Controlled Experiments. In
ACM International Conference on Web Search and Data Mining (WSDM). 55â€“63.
[5]Pauline Burke et al .2019. Measuring Average Treatment Effect from Heavy-tailed
Data. arXiv preprint arXiv:1905.09252 (2019).
[6]Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian
Hansen, Whitney Newey, and James Robins. 2018. Double/Debiased Machine
Learning for Treatment and Structural Parameters. The Econometrics Journal 21,
1 (2018), C1â€“C68.
[7]Anirban DasGupta. 2008. Asymptotic Theory of Statistics and Probability. Vol. 180.
Springer.
[8]Alex Deng, Michelle Du, Anna Matlin, and Qing Zhang. 2023. Variance Reduction
Using In-Experiment Data: Efficient and Targeted Online Measurement for Sparse
and Delayed Outcomes. In ACM SIGKDD Conference on Knowledge Discovery and
Data Mining (KDD). 3937â€“3946.
[9]Alex Deng, Ya Xu, Ron Kohavi, and Toby Walker. 2013. Improving the Sensitivity
of Online Controlled Experiments by Utilizing Pre-Experiment Data. In ACM
International Conference on Web Search and Data Mining (WSDM). 123â€“132.
[10] Alex Deng, Lo-Hua Yuan, Naoya Kanai, and Alexandre Salama-Manteau. 2023.
Zero to Hero: Exploiting Null Effects to Achieve Variance Reduction in Experi-
ments with One-sided Triggering. In ACM International Conference on Web Search
and Data Mining (WSDM). 823â€“831.
[11] Wilfrid J Dixon. 1960. Simplified estimation from censored normal samples. The
Annals of Mathematical Statistics (1960), 385â€“391.
[12] David A Freedman. 2008. On Regression Adjustments to Experimental Data.
Advances in Applied Mathematics 40, 2 (2008), 180â€“193.
[13] Yongyi Guo, Dominic Coey, Mikael Konutgan, Wenting Li, Chris Schoener, and
Matt Goldman. 2021. Machine Learning for Variance Reduction in Online Experi-
ments. In Conference on Neural Information Processing Systems (NIPS). 8637â€“8648.
[14] Henning Hohnhold, Deirdre Oâ€™Brien, and Diane Tang. 2015. Focusing on the
Long-term: Itâ€™s Good for Users and Business. In ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining (KDD). 1849â€“1858.[15] Ying Jin and Shan Ba. 2023. Toward Optimal Variance Reduction in Online
Controlled Experiments. Technometrics 65, 2 (2023), 231â€“242.
[16] Kenneth Lange, David R Hunter, and Ilsoon Yang. 2000. Optimization Transfer
Using Surrogate Objective Functions. Journal of Computational and Graphical
Statistics 9, 1 (2000), 1â€“20.
[17] Lin and Winston. 2013. Agnostic Notes on Regression Adjustments to Experi-
mental Data: Reexamining Freedmanâ€™s Critique. The Annals of Applied Statistics
7, 1 (2013), 295â€“318.
[18] Chuanhai Liu and Donald B Rubin. 1995. ML Estimation of the T Distribution
using EM and Its Extensions, ECM and ECME. Statistica Sinica 5, 1 (1995), 19â€“39.
[19] Sobhan Naderi Parizi, Kun He, Reza Aghajani, Stan Sclaroff, and Pedro Felzen-
szwalb. 2019. Generalized Majorization-Minimization. In ACM International
Conference on Machine Learning (ICML). 5022â€“5031.
[20] David Peel and Geoffrey J McLachlan. 2000. Robust Mixture Modelling Using
the T Distribution. Statistics and Computing 10 (2000), 339â€“348.
[21] Jasjeet S Sekhon. 2008. The Neyman-Rubin Model of Causal Inference and
Estimation via Matching Methods. The Oxford Handbook of Political Methodology
2 (2008), 1â€“32.
[22] Markus SvensÃ©n and Christopher M Bishop. 2005. Robust Bayesian Mixture
Modelling. Neurocomputing 64 (2005), 235â€“252.
[23] Yixin Tang, Caixia Huang, David Kastelman, and Jared Bauman. 2020. Control
Using Predictions as Covariates in Switchback Experiments. (2020).
[24] Stefan Wager, Wenfei Du, Jonathan Taylor, and Robert J Tibshirani. 2016. High-
Dimensional Regression Adjustments in Randomized Experiments. National
Academy of Sciences 113, 45 (2016), 12673â€“12678.
[25] Edward Wu and Johann A Gagnon-Bartsch. 2018. The LOOP Estimator: Adjusting
for Covariates in Randomized Experiments. Evaluation Review 42, 4 (2018), 458â€“
488.
[26] Ya Xu and Nanyu Chen. 2016. Evaluating Mobile Apps with A/B and Quasi A/B
Tests. In ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining (KDD). 313â€“322.
[27] Li Yang and Anastasios A Tsiatis. 2001. Efficiency Study of Estimators for a
Treatment Effect in a Pretestâ€“Posttest Trial. The American Statistician 55, 4
(2001), 314â€“321.
[28] Wenjing Zheng and Mark J van der Laan. 2011. Cross-Validated Targeted
Minimum-Loss-Based Estimation. Targeted Learning: Causal Inference for Obser-
vational and Experimental Data (2011), 459â€“474.
6389