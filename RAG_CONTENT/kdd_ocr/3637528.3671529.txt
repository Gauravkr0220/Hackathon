Deep Ensemble Shape Calibration: Multi-Field Post-hoc
Calibration in Online Advertising
Shuai Yang
Shopee Discovery Ads
Beijing, China
lucas.yang@shopee.comHao Yang
Shopee Discovery Ads
Beijing, China
apple.yang@shopee.comZhuang Zou
Shopee Discovery Ads
Beijing, China
zhuang.zou@shopee.com
Linhe Xu
Shopee Discovery Ads
Beijing, China
linhe.xu@shopee.comShuo Yuan
Shopee Discovery Ads
Beijing, China
yuanshuo.ys@hotmail.comYifan Zeng
Shopee Discovery Ads
Beijing, China
alan.zeng@shopee.com
Abstract
In the e-commerce advertising scenario, estimating the true prob-
abilities (known as a calibrated estimate) on Click-Through Rate
(CTR) and Conversion Rate (CVR) is critical. Previous research has
introduced numerous solutions for addressing the calibration prob-
lem. These methods typically involve the training of calibrators
using a validation set and subsequently applying these calibrators
to correct the original estimated values during online inference.
However, what sets e-commerce advertising scenarios is the
challenge of multi-field calibration. Multi-field calibration requires
achieving calibration in each field. In order to achieve multi-field
calibration, it is necessary to have a strong data utilization ability.
Because the quantity of pCTR specified range for single field-value
(such as user ID and item ID) sample is relatively small, which makes
the calibrator more difficult to train. However, existing methods
have difficulty effectively addressing these issues.
To solve these problems, we propose a new method named Deep
Ensemble Shape Calibration (DESC). In terms of business under-
standing and interpretability, we decompose multi-field calibration
intovalue calibration and shape calibration. We introduce in-
novative basis calibration functions, which enhance both function
expression capabilities and data utilization by combining these basis
calibration functions. A significant advancement lies in the develop-
ment of an allocator capable of allocating the most suitable calibra-
tors to different estimation error distributions within diverse fields
and values. We achieve significant improvements in both public and
industrial datasets. In online experiments, we observe a +2.5% in-
crease in CVR and +4.0% in GMV. (Gross Merchandise Volume). Our
code is now available at: https://github.com/HaoYang0123/DESC.
CCS Concepts
â€¢Computing methodologies â†’Machine learning.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671529Keywords
Multi-Field Calibration, Basis Calibration Function, Field-aware
Attention
ACM Reference Format:
Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng.
2024. Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration
in Online Advertising. In Proceedings of the 30th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining (KDD â€™24), August 25â€“29, 2024,
Barcelona, Spain. ACM, New York, NY, USA, 10 pages. https://doi.org/10.
1145/3637528.3671529
1 INTRODUCTION
Estimating CTR and CVR is a crucial technology in e-commerce
advertising domains [ 2â€“6,10,14,22,26â€“28,30,33,35]. Accurate
prediction of CTR (pCTR) and CVR (pCVR) is essential, as it neces-
sitates precision not only in ranking but also in absolute values.
However, recent studies [ 1,7,9,16,23] have revealed that nu-
merous established machine learning techniques, particularly deep
learning methods extensively applied in the fields of e-commerce
advertising, often yield inadequately calibrated probability predic-
tions.
In previous research, there are many solutions to solve the cali-
bration problem. These methods learn calibrator through the vali-
dation set, and then use the calibrator to correct the original esti-
mated values in the online inference stage. These methods can be
categorized into parameter methods (including Platt Scaling [ 25],
Temperature scaling [9], Beta calibration [18], Gamma calibration
[20] and Dirichlet calibration [ 17]), non-parameter methods (such
as Histogram Binnning [ 31] and Isotonic Regression [ 32]) and hy-
brid methods. Hybrid methods encompass both non-field-aware
[15, 19, 34] and field-aware approaches [13, 24, 29].
In the advertising scenarios, there are multiple fields (such as
user group and item category), and if predictions of CTR (pCTR)
or CVR (pCVR) are not calibrated in certain fields, such as item
category, it can lead to a negative impact on the earnings of some
advertisers. Simultaneously, in the e-commerce scenario, there is a
particularly large number of fields to consider. This necessitates the
calibration of each field, referred to as multi-field calibration. To
achieve multi-field calibration, it is necessary to have a strong data
utilization ability. Because the samples of the specified pCTR range
for a single field value (such as user ID and item ID) are relatively
small, which makes the calibrator more difficult to train.
6117
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
CTR
PCTR PCTR PCTRpCTR = CTRShape Miscalibrated Value  Miscalibrated Shape & Value Calibrated
Calibrated Calibrated Calibrated
Figure 1: Examples to show the shape miscalibration and
value miscalibration
012345678910111213141516171819202122231.01.52.0pCTR/CTRValuemiscalibration over 24 hours
cat_0 cat_1 cat_2 cat_3 cat_4 cat_50.60.81.01.21.4pCTR/CTRValuemiscalibration across Categories
Figure 2: Examples to show significant variations in value
miscalibration among different fields and values.
0.011 0.019 0.027 0.035 0.043
Un-calibrated pCTR0.20.40.60.81.01.21.4pCTR/CTR
Calibrated pCTR
value="Food",field="category"
0.011 0.019 0.027 0.035 0.043
Un-calibrated pCTR0.20.40.60.81.01.21.4
 Calibrated pCTR
value="Book",field="category"Shapemiscalibration across values
Figure 3: Examples to show significant variations in shape
miscalibration among different values within the same field.
In terms of business understanding and interpretability, we de-
compose multi-field calibration into value calibration and shape
calibration. Figure 1 shows shape miscalibration and value miscali-
bration. Value calibration is defined as no over- or under-estimation
each value under concerned fields (such as average of pCTR should
equal to the CTR for value "womenâ€™s shoes" in the field "category",
in the e-commerce advertising context, the number of fields can
range from dozens to even hundreds). From the advertising per-
spective, value calibration ensures that the ECPM (Effective Cost
Per Mille) and GMV (Gross Merchandise Value) of different items
are not over- or under estimated. Figure 2 illustrates the significant
inconsistency of over- and under-estimation across different values.
Shape calibration is defined as no over- or under-estimation for
each subset of the pCTR within the specified range. Explaining
from the advertising perspective, shape calibration ensures that
some already popular items are not excessively exposed or sup-
pressed. Take Figure 3 as an example, for the field "Category" with
values "Food" and "Book", the calibrated pCTR/CTR is 1 in anypCTR interval, whereas the distribution (shape) of the uncalibrated
pCTR/CTR will be different. However, the existing methods cannot
simultaneously fulfill both value calibration and shape calibration.
For parameter methods, non-parameter methods and non-field-
aware methods, they involve the training of a single calibration
function to address the issue of over- or under-estimation for each
subset of the pCTR globally but overlook the biases across different
fields.
For field-aware methods, they have different emphases, and can-
not simultaneously fulfill both value calibration and shape calibra-
tion. NeuralCalib/Field-aware Calibration (FAC) [ 24] places its focus
on modeling estimation value biases across various field values,
rather than addressing shape miscalibrations. Multiple Boosting
Calibration Tree (MBCT) [ 13] effectively enhances the binning of
field values, giving less emphasis to shape miscalibrations. AdaCalib
(Ada) [ 29] can only model shape calibration and value calibration
under the condition of a single field.
An analysis of the aforementioned field-aware methods reveals
several key observations. Firstly, within a single field, there exists
multiple values. In some cases, the allocation of samples to each
field value may be limited, particularly in scenarios involving user
ID, item ID and certain sparse cross-features. Consequently, train-
ing a calibrator under such limited samples can be challenging.
Additionally, field-aware methods often employ a binning strat-
egy, followed by the generation of calibration parameters based on
information from two adjacent bins. This approach can lead to a
sample isolation issue wherein the parameters of a bin are exclu-
sively influenced by the samples within that bin and its neighboring
bins, with no updates from samples in other bins. As a result, these
methods can result in suboptimal data utilization.
To solve these above problems, we propose a new method named
Deep Ensemble Shape Calibration (DESC). There are four contri-
butions in our work:
â€¢We redefine the multi-field calibration: perform shape cali-
bration and value calibration at the same time.
â€¢We propose the novel basis calibration functions, which can
simultaneously improve function expression ability and data
utilization through the combination of basis calibration func-
tions.
â€¢We make a breakthrough in putting forward an allocator that
can allocate the most suitable shape calibrators for different
estimation error distributions on various fields and values.
â€¢Our proposed DESC method outperforms other methods sig-
nificantly across both calibration and non-calibration met-
rics, as demonstrated on two public datasets and one indus-
trial dataset. Additionally, in online experiments, we observe
a notable increase of +2.5% in CVR and +4.0% in GMV.
2 RELATED WORKS
With the growing emphasis on improving the reliability and accu-
racy of machine learning models, several research approaches have
emerged. Numerous calibration methods focus on acquiring a map-
ping function to convert predicted probabilities into observed poste-
rior probabilities, referred to as post-hoc calibration. These studies
can be broadly classified into three categories: non-parameter, pa-
rameter, and hybrid methods.
6118Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
2.1 Non-parametric Methods
Non-parametric methods do not rely on any assumptions regarding
the distribution of estimates. Examples of non-parametric methods
encompass Histogram Binning (HB)[ 31] and Isotonic Regression
(IR) [ 32]. HB involves sorting the estimated values and then dividing
them into bins of equal frequencies or intervals. Building upon this,
IR introduces the additional constraint of order preservation. These
approach can introduce instability in the bin boundary values.
2.2 Parametric Methods
Parameter methods often rely on specific probability distribution
assumptions for deriving mapping functions. Platt Scaling [ 25],
extensively employed in binary classification calibration, assumes
a Gaussian distribution with equal variances for both positive and
negative classes [ 20]. For multi-class tasks, Temperature Scaling [ 9]
extends this approach. Beta calibration [ 18], Gamma calibration [ 20]
and Dirichlet calibration [ 17] rely on their respective probability
distributions for calibration. Parameter methods are highly reliant
on the strong distribution assumption, which can lead to suboptimal
performance if the assumption does not hold in practical scenarios.
2.3 Hybrid Methods
Hybrid methods integrate non-parametric and parametric approaches.
Based on whether they are applied at the field-level, we further cat-
egorize hybrids into two groups: non-field-aware and field-aware
methods.
2.3.1 Non-field-aware Methods. Non-field-aware methods encom-
pass three notable approaches: Scaling-binning [ 19], Smooth Iso-
tonic Regression (SIR) [ 15], and Ensemble Temperature Scaling
(ETS) [ 34]. Scaling-binning combines the techniques of Platt Scal-
ing and Histogram Binning. SIR employs linear interpolation based
on isotonic regression, while ETS combines multiple temperature
scalings for calibration. Notably, all of these methods utilize raw
predicted scores as input without taking field information into
account.
2.3.2 Field-aware Methods. Field-aware methods integrate supple-
mentary features to formulate calibration functions. NeuralCalib
(FAC) [ 24] introduces an auxiliary module but it does not address
the challenge of shape miscalibration variance among different field
values. AdaCalib (Ada) [ 29] learns an isotonic function based on
posterior statistics and selects the most appropriate bin number
for a single field value. However, AdaCalib does not encompass all
fields. MBCT [ 13] employs trees to uncover more effective calibra-
tion across fields. However, calibration trees are unable to handle
sparse fields, such as user ID and item ID.
3 CALIBRATION PROBLEM FORMULATION
In online advertising systems, using CTR as an illustration (CVR
follows the same principles), we have trained a neural predictor,
denoted asğ‘“ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘ , on a training dataset Dğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› . This dataset in-
cludes all field values as inputs ( ğ‘¥) and click responses ( ğ‘¦), where
ğ‘¦=0represents non-click events and ğ‘¦=1signifies click events.
The neural predictor is capable of forecasting the likelihood of a
click using the following formula.
Ë†ğ‘ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘ =ğ‘“ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘(ğ‘¥) (1)
To address the under- and over-estimation issues associated
with the predicted scores generated by ğ‘“ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘ , we must train anadditional calibrator, denoted as ğ‘“ğ‘ğ‘ğ‘™ğ‘–ğ‘ , while considering ğ‘›distinct
fields (ğ‘1,ğ‘2, ...,ğ‘ğ‘›) in a validation dataset. Our objective is for
ğ‘“ğ‘ğ‘ğ‘™ğ‘–ğ‘ to predict the conditional expectation E[ğ‘¦|ğ‘¥]. Subsequently,
the theoretical calibration error of ğ‘“ğ‘ğ‘ğ‘™ğ‘–ğ‘ with respect to the ground-
truth under the ğ‘™ğ‘-norm is defined as:
ğ‘‡ğ¶ğ¸ğ‘(ğ‘“ğ‘ğ‘ğ‘™ğ‘–ğ‘)=(Eğ‘¥[|E[ğ‘¦|ğ‘¥]âˆ’ğ‘“ğ‘ğ‘ğ‘™ğ‘–ğ‘(ğ‘¥)|ğ‘])1
ğ‘. (2)
The calibrator ğ‘“ğ‘ğ‘ğ‘™ğ‘–ğ‘ is considered to be perfectly calibrated when
the theoretical calibration error ğ‘‡ğ¶ğ¸ğ‘(ğ‘“ğ‘ğ‘ğ‘™ğ‘–ğ‘)is zero. However, in
fact perfect calibration is impossible in practice. Only approximate
and asymptotic grouped calibrations are possible for finite and
specific partitions of samples [ 11]. To test the performance of dif-
ferent calibrators, we will explain some related calibration metrics
in EXPERIMENTS section.
4 METHODS
Under the requirement of multi-field calibration, both shape cali-
bration and value calibration need to be performed simultaneously.
Therefore, within the entire DESC architecture, we have designed
separate modules, namely Shape Calibrator and Value Calibrator
(Figure 4), to achieve shape calibration and value calibration. The
final calibrated score is the product of these two parts:
Ë†ğ‘ğ‘ğ‘ğ‘™ğ‘–ğ‘ =S(ğ‘¥)Â·V(ğ‘¥), ğ‘¥={ğ‘,Ë†ğ‘ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘} (3)
The inputğ‘¥consists of all ğ‘›field values ğ‘and non-calibrated
scores Ë†ğ‘ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘ .S(ğ‘¥)andV(ğ‘¥)refer to the shape calibrated score
(the output of Shape Calibrator) and value calibrated score (the
output of Value Calibrator), respectively. The training loss function
is the negative log-likelihood function.
L(ğ‘¥, ğ‘¦)=âˆ’1
|D|(ğ‘¦Â·ğ‘™ğ‘œğ‘”Ë†ğ‘ğ‘ğ‘ğ‘™ğ‘–ğ‘+(1âˆ’ğ‘¦)Â·ğ‘™ğ‘œğ‘”(1âˆ’Ë†ğ‘ğ‘ğ‘ğ‘™ğ‘–ğ‘)) (4)
In Section 4.1, we present the Shape Calibrator module, which is
responsible for achieving shape calibration. In Section 4.2, we dis-
cuss the Value Calibrator module, which is designed to accomplish
value calibration. In Section 4.3, we elaborate on the deployment of
DESC in an online setting, outlining the necessary procedures and
considerations.
4.1 Shape Calibrator
For multi-field calibration, the goal of Shape Calibrator is to ensure
that: given input features ğ‘¥, we need to reduce the problems of
over- and under-estimation across all intervals of pCTR (shape
miscalibration).
In section 4.1.1, we pre-define a variety of basis functions to
accommodate different shape requirements. Section 4.1.2 deals with
the allocation of appropriate shape functions given specific field
conditions. This section offers separate discussions on how shape
allocation is managed for regular fields and sparse fields.
In section 4.1.3, when dealing with multiple fields, there may be
conflicts in terms of the influence of different fields on calibration.
Thus, we introduce a multi-field fusion mechanism named Multi-
Field Shape Ensemble.
Collectively, sections 4.1.1 and 4.1.2 are referred to as the Single
Field Shape Calibrator (SFSC), as depicted in Figure 4b.
4.1.1 Shape Pre-Define. In this section, we pre-define some basis
calibration functions. Then, we merge the basis calibration func-
tions into shape functions to enhance their expressive ability.
For the variable ğ‘¡,ğ‘¡is between 0 and 1, basis calibration function
B(ğ‘¡)satisfies the following conditions:
6119KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
(a)Â Overall Architecture
Value Calibrator Shape Calibrator
SFSC SFSC
0.10.7
0.2
pCTRlookup
table
bucketidMLP
fieldiemb (emb) emb(b) S ingle Field Shape Calibrator
Embedding
AugmentSoftmax
Softmax
Global
Shape
AttentionSFSC
pCTR fields value dot-pr oduct
inner -
productMulti-Field
Shape EnsembleShape
Pre-defineattention
scoressum sigmoid
inverse
sigmoid
Figure 4: (a) Overall architecture of DESC, its input includes the non-calibrated pCTR and the original fields, and the final
output is the calibrated pCTR. It is end-to-end trainable. (b) Single Field Shape Calibrator takes one field and the non-calibrated
pCTR as inputs and outputs the calibrated shape score for this field.
1.The function is monotonically non-decreasing and continuous
in range(0,1).
2.Whenğ‘¡approaches 0+, the limit ofB(ğ‘¡)is 0, and when ğ‘¡
approaches 1âˆ’, the limit ofB(ğ‘¡)is 1 (Equation 5).
lim
ğ‘¡â†’0+B(ğ‘¡)=0ğ‘ğ‘›ğ‘‘ lim
ğ‘¥â†’1âˆ’B(ğ‘¡)=1 (5)
We pre-define ğ‘šbasis functions consisting of ğ‘power functions,
ğ‘™logarithmic functions and ğ‘ scaling functions (shown in Equa-
tion 6). These functions exhibit different shape characteristics,
and their shapes vary when the hyper-parameters (e.g. the coeffi-
cients in these basis calibration functions) are different. We choose
predefined functions over Multi-Layer Perceptron (MLP) because,
through data research, we have found that predefined functions
can address the issue of over- or underestimation for each subset of
pCTR within the specified range (shape calibration). Additionally,
predefined functions have a lower parameter count and superior
performance.
Compared to segmented linear functions in traditional calibra-
tion methods, including SIR, FAC, Ada, using basis calibration func-
tions doesnâ€™t require data segmentation. In other words, shape
learning can utilize all samples for training, significantly enhancing
the data utilization. Basis calibration functions include, but are not
limited toğ‘™ğ‘œğ‘”,ğ‘’ğ‘¥ğ‘andğ‘ ğ‘ğ‘ğ‘™ğ‘–ğ‘›ğ‘” . By analyzing the data, we find that
the combination of ğ‘™ğ‘œğ‘”,ğ‘’ğ‘¥ğ‘andğ‘ ğ‘ğ‘ğ‘™ğ‘–ğ‘›ğ‘” functions can satisfactorily
fulfill our requirements with ease.
B(ğ‘¡)={Bğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ
1,...,Bğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ
ğ‘
|                     {z                     }
ğ‘ğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ ğ‘“ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ ,Bğ‘™ğ‘œğ‘”
1,...,Bğ‘™ğ‘œğ‘”
ğ‘™|            {z            }
ğ‘™ğ‘™ğ‘œğ‘” ğ‘“ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ ,Bğ‘ ğ‘ğ‘ğ‘™ğ‘–ğ‘›ğ‘”
1,...,Bğ‘ ğ‘ğ‘ğ‘™ğ‘–ğ‘›ğ‘”
ğ‘ |                       {z                       }
ğ‘ ğ‘ ğ‘ğ‘ğ‘™ğ‘–ğ‘›ğ‘” ğ‘“ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ }
(6)
Bğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ
ğ‘–(ğ‘¡;â„ğ‘–)=ğ‘¥â„ğ‘– (7)
Bğ‘™ğ‘œğ‘”
ğ‘–(ğ‘¡;ğ‘£ğ‘–)=ğ‘™ğ‘œğ‘”(1+ğ‘£ğ‘–Â·ğ‘¡)
ğ‘™ğ‘œğ‘”(1+ğ‘£ğ‘–)(8)
Bğ‘ ğ‘ğ‘ğ‘™ğ‘–ğ‘›ğ‘”
ğ‘–(ğ‘¡;ğ‘ğ‘–)=ğœ(ğœâˆ’1(ğ‘¡)Â·ğ‘ğ‘–), (9)
ğ‘¤â„ğ‘’ğ‘Ÿğ‘’ğœ(ğ‘¡)=1
1+ğ‘’ğ‘¥ğ‘(âˆ’ğ‘¡)ğ‘ğ‘›ğ‘‘ğœâˆ’1(ğ‘¡)=ğ‘™ğ‘œğ‘”(ğ‘¡
1âˆ’ğ‘¡) (10)
0.0 0.5 1.00.00.51.0S(x)
0.0 0.5 1.00.00.51.0=  0.5 * scaling(x;0.5)
0.0 0.5 1.00.00.51.0+  0.5 * scaling(x;3.8)
Figure 5: Complex shape can be composed of simple shapes.
â„ğ‘–,ğ‘£ğ‘–andğ‘ğ‘–(â„ğ‘–,ğ‘£ğ‘–,ğ‘ğ‘–âˆˆR+) are parameters of basis calibration
functions. For each type of basic calibration function, we pre-define
these parameters using equally spaced floats (e.g., [0.1,0.3,0.5,0.7]),
which can be set as trainable.
However,B(ğ‘¡)can only represent simple shapes, and complex
shapes can be composed of simple shapes, as shown in Figure 5.
Therefore, we need to combine these basis calibration functions
through weighted summation to create shape function Sğ‘–(ğ‘¥)ca-
pable of representing complex shapes for ğ‘–-th field, as shown in
Equation 11, where ğ›¼ğ‘—
ğ‘–refers to the attention weight of ğ‘—-th basis
function for ğ‘–-th field, which will be explained in next section.
Sğ‘–(ğ‘¥)=ğ‘šâˆ‘ï¸
ğ‘—=1ğ›¼ğ‘—
ğ‘–Â·Bğ‘—(ğ‘¡),Bğ‘—(ğ‘¡)âˆˆB(ğ‘¡) (11)
4.1.2 Shape Allocation. In shape allocation, we allocate suitable
shape functions based on feature values. These features include
two parts: pCTR bucket feature and original field features. PCTR
bucket feature categorizes pCTR into intervals. For example, 0 to
0.001 is bucket 1, and 0.001 to 0.003 is bucket 2. Introducing pCTR
bucket feature allows for better shape allocation within different
pCTR intervals. The specific steps are as follows:
Step1. We pre-define the embedding size for each feature. Each
one-hot feature (including pCTR bucket feature ğ‘ğ‘¢ğ‘ğ‘˜ğ‘’ğ‘¡ Ë†ğ‘ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘and
original field ğ‘ğ‘–) is projected into a fixed-size dense embedding,
such as bË†puncalibandei. The bucket size of ğ‘ğ‘¢ğ‘ğ‘˜ğ‘’ğ‘¡ Ë†ğ‘ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘is assigned
as 100.
Step2. We concatenate embedding vectors into a Multi-Layer Per-
ceptron (MLP), followed by a softmax operation, the output ğ›¼ğ‘–
6120Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
size of softmax is 1Ã—ğ‘š, withğ›¼1
ğ‘–toğ›¼ğ‘š
ğ‘–, same as the number of
pre-defined basis functions.
ğ›¼ğ‘–=ğ‘†ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘€ğ¿ğ‘ƒ(bË†puncalib,ei)) (12)
Step3. Finally, we obtain the output value of the Shape Calibrator
Sğ‘–(ğ‘¥)forğ‘ğ‘–shown in the previous Equation 11.
In the shape allocation stage, the expressive ability of embed-
ding directly affects the ability of allocating shapes. For sparse
fields, we enhance the expressive ability of embeddings by using
self-attention. The specific formula is shown in following formula,
whereğ‘‘is the dimension of eandğ‘›is the number of fields.
X(ei)=ğ‘›âˆ‘ï¸
ğ‘—=1(ğ‘†ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(eiÂ·ejğ‘‡
âˆš
ğ‘‘)Â·ej)1[ğ‘–â‰ ğ‘—] (13)
That means: for more similar fields, their miscalibration distri-
butions will be similar. If the semantics between two embeddings
eiandejis similar, then the corresponding weight is also relatively
large.
ğ›¼ğ‘–=ğ‘†ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘€ğ¿ğ‘ƒ(bË†puncalib,ei,X(ei))) (14)
Next, we concatenate the original embedding ei, the enhanced
output embedding X(ei), and the pCTR bucket embedding bË†puncalib.
Then, following the same process as in the shape allocation stage,
we generate the attention for shape allocation ğ›¼ğ‘–and perform the
final fusion.
4.1.3 Multi-Field Shape Ensemble. Different calibration values for
different fields can conflict with each other. For example, there
is a scenario where 19 to 26-year-old users demand for womenâ€™s
shoes. Under the item category field of "womenâ€™s shoes", the non-
calibrated model behaves 30% over-estimation of pCTR in the 0.01
to 0.03 range. However, under the user age field of "19 to 26", thereâ€™s
a 20% under-estimation of pCTR in the same 0.01 to 0.03 range.
Consequently, we not only need to perform shape calibration on
individual field but also need to globally harmonize the outputs of
shape calibrators for different fields. This helps reduce calibration
errors at a global level.
We use Global Shape Attention to combine the output results
obtained from different fields (Figure 4a). Global Shape Attention,
denoted as Î¨, is derived from the Global Shape Attention Generator
module (details will be elaborated in section 4.2.2). The size of Î¨is
1Ã—ğ‘›, with Î¨ğ‘–âˆˆ[0,1], andÃğ‘›
ğ‘–=1Î¨ğ‘–=1. The fusion formula is as
follows, where there are a total of ğ‘›fields, and Sğ‘–(ğ‘¥)represents the
output of the shape calibrator for ğ‘–-th field.
S(ğ‘¥)=ğ‘›âˆ‘ï¸
ğ‘–=1Sğ‘–(ğ‘¥)Â·Î¨ğ‘– (15)
We finally obtain the output of Global Shape Calibrator: S(ğ‘¥).
4.2 Value Calibrator
The goal of the Value Calibrator is to ensure that, for each sample
ğ‘¥, there is no overall over- or under-estimation (value calibration).
We use all fields for Value Calibrator to achieve the best overall
performance, as described in section 4.2.1. Considering all fields
allows for the excellent allocation of shapes for each field, we use
global shape attention depicted in section 4.2.2.
MatchingLogs
Ranking Model Plugin DESC
Rankingfeaturestraining 
Save checkpoint
ResultrequestFigure 6: Real-Time calibration system used DESC method for
CXR (CTR/CVR) task in our industrial advertising system.
4.2.1 Global Field Value Calibrator. Global Field Value Calibrator
encompasses all the necessary information of the fields concerned.
We train a neural network to fix the field-level miscalibration or
biases by utilizing all necessary features[ 24]. These input fields are
projected into fixed-size dense representations, which are fed into
a neural network (the form of the neural network is not restricted,
here we use MLP). Then we get the middle output â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ and
the final output V(ğ‘¥)for the Global Field Value Calibrator. Finally,
by combining V(ğ‘¥)andS(ğ‘¥), we obtain the final calibrated output
Ë†ğ‘ğ‘ğ‘ğ‘™ğ‘–ğ‘=S(ğ‘¥)Â·V(ğ‘¥).
â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ =ğ‘€ğ¿ğ‘ƒ 1(ğ¶ğ‘œğ‘›ğ‘ğ‘ğ‘¡(bË†puncalib,e1,e2,...,eğ‘›)) (16)
V(ğ‘¥)=ğ‘€ğ¿ğ‘ƒ 2(â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ) (17)
4.2.2 Global Shape Attention Generator. The Global Field Value
Calibrator not only produces the final output but also yields valuable
intermediate representation. In this context, we use the intermedi-
ate representation â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ as input of Equation 18, which can
effectively learn information from all fields. After passing through
a MLP and softmax layer, it produces Global Shape Attention Î¨
with a size equal to the number of fields ğ‘›. In the Shape Calibra-
tion stage, the output produced by each field ğ‘ğ‘–is multiplied by
its corresponding score Î¨ğ‘–and summed to obtain the final Shape
Calibration Score.
Î¨=ğ‘†ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘€ğ¿ğ‘ƒ 3(â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ)) (18)
4.3 Online Deployment
The overall framework of the online service using the DESC cal-
ibration method in our industrial advertising system is shown in
Figure 6. When a real-time user request comes, all candidate items
are recalled and predicted with pCTRs by a non-calibration model
(ranking model). Then DESC model calibrates the pCTRs consider-
ing different field values, including user, item, and context features.
In detail, the input ğ‘¥of DESC has two parts: different field val-
ues and its non-calibrated score Ë†ğ‘ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘ . DESC uses a light neural
network to output the calibrated score Ë†ğ‘ğ‘ğ‘ğ‘™ğ‘–ğ‘, which is then used
to sort the final ranks for all candidate items. We have integrated
the DESC method as a plugin into the ranking model to reduce
maintenance costs while only adding a little more time (about 2ms
for one userâ€™s request) for online inference.
5 EXPERIMENTS
5.1 Experimental Setup
5.1.1 Datasets. To validate the effectiveness of our proposed DESC
method, we conduct experiments on two public datasets (AliCCP
andCRITEO for CTR prediction tasks) and one industrial dataset
(Shopee for CVR prediction task). CRITEO display advertising
6121KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
data1, which consists of 46 million samples. We split the samples
into 28 million samples as training set ( Dğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› ), 9 million samples
as validation set (Dğ‘‘ğ‘’ğ‘£) and other 9 million samples as testing set
(Dğ‘¡ğ‘’ğ‘ ğ‘¡).AliCCP (Alibaba Click and Conversion Prediction) [ 21]
2contains 80 million samples. We split these samples with the
proportion 2:1:1 to Dğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› ,Dğ‘‘ğ‘’ğ‘£andDğ‘¡ğ‘’ğ‘ ğ‘¡. To test DESC method
on CVR prediction task, we collect the conversion logs from the
Shopeeâ€™s online advertising system. It contains 100 million samples,
where the first 60 million for Dğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› , the next 20 million for Dğ‘‘ğ‘’ğ‘£
and the last 20 million for Dğ‘¡ğ‘’ğ‘ ğ‘¡.
5.1.2 Competing Methods. Several representative calibration meth-
ods are used as competitors. We tested several competitive methods,
including parametric methods, non-parametric methods, non-field-
aware hybrid methods and field-aware hybrid methods. Parametric
method contains Platt Scaling (PS) [ 25]. Non-parametric method
contains Histogram Binning (HB) [ 31] and Istonic Regression (IR)
[32]. Non-field-aware method contains Smooth Isotonic Regression
(SIR) [ 15] and Ensemble Temperature Scaling (ETS) [ 34]. Field-
aware method contains FAC [24], Ada [29] and MBCT [13].
We use DeepFM [ 10] to train the non-calibrated models with all
fields inDğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› , and predict the non-calibrated scores in Dğ‘‘ğ‘’ğ‘£and
Dğ‘¡ğ‘’ğ‘ ğ‘¡. DeepFM consists of both the fully connected part and the FM
part. We utilized the open-source DeepFM "from deepctr.models
import DeepFM" and incorporated all features into DeepFM.
All calibration methods are trained using samples of Dğ‘‘ğ‘’ğ‘£and
are tested using samples of Dğ‘¡ğ‘’ğ‘ ğ‘¡.
5.1.3 Parameter Configuration. For all neural calibrators, including
FAC, Ada and DESC, we use Adam as the optimizer with a learning
rate of 1e-3 and batch size of 16,384. For the embedding size of field
valueğ‘‘, both FAC and Ada are set as 256 while for DESC, it is 128
because it obtains a better result. For FAC, we set the number of
bins to 100 while for Ada, the candidate set of bin numbers is set
{2, 4, 8} following in [ 29]. For DESC, the number of basis functions
ğ‘šis 48 (the numbers of the three types of basis functions are both
16), and the numbers of fields ğ‘›are 26, 23 and 10 for Criteo, AliCCP
and Industrial dataset, respectively. For MBCT, we set the same
hyperparameters according to the paper.
5.1.4 Compared Metrics. Two commonly used metrics, F-RCE
(Field RCE) and F-ECE (Field ECE) for each field ğ‘ğ‘–are used. To
calculate the F-RCE of ğ‘–-th field (shown in Equation 19), we use
the testing dataset Dğ‘¡ğ‘’ğ‘ ğ‘¡(for simplicity,Drefers toDğ‘¡ğ‘’ğ‘ ğ‘¡here)
consisting of(ğ‘¥ğ‘—,ğ‘¦ğ‘—), whereğ‘¥ğ‘—andğ‘¦ğ‘—mean the input features
with different fields and clicked label of ğ‘—-th sample. The subset of
Dğ‘§has the samples with the same value ğ‘§forğ‘–-th field. F-RCE of
ğ‘–-th field evaluates the deviation level of each sampleâ€™s calibrated
probability Ë†ğ‘ğ‘—
ğ‘ğ‘ğ‘™ğ‘–ğ‘considering ğ‘—-th field.
Another metric is the F-ECE of ğ‘–-th field. As shown in Equation
20, it can be calculated for each subset ğ·ğ‘§of samples with the same
value inğ‘–-th field. We can calculate the subset of F-ECE (shown
in Equation 21) by partitioning predictions into ğ‘€equally-spaced
bins and taking a weighted average of the difference between binsâ€™
accuracy and confidence. In detail, firstly we sort the samples by
the non-calibrated scores Ë†ğ‘ğ‘—
ğ‘¢ğ‘›ğ‘ğ‘ğ‘™ğ‘–ğ‘. Then all samples are grouped
intoğ‘€interval bins. For all samples ( ğµğ‘š) inğ‘š-th bin, we calculate
1https://www.kaggle.com/c/criteo-display-ad-challenge
2https://tianchi.aliyun.com/datalab/dataSet.html?dataId=408the accuracy and confidence, where the accuracy is the average of
labels and the confidence is the average of calibrated scores.
ğ¹-ğ‘…ğ¶ğ¸ğ‘–=1
|D|âˆ‘ï¸
ğ‘§âˆˆğ‘ğ‘–|Ã
(ğ‘¥ğ‘—,ğ‘¦ğ‘—)âˆˆDğ‘§(ğ‘¦ğ‘—âˆ’Ë†ğ‘ğ‘—
ğ‘ğ‘ğ‘™ğ‘–ğ‘)|
1
|Dğ‘§|Ã
(ğ‘¥ğ‘—,ğ‘¦ğ‘—)âˆˆDğ‘§ğ‘¦ğ‘—(19)
ğ¹-ğ¸ğ¶ğ¸ğ‘–@ğ‘€=1
|D|âˆ‘ï¸
ğ‘§âˆˆğ‘ğ‘–|Dğ‘§|Â·(ğ¹-ğ¸ğ¶ğ¸Dğ‘§@ğ‘€) (20)
ğ¹-ğ¸ğ¶ğ¸Dğ‘§@ğ‘€=ğ‘€âˆ‘ï¸
ğ‘š=1|ğµğ‘š|
|Dğ‘§||ğ‘ğ‘ğ‘(ğµğ‘š)âˆ’ğ‘ğ‘œğ‘›ğ‘“(ğµğ‘š)| (21)
ğ‘ğ‘ğ‘(ğµğ‘š)=1
|ğµğ‘š|âˆ‘ï¸
ğ‘—âˆˆğµğ‘šğ‘¦ğ‘—, ğ‘ğ‘œğ‘›ğ‘“(ğµğ‘š)=1
|ğµğ‘š|âˆ‘ï¸
ğ‘—âˆˆğµğ‘šË†ğ‘ğ‘—
ğ‘ğ‘ğ‘™ğ‘–ğ‘(22)
As explained that the traditional field-aware calibration methods,
such as FAC [ 24] and Ada [ 29], only consider one field to calibrate,
these methods do not take into account the influence of other fields
on the calibration results. We found that the calibration results from
these models only training on one field perform poorly on other
fields. So we use the Multi-Field RCE (MF-RCE) and Multi-Field
ECE (MF-ECE) on all fields to compare different methods as follows:
ğ‘€ğ¹-ğ‘…ğ¶ğ¸=1
ğ‘›âˆ‘ï¸
ğ‘–ğ¹-ğ‘…ğ¶ğ¸ğ‘– (23)
ğ‘€ğ¹-ğ¸ğ¶ğ¸ @ğ‘€=1
ğ‘›âˆ‘ï¸
ğ‘–ğ¹-ğ¸ğ¶ğ¸ğ‘–@ğ‘€, (24)
whereğ‘›is the number of fields.
We use F-RCE and F-ECE as the primary empirical metrics to
compare the calibration errors of different calibration methods on
one field and MF-RCE and MF-ECE to test on all fields. Besides,
we also report the overall ranking performance by using AUC
and Log-loss metrics. Since PCOC (Predicted Click Over Click)
[8,12] and ECE (Expected Calibration Error) [ 13] indicators can be
achieved well for all competing methods, and F-ECE and MF-ECE,
as compared to the traditional ECE, can provide a finer-grained
representation of calibration error in the context of field-aware
problems, PCOC and ECE are not listed in the main results.
5.2 Main Results
5.2.1 Results on One Field. As other hybrid field-aware based meth-
ods only consider one field to calibrate, we compare our proposed
method in one field in the same way. We select the field of "C2" (577
unique values) in Criteo, "853" (39,979 unique values) in AliCCP
and "item ID" (5 million unique values) in Industrial data to perform
our experiments. As shown in Table 1, the AUCs of all calibrators
are higher than the uncalibrator while all other calibration-related
metrics (F-ECE, F-RCE) of calibrators are smaller than the uncali-
brator, which shows that the calibration methods can improve the
accuracy of pCTR while maintaining a certain increase in ranking
performance. Specially, by fusing multiple fields in shape allocation
and shape augmentation, our proposed DESC can achieve much
smaller calibration errors compared to other competitors even in
one field evaluation. Itâ€™s worth explaining that DESC performs
much better than other competitors in industrial data than public
data. The reason is that DESC behaves better in calibration per-
formance in this scene where the data sparsity is more serious in
practical industrial data.
6122Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 1: Results of different methods for calibrating CTR predictive models on public and industrial datasets for one field.
Type MethodCriteo AliCCP Industrial Data
AUCâ†‘Log-lossâ†“F-RCEâ†“F-ECE@3â†“AUCâ†‘Log-lossâ†“F-RCEâ†“F-ECE@3â†“AUCâ†‘Log-lossâ†“F-RCEâ†“F-ECE@3â†“
No Calib. N/A 0.7949 0.4559 0.0426 0.0119 0.6130 0.1611 0.0876 0.0135 0.8613 0.5212 0.0743 0.0253
Non-ParamHB 0.7944 0.4562 0.0328 0.0112 0.6128 0.1621 0.0852 0.0130 0.8610 0.5218 0.0669 0.0204
IR 0.7949 0.4559 0.0320 0.0110 0.6130 0.1611 0.0843 0.0132 0.8613 0.5212 0.0665 0.0202
Param PS 0.7949 0.4559 0.0301 0.0105 0.6130 0.1611 0.0841 0.0128 0.8613 0.5212 0.0660 0.0201
Non-Field-
AwareSIR 0.7949 0.4559 0.0300 0.0097 0.6130 0.1611 0.0836 0.0127 0.8613 0.5211 0.0660 0.0201
ETS 0.7949 0.4559 0.0293 0.0095 0.6130 0.1611 0.0837 0.0127 0.8613 0.5212 0.0661 0.0199
Field-
AwareFAC 0.7991 0.4523 0.0265 0.0087 0.6751 0.1571 0.0829 0.0123 0.8634 0.5203 0.0402 0.0163
Ada 0.7992 0.4521 0.0273 0.0089 0.6752 0.1568 0.0832 0.0125 0.8639 0.5201 0.0413 0.0170
MBCT 0.7951 0.4550 0.0248 0.0095 0.6742 0.1611 0.0828 0.0128 0.8621 0.5209 0.0409 0.0175
DESC 0.7992 0.4522 0.0203 0.0080 0.6774 0.1566 0.0821 0.0120 0.8641 0.5192 0.0307 0.0132
Table 2: Results of different methods for calibrating CTR predictive models on public and industrial datasets for all fields.
Type MethodCriteo AliCCP Industrial Data
MF-RCEâ†“MF-ECE@3â†“MF-RCEâ†“MF-ECE@3â†“MF-RCEâ†“MF-ECE@3â†“
No Calib. N/A 0.0702 0.0142 0.1492 0.0143 0.0793 0.0370
Non-ParamHB 0.0692 0.0134 0.1430 0.0135 0.0779 0.0250
IR 0.0688 0.0131 0.1427 0.0131 0.0766 0.0249
Param PS 0.0685 0.0130 0.1420 0.0129 0.0765 0.0248
Non-Field-
AwareSIR 0.0686 0.0131 0.1422 0.0130 0.0764 0.0247
ETS 0.0683 0.0127 0.1470 0.0129 0.0761 0.0248
Field-
AwareFAC 0.0517 0.0101 0.1321 0.0120 0.0412 0.0183
Ada 0.0501 0.0102 0.1338 0.0122 0.0415 0.0180
MBCT 0.0660 0.0104 0.1357 0.0125 0.0430 0.0192
DESC 0.0489 0.0099 0.1264 0.0115 0.03606 0.0132
5.2.2 Results on All Fields. As DESC can consider the effects of
different fields on calibration, we need to evaluate its performance
on all fields. As shown in Table 2, the conclusion is consistent with
the smallest calibration errors on all three datasets.
5.3 In-Depth Analysis
5.3.1 Model Structure Ablation Experiment for DESC. We perform
some model structure ablation experiments to validate the signifi-
cance and effectiveness.
(1) Ablation Experiment of Shape Calibrator. To evaluate
the effectiveness of the Shape Calibrator and Value Calibrator, we
delete the corresponding module and left the other parts unchanged.
Firstly, we delete the Shape Calibrator sub-module, the AUC reduces
to 0.6602 while the metrics of MF-RCE and MF-ECE@3 on all fields
are slightly larger than DESC with 0.1434 and 0.0120 (first line on
Table. 3).
(2) Ablation Experiment of Value Calibrator. Secondly, we
delete another sub-module, the Value Calibrator. The phenomenon
is almost the same, with 0.6761 of AUC, and 0.1398 and 0.0119 of
MF-RCE and MF-ECE@3 on all fields (second line on Table. 3).
(3) Ablation Experiment of Multi-Field Shape Ensemble.
In METHODS section, we have emphasized that shape calibration
needs to consider multiple fields because different fields and values
can have numerous different shapes. Then, we only use mean-
pooling to compute the final predicted result considering different
fields ( Î¨ğ‘–is all the same with 1/ğ‘›in Equation 15). The results are
still inferior as shown in the third line in Table. 3.
(4) Ablation Experiment of pCTR Bucket Feature. The pCTR
bucket feature is concatenated with the field embedding to calculateTable 3: Ablation study of DESC on AliCCP.
Type AUCâ†‘Log-lossâ†“MF-RCEâ†“MF-ECE@3â†“
w/o Shape Calibrator 0.6602 0.1581 0.1434 0.0120
w/o Value Calibrator 0.6761 0.1567 0.1398 0.0119
w/o Multi-Field Shape Ensemble 0.6755 0.1568 0.1324 0.0116
w/o pCTR Bucket Feature 0.6764 0.1567 0.1391 0.0120
w/o Embedding Augment 0.6764 0.1567 0.1398 0.0119
DESC 0.6774 0.1566 0.1264 0.0115
the shape allocation weights in DESC (Equation 14). Then we delete
the pCTR bucket feature (fourth line on Table. 3) to verify that
different pCTR values can also have effects on the calibration shape.
(5) Ablation Experiment of Embedding Augmentation. To
enhance the expressive ability of embeddings, the self-attention
mechanism is used. Then we delete this part by using the original
Equation 12 rather than Equation 14. The fifth line on Table. 3
shows that the embedding augmentation mechanism can enhance
the representational power of embedding.
5.3.2 DESC exhibits a stronger data utilization capability. In this
part, we analyze the data utilization capabilities of different calibra-
tors from both a global perspective (overall down sampling) and an
individual perspective (field value sample quantity).
(1) Overall Down Sampling We further conducted experi-
ments to compare the calibration performance of four different
hybrid field-aware methods (FAC, Ada, MBCT and DESC) across
various sampling ratios. As shown in Figure 7, DESC exhibits a
distinct lower MF-ECE in the context of varying sampling ratios.
In a global perspective, this demonstrates that DESC exhibits a
stronger data utilization capability.
6123KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
0.2 0.4 0.6 0.8 1.0
Sampling Ratio0.01000.01050.01100.01150.01200.01250.0130MF-ECE@3
FAC
Ada
MBCT
DESC
Figure 7: Down sampling analysis in CRITEO.
Figure 8: Performance differences for the sample quantity
of the field value.
(2) Field Value Sample Quantity. We analysis the performance
differences among MBCT, FAC, Ada and DESC at sample quantity
aspect. We set the quantity of samples with a specific field value
(for the convenience of display, we use ğ‘™ğ‘œğ‘”10(ğ‘¥)) as the x-axis and
ğ¸ğ¸ğ‘…ğ¶ğ‘ğ‘™ğ‘–ğ‘ (Except Calibration Error Ratio) as the y-axis (the smaller
ğ¸ğ¸ğ‘…ğ¶ğ‘ğ‘™ğ‘–ğ‘ is, the better DESC is compared with other calibrators),
as shown in Figure 8.
ğ¸ğ¸ğ‘…ğ¶ğ‘ğ‘™ğ‘–ğ‘ =ğ¸ğ¶ğ¸ğ·ğ¸ğ‘†ğ¶
ğ¸ğ¶ğ¸ğ¶ğ‘ğ‘™ğ‘–ğ‘,ğ¶ğ‘ğ‘™ğ‘–ğ‘âˆˆ{ğ‘€ğµğ¶ğ‘‡,ğ¹ğ´ğ¶,ğ´ğ‘‘ğ‘} (25)
ECE (Expected Calibration Error) [ 13] is used as the calibration
error to explain the results. The ECE value ranges from (0,+âˆ].
The higher ECE value indicates higher calibration error and worse
performance. We can find that for the samples with small sized of
number,ğ¸ğ¸ğ‘… is less than 1, which means, from an individual per-
spective, that DESC possesses a stronger data utilization capability.
Figure 9: Performance differences for miscalibration com-
plexity aspect.
5.3.3 DESC Can Adapt to Complex Miscalibration Shapes. We anal-
ysis the performance differences among MBCT, FAC, Ada and DESC
at shape complexity.
From the perspective of pCTR, we divide the estimated pCTR
values into bins either with equal frequency or equal interval, and
each bin can calculate the PCOC (Predicted Click Over Click) [ 8,12]
to describe the over- and under-estimation within that bin.
For some cases, the over- and under-estimation within each bin
are close, while in other cases, there is a significant difference in
over- and under-estimation for each bin. We define the "Miscalibra-
tion Complexity" metric to characterize the disparity in over- and
under-estimation across different pCTR bins. We selected all field
values for a subset of fields. For field ğ‘§with a value ğ‘£, the samples
are divided into ğ‘„(ğ‘„>1) bins. The miscalibration complexity is
denoted as Dğ‘,ğ‘£as follows:
Dğ‘,ğ‘£=1
ğ‘„âˆ’1ğ‘„âˆ’1âˆ‘ï¸
ğ‘ğ‘–ğ‘›=1|ğ‘ƒğ¶ğ‘‚ğ¶ğ‘ğ‘–ğ‘›+1âˆ’ğ‘ƒğ¶ğ‘‚ğ¶ğ‘ğ‘–ğ‘›|. (26)
In general, the higher the miscalibration complexity, the higher
the disparity in over- and under-estimation within the bins. For a
calibrator, a higher miscalibration complexity indicates a greater
calibration challenge. On one hand, it requires higher precision in
shaping the accuracy of the calibration, and on the other hand, an
excessive reliance on posterior data can compromise the general-
ization capability of the calibrator.
We still use the ECE metric to characterize the calibration error
of different calibrators under the specific field value. We compare
MBCT, FAC, Ada, and DESC and obtain the ğ¸ğ¸ğ‘…ğ¶ğ‘ğ‘™ğ‘–ğ‘ .
For each calibrator and each field value, there is a corresponding
Dğ‘,ğ‘£value as the x-axis and ğ¸ğ¸ğ‘…ğ¶ğ‘ğ‘™ğ‘–ğ‘ as the y-axis. As shown in
Figure 9, we can observe that in the high Dğ‘,ğ‘£range, allğ¸ğ¸ğ‘…ğ¶ğ‘ğ‘™ğ‘–ğ‘
6124Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
values are less than 1, which indicates that DESC always performs
better in conditions of complex shapes compared to other methods.
5.4 Online Results
To prove the effectiveness of the proposed method, we further con-
duct real-world online experiments. We feed item ID with 5 million
unique values, category ID with 5,000 unique values, bidding type,
time, raw predict score and other features into DESC. Then the
model is deployed for online pCVR calibration on Shopeeâ€™s adver-
tising system. For the online A/B test, we build two experimental
buckets, each with ten percent of the traffic. One bucket was con-
figured with SIR [ 15] as the control group, while the other was
configured with DESC as the experimental group. We use the two
significant important business metrics CVR (Conversion Rate) and
GMV (Gross Merchandise Volume) to evaluate our calibration ef-
fectiveness. The online results over a 7-day period indicated that
DESC brings +2.5% on CVR and +4.0% on GMV compared to SIR.
These improvements verify the effectiveness and business values
of DESC in practical advertising system.
6 DISCUSSION
We propose a new calibration approach named DESC. Firstly, we put
forward multiple types of functions (e.g., power function, scaling
function, logarithmic function) as the basis functions. Secondly,
we allocate the appropriate basis functions to combine the shape
function given the specific field and specific value. Finally, all fields
are concatenated and used to calculate the weight for the calibration
value from each field, which can further improve the accuracy of
pCTR on multiple fields. Both offline and online experiments verify
that DESC achieves significant improvement. In future work, we
should explore the performance of our proposed method on other
machine learning tasks except CXR task. Also, we need to study
the reasons of miscalibration error in these machine learning tasks,
especially for CXR task, and find new technology ( e.g.data augment,
multi-tasking learning) to further improve the performance.
References
[1]Antonio Bella, CÃ¨sar Ferri, JosÃ© HernÃ¡ndez-Orallo, and MarÃ­a JosÃ© RamÃ­rez-
Quintana. 2010. Calibration of machine learning models. In Handbook of Research
on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques .
IGI Global, 128â€“146.
[2]Weijie Bian, Kailun Wu, Lejian Ren, Qi Pi, Yujing Zhang, Can Xiao, Xiang-Rong
Sheng, Yong-Nan Zhu, Zhangming Chan, Na Mou, et al .2022. CAN: feature
co-action network for click-through rate prediction. In Proceedings of the fifteenth
ACM international conference on web search and data mining. 57â€“65.
[3]Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,
Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al .
2016. Wide & deep learning for recommender systems. In Proceedings of the 1st
workshop on deep learning for recommender systems. 7â€“10.
[4]James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet,
Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al .2010.
The YouTube video recommendation system. In Proceedings of the fourth ACM
conference on Recommender systems. 293â€“296.
[5] Chao Deng, Hao Wang, Qing Tan, Jian Xu, and Kun Gai. 2021. Calibrating user
response predictions in online advertising. In Machine Learning and Knowledge
Discovery in Databases: Applied Data Science Track: European Conference, ECML
PKDD 2020, Ghent, Belgium, September 14â€“18, 2020, Proceedings, Part IV. Springer,
208â€“223.
[6]Chao Du, Zhifeng Gao, Shuo Yuan, Lining Gao, Ziyan Li, Yifan Zeng, Xiaoqiang
Zhu, Jian Xu, Kun Gai, and Kuang-Chih Lee. 2021. Exploration in online adver-
tising systems with deep uncertainty-aware learning. In Proceedings of the 27th
ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 2792â€“2801.
[7]Shai Feldman, Stephen Bates, and Yaniv Romano. 2023. Calibrated multiple-
output quantile regression with representation learning. Journal of Machine
Learning Research 24, 24 (2023), 1â€“48.[8]Thore Graepel, Joaquin Quinonero Candela, Thomas Borchert, and Ralf Herbrich.
2010. Web-scale bayesian click-through rate prediction for sponsored search
advertising in microsoftâ€™s bing search engine. Omnipress.
[9]Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. 2017. On calibration of
modern neural networks. In International conference on machine learning. PMLR,
1321â€“1330.
[10] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017.
DeepFM: a factorization-machine based neural network for CTR prediction. arXiv
preprint arXiv:1703.04247 (2017).
[11] Chirag Gupta, Aleksandr Podkopaev, and Aaditya Ramdas. 2020. Distribution-
free binary classification: prediction sets, confidence intervals and calibration.
Advances in Neural Information Processing Systems 33 (2020), 3711â€“3723.
[12] Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine
Atallah, Ralf Herbrich, Stuart Bowers, et al .2014. Practical lessons from predicting
clicks on ads at facebook. In Proceedings of the eighth international workshop on
data mining for online advertising. 1â€“9.
[13] Siguang Huang, Yunli Wang, Lili Mou, Huayue Zhang, Han Zhu, Chuan Yu,
and Bo Zheng. 2022. MBCT: Tree-Based Feature-Aware Binning for Individual
Uncertainty Calibration. In Proceedings of the ACM Web Conference 2022. 2236â€“
2246.
[14] Tongwen Huang, Zhiqi Zhang, and Junlin Zhang. 2019. FiBiNET: combining fea-
ture importance and bilinear feature interaction for click-through rate prediction.
InProceedings of the 13th ACM Conference on Recommender Systems. 169â€“177.
[15] Xiaoqian Jiang, Melanie Osl, Jihoon Kim, and Lucila Ohno-Machado. 2011.
Smooth isotonic regression: a new method to calibrate predictive models. AMIA
Summits on Translational Science Proceedings 2011 (2011), 16.
[16] Kevin B Korb. 1999. Calibration and the evaluation of predictive learners. In
Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence .
Citeseer, 73â€“77.
[17] Meelis Kull, Miquel Perello Nieto, Markus KÃ¤ngsepp, Telmo Silva Filho, Hao Song,
and Peter Flach. 2019. Beyond temperature scaling: Obtaining well-calibrated
multi-class probabilities with dirichlet calibration. Advances in neural information
processing systems 32 (2019).
[18] Meelis Kull, Telmo Silva Filho, and Peter Flach. 2017. Beta calibration: a well-
founded and easily implemented improvement on logistic calibration for binary
classifiers. In Artificial Intelligence and Statistics. PMLR, 623â€“631.
[19] Ananya Kumar, Percy S Liang, and Tengyu Ma. 2019. Verified uncertainty
calibration. Advances in Neural Information Processing Systems 32 (2019).
[20] Wonbin Kweon, SeongKu Kang, and Hwanjo Yu. 2022. Obtaining Calibrated
Probabilities with Personalized Ranking Models. In Proceedings of the AAAI
Conference on Artificial Intelligence, Vol. 36. 4083â€“4091.
[21] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun
Gai. 2018. Entire space multi-task model: An effective approach for estimating
post-click conversion rate. In The 41st International ACM SIGIR Conference on
Research & Development in Information Retrieval. 1137â€“1140.
[22] Dang Minh Nguyen, Chenfei Wang, Yan Shen, and Yifan Zeng. 2023. LightSAGE:
Graph Neural Networks for Large Scale Item Retrieval in Shopeeâ€™s Advertisement
Recommendation. In Proceedings of the 17th ACM Conference on Recommender
Systems. 334â€“337.
[23] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian
Nowozin, Joshua Dillon, Balaji Lakshminarayanan, and Jasper Snoek. 2019. Can
you trust your modelâ€™s uncertainty? evaluating predictive uncertainty under
dataset shift. Advances in neural information processing systems 32 (2019).
[24] Feiyang Pan, Xiang Ao, Pingzhong Tang, Min Lu, Dapeng Liu, Lei Xiao, and
Qing He. 2020. Field-aware calibration: a simple and empirically strong method
for reliable probabilistic predictions. In Proceedings of The Web Conference 2020.
729â€“739.
[25] John Platt et al .1999. Probabilistic outputs for support vector machines and com-
parisons to regularized likelihood methods. Advances in large margin classifiers
10, 3 (1999), 61â€“74.
[26] Ying Shan, T Ryan Hoens, Jian Jiao, Haijing Wang, Dong Yu, and JC Mao. 2016.
Deep crossing: Web-scale modeling without manually crafted combinatorial
features. In Proceedings of the 22nd ACM SIGKDD international conference on
knowledge discovery and data mining. 255â€“262.
[27] Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun
Lee. 2018. Billion-scale commodity embedding for e-commerce recommendation
in alibaba. In Proceedings of the 24th ACM SIGKDD international conference on
knowledge discovery & data mining. 839â€“848.
[28] Zhiqiang Wang, Qingyun She, and Junlin Zhang. 2021. MaskNet: Introducing
feature-wise multiplication to CTR ranking models by instance-guided mask.
arXiv preprint arXiv:2102.07619 (2021).
[29] Penghui Wei, Weimin Zhang, Ruijie Hou, Jinquan Liu, Shaoguo Liu, Liang Wang,
and Bo Zheng. 2022. Posterior Probability Matters: Doubly-Adaptive Calibra-
tion for Neural Predictions in Online Advertising. In Proceedings of the 45th
International ACM SIGIR Conference on Research and Development in Information
Retrieval. 2645â€“2649.
[30] Hao Yang, Ziliang Wang, Weijie Bian, and Yifan Zeng. 2023. Practice on Effectively
Extracting NLP Features for Click-Through Rate Prediction. In Proceedings of the
6125KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
32nd ACM International Conference on Information and Knowledge Management .
4887â€“4893.
[31] Bianca Zadrozny and Charles Elkan. 2001. Obtaining calibrated probability
estimates from decision trees and naive bayesian classifiers. In Icml, Vol. 1. 609â€“
616.
[32] Bianca Zadrozny and Charles Elkan. 2002. Transforming classifier scores into ac-
curate multiclass probability estimates. In Proceedings of the eighth ACM SIGKDD
international conference on Knowledge discovery and data mining. 694â€“699.
[33] Shuangfei Zhai, Keng-hao Chang, Ruofei Zhang, and Zhongfei Mark Zhang. 2016.
Deepintent: Learning attentions for online advertising with recurrent neuralnetworks. In Proceedings of the 22nd ACM SIGKDD international conference on
knowledge discovery and data mining. 1295â€“1304.
[34] Jize Zhang, Bhavya Kailkhura, and T Yong-Jin Han. 2020. Mix-n-match: Ensem-
ble and compositional methods for uncertainty calibration in deep learning. In
International conference on machine learning. PMLR, 11117â€“11128.
[35] Han Zhu, Junqi Jin, Chang Tan, Fei Pan, Yifan Zeng, Han Li, and Kun Gai. 2017.
Optimized cost per click in taobao display advertising. In Proceedings of the 23rd
ACM SIGKDD international conference on knowledge discovery and data mining.
2191â€“2200.
6126