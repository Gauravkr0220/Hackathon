Debiased Recommendation with Noisy Feedback
Haoxuan Li
Peking University
Beijing, China
hxli@stu.pku.edu.cnChunyuan Zheng
Peking University
Beijing, China
zhengchunyuan99@gmail.comWenjie Wang
National University of Singapore
Singapore, Singapore
wenjiewang96@gmail.com
Hao Wang
Zhejiang University
Hangzhou, China
haohaow@zju.edu.cnFuli Feng
University of Science and
Technology of China
fulifeng93@gmail.comXiao-Hua Zhouâˆ—
Peking University
Beijing, China
azhou@math.pku.edu.cn
Abstract
Ratings of a user to most items in recommender systems are usually
missing not at random (MNAR), largely because users are free to
choose which items to rate. To achieve unbiased learning of the
prediction model under MNAR data, three typical solutions have
been proposed, including error-imputation-based (EIB), inverse-
propensity-scoring (IPS), and doubly robust (DR) methods. How-
ever, these methods ignore an alternative form of bias caused by
the inconsistency between the observed ratings and the usersâ€™ true
preferences, also known as noisy feedback or outcome measure-
ment errors (OME), e.g., due to public opinion or low-quality data
collection process. In this work, we study intersectional threats to
the unbiased learning of the prediction model from data MNAR and
OME in the collected data. First, we design OME-EIB, OME-IPS, and
OME-DR estimators, which largely extend the existing estimators
to combat OME in real-world recommendation scenarios. Next, we
theoretically prove the unbiasedness and generalization bound of
the proposed estimators. We further propose an alternate denoising
training approach to achieve unbiased learning of the prediction
model under MNAR data with OME. Extensive experiments are con-
ducted on three real-world datasets and one semi-synthetic dataset
to show the effectiveness of our proposed approaches. The code is
available at https://github.com/haoxuanli-pku/KDD24-OME-DR.
CCS Concepts
â€¢Information systems â†’Recommender systems.
Keywords
Bias, Debias, Noisy Feedback, Recommender Systems
ACM Reference Format:
Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-
Hua Zhou. 2024. Debiased Recommendation with Noisy Feedback. In Pro-
ceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and
âˆ—Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671915Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3637528.3671915
1 Introduction
Recommender systems (RS) are designed to generate meaningful
recommendations to a collection of users for items or products
that might interest them, which have made a number of significant
advancements in recent years [ 53,72,85,88]. Nevertheless, direct
use of these advanced models in real-world scenarios while ignoring
the presence of numerous biases in the collected data can lead to
sub-optimal performance of the rating prediction model [ 6,80,81].
Among these, the problem of missing data is particularly prevalent,
as users are free to choose items to rate and the ratings with a lower
value are more likely to be missing [ 12], leading to the collected
data in RS is always missing not at random (MNAR) [ 41]. MNAR
ratings pose a serious challenge to the unbiased evaluation and
learning of the prediction model because the observed data might
not faithfully represent the entirety of user-item pairs [59, 73].
To tackle this problem, previous studies evaluate the perfor-
mance of a prediction model by computing the prediction inaccuracy :
the average of the prediction errors (e.g., the squared difference be-
tween a predicted rating and the potentially observed rating) for all
ratings [ 54,56]. To unbiasedly estimate the prediction inaccuracy
when the ratings are partially observable, three typical approaches
have been proposed, including: (1) The error-imputation-based
(EIB) approaches [ 18,65], which compute an imputed error for
each missing rating. (2) The inverse-propensity-scoring (IPS) ap-
proaches [ 58,59], which inversely weight the prediction error for
each observed rating with the probability of observing that rating.
(3) The doubly robust (DR) approaches [ 28â€“30,64], which use both
the error imputation model and the propensity model to estimate
the prediction inaccuracy, and the estimation is unbiased when
either the imputed errors or the learned propensities are accurate.
Despite the widespread use of these methods, they ignore an
alternative form of bias caused by the inconsistency between the
observed ratings and the usersâ€™ true preferences, also known as
noisy feedback or outcome measurement errors (OME). Similar to
selection bias, OME also arises from systematic bias during the data
collection. For example, the collected user feedback may differ from
the true user preferences due to the influence of public opinions [ 89].
Meanwhile, low-quality data collection such as recommender at-
tacks [ 16] or carelessly filling out the after-sales assessment can
also result in noisy user feedback [ 71]. Therefore, to make current
debiased recommendation techniques more applicable to real-world
 
1576
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
scenarios that may contain OME, it is worthwhile to develop new
model evaluation criteria and corresponding estimators to achieve
unbiased learning under OME.
In this work, we study intersectional threats to the unbiased
learning of the prediction model introduced by data MNAR and
OME from historical interactions, where the observed ratings are
not only MNAR but may differ from the true ratings due to the
presence of OME. In such a context, a natural evaluation criterion
for the prediction models is proposed, called true prediction inac-
curacy : the average of the trueprediction errors (e.g., the squared
difference between a predicted rating and the true rating) for all
ratings. Given the collected data with OME, the true prediction
errors are difficult to obtain even for the observed ratings, making
the previous debiasing estimators severely biased in estimating the
true prediction inaccuracy and training the rating prediction model.
To combat the influence of OME on the performance of the
prediction model, many data-driven error parameter estimation
methods are developed in recent machine learning literature [ 45,60,
61,79]. Meanwhile, given knowledge of measurement error parame-
ters, recent studies propose unbiased risk minimization approaches
for learning under noisy labels [ 9,44,49,67]. Despite the prevalence
of OME in real-world recommendation scenarios, there is still only
limited work focusing on denoising in RS [ 4,38,50,82]. For exam-
ple, [ 87] proposes to overcome noisy confounders by leveraging the
sensitivity analysis in the statistics literature. By noticing that noisy
feedback typically has large loss values in the early stages, [ 71]
proposes adaptive denoising training and [ 15] proposes self-guided
denoising learning for implicit feedback. However, most of these
methods are heuristic and lack theoretical guarantees of statistical
unbiasedness for estimating the true prediction inaccuracy.
To address the above problem, we extend the widely adopted
EIB, IPS, and DR estimators to achieve unbiased estimations with
the true prediction inaccuracy under OME, named OME-EIB, OME-
IPS, and OME-DR estimators, respectively. Our methods are built
upon the existing weak separability assumption [ 42], which states
that there exist "perfectly positive" and "perfectly negative" sam-
ples among the entire user-item pairs. Specifically, we discuss the
rationality of the weak separability assumption in real-world recom-
mendation scenarios and build up the linkage between the observed
and true outcome probabilities at specific instances, from which
we are able to obtain unbiased estimations of the measurement
error parameters. We also derive explicit forms of the biases and
the generalization bounds of the proposed OME-EIB, OME-IPS, and
OME-DR estimators under inaccurately estimated measurement
error parameters, from which we prove the double robustness of the
OME-DR estimator. We further propose an alternating denoise train-
ing approach to achieve unbiased learning of the prediction model,
which corrects for data MNAR and OME in parallel. In particular,
the imputation model learns to accurately estimate the prediction
errors made by the prediction model, while the prediction model
learns from the imputation model to reduce the prediction errors in
itself. In this way, the prediction and imputation models mutually
regularize each other to reduce both prediction and imputation
inaccuracies. The effectiveness of our proposed approaches is vali-
dated on three real-world datasets and one semi-synthetic dataset
with varying MNAR levels and OME rates. To the best of our knowl-
edge, our holistic evaluation is the first to examine how OME withits measurement error parametersâ€™ estimation in the context of
selection bias interact to affect the debiased recommendations.
The contributions of this paper are summarized as follows.
â€¢We formulate OME caused by the inconsistency between the
observed ratings and the usersâ€™ true preferences, and establish an
evaluation criterion for the unbiased learning of the prediction
model under OME, named true prediction inaccuracy.
â€¢We develop OME-EIB, OME-IPS, and OME-DR estimators for
unbiasedly estimating the true prediction inaccuracy of the pre-
diction model under MNAR data with OME, and theoretically
analyze the biases and generalization bounds of the estimators.
â€¢We further propose an alternating denoise training approach to
estimate the measurement error parameters and achieve unbiased
learning of the prediction model under MNAR data with OME,
which corrects for data MNAR and OME in parallel.
â€¢We conduct extensive experiments on three real-world datasets
and one semi-synthetic dataset, and the results demonstrate the
superiority of our methods with varying MNAR and OME rates.
2 Preliminaries
2.1 Task Formulation without OME
LetU={ğ‘¢1,...,ğ‘¢ğ‘}be a set of users,I={ğ‘–1,...,ğ‘–ğ‘€}a set of
items, andD=UÃ—I the collection of all user-item pairs. The po-
tentially observed rating matrix RâˆˆRğ‘Ã—ğ‘€comprises potentially
observed ratings ğ‘Ÿğ‘¢,ğ‘–, which represents the observed rating if user
ğ‘¢had rated the item ğ‘–. In RS, given the user-item features ğ‘¥ğ‘¢,ğ‘–, the
prediction model ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)parameterized by ğœƒaims to accurately
predict the ratings of all users for all items, and then recommend to
the user the items with the highest predicted ratings, as described
in [51]. The prediction matrix Ë†RâˆˆRğ‘Ã—ğ‘€comprises the predicted
ratingsğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)obtained from this prediction model. If the rating
matrix Rhad been fully observed, then the prediction inaccuracy P
of the prediction model can be measured using
P=P(Ë†R,R)=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘’ğ‘¢,ğ‘–,
whereğ‘’ğ‘¢,ğ‘–=â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿğ‘¢,ğ‘–)is the prediction error, and â„“(Â·,Â·)
is a pre-defined loss, such as the mean square error (MSE), i.e.,
ğ‘’ğ‘¢,ğ‘–=(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)âˆ’ğ‘Ÿğ‘¢,ğ‘–)2. LetOâˆˆ{0,1}ğ‘Ã—ğ‘€be an indicator matrix,
where each entry ğ‘œğ‘¢,ğ‘–is an observation indicator: ğ‘œğ‘¢,ğ‘–=1if the rat-
ingğ‘Ÿğ‘¢,ğ‘–is observed, and ğ‘œğ‘¢,ğ‘–=0if the rating ğ‘Ÿğ‘¢,ğ‘–is missing. Given
Rğ‘œas the set of the observed entries in the rating matrix R, the
rating prediction model aims to train the prediction model that min-
imizes the prediction inaccuracy P. Nonetheless, as users are free
to choose items to rate, leading to the collection of observational
data that is always missing not at random (MNAR) [ 12,41,83],
e.g., the ratings with a lower value are more likely to be miss-
ing. LetO=
(ğ‘¢,ğ‘–)|(ğ‘¢,ğ‘–)âˆˆD,ğ‘œğ‘¢,ğ‘–=1	be the set of user-item
pairs for the observed ratings, the direct use of the naive estima-
torEN=EN(Ë†R,Rğ‘œ)=1
|O|Ã
(ğ‘¢,ğ‘–)âˆˆOğ‘’ğ‘¢,ğ‘–that computes on the
observed data would yield severely biased estimation [59, 73].
2.2 Existing Estimators
To unbiasedly estimate the prediction inaccuracy Pgiven the par-
tially observed ratings Rğ‘œ, the error-imputation-based (EIB) ap-
proaches [ 18,65] compute an imputed error Ë†ğ‘’ğ‘¢,ğ‘–for each missing
 
1577Debiased Recommendation with Noisy Feedback KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
rating, and estimate the prediction inaccuracy with
EEIB(Ë†R,Rğ‘œ)=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆD(ğ‘œğ‘¢,ğ‘–ğ‘’ğ‘¢,ğ‘–+(1âˆ’ğ‘œğ‘¢,ğ‘–)Ë†ğ‘’ğ‘¢,ğ‘–),
which is an unbiased estimator of the prediction inaccuracy when
the imputed errors are accurate, i.e.,Ë†ğ‘’ğ‘¢,ğ‘–=ğ‘’ğ‘¢,ğ‘–.
The inverse-propensity-scoring (IPS) approaches [ 58,59] first
learn Ë†ğ‘ğ‘¢,ğ‘–as the estimate of the propensity ğ‘ğ‘¢,ğ‘–=P(ğ‘œğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–),
i.e., the probability of observing the rating, then inversely weight the
prediction error for each observed rating with the learned propen-
sity, and estimate the prediction inaccuracy with
EIPS(Ë†R,Rğ‘œ)=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–ğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–,
which is an unbiased estimator of the prediction inaccuracy when
the learned propensities are accurate, i.e.,Ë†ğ‘ğ‘¢,ğ‘–=ğ‘ğ‘¢,ğ‘–.
The doubly robust (DR) approaches [ 24â€“26,73] use both the
error imputation model and the propensity model to estimate the
prediction inaccuracy with
EDR(Ë†R,Rğ‘œ)=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆD
Ë†ğ‘’ğ‘¢,ğ‘–+ğ‘œğ‘¢,ğ‘–(ğ‘’ğ‘¢,ğ‘–âˆ’Ë†ğ‘’ğ‘¢,ğ‘–)
Ë†ğ‘ğ‘¢,ğ‘–
,
which is an unbiased estimator of the prediction inaccuracy when
either the imputed errors or the learned propensities are accurate,
i.e.,Ë†ğ‘’ğ‘¢,ğ‘–=ğ‘’ğ‘¢,ğ‘–orË†ğ‘ğ‘¢,ğ‘–=ğ‘ğ‘¢,ğ‘–, this is also known as double robustness.
3 Methodology
3.1 Task Formulation under OME
Despite many methods have been proposed for achieving unbi-
ased learning to tackle the data MNAR problem [ 27,56,59,70,73],
they ignore an alternative form of bias caused by the inconsis-
tency between the observed ratings and the usersâ€™ true prefer-
ences, also known as noisy feedback or outcome measurement
errors (OME). Both data MNAR and OME arise from systematic
bias during the data collection. In RS, two common scenarios that
cause incorrect user feedback signals include the influence of public
opinions [ 89], and the low-quality data collection such as recom-
mender attacks [ 16] or carelessly filling out the after-sales assess-
ments [ 71]. Formally, we denote Râˆ—as the userâ€™s true preference
matrix, with ğ‘Ÿâˆ—
ğ‘¢,ğ‘–as its entries, which may deviate from the poten-
tially observed ratings ğ‘Ÿğ‘¢,ğ‘–. LetP(ğ‘Ÿğ‘¢,ğ‘–=0|ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1)=ğœŒ01and
P(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0)=ğœŒ10be the false negative rate and false
positive rate, respectively, where ğœŒ01+ğœŒ10<1, then we have
P(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)=(1âˆ’ğœŒ01)Â·P(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)+ğœŒ10Â·P(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0|ğ‘¥ğ‘¢,ğ‘–).
To make current debiased recommendation techniques more
applicable to real-world scenarios that may contain OME, we then
establish a new model evaluation criterion for the unbiased learning
under OME, named true prediction inaccuracy, formally defined as
Pâˆ—=P(Ë†R,Râˆ—)=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘’âˆ—
ğ‘¢,ğ‘–,
whereğ‘’âˆ—
ğ‘¢,ğ‘–=â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿâˆ—
ğ‘¢,ğ‘–)is called the true prediction error.3.2 Proposed OME-EIB, OME-IPS, and OME-DR
Estimators
To achieve unbiased learning of ğ‘Ÿâˆ—
ğ‘¢,ğ‘–using MNAR data with OME, a
typical class of methods [ 36,44] propose the use of a surrogate loss
Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿğ‘¢,ğ‘–)based on the observed labels ğ‘Ÿğ‘¢,ğ‘–, which satisfies
Eğ‘Ÿ|ğ‘Ÿâˆ—[Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿğ‘¢,ğ‘–)]=â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿâˆ—
ğ‘¢,ğ‘–).
Considering the cases ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1andğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0separately, we have
(1âˆ’ğœŒ01)Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğœŒ01Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)=â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1),
(1âˆ’ğœŒ10)Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)+ğœŒ10Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)=â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0).
Solving these equations for Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)and Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)gives
Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)=(1âˆ’ğœŒ10)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)âˆ’ğœŒ01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
1âˆ’ğœŒ01âˆ’ğœŒ10,
Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)=(1âˆ’ğœŒ01)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)âˆ’ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
1âˆ’ğœŒ01âˆ’ğœŒ10.
However, the existing surrogate loss-based methods require fully
observed noisy labels ğ‘Ÿğ‘¢,ğ‘–, which prevents the direct use of such
methods for RS in the presence of missing data. To fill this gap,
motivated by the broad usage of EIB, IPS, and DR estimators in
the missing data literature [ 2,32], we extend the above surrogate
loss-based methods to address the data MNAR and OME in parallel.
Specifically, given knowledge of error parameters ğœŒ01andğœŒ10, let
Ëœğ‘’ğ‘¢,ğ‘–=ğ‘Ÿğ‘¢,ğ‘–Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+(1âˆ’ğ‘Ÿğ‘¢,ğ‘–)Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)be the surrogate
loss with the rating ğ‘Ÿğ‘¢,ğ‘–, the OME-EIB estimator estimates the true
prediction inaccuracy Pâˆ—=P(Ë†R,Râˆ—)with
EOMEâˆ’EIB(Ë†R,Rğ‘œ;ğœŒ01,ğœŒ10)=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆD(1âˆ’ğ‘œğ‘¢,ğ‘–)Â¯ğ‘’ğ‘¢,ğ‘–+
1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–ğ‘Ÿğ‘¢,ğ‘–{(1âˆ’ğœŒ10)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)âˆ’ğœŒ01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)}
1âˆ’ğœŒ01âˆ’ğœŒ10+
1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–(1âˆ’ğ‘Ÿğ‘¢,ğ‘–){(1âˆ’ğœŒ01)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)âˆ’ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)}
1âˆ’ğœŒ01âˆ’ğœŒ10,
where Â¯ğ‘’ğ‘¢,ğ‘–is the imputed error for estimating Ëœğ‘’ğ‘¢,ğ‘–, and OME-EIB is
an unbiased estimator of the true prediction inaccuracy when the
imputed errors are accurate, i.e.,Â¯ğ‘’ğ‘¢,ğ‘–=Ëœğ‘’ğ‘¢,ğ‘–. Since the proof is not
trivial, we postpone to show unbiasedness of OME-EIB estimator
and the following OME-IPS and OME-DR estimators in Sec. 3.4.
Similarly, the OME-IPS estimator estimates Pâˆ—=P(Ë†R,Râˆ—)with
EOMEâˆ’IPS(Ë†R,Rğ‘œ;ğœŒ01,ğœŒ10)=
1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–ğ‘Ÿğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–Â·(1âˆ’ğœŒ10)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)âˆ’ğœŒ01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
1âˆ’ğœŒ01âˆ’ğœŒ10+
1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–(1âˆ’ğ‘Ÿğ‘¢,ğ‘–)
Ë†ğ‘ğ‘¢,ğ‘–Â·(1âˆ’ğœŒ01)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)âˆ’ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
1âˆ’ğœŒ01âˆ’ğœŒ10,
where Ë†ğ‘ğ‘¢,ğ‘–is the learned propensity for estimating ğ‘ğ‘¢,ğ‘–, and OME-
IPS is an unbiased estimator of the true prediction inaccuracy when
the learned propensities are accurate, i.e.,Ë†ğ‘ğ‘¢,ğ‘–=ğ‘ğ‘¢,ğ‘–.
The OME-DR estimator estimates Pâˆ—=P(Ë†R,Râˆ—)with
 
1578KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
EOMEâˆ’DR(Ë†R,Rğ‘œ;ğœŒ01,ğœŒ10)=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆD
1âˆ’ğ‘œğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+
1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–ğ‘Ÿğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–Â·(1âˆ’ğœŒ10)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)âˆ’ğœŒ01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
1âˆ’ğœŒ01âˆ’ğœŒ10+
1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–(1âˆ’ğ‘Ÿğ‘¢,ğ‘–)
Ë†ğ‘ğ‘¢,ğ‘–Â·(1âˆ’ğœŒ01)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)âˆ’ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
1âˆ’ğœŒ01âˆ’ğœŒ10,
which is an unbiased estimate of the true prediction inaccuracy
when either the imputed errors or the learned propensities are
accurate, i.e.,Â¯ğ‘’ğ‘¢,ğ‘–=Ëœğ‘’ğ‘¢,ğ‘–orË†ğ‘ğ‘¢,ğ‘–=ğ‘ğ‘¢,ğ‘–.
3.3 Identification and Estimation of ğœŒ01andğœŒ10
The proposed OME-EIB, OME-IPS, and OME-DR estimators require
knowledge of the known error parameters ğœŒ01andğœŒ10, which are
usually not directly available from the collected data. By building
upon the existing weak separability assumption [ 42], we present a
data-driven identification and estimation method of ğœŒ01andğœŒ10.
We impose the following weak separability assumption that
inf
(ğ‘¢,ğ‘–)âˆˆDP(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)=0and sup
(ğ‘¢,ğ‘–)âˆˆDP(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)=1,
which also known as mutual irreducibility [ 60,61] in the observa-
tional label noise literature. This does not require the true ratings
to be separable, i.e.,P(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–) âˆˆ{ 0,1}for all user-item
pairs, but instead stipulates that there exist "perfectly positive"
and "perfectly negative" samples among the entire user-item pairs.
In real-world recommendation scenarios, the weak separability
assumption is easily satisfied, providing there exists at least one
"perfectly positive" feedback and one "perfectly negative" feedback
among the thousands of collected ratings. For example, in the movie
rating scenario, "perfectly positive" feedback refers to at least one of
the users who made a positive review of the movie is fully reliable,
and we do not need to know who that user exactly is.
By noting the linkage between the observed and the true ratings
P(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)=(1âˆ’ğœŒ01)P(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)+ğœŒ10P(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0|ğ‘¥ğ‘¢,ğ‘–)
=(1âˆ’ğœŒ01âˆ’ğœŒ10)P(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)+ğœŒ10,
which demonstrates the monotonicity between P(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)
andP(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)underğœŒ01+ğœŒ10<1, we have
(ğ‘¢<,ğ‘–<)=arg min
(ğ‘¢,ğ‘–)âˆˆDP(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)=arg min
(ğ‘¢,ğ‘–)âˆˆDP(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–),
(ğ‘¢>,ğ‘–>)=arg max
(ğ‘¢,ğ‘–)âˆˆDP(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)=arg max
(ğ‘¢,ğ‘–)âˆˆDP(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–).
Then, we can identify the error parameters ğœŒ01andğœŒ10via
ğœŒ01=1âˆ’P(ğ‘Ÿğ‘¢>,ğ‘–>=1|ğ‘¥ğ‘¢>,ğ‘–>)andğœŒ10=P(ğ‘Ÿğ‘¢<,ğ‘–<=1|ğ‘¥ğ‘¢<,ğ‘–<),
where P(ğ‘Ÿğ‘¢>,ğ‘–>=1|ğ‘¥ğ‘¢>,ğ‘–>)andP(ğ‘Ÿğ‘¢<,ğ‘–<=1|ğ‘¥ğ‘¢<,ğ‘–<)can be
unbiasedly estimated from the existing EIB, IPS, or DR estimators
for estimating P(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)without considering the OME.
3.4 Theoretical Analyses
Since the OME-DR estimator degenerates to the OME-IPS estimator
when Â¯ğ‘’ğ‘¢,ğ‘–=0, and degenerates to the OME-EIB estimator when
Ë†ğ‘ğ‘¢,ğ‘–=1, without loss of generality, we only analyze the explicit biasform of the OME-DR estimator. Following existing literature [ 59,
73], we assume that the indicator matrix Ocontains independent
random variables and each ğ‘œğ‘¢,ğ‘–follows a Bernoulli distribution with
probabilityğ‘ğ‘¢,ğ‘–. In addition, due to the presence of OME, we also
consider the randomness of the potentially observed ratings ğ‘Ÿğ‘¢,ğ‘–
given the true ratings ğ‘Ÿâˆ—
ğ‘¢,ğ‘–,e.g.,ğ‘Ÿğ‘¢,ğ‘–=1with probability 1âˆ’ğœŒ01
givenğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1, andğ‘Ÿğ‘¢,ğ‘–=0with probability ğœŒ01givenğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1.
Theorem 3.1 (Bias of OME-DR Estimator). Given Ë†ğœŒ01and Ë†ğœŒ10
with Ë†ğœŒ01+Ë†ğœŒ10<1, imputed errors Â¯Eand learned propensities Ë†Pwith
Ë†ğ‘ğ‘¢,ğ‘–>0for all user-item pairs, the bias of the OME-DR estimator is
Bias[EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)]=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆD
1âˆ’ğ‘œğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+
âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1ğ‘ğ‘¢,ğ‘–ğœ”11âˆ’Ë†ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğ‘ğ‘¢,ğ‘–ğœ”01
Ë†ğ‘ğ‘¢,ğ‘–â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
+
âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0ğ‘ğ‘¢,ğ‘–ğœ”10
Ë†ğ‘ğ‘¢,ğ‘–â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğ‘ğ‘¢,ğ‘–ğœ”00âˆ’Ë†ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0),
whereğœ”11,ğœ”01,ğœ”10, andğœ”00are given by
ğœ”11=1âˆ’ğœŒ01âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10, ğœ” 01=ğœŒ01âˆ’Ë†ğœŒ01
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10,
ğœ”10=ğœŒ10âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10, ğœ” 00=1âˆ’Ë†ğœŒ01âˆ’ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10.
The bias of the OME-DR estimator includes the three terms: (1)
The first term shares a similar form to the bias of the previous IPS
estimator and leads to smaller bias when Ë†ğ‘ğ‘¢,ğ‘–â‰ˆğ‘ğ‘¢,ğ‘–. (2) The second
term is novel for OME, specifically focusing on the estimated false
negative rate Ë†ğœŒ01that corresponds to the positive samples ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1.
Moreover, we find that ğœ”11=1andğœ”01=0when the the estimated
false negative rate Ë†ğœŒ01is accurate, i.e.,Ë†ğœŒ01=ğœŒ01, which results in
smaller bias when Â¯ğ‘’ğ‘¢,ğ‘–â‰ˆËœğ‘’ğ‘¢,ğ‘–. (3) The third term is similar to the
second term, but instead focuses on the estimated false positive
rate Ë†ğœŒ10that corresponds to the negative samples ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0, and also
results in smaller bias when Â¯ğ‘’ğ‘¢,ğ‘–â‰ˆËœğ‘’ğ‘¢,ğ‘–. Given the importance of
bias derivation for constructing estimators under OME, we provide
a proof sketch as below (see Appendix A for more details).
Proof Sketch. By definition, bias of the OME-DR estimator is
Bias[EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)]=ER,O[EOMEâˆ’DR]âˆ’Pâˆ—.
Then, we can derive the bias of the OME-DR estimator as follows
Bias[EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)]=ER|O[EO[EOMEâˆ’DR]]âˆ’Pâˆ—
=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1ER|O
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+ğ‘ğ‘¢,ğ‘–Ëœğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
âˆ’â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
+1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0ER|O
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+ğ‘ğ‘¢,ğ‘–Ëœğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
âˆ’â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0).
 
1579Debiased Recommendation with Noisy Feedback KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
For the user-item pairs with ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1, we have
ER|OËœğ‘’ğ‘¢,ğ‘–
=(1âˆ’ğœŒ01)Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1;Ë†ğœŒ01,Ë†ğœŒ10)+ğœŒ01Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0;Ë†ğœŒ01,Ë†ğœŒ10)
=(1âˆ’ğœŒ01)Â·(1âˆ’Ë†ğœŒ10)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)âˆ’ Ë†ğœŒ01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10
+ğœŒ01Â·(1âˆ’Ë†ğœŒ01)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)âˆ’ Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10
=1âˆ’ğœŒ01âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğœŒ01âˆ’Ë†ğœŒ01
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
:=ğœ”11â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğœ”01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0),
whereğœ”11andğœ”01are given by
ğœ”11=1âˆ’ğœŒ01âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10, ğœ” 01=ğœŒ01âˆ’Ë†ğœŒ01
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10.
Similar results hold for the user-item pairs with ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0that
ER|OËœğ‘’ğ‘¢,ğ‘–
=ğœŒ10âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+1âˆ’Ë†ğœŒ01âˆ’ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
:=ğœ”10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğœ”00â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0),
whereğœ”10andğœ”00are given by
ğœ”10=ğœŒ10âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10, ğœ” 00=1âˆ’Ë†ğœŒ01âˆ’ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10.
This completes the proof. â–¡
We formally describe double robustness under OME as follows.
Corollary 3.2 (Double Robustness). Given Ë†ğœŒ01=ğœŒ01and
Ë†ğœŒ10=ğœŒ10, the OME-DR estimator is unbiased when either imputed
errors Â¯Eor learned propensities Ë†Pare accurate for all user-item pairs.
The above result is obtained via substituting either Â¯ğ‘’ğ‘¢,ğ‘–=Ëœğ‘’ğ‘¢,ğ‘–or
Ë†ğ‘ğ‘¢,ğ‘–=ğ‘ğ‘¢,ğ‘–into the bias of the OME-DR estimator in Theorem 3.1.
Given the estimated error parameters Ë†ğœŒ01and Ë†ğœŒ01, we obtain the
optimal prediction model under OME by minimizing the OME-DR
estimator over a hypothesis space Fof the prediction models ğ‘“ğœƒ
Ë†Râ€¡=arg min
ğ‘“ğœƒâˆˆF{EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)}.
We next derive the generalization bound of the optimal prediction
model in terms of the empirical Rademacher complexity [ 62]. The
basic idea of proving the performance guarantee under OME is to
exploit the inheritance of the Lipschitz continuity from the ture
prediction loss â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿâˆ—
ğ‘¢,ğ‘–)to the surrogate loss Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿğ‘¢,ğ‘–).
Lemma 3.3 (Lipschitz Continuity). Given Ë†ğœŒ01and Ë†ğœŒ10with
Ë†ğœŒ01+Ë†ğœŒ10<1, ifâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿâˆ—
ğ‘¢,ğ‘–)isğ¿-Lipschitz in ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)for allğ‘Ÿâˆ—
ğ‘¢,ğ‘–,
then Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿğ‘¢,ğ‘–)is2ğ¿
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10-Lipschitz in ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)for allğ‘Ÿğ‘¢,ğ‘–.
The above lemma immediately leads to a generalization bound
with respect to the true ratings by using the contraction principle
for Rademacher complexity (see Appendix A for proofs).
Theorem 3.4 (Generalization Bound). Given Ë†ğœŒ01andË†ğœŒ10with
Ë†ğœŒ01+Ë†ğœŒ10<1, supposeâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿâˆ—
ğ‘¢,ğ‘–)isğ¿-Lipschitz in ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)for
allğ‘Ÿâˆ—
ğ‘¢,ğ‘–, and Ë†ğ‘ğ‘¢,ğ‘–â‰¥ğ¶ğ‘,|Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿğ‘¢,ğ‘–)|â‰¤ğ¶ğ‘™for allğ‘Ÿğ‘¢,ğ‘–, then with
probability 1âˆ’ğœ‚, the true prediction inaccuracy P(Ë†Râ€¡,Râˆ—)of theAlgorithm 1: Alternating Denoise Training with OME-DR.
Input: observed ratings Rğ‘œ, learned propensities Ë†ğ‘ğ‘¢,ğ‘–, initial
estimates Ë†ğœŒ01and Ë†ğœŒ10, a pre-trained model â„ğœƒâ€²(ğ‘¥ğ‘¢,ğ‘–)
for estimating P(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)via existing method.
1while stopping criteria is not satisfied do
2 fornumber of steps for training the denoising prediction
model do
3 Sample a batch{(ğ‘¢ğ‘—,ğ‘–ğ‘—)}ğ½
ğ‘—=1fromD;
4 Updateğœƒby descending along the gradient
âˆ‡ğœƒEOMEâˆ’DR(ğœƒ,ğœ™;Ë†ğœŒ01,Ë†ğœŒ10);
5(ğ‘¢<,ğ‘–<)â† arg min(ğ‘¢,ğ‘–)âˆˆDğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–);
6(ğ‘¢>,ğ‘–>)â† arg max(ğ‘¢,ğ‘–)âˆˆDğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–);
7 end
8 fornumber of steps for training the denoising imputation
model do
9 Ë†ğœŒ01â†1âˆ’â„ğœƒâ€²(ğ‘¥ğ‘¢>,ğ‘–>)and Ë†ğœŒ10â†â„ğœƒâ€²(ğ‘¥ğ‘¢<,ğ‘–<);
10 Sample a batch{(ğ‘¢ğ‘˜,ğ‘–ğ‘˜)}ğ¾
ğ‘˜=1fromO;
11 Updateğœ™by descending along the gradient
âˆ‡ğœ™LÂ¯ğ‘’(ğœƒ,ğœ™;Ë†ğœŒ01,Ë†ğœŒ10);
12 end
13end
optimal prediction matrix using the OME-DR estimator with imputed
errors Â¯Eand learned propensities Ë†Phas the upper bound
EOMEâˆ’DR(Ë†Râ€¡,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)+Bias[EOMEâˆ’DR(Ë†Râ€¡,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)]+

1+2
ğ¶ğ‘ï£®ï£¯ï£¯ï£¯ï£¯ï£°4ğ¿
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10R(F)+
ğ¶ğ‘™+4ğ¿
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10âˆšï¸„
2 log(4/ğœ‚)
|D|ï£¹ï£ºï£ºï£ºï£ºï£»,
whereR(F) is the empirical Rademacher complexity defined as
R(F) =Eğœâˆ¼{âˆ’ 1,+1}|D|sup
ğ‘“ğœƒâˆˆFï£®ï£¯ï£¯ï£¯ï£¯ï£°1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğœğ‘¢,ğ‘–ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)ï£¹ï£ºï£ºï£ºï£ºï£»,
in whichğœ={ğœğ‘¢,ğ‘–:(ğ‘¢,ğ‘–)âˆˆD} , andğœğ‘¢,ğ‘–are independent uniform
random variables taking values in {âˆ’1,+1}. The random variables
ğœğ‘¢,ğ‘–are called Rademacher variables.
3.5 Alternating Denoise Training Approach
We further propose an alternating denoise training approach to
achieve unbiased learning of the prediction model, which corrects
for data MNAR and OME in parallel. Specifically, we first train a
propensity model using the observed MNAR data. Based on the
estimated propensities, the denoising prediction and imputation
models are alternately updated, which also facilitates the accurate
estimations Ë†ğœŒ01and Ë†ğœŒ10of the error parameters ğœŒ01andğœŒ10.
Propensity Estimation via Logistic Regression. Since unbiased
ratings are difficult to be collected in the real-world scenarios [ 57],
following previous studies [ 23,59], we adopt logistic regression
to train a propensity model Ë†ğ‘ğ‘¢,ğ‘–=ğœ(ğ‘¤âŠ¤ğ‘¥ğ‘¢,ğ‘–+ğ›½ğ‘¢+ğ›¾ğ‘–)parameter-
ized byğœ“=(ğ‘¤,ğ›½ 1,...,ğ›½ğ‘,ğ›¾1,...,ğ›¾ğ‘€)using the observed MNAR
data, where ğœ(Â·)is the sigmoid function, ğ‘¤âˆˆRğ‘+ğ‘€is the weight
 
1580KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
Table 1: RE on ML-100K dataset with ğœŒ01= 0.2 andğœŒ10= 0.1. The best two results are bolded and the best baseline is underlined.
RO
TATE SKEW CRS ONE THREE FIVE
Naiv
e [20] 0.125Â±0.002
0.179Â±0.001 0.175Â±0.002 0.241Â±0.002 0.264Â±0.003 0.299Â±0.003
OME ( Ë†ğœŒ01,Ë†ğœŒ10) 0.087Â±0.006
0.163Â±0.002 0.104Â±0.014 0.161Â±0.013 0.179Â±0.014 0.213Â±0.014
OME (ğœŒ01,ğœŒ10) 0.024Â±0.003 0.136Â±0.002
0.105Â±0.004 0.067Â±0.004 0.076Â±0.004 0.100Â±0.004
MRDR
[17] 0.098Â±0.003
0.089Â±0.001 0.099Â±0.002 0.172Â±0.004
0.190Â±0.004 0.194Â±0.004
SDR [29] 0.097Â±0.002
0.089Â±0.001 0.102Â±0.002 0.172Â±0.003 0.191Â±0.003 0.194Â±0.003
TDR [23] 0.092Â±0.002
0.080Â±0.001 0.103Â±0.002
0.171Â±0.003 0.189Â±0.003 0.195Â±0.003
EIB
[65] 0.366Â±0.001
0.256Â±0.001 0.150Â±0.001 0.562Â±0.001 0.605Â±0.001 0.635Â±0.001
OME-EIB ( Ë†ğœŒ01,Ë†ğœŒ10) 0.362Â±0.001
0.255Â±0.001 0.144Â±0.001 0.554Â±0.001 0.598Â±0.001 0.627Â±0.001
OME-EIB (ğœŒ01,ğœŒ10) 0.357Â±0.001
0.253Â±0.001 0.144Â±0.001 0.546Â±0.001 0.589Â±0.001 0.618Â±0.001
IPS
[59] 0.110Â±0.002
0.116Â±0.002 0.134Â±0.003 0.212Â±0.004 0.231Â±0.004 0.254Â±0.004
OME-IPS ( Ë†ğœŒ01,Ë†ğœŒ10) 0.060Â±0.003
0.096Â±0.002 0.075Â±0.017 0.111Â±0.006 0.125Â±0.007 0.144Â±0.007
OME-IPS (ğœŒ01,ğœŒ10)0.013Â±0.003âˆ—0.068Â±0.003âˆ—0.052Â±0.004âˆ—0.034Â±0.005âˆ—0.038Â±0.006âˆ—0.050Â±0.005âˆ—
DR
[56] 0.106Â±0.002
0.087Â±0.001 0.104Â±0.002 0.190Â±0.003 0.209Â±0.003 0.216Â±0.003
OME-DR ( Ë†ğœŒ01,Ë†ğœŒ10) 0.056Â±0.004
0.067Â±0.001 0.045Â±0.018 0.090Â±0.006 0.102Â±0.006 0.106Â±0.007
OME-DR (ğœŒ01,ğœŒ10) 0.009Â±0.003âˆ—0.039Â±0.002âˆ—0.022Â±0.003âˆ—0.013Â±0.004âˆ—0.016Â±0.005âˆ—0.012Â±0.004âˆ—
Note: * means statistically significant results (p-value â‰¤0.05) using the paired-t-test compared with the best baseline.
vector,ğ›½ğ‘¢andğ›¾ğ‘–are the user-specific and item-specific constants,
respectively. We train the propensity model by minimizing the loss
Lğ‘(ğœ“)=âˆ’1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–log(Ë†ğ‘ğ‘¢,ğ‘–)+(1âˆ’ğ‘œğ‘¢,ğ‘–)log(1âˆ’Ë†ğ‘ğ‘¢,ğ‘–).
Denoising Prediction Model Training. Based on the learned
propensities Ë†ğ‘ğ‘¢,ğ‘–, imputed errors Â¯ğ‘’ğ‘¢,ğ‘–(ğœ™), and initial estimates Ë†ğœŒ01
and Ë†ğœŒ10, we train the denoising prediction model by minimizing
the estimated true prediction inaccuracy from the proposed OME-
DR estimatorEOMEâˆ’DR(ğœƒ,ğœ™;Ë†ğœŒ01,Ë†ğœŒ10). To obtain more accurate
estimates Ë†ğœŒ01and Ë†ğœŒ10from the training loop, we then compute the
minimum and maximum predicted ratings in the training batch
to update(ğ‘¢<,ğ‘–<)and(ğ‘¢>,ğ‘–>), respectively. The choice not to
employ a separate noisy rating prediction model for computing
(ğ‘¢<,ğ‘–<)and(ğ‘¢>,ğ‘–>)is guaranteed by the monotonicity between
P(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)andP(ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)(see Sec. 3.3 for proofs),
where the latter has a larger gap between the minimum and the
maximum, making it easier to distinguish (ğ‘¢<,ğ‘–<)and(ğ‘¢>,ğ‘–>).
Denoising Imputation Model Training. Given a pre-trained
modelâ„ğœƒâ€²(ğ‘¥ğ‘¢,ğ‘–)for estimating P(ğ‘Ÿğ‘¢,ğ‘–=1|ğ‘¥ğ‘¢,ğ‘–)via existing meth-
ods [ 59,73], we update the estimates Ë†ğœŒ01and Ë†ğœŒ10by computing
1âˆ’â„ğœƒâ€²(ğ‘¥ğ‘¢>,ğ‘–>)andâ„ğœƒâ€²(ğ‘¥ğ‘¢<,ğ‘–<), respectively. We finally train the
denoising imputation model Â¯ğ‘’ğ‘¢,ğ‘–(ğœ™)by minimizing the loss
LÂ¯ğ‘’(ğœƒ,ğœ™;Ë†ğœŒ01,Ë†ğœŒ10)=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–(Ëœğ‘’ğ‘¢,ğ‘–âˆ’Â¯ğ‘’ğ‘¢,ğ‘–)2
Ë†ğ‘ğ‘¢,ğ‘–.
The overall training process with OME-DR is summarized in Alg. 1.
4 Semi-Synthetic Experiments
To investigate if the proposed estimators are able to estimate the
true prediction inaccuracy accurately in the presence of OME and
MNAR effect, several semi-synthetic experiments are conducted on
a widely-used dataset MovieLens-100K (ML-100K). We first adopt
MF to complete the five-scaled rating matrix R. However, the com-
pleted matrix will have an unrealistic rating distribution, thus wesort the matrix entries in ascending order and assign a positive feed-
back probability of 0.1 for the lowest ğ‘1proportion, a positive feed-
back probability of 0.3 for the next ğ‘2proportion, and so on to obtain
a true positive feedback probability ğ›¾ğ‘¢,ğ‘–for each user-item pair. The
adjusted probability matrix contains ğ›¾ğ‘¢,ğ‘–âˆˆ{0.1,0.3,0.5,0.7,0.9}
with proportion[ğ‘1,ğ‘2,ğ‘3,ğ‘4,ğ‘5], respectively.
Second, following the previous studies [ 17,59,73], we use six
matrices below as the prediction matrix Ë†R:
â€¢ROTATE: Set predicted Ë†ğ‘Ÿğ‘¢,ğ‘–=ğ›¾ğ‘¢,ğ‘–âˆ’0.2whenğ›¾ğ‘¢,ğ‘–â‰¥0.3, and
Ë†ğ‘Ÿğ‘¢,ğ‘–=0.9whenğ›¾ğ‘¢,ğ‘–=0.1.
â€¢SKEW: Predicted Ë†ğ‘Ÿğ‘¢,ğ‘–are sampled from the Gaussian distribution
N(ğœ‡=ğ›¾ğ‘¢,ğ‘–,ğœ=(1âˆ’ğ›¾ğ‘¢,ğ‘–)/2), and clipped to the interval [0.1,0.9].
â€¢CRS: If the true ğ›¾ğ‘¢,ğ‘–â‰¤0.6, then Ë†ğ‘Ÿğ‘¢,ğ‘–=0.2. Otherwise, Ë†ğ‘Ÿğ‘¢,ğ‘–=0.6.
â€¢ONE: The predicted matrix Ë†Ris identical to the true positive
feedback probability matrix, except that randomly select ğ›¾ğ‘¢,ğ‘–=0.1
with total amount|{(ğ‘¢,ğ‘–)|ğ›¾ğ‘¢,ğ‘–=0.9}|are flipped to 0.9.
â€¢THREE: Same as ONE, but flipping ğ›¾ğ‘¢,ğ‘–=0.3instead.
â€¢FIVE: Same as ONE, but flipping ğ›¾ğ‘¢,ğ‘–=0.5instead.
Next, we assign the propensity ğ‘ğ‘¢,ğ‘–=ğ‘ğ›¼min(4,6âˆ’ğ‘Ÿğ‘¢,ğ‘–)for each
user-item pair and obtain the estimate propensities
1
Ë†ğ‘ğ‘¢,ğ‘–=1âˆ’ğ›½
ğ‘ğ‘¢,ğ‘–+ğ›½
ğ‘ğ‘’,
whereğ‘ğ‘’=|D|âˆ’1Ã
(ğ‘¢,ğ‘–)âˆˆDğ‘œğ‘¢,ğ‘–,ğ‘is set to 1 in our experiment
andğ›½is randomly sampled from a uniform distribution ğ‘ˆ(0,1)to
introduce noises. Then, we sample the binary true feedback matrix
Râˆ—and binary observation matrix Oas follows:
ğ‘œğ‘¢,ğ‘–âˆ¼Bern(ğ‘ğ‘¢,ğ‘–),âˆ€(ğ‘¢,ğ‘–)âˆˆD, ğ‘Ÿâˆ—
ğ‘¢,ğ‘–âˆ¼Bern(ğ›¾ğ‘¢,ğ‘–),âˆ€(ğ‘¢,ğ‘–)âˆˆD,
where Bern(Â·)denotes the Bernoulli distribution. Then we flip the
feedback matrix according to the ğœŒ01andğœŒ10to generate a binary
noise feedback matrix R. The absolute relative error (RE) is used for
evaluation, which is defined as RE(Eğ‘’ğ‘ ğ‘¡)=|Pâˆ—âˆ’Eğ‘’ğ‘ ğ‘¡(Ë†R,R)|/Pâˆ—,
whereEğ‘’ğ‘ ğ‘¡denotes the estimate prediction inaccuracy. The smaller
the RE, the more accurate the estimation. In addition, we provide
both results for using estimated Ë†ğœŒ01and Ë†ğœŒ10to estimatePâˆ—and
directly using true ğœŒ01andğœŒ10to estimatePâˆ—.
 
1581Debiased Recommendation with Noisy Feedback KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
(
a) Estimation error of Ë†ğœŒ01and Ë†ğœŒ10
 (
b) RE on EIB-based methods
 (
c) RE on IPS-based methods
 (
d) RE on DR-based methods
Figur
e 1: Estimation errors of Ë†ğœŒ01and Ë†ğœŒ10and RE with varying observed data ratios.
Table 2: Performance on AUC, NDCG@K, and Recall@K on the MAR test set of Coat, Music andKuaiRec withğœŒ01= 0.2 and
ğœŒ10= 0.1. The best three results are bolded, and the best baseline is underlined.
Co
at Music K
uaiRec
Metho
d AUC
NDCG@5 Recall@5 AUC
NDCG@5 Recall@5 AUC
NDCG@50 Recall@50
MF
[20] 0.619Â±0.002 0.531Â±0.005 0.364Â±0.005 0.632Â±0.005 0.616Â±0.003 0.361Â±0.001 0.621Â±0.002 0.652Â±0.003 0.702Â±0.002
OME
[36] 0.621Â±0.003 0.543Â±0.006 0.371Â±0.007 0.650Â±0.005 0.615Â±0.004 0.373Â±0.004 0.645Â±0.002 0.660Â±0.002 0.722Â±0.002
T
-MF [71] 0.633Â±0.004 0.540Â±0.005 0.372Â±0.006 0.650Â±0.005 0.614Â±0.003 0.376Â±0.004 0.657Â±0.002 0.665Â±0.002 0.739Â±0.003
R-MF
[71] 0.641Â±0.004 0.544Â±0.005 0.376Â±0.009 0.657Â±0.005 0.614Â±0.006 0.371Â±0.004 0.645Â±0.002 0.661Â±0.001 0.720Â±0.003
LCD-MF
[11] 0.631Â±0.003 0.552Â±0.0070.381Â±0.006 0.659Â±0.005 0.617Â±0.005 0.374Â±0.004 0.664Â±0.003 0.677Â±0.003 0.738Â±0.003
EIB
[65] 0.621Â±0.003 0.547Â±0.006 0.368Â±0.008 0.648Â±0.003 0.620Â±0.002 0.371Â±0.002 0.641Â±0.001 0.653Â±0.001 0.713Â±0.002
IPS
[59] 0.625Â±0.002 0.534Â±0.009 0.360Â±0.008 0.648Â±0.001 0.615Â±0.001 0.369Â±0.001 0.636Â±0.001 0.642Â±0.002 0.714Â±0.001
SNIPS
[59] 0.631Â±0.004 0.544Â±0.008 0.369Â±0.007 0.659Â±0.005 0.617Â±0.005 0.375Â±0.004 0.657Â±0.002 0.670Â±0.001 0.735Â±0.001
CVIB
[75] 0.626Â±0.001 0.552Â±0.009 0.379Â±0.004 0.661Â±0.001 0.612Â±0.002 0.381Â±0.001 0.653Â±0.001 0.644Â±0.001 0.736Â±0.001
D
AMF [57] 0.631Â±0.004 0.548Â±0.006 0.367Â±0.006 0.640Â±0.0030.627Â±0.002 0.377Â±0.004 0.657Â±0.003 0.669Â±0.003 0.735Â±0.004
DR
[56] 0.633Â±0.009 0.548Â±0.015 0.360Â±0.011 0.654Â±0.009 0.613Â±0.007 0.372Â±0.005 0.643Â±0.002 0.650Â±0.001 0.721Â±0.001
DR-JL
[73] 0.633Â±0.005 0.546Â±0.006 0.366Â±0.007 0.650Â±0.002 0.617Â±0.001 0.382Â±0.001 0.644Â±0.001 0.669Â±0.002 0.725Â±0.002
MRDR-JL
[17] 0.634Â±0.005 0.538Â±0.010 0.373Â±0.008 0.659Â±0.002 0.624Â±0.007 0.376Â±0.006 0.658Â±0.003 0.670Â±0.002 0.741Â±0.003
DR-BIAS
[10] 0.632Â±0.004 0.549Â±0.009 0.369Â±0.008 0.660Â±0.001 0.619Â±0.003 0.378Â±0.0020.665Â±0.0040.679Â±0.004 0.737Â±0.002
DR-MSE
[10] 0.631Â±0.0030.557Â±0.008 0.374Â±0.008 0.662Â±0.002 0.623Â±0.004 0.374Â±0.002 0.653Â±0.002 0.660Â±0.002 0.732Â±0.002
DIB
[35] 0.626Â±0.003 0.550Â±0.009 0.376Â±0.006 0.647Â±0.0050.626Â±0.005 0.382Â±0.006 0.641Â±0.002 0.642Â±0.003 0.738Â±0.003
MR
[22] 0.630Â±0.005 0.546Â±0.009 0.376Â±0.007 0.656Â±0.005 0.623Â±0.004 0.380Â±0.004 0.637Â±0.002 0.644Â±0.004 0.723Â±0.002
SDR
[29] 0.635Â±0.005 0.543Â±0.005 0.368Â±0.006 0.660Â±0.006 0.618Â±0.006 0.376Â±0.005 0.661Â±0.003 0.675Â±0.001 0.739Â±0.002
TDR
[23] 0.638Â±0.007 0.556Â±0.014 0.370Â±0.013 0.657Â±0.004 0.616Â±0.002 0.371Â±0.003 0.650Â±0.002 0.670Â±0.001 0.723Â±0.003
IPS-
V2 [26] 0.631Â±0.005 0.549Â±0.008 0.373Â±0.008 0.648Â±0.005 0.615Â±0.005 0.373Â±0.004 0.658Â±0.002 0.675Â±0.003 0.734Â±0.002
DR-
V2 [26] 0.631Â±0.005 0.553Â±0.009 0.378Â±0.006 0.636Â±0.003 0.620Â±0.0020.392Â±0.004 0.658Â±0.001 0.671Â±0.001 0.734Â±0.002
OME-EIB
(ours) 0.627Â±0.0020.563âˆ—
Â±0.0020.387âˆ—
Â±0.0020.664Â±0.003 0.622Â±0.004 0.384Â±0.0050.667Â±0.0030.682âˆ—
Â±0.0020.742Â±0.002
OME-IPS
(ours) 0.636Â±0.002 0.548Â±0.003 0.373Â±0.0040.664Â±0.003 0.625Â±0.0020.385Â±0.0020.671âˆ—
Â±0.0020.693âˆ—
Â±0.0040.763âˆ—
Â±0.002
OME-DR
(ours) 0.651âˆ—
Â±0.0060.561Â±0.0060.385âˆ—
Â±0.0050.671âˆ—
Â±0.0030.632âˆ—
Â±0.0030.389Â±0.002 0.662Â±0.002 0.677Â±0.0040.743Â±0.002
Note: * means statistically significant results (p-value â‰¤0.05) using the paired-t-test compared with the best baseline.
Performance Comparison. We compare the proposed methods
with the Naive method [ 20], the EIB method [ 65], the IPS method [ 59],
and the DR-based methods [ 17,23,29,73]. The RE results are shown
in Table 1 with ğœŒ01=0.2andğœŒ10=0.1. First, most debiasing and
denoising methods have lower RE than the Naive method. In addi-
tion, our proposed methods stably and significantly outperform the
corresponding debiasing baseline methods. Meanwhile, the OME
methods are only able to denoising, thus they still have a large RE,
even the true ğœŒis used for estimation. This shows the effectiveness
of our method in the presence of both the OME and MNAR effects.
In Depth Analysis. We explore the effect of the proportion of
observed data on the estimation accuracy of Ë†ğœŒ01and Ë†ğœŒ10, and the
results when ğœŒ01=0.2andğœŒ10=0.1are shown in Figure 1. We take
ROTATE as an example, and the same phenomenon is observed forthe other five prediction matrices. First, our methods stably outper-
form the baseline methods in all scenarios. Second, the estimation
error decreases significantly as the proportion of observed data
increases. Moreover, even with the estimation error, our estimation
results are only slightly worse than using the real ğœŒ. This further
validates the stability and practicality of our methods.
5 Real-World Experiments
Datasets and Experiment Details. We verify the effectiveness of
our methods on three real-world datasets: Coat [59],Music [59]
andKuaiRec [14].Coat includes 6,960 MNAR ratings and 4,640
missing-at-random (MAR) ratings from 290 users to 300 items. Mu-
sichas 311,704 MNAR ratings and 54,000 MAR ratings of 15,400
users to 1,000 items. For Coat andMusic, we binarize the ratings
 
1582KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
less than three to 0 and otherwise to 1. KuaiRec is a fully exposed
large-scale industrial dataset, which has 4,676,570 video watch-
ing ratio records from 1,411 users to 3,327 items. We binarize the
records less than one to 0 and otherwise to 1. We adopt three com-
mon metrics, i.e., AUC, NDCG@K, and Recall@K for performance
evaluation. For Coat andMusic, K is set to 5. For KuaiRec, K is
set to 50. All the experiments are implemented on PyTorch with
Adam as the optimizer. For all experiments, we use GeForce RTX
3090 as the computing resource. Logistic regression is used as the
propensity model for all the methods requiring propensity. The
learning rate is tuned in {0.001,0.005,0.01,0.05}and the batch size
is tuned in{64,128,256}forCoat and{2048,4096,8192}forMusic
andKuaiRec. We tune the embedding dimension in {4,8,16,32}
forCoat and{8,16,32,64}forMusic andKuaiRec. Moreover, we
tune the weight decay rate in [1ğ‘’âˆ’6,5ğ‘’âˆ’3].
Baselines. We use matrix factorization (MF) [ 20] as the base model
and compare our methods to the following debiasing methods:
EIB [ 65], IPS [ 59], SNIPS [ 59], CVIB [ 75], DAMF [ 57], DR [ 56],
DR-JL [ 73], MRDR-JL [ 17], DR-BIAS [ 10], DR-MSE [ 10], DIB [ 35],
MR [ 22], SDR [ 29], TDR [ 23], IPS-V2 [ 26] and DR-V2 [ 26]. We also
compare denoising methods including surrogate loss minimization
(OME) [36], T-MF [71], R-MF [71], and LCD-MF [11].
Performance Comparision. Table 2 shows the prediction perfor-
mance with varying baselines and our methods. First, most of the
debiasing and denoising methods have better performance com-
pared to the Naive method, which shows the necessity of debiasing
and denoising. Meanwhile, our methods exhibit the most competi-
tive performance in all three datasets, significantly outperforming
the baselines including debiasing methods and denoising methods.
6 Related Work
6.1 Debiased Recommendation
The data collected in recommender systems are often systematically
subject to varying types of bias, such as conformity bias [ 37], item
popularity bias [ 77,86], latent confounders [ 13,25], and position
bias [ 46,47]. In order to achieve unbiased learning of the predic-
tion model, three typical approaches have been proposed, includ-
ing: (1) The error-imputation-based (EIB) approaches [ 18,55,65],
which compute an imputed error for each missing rating. (2) The
inverse-propensity-scoring (IPS) approaches [ 54,58,59,66], which
inversely weight the prediction error for each observed rating with
the probability of observing that rating. (3) The doubly robust (DR)
approaches [ 21,56,73], which use both the error imputation model
and the propensity model, and the unbiased learning of the pre-
diction model can be achieved when either the error imputation
model or the propensity model is accurate. Based on the above
EIB, IPS, and DR estimators, in terms of learning paradigms, recent
studies have investigated flexible trade-offs between bias and vari-
ance [ 10,17], parameter sharing in multi-task learning [ 40,69,84],
and the use of a few unbiased ratings to improve the estimation of
the prediction inaccuracy [ 3,5,31,33,34,74]. In terms of statisti-
cal theory, recent studies have developed targeted DR (TDR) [ 23]
and conservative DR (CDR) [ 64] to combat the inaccurate imputed
errors, StableDR [ 29] to combat sparse data, and new propensity
estimation methods based on balancing metrics [ 26,39,80]. In
addition, [ 57] proposes to minimize the propensity-independentgeneralization error bound via adversarial learning. [ 22] extends DR
to multiple robust learning. These methods have also been applied
to sequential recommendation [ 76] and social recommendation [ 7].
Furthermore, methods based on information bottlenecks [ 35,75]
and representation learning [ 48,80] have also been proposed for
debiased recommendation. In this work, we extend the previous
debiasing methods to a more realistic RS scenario, in which the
observed ratings and the usersâ€™ true preferences may be different.
6.2 Outcome Measurement Error
Outcome measurement error (OME) refers to the inconsistency
between the observed outcomes and the true outcomes, also known
as noisy outcomes in social science [ 52], biostatistics [ 19], and
psychometrics [ 63]. The error models or transition matrices in
OME establish the relation between the true outcomes and the
observed outcomes, including uniform [ 1,68], class-conditional
[36,42,61], and instance-dependent [ 8,78] structures of outcome
misclassification. Many data-driven error parameter estimation
methods are developed in recent machine learning literature [ 45,
60,61,79]. Meanwhile, given knowledge of measurement error
parameters, recent studies propose unbiased risk minimization
approaches for learning under noisy labels [9, 44, 49, 67].
Despite the prevalence of OME in real-world recommendation
scenarios, there is still only limited work focusing on denoising in
RS [4,82,87]. Recently, by noticing that noisy feedback typically
has large loss values in the early stages, [ 71] proposes adaptive
denoising training and [ 15] proposes self-guided denoising learning
in implicit feedback. However, the existing methods are mostly
heuristic and require the fully observed noisy labels, which prevents
the direct use of such methods for RS in the presence of missing
data. To fill this gap, we extend the surrogate loss-based methods
to address the data MNAR and OME in parallel.
7 Conclusion
In this study, we explored the challenges characterized MNAR data
with noisy feedback encountered in real-world recommendation
scenarios. First, we introduced the concept of true prediction inaccu-
racy as a more comprehensive evaluation criterion that accounts for
OME, and proposed OME-EIB, OME-IPS, and OME-DR estimators
to provide unbiased estimations of the true prediction inaccuracy.
Next, we derived the explicit forms of the biases and the general-
ization bounds of the proposed estimators, and proved the double
robustness of our OME-DR estimator. We further proposed an al-
ternating denoise training approach that corrects for MNAR data
with OME. The effectiveness of our methods was validated on both
semi-synthetic and real-world datasets with varying MNAR and
OME rates. The potential limitations includes the usage of weak sep-
arability assumption, and accurate measurement error parametersâ€™
estimation for ensuring unbiasedness. In future research, we aim
to develop unbiased learning methods applicable to more complex
OME forms, study alternative practical assumptions for identifying
and estimating the error parameters, and extend the applicability
of the proposed methods to a wider range of RS settings.
Acknowledgements
This work was supported in part by National Natural Science Foun-
dation of China (623B2002, 62272437).
 
1583Debiased Recommendation with Noisy Feedback KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
References
[1]Dana Angluin and Philip Laird. 1988. Learning from noisy examples. Machine
learning (1988), 343â€“370.
[2]Heejung Bang and James M Robins. 2005. Doubly robust estimation in missing
data and causal inference models. Biometrics (2005), 962â€“973.
[3]Stephen Bonner and Flavian Vasile. 2018. Causal embeddings for recommendation.
InRecSys.
[4]Huiyuan Chen, Yusan Lin, Menghai Pan, Lan Wang, Chin-Chia Michael Yeh,
Xiaoting Li, Yan Zheng, Fei Wang, and Hao Yang. 2022. Denoising self-attentive
sequential recommendation. In RecSys.
[5]Jiawei Chen, Hande Dong, Yang Qiu, Xiangnan He, Xin Xin, Liang Chen, Guli Lin,
and Keping Yang. 2021. AutoDebias: Learning to Debias for Recommendation. In
SIGIR.
[6]Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan
He. 2023. Bias and debias in recommender system: A survey and future directions.
ACM Transactions on Information Systems (2023), 1â€“39.
[7]Jiawei Chen, Can Wang, Martin Ester, Qihao Shi, Yan Feng, and Chun Chen. 2018.
Social recommendation with missing not at random data. In ICDM.
[8]Pengfei Chen, Junjie Ye, Guangyong Chen, Jingwei Zhao, and Pheng-Ann Heng.
2021. Beyond class-conditional assumption: A primary attempt to combat
instance-dependent label noise. In AAAI.
[9]Yu-Ting Chou, Gang Niu, Hsuan-Tien Lin, and Masashi Sugiyama. 2020. Unbiased
risk estimators can mislead: A case study of learning with complementary labels.
InICML.
[10] Quanyu Dai, Haoxuan Li, Peng Wu, Zhenhua Dong, Xiao-Hua Zhou, Rui Zhang,
Xiuqiang He, Rui Zhang, and Jie Sun. 2022. A Generalized Doubly Robust Learning
Framework for Debiasing Post-Click Conversion Rate Prediction. In KDD.
[11] Quanyu Dai, Yalei Lv, Jieming Zhu, Junjie Ye, Zhenhua Dong, Rui Zhang, Shu-Tao
Xia, and Ruiming Tang. 2022. LCD: Adaptive label correction for denoising music
recommendation. In CIKM.
[12] Arnaud De Myttenaere, BÃ©nÃ©dicte Le Grand, Boris Golden, and Fabrice Rossi.
2014. Reducing offline evaluation bias in recommendation systems. arXiv preprint
arXiv:1407.0822 (2014).
[13] Sihao Ding, Peng Wu, Fuli Feng, Xiangnan He, Yitong Wang, Yong Liao, and Yong-
dong Zhang. 2022. Addressing Unmeasured Confounder for Recommendation
with Sensitivity Analysis. In KDD.
[14] Chongming Gao, Shijun Li, Wenqiang Lei, Jiawei Chen, Biao Li, Peng Jiang,
Xiangnan He, Jiaxin Mao, and Tat-Seng Chua. 2022. KuaiRec: A Fully-observed
Dataset and Insights for Evaluating Recommender Systems. In CIKM.
[15] Yunjun Gao, Yuntao Du, Yujia Hu, Lu Chen, Xinjun Zhu, Ziquan Fang, and Baihua
Zheng. 2022. Self-guided learning to denoise for robust recommendation. In
SIGIR.
[16] Ihsan Gunes, Cihan Kaleli, Alper Bilge, and Huseyin Polat. 2014. Shilling attacks
against recommender systems: a comprehensive survey. Artificial Intelligence
Review (2014), 767â€“799.
[17] Siyuan Guo, Lixin Zou, Yiding Liu, Wenwen Ye, Suqi Cheng, Shuaiqiang Wang,
Hechang Chen, Dawei Yin, and Yi Chang. 2021. Enhanced Doubly Robust Learn-
ing for Debiasing Post-Click Conversion Rate Estimation. In SIGIR.
[18] JosÃ© Miguel HernÃ¡ndez-Lobato, Neil Houlsby, and Zoubin Ghahramani. 2014.
Probabilistic matrix factorization with non-random missing data. In ICML.
[19] Sui L Hui and Steven D Walter. 1980. Estimating the error rates of diagnostic
tests. Biometrics (1980), 167â€“171.
[20] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech-
niques for recommender systems. Computer (2009), 30â€“37.
[21] Wonbin Kweon and Hwanjo Yu. 2024. Doubly Calibrated Estimator for Recom-
mendation on Data Missing Not At Random. In WWW.
[22] Haoxuan Li, Quanyu Dai, Yuru Li, Yan Lyu, Zhenhua Dong, Xiao-Hua Zhou, and
Peng Wu. 2023. Multiple Robust Learning for Recommendation. In AAAI.
[23] Haoxuan Li, Yan Lyu, Chunyuan Zheng, and Peng Wu. 2023. TDR-CL: Targeted
Doubly Robust Collaborative Learning for Debiased Recommendations. In ICLR.
[24] Haoxuan Li, Kunhan Wu, Chunyuan Zheng, Yanghao Xiao, Hao Wang, Zhi Geng,
Fuli Feng, Xiangnan He, and Peng Wu. 2023. Removing Hidden Confounding in
Recommendation: A Unified Multi-Task Learning Approach. In NeurIPS.
[25] Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, and Peng Wu. 2023. Balancing un-
observed confounding with a few unbiased ratings in debiased recommendations.
InWWW.
[26] Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, Peng Wu, and Peng Cui. 2023.
Propensity Matters: Measuring and Enhancing Balancing for Recommendation.
InICML.
[27] Haoxuan Li, Chunyuan Zheng, Sihao Ding, Peng Wu, Zhi Geng, Fuli Feng, and
Xiangnan He. 2024. Be Aware of the Neighborhood Effect: Modeling Selection
Bias under Interference for Recommendation. In ICLR.
[28] Haoxuan Li, Chunyuan Zheng, Shuyi Wang, Kunhan Wu, Hao Wang, peng Wu,
Zhi Geng, Xu Chen, and Xiao-Hua Zhou. 2024. Relaxing the Accurate Imputation
Assumption in Doubly Robust Learning for Debiased Collaborative Filtering. In
ICML.[29] Haoxuan Li, Chunyuan Zheng, and Peng Wu. 2023. StableDR: Stabilized Doubly
Robust Learning for Recommendation on Data Missing Not at Random. In ICLR.
[30] Haoxuan Li, Chunyuan Zheng, Yanghao Xiao, Peng Wu, Zhi Geng, Xu Chen,
and Peng Cui. 2024. Debiased Collaborative Filtering with Kernel-Based Causal
Balancing. In ICLR.
[31] Zinan Lin, Dugang Liu, Weike Pan, Qiang Yang, and Zhong Ming. 2023. Trans-
fer learning for collaborative recommendation with biased and unbiased data.
Artificial Intelligence (2023), 103992.
[32] Roderick JA Little and Donald B Rubin. 2019. Statistical analysis with missing
data. Vol. 793. John Wiley & Sons.
[33] Dugang Liu, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Weike Pan, and
Zhong Ming. 2020. A general knowledge distillation framework for counterfactual
recommendation via uniform data. In SIGIR.
[34] Dugang Liu, Pengxiang Cheng, Zinan Lin, Jinwei Luo, Zhenhua Dong, Xiuqiang
He, Weike Pan, and Zhong Ming. 2022. KDCRec: Knowledge distillation for
counterfactual recommendation via uniform data. IEEE Transactions on Knowledge
and Data Engineering (2022).
[35] Dugang Liu, Pengxiang Cheng, Hong Zhu, Zhenhua Dong, Xiuqiang He, Weike
Pan, and Zhong Ming. 2021. Mitigating Confounding Bias in Recommendation
via Information Bottleneck. In RecSys.
[36] Tongliang Liu and Dacheng Tao. 2015. Classification with noisy labels by impor-
tance reweighting. IEEE Transactions on pattern analysis and machine intelligence
(2015), 447â€“461.
[37] Yiming Liu, Xuezhi Cao, and Yong Yu. 2016. Are You Influenced by Others When
Rating? Improve Rating Prediction by Conformity Modeling. In RecSys.
[38] Yiyu Liu, Qian Liu, Yu Tian, Changping Wang, Yanan Niu, Yang Song, and
Chenliang Li. 2021. Concept-aware denoising graph neural network for micro-
video recommendation. In CIKM.
[39] Jinwei Luo, Dugang Liu, Weike Pan, and Zhong Ming. 2021. Unbiased recom-
mendation model based on improved propensity score estimation. Journal of
Computer Applications (2021), 3508.
[40] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun
Gai. 2018. Entire Space Multi-Task Model: An Effective Approach for Estimating
Post-Click Conversion Rate. In SIGIR.
[41] Benjamin M Marlin and Richard S Zemel. 2009. Collaborative prediction and
ranking with non-random missing data. In RecSys.
[42] Aditya Menon, Brendan Van Rooyen, Cheng Soon Ong, and Bob Williamson.
2015. Learning from corrupted binary labels via class-probability estimation. In
ICML.
[43] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. 2018. Foundations
of machine learning. MIT press.
[44] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari.
2013. Learning with noisy labels. In NeurIPS.
[45] Curtis Northcutt, Lu Jiang, and Isaac Chuang. 2021. Confident learning: Estimat-
ing uncertainty in dataset labels. Journal of Artificial Intelligence Research (2021),
1373â€“1411.
[46] Harrie Oosterhuis. 2022. Reaching the end of unbiasedness: Uncovering implicit
limitations of click-based learning to rank. In SIGIR.
[47] Harrie Oosterhuis. 2023. Doubly robust estimation for correcting position bias in
click feedback for unbiased learning to rank. ACM Transactions on Information
Systems (2023), 1â€“33.
[48] Hang Pan, Jiawei Chen, Fuli Feng, Wentao Shi, Junkang Wu, and Xiangnan He.
2023. Discriminative-Invariant Representation Learning for Unbiased Recom-
mendation. In IJCAI.
[49] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and
Lizhen Qu. 2017. Making deep neural networks robust to label noise: A loss
correction approach. In CVPR.
[50] Yuqi Qin, Pengfei Wang, and Chenliang Li. 2021. The world is binary: Contrastive
learning for denoising next basket recommendation. In SIGIR.
[51] Francesco Ricci, Lior Rokach, and Bracha Shapira. 2010. Introduction to rec-
ommender systems handbook. In Recommender systems handbook. Springer,
1â€“35.
[52] Fred S Roberts. 1985. Measurement theory. (1985).
[53] Yong Rui, Vicente Ivan Sanchez Carmona, Mohsen Pourvali, Yun Xing, Wei-Wen
Yi, Hui-Bin Ruan, and Yu Zhang. 2022. Knowledge mining: A cross-disciplinary
survey. Machine Intelligence Research (2022), 89â€“114.
[54] Yuta Saito. 2019. Unbiased Pairwise Learning from Implicit Feedback. In NeurIPS
Workshop.
[55] Yuta Saito. 2020. Asymmetric Tri-training for Debiasing Missing-Not-At-Random
Explicit Feedback. In SIGIR.
[56] Yuta Saito. 2020. Doubly robust estimator for ranking metrics with post-click
conversions. In RecSys.
[57] Yuta Saito and Masahiro Nomura. 2022. Towards Resolving Propensity Contra-
diction in Offline Recommender Learning. In IJCAI.
[58] Yuta Saito, Suguru Yaginuma, Yuta Nishino, Hayato Sakata, and Kazuhide Nakata.
2020. Unbiased recommender learning from missing-not-at-random implicit
feedback. In WSDM.
 
1584KDD â€™24, August 25â€“29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
[59] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and
Thorsten Joachims. 2016. Recommendations as Treatments: Debiasing Learning
and Evaluation. In ICML.
[60] Clayton Scott. 2015. A rate of convergence for mixture proportion estimation,
with application to learning from noisy labels. In AISTATS.
[61] Clayton Scott, Gilles Blanchard, and Gregory Handy. 2013. Classification with
asymmetric label noise: Consistency and maximal denoising. In COLT.
[62] Shai Shalev-Shwartz and Shai Ben-David. 2014. Understanding machine learning:
From theory to algorithms. Cambridge university press.
[63] Patrick E Shrout and Sean P Lane. 2012. Psychometrics. (2012).
[64] Zijie Song, Jiawei Chen, Sheng Zhou, Qihao Shi, Yan Feng, Chun Chen, and Can
Wang. 2023. CDR: Conservative doubly robust learning for debiased recommen-
dation. In CIKM.
[65] Harald Steck. 2010. Training and testing of recommender systems on data missing
not at random. In KDD.
[66] Adith Swaminathan and Thorsten Joachims. 2015. The self-normalized estimator
for counterfactual learning. In NeurIPS.
[67] Brendan Van Rooyen et al. 2015. Machine learning via transitions. (2015).
[68] Brendan Van Rooyen, Aditya Menon, and Robert C Williamson. 2015. Learning
with symmetric label noise: The importance of being unhinged. In NeurIPS.
[69] Hao Wang, Tai-Wei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao Yu,
Ruopeng Li, and Wei Chu. 2022. ESCM2: Entire space counterfactual multi-task
model for post-click conversion rate estimation. In SIGIR.
[70] Jun Wang, Haoxuan Li, Chi Zhang, Dongxu Liang, Enyun Yu, Wenwu Ou, and
Wenjia Wang. 2023. CounterCLR: Counterfactual contrastive learning with
non-random missing data in recommendation. In ICDM.
[71] Wenjie Wang, Fuli Feng, Xiangnan He, Liqiang Nie, and Tat-Seng Chua. 2021.
Denoising implicit feedback for recommendation. In WSDM.
[72] Wenjie Wang, Yang Zhang, Haoxuan Li, Peng Wu, Fuli Feng, and Xiangnan He.
2023. Causal Recommendation: Progresses and Future Directions. In SIGIR.
[73] Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. 2019. Doubly Robust Joint
Learning for Recommendation on Data Missing Not at Random. In ICML.
[74] Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. 2021. Combating Selection
Biases in Recommender Systems with A Few Unbiased Ratings. In WSDM.
[75] Zifeng Wang, Xi Chen, Shao-Lun Wen, Rui anFd Huang, Ercan E Kuruoglu,
and Yefeng Zheng. 2020. Information Theoretic Counterfactual Learning from
Missing-Not-At-Random Feedback. In NeurIPS.
[76] Zhenlei Wang, Shiqi Shen, Zhipeng Wang, Bo Chen, Xu Chen, and Ji-Rong Wen.
2022. Unbiased sequential recommendation with latent confounders. In WWW.
[77] Tianxin Wei, Fuli Feng, Jiawei Chen, Ziwei Wu, Jinfeng Yi, and Xiangnan He.
2021. Model-agnostic counterfactual reasoning for eliminating popularity bias in
recommender system. In KDD.
[78] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng
Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. 2020. Part-dependent label
noise: Towards instance-dependent label noise. In NeurIPS.
[79] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and
Masashi Sugiyama. 2019. Are anchor points really indispensable in label-noise
learning?. In NeurIPS.
[80] Mengyue Yang, Guohao Cai, Furui Liu, Jiarui Jin, Zhenhua Dong, Xiuqiang He,
Jianye Hao, Weiqi Shao, Jun Wang, and Xu Chen. 2023. Debiased recommendation
with user feature balancing. ACM Transactions on Information Systems (2023).
[81] Mengyue Yang, Quanyu Dai, Zhenhua Dong, Xu Chen, Xiuqiang He, and Jun
Wang. 2021. Top-N recommendation with counterfactual user preference simula-
tion. In CIKM.
[82] Chi Zhang, Rui Chen, Xiangyu Zhao, Qilong Han, and Li Li. 2023. Denoising and
Prompt-Tuning for Multi-Behavior Recommendation. In WWW.
[83] Honglei Zhang, Shuyi Wang, Haoxuan Li, Chunyuan Zheng, Xu Chen, Li Liu,
Shanshan Luo, and Peng Wu. 2024. Uncovering the Propensity Identification
Problem in Debiased Recommendations. In ICDE.
[84] Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong
Wen, and Ramin Ramezani. 2020. Large-scale Causal Approaches to Debiasing
Post-click Conversion Rate Estimation with Multi-task Learning. In WWW.
[85] Yongfeng Zhang, Xu Chen, et al .2020. Explainable recommendation: A survey
and new perspectives. Foundations and TrendsÂ® in Information Retrieval (2020),
1â€“101.
[86] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui
Ling, and Yongdong Zhang. 2021. Causal intervention for leveraging popularity
bias in recommendation. In SIGIR.
[87] Zhiheng Zhang, Quanyu Dai, Xu Chen, Zhenhua Dong, and Ruiming Tang. 2023.
Robust causal inference for recommender system to overcome noisy confounders.
InSIGIR.
[88] Xiangyu Zhao, Long Xia, Jiliang Tang, and Dawei Yin. 2019. Deep reinforcement
learning for search, recommendation, and online advertising: a survey. ACM
Sigweb Newsletter, 1â€“15.
[89] Yu Zheng, Chen Gao, Xiang Li, Xiangnan He, Depeng Jin, and Yong Li. 2021.
Disentangling User Interest and Conformity for Recommendation with Causal
Embedding. In WWW.A Proofs
Theorem 3.1 (Bias of OME-DR Estimator). Given Ë†ğœŒ01and Ë†ğœŒ10
with Ë†ğœŒ01+Ë†ğœŒ10<1, imputed errors Â¯Eand learned propensities Ë†Pwith
Ë†ğ‘ğ‘¢,ğ‘–>0for all user-item pairs, the bias of the OME-DR estimator is
Bias[EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)]=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆD
1âˆ’ğ‘œğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+
âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1ğ‘ğ‘¢,ğ‘–ğœ”11âˆ’Ë†ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğ‘ğ‘¢,ğ‘–ğœ”01
Ë†ğ‘ğ‘¢,ğ‘–â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
+
âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0ğ‘ğ‘¢,ğ‘–ğœ”10
Ë†ğ‘ğ‘¢,ğ‘–â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğ‘ğ‘¢,ğ‘–ğœ”00âˆ’Ë†ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0),
whereğœ”11,ğœ”01,ğœ”10, andğœ”00are given by
ğœ”11=1âˆ’ğœŒ01âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10, ğœ” 01=ğœŒ01âˆ’Ë†ğœŒ01
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10,
ğœ”10=ğœŒ10âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10, ğœ” 00=1âˆ’Ë†ğœŒ01âˆ’ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10.
Proof. By definition, the bias of the OME-DR estimator is
Bias[EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)]=ER,O[EOMEâˆ’DR]âˆ’Pâˆ—.
By double expectation formula, the first term is
ER,O
EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)
=ER|O
EO
EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)
=ER|Oï£®ï£¯ï£¯ï£¯ï£¯ï£°1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆD
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+ğ‘ğ‘¢,ğ‘–Ëœğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–ï£¹ï£ºï£ºï£ºï£ºï£»
=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1ER|O
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+ğ‘ğ‘¢,ğ‘–Ëœğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
+1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0ER|O
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+ğ‘ğ‘¢,ğ‘–Ëœğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
.
Then, we can derive the bias of the OME-DR estimator as follows
Bias[EOMEâˆ’DR(Ë†R,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)]=ER|O[EO[EOMEâˆ’DR]]âˆ’Pâˆ—
=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1ER|O
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+ğ‘ğ‘¢,ğ‘–Ëœğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
âˆ’â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
+1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0ER|O
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+ğ‘ğ‘¢,ğ‘–Ëœğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
âˆ’â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
=1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0
1âˆ’ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–
+âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–Â·ER|OËœğ‘’ğ‘¢,ğ‘–
âˆ’â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
+âˆ‘ï¸
(ğ‘¢,ğ‘–):ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0ğ‘ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–Â·ER|OËœğ‘’ğ‘¢,ğ‘–
âˆ’â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0).
 
1585Debiased Recommendation with Noisy Feedback KDD â€™24, August 25â€“29, 2024, Barcelona, Spain.
On one hand, for the user-item pairs with ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=1, we have
ER|OËœğ‘’ğ‘¢,ğ‘–
=(1âˆ’ğœŒ01)Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1;Ë†ğœŒ01,Ë†ğœŒ10)+ğœŒ01Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0;Ë†ğœŒ01,Ë†ğœŒ10)
=(1âˆ’ğœŒ01)Â·(1âˆ’Ë†ğœŒ10)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)âˆ’ Ë†ğœŒ01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10
+ğœŒ01Â·(1âˆ’Ë†ğœŒ01)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)âˆ’ Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10
=1âˆ’ğœŒ01âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğœŒ01âˆ’Ë†ğœŒ01
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
:=ğœ”11â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğœ”01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0),
whereğœ”11andğœ”01are given by
ğœ”11=1âˆ’ğœŒ01âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10, ğœ” 01=ğœŒ01âˆ’Ë†ğœŒ01
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10.
On the other hand, for the user-item pairs with ğ‘Ÿâˆ—
ğ‘¢,ğ‘–=0, we have
ER|OËœğ‘’ğ‘¢,ğ‘–
=ğœŒ10Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1;Ë†ğœŒ01,Ë†ğœŒ10)+(1âˆ’ğœŒ10)Â·Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0;Ë†ğœŒ01,Ë†ğœŒ10)
=ğœŒ10Â·(1âˆ’Ë†ğœŒ10)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)âˆ’ Ë†ğœŒ01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10
+(1âˆ’ğœŒ10)Â·(1âˆ’Ë†ğœŒ01)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)âˆ’ Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10
=ğœŒ10âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+1âˆ’Ë†ğœŒ01âˆ’ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
:=ğœ”10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)+ğœ”00â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0),
whereğœ”10andğœ”00are given by
ğœ”10=ğœŒ10âˆ’Ë†ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10, ğœ” 00=1âˆ’Ë†ğœŒ01âˆ’ğœŒ10
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10.
This completes the proof. â–¡
Lemma 3.3 (Lipschitz Continuity). Given Ë†ğœŒ01and Ë†ğœŒ10with
Ë†ğœŒ01+Ë†ğœŒ10<1, ifâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿâˆ—
ğ‘¢,ğ‘–)isğ¿-Lipschitz in ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)for allğ‘Ÿâˆ—
ğ‘¢,ğ‘–,
then Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿğ‘¢,ğ‘–)is2ğ¿
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10-Lipschitz in ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)for allğ‘Ÿğ‘¢,ğ‘–.
Proof. The explicit form of Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)and Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)are
Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)=(1âˆ’Ë†ğœŒ10)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)âˆ’ Ë†ğœŒ01â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10,
Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)=(1âˆ’Ë†ğœŒ01)â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),0)âˆ’ Ë†ğœŒ10â„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),1)
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10.
Then the conclusion can be dirived directly from Ë†ğœŒ01+Ë†ğœŒ10<1.â–¡
Lemma A.1 (McDiarmidâ€™s Ineqality). Letğ‘‰be some set and
letğ‘“:ğ‘‰ğ‘šâ†’Rbe a function of ğ‘švariables such that for some ğ‘>0,
for allğ‘–âˆˆ[ğ‘š]and for allğ‘¥1,...,ğ‘¥ğ‘š,ğ‘¥â€²
ğ‘–âˆˆğ‘‰we have
ğ‘“(ğ‘¥1,...,ğ‘¥ğ‘š)âˆ’ğ‘“ ğ‘¥1,...,ğ‘¥ğ‘–âˆ’1,ğ‘¥â€²
ğ‘–,ğ‘¥ğ‘–+1,...,ğ‘¥ğ‘šâ‰¤ğ‘
Letğ‘‹1,...,ğ‘‹ğ‘šbeğ‘šindependent random variables taking values in
ğ‘‰. Then, with probability of at least 1âˆ’ğœ‚we have
|ğ‘“(ğ‘‹1,...,ğ‘‹ğ‘š)âˆ’E[ğ‘“(ğ‘‹1,...,ğ‘‹ğ‘š)]|â‰¤ğ‘âˆšï¸„
log2
ğœ‚
ğ‘š/2.
Proof. The proof can be found in Lemma 26.4 of [62]. â–¡Theorem 3.4 (Generalization Bound). Given Ë†ğœŒ01and Ë†ğœŒ10with
Ë†ğœŒ01+Ë†ğœŒ10<1, supposeâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿâˆ—
ğ‘¢,ğ‘–)isğ¿-Lipschitz in ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)for
allğ‘Ÿâˆ—
ğ‘¢,ğ‘–, and Ë†ğ‘ğ‘¢,ğ‘–â‰¥ğ¶ğ‘,|Ëœâ„“(ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–),ğ‘Ÿğ‘¢,ğ‘–)|â‰¤ğ¶ğ‘™for allğ‘Ÿğ‘¢,ğ‘–, then with
probability 1âˆ’ğœ‚, the true prediction inaccuracy P(Ë†Râ€¡,Râˆ—)of the
optimal prediction matrix using the OME-DR estimator with imputed
errors Â¯Eand learned propensities Ë†Phas the upper bound
EOMEâˆ’DR(Ë†Râ€¡,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)+Bias[EOMEâˆ’DR(Ë†Râ€¡,Rğ‘œ;Ë†ğœŒ01,Ë†ğœŒ10)]+

1+2
ğ¶ğ‘ï£®ï£¯ï£¯ï£¯ï£¯ï£°4ğ¿
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10R(F)+
ğ¶ğ‘™+4ğ¿
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10âˆšï¸„
2 log(4/ğœ‚)
|D|ï£¹ï£ºï£ºï£ºï£ºï£».
Proof. The true prediction inaccuracy can be decomposed as
Pâˆ—=EOMEâˆ’DR+ Pâˆ—âˆ’E[EOMEâˆ’DR]+(E[EOMEâˆ’DR]âˆ’E OMEâˆ’DR)
â‰¤E OMEâˆ’DR+Bias(EOMEâˆ’DR)+(E[EOMEâˆ’DR]âˆ’E OMEâˆ’DR)
â‰¤E OMEâˆ’DR+Bias(EOMEâˆ’DR)+sup
ğ‘“ğœƒâˆˆF(E[EOMEâˆ’DR]âˆ’E OMEâˆ’DR).
To simplify notation, let B(F) =supğ‘“ğœƒâˆˆF(E[EOMEâˆ’DR]âˆ’E OMEâˆ’DR),
which can be decomposed as
B(F) =E
ğ‘†âˆ¼P|D|[B(F)]+
B(F)âˆ’ E
ğ‘†âˆ¼P|D|[B(F)]
.
For the first term E
ğ‘†âˆ¼P|D|[B(F)] , according to the Rademacher
Comparison Lemma [62] and Talagrandâ€™s Lemma [43], we have
E
ğ‘†âˆ¼P|D|[B(F)]
â‰¤2E
ğ‘†âˆ¼P|D|Eğœsup
ğ‘“ğœƒâˆˆFï£®ï£¯ï£¯ï£¯ï£¯ï£°1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğœğ‘¢,ğ‘–
1âˆ’ğ‘œğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–
Â¯ğ‘’ğ‘¢,ğ‘–+ğ‘œğ‘¢,ğ‘–Ëœğ‘’ğ‘¢,ğ‘–
Ë†ğ‘ğ‘¢,ğ‘–ï£¹ï£ºï£ºï£ºï£ºï£»
â‰¤2
1+2
ğ¶ğ‘2ğ¿
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10Â·E
ğ‘†âˆ¼P|D|Eğœsup
ğ‘“ğœƒâˆˆFï£®ï£¯ï£¯ï£¯ï£¯ï£°1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğœğ‘¢,ğ‘–ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)ï£¹ï£ºï£ºï£ºï£ºï£»
=2
1+2
ğ¶ğ‘2ğ¿
1âˆ’Ë†ğœŒ01âˆ’Ë†ğœŒ10Â·E
ğ‘†âˆ¼P|D|{R(F)},
whereR(F) is the empirical Rademacher complexity of F
R(F) =Eğœâˆ¼{âˆ’ 1,+1}|D|sup
ğ‘“ğœƒâˆˆFï£®ï£¯ï£¯ï£¯ï£¯ï£°1
|D|âˆ‘ï¸
(ğ‘¢,ğ‘–)âˆˆDğœğ‘¢,ğ‘–ğ‘“ğœƒ(ğ‘¥ğ‘¢,ğ‘–)ï£¹ï£ºï£ºï£ºï£ºï£».
By applying McDiarmidâ€™s inequality, and let ğ‘=2
|D|, with prob-
ability at least 1âˆ’ğœ‚
2,
R(F)âˆ’ E
ğ‘†âˆ¼P|D|{R(F)}â‰¤2âˆšï¸„
log(4/ğœ‚)
2|D|=âˆšï¸„
2 log(4/ğœ‚)
|D|.
For the rest term B(F)âˆ’ E
ğ‘†âˆ¼P|D|[B(F)] , by applying McDi-
armidâ€™s inequality, and let ğ‘=2
|D|ğ¶ğ‘™
1+2
ğ¶ğ‘
, with probability at
least 1âˆ’ğœ‚
2,
B(F)âˆ’ E
ğ‘†âˆ¼P|D|[B(F)]â‰¤ğ¶ğ‘™
1+2
ğ¶ğ‘âˆšï¸„
2 log(4/ğœ‚)
|D|.
After adding the inequalities above, we can rearrange the terms to
obtain the stated results. â–¡
 
1586