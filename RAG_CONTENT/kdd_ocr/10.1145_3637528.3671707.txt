Tackling Instance-Dependent Label Noise with Class Rebalance
and Geometric Regularization
Shuzhi Caoâˆ—
School of Computer Science and Technology & Shaanxi
Provincial Key Laboratory of Big Data Knowledge
Engineering, Xiâ€™an Jiaotong University
Xiâ€™an, China
cao309615@gmail.comJianfei Ruanâˆ—
School of Computer Science and Technology & Shaanxi
Provincial Key Laboratory of Big Data Knowledge
Engineering, Xiâ€™an Jiaotong University
Xiâ€™an, China
jianfei.ruan@hotmail.com
Bo Dongâ€ 
School of Distance Education & Shaanxi Provincial Key
Laboratory of Big Data Knowledge Engineering, Xiâ€™an
Jiaotong University
Xiâ€™an, China
dong.bo@xjtu.edu.cnBin Shi
School of Computer Science and Technology & Ministry of
Education Key Lab For Intelligent Networks and Network
Security, Xiâ€™an Jiaotong University
Xiâ€™an, China
shibin@xjtu.edu.cn
ABSTRACT
In label-noise learning, accurately identifying the transition ma-
trix is crucial for developing statistically consistent classifiers. This
task is complicated by instance-dependent noise, which introduces
identifiability challenges in the absence of stringent assumptions.
Existing methods use neural networks to estimate the transition
matrix by initially extracting confident clean instances. However,
this extraction process is hindered by severe inter-class imbalance
and a bias toward selecting unambiguous intra-class instances,
leading to a distorted understanding of noise patterns. To tackle
these challenges, our paper introduces a Class Rebalance and Geo-
metric Regularization-based Framework (CRGR). CRGR employs
a smoothed, noise-tolerant reweighting mechanism to equilibrate
inter-class representation, thereby mitigating the risk of model over-
fitting to dominant classes. Additionally, recognizing that instances
with similar characteristics often exhibit parallel noise patterns, we
propose that the transition matrix should mirror the similarity of
the feature space. This insight promotes the inclusion of ambiguous
instances in training, serving as a form of geometric regularization.
Such a strategy enhances the modelâ€™s ability to navigate diverse
noise patterns and strengthens its generalization capabilities. By ad-
dressing both inter-class and intra-class biases, CRGR offers a more
balanced and robust classification model. Extensive experiments on
both synthetic and real-world datasets demonstrate CRGRâ€™s superi-
ority over existing state-of-the-art methods, significantly boosting
âˆ—Both authors contributed equally to this research.
â€ Corresponding Author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671707classification accuracy and showcasing its effectiveness in handling
instance-dependent noise.
CCS CONCEPTS
â€¢Computing methodologies â†’Machine learning.
KEYWORDS
Instance-dependent label noise, Class rebalance, Geometric regu-
larization, Confident clean instance
ACM Reference Format:
Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi. 2024. Tackling Instance-
Dependent Label Noise with Class Rebalance and Geometric Regularization.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3637528.3671707
1 INTRODUCTION
Deep learning methods have excelled in various computer vision
tasks, such as image classification [ 25,34] and object detection
[12,27,47], among others. Despite their success, these methods
heavily rely on extensive, fully labeled datasets, which are costly
to obtain due to the required expertise for accurate labeling. A
common workaround involves sourcing large-scale training data via
mobile crowdsourcing [ 16,42] or online queries [ 3]. Nonetheless,
these techniques tend to introduce label noise into the datasets
[7,43], which can significantly impair the generalization capabilities
of deep learning models. The susceptibility of these models to noisy
data, due to their complex architectures and strong fitting abilities,
highlights the importance of developing robust algorithms that can
effectively handle label noise.
Recent methods for addressing label noise can be categorized
into heuristic approaches [ 19,20,24,33,36,37,45] and statistically
consistent algorithms [ 6,7,39,40,43,44]. Heuristic approaches,
based on empirical techniques like selecting presumably clean data
[14,19,20,36,37,45], label correction [ 22,31,33], or integrating
extra regularization constraints [ 24,32], may offer practical efficacy.
However, these methods lack theoretical guarantees and may not
 
211
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
/uni0000001b /uni00000017 /uni00000019 /uni0000001c /uni00000016 /uni00000015 /uni00000018 /uni00000013 /uni00000014 /uni0000001a
/uni00000026/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni0000002c/uni00000051/uni00000047/uni00000048/uni0000005b/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013/uni00000031/uni00000058/uni00000050/uni00000045/uni00000048/uni00000055/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000026/uni00000052/uni00000051/uni00000049/uni0000004c/uni00000047/uni00000048/uni00000051/uni00000057/uni00000003/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048 /uni00000024/uni00000050/uni00000045/uni0000004c/uni0000004a/uni00000058/uni00000052/uni00000058/uni00000056/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
(a)
/uni00000024/uni00000050/uni00000045/uni0000004c/uni0000004a/uni00000058/uni00000052/uni00000058/uni00000056/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048 /uni00000026/uni00000052/uni00000051/uni00000049/uni0000004c/uni00000047/uni00000048/uni00000051/uni00000057/uni00000003/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048 (b)
Figure 1: (a) exhibits the imbalanced inter-class distribution
of confident clean instances in CIFAR-10. (b) visualizes the
distributions of the confident clean and ambiguous instances
to show the intra-class selection bias problem by using the
T-SNE technique.
converge to an optimal classifier [ 26,40]. Conversely, statistically
consistent algorithms aim to model label noise directly, estimating
a transition matrix ğ‘‡(ğ’™)âˆˆRğ‘Ã—ğ‘, whereğ‘represents the number of
classes, andğ‘‡ğ‘–ğ‘—(ğ’™)=ğ‘ƒ(Â¯ğ‘Œ=ğ‘—|ğ‘Œ=ğ‘–,ğ‘‹=ğ’™)represents the probabil-
ity of an instance with true label ğ‘–being mislabeled as noisy label
ğ‘—, given its features ğ’™. This matrix allows for the inference of clean
class posterior probabilities from noisy ones, thereby constructing
a consistent classifier.
To simplify the form of ğ‘‡(ğ’™), some researchers present class-
conditional noise (CCN) model [ 26,40,44], which assumes a con-
stant mislabeling probability across instances within a class, i.e.,
ğ‘ƒ(Â¯ğ‘Œ=ğ‘—|ğ‘Œ=ğ‘–,ğ‘‹=ğ’™)=ğ‘ƒ(Â¯ğ‘Œ=ğ‘—|ğ‘Œ=ğ‘–). However, this label noise
model does not take into account the impact of instance features on
noisy labels, making it difficult to describe real-world noise patterns.
To mitigate this issue, instance-dependent noise (IDN) [ 5,6,39,43]
is proposed, which accounts for variability in mislabeling probabil-
ities among instances, even within the same class, based on their
true class and specific features. This paper primarily focuses on
IDN due to its broader practical relevance and realism.
Estimatingğ‘‡(ğ’™)under IDN conditions is challenging due to its
reliance on instance-specific features, leading to a wide array of
potential matrix configurations. Unlike CCN, IDN lacks the conve-
nience of using anchor points [ 30,40] for fixed matrix estimation.
Researchers have tried to circumvent this complexity by introduc-
ing restrictive assumptions like part-dependent noise [ 39], confi-
dence scores [ 2], or noise bounds [ 9], but these solutions often com-
promise practical utility. To mitigate reliance on such assumptions,
recent advancements [ 6,43] employ neural networks to adaptively
fit transition matrix ğ‘‡(ğ’™), using a subset of confident clean instances
as a learning foundation without extra assumptions. Methods such
as distillation [ 9], early-stop strategies [ 1], and small-loss-based
techniques [ 14] have been used to gather these instances. How-
ever, these methods tend to select clear-cut instances from easily
identifiable categories [ 20,37], leading to two main challenges: (1)
Inter-class imbalance: As Figure 1a shows, there exists a signif-
icant disparity in the number of confident clean instances across
classes, causing model overfitting to overrepresented classes. (2)
Intra-class selection bias: Figure 1b illustrates the selection ofeasily identifiable instances as confident clean ones, ignoring am-
biguous instances near the decision boundaries. This leads to an
inadequate representation of complex noise generation patterns.
These issues pose challenges to current state-of-the-art approaches
[6,43] that utilize neural networks to fit ğ‘‡(ğ’™), as they directly train
the neural network on such biased extracted instances, leading to a
skewed classifier.
To tackle these issues, we propose a novel label noise learn-
ing method, CRGR. Our first solution targets the imbalance in
the inter-class distribution of extracted instances. We propose a
smoothed noise-tolerant reweighting strategy that equalizes the
neural networkâ€™s exposure to noise generation patterns across dif-
ferent classes. The second solution draws inspiration from psy-
chological and physiological studies [ 10,28], which suggest that
instances sharing similar features are more likely to be mislabeled
into the same class and vice versa. This observation guides us to
posit thatğ‘‡(ğ’™)should mirror the similarity of the feature space, en-
suring that the similarity relation between instances in the feature
space aligns consistently with those in the transition matrix space.
This insight leads us to further include ambiguous instances in the
training process as geometric regularization, aiding the network in
grasping complex noise dynamics. In summary, CRGR refines the
neural networkâ€™s training and enhances its capacity to depict noise
patterns, leading to a more equitable and robust classifier. The main
contributions are shown as follows:
â€¢We propose a novel label noise learning method, CRGR,
which enhances the neural networkâ€™s capacity to depict com-
prehensive noise patterns by solving both the inter-class
imbalance and intra-class selection bias problems among the
extracted confident clean instances, ultimately resulting in a
more equitable and robust classifier.
â€¢In this paper, we first propose a novel smoothed noise-tolerant
reweighting strategy that equalizes the networkâ€™s exposure
to noise patterns in each class to balance inter-class rep-
resentation. Subsequently, recognizing that instances with
similar features often exhibit parallel noise patterns, we pro-
pose that the transition matrix should mirror the similarity
of the feature space. This insight guides us to leverage the
characteristic information of ambiguous instances and incor-
porate them into training as geometric regularization. These
two enhancements improve the modelâ€™s ability to depict
complex noise patterns, eliminating both the inter-class and
intra-class fitting bias.
â€¢Extensive experiments on both synthetic and real-world
datasets demonstrate that CRGR outperforms existing state-
of-the-art methods in handling IDN.
The remainder of the paper is organized as follows: Section 2
reviews related work. Section 3 describes preliminary concepts and
notations. Section 4 details the proposed method. Section 5 presents
experimental results. Finally, Section 6 concludes the paper.
2 RELATED WORK
In this section, we provide a concise overview of the relevant liter-
ature pertaining to label noise models and learning with IDN.
Label noise models. The label noise model depicts the genera-
tion of noisy labels. In general, label noise models are commonly
 
212Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
categorized into class-conditional noise (CCN) [ 7,26,30,40,44]
and instance-dependent noise (IDN) [ 5,6,9,39,43]. CCN consid-
ers that an instanceâ€™s noisy label is exclusively related to its true
class. Specifically, CCN ignores the effect of instance features on
noisy labels and assumes that all instances in the same class share
the same noise generation patterns. As a result, all the instances
belonging to the same class have a fixed probability of being misla-
beled as another class. In contrast, IDN considers the probability of
mislabeling to vary among instances, even within the same class,
depending on their true class and specific features. Comparatively,
IDN is more realistic [ 5,39] since humans always assign labels to
instances based on their unique features. For example, during the
annotation process, fuzzy photos with less information are more
likely to be mislabeled. Despite the realism of the IDN model, learn-
ing with IDN is formidable since the transition matrix ğ‘‡(ğ’™), which
plays an essential role in building statistically consistent classifiers,
is unidentifiable under IDN without extra assumptions.
Learning with IDN. Existing IDN-based label noise learning
methods can be classified into two categories: heuristic approaches
[14,20,22,31,36,37,45] and statistically consistent algorithms
[6,7,30,39,40,43,44]. Heuristic approaches utilize empirical tech-
niques, such as selecting presumably clean data [ 14,19,20,36,37,
45], label correction [ 22,33], or adding extra regularization con-
straints [ 24,32] to mitigate the adverse effects of label noise. While
these approaches may empirically work well, their performance
ceiling remains limited as they lack theoretical guarantees and may
not converge to the ideal classifier that would result from using
accurately labeled data. Driven by this concern, the development
of statistically consistent algorithms has emerged, aiming to build
consistent classifiers. In this pursuit, the estimation of the transition
matrixğ‘‡(ğ’™)plays a crucial role. Under IDN, ğ‘‡(ğ’™)is unidentifiable
without extra constraints, hence, to uniquely ascertain the ğ‘‡(ğ’™),
several extra assumptions have been proposed. For instance, [ 39]
hypothesizes that the noise of an instance depends only on its parts;
[2] necessitates additional confident scores, and [ 9] studies a spe-
cial case of IDN where the noise rate has an upper bound. While
these methods partially address the matrix estimation problem,
their practical application is impeded by the heavy dependence on
assumptions. To eliminate these assumptions, recent advancements
like [ 6,43] employ extra neural networks to adaptively fit ğ‘‡(ğ’™).
These approaches leverage a subset of confident clean instances as
a foundation for learning noise patterns without extra presupposi-
tions, enhancing their applicability and performance. Despite these
advantages, these approaches encounter two significant challenges.
First, the imbalanced inter-class distributions of extracted instances
lead the neural network to overfit classes with more instances and
overlook others. Second, current methods tend to select clean-cut
intra-class instances as extracted instances and neglect ambiguous
instances. This selection bias poses a challenge for the network to
learn intricate noise patterns, leading to a skewed classifier. As a re-
sult, how to effectively handle IDN remains a challenging problem.
3 PRELIMINARIES
In this section, we first present the definition of label noise learning,
followed by systematic formulations of the transition matrix and
confident clean instances.Problem setting. Letğ·be the distribution of a pair of random
variables(ğ‘‹,ğ‘Œ)âˆˆXÃ—Y , whereğ‘‹denotes the random variable of
instances and ğ‘Œis the corresponding clean labels. Moreover, XâˆˆRğ‘‘
is defined as the feature space, and Y={1,2,...,ğ‘}is the label
space, where ğ‘‘andğ‘stand for the dimension of the feature space
and the number of classes, respectively. In the task of classification,
given an instance ğ’™âˆˆX, our goal is to predict its true label ğ‘¦âˆˆY.
However, in real-world scenarios, collecting large-scale training
data through crowdsourcing or online queries inevitably introduces
label noise. Therefore, we define Â¯ğ·as the distribution of noisy
instances(ğ‘‹,Â¯ğ‘Œ)âˆˆXÃ— Â¯Y, where Â¯ğ‘Œdenotes the variable of noisy
labels. In IDN, only a noisy training dataset Â¯D={ğ’™ğ‘–,Â¯ğ‘¦ğ‘–}ğ‘›
ğ‘–=1with
ğ‘›instances that independently drawn from the distribution Â¯ğ·are
available.
Transition matrix. The transition matrix ğ‘‡(ğ’™)âˆˆT depicts
the generation of the noisy label of instance ğ’™, whereTâˆˆRğ‘Ã—ğ‘
stands for the transition matrix space, and the ğ‘–ğ‘—-th entry of the
matrix, i.e., ğ‘‡ğ‘–ğ‘—(ğ’™)=ğ‘ƒ(Â¯ğ‘Œ=ğ‘—|ğ‘Œ=ğ‘–,ğ‘‹=ğ’™), represents the prob-
ability that an instance ğ’™belongs to the true class ğ‘Œ=ğ‘–and is
mislabeled as the noisy class Â¯ğ‘Œ=ğ‘—. In fact, the clean class pos-
teriorğ‘ƒ(ğ‘Œ|ğ’™)=[ğ‘ƒ(ğ‘Œ=1|ğ‘‹=ğ’™),...,ğ‘ƒ(ğ‘Œ=ğ‘|ğ‘‹=ğ’™)]âŠ¤can be
inferred from the noisy class posterior ğ‘ƒ(Â¯ğ‘Œ|ğ’™)=[ğ‘ƒ((Â¯ğ‘Œ=1|ğ‘‹=
ğ’™),...,ğ‘ƒ((Â¯ğ‘Œ=ğ‘|ğ‘‹=ğ’™)]âŠ¤and the transition matrix ğ‘‡(ğ’™), i.e.,
ğ‘ƒ(Â¯ğ‘Œ|ğ’™)=ğ‘‡(ğ’™)ğ‘ƒ(ğ‘Œ|ğ’™). By learning with noisy instances, the noisy
class posterior ğ‘ƒ(Â¯ğ‘Œ|ğ’™)can be directly estimated. As a result, once
ğ‘‡(ğ’™)is identified, constructing statistically consistent classifiers
becomes a straightforward task. Nevertheless, ğ‘‡(ğ’™)is unidentifi-
able under IDN without extra assumptions, making it a non-trivial
task to construct the statistically consistent classifier.
Confident clean instances. Clean instances are indispensable
for training the transition network ğ‘‡(ğ’™;ğœƒ)that fits the transition
matrixğ‘‡(ğ’™). However, in real-world scenarios, obtaining even a
small number of clean instances can be a difficult task. When clean
data is unavailable, it is necessary to automatically extract a sub-
set of instances with confident true labels, i.e., confident clean
instances, from the noisy data. Current off-the-shelf extraction ap-
proaches include techniques like the distillation method [ 9,43],
sample sieve approach [ 8], small-loss based methods [ 14,45], and
early-stop strategies [ 1,18,38]. In this paper, we directly employ
the distillation method [ 9] to extract the confident clean instances.
4 METHOD
This section provides an in-depth examination of CRGR, which
enhances the neural networkâ€™s capacity to depict noise patterns
by addressing both inter-class imbalance and intra-class selection
bias issues among the extracted instances, leading to a more equi-
table and robust classifier. Specifically, we first extract a subset of
confident clean instances as training instances (Section 4.1). Sec-
ondly, we propose a novel smoothed noise-tolerant reweighting
technique (Section 4.2) to calibrate the imbalanced inter-class dis-
tribution of the extracted instances. Subsequently, by maintaining
the consistency of similarity relations between instances in the
feature space and those in the transition matrix space, we include
the ambiguous instances in the training framework as a geometric
regularization, which assists the transition network in simulating
the complex noise generation patterns (Section 4.3). Finally, with
 
213KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
the well-trained transition network, we employ the F-Correction
[30] paradigm to obtain a consistent classifier (Section 4.4).
4.1 Confident Clean Instance Extraction
Confident clean instances, defined as instances with clean labels,
are indispensable for transition network training. However, in real-
world scenarios, acquiring even a small number of clean instances
is challenging. Motivated by this fact, some empirical techniques
[1,9,18,38] have attempted to extract clean instances from noisy
data automatically. In this paper, we employ an off-the-shelf distil-
lation method [ 9] to extract a subset of confident clean instances
Dğ‘ğ‘™ğ‘’ğ‘ğ‘› =
ğ’™ğ’Š,Â¯ğ‘¦ğ‘–,ğ‘¦âˆ—
ğ‘–	ğ‘›ğ‘
ğ‘–=1, whereğ‘¦âˆ—represents the estimated la-
tent clean label, and ğ‘›ğ‘denotes the number of extracted instances.
Specifically, for each instance ğ’™in the noisy training data Â¯D, we
first calculate its corresponding noisy class posterior ğ‘ƒ(Â¯ğ‘Œ|ğ’™)=
[ğ‘ƒ(Â¯ğ‘Œ=1|ğ‘‹=ğ’™),...,ğ‘ƒ(Â¯ğ‘Œ=ğ‘|ğ‘‹=ğ’™)]âŠ¤and then select the in-
stances that satisfies ğ‘šğ‘ğ‘¥
ğ‘ƒ(Â¯ğ‘Œ|ğ’™)	
>1+ğœŒğ‘šğ‘ğ‘¥
2as confident clean
instances, while considering the remaining instances as ambiguous
instances, where ğœŒğ‘šğ‘ğ‘¥ is a pre-defined threshold. Simultaneously,
ğ‘¦âˆ—=argmaxÂ¯ğ‘¦âˆˆ{1,2,...,ğ‘}ğ‘ƒ(Â¯ğ‘Œ=Â¯ğ‘¦|ğ’™)is taken as the estimated latent
clean label. According to the above criteria, the original noisy train-
ing data Â¯Dis divided into confident clean instances Dğ‘ğ‘™ğ‘’ğ‘ğ‘› and
ambiguous instances Dğ‘ğ‘šğ‘ğ‘–ğ‘” , i.e., Â¯D=Dğ‘ğ‘™ğ‘’ğ‘ğ‘›âˆªDğ‘ğ‘šğ‘ğ‘–ğ‘” . With the
extracted confident clean instances, we can train the transition net-
workğ‘‡(ğ’™;ğœƒ). Specifically, the transition network is optimized by
minimizing the empirical risk on the inferred noisy label ğ’šâˆ—Â·ğ‘‡(ğ’™;ğœƒ)
and its ground-truth noisy label Â¯ğ’š. The empirical risk is formulated
as follows:
R(ğœƒ)=âˆ’1
ğ‘›ğ‘ğ‘›ğ‘âˆ‘ï¸
ğ‘–=1Â¯ğ’šğ’Šlog(ğ’šâˆ—
ğ’ŠÂ·ğ‘‡(ğ’™ğ’Š;ğœƒ)), (1)
where Â¯ğ’šğ’ŠâˆˆR1Ã—ğ‘andğ’šâˆ—
ğ’ŠâˆˆR1Ã—ğ‘denotes the noisy label Â¯ğ‘¦ğ‘–and the
clean labelğ‘¦âˆ—
ğ‘–in one-hot vector form, respectively.
4.2 Class Rebalance
Despite the fact that the transition network ğ‘‡(ğ’™;ğœƒ)can be trained
by minimizing the risk formulated by Eq.(1), there remains a signif-
icant problem with this direct optimization approach. Specifically,
considering the severely imbalanced inter-class distribution of the
extracted confident clean instances, directly minimizing the risk in
Eq.(1) inevitably leads the neural network to overfit the classes with
more instances and overlook others. As a consequence, the transi-
tion network develops a skewed understanding of noise generation
patterns, and thus its generalization ability is greatly degraded.
To tackle this issue, we propose a novel smoothed noise-tolerant
reweighting technique to calibrate the imbalanced inter-class dis-
tribution. By assigning different weights to different instances, we
transform the empirical risk in Eq.(1) into a cost-sensitive risk
[11, 13], which is illustrated as follows:
Rğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘(ğœƒ)=âˆ’1
ğ‘›ğ‘ğ‘›ğ‘âˆ‘ï¸
ğ‘–=1ğ‘¤(ğ’™ğ’Š)Â¯ğ’šğ’Šlog (ğ’šâˆ—
ğ’ŠÂ·ğ‘‡(ğ’™ğ’Š;ğœƒ),(2)
whereğ‘¤(ğ’™)represents the weight corresponding to the instance ğ’™.
In general, greater weight should be given to the class with fewer ex-
tracted instances to equalize the imbalanced inter-class distribution.
However, under IDN, the estimated latent clean label ğ‘¦âˆ—may not beconsistent with its clean label. As a result, directly using the inverse
class frequency [ 17,35] to weight instances may lead the transition
network to erroneously concentrate on misestimated labels. To
mitigate this issue, we use the clean class posterior ğ‘ƒ(ğ‘Œ=ğ‘¦âˆ—|ğ’™)to
evaluate the confidence degree of the estimated latent clean label
ğ‘¦âˆ—and assign different weights to various instances based on their
label confidence. Based on this criterion, we determine the weight
ğ‘¤(ğ‘¥)as follows:
ğ‘¤(ğ’™)=ï£±ï£´ï£´ï£´ï£´ ï£²
ï£´ï£´ï£´ï£´ï£³ğ‘›ğ‘Ãğ‘›ğ‘
ğ‘–=11[ğ‘¦âˆ—
ğ‘–=ğ‘¦âˆ—],ifğ‘ƒ(ğ‘Œ=ğ‘¦âˆ—|ğ’™)â‰¥ğ‘¤ğ‘šğ‘ğ‘¥,
âˆšï¸ƒğ‘›ğ‘Ãğ‘›ğ‘
ğ‘–=11[ğ‘¦âˆ—
ğ‘–=ğ‘¦âˆ—],ifğ‘ƒ(ğ‘Œ=ğ‘¦âˆ—|ğ’™)<ğ‘¤ğ‘šğ‘ğ‘¥,(3)
where 1[Â·]is the indicator function, and ğ‘¤ğ‘šğ‘ğ‘¥ is a self-adaptive
coefficient, which is defined as follows:
ğ‘¤ğ‘šğ‘ğ‘¥=1
ğ‘›ğ‘ğ‘›ğ‘âˆ‘ï¸
ğ‘–=1ğ‘ƒ(ğ‘Œ=ğ‘¦âˆ—
ğ‘–|ğ‘‹=ğ’™ğ’Š), (4)
As previously demonstrated, we directly employ the inverse class
frequency to weight the instances whose clean class posterior ex-
ceeds the threshold ğ‘¤ğ‘šğ‘ğ‘¥. In the case of instances whose clean
class posterior is less than the threshold, we utilize the smoothed
form of the inverse square root of the class frequency to weight
these instances to prevent the latent overfitting problem. Hence, by
optimizing the weighted risk in Eq.(2), we equalize the transition
networkâ€™s exposure to noise generation patterns in each class to
overcome the overfitting problem, leading to class rebalance.
4.3 Geometric Regularization
Existing approaches tend to extract easily identifiable instances
within each class as confident clean instances and neglect ambigu-
ous instances lying around the decision boundary. Consequently,
the transition network is unable to capture the intricate noise pat-
terns since it does not encounter any ambiguous instances dur-
ing the training process. To tackle this issue, we consider leverag-
ing the information of ambiguous instances Dğ‘ğ‘šğ‘ğ‘–ğ‘” to guide the
network training. Specifically, inspired by the evidence [ 10,28]
that instances with similar characteristics often exhibit parallel
noise patterns, we propose that the transition matrix ğ‘‡(ğ’™)should
mirror the similarity of the feature space, i.e., keeping the simi-
larity relation between instances in the feature space consistent
with those in the transition matrix space. This insight leads to
the inclusion of ambiguous instances in training as the geometric
regularization. Specifically, we use ğ‘‘X(ğ’™ğ’Š,ğ’™ğ’‹)=||ğ’™ğ’Šâˆ’ğ’™ğ’‹||2and
ğ‘‘T(ğ‘‡(ğ’™ğ’Š),ğ‘‡(ğ’™ğ’‹))=||ğ‘‡(ğ’™ğ’Š)âˆ’ğ‘‡(ğ’™ğ’‹)||2to measure the similarity
between the instances ğ’™ğ’Šandğ’™ğ’‹in feature and transition matrix
spaces, respectively, where ||Â·|| 2represents the â„“2norm of a vector.
Following the property that ğ‘‡(ğ’™)should mirror the similarity of
the feature space, we claim that the distance between instances in
the feature and transition matrix space should be proportional and
thus have the following relationship:
ğ‘‘X(ğ’™ğ’Š,ğ’™ğ’‹)=ğœ…Â·ğ‘‘T(ğ‘‡(ğ’™ğ’Š),ğ‘‡(ğ’™ğ’‹)), (5)
whereğœ…âˆˆRis a constant scaling factor, XandTdenote the fea-
ture and transition matrix spaces, respectively. Considering com-
putational efficiency, we only calculate the distance between the
 
214Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
instance ğ’™and the center of each class to measure its global similar-
ity relations. Specifically, let ğœ‡ğ‘–(ğ‘–âˆˆ{1,...,ğ‘})denotes the center
of classğ‘–, which can be estimated using confident clean instances
as follows:
ğœ‡ğ‘–=Ã
(ğ’™ğ’‹,ğ‘¦âˆ—
ğ‘—)âˆˆD ğ‘ğ‘™ğ‘’ğ‘ğ‘›ğ’™ğ’‹Â· 1(ğ‘¦âˆ—
ğ‘—=ğ‘–)
Ã
(ğ’™ğ’‹,ğ‘¦âˆ—
ğ‘—)âˆˆD ğ‘ğ‘™ğ‘’ğ‘ğ‘›1(ğ‘¦âˆ—
ğ‘—=ğ‘–). (6)
We define vectors ğ‘†X(ğ’™)=[ğ‘‘X(ğ’™,ğ1),...,ğ‘‘X(ğ’™,ğğ’„)]andğ‘†T(ğ’™)=
[ğ‘‘T(ğ‘‡(ğ’™),ğ‘‡(ğ1)),...,ğ‘‘T(ğ‘‡(ğ’™),ğ‘‡(ğğ’„))]to reflect global similarity
relations of ğ’™and use the transition networkâ€™s prediction ğ‘‡(ğ’™;ğœƒ)to
approximate its ground truth. Following Eq.(5), ğœ…Â·ğ‘†T(ğ’™)should be
consistent with ğ‘†X(ğ’™). To eliminate the effect of scale discrepancy,
we minimize the difference between the normalized ğ‘†X(ğ’™)and
ğ‘†T(ğ’™), offering a geometric regularization as follows:
Rğ‘Ÿğ‘’ğ‘”ğ‘¢ğ‘™ğ‘ğ‘Ÿ(ğœƒ)=âˆ’1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1||ğ‘†X(ğ’™ğ’Š)
||ğ‘†X(ğ’™ğ’Š)||2âˆ’ğ‘†T(ğ’™ğ’Š)
||ğ‘†T(ğ’™ğ’Š)||2||2. (7)
Finally, the overall objective function can be expressed as Eq.(8),
whereğ›¼is the hyperparameter to balance Rğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ andRğ‘Ÿğ‘’ğ‘”ğ‘¢ğ‘™ğ‘ğ‘Ÿ .
min
ğœƒL(ğœƒ)=Rğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘(ğœƒ)+ğ›¼Rğ‘Ÿğ‘’ğ‘”ğ‘¢ğ‘™ğ‘ğ‘Ÿ(ğœƒ). (8)
By minimizing the overall objective function mentioned above,
the parameter ğœƒof the transition network ğ‘‡(ğ‘¥)can be learned.
4.4 Classifier Training
By optimizing the overall objective function in Eq.(8), the transi-
tion network ğ‘‡(ğ’™;ğœƒ)is well trained. Our ultimate goal is to ob-
tain a classifier ğ‘“(ğ’™;ğœ”)parameterized by ğœ”that can predict the
clean class posterior of the input instance ğ’™, i.e.,ğ‘ƒ(ğ‘Œ|ğ’™)=ğ‘“(ğ’™;ğœ”).
Specifically, the noisy class posterior ğ‘ƒ(Â¯ğ‘Œ|ğ’™)can be inferred as
ğ‘ƒ(Â¯ğ‘Œ|ğ’™)=ğ‘‡(ğ’™)ğ‘ƒ(ğ‘Œ|ğ’™). Here, we approximate ğ‘‡(ğ’™)andğ‘ƒ(ğ‘Œ|ğ’™)by
usingğ‘‡(ğ’™;ğœƒ)andğ‘“(ğ’™;ğœ”), respectively, where ğœƒis a fixed param-
eter andğœ”is a trainable parameter. Furthermore, we use them to
approximate ğ‘ƒ(Â¯ğ‘Œ|ğ’™)and calculate the cross-entropy loss between
the inferred noisy class posterior and the given noisy label to learn
the parameter ğœ”of the classifier ğ‘“(ğ’™;ğœ”)as follows:
minğœ”R(ğœ”)=âˆ’1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1Â¯ğ’šğ’Šlog(ğ‘“(ğ’™ğ’Š;ğœ”)Â·ğ‘‡(ğ’™ğ’Š;ğœƒ)), (9)
In conclusion, the details of CRGR are summarized in Algorithm 1
with a visual representation shown in Figure 2.
5 EXPERIMENTS
In this section, we conduct comprehensive experiments on both syn-
thetic and real-world instance-dependent noisy datasets to verify
the effectiveness and superiority of the proposed CRGR method.
5.1 Experiment Setup
Datasets We conduct extensive experiments on synthetic noisy
datasets, namely SVHN, CIFAR-10 andCIFAR-100, as well as on a
real-world noisy dataset Clothing-1M, to verify the effectiveness
of the proposed CRGR method. SVHN consists of 10 classes of
images with 73,257 training instances and 26,032 test instances of
varying sizes. CIFAR-10 andCIFAR-100 contain 10 and 100 classes
respectively, and both datasets have 50k training images and 10k
test images of size 32Ã—32. As for the real-world dataset, Clothing-1MAlgorithm 1 CRGR
Input: Noisy training dataset Â¯D={ğ’™ğ’Š,Â¯ğ‘¦ğ‘–}ğ‘›
ğ‘–=1
1:Warm up the classifier ğ‘“(ğ’™;ğœ”)with an early-stop strategy and
divide Â¯Dinto confident clean instances Dğ‘ğ‘™ğ‘’ğ‘ğ‘› and ambiguous
instancesDğ‘ğ‘šğ‘ğ‘–ğ‘” .
2:whileğ‘’ğ‘ğ‘œğ‘â„â‰¤ğ‘€ğ‘ğ‘¥ -ğ¸ğ‘ğ‘œğ‘â„ do
3: Calculate the riskRğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘(ğœƒ)shown in Eq.(2) and the risk
Rğ‘Ÿğ‘’ğ‘”ğ‘¢ğ‘™ğ‘ğ‘Ÿ(ğœƒ)shown in Eq.(7).
4: Minimize the overall objective function shown in Eq.(8) to
learn the parameter ğœƒof the transition network;
5:end while
6:Fix the learned ğœƒand optimize the classifier ğ‘“(ğ’™;ğœ”)by mini-
mizing the risk shown in Eq.(9).
Output: The classifier ğ‘“(ğ’™;ğœ”)
is a large-scale image dataset with 1M training images containing
noisy labels collected through crowdsourcing and online queries,
and 10k images with clean labels for testing.
Algorithm 2 Instance-dependent Label Noise Generation
Input: Clean instancesD={ğ’™ğ’Š,ğ‘¦ğ‘–}ğ‘›
ğ‘–=1; Noise rate ğœ.
1:Sample instance flip rates ğ‘âˆˆ Rğ‘›from the truncated normal
distributionN(ğœ,0.12,[0,1]);
2:Independently sample ğ‘¤1,ğ‘¤2,...,ğ‘¤ğ‘from the standard normal
distributionN(0,12);
3:forğ‘–=0to ndo
4:ğ‘=ğ’™ğ’ŠÃ—ğ‘¤ğ‘¦ğ‘–; // generate instance-dependent flip rates
5:ğ‘ğ‘¦ğ‘–=âˆ’âˆ; // control the diagonal entry of the instance-
dependent transition matrix
6:ğ‘=ğ‘ğ‘–Ã—ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘); // make the sum of the off-diagonal
entries of the ğ‘¦ğ‘–-th row equal to ğ‘ğ‘–
7:ğ‘ğ‘¦ğ‘–=1âˆ’ğ‘ğ‘–; // set the diagonal entry to be 1âˆ’ğ‘ğ‘–
8: Randomly choose a label from the label space according to
probabilities ğ‘as the noisy label Â¯ğ‘¦ğ‘–;
9:end for
Output: Noisy instances Â¯D={ğ’™ğ’Š,Â¯ğ‘¦ğ‘–}ğ‘›
ğ‘–=1
IDN generation In our experiments, we utilize the follow-
ing commonly used instance-dependent label noise generation ap-
proach (see Algorithm 2) to generate synthetic noisy datasets. To
be specific, given the clean instances D={ğ’™ğ’Š,ğ‘¦ğ‘–}ğ‘›
ğ‘–=1and noise
rateğœ, we first sample instance flip rates (noise rates) ğ‘âˆˆ Rğ‘›
from the truncated normal distribution N(ğœ,0.12,[0,1])for each
instance, where the average flip rate is set as ğœ. Subsequently, we
independently sample parameters ğ‘¤1,ğ‘¤2,...,ğ‘¤ğ‘from the standard
normal distribution N(0,12)for generating instance-dependent
label noise, where the dimensionality of each parameter is ğ‘‘Ã—ğ‘,
ğ‘‘denotes the dimensionality of the instance and ğ‘stands for the
number of classes. With the sampled parameter ğ‘¤ğ‘–ğ‘–âˆˆ{1,2,...,ğ‘},
we generate instance-dependent flip rates for all the instances that
belonging to the class ğ‘Œ=ğ‘–. Specifically, for the instance ğ‘¥ğ‘–with
clean labelğ‘¦ğ‘–, its noisy label is only related to the ğ‘¦ğ‘–-th row of the
transition matrix. We use vector ğ‘to represent the ğ‘¦ğ‘–-th row of the
transition matrix. To calculate ğ‘for each instance, in steps 4-7, we
first use parameter ğ‘¤ğ‘–and the feature ğ‘¥ğ‘–to initialize ğ‘=ğ’™ğ’ŠÃ—ğ‘¤ğ‘¦ğ‘–,
 
215KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
Noisy Training Data
Dog
Wolf
â€¦Distillation MethodSoftmaxBackbone Network
Transition Network
Geometric Regularization
Figure 2: The overview of CRGR.
Table 1: Means and standard deviations (percentage) of classification accuracy on CIFAR-10 with different label noise levels.
Method IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
CE 74.31Â±0.39 68.11Â±0.81 59.63Â±0.98 49.56Â±1.57 39.22Â±2.79
Co-teaching+ 73.95Â±0.98 70.25Â±1.27 64.36Â±1.49 47.11Â±2.31 39.26Â±2.98
JoCoR 76.21Â±0.47 73.56Â±0.51 68.21Â±0.49 53.69Â±3.21 43.22Â±4.09
T-Revision 77.72Â±0.31 75.31Â±0.43 73.51Â±0.55 57.92Â±1.02 50.10Â±2.76
CCR 74.47Â±0.19 68.47Â±0.32 65.46Â±0.29 56.07Â±0.89 48.05Â±1.49
VolMinNet 80.02Â±0.23 76.73Â±0.31 72.02Â±0.44 65.83Â±0.97 49.96Â±1.21
PTD 78.36Â±0.43 76.69Â±0.39 72.04Â±0.45 58.32Â±1.32 42.69Â±2.99
BLTM 80.01Â±0.34 79.58Â±0.23 73.17Â±1.02 64.78Â±1.92 56.49Â±3.69
MEIDTM 79.37Â±0.39 70.65Â±0.47 62.43Â±0.41 52.98Â±1.23 42.97Â±2.92
CRGR 81.51Â±0.57 80 .01Â±0.51 77 .01Â±1.75 68 .28Â±4.06 60 .86Â±3.18
and then we set the diagonal entry ğ‘ğ‘¦ğ‘–=1âˆ’ğ‘ğ‘–while making the
sum of the off-diagonal entries of ğ‘¦ğ‘–-th row equal to ğ‘ğ‘–. Finally,
according to the probabilities ğ‘, we randomly choose noisy labels
for all the instances to generate synthetic noisy datasets. For all
the experiments on synthetic datasets, we split the images into
the training set and validation set according to the ratio of 4:1 and
conducted five repeated experiments with different seeds to ensure
the experimental results are dependable.
Implementation details. We use ResNet-34 [ 15] as the back-
bone network for all the experiments on synthetic noisy datasets
and ResNet-50 [ 15] for the experiments on real-world noisy dataset
Clothing-1M. For the transition network, while maintaining the
overall architecture of the backbone network, we modify the last
linear layer to accommodate the specific shape of the transition
matrix. For all the experiments, we first use the early-stop strategy
[1,38] to warm up the backbone network for five epochs on the
noisy dataset and then extract confident clean instances with the
pre-defined threshold ğœŒğ‘šğ‘ğ‘¥=0.3. Subsequently, we use the SGD
[4] optimizer with a momentum of 0.9, a batch size of 128, and an
initial learning rate of 0.01 to train the transition network. Finally,
we fix the well-trained transition network to learn the parametersof the classification network. In this stage, the classification net-
work is trained using the Adam [ 21] optimizer with a weight decay
1Ã—10âˆ’4, a batch size of 128, and a learning rate 5Ã—10âˆ’7. For a fair
comparison, it is worth noting that we do not use any data aug-
mentation techniques in all the experiments. All the experiments
documented in this paper are executed using PyTorch [ 29] on two
GPUs (NVIDIA RTX 3090) functioning in parallel.
Comparison methods. To demonstrate the superiority of the
proposed CRGR method, we compare it with the following ap-
proaches: (1) CE, which trains the classifier directly on the noisy
dataset with the standard cross-entropy loss and is considered as
baseline; (2) Co-teaching+ [ 45], which simultaneously develops
two neural networks to select small-loss instances with prediction
disagreement for network training; (3) JoCoR [ 36], which adopts a
joint training method with co-regularization; (4) T-Revision [ 40],
which first initializes transition matrix by exploiting instances that
are similar to anchor points and then introducing a slack variable
to modify the initial estimator; (5) CCR [ 7], which estimates the
transition matrix under a forward-backward cycle-consistency reg-
ularization and constructs the classifier; (6) VolMinNet [ 26], which
solves label noise learning by optimizing the volume of the sim-
plex formed by the columns of the transition matrix; (7) PTD [ 39],
 
216Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 2: Means and standard deviations (percentage) of classification accuracy on SVHN with different label noise levels.
Method IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
CE 90.27Â±0.41 89.69Â±0.53 85.99Â±0.97 65.24Â±1.69 48.76Â±4.12
Co-teaching+ 92.96Â±0.77 91.65Â±0.81 85.77Â±1.98 56.33Â±1.77 42.68Â±3.38
JoCoR 88.57Â±0.54 80.26Â±0.67 77.52Â±0.99 65.86Â±1.92 47.52Â±3.82
T-Revision 92.84Â±0.33 92.33Â±0.71 83.16Â±0.88 73.60Â±1.45 66.91Â±4.49
CCR 92.64Â±0.39 90.46Â±0.57 88.69Â±0.93 76.84Â±1.85 70.24Â±2.01
VolMinNet 93.89Â±0.21 93.23Â±0.53 78.37Â±0.49 69.21Â±0.99 56.91Â±3.09
PTD 94.71Â±0.57 94.33Â±0.66 91.11Â±0.89 90.32Â±1.44 53.65Â±4.32
BLTM 94.35Â±0.42 91.55Â±1.29 89.78Â±3.58 83.71Â±3.99 70.41Â±6.53
MEIDTM 91.74Â±0.65 85.52Â±0.72 79.71Â±1.64 66.22Â±3.12 60.76Â±4.22
CRGR 95.12Â±0.33 94 .59Â±0.88 93 .23Â±1.13 91 .35Â±1.99 77 .58Â±4.24
Table 3: Means and standard deviations (percentage) of classification accuracy on CIFAR-100 with different label noise levels.
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
CE 46.45Â±0.29 41.51Â±0.55 38.71Â±1.76 30.01Â±0.98 27.81Â±1.86
Co-teaching+ 49.05Â±0.58 43.21Â±1.33 41.55Â±1.01 38.11Â±0.95 30.09Â±2.55
JoCoR 49.31Â±0.27 43.55Â±0.77 40.11Â±0.92 37.21Â±1.82 31.02Â±2.34
T-Revision 47.74Â±0.54 43.31Â±0.91 36.19Â±1.56 29.25Â±1.33 25.23Â±1.19
CCR 45.28Â±0.19 40.72Â±0.24 34.68Â±0,58 28.53Â±0.97 27.08Â±1.22
VolMinNet 49.17Â±0.32 47.02Â±0.27 43.11Â±0.94 38.62Â±1.41 29.88Â±1.88
PTD 44.77Â±0.49 41.39Â±0.68 36.77Â±1.97 30.59Â±1.37 26.87Â±2.26
BLTM 44.65Â±1.13 42.09Â±0.61 37.85Â±1.14 33.23Â±0.61 27.73Â±1.07
MEIDTM 45.21Â±0.99 41.14Â±0.51 34.55Â±1.78 29.58Â±1.99 26.25Â±2.06
CRGR 51.03Â±0.67 48 .94Â±0.27 44 .91Â±2.15 39 .76Â±1.68 32 .04Â±2.25
which approximates the IDN by exploiting part-dependent label
noise; (8) BLTM [ 43], which estimates the IDN transition matrix
using a deep neural network; (9) MEIDTM [ 6], which proposes a
manifold-regularized technique to facilitate the estimation of the
IDN transition matrix and finally construct a consistent classifier.
5.2 Experimental Results
In this subsection, We conclude the experimental results from the
following three aspects:
(1) How are the results on the synthetic noisy datasets?
Table 1, 2 and 3 demonstrate the classification accuracy on syn-
thetic noisy datasets CIFAR-10, SVHN, and CIFAR-100, respectively,
where the best classification results are emphasized in bold. These
results indicate that CRGR outperforms current state-of-the-art
methods in tackling IDN. Specifically, compared with the previous
approaches, CRGR outperforms the former by a margin of 4.37%,
7.17%, and 2.16% on the datasets CIFAR-10, SVHN, and CIFAR-100respectively. Additionally, as the noise rate increases, CRGR re-
veals its superiority, outperforming the second-best method by an
average margin of 1.21% and 4.19% under IDN-10% and IDN-50%,
exhibiting its robustness under the extreme noise rate.
(2) How are the results on the real-world dataset? To evalu-
ate the performance of CRGR in real-world scenarios, we conduct
experiments on the real-world noisy dataset Clothing-1M. The clas-
sification accuracy is exhibited in Table 4. The results show that
CRGR surpasses all comparison methods and achieves the best clas-
sification accuracy, demonstrating its effectiveness and superiority
in practical applications.
(3) How well are the inter-class imbalance and intra-class
selection bias problems solved? We conduct experiments on
the synthetic CIFAR-10 dataset with a 50% noise rate to evaluate
CRGRâ€™s performance on different classes and instances. As shown
in Figure 4, compared with the base method, CRGR improves the
classification accuracy by 5.25% and 27.16% on the classes with the
most and the least extracted instances, respectively, reducing the
 
217KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
Table 4: Classification accuracy on the Clothing-1M dataset.
Methods CE Co-teaching+ JoCoR CCR T-Revision VolMinNet PTD BLTM MEIDTM CRGR
Accuracy(%) 68.64 66.37 70.39 71.85 70.82 72.38 71.53 73.09 73.57 74.29
/uni00000014/uni00000013/uni00000008 /uni00000015/uni00000013/uni00000008 /uni00000016/uni00000013/uni00000008 /uni00000017/uni00000013/uni00000008 /uni00000018/uni00000013/uni00000008
/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000035/uni00000044/uni00000057/uni00000048/uni00000018/uni00000018/uni00000019/uni00000013/uni00000019/uni00000018/uni0000001a/uni00000013/uni0000001a/uni00000018/uni0000001b/uni00000013/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c
/uni00000026/uni00000035/uni0000002a/uni00000035
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni00000048
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni0000005a
/uni00000045/uni00000044/uni00000056/uni00000048
(a)
/uni00000014/uni00000013/uni00000008 /uni00000015/uni00000013/uni00000008 /uni00000016/uni00000013/uni00000008 /uni00000017/uni00000013/uni00000008 /uni00000018/uni00000013/uni00000008
/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000035/uni00000044/uni00000057/uni00000048/uni00000019/uni00000018/uni0000001a/uni00000013/uni0000001a/uni00000018/uni0000001b/uni00000013/uni0000001b/uni00000018/uni0000001c/uni00000013/uni0000001c/uni00000018/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c
/uni00000026/uni00000035/uni0000002a/uni00000035
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni00000048
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni0000005a
/uni00000045/uni00000044/uni00000056/uni00000048 (b)
/uni00000014/uni00000013/uni00000008 /uni00000015/uni00000013/uni00000008 /uni00000016/uni00000013/uni00000008 /uni00000017/uni00000013/uni00000008 /uni00000018/uni00000013/uni00000008
/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000035/uni00000044/uni00000057/uni00000048/uni00000016/uni00000013/uni00000016/uni00000018/uni00000017/uni00000013/uni00000017/uni00000018/uni00000018/uni00000013/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c
/uni00000026/uni00000035/uni0000002a/uni00000035
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni00000048
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni0000005a
/uni00000045/uni00000044/uni00000056/uni00000048 (c)
/uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000014 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000016 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000018
/uni00000017/uni00000018/uni00000018/uni00000013/uni00000018/uni00000018/uni00000019/uni00000013/uni00000019/uni00000018/uni0000001a/uni00000013/uni0000001a/uni00000018/uni0000001b/uni00000013/uni0000001b/uni00000018/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c
 /uni0000002c/uni00000027/uni00000031/uni00000010/uni00000014/uni00000013/uni00000008
/uni0000002c/uni00000027/uni00000031/uni00000010/uni00000015/uni00000013/uni00000008
/uni0000002c/uni00000027/uni00000031/uni00000010/uni00000016/uni00000013/uni00000008/uni0000002c/uni00000027/uni00000031/uni00000010/uni00000017/uni00000013/uni00000008
/uni0000002c/uni00000027/uni00000031/uni00000010/uni00000018/uni00000013/uni00000008 (d)
Figure 3: Illustration of the ablation study of each component and the hyper-parameter sensitivity. Figure 3a-3c demonstrate
the ablation studies on synthetic noisy datasets CIFAR-10, SVHN, and CIFAR-100 with different noise rates, respectively. Figure
3d illustrates the classification accuracy with various values of hyper-parameter ğ›¼onCIFAR-10 noisy dataset with different
noise rates.
Majority Class Minority Class
Class02040Accuracy (%)
Confident Clean Instance Ambiguous Instance
Instance020406080Accuracy (%)base CRGR base CRGR
Figure 4: An illustration of classification accuracy on dif-
ferent classes and instances, where the base method repre-
sents the method that trains transition network on biased
extracted instances with cross-entropy loss. Majority and
minority classes denote the classes with the most and least
extracted instances, respectively.
gap between them. Analogously, CRGR improves the classification
accuracy on confident clean instances and ambiguous instances by
6.05% and 9.08%, respectively, narrowing the gap by 3.03%. These
results indicate that CRGR effectively mitigates both inter-class
and intra-class fitting bias, leading to a more equitable and robust
classifier.
5.3 Ablation Study
In this subsection, we first conduct ablation experiments to inves-
tigate the effect of reweighting technique and geometric regular-
ization on the proposed method. Then we discuss the selection of
hyperparameters ğ›¼andğœŒğ‘šğ‘ğ‘¥.
Effect of reweighting technique and geometric regulariza-
tion. In this paper, we utilize a smoothed noise-tolerant reweightingtechnique to calibrate the inter-class imbalance and incorporate am-
biguous instances into the training framework by adding geometric
regularization. Ablation experiments are conducted to assess the in-
dividual contributions of the reweighting technique and geometric
regularization in enhancing the performance of the classifier. Specif-
ically, we use â€™w/o rwâ€™ and â€™w/o reâ€™ to indicate the approach that
does not apply the reweighting methodology and geometric reg-
ularization respectively. The method directly trains the transition
network on the biased extracted instances without any improve-
ments is used as the base method. We compare the classification
accuracy of different methods on synthetic datasets with different
noise rates, and the corresponding results are shown in Figure 3a
- 3c. The results show that either removing the reweighting tech-
nique (w/o rw) or geometric regularization (w/o re) degrades the
performance of the classifier. At the same time, the basic method
(base), which removes both of the above improvements, exhibits the
worst performance. These observations collectively demonstrate
the effectiveness of both the reweighting technique and geometric
regularization in constructing a more robust classifier.
The selection of hyperparameters ğ›¼andğœŒğ‘šğ‘ğ‘¥.To investigate
the influence of the hyperparameter ğ›¼on the proposed method,
we conduct experiments on the synthetic noisy dataset CIFAR-10
with various values of ğ›¼under noise rates from 10% to 50%. The
corresponding results are shown in Figure 3d. The findings indicate
that the classification accuracy is not sensitive to ğ›¼when the noise
rate is low, but it is sensitive when the noise rate is high. At the
same time, with the increase of ğ›¼, the classification accuracy first
rises and then declines, achieving the best value when ğ›¼is set as
0.3. Therefore, we set ğ›¼=0.3in all the experiments.
Meanwhile, we use the distillation method in [ 6] to extract the
confident clean instances. According to [ 6], onceğœŒğ‘šğ‘ğ‘¥ is selected
as the upper bound of the noise rate, the distilled confident clean
 
218Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
instancesâ€™ inferred latent clean labels are identical to the Bayes
optimal labels. Hence, the clean labels can be accurately identified.
However, when the noise rate is high, the number of distilled confi-
dent clean instances drops. Therefore, we should trade-off between
the number of distilled instances and distillation accuracy. [6] has
provided sufficient evidence that ğœŒğ‘šğ‘ğ‘¥=0.3is reasonable for distil-
lation. Specifically, they set the hyperparameter ğœŒğ‘šğ‘ğ‘¥ to 0.1, 0.2, 0.3,
0.4, 0.5, and 0.6, respectively, and calculate the instance-dependent
transition matrix approximation error under different thresholds on
the CIFAR-10 dataset with IDN-30% noise rate. When the threshold
ğœŒğ‘šğ‘ğ‘¥ is set as 0.3, the error achieves the minimum value. Therefore,
following their conclusion, we set ğœŒğ‘šğ‘ğ‘¥=0.3in all the experiments
in this paper.
6 CONCLUSION AND LIMITATION
Conclusion. In this paper, we propose a novel label noise learning
framework called CRGR, which addresses both inter-class imbal-
ance and intra-class selection bias issues inherent in confident clean
instances, ultimately leading to a more equitable and robust clas-
sifier. Specifically, we introduce a novel smoothed, noise-tolerant
reweighting technique that equalizes the networkâ€™s exposure to
noise patterns across different classes, thereby calibrating the imbal-
anced inter-class distribution. Additionally, based on evidence that
similar instances tend to exhibit comparable noise patterns, we posit
thatğ‘‡(ğ’™)should mirror the similarity of the feature space. This
insight leads to the inclusion of ambiguous instances in training,
serving as geometric regularization. Such regularization aids the
model in overcoming intra-class selection bias and understanding
complex noise patterns. Extensive experiments on both synthetic
and real-world datasets demonstrate that CRGR outperforms cur-
rent state-of-the-art methods, showcasing its superiority.
Limitation. One major limitation of our study is that the use
of Euclidean distance to measure similarity relations between in-
stances in both feature and transition matrix spaces. However,
Euclidean distance may not be an ideal indicator, as the high-
dimensional space may be embedded in a manifold. In the future,
we will employ geodesic distance to measure the similarity between
instances, thereby more effectively grasping their underlying re-
lationships and contributing to the development of a more robust
classifier.
ACKNOWLEDGMENTS
This research was partially supported by the National Key Re-
search and Development Project of China No. 2021ZD0110700, the
Key Research and Development Project in Shaanxi Province No.
2022GXLH-01-03, and the National Science Foundation of China
under Grant Nos. 62037001 and 62250009.
REFERENCES
[1]Yingbin Bai, Erkun Yang, Bo Han, Yanhua Yang, Jiatong Li, Yinian Mao, Gang
Niu, and Tongliang Liu. 2021. Understanding and improving early stopping for
learning with noisy labels. Advances in Neural Information Processing Systems 34
(2021), 24392â€“24403.
[2]Antonin Berthon, Bo Han, Gang Niu, Tongliang Liu, and Masashi Sugiyama. 2021.
Confidence scores make instance-dependent label-noise learning possible. In
International conference on machine learning. PMLR, 825â€“836.
[3]Avrim Blum, Adam Kalai, and Hal Wasserman. 2003. Noise-tolerant learning,
the parity problem, and the statistical query model. Journal of the ACM (JACM)
50, 4 (2003), 506â€“519.[4]LÃ©on Bottou. 2010. Large-scale machine learning with stochastic gradient descent.
InProceedings of COMPSTATâ€™2010: 19th International Conference on Computational
StatisticsParis France, August 22-27, 2010 Keynote, Invited and Contributed Papers.
Springer, 177â€“186.
[5]Pengfei Chen, Junjie Ye, Guangyong Chen, Jingwei Zhao, and Pheng-Ann Heng.
2021. Beyond class-conditional assumption: A primary attempt to combat
instance-dependent label noise. In Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 35. 11442â€“11450.
[6]De Cheng, Tongliang Liu, Yixiong Ning, Nannan Wang, Bo Han, Gang Niu, Xinbo
Gao, and Masashi Sugiyama. 2022. Instance-dependent label-noise learning with
manifold-regularized transition matrix estimation. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition. 16630â€“16639.
[7]De Cheng, Yixiong Ning, Nannan Wang, Xinbo Gao, Heng Yang, Yuxuan Du,
Bo Han, and Tongliang Liu. 2022. Class-Dependent Label-Noise Learning with
Cycle-Consistency Regularization. Advances in Neural Information Processing
Systems 35 (2022), 11104â€“11116.
[8]Hao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu. 2021.
Learning with Instance-Dependent Label Noise: A Sample Sieve Approach. In
International Conference on Learning Representations.
[9]Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, and Dacheng Tao. 2020.
Learning with bounded instance and label-dependent label noise. In International
conference on machine learning. PMLR, 1789â€“1799.
[10] Uri Cohen, SueYeon Chung, Daniel D Lee, and Haim Sompolinsky. 2020. Sep-
arability and geometry of object manifolds in deep neural networks. Nature
communications 11, 1 (2020), 746.
[11] Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. 2019. Class-
balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition. 9268â€“9277.
[12] Tausif Diwan, G Anirudh, and Jitendra V Tembhurne. 2023. Object detection
using YOLO: Challenges, architectural successors, datasets and applications.
multimedia Tools and Applications 82, 6 (2023), 9243â€“9275.
[13] Charles Elkan. 2001. The foundations of cost-sensitive learning. In International
joint conference on artificial intelligence, Vol. 17. Lawrence Erlbaum Associates
Ltd, 973â€“978.
[14] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang,
and Masashi Sugiyama. 2018. Co-teaching: Robust training of deep neural net-
works with extremely noisy labels. Advances in neural information processing
systems 31 (2018).
[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770â€“778.
[16] Danula Hettiachchi, Vassilis Kostakos, and Jorge Goncalves. 2022. A survey on
task assignment in crowdsourcing. ACM Computing Surveys (CSUR) 55, 3 (2022),
1â€“35.
[17] Chen Huang, Yining Li, Chen Change Loy, and Xiaoou Tang. 2016. Learning deep
representation for imbalanced classification. In Proceedings of the IEEE conference
on computer vision and pattern recognition. 5375â€“5384.
[18] Huaxi Huang, Hui Kang, Sheng Liu, Olivier Salvado, Thierry Rakotoarivelo,
Dadong Wang, and Tongliang Liu. 2023. Paddles: Phase-amplitude spectrum
disentangled early stopping for learning with noisy labels. In Proceedings of the
IEEE/CVF International Conference on Computer Vision. 16719â€“16730.
[19] Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. 2018. Mentor-
net: Learning data-driven curriculum for very deep neural networks on corrupted
labels. In International conference on machine learning. PMLR, 2304â€“2313.
[20] Nazmul Karim, Mamshad Nayeem Rizve, Nazanin Rahnavard, Ajmal Mian, and
Mubarak Shah. 2022. Unicon: Combating label noise through uniform selection
and contrastive learning. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. 9676â€“9686.
[21] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[22] Jan Kremer, Fei Sha, and Christian Igel. 2018. Robust active label correction. In
International conference on artificial intelligence and statistics. PMLR, 308â€“316.
[23] Alex Krizhevsky and Geoffrey Hinton. 2009. Learning multiple layers of features
from tiny images. Technical Report. Citeseer.
[24] Mingchen Li, Mahdi Soltanolkotabi, and Samet Oymak. 2020. Gradient descent
with early stopping is provably robust to label noise for overparameterized neural
networks. In International conference on artificial intelligence and statistics. PMLR,
4313â€“4324.
[25] Shutao Li, Weiwei Song, Leyuan Fang, Yushi Chen, Pedram Ghamisi, and Jon Atli
Benediktsson. 2019. Deep learning for hyperspectral image classification: An
overview. IEEE Transactions on Geoscience and Remote Sensing 57, 9 (2019),
6690â€“6709.
[26] Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. 2021.
Provably end-to-end label-noise learning without anchor points. In International
conference on machine learning. PMLR, 6403â€“6413.
[27] Li Liu, Wanli Ouyang, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, and
Matti PietikÃ¤inen. 2020. Deep learning for generic object detection: A survey.
International journal of computer vision 128 (2020), 261â€“318.
 
219KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
[28] Stephen E Palmer. 1977. Hierarchical structure in perceptual representation.
Cognitive psychology 9, 4 (1977), 441â€“474.
[29] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al .2019.
Pytorch: An imperative style, high-performance deep learning library. Advances
in neural information processing systems 32 (2019).
[30] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and
Lizhen Qu. 2017. Making deep neural networks robust to label noise: A loss
correction approach. In Proceedings of the IEEE conference on computer vision and
pattern recognition. 1944â€“1952.
[31] Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. 2018.
Joint optimization framework for learning with noisy labels. In Proceedings of
the IEEE conference on computer vision and pattern recognition. 5552â€“5560.
[32] Arash Vahdat. 2017. Toward robustness against label noise in training deep
discriminative neural networks. Advances in neural information processing systems
30 (2017).
[33] Kai Wang, Xiangyu Peng, Shuo Yang, Jianfei Yang, Zheng Zhu, Xinchao Wang,
and Yang You. 2022. Reliable label correction is a good booster when learning
with extremely noisy labels. arXiv preprint arXiv:2205.00186 (2022).
[34] Wei Wang, Yujing Yang, Xin Wang, Weizheng Wang, and Ji Li. 2019. Development
of convolutional neural network and its application in image classification: a
survey. Optical Engineering 58, 4 (2019), 040901â€“040901.
[35] Yu-Xiong Wang, Deva Ramanan, and Martial Hebert. 2017. Learning to model
the tail. Advances in neural information processing systems 30 (2017).
[36] Hongxin Wei, Lei Feng, Xiangyu Chen, and Bo An. 2020. Combating noisy labels
by agreement: A joint training method with co-regularization. In Proceedings of
the IEEE/CVF conference on computer vision and pattern recognition. 13726â€“13735.
[37] Qi Wei, Haoliang Sun, Xiankai Lu, and Yilong Yin. 2022. Self-filtering: A noise-
aware sample selection for label noise with confidence penalization. In European
Conference on Computer Vision. Springer, 516â€“532.
[38] Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge,
and Yi Chang. 2020. Robust early-learning: Hindering the memorization of noisy
labels. In International conference on learning representations.
[39] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng
Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. 2020. Part-dependent label
noise: Towards instance-dependent label noise. Advances in Neural Information
Processing Systems 33 (2020), 7597â€“7610.
[40] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and
Masashi Sugiyama. 2019. Are anchor points really indispensable in label-noise
learning? Advances in neural information processing systems 32 (2019).
[41] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. 2015. Learning
from massive noisy labeled data for image classification. In Proceedings of the
IEEE conference on computer vision and pattern recognition. 2691â€“2699.
[42] Yan Yan, RÃ³mer Rosales, Glenn Fung, Ramanathan Subramanian, and Jennifer
Dy. 2014. Learning from multiple annotators with varying expertise. Machine
learning 95 (2014), 291â€“327.
[43] Shuo Yang, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, and Tongliang
Liu. 2022. Estimating instance-dependent bayes-label transition matrix using a
deep neural network. In International Conference on Machine Learning. PMLR,
25302â€“25312.
[44] Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang Deng, Gang Niu, and
Masashi Sugiyama. 2020. Dual t: Reducing estimation error for transition matrix
in label-noise learning. Advances in neural information processing systems 33
(2020), 7260â€“7271.
[45] Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama.
2019. How does disagreement help generalization against label corruption?. In
International Conference on Machine Learning. PMLR, 7164â€“7173.
[46] Netzer Yuval. 2011. Reading digits in natural images with unsupervised feature
learning. In Proceedings of the NIPS Workshop on Deep Learning and Unsupervised
Feature Learning.
[47] Zhong-Qiu Zhao, Peng Zheng, Shou-tao Xu, and Xindong Wu. 2019. Object
detection with deep learning: A review. IEEE transactions on neural networks and
learning systems 30, 11 (2019), 3212â€“3232.A APPENDIX
A.1 Details of Datasets
â€¢SVHN [46]: The SVHN (Street View House Numbers) dataset
consists of a large collection of color digit images extracted
from Google Street View images. SVHN has 10 classes of
images in total, with 73,257 training instances and 26,032 test
instances of varying sizes.
â€¢CIFAR-10 and CIFAR-100 [23]: Both the CIFAR-10 and CIFAR-
100 datasets were created by the Canadian Institute for Ad-
vanced Research, with images were collected from various
sources covering a wide range of object categories. The
CIFAR-10 and CIFAR-100 datasets each contain 60,000 R GB
images, divided into 50,000 training images and 10,000 test
images. Each image has a resolution of 32Ã—32pixels. CIFAR-
10 consists of 10 object classes, including airplanes, automo-
biles, birds, cats, deer, dogs, frogs, horses, ships, and trucks.
On the other hand, CIFAR-100 contains 100 object classes,
covering a wider range of fine-grained categories, such as
different breeds of dogs, flowers, and household objects.
â€¢Clothing-1M [41]: Clothing-1M is a large-scale RGB image
dataset with 1M training images with noisy labels and 10k im-
ages with clean labels for testing. Clothing-1M has 14 classes
in and all the training images are collected from online shop-
ping websites. Without expert annotation, the labels of the
training images are assigned automatically based on their
surrounding environment, leading to label noise. The clean
images are manually annotated to ensure their labels are
accurate for testing the classifierâ€™s performance.
A.2 Experimental Results of Ablation Study
In the main text, we have conducted ablation experiments to il-
lustrate the contributions of both the reweighting technique and
geometric regularization in improving the classifierâ€™s performance.
However, due to space limitations, we only provided illustrations
using figures. In this supplementary material, more detailed results,
including means and standard deviations of classification accuracy
from the ablation experiments on CIFAR-10, SVHN, and CIFAR-
100, are shown in Table 5, 6 and 7, respectively. Specifically, we
use â€™w/o reâ€™ and â€™w/o rwâ€™ to indicate the approaches that do not
apply geometric regularization and reweighting methodology, re-
spectively, and use the method that directly trains the transition
network on the biased extracted instances without any improve-
ments as the base method. The results show that either removing
the reweighting technique (w/o rw) or geometric regularization
(w/o re) degrades the performance of the classifier. At the same time,
the base method, which removes both of the above improvements,
exhibits the worst performance. These observations collectively
demonstrate the effectiveness of both the reweighting technique
and geometric regularization in constructing a more robust classi-
fier.
 
220Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 5: Means and standard deviations (percentage) of classification accuracy on CIFAR-10 with different IDN levels.
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
base 80.01Â±1.34 79.08Â±0.23 73.17Â±1.02 64.78Â±3.92 56.49Â±3.69
w/o re 80.66Â±0.31 79.65Â±0.37 75.28Â±3.38 66.84Â±4.49 58.76Â±2.67
w/o rw 80.21Â±0.42 79.31Â±0.53 76.32Â±2.47 68.22Â±4.39 59.42Â±2.89
CRGR 81.51Â±0.57 80 .01Â±0.51 77 .01Â±1.75 68 .28Â±4.06 60 .86Â±3.18
Table 6: Means and standard deviations (percentage) of classification accuracy on SVHN with different IDN levels.
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
base 94.35Â±0.42 91.55Â±4.19 89.78Â±3.58 83.71Â±4.60 70.41Â±6.53
w/o re 94.65Â±0.51 92.83Â±1.37 90.82Â±2.69 89.12Â±3.50 72.37Â±3.37
w/o rw 94.45Â±0.62 93.32Â±1.53 91.57Â±2.78 85.49Â±3.29 75.09Â±3.09
CRGR 95.12Â±0.33 94 .59Â±0.89 93 .23Â±1.13 91 .35Â±1.99 77 .58Â±6.25
Table 7: Means and standard deviations (percentage) of classification accuracy on CIFAR-100 with different IDN levels.
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
base 44.65Â±1.14 42.09Â±0.61 37.85Â±1.18 33.23Â±0.60 27.73Â±1.07
w/o re 49.28Â±1.51 47.19Â±2.16 42.95Â±2.02 37.65Â±1.09 31.63Â±0.87
w/o rw 49.90Â±1.42 46.67Â±1.53 43.26Â±1.78 38.58Â±0.89 31.89Â±1.09
CRGR 51.03Â±0.67 48 .94Â±0.27 44 .91Â±2.15 39 .76Â±1.54 32 .04Â±2.25
 
221