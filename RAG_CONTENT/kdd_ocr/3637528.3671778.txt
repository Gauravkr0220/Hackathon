Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint
Shuang Cui
lakers@mail.ustc.edu.cn
School of Computer Science and
Technology, University of Science and
Technology of China
Hefei, Anhui, ChinaKai Hanâˆ—
hankai@suda.edu.cn
School of Computer Science and
Technology, Soochow University
Suzhou, Jiangsu, ChinaShaojie Tang
shaojie.tang@utdallas.edu
The University of Texas at Dallas
Richardson, Texas, United States
Feng Li
fli@sdu.edu.cn
School of Computer Science and 
Technology, Shandong University /
Key Laboratory of Computing Power 
Network and Information Security, 
Ministry of Education, Qilu 
University of Technology
Qingdao / Jinan, Shandong, ChinaJun Luo
junluo@ntu.edu.sg
Nanyang Technological University
Singapore
ABSTRACT
Submodular optimization has been identified as a powerful tool for
many data mining applications, where a representative subset of
moderate size needs to be extracted from a large-scale dataset. In
scenarios where data points possess sensitive attributes such as age,
gender, or race, it becomes imperative to integrate fairness measures
into submodular optimization to mitigate bias and discrimination.
In this paper, we study the fundamental problem of fair submodular
maximization subject to a knapsack constraint and propose the first
streaming algorithm for it with provable performance guarantees
for both monotone and non-monotone submodular functions. As a
byproduct, we also propose a streaming algorithm for submodular
maximization subject to a partition matroid and a knapsack con-
straint, significantly improving the performance bounds achieved
by previous work. We conduct extensive experiments on real-world
applications such as movie recommendation, image summariza-
tion, and maximum coverage in social networks. The experimental
results strongly demonstrate the superiority of our proposed algo-
rithms in terms of both fairness and utility.
CCS CONCEPTS
â€¢Information systems â†’Data stream mining; â€¢Theory of
computationâ†’Approximation algorithms analysis.
âˆ—Corresponding author: Kai Han
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671778KEYWORDS
data stream mining, fairness, submodular maximization, streaming
algorithm
ACM Reference Format:
Shuang Cui, Kai Han, Shaojie Tang, Feng li, and Jun Luo. 2024. Fairness in
Streaming Submodular Maximization Subject to a Knapsack Constraint. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671778
1 INTRODUCTION
Data mining applications usually need to extract a representative
subset with moderate size from a large-scale dataset. Submodular
optimization theory has been identified as a powerful tool for this
task, especially when the underlying dataset obeys the â€œdiminishing
returnsâ€ property. This can be seen from the fact that a lot of studies
have applied submodular optimization into numerous data mining
applications including social media marketing [ 8,39,40,47,49,67],
feature selection [ 3,4,9,45,72,76], information gathering [ 51],
document summarization [ 16,53,57â€“60,74], movie recommenda-
tion [5, 24, 36, 65], image summarization [29, 63, 70], and so on.
However, recent studies have found that data summaries gener-
ated by traditional submodular optimization algorithms may exhibit
bias and discrimination concerning sensitive attributes such as age,
gender, or race, which can be a crucial problem in some domains like
voting, hiring, criminal justice, and higher education [ 25,26,71]. To
address this problem, Celis et al . [14] introduced fairness constraints
into submodular maximization problems, ensuring that the selected
data should represent each sensitive attribute equitably. Formally,
assuming that each element ğ‘¢in the ground dataset Nis assigned
a unique group from the set {1,...,â„}, Celis et al . [14] defined a
setğ´âŠ†N to be fair if it satisfies âˆ€ğ‘¡âˆˆ[â„]:â„“ğ‘¡â‰¤|ğ´âˆ©Nğ‘¡|â‰¤ğ‘¢ğ‘¡for
the given lower and upper bounds â„“ğ‘¡,ğ‘¢ğ‘¡âˆˆZâ‰¥0(âˆ€ğ‘¡âˆˆ[â„]), where
Nğ‘¡denotes the set of all elements in group ğ‘¡. Subsequently, several
514
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
studies have adopted this fairness model and proposed fair submod-
ular maximization algorithms under different constraints, including
cardinality constraint [26] and matroid constraint [25, 37].
However, to the best of our knowledge, no previous studies
have considered the fundamental problem of fairsubmodular max-
imization subject to a knapsack constraint (abbreviated as the FSK
problem). This gap in the literature is significant as the FSK problem
is pertinent to many real-world scenarios. For example, in multi-
winner voting and participatory budgeting [ 10,11,14,33,34,41,
46,66], some items/projects with different costs need to be selected
under a budget constraint, while the projects may belong to various
categories such as educational projects, elderly-care initiatives, and
suburban development. Since different categories involve different
peopleâ€™s interests, it is crucial to consider fairness in this scenario.
It is also noted that the traditional problem of submodular max-
imization under a knapsack constraint (without considering the
fairness issue) has been extensively studied (e.g., [ 1,27,28,35,50,
54,55]), and most of these studies concentrate on the offline set-
ting where one has full access to the whole dataset. However, in
many applications for â€œbig dataâ€, the overwhelming scale of the
underlying dataset makes it infeasible to store all data in mem-
ory and hence the offline submodular optimization algorithms no
longer work. To address this issue, a few studies try to address the
problem of streaming submodular maximization under a knapsack
constraint [ 21,38,42â€“44,75,77]. Unfortunately, these studies still
neglect the fairness issue, and it is highly non-trivial (if possible) to
adapt them to address the fair submodular maximization problem.
Based on the above observations, this paper aims to fill the gap in
the existing studies by proposing the first streaming algorithm with
provable performance bounds for the problem of fair submodular
maximization subject to a knapsack constraint.
1.1 Challenges and Techniques
As aforementioned, the existing algorithms for fair submodular max-
imization can only handle cardinality or matroid constraints [ 14,25,
26,37,71]. Since the cardinality constraint and matroid constraint
are both special cases of a 1-extendable system constraint [ 61], and a
knapsack constraint can only be modeled as ağ‘ğ‘šğ‘ğ‘¥
ğ‘ğ‘šğ‘–ğ‘›-extendable sys-
tem constraint with ğ‘ğ‘šğ‘–ğ‘›=minğ‘’âˆˆNğ‘(ğ‘’)andğ‘ğ‘šğ‘ğ‘¥=maxğ‘’âˆˆNğ‘(ğ‘’)
whereğ‘(ğ‘’)denotes the cost of the element ğ‘’[32], directly applying
the existing algorithms to our FSK problem cannot lead to any per-
formance guarantee. Even for a 1-extendable system constraint (i.e.,
matroid), El Halabi et al . [25] have proved that it is impossible to
design a fair memory-efficient streaming algorithm with a provable
approximation ratio, so they only provide streaming algorithms
where the fairness lower bounds (i.e., {ğ‘™ğ‘¡:ğ‘¡âˆˆ[â„]}) can be violated
by a factor of 1/2. Therefore, we follow [ 25] to allow that the fair-
ness lower bounds can be violated by the same factor of 1/2in this
paper.
In fact, the FSK problem is challenging even if there are only
fairness upper bounds (i.e., {ğ‘¢ğ‘¡:ğ‘¡âˆˆ [â„]}) whenğ‘™ğ‘¡=0for all
ğ‘¡âˆˆ[â„]. In this case, the FSK problem degenerates into the prob-
lem of streaming submodular maximization subject to a partition
matroid and a knapsack constraint (abbreviated as the SMK prob-
lem), which still has not been well studied. To our knowledge, only
Cui et al . [21] have provided a streaming algorithm to address theSMK problem, but their approximation ratio deteriorates as the
size of the maximum feasible solution increases, which is far from
satisfactory.
To address the above challenges, we propose a novel approach
to address the FSK problem as follows. In the first step, we scan the
data stream once to construct a small â€œreserved datasetâ€ using a
small portion of the budget ğµ, such that the reserved dataset has
exactly 2âŒŠğ‘™ğ‘¡/2âŒ‹â‰ˆğ‘™ğ‘¡elements for each ğ‘¡âˆˆ[â„]but has no perfor-
mance guarantee on the objective function value. Then, we use the
leftover budget to construct another dataset that has guaranteed
performance on the objective function value but only satisfies the
fairness upper bounds {ğ‘¢ğ‘¡:ğ‘¡âˆˆ[â„]}. To achieve this, we propose
a novel steaming algorithm for the SMK problem, which achieves
much better performance bounds than the previous work in [ 21].
Finally, the two generated datasets mentioned above are combined
together to produce a solution satisfying both the (relaxed) fairness
constraint and the budget constraint. The major difficulty behind
this approach is about deriving the performance guarantees on the
approximation ratio and time/space complexities, because neither
of the aforementioned two datasets is generated using the total
budget. To bypass this difficulty, we leverage some specific tricks in-
cluding random sampling to ensure the quality of the final solution.
More details can be found in Section 4.
1.2 Our Contributions
In this study, we propose two novel streaming algorithms to address
the FSK and SMK problems, respectively. The main contributions
of our paper can be summarized as follows:
â€¢We propose a two-pass streaming algorithm dubbed FairK-
napStream for the FSK problem, achieving the approxima-
tion ratios of1
12âˆ’ğœ–and1
40+16âˆš
2âˆ’ğœ–for monotone and non-
monotone submodular functions, respectively. The query
complexity and space complexity of FairKnapStream isO(ğ‘›ğ‘˜)
andO(ğ‘˜), respectively, where ğ‘˜is the size of the maximum
feasible solution to the FSK problem. To the best of our
knowledge, FairKnapStream is the first attempt on FSK, as
no previous studies have proposed any offline or streaming
algorithm to address the FSK problem, no matter the objec-
tive submodular function is monotone or non-monotone.
â€¢As a byproduct, we propose a one-pass streaming algorithm
dubbed MatKnapStream for the SMK problem, which achieves
approximation ratios of1
6(1+ğœ–)and1
(10+4âˆš
2)(1+ğœ–)for mono-
tone and non-monotone submodular functions, respectively.
The query complexity and space complexity of MatKnap-
Stream areO(ğ‘›ğ‘˜)andO(ğ‘˜), respectively. Note that MatK-
napStream significantly improves the streaming algorithm
proposed in Cui et al . [21] with an approximation ratio of
1âˆ’1/â„
(3+2 log2ğ‘˜)(2+â„)+3(where the integer â„>2is an input pa-
rameter), because the ratio of Cui et al . [21] is no more than
1/42 even for a small ğ‘˜such as 2.
â€¢We conduct extensive experiments using several real-world
applications including movie recommendation, image sum-
marization, and maximum coverage in social networks. The
experimental results demonstrate that our proposed algo-
rithms fully satisfy the fairness constraints, while achieving
515Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
similar performance on utility compared to the state-of-the-
art streaming algorithms for knapsack and/or ğ‘-system con-
straints such as [21, 38].
Due to the space limit, we defer the detailed proofs of most
lemmas and theorems to Appendix A, while only providing some
intuitions and key ideas for them in the main text.
2 RELATED WORK
2.1 Fair Submodular Maximization
Several studies [ 13â€“15,17,18,25,26,37] have adopted the same
fairness model as our work. Celis et al . [14] investigated the fair sub-
modular maximization problem subject to a cardinality constraint ğ‘˜,
and they provided a tight (1âˆ’1/ğ‘’)-approximation under the offline
setting using a continuous greedy algorithm. Subsequently, El Hal-
abi et al . [26] studied the same problem as that in [ 14] under the
streaming setting, and proposed a 1/4-approximation algorithm for
a monotone submodular function using O(ğ‘˜)memory consumption
and two oracle queries per element. Moreover, for non-monotone
objective functions, El Halabi et al . [26] proved that it is impossible
to achieve an approximation ratio better than 1âˆ’maxğ‘¡âˆˆ[â„]â„“ğ‘¡
|Nğ‘¡|
under sublinear space complexity. More recently, El Halabi et al .
[25] considered the problem of fair monotone submodular maxi-
mization under a more general matroid constraint, and proved that
it is impossible to design a multi-pass, memory-efficient streaming
algorithm with a provable approximation ratio. They also proposed
a two-pass streaming algorithm with an approximation ratio of
1/11.656, but relaxing the fairness lower bounds by a factor of 1/2.
Besides, there exist several studies (e.g., [ 68,69,71,78]) consider-
ing some special cases or variations of the fairness model adopted
in [13â€“15,17,18,25,26,37]. A representative work among them
is [71], in which the fairness model has identical lower and up-
per bounds for each group (i.e., â„“ğ‘¡=ğ‘¢ğ‘¡for allğ‘¡âˆˆ[â„]), and they
designed a streaming algorithm with 1/2-approximation under a
cardinality constraint.
To the best of our knowledge, no previous studies have inves-
tigated the problem of fair submodular maximization subject to a
knapsack constraint under any fairness model.
2.2 Submodular Maximization Subject to a
Knapsack Constraint
Without considering the fairness issue, a lot of studies have investi-
gated the problem of submodular maximization with a knapsack
constraint. The pioneering work [ 73] in this line achieved an approx-
imation ratio of 0.357for monotone submodular functions. Most
of the subsequent studies (e.g., [ 1,7,27,28,35,50,54,55]) focused
on designing offline algorithms for monotone or non-monotone
submodular functions, until recently there appeared some algo-
rithms under the streaming setting [ 38,42â€“44,75,77]. Among
these streaming algorithms, the best approximation ratios achieved
for monotone and non-monotone submodular functions are 1/2
(achieved by [38]), and 1/4.7(achieved by [21]), respectively.
3 PROBLEM DEFINITION
Given a finite ground set Nwith|N|=ğ‘›, a non-negative submod-
ular function ğ‘“(Â·)is defined as follows:Definition 3.1 (Submodular Function). A set function ğ‘“:2Nâ†¦â†’
Râ‰¥0is submodular if it satisfies âˆ€ğ‘‹,ğ‘ŒâŠ† N :ğ‘“(ğ‘‹)+ğ‘“(ğ‘Œ) â‰¥
ğ‘“(ğ‘‹âˆªğ‘Œ)+ğ‘“(ğ‘‹âˆ©ğ‘Œ). The function ğ‘“(Â·)is called monotone if
ğ‘“(ğ‘‹)â‰¤ğ‘“(ğ‘Œ)for allğ‘‹âŠ†ğ‘ŒâŠ†N, otherwise it is non-monotone.
In this paper, we allow ğ‘“(Â·)to be either monotone or non-
monotone. Following the existing work such as [ 24â€“26,64], we as-
sume thatğ‘“(Â·)is normalized, i.e., ğ‘“(âˆ…)=0. We assume that each ele-
mentğ‘’âˆˆN has a costğ‘(ğ‘’)and define the function ğ‘(ğ‘†)=Ã
ğ‘’âˆˆğ‘†ğ‘(ğ‘’)
for anyğ‘†âŠ†N . To facilitate the comparison with the existing stud-
ies, we follow [ 5,21,38,75] to assume that the costs of elements in
Nare normalized such that âˆ€ğ‘’âˆˆN:ğ‘(ğ‘’)â‰¥1. For convenience, we
define the marginal gain of anyğ‘’âˆˆN with respect to any ğ´âŠ†N
asğ‘“(ğ‘’|ğ´)=ğ‘“(ğ´âˆª{ğ‘’})âˆ’ğ‘“(ğ´). We also denote the set {1,...,ğ‘–}as
[ğ‘–]for any natural number ğ‘–, and denote the maximum cardinality
of any feasible solution to our problem as ğ‘˜.
We assume that each element ğ‘’âˆˆN is assigned a unique group
number from the set {1,...,â„}. We useNğ‘¡to denote the set of all
elements of group ğ‘¡inNand useğ‘”(ğ‘’)to denote the group number
assigned to any element ğ‘’âˆˆN . Given a set of fairness bounds
{(â„“ğ‘¡,ğ‘¢ğ‘¡):ğ‘¡âˆˆ[â„]}and a budget ğµ, we define the problem of fair
submodular maximization subject to a knapsack constraint
(abbreviated as the FSK problem) as:
max{ğ‘“(ğ´):ğ´âŠ†Nâˆ§ğ‘(ğ´)â‰¤ğµâˆ§âˆ€ğ‘¡âˆˆ[â„]:â„“ğ‘¡â‰¤|ğ´âˆ©Nğ‘¡|â‰¤ğ‘¢ğ‘¡}
We study the FSK problem under the streaming setting, where all
elements inNarrive sequentially in an arbitrary order. Without
loss of generality, we assume that ğ‘(ğ‘’)â‰¤ğµfor everyğ‘’âˆˆN, as
any element ğ‘’withğ‘(ğ‘’)>ğµcan be immediately removed when it
arrives. Throughout this paper, we denote an optimal solution to
the FSK problem as ğ‘‚.
4 ALGORITHMS
In this section, we propose our FairKnapStream algorithm (i.e.,
Algorithm 2, introduced in Sec. 4.2) for the FSK problem, which
invokes two key procedures FairStream (i.e., Algorithm 1, intro-
duced in Sec. 4.1 and MatKnapStream (i.e., Algorithm 3, introduced
in Sec. 4.3). As explained in Sec. 1.1, FairStream creates a scalable
and fair â€œreserved datasetâ€, which forms part of our final solution
to ensure that the (relaxed) fairness lower bounds are satisfied,
while MatKnapStream generates a set satisfying both the knapsack
constraint and the fairness upper bounds. Our main algorithm FairK-
napStream for the FSK problem manages to combine the datasets
output by FairStream andMatKnapStream together to generate
the final solution with a provable performance ratio.
4.1 The FairStream Algorithm
In this section, we introduce the procedure FairStream, as shown
by Algorithm 1. Algorithm 1 reads the data stream in a single pass
and performs the following operations: for each ğ‘¡âˆˆ[â„], it picks
â„“ğ‘¡elements with the lowest costs, and then adds these elements
into a setğ¿. Obviously, ğ¿is the one with the lowest cost and the
least number of elements among all feasible solutions to the FSK
problem. Then, Algorithm 1 samples the feasible set ğ¿to construct
two disjoint sets ğ¿1andğ¿2in a balanced way, i.e., âˆ€ğ‘¡âˆˆ[â„]:|ğ¿1âˆ©
Nğ‘¡|=|ğ¿2âˆ©Nğ‘¡|=âŒŠâ„“ğ‘¡/2âŒ‹.
516KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
Algorithm 1: FairStream
1ğ´ğ‘¡â†âˆ… for eachğ‘¡âˆˆ[â„];
2while there is an incoming element ğ‘’do
3 if|ğ´ğ‘”(ğ‘’)|<â„“ğ‘¡then
4ğ´ğ‘”(ğ‘’)â†ğ´ğ‘”(ğ‘’)âˆª{ğ‘’}
5 else
6 ifğ‘(ğ‘’)<maxğ‘âˆˆğ´ğ‘”(ğ‘’)ğ‘(ğ‘)then
7 Addğ‘’toğ´ğ‘”(ğ‘’)and then pop the element ğ‘with
the largest value of ğ‘(ğ‘)inğ´ğ‘”(ğ‘’);
8ğ¿â†Ã
ğ‘¡âˆˆ[â„]ğ´ğ‘¡;ğ¿1â†âˆ…;ğ¿2â†âˆ…;
9foreachğ‘¡âˆˆ[â„]do
10 Randomly select 2âŒŠâ„“ğ‘¡/2âŒ‹elements from ğ¿âˆ©Nğ‘¡and
divide them evenly into ğ¿1andğ¿2;
11returnğ¿1,ğ¿2;
The purpose of generating ğ¿1orğ¿2is to insert them into some
candidate solutions generated by MatKnapStream (introduced in
Sec. 4.3) to ensure that the (relaxed) fairness lower bounds are sat-
isfied. Note that ğ¿1orğ¿2does not have any performance guarantee
on the objective function value. In fact, they are generated in a way
to ensure that the total cost of the elements in them is as small
as possible, such that we have sufficient leftover budget to call
MatKnapStream to get some candidate solutions with good perfor-
mance ratios. However, since MatKnapStream cannot use the total
budget, we need to carefully analyze the quantitative relationships
betweenğ‘‚,ğ¿1,ğ¿2(as done by Lemmas 4.1-4.2) to ensure that the
objective function values of the candidate solutions generated by
MatKnapStream are comparable to that of the optimal solution ğ‘‚,
which uses the total budget. So we introduce Lemmas 4.1-4.2 in the
sequel:
Lemma 4.1. The setğ¿generated in Line 8 of Algorithm 1 satisfies:
â€¢For anyğ‘¡âˆˆ[â„], we have|ğ‘‚âˆ©Nğ‘¡|â‰¥|ğ¿âˆ©Nğ‘¡|andğ‘(ğ‘‚âˆ©Nğ‘¡)â‰¥
ğ‘(ğ¿âˆ©Nğ‘¡), which means
|(ğ‘‚\ğ¿)âˆ©Nğ‘¡|â‰¥|(ğ¿\ğ‘‚)âˆ©Nğ‘¡|and
ğ‘((ğ‘‚\ğ¿)âˆ©Nğ‘¡)â‰¥ğ‘((ğ¿\ğ‘‚)âˆ©Nğ‘¡). (1)
â€¢For anyğ‘¡âˆˆ[â„], we have
âˆ€ğ‘’âˆˆ(ğ‘‚\ğ¿)âˆ©Nğ‘¡,ğ‘£âˆˆğ¿âˆ©Nğ‘¡:ğ‘(ğ‘’)â‰¥ğ‘(ğ‘£) (2)
Lemma 4.2. We can divide the set ğ‘‚\(ğ¿1âˆªğ¿2)into two disjoint
setğ‘‚1andğ‘‚2such that
â€¢ğ‘(ğ‘‚2âˆª(ğ‘‚âˆ©ğ¿1))â‰¤ğµâˆ’ğ‘(ğ¿2)
â€¢ğ‘(ğ‘‚1âˆª(ğ‘‚âˆ©ğ¿2))â‰¤ğµâˆ’ğ‘(ğ¿1)
Proof. Due to Eqn (1), we can get a subset ğ‘‚2âŠ†ğ‘‚\(ğ¿1âˆªğ¿2)
such thatâˆ€ğ‘¡âˆˆ[â„]:|ğ‘‚2âˆ©Nğ‘¡|=|(ğ¿1\ğ‘‚)âˆ©Nğ‘¡|. Letğ‘‚1=(ğ‘‚\
(ğ¿1âˆªğ¿2))\ğ‘‚2, then for any ğ‘¡âˆˆ[â„], we have
|ğ‘‚1âˆ©Nğ‘¡|=|(ğ‘‚\(ğ¿1âˆªğ¿2))âˆ©Nğ‘¡|âˆ’|ğ‘‚2âˆ©Nğ‘¡|
=|(ğ‘‚\(ğ¿1âˆªğ¿2))âˆ©Nğ‘¡|âˆ’|(ğ¿1\ğ‘‚)âˆ©Nğ‘¡|
â‰¥|((ğ¿1âˆªğ¿2)\ğ‘‚)âˆ©Nğ‘¡|âˆ’|(ğ¿1\ğ‘‚)âˆ©Nğ‘¡|=|(ğ¿2\ğ‘‚)âˆ©Nğ‘¡|Algorithm 2: FairKnapStream
1ğ¿1,ğ¿2â†FairStream();
2forğ‘¥=1,2in parallel do
3ğ‘‡ğ‘¥â†MatKnapStream(ğµâˆ’ğ‘(ğ¿ğ‘¥));
4forğ‘¥=1,2do
5ğ‘‡â€²ğ‘¥â†ğ‘‡ğ‘¥;
6 forğ‘’âˆˆğ¿ğ‘¥do
7 if|ğ‘‡â€²ğ‘¥âˆ©Nğ‘”(ğ‘’)|<ğ‘¢ğ‘”(ğ‘’)then
8 ğ‘‡â€²ğ‘¥â†ğ‘‡â€²ğ‘¥âˆª{ğ‘’};
9ğ‘‡â€²â€²ğ‘¥â†ğ‘‡â€²ğ‘¥;
10 forğ‘’âˆˆğ¿ğ‘¥mod 2+1do
11 if|ğ‘‡â€²â€²ğ‘¥âˆ©Nğ‘”(ğ‘’)|<â„“ğ‘”(ğ‘’)âˆ§ğ‘(ğ‘‡â€²â€²ğ‘¥âˆª{ğ‘’})<ğµthen
12 ifğ‘“(ğ‘’|ğ‘‡â€²â€²ğ‘¥)â‰¥0thenğ‘‡â€²â€²ğ‘¥â†ğ‘‡â€²â€²ğ‘¥âˆª{ğ‘’};
13returnğ‘‡âˆ—â†arg maxğ´âˆˆ{ğ‘‡â€²â€²
1,ğ‘‡â€²â€²
2,ğ¿1âˆªğ¿2}ğ‘“(ğ´)
Combining the above with Eqn (2), we get for every ğ‘¡âˆˆ[â„]
ğ‘(ğ‘‚1âˆ©Nğ‘¡)â‰¥ğ‘((ğ¿2\ğ‘‚)âˆ©Nğ‘¡)and
ğ‘(ğ‘‚2âˆ©Nğ‘¡)â‰¥ğ‘((ğ¿1\ğ‘‚)âˆ©Nğ‘¡),
which implies ğ‘(ğ‘‚1)â‰¥ğ‘(ğ¿2\ğ‘‚)andğ‘(ğ‘‚2)â‰¥ğ‘(ğ¿1\ğ‘‚).
Then we can derive
ğµâ‰¥ğ‘(ğ‘‚)=ğ‘(ğ‘‚\(ğ¿1âˆªğ¿2))+ğ‘(ğ‘‚âˆ©(ğ¿1âˆªğ¿2))
=ğ‘(ğ‘‚1)+ğ‘(ğ‘‚2)+ğ‘(ğ‘‚âˆ©(ğ¿1âˆªğ¿2))
â‰¥ğ‘(ğ¿2\ğ‘‚)+ğ‘(ğ‘‚2)+ğ‘(ğ‘‚âˆ©(ğ¿1âˆªğ¿2))
=ğ‘(ğ¿2\ğ‘‚)+ğ‘(ğ‘‚2)+ğ‘(ğ‘‚âˆ©ğ¿1)+ğ‘(ğ‘‚âˆ©ğ¿2)
=ğ‘(ğ¿2)+ğ‘(ğ‘‚2âˆª(ğ‘‚âˆ©ğ¿1)).
Similarly, we can derive ğµâˆ’ğ‘(ğ¿1)â‰¥ğ‘(ğ‘‚1âˆª(ğ‘‚âˆ©ğ¿2)).Combining
all above then the lemma follows. â–¡
4.2 The FairKnapStream Algorithm
In this section, we introduce our main algorithm FairKnapStream for
the FSK problem, as shown by Algorithm 2. FairKnapStream first
callFairStream to get two datasets ğ¿1,ğ¿2with small costs (Line 1),
and then call the MatKnapStream procedure using the leftover
budgetğµâˆ’ğ‘(ğ¿ğ‘¥)(ğ‘¥âˆˆ{1,2}) to get two candidate solutions ğ‘‡1and
ğ‘‡2(Lines 2-3). Note that the MatKnapStream procedure can be
any streaming algorithm for the problem of submodular maximiza-
tion subject to a partition matroid and a knapsack constraint (i.e.,
SMK problem) with a provable performance ratio. To maintain flu-
ency, we defer the description of our MatKnapStream algorithm to
Sec. 4.3. Afterwards, for each ğ‘¥âˆˆ{1,2},FairKnapStream inserts as
many elements as possible from ğ¿ğ‘¥intoğ‘‡ğ‘¥to obtain the candidate
solutionğ‘‡â€²ğ‘¥(Lines 4-8), such that ğ‘‡â€²ğ‘¥satisfies the (relaxed) fairness
lower bounds without violating the knapsack constraint.
Technically, the theoretical performance bounds of FairKnap-
Stream can be derived by using ğ‘‡â€²
1andğ‘‡â€²
2. In Lines 10-12, we im-
prove the practical performance of FairKnapStream by inserting
more elements from ğ¿1âˆªğ¿2intoğ‘‡â€²
1andğ‘‡â€²
2without violating the
knapsack constraint and fairness constraint, resulting in two new
candidate solutions ğ‘‡â€²â€²
1andğ‘‡â€²â€²
2. Finally, FairKnapStream returns
the best on among {ğ‘‡â€²â€²
1,ğ‘‡â€²â€²
2,ğ¿1âˆªğ¿2}as the final solution (Line 13).
517Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Thanks to the design of FairStream and Lemma 4.2, we can
prove that the sets ğ‘‡ğ‘¥:ğ‘¥âˆˆ{1,2}generated by MatKnapStream in
Lines 2-3 of FairKnapStream can be used to provide an upper bound
of the objective function value of the optimal solution ğ‘‚, as shown
by the following lemma:
Lemma 4.3. Suppose that MatKnapStream achievesğ›½-approximation
to the SMK problem. For any ğ‘¥âˆˆ{1,2}, we have
â€¢âˆ€ğ‘¡âˆˆ[â„]:|ğ‘‡ğ‘¥âˆ©Nğ‘¡|â‰¤ğ‘¢ğ‘¡,
â€¢ğ‘(ğ‘‡ğ‘¥)â‰¤ğµâˆ’ğ‘(ğ¿ğ‘¥),
â€¢ğ‘“(ğ‘‡1)â‰¥ğ‘“(ğ‘‚1âˆª(ğ‘‚âˆ©ğ¿2))
(1+ğœ–)ğ›½,ğ‘“(ğ‘‡2)â‰¥ğ‘“(ğ‘‚2âˆª(ğ‘‚âˆ©ğ¿1))
(1+ğœ–)ğ›½,
which implies ğ‘“(ğ‘‡1)+ğ‘“(ğ‘‡2)â‰¥ğ‘“(ğ‘‚)
(1+ğœ–)ğ›½.
Proof. The first three properties are immediately derived by
the Lemma 4.2 and the properties of MatKnapStream. Then by
submodularity and the definition of ğ‘‚1andğ‘‚2in Lemma 4.2, we
can get
ğ‘“(ğ‘‡1)+ğ‘“(ğ‘‡2)â‰¥ğ‘“(ğ‘‚1âˆª(ğ‘‚âˆ©ğ¿2)âˆªğ‘‚2âˆª(ğ‘‚âˆ©ğ¿1))
(1+ğœ–)ğ›½
=ğ‘“((ğ‘‚âˆ©(ğ¿1âˆªğ¿2))âˆª(ğ‘‚\(ğ¿1âˆªğ¿2)))
(1+ğœ–)ğ›½=ğ‘“(ğ‘‚)
(1+ğœ–)ğ›½,
which completes the proof. â–¡
Moreover, since all the elements in ğ¿ğ‘¥can be added into ğ‘‡â€²ğ‘¥with-
out violating the knapsack constraint, and ğ¿ğ‘¥satisfies the fairness
lower bounds by a factor of 1/2due to Lines 9-10 of Algorithm 1,
we can get:
Lemma 4.4. For anyğ‘¥âˆˆ{1,2}, we haveğ‘(ğ‘‡â€²ğ‘¥)â‰¤ğµandâˆ€ğ‘¡âˆˆ[â„]:
âŒŠâ„“ğ‘¡/2âŒ‹â‰¤|ğ‘‡â€²ğ‘¥âˆ©Nğ‘¡|â‰¤ğ‘¢ğ‘¡.
For monotone submodular functions, Lemma 4.3 is sufficient to
derive the approximation ratio of FairKnapStream, because we have
max{ğ‘“(ğ‘‡â€²â€²
1),ğ‘“(ğ‘‡â€²â€²
2)}â‰¥ max{ğ‘“(ğ‘‡1),ğ‘“(ğ‘‡2)}due toğ‘‡ğ‘¥âŠ†ğ‘‡â€²â€²ğ‘¥. How-
ever, for non-monotone submodular functions, this may not be true
because inserting the elements from ğ¿1âˆªğ¿2intoğ‘‡ğ‘¥(âˆ€ğ‘¥âˆˆ{1,2})
may decrease the function value of ğ‘‡ğ‘¥. Fortunately, since the ele-
ments inğ¿1âˆªğ¿2are generated by random sampling due to Lines 9-10
ofFairStream, we can prove that adding them into ğ‘‡ğ‘¥(âˆ€ğ‘¥âˆˆ{1,2})
would not cause significant harm to ğ‘“(ğ‘‡ğ‘¥)(shown by Lemmas 4.5-
4.6). Combining these results, we can get the performance bounds
ofFairKnapStream, as shown by Theorem 4.7.
Lemma 4.5 (Buchbinder et al . [12] ).Given a ground set N
and any non-negative submodular function ğ‘§(Â·)defined on 2N, we
haveE[ğ‘§(ğ‘Œ)]â‰¥( 1âˆ’ğ‘)ğ‘§(âˆ…)ifğ‘Œis a random subset of Nsuch that
each element inNappears inğ‘Œwith probability of at most ğ‘(not
necessarily independently).
Lemma 4.6. For anyğ‘¥âˆˆ{1,2}, we haveğ‘“(ğ‘‡â€²ğ‘¥)â‰¥ğ‘“(ğ‘‡ğ‘¥)if the
objective function is monotone and E[ğ‘“(ğ‘‡â€²ğ‘¥)]â‰¥ 1/2Â·ğ‘“(ğ‘‡ğ‘¥)if the
objective function is non-monotone.
Proof. For anyğ‘¥âˆˆ {1,2}, we show that the set ğ‘‡â€²ğ‘¥\ğ‘‡ğ‘¥of
elements added to ğ‘‡â€²ğ‘¥at Lines 4-8 of Algorithm 2 contains each
element ofğ¿with a probability of at most 1/2. By the construction
ofğ¿1andğ¿2at Lines 9-10 of Algorithm 1, we have for any group ğ‘¡
and anyğ‘’âˆˆğ¿âˆ©Nğ‘¡:
Pr(ğ‘’âˆˆ(ğ‘‡â€²
ğ‘¥\ğ‘‡ğ‘¥)âˆ©Nğ‘¡)â‰¤Pr(ğ‘’âˆˆğ¿ğ‘¥âˆ©Nğ‘¡)=1
2Â·2âŒŠâ„“ğ‘¡/2âŒ‹
|ğ¿âˆ©Nğ‘¡|=âŒŠâ„“ğ‘¡/2âŒ‹
â„“ğ‘¡â‰¤1/2.
We define two non-negative submodular functions ğ‘§1andğ‘§2as
follows:ğ‘§ğ‘¥(ğ´)=ğ‘“(ğ´âˆªğ‘‡ğ‘¥)for allğ´âŠ†ğ¿andğ‘¥âˆˆ{1,2}. Then by
applying Lemma 4.5, we can get
E[ğ‘“(ğ‘‡â€²
ğ‘¥)]=E[ğ‘§ğ‘¥(ğ‘‡â€²
ğ‘¥\ğ‘‡ğ‘¥)]â‰¥ 1/2Â·ğ‘§ğ‘¥(âˆ…)=1/2Â·ğ‘“(ğ‘‡ğ‘¥)
if the objective function is non-monotone. When the objective
function is monotone, we can immediately get ğ‘“(ğ‘‡â€²ğ‘¥)â‰¥ğ‘“(ğ‘‡ğ‘¥)due
toğ‘‡ğ‘¥âŠ†ğ‘‡â€²ğ‘¥. The lemma then follows. â–¡
Theorem 4.7. Suppose MatKnapStream achievesğ›½-approximation
to the SMK problem using O(ğ‘˜)oracle queries per element and O(ğ‘˜)
memory consumption. Then FairKnapStream can return a solution ğ‘‡âˆ—
to the FSK problem satisfying: (1) ğ‘“(ğ‘‡âˆ—)â‰¥ğ‘“(ğ‘‚)
2(1+ğœ–)ğ›½(resp.E[ğ‘“(ğ‘‡âˆ—)]â‰¥
ğ‘“(ğ‘‚)
4(1+ğœ–)ğ›½) when the objective function is monotone (resp. non-monotone);
(2)ğ‘(ğ‘‡âˆ—)â‰¤ğµ; and (3)âˆ€ğ‘¡âˆˆ[â„]:âŒŠğ‘™ğ‘¡/2âŒ‹â‰¤|ğ‘‡âˆ—âˆ©Nğ‘¡|â‰¤ğ‘¢ğ‘¡.
To achieve the above bounds, FairKnapStream takes two passes over
the stream, usingO(ğ‘˜)oracle queries per element and O(ğ‘˜)memory.
Proof. We only need to analyze the complexity of FairKnap-
Stream since other parts of the theorem can be directly proven
by combining Lemma 4.4, Lemma 4.6 and the fact that ğ‘“(ğ‘‡â€²ğ‘¥)â‰¤
ğ‘“(ğ‘‡â€²â€²ğ‘¥)â‰¤ğ‘“(ğ‘‡âˆ—).
FairStream algorithm reads one pass over the data stream, uses
O(ğ‘˜)memory, and doesnâ€™t incur any oracle queries. MatKnap-
Stream algorithm reads one pass over the data stream, while using
O(ğ‘˜)oracle queries per element and O(ğ‘˜)memory. Lines 4-12 of
FairKnapStream use at mostO(ğ‘˜)oracle queries andO(ğ‘˜)memory.
Combining all the above, the theorem follows. â–¡
We will show in Sec. 4.3 that ğ›½=1
6(1+ğœ–)(resp.ğ›½=1
(10+4âˆš
2)(1+ğœ–))
for monotone (resp. non-monotone) submodular functions. So we
immediately get:
Corollary 1. For the FSK problem, FairKnapStream can achieve
an approximation ratio of1
12âˆ’ğœ–(resp.1
40+16âˆš
2âˆ’ğœ–) when the objective
function is monotone (resp. non-monotone).
4.3 The MatKnapStream Algorithm
In this section, we present our MatKnapStream algorithm (i.e., Al-
gorithm 3) to address the SMK problem. MatKnapStream takes
as input a parameter ğœâˆˆ [ğ‘“(ğ‘€)
(1+ğœ–)ğœ†ğµ,ğ‘“(ğ‘€)
ğœ†ğµ]to control the cost-
effectiveness ratio (i.e., â€œdensityâ€) of the selected elements, where
ğ‘€denotes an optimal solution to the SMK problem, i.e.,
ğ‘€= arg max
ğ‘(ğ´)â‰¤ğµâˆ§âˆ€ğ‘¡âˆˆ[â„]:|ğ´âˆ©Nğ‘¡|â‰¤ğ‘¢ğ‘¡ğ‘“(ğ´),
andğœ†is a constant to be determined later. This implies that we
assume that ğ‘“(ğ‘€)is known. This assumption can be easily removed
using a geometric search trick, as explained in Appendix B.
Suppose that the elements in the stream are {ğ‘’1,ğ‘’2,Â·Â·Â·,ğ‘’ğ‘›}
(listed according to their arriving order). MatKnapStream main-
tains|ğ‘„|candidate solutions {ğ‘†ğ‘–,ğ‘¥:ğ‘¥âˆˆğ‘„}for each incoming
elementğ‘’ğ‘–, whereğ‘„={1}(resp.ğ‘„={1,2}) for monotone (resp.
non-monotone) submodular functions. When an element ğ‘’ğ‘–in the
stream arrives, we try to identify a subset ğ¼ofğ‘„such that it is
possible to add ğ‘’ğ‘–intoğ‘†ğ‘–âˆ’1,ğ‘¥:ğ‘¥âˆˆğ¼to increase its function value
518KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
Algorithm 3: MatKnapStream (with pre-access to ğœ)
Input: thresholdğœâˆˆ[ğ‘“(ğ‘€)
(1+ğœ–)ğœ†ğµ,ğ‘“(ğ‘€)
ğœ†ğµ]and number ğ›¼>1
1ifğ‘“(Â·)is monotone thenğ‘„={1};
2elseğ‘„={1,2};
3ğ‘†0,ğ‘¥â†âˆ… for eachğ‘¥âˆˆğ‘„;ğ‘’âˆ—â†null;
4while there is an incoming element ğ‘’ğ‘–do
5 ifğ‘¢ğ‘”(ğ‘’ğ‘–)>0âˆ§ğ‘“({ğ‘’ğ‘–})>ğ‘“({ğ‘’âˆ—})then
6ğ‘’âˆ—â†ğ‘’ğ‘–;
7ğ¼â†âˆ…;ğ‘†ğ‘–,ğ‘¥â†ğ‘†ğ‘–âˆ’1,ğ‘¥andğ¸ğ‘¥â†null for each ğ‘¥âˆˆğ‘„;
8 forğ‘¥âˆˆğ‘„do
9 ifğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥)â‰¥ğœÂ·ğ‘(ğ‘’ğ‘–)then
10 if|ğ‘†ğ‘–âˆ’1,ğ‘¥âˆ©Nğ‘”(ğ‘’ğ‘–)|<ğ‘¢ğ‘”(ğ‘’ğ‘–)then
11 ifğ‘(ğ‘†ğ‘–âˆ’1,ğ‘¥âˆª{ğ‘’ğ‘–})â‰¤ğµthen
12 ğ¼â†ğ¼âˆª{ğ‘¥};ğ¸ğ‘¥=true
13 else
14 ğ‘£ğ‘–,ğ‘¥â†arg minğ‘’âˆˆğ‘†ğ‘–âˆ’1,ğ‘¥âˆ©Nğ‘”(ğ‘’ğ‘–)ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘–âˆ’1,ğ‘¥);
15 ifğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥)â‰¥ğ›¼Â·ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†<ğ‘£ğ‘–,ğ‘¥
ğ‘–âˆ’1,ğ‘¥)then
16 ifğ‘(ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥}âˆª{ğ‘’ğ‘–})â‰¤ğµthen
17 ğ¼â†ğ¼âˆª{ğ‘¥};ğ¸ğ‘¥=false
18ğ‘¥âˆ—â†arg maxğ‘¥âˆˆğ¼ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥);
19 ifğ¸ğ‘¥âˆ—=truethenğ‘†ğ‘–,ğ‘¥âˆ—â†ğ‘†ğ‘–âˆ’1,ğ‘¥âˆ—âˆª{ğ‘’ğ‘–};
20 elseğ‘†ğ‘–,ğ‘¥âˆ—â†ğ‘†ğ‘–âˆ’1,ğ‘¥âˆ—\{ğ‘£ğ‘–,ğ‘¥âˆ—}âˆª{ğ‘’ğ‘–};
21returnğ‘†âˆ—â†arg maxğ´âˆˆ{ğ‘†ğ‘›,1,ğ‘†ğ‘›,2,ğ‘’âˆ—}ğ‘“(ğ´);
without violating any constraint. Specifically, we decide whether
ğ‘¥âˆˆğ¼for eachğ‘¥âˆˆğ‘„according to the following cases:
(1)If the density of ğ‘’ğ‘–is poor (i.e., ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥)/ğ‘(ğ‘’ğ‘–)<ğœ, then
ğ‘¥âˆ‰ğ¼(Line 9).
(2)Ifğ‘†ğ‘–âˆ’1,ğ‘¥âˆª{ğ‘’ğ‘–}does not violate any constraint, then ğ‘¥âˆˆğ¼
(Lines 10-12).
(3)Ifğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥}âˆª{ğ‘’ğ‘–}does not violate any constraint, where
ğ‘£ğ‘–,ğ‘¥is the element in ğ‘†ğ‘–âˆ’1,ğ‘¥with the minimum marginal gain,
and addingğ‘’ğ‘–intoğ‘†ğ‘–âˆ’1,ğ‘¥can bring a marginal gain being at
leastğ›¼times of that of ğ‘£ğ‘–,ğ‘¥, thenğ‘¥âˆˆğ¼(Lines 14-17).
After identifying ğ¼,MatKnapStream greedily picks ğ‘¥âˆ—âˆˆğ¼(Line 18)
and then add ğ‘’ğ‘–intoğ‘†ğ‘–âˆ’1,ğ‘¥to generate ğ‘†ğ‘–,ğ‘¥. For Case (3) described
above,ğ‘£ğ‘–,ğ‘¥is also deleted from ğ‘†ğ‘–,ğ‘¥as an â€œexchangeâ€ of ğ‘’ğ‘–. After all
theğ‘›elements in the stream are processed using the above process,
MatKnapStream returns the best one among {{ğ‘’âˆ—},ğ‘†ğ‘›,ğ‘¥:ğ‘¥âˆˆğ‘„}
as the final solution, where ğ‘’âˆ—is the singleton element with the
maximum function value (Line 21).
Next, we analyze the performance of MatKnapStream. We will
first provide the performance analysis for non-monotone submod-
ular functions and defer the analysis for monotone submodular
functions to Sec. 4.3.3, because the latter is simpler. For clarity, we
divide our main performance analysis into two distinct cases, as
shown by Sec. 4.3.1 and Sec. 4.3.2, respectively.
In our performance analysis, we use ğ‘†<ğ‘’ğ‘—
ğ‘–,ğ‘¥to denote the ele-
ments inğ‘†ğ‘–,ğ‘¥that arrived in the stream before ğ‘’ğ‘—, i.e.,ğ‘†<ğ‘’ğ‘—
ğ‘–,ğ‘¥=
ğ‘†ğ‘–,ğ‘¥âˆ©{ğ‘’1,Â·Â·Â·,ğ‘’ğ‘—}for anyğ‘–,ğ‘—âˆˆ[ğ‘›]and anyğ‘¥âˆˆğ‘„. So we haveğ‘†<ğ‘’ğ‘—
ğ‘–+1,ğ‘¥âŠ†ğ‘†<ğ‘’ğ‘—
ğ‘–,ğ‘¥because any element removed from ğ‘†ğ‘–,ğ‘¥is never
added back in our algorithm.
4.3.1 Case One: In this case, MatKnapStream never encounters
an element violating the knapsack constraint in Line 11 or Line 16.
Letğ‘ˆ1=Ã
ğ‘–âˆˆ[ğ‘›]ğ‘†ğ‘–,1andğ‘ˆ2=Ã
ğ‘–âˆˆ[ğ‘›]ğ‘†ğ‘–,2. Sinceğ‘ˆ1andğ‘ˆ2are
disjoint, we can use submodularity to get an upper bound on the
objective function value of ğ‘€, i.e.,:
ğ‘“(ğ‘ˆ1âˆªğ‘€)+ğ‘“(ğ‘ˆ2âˆªğ‘€)â‰¥ğ‘“(ğ‘€), (3)
Next, we try to find some upper bounds of ğ‘“(ğ‘ˆğ‘–âˆªğ‘€):ğ‘–âˆˆ{1,2}.
For eachğ‘¥âˆˆ{1,2}, we useğ‘€ğœ,ğ‘¥(resp.ğ‘€ğ‘£,ğ‘¥) to denote the set of
elements in ğ‘€that are ever considered by Line 9 (resp. Line 15)
but failed to pass the test conditions in these lines. Therefore, each
elementğ‘’ğ‘–âˆˆğ‘€\ğ‘ˆ1must belong to one of the following three
categories:
(1)ğ‘’ğ‘–âˆˆğ‘€ğœ,1, i.e.,ğ‘’ğ‘–fails to pass the density test in Line 9. This
implies:
ğ‘“(ğ‘’ğ‘–|ğ‘ˆ1)â‰¤ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,1)<ğœÂ·ğ‘(ğ‘’ğ‘–)
(2)ğ‘’ğ‘–âˆˆğ‘€ğ‘£,1, i.e.,ğ‘’ğ‘–fails to pass the test condition on marginal
gain in Line 15. This implies:
ğ‘“(ğ‘’ğ‘–|ğ‘ˆ1)â‰¤ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,1)<ğ›¼Â·ğ‘“(ğ‘£ğ‘–,1|ğ‘†<ğ‘£ğ‘–,1
ğ‘–âˆ’1,1)
(3)ğ‘’ğ‘–âˆˆğ‘€âˆ©ğ‘ˆ2, i.e.,ğ‘’ğ‘–is included in ğ‘†ğ‘–,1due to the greedy rule
in Line 18. This implies:
ğ‘“(ğ‘’ğ‘–|ğ‘ˆ1)â‰¤ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,1)â‰¤ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,2)
Note that similar reasoning also applies to the elements in ğ‘€\
ğ‘ˆ2. Combining these results, we can derive the upper bounds of
ğ‘“(ğ‘€âˆªğ‘ˆğ‘–):ğ‘–âˆˆ{1,2}as follows:
Lemma 4.8. By submodularity, we have:
ğ‘“(ğ‘€âˆªğ‘ˆ1)â‰¤ğ‘“(ğ‘€ğœ,1|ğ‘ˆ1)+ğ‘“(ğ‘€âˆ©ğ‘ˆ2|ğ‘ˆ1)+ğ‘“(ğ‘€ğ‘£,1|ğ‘ˆ1)+ğ‘“(ğ‘ˆ1)
ğ‘“(ğ‘€âˆªğ‘ˆ2)â‰¤ğ‘“(ğ‘€ğœ,2|ğ‘ˆ2)+ğ‘“(ğ‘€âˆ©ğ‘ˆ1|ğ‘ˆ2)+ğ‘“(ğ‘€ğ‘£,2|ğ‘ˆ2)+ğ‘“(ğ‘ˆ2)
Now we proceed to bound the additive factors in the R.H.S. of
the above equations. First, using the fact that each element in ğ‘€ğœ,ğ‘¥
has a density less than ğœâˆˆ[ğ‘“(ğ‘€)
(1+ğœ–)ğœ†ğµ,ğ‘“(ğ‘€)
ğœ†ğµ], we can get
Lemma 4.9. For eachğ‘¥âˆˆ{1,2},ğ‘“(ğ‘€ğœ,ğ‘¥|ğ‘ˆğ‘¥)â‰¤ğ‘“(ğ‘€)
ğœ†.
Proof.
ğ‘“(ğ‘€ğœ,ğ‘¥|ğ‘ˆğ‘¥)â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğœ,ğ‘¥ğ‘“(ğ‘’ğ‘–|ğ‘ˆğ‘¥)â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğœ,ğ‘¥ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,)
<âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğœ,ğœÂ·ğ‘(ğ‘’ğ‘–)â‰¤ğœğµ=ğ‘“(ğ‘€)
ğœ†,
where the first and second inequalities are due to submodularity.
â–¡
Next, we try to bound ğ‘“(ğ‘€ğ‘£,ğ‘¥|ğ‘ˆğ‘¥):ğ‘¥âˆˆ {1,2}. According
to submodularity and Line 15 of Algorithm 3, the marginal gain
of any element ğ‘’ğ‘–âˆˆğ‘€ğ‘£,ğ‘¥with respect to ğ‘ˆğ‘¥is not much better
thanğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†<ğ‘£ğ‘–,ğ‘¥
ğ‘–âˆ’1,ğ‘¥)(i.e, the marginal gain of ğ‘£ğ‘–,ğ‘¥with respect
toğ‘†ğ‘–âˆ’1,ğ‘¥), whereğ‘£ğ‘–,ğ‘¥is the element with the minimum marginal
gain among all the elements in ğ‘†ğ‘–âˆ’1,ğ‘¥at the moment that ğ‘’ğ‘–arrives.
Moreover, we can prove that the marginal gains of such elements
519Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
ğ‘£ğ‘–,ğ‘¥:ğ‘–âˆˆ[ğ‘›]are non-decreasing when ğ‘–gets larger (as shown by
Lemma 4.10), because they can only be replaced by elements with
larger marginal gains. This implies that the elements in ğ‘†ğ‘›,ğ‘¥have
the largest marginal gains. Meanwhile, we can also prove that ğ‘†ğ‘›,ğ‘¥
has more elements than ğ‘€ğ‘£,ğ‘¥for each group ğ‘¡âˆˆ[â„](as shown by
Lemma 4.11). Based on all these results and submodularity, we can
useğ‘“(ğ‘†ğ‘›,ğ‘¥)to boundğ‘“(ğ‘€ğ‘£,ğ‘¥|ğ‘ˆğ‘¥), as shown by Lemma 4.12.
Lemma 4.10. For anyğ‘¡âˆˆ [â„]andğ‘¥âˆˆ {1,2}, we must have
minğ‘’âˆˆğ‘†ğ‘–,ğ‘¥âˆ©Nğ‘¡ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘–,ğ‘¥)is non-decreasing as ğ‘–âˆˆ[ğ‘›]increases.
Proof. Recall thatğ‘†<ğ‘’ğ‘—
ğ‘–,ğ‘¥=ğ‘†ğ‘–âˆ©{ğ‘’1,ğ‘’2,Â·Â·Â·,ğ‘’ğ‘—âˆ’1}for anyğ‘’ğ‘—âˆˆ
ğ‘†ğ‘–(ğ‘–,ğ‘—âˆˆ[ğ‘›])andğ‘¥âˆˆ{1,2}. Then, it follows that ğ‘†<ğ‘’ğ‘—
ğ‘–+1,ğ‘¥âŠ†ğ‘†<ğ‘’ğ‘—
ğ‘–,ğ‘¥
since any element ğ‘’âˆˆ{ğ‘’1,ğ‘’2,Â·Â·Â·,ğ‘’ğ‘—âˆ’1}(i.e., an element already
arrived) can only be removed from the candidate solution with the
increasing of ğ‘–according to Line 20 of Algorithm 3. Therefore, by
submodularity, ğ‘“(ğ‘’ğ‘—|ğ‘†<ğ‘’ğ‘—
ğ‘–,ğ‘¥)must be non-decreasing as ğ‘–âˆˆ [ğ‘›]
increases.
Moreover, we note that the newly added element ğ‘’ğ‘–to the candi-
date solution satisfies the condition ğ‘“(ğ‘’ğ‘–|ğ‘†<ğ‘’ğ‘–
ğ‘–,ğ‘¥)=ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥)â‰¥
ğ›¼Â·minğ‘’âˆˆğ‘†ğ‘–âˆ’1,ğ‘¥âˆ©Nğ‘”(ğ‘’ğ‘–)ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘–âˆ’1,ğ‘¥)whereğ›¼>1.
Combining all of the above, the lemma follows. â–¡
Lemma 4.11. For anyğ‘¡âˆˆ[â„]andğ‘¥âˆˆ{1,2}, we have|ğ‘€ğ‘£,ğ‘¥âˆ©
Nğ‘¡|â‰¤|ğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡|.
Proof. Consider a fixed ğ‘¡âˆˆ[â„]andğ‘¥âˆˆ{1,2}. If|ğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡|=ğ‘¢ğ‘¡,
the lemma follows, as |ğ‘€âˆ©Nğ‘¡| â‰¤ğ‘¢ğ‘¡. Otherwise, Line 15 has
never been executed for such ğ‘¡andğ‘¥due to Line 10, implying
ğ‘€ğ‘£,ğ‘¥âˆ©Nğ‘¡=âˆ…. Combining all of the above, the lemma follows. â–¡
Lemma 4.12. For anyğ‘¥âˆˆ{1,2}, we haveğ‘“(ğ‘€ğ‘£,ğ‘¥|ğ‘ˆğ‘¥)â‰¤ğ›¼Â·
ğ‘“(ğ‘†ğ‘›,ğ‘¥).
Proof. By applying submodularity and the definition of ğ‘€ğ‘£,ğ‘¥,
we can conclude
ğ‘“(ğ‘€ğ‘£,ğ‘¥|ğ‘ˆğ‘¥)â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğ‘£,ğ‘¥ğ‘“(ğ‘’ğ‘–|ğ‘ˆğ‘¥)â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğ‘£,ğ‘¥ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥)
<âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğ‘£,ğ‘¥ğ›¼Â·ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†<ğ‘£ğ‘–,ğ‘¥
ğ‘–âˆ’1,ğ‘¥)
=ğ›¼âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğ‘£,ğ‘¥min
ğ‘’âˆˆğ‘†ğ‘–âˆ’1,ğ‘¥âˆ©Nğ‘”(ğ‘’ğ‘–)ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘–âˆ’1,ğ‘¥)
â‰¤ğ›¼âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğ‘£,ğ‘¥min
ğ‘’âˆˆğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘”(ğ‘’ğ‘–)ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘›,ğ‘¥)
=ğ›¼âˆ‘ï¸
ğ‘¡âˆˆ[â„]âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğ‘£,ğ‘¥âˆ©Nğ‘¡min
ğ‘’âˆˆğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘”(ğ‘’ğ‘–)ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘›,ğ‘¥)
=ğ›¼âˆ‘ï¸
ğ‘¡âˆˆ[â„]âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€ğ‘£,ğ‘¥âˆ©Nğ‘¡min
ğ‘’âˆˆğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘›,ğ‘¥)
=ğ›¼âˆ‘ï¸
ğ‘¡âˆˆ[â„]|ğ‘€ğ‘£,ğ‘¥âˆ©Nğ‘¡|min
ğ‘’âˆˆğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘›,ğ‘¥),
whereğ‘£ğ‘–,ğ‘¥is defined at Line 14 of Algorithm 3; the last inequality
is due to Lemma 4.10. By applying Lemma 4.11, we can get
âˆ‘ï¸
ğ‘¡âˆˆ[â„]|ğ‘€ğ‘£,ğ‘¥âˆ©Nğ‘¡|min
ğ‘’âˆˆğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘›,ğ‘¥)â‰¤âˆ‘ï¸
ğ‘¡âˆˆ[â„]|ğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡|min
ğ‘’âˆˆğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡ğ‘“(ğ‘’|ğ‘†<ğ‘’
ğ‘›,ğ‘¥)
=âˆ‘ï¸
ğ‘¡âˆˆ[â„]âˆ‘ï¸
ğ‘’â€²âˆˆğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡min
ğ‘’âˆˆğ‘†ğ‘›âˆ©Nğ‘¡ğ‘“(ğ‘¢|ğ‘†<ğ‘’
ğ‘›,ğ‘¥)
â‰¤âˆ‘ï¸
ğ‘¡âˆˆ[â„]âˆ‘ï¸
ğ‘’â€²âˆˆğ‘†ğ‘›,ğ‘¥âˆ©Nğ‘¡ğ‘“(ğ‘’â€²|ğ‘†<ğ‘’â€²
ğ‘›,ğ‘¥)=ğ‘“(ğ‘†ğ‘›,ğ‘¥).
Combining all of the above, the lemma follows. â–¡
Next, we try to use ğ‘“(ğ‘†ğ‘›,ğ‘¥)to boundğ‘“(ğ‘ˆğ‘¥)for eachğ‘¥âˆˆ{1,2}.
According to Lines 14-20 of Algorithm 3, any element ğ‘£ğ‘–,ğ‘¥inğ‘ˆğ‘¥\ğ‘†ğ‘›,ğ‘¥
must have a marginal gain at least ğ›¼times smaller than that of ğ‘’ğ‘–
with respect to ğ‘†ğ‘¥
ğ‘–âˆ’1. Therefore, the utility loss of dropping ğ‘£ğ‘–,ğ‘¥can
be well compensated by the utility gain of adding ğ‘’ğ‘–(as shown by
Lemma 4.13). With this result, we can use submodularity to provide
an upper bound of ğ‘“(ğ‘ˆğ‘¥)(as shown by Lemma 4.14).
Lemma 4.13. For any element ğ‘£ğ‘–,ğ‘¥removed from ğ‘†ğ‘–,ğ‘¥by Algorithm
3, we haveğ‘“(ğ‘†ğ‘–,ğ‘¥)âˆ’ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥)â‰¥(ğ›¼âˆ’1)ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†<ğ‘£ğ‘–,ğ‘¥
ğ‘–âˆ’1,ğ‘¥)â‰¥0.
Lemma 4.14. For anyğ‘¥âˆˆ{1,2}, we haveğ‘“(ğ‘ˆğ‘¥)â‰¤ğ›¼
ğ›¼âˆ’1Â·ğ‘“(ğ‘†ğ‘›,ğ‘¥).
Finally, we can use ğ‘†ğ‘›,ğ‘¥to boundğ‘“(ğ‘€âˆ©ğ‘ˆğ‘¥|ğ‘ˆğ‘§)based on the
greedy rule in Line 18 of Algorithm 3, and get
Lemma 4.15. For anyğ‘¥,ğ‘§âˆˆ{1,2}andğ‘¥â‰ ğ‘§, we haveğ‘“(ğ‘€âˆ©ğ‘ˆğ‘¥|
ğ‘ˆğ‘§)â‰¤ğ‘“(ğ‘†ğ‘›,ğ‘¥)
ğ›¼âˆ’1+ğ‘“(ğ‘†ğ‘›,ğ‘¥)andğ‘“(ğ‘€âˆ©ğ‘ˆğ‘§|ğ‘ˆğ‘¥)â‰¤ğ‘“(ğ‘†ğ‘›,ğ‘§)
ğ›¼âˆ’1+ğ‘“(ğ‘†ğ‘›,ğ‘§).
By combining the above lemmas, we immediately get the ap-
proximation ratio of MatKnapStream under case one:
Lemma 4.16. When case one happens, the solution ğ‘†âˆ—returned by
Algorithm 3 satisfies (1âˆ’2
ğœ†)ğ‘“(ğ‘€)â‰¤2ğ›¼2+2ğ›¼
ğ›¼âˆ’1ğ‘“(ğ‘†âˆ—).
4.3.2 Case Two: In this case, MatKnapStream must encounter an
element violating the knapsack constraint in Line 11 or Line 16.
In this case, we can easily get the quantitative relationship be-
tweenğ‘€andğ‘†âˆ—as follows:
Lemma 4.17. If some element ğ‘’ğ‘¡fails to pass the test condition in
Line 11 or Line 16 of Algorithm 3 for certain ğ‘†ğ‘¡âˆ’1,ğ‘¥(ğ‘¥âˆˆ{1,2}), then
the solution ğ‘†âˆ—returned by Algorithm 3 satisfies ğ‘“(ğ‘†âˆ—)â‰¥ğ‘“(ğ‘€)
2(1+ğœ–)ğœ†.
Proof. We have
ğ‘“(ğ‘†ğ‘¡âˆ’1,ğ‘¥)+ğ‘“(ğ‘’ğ‘¡)=âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘†ğ‘¡âˆ’1,ğ‘¥ğ‘“(ğ‘’ğ‘–|ğ‘†<ğ‘’ğ‘–
ğ‘¡âˆ’1,ğ‘¥)+ğ‘“(ğ‘’ğ‘¡)
â‰¥âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘†ğ‘–âˆ’1,ğ‘¥ğ‘“(ğ‘’ğ‘–|ğ‘†<ğ‘’ğ‘–
ğ‘–âˆ’1,ğ‘¥)+ğ‘“(ğ‘’ğ‘¡)=âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘†ğ‘¡âˆ’1,ğ‘¥ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥)+ğ‘“(ğ‘’ğ‘¡)
â‰¥âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘†ğ‘¡âˆ’1,ğ‘¥ğœÂ·ğ‘(ğ‘’ğ‘–)+ğœÂ·ğ‘(ğ‘’ğ‘¡)=ğœâˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘†ğ‘¡âˆ’1,ğ‘¥âˆª{ğ‘’ğ‘¡}ğ‘(ğ‘’ğ‘–)
>ğœğµ=ğ‘“(ğ‘€)
(1+ğœ–)ğœ†,
where the first inequality is due to submodularity. Then, due to
ğ‘“(ğ‘’ğ‘¡)â‰¤ğ‘“(ğ‘’âˆ—)â‰¤ğ‘“(ğ‘†âˆ—)andğ‘“(ğ‘†ğ‘¡âˆ’1,ğ‘¥)â‰¤ğ‘“(ğ‘†ğ‘¡,ğ‘¥)â‰¤Â·Â·Â·â‰¤ğ‘“(ğ‘†ğ‘›,ğ‘¥)â‰¤
ğ‘“(ğ‘†âˆ—)(as shown by Lemma 4.13), the lemma holds. â–¡
Combining Lemma 4.16 and Lemma 4.17, we can immediately get
the approximation ratio of Algorithm 3, as shown by Theorem 4.18.
Besides, the complexity of our approach is presented in Theorem
4.19.
520KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
Theorem 4.18. By settingğœ†=5+2âˆš
2andğ›¼=1+âˆš
2, Algorithm
3 can achieve an approximation ratio of1
(10+4âˆš
2)(1+ğœ–)â‰¥1
10+4âˆš
2âˆ’ğœ–
for the non-monotone SMK problem.
Theorem 4.19. MatKnapStream takes one pass over the data
stream, usingO(ğ‘˜)oracle queries per element and O(ğ‘˜)memory
consumption.
Proof. For each incoming element, the algorithm incurs at most
O(|ğ‘†ğ‘–âˆ’1,ğ‘¥|)oracle queries according to Line 14 and maintains at
most two candidate solutions. The theorem then follows by using
|ğ‘†ğ‘–âˆ’1,ğ‘¥|â‰¤ğ‘˜. â–¡
4.3.3 Improved Approximation Ratio for Monotone Submodular
Functions. Note that monotone submodular functions are special
cases of the non-monotone ones. So all the performance analysis
described above also applies to monotone submodular functions
and can be further simplified and improved. Therefore, we can get
stronger performance bounds than Lemma 4.16 under case one as
follows:
Lemma 4.20. When the objective function is monotone and case
one happens, the solution ğ‘†âˆ—returned by Algorithm 3 satisfies (1âˆ’
1
ğœ†)ğ‘“(ğ‘€)â‰¤ğ›¼2
ğ›¼âˆ’1ğ‘“(ğ‘†âˆ—).
Under case two, Lemma 4.17 still holds for monotone submodular
functions. Combining Lemma 4.20 and Lemma 4.17, we can get an
improved approximation ratio of MatKnapStream for monotone
submodular functions:
Theorem 4.21. By settingğœ†=3andğ›¼=2, Algorithm 3 can
achieve an approximation ratio of1
6(1+ğœ–)â‰¥1
6âˆ’ğœ–for the monotone
SMK problem.
5 EXPERIMENTS
In this section, we empirically evaluate the performance of our
FairKnapStream algorithm in several real-world applications. To
the best of our knowledge, our FairKnapStream algorithm is the
first to address the FSK problem, and the existing algorithms for fair
submodular maximization cannot output a feasible solution to our
problem. Therefore, we adopt several state-of-the-art streaming
algorithms for submodular maximization with knapsack and/or
ğ‘-system constraints as the baselines, with the purpose of demon-
strating that FairKnapStream can achieve good performance on
utility even compared to these algorithms without fairness consid-
erations. Specifically, our implemented algorithms include:
â€¢FairKnapStream: Our Algorithm 2.
â€¢SmkStream [38]: The state-of-the-art streaming algorithm
for submodular maximization with a knapsack constraint.
â€¢MultiplexGreedy [21]: The state-of-the-art streaming algo-
rithm for submodular maximization with knapsack and ğ‘-
system constraints. By setting ğ‘=1, this algorithm can
partially satisfy the fairness constraint by outputting a solu-
tion satisfying the upper bounds {ğ‘¢ğ‘¡:ğ‘¡âˆˆ[â„]}.
â€¢RandomStream: A simple heuristic that adds each incoming
element into the current solution with a probability of 1/2
without violating the knapsack constraint.We use two metrics in our experiments: (1) Utility (i.e., the objective
function value); and (2) The number of violations of the fairness
constraint, defined as
violation(ğ´)=âˆ‘ï¸
ğ‘¡âˆˆ[â„]max{|ğ´âˆ©Nğ‘¡|âˆ’ğ‘¢ğ‘¡,â„“ğ‘¡âˆ’|ğ´âˆ©Nğ‘¡|,0},
whereğ´is any solution output by the implemented algorithms. Note
that this metric is also adopted by [ 25,26] to measure the degree to
which the fairness constraint is breached. All our experiments are
conducted on a Linux server with Intel Xeon Gold 6126 @ 2.60GHz
CPU and 256GB memory1. For each of the implemented algorithms,
the parameter ğœ–for accuracy (if any) is set to 0.1.
In our experiments, we consider several real-world applications
including movie recommendation, image summarization, and max-
imum coverage in social networks, as elaborated below:
5.1 Movie recommendation
This application has also been considered in previous studies includ-
ing [ 2,6,19,21â€“23,30,31,36,62]. In this application, there is a set
Nof movies, each labeled with a genre, and we aim to recommend
a list of high-quality and diverse movies to a user based on the
ratings from similar users. Each movie ğ‘¢âˆˆN is associated with
a 25-dimensional feature vector ğ‘ğ‘¢calculated from user ratings.
Following [ 1,8,29,30,36,62], we define the utility of any ğ‘†âŠ†N
as a non-monotone submodular function:
ğ‘“(ğ‘†)=âˆ‘ï¸
ğ‘¢âˆˆğ‘†âˆ‘ï¸
ğ‘£âˆˆNğ‘ ğ‘¢,ğ‘£âˆ’âˆ‘ï¸
ğ‘¢âˆˆğ‘†âˆ‘ï¸
ğ‘£âˆˆğ‘†ğ‘ ğ‘¢,ğ‘£,
where we use ğ‘ ğ‘¢,ğ‘£=ğ‘’âˆ’ğœ†dist(ğ‘ğ‘¢,ğ‘ğ‘£)to measure the similarity be-
tween movies ğ‘¢andğ‘£. Following [ 36],dist(ğ‘ğ‘¢,ğ‘ğ‘£)is the Euclidean
distance between ğ‘ğ‘¢andğ‘ğ‘£andğœ†is set to 0.2. The cost ğ‘(ğ‘¢)of
any movieğ‘¢is defined to be proportional to 10âˆ’ğ‘Ÿğ‘¢, whereğ‘Ÿğ‘¢
denotes the rating of movie ğ‘¢(ranging from 0 to 10), and the
costs of all movies are normalized such that the average movie
cost is 2. Thus, movies with higher ratings have smaller costs,
and we requireÃ
ğ‘¢âˆˆğ‘†ğ‘(ğ‘¢) â‰¤ğµto ensure that the movies in ğ‘†
have high ratings. Moreover, we also consider the fairness con-
straint that the number of movies in ğ‘†labeled by each genre ğ‘¡
satisfies the upper bound ğ‘¢ğ‘¡=âŒˆ1.2Â·ğµÂ·|Nğ‘¡|/|N|âŒ‰ and lower bound
â„“ğ‘¡=âŒˆ0.8Â·BudgetÂ·|Nğ‘¡|/|N|âŒ‰ . In the experiments, we use the Movie-
Lens dataset [ 6,36] which contains 1,793 movies from three genres
â€œAdventureâ€, â€œAnimationâ€ and â€œFantasyâ€.
5.2 Image Summarization
This application has also been considered in previous studies includ-
ing [8,23,29,38,62], where the goal is to select a representative set
ğ‘†of images from a ground set N. The objective function is defined
as a monotone submodular function denoting the â€œcoverageâ€ of ğ‘†,
i.e.,
ğ‘“(ğ‘†)=âˆ‘ï¸
ğ‘¢âˆˆNmax
ğ‘£âˆˆğ‘†ğ‘ ğ‘¢,ğ‘£,
whereğ‘ ğ‘¢,ğ‘£is the cosine similarity between image ğ‘¢and image
ğ‘£. Following [ 38,62], the costğ‘(ğ‘¢)of any image ğ‘¢is chosen in
proportional to the standard deviation of its pixel intensities, such
that we assign higher costs to images with higher contrast and
lower costs to blurry images. The costs of all images are normalized
such that the average cost is 2. In addition, we also consider the
1The code is available at: https://github.com/cuilakers/KDD2024-FairKnapStream.
521Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
(a)Movie Recommendation     
  (f) Maximum Coverage in Social Networks10 100Utility
Budget535545555565
10 100Utility
Budget 10 100Utility
Budget
010203040
10 100Fainess Violations
Budget020406080
10 100Fainess Violations
Budget0306090
10 100Fainess Violations
Budget1.2x105
8x104
4x104
03x104
2x104
1x104
0
(b)Image Summarization (c)Maxim um Coverage in Social Networks
(d)Movie Recommendation (e)Image Summarization
Figure 1: Experimental Results
fairness constraint that the number of images in ğ‘†belonging to
any category ğ‘¡satisfies the upper bound ğ‘¢ğ‘¡=âŒˆ1.2Â·ğµÂ·|Nğ‘¡|
|N|âŒ‰and
lower bound â„“ğ‘¡=âŒˆ0.8Â·ğµÂ·|Nğ‘¡|
|N|âŒ‰. Following [ 8,29,38], we randomly
select 600images from the CIFAR-10 dataset [ 52] in the categories
of airplane, automobile or bird to construct N.
5.3 Maximum Coverage in Social Networks
This application has also been considered in previous studies in-
cluding [ 5,19,20,24â€“26,71,79]. Given a social network ğº=(N,ğ¸),
we need to identify a subset of seed nodes ğ‘†âŠ†N that can influence
a large number of users within a budget ğµ, as formulated by
max{ğ‘“(ğ‘†)=|âˆªğ‘¢âˆˆğ‘†ğ‘(ğ‘¢)|:ğ‘(ğ‘†)â‰¤ğµ},
whereğ‘(ğ‘¢)={ğ‘£:(ğ‘¢,ğ‘£)âˆˆğ¸}denotes the neighbors of ğ‘¢andğ‘“(Â·)
is a monotone submodular function. Following [ 39,48], each node
ğ‘¢âˆˆN is associated with a non-negative cost ğ‘({ğ‘¢})=1+âˆšï¸
ğ‘‘(ğ‘¢),
whereğ‘‘(ğ‘¢)represents the out-degree of ğ‘¢, and the costs of all nodes
are normalized such that the average cost is 1. We assume thatNis
partitioned into 5disjoint groupsN1,N2,...,N5according to userâ€™s
properties such as ages and political leanings, and we consider the
fairness constraint that the number of nodes in ğ‘†belonging to any
groupğ‘¡satisfies the upper bound ğ‘¢ğ‘¡=âŒˆ1.2Â·ğµÂ·|Nğ‘¡|
|N|âŒ‰and the
lower bound â„“ğ‘¡=âŒˆ0.8Â·ğµÂ·|Nğ‘¡|
|N|âŒ‰. In our experiments, we use the
Epinions [56] dataset containing 131,828 nodes and 841,372 edges.
5.4 Experimental Results
In Figure 1, we plot the utilities and fairness violations of the im-
plemented algorithms when the budget varies. The utility achieved
by our FairKnapStream algorithm, as depicted in Figure 1 (a)-(c), is
comparable to, and in some cases, even surpasses that of the baselinealgorithms designed for submodular maximization under knapsack
and/orğ‘-system constraints. Meanwhile, as depicted in Figure 1
(d)-(f), our FairKnapStream algorithm consistently adheres to the
fairness constraint (i.e., strictly satisfying all the fairness bounds
{(ğ‘™ğ‘¡,ğ‘¢ğ‘¡):ğ‘¡âˆˆ [â„]}throughout the experiments. In contrast, all
baseline algorithms significantly violate fairness, highlighting their
ineffectiveness in solving the FSK problem. In summary, the exper-
imental results demonstrate that our FairKnapStream algorithm
can ensure fairness without sacrificing performance on utility, com-
pared to the state-of-the-art streaming algorithms for submodular
maximization with knapsack and/or ğ‘-system constraints.
6 CONCLUSION
We have proposed the first streaming algorithm with provable per-
formance bounds for fair submodular maximization subject to a
knapsack constraint, and have also proposed an improved stream-
ing algorithm for submodular maximization subject to a partition
matroid constraint and a knapsack constraint. The superiorities
of our approaches have been demonstrated both theoretically and
experimentally.
ACKNOWLEDGMENTS
Kai Hanâ€™s work is partially supported by the National Natural Sci-
ence Foundation of China (NSFC) under Grant No. 62172384. Feng
Liâ€™s work is supported by NSFC under Grant 62072278, Open Project
of Key Laboratory of Computing Power Network and Information
Security, Ministry of Education, Qilu University of Technology
(Shandong Academy of Sciences) under Grant 2023ZD007. The
work of Shuang Cui is done under the guidance of his supervisor:
Kai Han.
522KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
REFERENCES
[1]Georgios Amanatidis, Federico Fusco, Philip Lazos, Stefano Leonardi, and Rebecca
ReiffenhÃ¤user. 2020. Fast adaptive non-monotone submodular maximization
subject to a knapsack constraint. In Advances in Neural Information Processing
Systems (NeurIPS).
[2]Georgios Amanatidis, Federico Fusco, Philip Lazos, Stefano Leonardi, and Rebecca
ReiffenhÃ¤user. 2022. Fast adaptive non-monotone submodular maximization
subject to a knapsack constraint. Journal of Artificial Intelligence Research (JAIR)
74 (2022), 661â€“690.
[3]Magda Amiridi, Nikos Kargas, and Nicholas D Sidiropoulos. 2021. Information-
theoretic feature selection via tensor decomposition and submodularity. IEEE
Transactions on Signal Processing 69 (2021), 6195â€“6205.
[4]Girija Attigeri, MM Manohara Pai, and Radhika M Pai. 2019. Feature selection us-
ing submodular approach for financial big data. Journal of Information Processing
Systems 15, 6 (2019), 1306â€“1325.
[5]Dmitrii Avdiukhin, Slobodan MitroviÄ‡, Grigory Yaroslavtsev, and Samson Zhou.
2019. Adversarially robust submodular maximization under knapsack constraints.
InACM SIGKDD International Conference on Knowledge Discovery and Data
Mining (KDD). 148â€“156.
[6]Ashwinkumar Badanidiyuru, Amin Karbasi, Ehsan Kazemi, and Jan VondrÃ¡k.
2020. Submodular maximization through barrier functions. In Advances in Neural
Information Processing Systems (NeurIPS).
[7]Ashwinkumar Badanidiyuru and Jan VondrÃ¡k. 2014. Fast algorithms for maxi-
mizing submodular functions. In ACM-SIAM Symposium on Discrete Algorithms
(SODA). 1497â€“1514.
[8]Eric Balkanski, Adam Breuer, and Yaron Singer. 2018. Non-monotone submodular
maximization in exponentially fewer iterations. In Advances in Neural Information
Processing Systems (NeurIPS). 2359â€“2370.
[9]Wei-Xuan Bao, Jun-Yi Hang, and Min-Ling Zhang. 2022. Submodular feature
selection for partial label learning. In ACM Knowledge Discovery and Data Mining
(SIGKDD). 26â€“34.
[10] Xiaohui Bei, Shengxin Liu, Chung Keung Poon, and Hongao Wang. 2022. Candi-
date selections with proportional fairness constraints. Autonomous Agents and
Multi-Agent Systems 36 (2022), 1â€“32.
[11] Robert Bredereck, Piotr Faliszewski, Ayumi Igarashi, Martin Lackner, and Pi-
otr Skowron. 2018. Multiwinner elections with diversity constraints. In AAAI
Conference on Artificial Intelligence (AAAI), Vol. 32.
[12] Niv Buchbinder, Moran Feldman, Joseph Naor, and Roy Schwartz. 2014. Sub-
modular maximization with cardinality constraints. In ACM-SIAM Symposium
on Discrete Algorithms (SODA). 1433â€“1452.
[13] Elisa Celis, Vijay Keswani, Damian Straszak, Amit Deshpande, Tarun Kathuria,
and Nisheeth Vishnoi. 2018. Fair and diverse DPP-based data summarization. In
International Conference on Machine Learning (ICML). 716â€“725.
[14] L Elisa Celis, Lingxiao Huang, and Nisheeth K Vishnoi. 2018. Multiwinner voting
with fairness constraints. In International Joint Conference on Artificial Intelligence
(IJCAI) . 144â€“151.
[15] L Elisa Celis, Damian Straszak, and Nisheeth K Vishnoi. 2018. Ranking with
Fairness Constraints. In International Colloquium on Automata, Languages, and
Programming (ICALP).
[16] Yllias Chali, Moin Tanvee, and Mir Tafseer Nayeem. 2017. Towards abstractive
multi-document summarization using submodular function-based framework,
sentence compression and merging. In International Joint Conference on Natural
Language Processing (IJCNLP). 418â€“424.
[17] Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvitskii. 2017.
Fair clustering through fairlets. In Advances in Neural Information Processing
Systems (NeurIPS), Vol. 30.
[18] Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvtiskii. 2019.
Matroids, matchings, and fairness. In International Conference on Artificial Intelli-
gence and Statistics (AISTATS). 2212â€“2220.
[19] Shuang Cui, Kai Han, and He Huang. 2024. Deletion-Robust Submodular Maxi-
mization with Knapsack Constraints. In AAAI Conference on Artificial Intelligence
(AAAI), Vol. 38. 11695â€“11703.
[20] Shuang Cui, Kai Han, Jing Tang, and He Huang. 2023. Constrained Subset
Selection from Data Streams for Profit Maximization. In International World Wide
Web Conferences (WWW). 1822â€“1831.
[21] Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, and Zhiyu Li. 2022.
Streaming Algorithms for Constrained Submodular Maximization. In Interna-
tional Conference on Measurement and Modeling of Computer Systems (SIGMET-
RICS).
[22] Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, and Aakas Zhiyuli.
2023. Practical parallel algorithms for submodular maximization subject to
a knapsack constraint with nearly optimal adaptivity. In AAAI Conference on
Artificial Intelligence (AAAI), Vol. 37. 7261â€“7269.
[23] Shuang Cui, Kai Han, Tianshuai Zhu, Jing Tang, Benwei Wu, and He Huang.
2021. Randomized Algorithms for Submodular Function Maximization with a
ğ‘˜-System Constraint. In International Conference on Machine Learning (ICML).
2222â€“2232.[24] Paul DÃ¼tting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi-Fard, and Morteza
Zadimoghaddam. 2022. Deletion robust submodular maximization over matroids.
InInternational Conference on Machine Learning (ICML) . 5671â€“5693.
[25] Marwa El Halabi, Federico Fusco, Ashkan Norouzi-Fard, Jakab Tardos, and Jakub
Tarnawski. 2023. Fairness in streaming submodular maximization over a matroid
constraint. In International Conference on Machine Learning (ICML). 9150â€“9171.
[26] Marwa El Halabi, Slobodan MitroviÄ‡, Ashkan Norouzi-Fard, Jakab Tardos, and
Jakub M Tarnawski. 2020. Fairness in streaming submodular maximization:
Algorithms and hardness. In Advances in Neural Information Processing Systems
(NeurIPS) .
[27] Alina Ene and Huy L Nguyen. 2019. A Nearly-Linear Time Algorithm for Sub-
modular Maximization with a Knapsack Constraint. In International Colloquium
on Automata, Languages and Programming (ICALP), Vol. 132. 53.
[28] Salman Fadaei, MohammadAmin Fazli, and MohammadAli Safari. 2011. Maxi-
mizing non-monotone submodular set functions subject to different constraints:
Combined algorithms. Operations Research Letters 39, 6 (2011), 447â€“451.
[29] Matthew Fahrbach, Vahab Mirrokni, and Morteza Zadimoghaddam. 2019. Non-
monotone submodular maximization with nearly optimal adaptivity and query
complexity. In International Conference on Machine Learning (ICML). 1833â€“1842.
[30] Moran Feldman, Christopher Harshaw, and Amin Karbasi. 2017. Greed Is Good:
Near-Optimal Submodular Maximization via Greedy Optimization. In Conference
on Learning Theory (COLT). 758â€“784.
[31] Moran Feldman, Christopher Harshaw, and Amin Karbasi. 2020. Simultane-
ous greedys: A swiss army knife for constrained submodular maximization.
arXiv:2009.13998 (2020).
[32] Moran Feldman, Christopher Harshaw, and Amin Karbasi. 2023. How do you
want your greedy: Simultaneous or repeated? Journal of Machine Learning
Research (JMLR) 24 (2023), 72â€“1.
[33] Till Fluschnik, Piotr Skowron, Mervin Triphaus, and Kai Wilker. 2019. Fair
knapsack. In AAAI Conference on Artificial Intelligence (AAAI), Vol. 33. 1941â€“
1948.
[34] Ashish Goel, Anilesh K Krishnaswamy, Sukolsak Sakshuwong, and Tanja Aita-
murto. 2019. Knapsack voting for participatory budgeting. ACM Transactions on
Economics and Computation (TEAC) 7, 2 (2019), 1â€“27.
[35] Anupam Gupta, Aaron Roth, Grant Schoenebeck, and Kunal Talwar. 2010. Con-
strained non-monotone submodular maximization: Offline and secretary algo-
rithms. In Conference on Web and Internet Economics (WINE). 246â€“257.
[36] Ran Haba, Ehsan Kazemi, Moran Feldman, and Amin Karbasi. 2020. Streaming
Submodular Maximization under a ğ‘˜-Set System Constraint. In International
Conference on Machine Learning (ICML).
[37] Marwa El Halabi, Jakub Tarnawski, Ashkan Norouzi-Fard, and Thuy-Duong
Vuong. 2023. Fairness in Submodular Maximization over a Matroid Constraint.
arXiv preprint arXiv:2312.14299 (2023).
[38] Kai Han, Shuang Cui, Tianshuai Zhu, Enpei Zhang, Benwei Wu, Zhizhuo Yin,
Tong Xu, Shaojie Tang, and He Huang. 2021. Approximation Algorithms for
Submodular Data Summarization with a Knapsack Constraint. In International
Conference on Measurement and Modeling of Computer Systems (SIGMETRICS).
[39] Chris Harshaw, Moran Feldman, Justin Ward, and Amin Karbasi. 2019. Sub-
modular maximization beyond non-negativity: Guarantees, fast algorithms, and
applications. In International Conference on Machine Learning (ICML). 2634â€“2643.
[40] Jason Hartline, Vahab Mirrokni, and Mukund Sundararajan. 2008. Optimal
marketing strategies over social networks. In International World Wide Web
Conferences (WWW). 189â€“198.
[41] D Ellis Hershkowitz, Anson Kahng, Dominik Peters, and Ariel D Procaccia. 2021.
District-fair participatory budgeting. In AAAI Conference on Artificial Intelligence
(AAAI), Vol. 35. 5464â€“5471.
[42] Chien-Chung Huang, Naonori Kakimura, and Yuichi Yoshida. 2020. Streaming
Algorithms for Maximizing Monotone Submodular Functions Under a Knapsack
Constraint. Algorithmica 82 (2020), 1006â€“1032.
[43] Chien-Chung Huang and Naonori Kakimura. 2018. Multi-pass streaming al-
gorithms for monotone submodular function maximization. arXiv preprint
arXiv:1802.06212 (2018).
[44] Chien-Chung Huang and Naonori Kakimura. 2021. Improved streaming al-
gorithms for maximizing monotone submodular functions under a knapsack
constraint. Algorithmica 83, 3 (2021), 879â€“902.
[45] Rishabh Iyer, Ninad Khargonkar, Jeff Bilmes, and Himanshu Asnani. 2021. Gen-
eralized submodular information measures: Theoretical properties, examples,
optimization algorithms, and applications. IEEE Transactions on Information
Theory 68, 2 (2021), 752â€“781.
[46] Pallavi Jain, Krzysztof Sornat, Nimrod Talmon, and Meirav Zehavi. 2021. Par-
ticipatory Budgeting with Project Groups. In International Joint Conference on
Artificial Intelligence (IJCAI). 276â€“282.
[47] Tianyuan Jin, Yu Yang, Renchi Yang, Jieming Shi, Keke Huang, and Xiaokui
Xiao. 2021. Unconstrained submodular maximization with modular costs: Tight
approximation and application to profit maximization. In International Conference
on Very Large Data Bases (VLDB). 1756â€“1768.
[48] Ehsan Kazemi, Shervin Minaee, Moran Feldman, and Amin Karbasi. 2021. Regu-
larized submodular maximization at scale. In International Conference on Machine
523Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Learning (ICML). 5356â€“5366.
[49] David Kempe, Jon Kleinberg, and Ã‰va Tardos. 2003. Maximizing the spread of
influence through a social network. In ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (KDD). 137â€“146.
[50] Samir Khuller, Anna Moss, and Joseph Seffi Naor. 1999. The budgeted maximum
coverage problem. Information Processing Letters (IPL) 70, 1 (1999), 39â€“45.
[51] Andreas Krause and Carlos Guestrin. 2011. Submodularity and its applications
in optimized information gathering. ACM Transactions on Intelligent Systems and
Technology (TIST) 2, 4 (2011), 1â€“20.
[52] Alex Krizhevsky, Geoffrey Hinton, et al .2009. Learning multiple layers of features
from tiny images. (2009).
[53] Alex Kulesza, Ben Taskar, et al .2012. Determinantal point processes for machine
learning. Foundations and Trends in Machine Learning 5, 2â€“3 (2012), 123â€“286.
[54] Ariel Kulik, Hadas Shachnai, and Tami Tamir. 2013. Approximations for mono-
tone and nonmonotone submodular maximization with knapsack constraints.
Mathematics of Operations Research 38, 4 (2013), 729â€“739.
[55] Jon Lee, Vahab S Mirrokni, Viswanath Nagarajan, and Maxim Sviridenko. 2010.
Maximizing nonmonotone submodular functions under matroid or knapsack
constraints. SIAM Journal on Discrete Mathematics (SIDMA) 23, 4 (2010), 2053â€“
2078.
[56] Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network
Dataset Collection. https://snap.stanford.edu/data
[57] Jingxuan Li, Lei Li, and Tao Li. 2011. Mssf: a multi-document summarization
framework based on submodularity. In International Conference on Research on
Development in Information Retrieval (SIGIR). 1247â€“1248.
[58] Jingxuan Li, Lei Li, and Tao Li. 2012. Multi-document summarization via sub-
modularity. Applied Intelligence 37 (2012), 420â€“430.
[59] Hui Lin and Jeff Bilmes. 2011. A class of submodular functions for document
summarization. In Annual Meeting of the Association for Computational Linguistics
(ACL). 510â€“520.
[60] Hui Lin and Jeff Bilmes. 2012. Learning mixtures of submodular shells with
application to document summarization. In Conference on Uncertainty in Artificial
Intelligence (UAI). 479â€“490.
[61] JuliÃ¡n Mestre. 2006. Greedy in approximation algorithms. In European Symposium
on Algorithms. 528â€“539.
[62] Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, and Amin Karbasi. 2016.
Fast constrained submodular maximization: Personalized data summarization. In
International Conference on Machine Learning (ICML). 1358â€“1367.
[63] Baharan Mirzasoleiman, Amin Karbasi, and Andreas Krause. 2017. Deletion-
robust submodular maximization: Data summarization with â€œthe right to be
forgottenâ€. In International Conference on Machine Learning (ICML) . 2449â€“2458.
[64] Slobodan Mitrovic, Ilija Bogunovic, Ashkan Norouzi-Fard, Jakub M Tarnawski,
and Volkan Cevher. 2017. Streaming robust submodular maximization: A par-
titioned thresholding approach. In Advances in Neural Information Processing
Systems (NeurIPS).
[65] Sofia Maria Nikolakaki, Alina Ene, and Evimaria Terzi. 2021. An efficient frame-
work for balancing submodularity and cost. In ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining (SIGKDD). 1256â€“1266.
[66] Deval Patel, Arindam Khan, and Anand Louis. 2021. Group Fairness for Knapsack
Problems. In International Conference on Autonomous Agents and MultiAgent
Systems (AAMAS). 1001â€“1009.
[67] Binghui Peng. 2021. Dynamic influence maximization. In Advances in Neural
Information Processing Systems (NeurIPS), Vol. 34. 10718â€“10731.
[68] Shaojie Tang and Jing Yuan. 2023. Beyond submodularity: a unified framework
of randomized set selection with group fairness constraints. Journal of Combina-
torial Optimization 45, 4 (2023), 102.
[69] Shaojie Tang, Jing Yuan, and Twumasi Mensah-Boateng. 2023. Achieving long-
term fairness in submodular maximization through randomization. arXiv preprint
arXiv:2304.04700 (2023).
[70] Sebastian Tschiatschek, Rishabh K Iyer, Haochen Wei, and Jeff A Bilmes. 2014.
Learning mixtures of submodular functions for image collection summarization.
InAdvances in Neural Information Processing Systems (NeurIPS), Vol. 27.
[71] Yanhao Wang, Francesco Fabbri, and Michael Mathioudakis. 2021. Fair and
representative subset selection from data streams. In International World Wide
Web Conferences (WWW). 1340â€“1350.
[72] Kai Wei, Yuzong Liu, Katrin Kirchhoff, Chris Bartels, and Jeff Bilmes. 2014. Sub-
modular subset selection for large-scale speech training data. In IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP). 3311â€“3315.
[73] Laurence A Wolsey. 1982. Maximising real-valued submodular functions: Primal
and dual heuristics for location problems. Mathematics of Operations Research 7,
3 (1982), 410â€“425.
[74] Keshou Wu, Lei Li, Jingxuan Li, and Tao Li. 2013. Ontology-enriched multi-
document summarization in disaster management using submodular function.
Information Sciences 224 (2013), 118â€“129.
[75] Grigory Yaroslavtsev, Samson Zhou, and Dmitrii Avdiukhin. 2020. â€œbring your
own greedyâ€+ max: Near-optimal 1/2-approximations for submodular knapsack.
InInternational Conference on Artificial Intelligence and Statistics (AISTATS). 3263â€“
3274.[76] Baosheng Yu, Meng Fang, Dacheng Tao, and Jie Yin. 2016. Submodular asymmet-
ric feature selection in cascade object detection. In AAAI Conference on Artificial
Intelligence (AAAI), Vol. 30.
[77] Qilian Yu, Li Xu, and Shuguang Cui. 2018. Streaming algorithms for news and
scientific literature recommendation: Monotone submodular maximization with
ağ‘‘-knapsack constraint. IEEE Access 6 (2018), 53736â€“53747.
[78] Jing Yuan and Shaojie Tang. 2023. Group fairness in non-monotone submodular
maximization. Journal of Combinatorial Optimization 45, 3 (2023), 88.
[79] Guangyi Zhang, Nikolaj Tatti, and Aristides Gionis. 2022. Coresets remem-
bered and items forgotten: submodular maximization with deletions. In IEEE
International Conference on Data Mining (ICDM).
A OMITTED PROOFS
A.1 Proof of Lemma 4.13
Proof. According to Line 14-20 of Algorithm 3, we have
ğ‘“(ğ‘†ğ‘–,ğ‘¥)âˆ’ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥)=ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥}âˆª{ğ‘’ğ‘–})âˆ’ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥)
=ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥})+ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥})âˆ’ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥)
=ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥})âˆ’ ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥)âˆ’ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥})
=ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥})âˆ’ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥})
â‰¥ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥)âˆ’ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥})
â‰¥ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,ğ‘¥)âˆ’ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†<ğ‘£ğ‘–,ğ‘¥
ğ‘–âˆ’1,ğ‘¥)
â‰¥(ğ›¼âˆ’1)ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†<ğ‘£ğ‘–,ğ‘¥
ğ‘–âˆ’1,ğ‘¥)â‰¥0,
where the first and second inequalities are due to submodularity
and the fact that ğ‘†<ğ‘£ğ‘–,ğ‘¥
ğ‘–âˆ’1,ğ‘¥âŠ†ğ‘†ğ‘–âˆ’1,ğ‘¥\{ğ‘£ğ‘–,ğ‘¥}; the last inequality is due
to the fact that the marginal gain of any element previously added
into the candidate solution is non-negative, a consequence of the
positive threshold ğœused in Line 9 of Algorithm 3. â–¡
A.2 Proof of Lemma 4.14
Proof. By applying Lemma 4.13 along with submodularity, we
can derive
ğ‘“(ğ‘ˆğ‘¥)âˆ’ğ‘“(ğ‘†ğ‘›,ğ‘¥)â‰¤âˆ‘ï¸
ğ‘£ğ‘–,ğ‘¥âˆˆğ‘ˆğ‘¥\ğ‘†ğ‘›,ğ‘¥ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†ğ‘›,ğ‘¥)
â‰¤âˆ‘ï¸
ğ‘£ğ‘–,ğ‘¥âˆˆğ‘ˆğ‘¥\ğ‘†ğ‘›,ğ‘¥ğ‘“(ğ‘£ğ‘–,ğ‘¥|ğ‘†<ğ‘£ğ‘–,ğ‘¥
ğ‘–âˆ’1,ğ‘¥)
â‰¤âˆ‘ï¸
ğ‘£ğ‘–,ğ‘¥âˆˆğ‘ˆğ‘¥\ğ‘†ğ‘›,ğ‘¥ğ‘“(ğ‘†ğ‘–,ğ‘¥)âˆ’ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥)
ğ›¼âˆ’1
=âˆ‘ï¸
ğ‘–âˆˆ[ğ‘›]ğ‘“(ğ‘†ğ‘–,ğ‘¥)âˆ’ğ‘“(ğ‘†ğ‘–âˆ’1,ğ‘¥)
ğ›¼âˆ’1
=ğ‘“(ğ‘†ğ‘›,ğ‘¥)âˆ’ğ‘“(ğ‘†0,ğ‘¥)
ğ›¼âˆ’1â‰¤ğ‘“(ğ‘†ğ‘›,ğ‘¥)
ğ›¼âˆ’1(4)
â–¡
A.3 Proof of Lemma 4.15
Proof. For the element ğ‘’ğ‘–âˆˆğ‘€âˆ©ğ‘ˆ2, we must have ğ‘“(ğ‘’ğ‘–|ğ‘ˆ1)â‰¤
ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,1)â‰¤ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,2)due to the greedy rule in Line 18 of
Algorithm 3.
By submodularity, we have
ğ‘“(ğ‘€âˆ©ğ‘ˆ2|ğ‘ˆ1)â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€âˆ©ğ‘ˆ2ğ‘“(ğ‘’ğ‘–|ğ‘ˆ1)
â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€âˆ©ğ‘ˆ2ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,1)â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘€âˆ©ğ‘ˆ2ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,2)
 
524KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng li, and Jun Luo
Algorithm 4: MatKnapStream (without pre-access to ğœ)
Input: numberğœ†>1;
1ğ‘„âˆ—â†âˆ…;
2while there is an incoming element ğ‘’do
3 ifğ‘“({ğ‘’})>ğ‘“(ğ‘„âˆ—)thenğ‘„âˆ—â†{ğ‘’};
4 Î“â†{( 1+ğœ–)ğ‘§:ğ‘§âˆˆZâˆ§ğ‘“(ğ‘„âˆ—)
(1+ğœ–)ğœ†ğµâ‰¤(1+ğœ–)ğ‘§â‰¤ğ‘“(ğ‘’)
ğ‘(ğ‘’)};
5 Delete any existing copy of Algorithm 3 whose
ğœâˆ‰[ğ‘“(ğ‘„âˆ—)
(1+ğœ–)ğœ†ğµ,ğ‘“(ğ‘„âˆ—)];
6 foreachğœâ€²âˆˆÎ“do
7 Create a new copy of Algorithm 3 by setting ğœ=ğœâ€²
if such a copy does not exist;
8 Passğ‘’to the copy of Algorithm 3 get the current
best solution ğ‘„ğœâ€²from the copy;
9 ifğ‘“(ğ‘„ğœâ€²)>ğ‘“(ğ‘„âˆ—)thenğ‘„âˆ—â†ğ‘„ğœâ€²;
10returnğ‘„âˆ—
â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘ˆ2ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,2),
where the last inequality is due to the positive threshold ğœat Line 9
of Algorithm 3. Furthermore, we can use submodularity and Eqn. (4)
to getâˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘ˆ2\ğ‘†ğ‘›,2ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,2)+âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘†ğ‘›,2ğ‘“(ğ‘’ğ‘–|ğ‘†ğ‘–âˆ’1,2)
â‰¤âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘ˆ2\ğ‘†ğ‘›,2ğ‘“(ğ‘’ğ‘–|ğ‘†<ğ‘’ğ‘–
ğ‘–âˆ’1,2)+âˆ‘ï¸
ğ‘’ğ‘–âˆˆğ‘†ğ‘›,2ğ‘“(ğ‘’ğ‘–|ğ‘†<ğ‘’ğ‘–
ğ‘›,2)
â‰¤ğ‘“(ğ‘†ğ‘›,2)
ğ›¼âˆ’1+ğ‘“(ğ‘†ğ‘›,2).
By combining all of the above and applying similar reasoning to
ğ‘“(ğ‘€âˆ©ğ‘ˆ1|ğ‘ˆ2), we can conclude the lemma. â–¡
A.4 Proof of Lemma 4.16
Proof. Combining Lemma 4.8-4.15, we have
ğ‘“(ğ‘€âˆªğ‘ˆ1)â‰¤ğ›¼
ğ›¼âˆ’1ğ‘“(ğ‘†ğ‘›,1)+ğ‘“(ğ‘€)
ğœ†+ğ›¼Â·ğ‘“(ğ‘†ğ‘›,1)+ğ›¼
ğ›¼âˆ’1ğ‘“(ğ‘†ğ‘›,2)
â‰¤ğ›¼2+ğ›¼
ğ›¼âˆ’1ğ‘“(ğ‘†âˆ—)+ğ‘“(ğ‘€)
ğœ†
Similarly, we can derive ğ‘“(ğ‘€âˆªğ‘ˆ2)â‰¤ğ›¼2+ğ›¼
ğ›¼âˆ’1ğ‘“(ğ‘†âˆ—)+ğ‘“(ğ‘€)
ğœ†. Com-
bining these results with Eqn. (3), we finally obtain:
ğ‘“(ğ‘€)â‰¤2ğ›¼2+2ğ›¼
ğ›¼âˆ’1ğ‘“(ğ‘†âˆ—)+2
ğœ†ğ‘“(ğ‘€)The lemma is concluded by rearranging the inequality above. â–¡
A.5 Proof of Lemma 4.20
Proof. Combining Lemma 4.8-4.15 and the fact that ğ‘ˆ2=âˆ…
when the objective function is monotone, we have
ğ‘“(ğ‘€âˆªğ‘ˆ1)â‰¤ğ›¼
ğ›¼âˆ’1ğ‘“(ğ‘†ğ‘›,1)+ğ‘“(ğ‘€)
ğœ†+ğ›¼Â·ğ‘“(ğ‘†ğ‘›,1)
â‰¤ğ›¼2
ğ›¼âˆ’1ğ‘“(ğ‘†âˆ—)+ğ‘“(ğ‘€)
ğœ†.
Since the objective function is monotone, we have ğ‘“(ğ‘€âˆªğ‘ˆ1)â‰¥
ğ‘“(ğ‘€), which competes the proof. â–¡
BMATKNAPSTREAM WITHOUT PRE-ACCESS
TOğœ
Theorem B.1. The solution returned by Algorithm 4 is at least
as good as the solution returned by Algorithm 3 with ğœ=ğœâˆ—, where
ğœâˆ—âˆˆ[ğ‘“(ğ‘€)
(1+ğœ–)ğœ†ğµ,ğ‘“(ğ‘€)
ğœ†ğµ].
Proof. Letâ€™s denote ğ‘£as the first element in the stream that
satisfies the conditionğ‘“({ğ‘£})
ğ‘(ğ‘£)>ğ‘“(ğ‘€)
ğœ†ğµ. The existence of such an
elementğ‘£is guaranteed sinceğ‘“(ğ‘€)
ğ‘(ğ‘€)â‰¥ğ‘“(ğ‘€)
ğµ>ğ‘“(ğ‘€)
ğœ†ğµ, given that
ğœ†>1.
Our first claim is that after processing the arrival of ğ‘£, Algorithm
4 creates a copy of Algorithm 3 using ğœ=ğœâˆ—, and this copy would
not be deleted. This can be explained as follows:
ğœâˆ—â‰¥ğ‘“(ğ‘€)
(1+ğœ–)ğœ†ğµâ‰¥ğ‘“(ğ‘„âˆ—ğ‘£)
(1+ğœ–)ğœ†ğµ,
ğœâˆ—â‰¤ğ‘“(ğ‘€)
ğœ†ğµ<ğ‘“({ğ‘£})
ğ‘(ğ‘£)â‰¤ğ‘“({ğ‘£})â‰¤ğ‘“(ğ‘„âˆ—
ğ‘£),
whereğ‘“(ğ‘„âˆ—ğ‘£)is the value of ğ‘“(ğ‘„âˆ—)after processing ğ‘£. This implies
thatğœâˆ—âˆˆÎ“must be created and the copy with ğœ=ğœâˆ—should not be
deleted by Line 5.
Our second claim is that all elements arriving before ğ‘£are not
eligible to be added to the candidate solutions maintained by the
copy usingğœ=ğœâˆ—. Specifically, for every element ğ‘’arriving before
ğ‘£, we have:
ğ‘“(ğ‘’|ğ‘†)
ğ‘(ğ‘’)â‰¤ğ‘“({ğ‘’})
ğ‘(ğ‘’)<ğ‘“({ğ‘£})
ğ‘(ğ‘£)for anyğ‘†âŠ†N.
Therefore, without meeting the threshold requirement (Line 9 of
Algorithm 3), ğ‘’is discarded by the copy of Algorithm 3 with ğœ=ğœâˆ—.
Combining all the above reasoning, we can conclude that the
solution returned by Algorithm 4 is at least as good as that returned
by Algorithm 3 with ğœ=ğœâˆ—, thus completing the proof. â–¡
 
525