Toward Structure Fairness in Dynamic Graph Embedding: A
Trend-aware Dual Debiasing Approach
Yicong Liâˆ—
The Education University of Hong
Kong
Hong Kong SAR, China
University of Technology Sydney
Australia
lyicong@eduhk.hk
yicong.li@student.uts.edu.auYu Yangâˆ—â€ 
The Hong Kong Polytechnic
University
Hong Kong SAR, China
cs-yu.yang@polyu.edu.hkJiannong Cao
The Hong Kong Polytechnic
University
Hong Kong SAR, China
jiannong.cao@polyu.edu.hk
Shuaiqi Liu
The Hong Kong Polytechnic
University
Hong Kong SAR, China
shuaiqi.liu@connect.polyu.hkHaoran Tang
The Hong Kong Polytechnic
University
Hong Kong SAR, China
haoran.tang@connect.polyu.hkGuandong Xuâ€ 
The Education University of Hong
Kong
Hong Kong SAR, China
University of Technology Sydney
Australia
gdxu@eduhk.hk
guandong.xu@uts.edu.au
ABSTRACT
Recent studies successfully learned static graph embeddings that
are structurally fair by preventing the effectiveness disparity of
high- and low-degree vertex groups in downstream graph mining
tasks. However, achieving structure fairness in dynamic graph em-
bedding remains an open problem. Neglecting degree changes in
dynamic graphs will significantly impair embedding effectiveness
without notably improving structure fairness. This is because the
embedding performance of high-degree and low-to-high-degree
vertices will significantly drop close to the generally poorer em-
bedding performance of most slightly changed vertices in the long-
tail part of the power-law distribution. We first identify biased
structural evolutions in a dynamic graph based on the evolving
trend of vertex degree and then propose FairDGE, the first struc-
turally Fair Dynamic Graph Embedding algorithm. FairDGE learns
biased structural evolutions by jointly embedding the connection
changes among vertices and the long-short-term evolutionary trend
of vertex degrees. Furthermore, a novel dual debiasing approach
is devised to encode fair embeddings contrastively, customizing
debiasing strategies for different biased structural evolutions. This
innovative debiasing strategy breaks the effectiveness bottleneck of
embeddings without notable fairness loss. Extensive experiments
demonstrate that FairDGE achieves simultaneous improvement in
the effectiveness and fairness of embeddings.
âˆ—Having equal contribution with the first author.
â€ Corresponsing authors.
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.3671848CCS CONCEPTS
â€¢Information systems â†’Data mining.
KEYWORDS
Dynamic graph embedding; Structural fairness; Degree fairness;
Debiased learning; Structural evolution
ACM Reference Format:
Yicong Li, Yu Yang, Jiannong Cao, Shuaiqi Liu, Haoran Tang, and Guandong
Xu. 2024. Toward Structure Fairness in Dynamic Graph Embedding: A
Trend-aware Dual Debiasing Approach. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD â€™24),
August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages.
https://doi.org/10.1145/3637528.3671848
1 INTRODUCTION
Graph embedding has achieved great success in many applications,
such as recommendation [ 15], social inference [ 32], risk assessment
[31], etc. Many of these applications are human-centered, where
fairness matters a lot [ 23]. For example, recommending jobs unbi-
asedly, making every demographic have the same opportunities,
ensuring algorithmic credit scoring for lending does not uninten-
tionally favor certain ethnic or age groups, providing equitable
access and connectivity in transportation networks, etc. This drives
the research on fair graph embeddings.
Fair graph embedding aims to learn low-dimension vertex/edge
representations that will not make disparate treatment or impacts
to vertices/edges in downstream graph mining tasks [ 12]. Disparate
treatment, which is direct discrimination, intentionally treats ver-
tices/edges differently based on sensitive attributes [ 2]. Disparate
impact is indirect discrimination, where algorithms perform much
worse on vertices/edges with sensitive attributes and/or connectiv-
ity than on others [2].
 
1701
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yicong Li et al.
Existing works successfully learn fair embeddings for static
graphs. Some studies employed adversarial training [ 7], fairness
regularizations [ 9,10,30], resampling [ 36,50], or graph argumen-
tation [ 47] to make sensitive vertex attributes transparent to the
embeddings, thus eliminating disparate treatment or impacts to
sensitive attributes. Other studies [ 13,17,35,39] learned static
graph embeddings that are structurally fair by preventing the ef-
fectiveness disparity of high- and low-degree vertex groups (i.e.,
disparate impact) in downstream graph mining tasks, given that
vertex degrees of real-world graphs usually follow a long-tailed
power-law distribution [1].
Despite the success of learning fair embeddings for static graphs,
achieving structure fairness in dynamic graph embedding remains
an open problem. Naively re-training the above structurally fair
static graph embedding methods from scratch at each timestamp
fails to deal with the evolving bias caused by structural changes in
dynamic graphs [ 6,14]. As the graph structure evolves, a minority
of lower-degree vertices (Tail) may become higher-degree vertices
(Head) by actively forming edges with other vertices, while most
tail vertices may change slightly. If the model prioritizes fairness
by reducing head and tail verticesâ€™ effectiveness disparity without
considering their evolutionary patterns, the performance of head
and tail-to-head vertices will significantly drop close to generally
poorer embedding performance of most slightly altered vertices in
the long-tail part of the power-law distribution. Such performance
degradation is empirically demonstrated in Section B of the Ap-
pendix. As a result, the effectiveness of learned structurally fair
embeddings in downstream tasks is questionable.
In this paper, we study a critical but overlooked problem of learn-
ing structurally fair dynamic graph embeddings that are highly
effective in downstream graph mining tasks. To achieve this goal,
we are confronted with two major challenges. (1) Learning biased
structural evolution over time. The structural evolution of head
and tail-to-head vertices leaves more linkage-changing information
than fluctuation tail vertices, giving rise to the structure bias in
the embeddings. Such structure bias changes as the graph evolves,
and not all structural evolutions bias embeddings. It is critical to
learn biased structural evolution for later debiasing. (2) Debiasing
properly to achieve fairness without sacrificing or even improv-
ing embedding effectiveness. Debiasing unbiased structural evolu-
tion impairs embedding effectiveness without notably improving
fairness. Structurally fair embedding algorithms should customize
debiasing strategies for different biased structural evolutions such
that the effectiveness of embedding is not greatly sacrificed.
In light of these challenges, we first identify three biased struc-
tural evolutions in a dynamic graph based on the evolutionary trend
of vertex degree, i.e., Fluctuation-at-Tail (FaT), Tail-to-Head (T2H),
andStarting-from-Head (SfH), then innovatively propose FairDGE,
a structurally Fair Dynamic Graph Embedding algorithm. To learn
biased structural evolution over time, FairDGE jointly embeds the
connection changes among vertices and the long-short-term evolu-
tionary trend of vertex degrees by an intermedia training task that
classifies the identified biased structural evolutions. Next, we devise
a dual debiasing approach for FairDGE to encode fair embeddings
that are highly effective in downstream tasks. It first debiases the
embeddings via contrastive learning, bringing closer the embed-
dings with identical biased structural evolutions and penalizingthose with different ones. Thanks to the theoretical proof in [ 39],
the embedding performance of the FaT vertices will be much im-
proved, resulting in a smaller performance gap with T2H and SfH
vertex groups. Meanwhile, we minimize the effectiveness disparity
of embeddings of T2H and SfH vertex groups, which are in the head
of the power-law distribution and with high performance, to boost
fairness further. Consequently, FairDGE breaks the effectiveness
bottleneck of embeddings with almost no fairness loss.
Our contributions are highlighted as follows:
â€¢A new problem. To the best of our knowledge, we are the
first to study the structure fairness problem in dynamic graph
embedding and identify three biased structural evolutions
that are Fluctuation-at-Tail (FaT), Tail-to-Head (T2H), and
Starting-from-Head (SfH).
â€¢A new and effective approach. We propose FairDGE, a
novel dynamic graph embedding algorithm, that learns bi-
ased structural evolutions and then uses a newly devised
dual debiasing method for encoding structurally fair embed-
dings that are highly effective in downstream graph mining
tasks.
â€¢Extensive experiments. The experimental results demon-
strate that FairDGE achieves simultaneous improvement in
the effectiveness and fairness of embeddings.
2 PROBLEM FORMULATION
In this section, we give the definition of dynamic graphs and for-
mulate the problem of structurally fair dynamic graph embedding.
Firstly, we define a dynamic graph as a snapshot graph sequence.
Definition 1. A Dynamic Graph. A dynamic graphG=(V,E)
=(G1,G2,...,Gğ‘‡)is a sequence of directed or undirected snapshot
graphsGğ‘¡, whereGğ‘¡=(Vğ‘¡,Eğ‘¡)is a static graph at time ğ‘¡âˆˆ{1,2,...,ğ‘‡}.
Vğ‘¡is a subset of the vertex set V={ğ‘£1,ğ‘£2,...,ğ‘£|V|}. An edgeğ‘’ğ‘¡
ğ‘–,ğ‘—=
(ğ‘£ğ‘¡
ğ‘–,ğ‘£ğ‘¡
ğ‘—)âˆˆEğ‘¡represents the connection between vertices ğ‘£ğ‘¡
ğ‘–andğ‘£ğ‘¡
ğ‘—in
Gğ‘¡, whereğ‘£ğ‘¡
ğ‘–,ğ‘£ğ‘¡
ğ‘—âˆˆVğ‘¡andEğ‘¡is a subset of the edge set E.
Similar to the existing work [ 7,17,39], we adopt statistical parity
proposed in [ 8] as the fairness metric, as in Definition 2. In other
words, the smaller the intergroup performance disparity, the better
the fairness.
Definition 2. Fairness Metric. Givenğ‘mutually exclusive ver-
tex groups{ğº1,...,ğºğ‘}andğº1Ã...Ãğºğ‘=V, fairness is achieved
whenP(â„ğ‘£|ğ‘£âˆˆğº1)=...=P(â„ğ‘£|ğ‘£âˆˆğºğ‘), whereP(Â·) indicates the
performance of ğ‘£â€™s embedding â„ğ‘£in a downstream task.
Dynamic graph embedding aims to learn low-dimensional rep-
resentations (i.e., embeddings) for every vertex that preserves its
dynamic connectivity changes. The learned embedding should be
highly effective in downstream graph mining tasks such as high
classification accuracy, small regression errors, high hit rate in rec-
ommendation, etc. Achieving structure fairness in dynamic graph
embeddings requires the embeddings learned from different struc-
tural evolution groups to perform similarly in downstream graph
mining tasks. To this end, we give the formal problem formulation
of structurally fair dynamic graph embedding in Definition 3.
 
1702Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Definition 3. Structurally Fair Dynamic Graph Embed-
ding. Given a dynamic graph G=(V,E)=(G1,G2,...,Gğ‘‡), the ver-
texVis divided into ğ‘mutually exclusive vertex groups {ğº1,...,ğºğ‘}
based on their structural evolution patterns, which is, ğº1Ã...Ãğºğ‘=
V. The objective is to learn a mapping function ğ‘“:ğ‘£â†¦â†’â„ğ‘£âˆˆRğ‘‘ğ‘–ğ‘š
forâˆ€ğ‘£âˆˆV such that the representation â„ğ‘£preserves the structural
evolution ofğ‘£in terms of dynamic connectivity changes between ğ‘£and
other vertices inVover time, achieves high performance in down-
stream graph mining tasks, and satisfies the fairness requirement
defined in Definition 2, where ğ‘‘ğ‘–ğ‘š is a positive integer indicating the
dimension of â„ğ‘£.
3 IDENTIFYING BIASED STRUCTURE
EVOLUTIONS OF DYNAMIC GRAPHS
In this section, we introduce intuitions for identifying the biased
structural evolution of dynamic graphs and explain the fairness
implications for dynamic graph embeddings.
The degree of a vertex represents the number of other vertices
connected to it, which indicates its neighborhood structures. As the
graph structure evolves, the connections among vertices change
accordingly, causing verticesâ€™ degrees to vary. Therefore, degree
change is capable of approximating the vertexâ€™s neighborhood
structure evolution over time.
Vertex degrees of real-world graphs usually follow a long-tailed
power-law distribution [ 1]. High- and low-degree vertices are in the
head and tail parts of the distribution, respectively. When the vertex
degree changes as the graph structure evolves, several evolution
patterns will be identified based on the evolving trend of degrees,
including Fluctuation-at-Tail (FaT), Tail-to-Head (T2H), Head-to-Tail
(H2T), and Fluctuation-at-Head (FaH). FaT is defined as the vertex
degree being always lower than a given degree threshold ğœƒin a
time periodğ‘¡. In other words, the vertex fluctuates at the tail during
ğ‘¡. FaH is the opposite in which the vertexâ€™s degree remains above
ğœƒ. T2H is defined as the degree of a vertex changes from below ğœƒto
aboveğœƒduringğ‘¡. The T2H vertexâ€™s degree is initially below ğœƒbut
becomes above ğœƒduringğ‘¡.
We conducted a statistical analysis on six months of data in
the Amazon Books dataset containing 64,425vertices and 217,163
edges. Two snapshot graphs are constructed using data from the
first three and the last three months. The head and tail groups are
divided by a degree threshold of 10to identify the evolving trend
of degrees across snapshot graphs. The results in Table 1 show
that the above-identified evolving trend of degrees approximately
follows the long-tailed power-law distribution as 90.67%vertices
fluctuate at the tail with slight connection changes while only 9.33%
verticesâ€™ neighborhood structures vary a lot. This makes dynamic
graph embedding algorithms exhibit structure unfairness [ 17,35,
39], favoring highly active structural evolutions (i.e., T2H, H2T, and
FaH) too much yet discriminating inactive ones (i.e., FaT). Thus,
we call them the biased structural evolutions of the dynamic graph.
Learning structurally fair dynamic graph embeddings is essential
and has wide real-world applications, as presented in Section A of
the Appendix.
In the next section, we will present our structurally fair dynamic
graph embedding algorithm to learn the above-identified structuralevolution patterns for encoding debiased embeddings toward struc-
ture fairness. Since the number of vertices in H2T and FaH is small,
we combine them in a single group called Start-from-Head (SfH) in
the rest of this paper. The detailed annotation approach of FaT, T2H,
and SfH is presented in the Appendix D. As for complex structural
evolution patterns such as first rising and then falling, first falling
and then rising, etc., we leave them to future work.
Table 1: Statistics on the evolutionary trend of vertex degrees.
FaT T2H H2T FaH
SnapshotsG1G2G1G2G1G2G1G2
A
vg. Degree 1.171
0.936 0.869
9.345 16.362
3.447 29.594
23.237
Std.
Degree 1.414
1.000 1.732
13.153 9.849
2.646 23.979
20.396
V
ertex Ratio 90.67% 7.02% 1.45% 0.86%
4 STRUCTURALLY FAIR DYNAMIC GRAPH
EMBEDDING ALGORITHM
In this section, we present the details of the FairDGE algorithm
to learn structurally fair dynamic graph embeddings. The symbol
notations are listed in Table 7 in the Appendix.
4.1 Overall Framework of FairDGE
The overall framework of FairDGE is presented in Figure 1. FairDGE
consists of two modules that are trained jointly. We design a trend-
aware structural evolution learning module to embed the connec-
tion changes among vertices as well as the evolving trend of the
corresponding degrees. An intermedia training task that classifies
the identified biased structural evolutions (i.e., FaT, T2H, and SfH)
is employed to supervise the learning of structural evolutions.
Another dual debiasing module is devised to encode structurally
fair embeddings. It customizes debiasing strategies for FaT, T2H,
and SfH vertex groups, respectively. In particular, we first debias
the embeddings via contrastive learning, bringing closer the em-
beddings with identical biased structural evolution and penalizing
those with different ones. Hence, the embedding performance of
FaT vertices will be significantly improved and close to that of T2H
and SfH. Then, we minimize the effectiveness disparity of T2H and
SfH verticesâ€™ embeddings in downstream tasks to boost fairness
further and simultaneously avoid dragging their embedding effec-
tiveness down by FaT vertices with relatively lower performance.
4.2 Embedding Trend-aware Structural
Evolutions in Dynamic Graphs
We present the details of the trend-aware structural evolution learn-
ing module to embed the FaT, T2H, and SfH vertices in a dynamic
graph, solving the first challenges identified in Section 1.
4.2.1 Learning Evolving Trend of Degrees. Calculating the degree
difference between the first and last timestamp to measure the trend
will lose a lot of information about short-term changes. We first
model the degree of vertex ğ‘£across the snapshot graph sequence
(G1,G2,...,Gğ‘‡)as a time series, denoting as ğ‘‘ğ‘’ğ‘”(ğ‘£)âˆˆRğ‘‡. Then, we
devise a long-short-term trend encoder to learn the comprehensive
varying patterns of ğ‘‘ğ‘’ğ‘”(ğ‘£), including long-term evolving trends
and short-term fluctuation patterns.
 
1703KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yicong Li et al.
ğ’¢!ğ’¢"ğ’¢#â€¦GNNDynamicgraphsğ’¢$ğ’—ğ‘‘ğ‘’ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘‡Short-termTrendEncoderğ’…(ğ’—)Long-termTrendEncoderğ’…)(ğ’—)ğ’‰ğ’—âˆˆâ„ğ’…ğ’Šğ’ğ’‰ğ’—ğ’”ğ’•ğ’“â‘ Trend-aware Structural Evolution Learning
ğ“›ğ’‡ğ’‚ğ’Šğ’“ğ’«ğ‘»ğŸğ‘¯ğ’«ğ‘ºğ’‡ğ‘¯â‘¡Dual Debiasing for Encoding Structurally Fair Embeddingsâ€¦ğ“—ğ“¥âˆˆâ„|ğ“¥|Ã—ğ’…ğ’Šğ’ğ’‰ğ’—ğ’…ğ’‰ğ’—ğ’…+âŠ•ğ’«ğ‘­ğ’‚ğ‘»ğ’…(ğ’—)ğ’…)(ğ’—)	ğ’‰ğ‘»ğŸğ‘¯ğ’‰ğ‘­ğ’‚ğ‘»ğ’‰ğ‘ºğ’‡ğ‘¯ContrastiveLearningamong the embeddingsofğ‘»ğŸğ‘¯,ğ‘­ğ’‚ğ‘»andğ‘ºğ’‡ğ‘¯vertices.DownstreamTaskMLP
ğ“›*ğ’ğ’ğ’•ğ’“ğ’‚ğ’”ğ’•ğ“›ğ‘«ğ‘ºğ’‰ğ’—ğ’…ğ’†ğ’ˆGRUâŠ•Linearï¼‹ğ“›ğ’„ğ’ğ’‚ğ’”ğ’”DynamicGraphEmbeddingBackbone
Degreetrendâ€¦ğ“—ğ’—{ğŸ,â€¦,ğ‘»}â€¦ğ“—ğ’—ğ’”ğ’•ğ’“
Figure 1: Overall framework of FairDGE.
Specifically, we employ a 3-layer Gate Recurrent Unit (GRU) as
the long-term trend encoder, denoting as Ë†ğ‘‘(ğ‘£), to learn the long-
term evolving patterns of ğ‘‘ğ‘’ğ‘”(ğ‘£)as follows:
â„Ë†ğ‘‘
ğ‘£=Ë†ğ‘‘(ğ‘£)=ğºğ‘…ğ‘ˆ(ğ‘’ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘(ğ‘‘ğ‘’ğ‘”(ğ‘£))) (1)
whereğ‘’ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘(ğ‘‘ğ‘’ğ‘”(ğ‘£))expands the dimension of ğ‘‘ğ‘’ğ‘”(ğ‘£)fromğ‘‡Ã—1
toğ‘‡Ã—ğ‘‘ğ‘–ğ‘šby duplication.
To capture and embed the short-term fluctuation patterns of
degrees, we employ a 1-d Convolutional Neural Network (CNN)
as the short-term trend encoder ğ‘‘(ğ‘£). 1-d CNN has a good ability
to capture the local differences of degrees at several adjacent time
points, especially salient degrees [34].
â„ğ‘‘
ğ‘£=ğ‘‘(ğ‘£)=ğ¶ğ‘ğ‘(ğ‘‘ğ‘’ğ‘”(ğ‘£)) (2)
We set the kernelâ€™s size and padding to 3 and 1, respectively. There-
fore,â„ğ‘‘ğ‘£keeps the same dimension as â„Ë†ğ‘‘ğ‘£.
Lastly, we fuse â„ğ‘‘ğ‘£andâ„Ë†ğ‘‘ğ‘£to obtain the trend embedding of ğ‘‘ğ‘’ğ‘”(ğ‘£)
by a stack-mean operation as shown below.
â„ğ‘‘ğ‘’ğ‘”
ğ‘£=ğ‘š([â„ğ‘‘
ğ‘£âŠ•â„Ë†ğ‘‘
ğ‘£]) (3)
whereâ„ğ‘‘ğ‘’ğ‘”
ğ‘£is the trend embedding of ğ‘‘ğ‘’ğ‘”(ğ‘£),âŠ•is a stack operator
for two embeddings, and ğ‘š(Â·)is the mean operation.
4.2.2 Embedding Structural Evolutions. Embedding the connection
changes among vertices, noting as the structural evolutions, in
the snapshot graph sequence (G1,G2,...,Gğ‘‡)is a typical dynamic
graph embedding problem, which has been well studied [ 22,26,44â€“
46,49]. Since it is not the main focus of this study and many existing
algorithms [ 5,22,26,44â€“46,49] are capable of being directly applied,
we use a graph neural network (GNN) to embed the snapshot graph
at each timestamp and then employ a GRU to learn the sequential
changing pattern across the snapshot graph sequence and obtain
structural evolution embeddings.
Hğ‘ ğ‘¡ğ‘Ÿ
V=ğºğ‘…ğ‘ˆ(ğºğ‘ğ‘(G1,G2,...,Gğ‘‡))) (4)
whereHğ‘ ğ‘¡ğ‘Ÿ
Vis the embedding of all vertices in the dynamic graph.We treat this as a dynamic graph embedding backbone that any
existing dynamic graph embedding algorithms can be plugged in
and learn the structural evolution embeddings.
4.2.3 Learning Trend-aware Structural Evolutions via An Interme-
dia Trend Classification Task. To embed the trend-aware structural
evolutions, we fuse the degree-trend embedding of â„ğ‘‘ğ‘’ğ‘”
ğ‘£and the
structural evolution embedding â„ğ‘ ğ‘¡ğ‘Ÿğ‘£for every vertex ğ‘£, as shown
in Eq. (5) where â„ğ‘ ğ‘¡ğ‘Ÿğ‘£comes fromHğ‘ ğ‘¡ğ‘Ÿ
Vforğ‘£âˆˆV,[.;.]is a concate-
nation operation and ğ‘”(.)is a linear layer.
â„ğ‘£=ğ‘”([â„ğ‘‘ğ‘’ğ‘”
ğ‘£;â„ğ‘ ğ‘¡ğ‘Ÿ
ğ‘£]) (5)
We leverage an intermedia training task to better train â„ğ‘£for
retaining the biased structural evolutions FaT, T2H, and SfH. A
two-layer Multi-Layer Perceptron (MLP) is employed to encode
the representation, followed by a softmax function to forecast the
probability of vertex ğ‘£belonging to one of the biased structural
evolutions, i.e., FaT, T2H, or SfH,
â„ğ‘†ğ‘“ğ»,ğ‘‡ 2ğ»,ğ¹ğ‘ğ‘‡
ğ‘£ =ğ‘€ğ¿ğ‘ƒ(â„ğ‘£) (6)
â„ğ‘£,ğ‘¦=ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘…ğ‘’ğ¿ğ‘ˆ(â„ğ‘†ğ‘“ğ»,ğ‘‡ 2ğ»,ğ¹ğ‘ğ‘‡
ğ‘£)) (7)
whereâ„ğ‘£,ğ‘¦indicates the probability of vertex ğ‘£that belongs to a
classğ‘¦âˆˆğ‘Œ={SfH, T2H, FaT}. Lastly, we employ a cross-entropy
loss to train â„ğ‘£andâ„ğ‘†ğ‘“ğ»,ğ‘‡ 2ğ»,ğ¹ğ‘ğ‘‡
ğ‘£ , which is
Lğ‘ğ‘™ğ‘ğ‘ ğ‘ =âˆ’âˆ‘ï¸
ğ‘£âˆˆVğ‘™ğ‘œğ‘”exp(â„ğ‘£,ğ‘¦ğ‘£)
Ãğ‘Œ
ğ‘¦=1exp(â„ğ‘£,ğ‘¦)(8)
â„ğ‘£,ğ‘¦ğ‘£is a one-hot vector indicating the ground truth biased struc-
tural evolutions of ğ‘£, which is manually labeled from the historical
data for training. It is fine to set a threshold of head and tail degrees
to annotate FaT, T2H, and SfH. However, finding a golden standard
to determine the threshold is sometimes difficult due to the am-
biguous degree boundary of head and tail vertices. We devise an
alternative method, as Algorithm 1 in the Appendix, to annotate
FaT, T2H, and SfH based on the slope of degree evolving trends.
 
1704Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
4.3 Dual Debiasing for Encoding Structurally
Fair Embeddings
We devise a dual debiasing module that customizes debiasing strate-
gies for FaT, T2H, and SfH vertices to encode structurally fair em-
beddings, overcoming the second challenge. The idea is to make the
embedding performance of SfH and T2H vertices high and close
while improving the embedding performance of FaT vertices as
much as possible to narrow the gap with that of SfH and T2H,
eventually achieving structure fairness without sacrificing or even
improving embedding effectiveness.
R. Wang et al. [ 39] had theoretically and empirically proved that
contrastive learning will improve the tail vertexâ€™s performance and
alleviate the performance gap between the head and tail vertex
groups, eventually improving fairness. Inspired by this, we employ
contrastive learning to debias the embedding of FaT, T2H, and SfH
vertices. Specifically, for each vertex ğ‘£, we randomly select two
verticesğ‘£+andğ‘£âˆ’fromVto form a positive pair (ğ‘£,ğ‘£+)and a
negative one(ğ‘£,ğ‘£âˆ’)in whichğ‘£andğ‘£+are in the same structural
evolution group but ğ‘£andğ‘£âˆ’are not. The objective is to make
the embeddings of the positive pairs as close as possible and the
representations of the negative pairs as far away as possible, bring-
ing closer the embeddings with identical structural evolutions and
penalizing those with different ones. A contrast loss is proposed in
Eq. (9) to achieve this goal, where â„ğ‘£,â„ğ‘£+,â„ğ‘£âˆ’are the embeddings
of vertexğ‘£,ğ‘£+andğ‘£âˆ’, respectively.
Lğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘ ğ‘¡ =âˆ’ğ‘™ğ‘œğ‘”ğ‘’ğ‘¥ğ‘(ğ‘ ğ‘–ğ‘š(â„ğ‘£,â„ğ‘£+))/ğœ
ğ‘’ğ‘¥ğ‘(ğ‘ ğ‘–ğ‘š(â„ğ‘£,â„ğ‘£+)
ğœ)+Ã
ğ‘£âˆ’âˆˆVâˆ’ğ‘’ğ‘¥ğ‘(ğ‘ ğ‘–ğ‘š(â„ğ‘£,â„ğ‘£âˆ’)
ğœ)(9)
ğ‘ ğ‘–ğ‘š(â„ğ‘£,â„ğ‘£+)is measuring the cosine similarity between â„ğ‘£andâ„ğ‘£+.
ğœis a scaling parameter. Vâˆ’is a set of negative vertices with dif-
ferent structural evolutions from ğ‘£. Thanks to contrastive learning,
the embedding performance of FaT vertices will improve, resulting
in a smaller performance disparity with T2H and SfH vertices.
Additionally, we alleviate the effectiveness disparity of T2H and
SfH verticesâ€™ embeddings in downstream tasks for a second debias-
ing, facilitated by a fairness loss for the embeddings of T2H and SfH
vertices in Eq. (10). This loss minimizes the performance disparity
of T2H and SfH vertices in downstream tasks, imposing statistical
parity as defined in Def. 2. Eventually, statistical parity equalizes
outcomes across T2H and SfH vertices [8, 17].
Lğ‘“ğ‘ğ‘–ğ‘Ÿ=||Lğ·ğ‘†(ğ»ğ‘‡2ğ»
V)âˆ’Lğ·ğ‘†(ğ»ğ‘†ğ‘“ğ»
V)||2 (10)
ğ»ğ‘‡2ğ»
Vandğ»ğ‘†ğ‘“ğ»
Vare the final learned embeddings of T2H and SfH
vertices, respectively. ||Â·|| 2denotes the â„“2norm.Lğ·ğ‘†(Â·)is a loss
function of the downstream tasks, which depends on the actual
applications. Notablely, FaT vertices are excluded from the second
debiasing, avoiding dragging down the performance of T2H and
SfH vertices.
Following [ 18], we employ the link prediction as the downstream
task in this paper. That is
Lğ·ğ‘†=âˆ’|V|âˆ‘ï¸
ğ‘£|Eğ‘£|âˆ‘ï¸
ğ‘’ğ‘¥ğ‘’Â·ğ‘™ğ‘œğ‘”ğ‘ğ‘’+(1âˆ’ğ‘¥ğ‘’)Â·ğ‘™ğ‘œğ‘”(1âˆ’ğ‘ğ‘’) (11)
Eğ‘£is an edge set of ğ‘£for training, which contains positive edges ğ‘’âˆˆ
Eğ‘£linking vertex ğ‘£and the same number of negative edges that doTable 2: Stastics of datasets.
Dataset #
User #
Item #
Vertex #
Edges Dens. #
Snapshots
Amazon
Books 4,054 17,651 21,705 72,317 0.1% 5
Mo
vieLens 2,342 5,579 7,921 477,419 3.65% 15
Go
odReads 16,701 20,823 37,524 1,084,781 0.3% 15
not connect to ğ‘£.ğ‘ğ‘’is a learned edge existence probability computed
by inputting the final embeddings to a Fermi-Dirac decoder [20].
Lastly, we jointly minimize all the loss items mentioned above
withâ„“2andâ„“1regularization of model parameters Î˜,
L=ğ›¾1Lğ·ğ‘†+ğ›¾2Lğ‘ğ‘™ğ‘ğ‘ ğ‘ +ğ›¾3Lğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘ ğ‘¡+ğ›¾4Lğ‘“ğ‘ğ‘–ğ‘Ÿ+||Î˜||2+||Î˜||1(12)
whereğ›¾1,ğ›¾2,ğ›¾3,ğ›¾4are loss hyperparameters, controlling the pro-
portion of different components in the loss function. FairDGE will
gradually achieve the best trade-off between fairness and model
utility in the downstream tasks when jointly optimizing the loss.
5 EXPERIMENTS
We conduct extensive experiments to validate the embedding effec-
tiveness of FairDGE in terms of performance and fairness.
5.1 Experiment Settings
5.1.1 Datasets. The experiments are respectively conducted on
small-, medium- and large-scale real-world datasets including Ama-
zon Books, MovieLens and GoodReads. In the Amazon Books dataset,
the user-book interactions from 09 Aug 2006 to 12 Aug 2007 are
selected. For the MovieLens dataset, we use the 10M movie ratings
from 07 Jan 2001 to 07 Jan 2003. The GoodReads dataset is from
an online book community website, and we select the Childrenâ€™s
books from 1 Jan 2013 to 30 Dec 2015. The detailed information of
datasets is presented in Table 2.
5.1.2 Baseline Methods. To comprehensively benchmark our pro-
posed FairDGE, we carefully select eight baseline methods for per-
formance comparison. Following are the detailed descriptions of
the selected baseline methods.
Graph learning methods:
â€¢GCN [ 11]: GCN adopts the graph convolutions to learn the
graph embeddings.
â€¢GAT [ 37]: GAT leverages masked self-attentional layers to
specify different weights to different vertices in a neighbor-
hood.
Dynamic graph learning methods:
â€¢MPNN-LSTM [ 21]: MPNN-LSTM proposes an LSTM-based
message passing mechanism to model the vertices evolution
in the dynamic graphs.
â€¢EvolveGCN [ 22]: EvolveGCN combines the graph convo-
lutional network model with an RNN to capture temporal
dynamics in a graph sequence.
Fair graph learning methods:
â€¢FairGNN [ 7]: FairGNN effectively mitigates the impact of
sensitive attributes in graph data by incorporating fairness
constraints during training.
â€¢FairVGNN [ 41]: FairVGNN is an extension of the FairGNN
model that includes a variational graph autoencoder to learn
 
1705KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yicong Li et al.
latent representations and generate fair and diverse outputs
in graph data.
â€¢DegFairGNN [ 17]: DegFairGNN is a fair graph neural net-
work to alleviate the structure bias problem using an equal
opportunity fair loss.
â€¢TailGNN [ 16]: TailGNN proposes transferable neighborhood
translation aiming at closing the performance disparity be-
tween head and tail vertices.
5.1.3 Evalution Metrics of Performance. We adopt the top ğ‘˜Hit
Rate (HR@ğ‘˜), topğ‘˜Precision (PREC@ ğ‘˜), and topğ‘˜Normalized Dis-
counted Cumulative Gain (NDCG@ ğ‘˜) as the performance metrics
of the recommendation tasks.
â€¢HR@ğ‘˜calculates the recall ratio of the prediction list,
ğ»ğ‘…@ğ‘˜=#ğ»ğ‘–ğ‘¡ğ‘  @ğ‘˜
|ğ‘ğ‘œğ‘ |(13)
where|ğ‘ğ‘œğ‘ |is the number of all positive items. #ğ»ğ‘–ğ‘¡ğ‘ @ğ‘˜is
the number of top ğ‘˜prediction list hit to the positive items.
â€¢PREC@ğ‘˜measures the precision of the prediction list,
ğ‘ƒğ‘…ğ¸ğ¶ @ğ‘˜=Ã
ğ‘¢âˆˆğ‘ˆğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘˜(ğ‘¢)Ã‘ğ‘ğ‘œğ‘ (ğ‘¢)Ã
ğ‘¢âˆˆğ‘ˆğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘˜(ğ‘¢)(14)
whereğ‘ˆis the user set, ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘˜(ğ‘¢)is the topğ‘˜prediction list
for userğ‘¢, andğ‘ğ‘œğ‘ (ğ‘¢)isğ‘¢â€™s positive item list.
â€¢NDCG@ğ‘˜calculates the normalized ranking of the recall
ratio of the prediction list,
ğ‘ğ·ğ¶ğº @ğ‘˜=1
|ğ‘ğ‘œğ‘ ||ğ‘ğ‘œğ‘ |âˆ‘ï¸
ğ‘–1
ğ‘™ğ‘œğ‘”2(ğ‘ğ‘˜
ğ‘–+1)(15)
whereğ‘ğ‘˜
ğ‘–is itemğ‘–â€™s ranking in the top ğ‘˜prediction list.
5.1.4 Evaluation Metrics of Fairness. We adopt the commonly used
ranking discrepancy metrics to quantitatively evaluate fairness.
In particular, we set ğ‘˜âˆˆğ¾={1,5,10,15,20,40,60,80,100}and
calculate the average Hit Ratio Difference (rHR) and Normalized
Discounted Difference (rND) as fairness metric [43].
â€¢Hit Ratio Difference (rHR) calculates the difference be-
tween the T2H itemsâ€™ ratio in the top ğ‘˜âˆˆğ¾candidates and
that in the overall ranking. A similar ratio, leading to less
rHR, denotes more fairness. Mathematically,
ğ‘Ÿğ»ğ‘… =1
ğ‘ğ¾âˆ‘ï¸
ğ‘˜|ğ‘‡2ğ»ğ‘˜|
ğ‘˜âˆ’|ğ‘‡2ğ»|
|V|(16)
where|ğ‘‡2ğ»ğ‘˜|denotes the number of T2H vertices in the top
ğ‘˜candidate list and|V|presents the total number of vertices
in the dynamic graph. Given |V|and|ğ‘‡2ğ»|,ğ‘is the highest
possible value of rHR for normalization.
â€¢Normalized Discounted Difference (rND) calculates the
difference between the T2H itemsâ€™ ranking order in the top
ğ‘˜âˆˆğ¾candidates and that in the overall ranking. The smaller
the rND, the better the fairness.
ğ‘Ÿğ‘ğ· =1
ğ‘ğ¾âˆ‘ï¸
ğ‘˜1
ğ‘™ğ‘œğ‘”2ğ‘˜|ğ‘‡2ğ»ğ‘˜|
ğ‘˜âˆ’|ğ‘‡2ğ»|
|V|(17)5.2 Performance and Fairness Comparison
To validate the effectiveness of our proposed FairDGE, we split the
Amazon Books, MovieLens, and GoodReads datasets into 5, 15, and
15 snapshots for training and testing, respectively. We regard each
userâ€™s last interacted item as the test data. We run our FairDGE and
all baselines five times with different random seeds and report the
mean and the standard deviation (Std) results in Table 3. Std values
are shown magnified by a factor of 10 to save space.
FairDGE performs best on all three datasets, outperforming base-
line methods of 1.98% - 36.46% in recommendations, and achieves
the smallest fairness scores, especially on the rND metric. The
smaller the rHR and rND scores, the better the fairness. GCN and
GAT always obtain the worst performance among these baselines
because they are simple static graph neural networks and fail to
embed the structural evolutions. Although EvolveGCN also gets
worse performance on the Amazon Books dataset, it performs well
on the MovieLens dataset because the Amazon Books dataset is
too sparse for EvolveGCN to learn abundant evolution information
via the recurrent architecture. Thanks to generative adversarial
network structures, FairGNN and FairVGNN are the best baselines
in both recommendation performance and fairness, but they still
perform much worse than our FairDGE.
Another observation is that better fairness performance is ob-
tained when equipping the baseline methods with our fairness loss
Lğ‘“ğ‘ğ‘–ğ‘Ÿ, especially rND. This demonstrates that our fairness loss
effectively pushes the T2H vertices to get more exposure in the
recommendation candidate list, especially to display in the high
ranking. At the same time, their recommended performance only
dropped slightly, and some even increased. This demonstrates that
the dual debiasing approach makes FairDGE successfully overcome
the second challenge.
5.3 Ablation Study of FairDGE
To study the contributions of each module to performance and fair-
ness, we conducted the ablation study on the Amazon Books dataset
as shown in Table 4. We compare the {HR, NDCG, PREC}@{10,15,20}
and rHR and rND scores to reveal the performance of recommenda-
tion and fairness regarding different variants of FairDGE. The Dec.
and Inc. columns denote the comparison with FairDGE about the
average decreasing percentage performance scores and the average
increasing percentage fairness scores, respectively. The higher the
fairness scores, the more discrepancy between the disadvantaged
and advantaged vertices, resulting in unfairness.
In Table 4, the first row of variants is our proposed FairDGE,
achieving the best performance and fairness scores. The second
row is FairDGE without the fairness loss Lğ‘“ğ‘ğ‘–ğ‘Ÿ. The performance
decreases by 38.13%, and fairness increases by 17.12%, indicating
that both performance and fairness become worse when removing
the fairness loss. This validates that our fairness loss not only im-
proves the fairness but also breaks the effectiveness bottleneck and
results in better performance.
The third row in Table 4 is FairDGE without the intermedia
training tasks of classifying the biased structural evolutions, which
differentiates the FaT, T2H, and SfHvertex groups. This module in-
fluences the most minor performance of the downstream task, but it
contributes much to fairness because this classification module aims
 
1706Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 3: FairDGE compares with 8 baselines on performance and fairness.
Datasets Amazon
Books Mo
vieLens Go
odReads
BaselinesPerformance
(â†‘) Fairness
(â†“) Performance
(â†‘) Fairness
(â†“) Performance
(â†‘) Fairness
(â†“)
HR@20
NDCG@20 PREC@20 rHR
rND HR@20
NDCG@20 PREC@20 rHR
rND HR@20
NDCG@20 PREC@20 rHR
rND
GCN 0.0726Â±0.034
0.0285Â±0.016 0.0036Â±0.002 0.1557Â±0.003
0.2614Â±0.014 0.0904Â±0.047
0.0420Â±0.029 0.0045Â±0.002 0.3265Â±0.020
0.5433Â±0.222 0.0641Â±0.071
0.0255Â±0.031 0.0032Â±0.003 0.3708Â±0.004
0.6865Â±0.027
w/Lğ‘“
ğ‘ğ‘–ğ‘Ÿ 0.0799Â±0.051
0.0313Â±0.027 0.0040Â±0.003 0.1550Â±0.003
0.2568Â±0.020 0.0769Â±0.105
0.0347Â±0.041 0.0038Â±0.005 0.3207Â±0.027
0.5720Â±0.157 0.0767Â±0.002
0.0309Â±0.001 0.0038Â±0.000 0.3703Â±0.001
0.6651Â±0.021
GA
T 0.0655Â±0.010
0.0261Â±0.004 0.0033Â±0.001 0.1559Â±0.010
0.2715Â±0.047 0.1109Â±0.011
0.0492Â±0.003 0.0055Â±0.000 0.3568Â±0.002
0.6109Â±0.021 0.0771Â±0.015
0.0296Â±0.004 0.0038Â±0.001 0.3839Â±0.003
0.6403Â±0.010
w/Lğ‘“
ğ‘ğ‘–ğ‘Ÿ 0.0654Â±0.003
0.0253Â±0.002 0.0033Â±0.000 0.1552Â±0.003
0.2658Â±0.009 0.0821Â±0.050
0.0348Â±0.025 0.0041Â±0.002 0.3549Â±0.009
0.6038Â±0.076 0.0789Â±0.004
0.0302Â±0.001 0.0039Â±0.001 0.3838Â±0.001
0.6402Â±0.013
MPNN-LSTM 0.1308Â±0.037
0.0514Â±0.018 0.0065Â±0.002 0.1553Â±0.007
0.2615Â±0.062 0.0359Â±0.013
0.0124Â±0.005 0.0018Â±0.001 0.3434Â±0.025
0.5947Â±0.045 0.0340Â±0.056
0.0128Â±0.022 0.0017Â±0.003 0.3683Â±0.028
0.6729Â±0.050
w/Lğ‘“
ğ‘ğ‘–ğ‘Ÿ 0.1330Â±0.036
0.0520Â±0.018 0.0066Â±0.002 0.1553Â±0.006
0.2607Â±0.039 0.0404Â±0.022
0.0135Â±0.003 0.0020Â±0.001 0.3431Â±0.041
0.5932Â±0.050 0.0403Â±0.014
0.0153Â±0.003 0.0020Â±0.001 0.3679Â±0.010
0.6651Â±0.041
Ev
olveGCN 0.0526Â±0.024
0.0208Â±0.011 0.0026Â±0.002 0.1555Â±0.010
0.2630Â±0.093 0.1707Â±0.012
0.0586Â±0.017 0.0085Â±0.000 0.3544Â±0.050
0.5332Â±0.083 0.0648Â±0.096
0.0279Â±0.001 0.0033Â±0.005 0.3192Â±0.038
0.5549Â±0.031
w/Lğ‘“
ğ‘ğ‘–ğ‘Ÿ 0.0504Â±0.050
0.0199Â±0.026 0.0025Â±0.003 0.1552Â±0.004
0.2584Â±0.008 0.1574Â±0.088
0.0556Â±0.027 0.0079Â±0.004 0.3531Â±0.013
0.5261Â±0.049 0.0628Â±0.110
0.0252Â±0.042 0.0032Â±0.006 0.3162Â±0.045
0.5448Â±0.202
Fair
GNN 0.1792Â±0.006
0.0816Â±0.047 0.0090Â±0.001 0.1547Â±0.006
0.2546Â±0.019 0.1782Â±0.014
0.0713Â±0.032 0.0089Â±0.000 0.3787Â±0.067
0.6719Â±0.028 0.0695Â±0.001
0.0242Â±0.001 0.0034Â±0.000 0.5149Â±0.000
0.7096Â±0.003
w/Lğ‘“
ğ‘ğ‘–ğ‘Ÿ 0.1855Â±0.071
0.0877Â±0.038 0.0093Â±0.004 0.1537Â±0.008
0.2515Â±0.048 0.1809Â±0.017
0.0737Â±0.017 0.0091Â±0.001 0.3750Â±0.051
0.6405Â±0.139 0.0749Â±0.005
0.0267Â±0.004 0.0037Â±0.001 0.5148Â±0.074
0.7049Â±0.008
Fair
VGNN 0.1743Â±0.127
0.0830Â±0.075 0.0087Â±0.006 0.1543Â±0.006
0.2516Â±0.139 0.1385Â±0.194
0.0782Â±0.322 0.0069Â±0.010 0.3472Â±0.038
0.5811Â±0.247 0.0846Â±0.033
0.0329Â±0.006 0.0043Â±0.002 0.4481Â±0.120
0.6399Â±0.411
w/Lğ‘“
ğ‘ğ‘–ğ‘Ÿ 0.1712Â±0.139
0.0816Â±0.093 0.0087Â±0.008 0.1539Â±0.004
0.2453Â±0.067 0.1281Â±0.088
0.1035Â±0.069 0.0064Â±0.005 0.3375Â±0.017
0.5683Â±0.223 0.0850Â±0.020
0.0339Â±0.021 0.0042Â±0.001 0.4425Â±0.139
0.6023Â±0.251
DegFair
GNN 0.1692Â±0.005
0.0774Â±0.018 0.0085Â±0.001 0.1601Â±0.012
0.3172Â±0.009 0.1205Â±0.052
0.0481Â±0.014 0.0060Â±0.003 0.3612Â±0.004
0.6685Â±0.105 0.0526Â±0.018
0.0201Â±0.008 0.0024Â±0.003 0.4659Â±0.053
0.6592Â±0.0027
w/Lğ‘“
ğ‘ğ‘–ğ‘Ÿ 0.1778Â±0.029
0.0818Â±0.050 0.0089Â±0.002 0.1590Â±0.008
0.3103Â±0.024 0.1208Â±0.015
0.0480Â±0.012 0.0060Â±0.001 0.3606Â±0.016
0.6615Â±0.094 0.0517Â±0.019
0.0202Â±0.006 0.0026Â±0.001 0.4654Â±0.019
0.6579Â±0.022
T
ailGNN 0.1289Â±0.005
0.0631Â±0.103 0.0088Â±0.020 0.1543Â±0.005
0.2578Â±0.028 0.1887Â±0.075
0.0928Â±0.033 0.0095Â±0.004 0.3754Â±0.026
0.6564Â±0.098 0.0836Â±0.022
0.0341Â±0.007 0.0042Â±0.001 0.5086Â±0.042
0.6086Â±0.059
w/Lğ‘“
ğ‘ğ‘–ğ‘Ÿ 0.1316Â±0.061
0.0654Â±0.086 0.0082Â±0.017 0.1541Â±0.005
0.2517Â±0.062 0.1924Â±0.038
0.0946Â±0.025 0.0096Â±0.002 0.3692Â±0.034
0.6191Â±0.163 0.0773Â±0.017
0.0319Â±0.017 0.0039Â±0.001 0.5082Â±0.056
0.6072Â±0.051
FairDGE 0.2006Â±0.033
0.0894Â±0.012 0.0100Â±0.002 0.1487Â±0.004
0.2061Â±0.031 0.2626Â±0.049
0.1330Â±0.039 0.0131Â±0.002 0.3189Â±0.020
0.1824Â±0.103 0.1029Â±0.016
0.0383Â±0.012 0.0052Â±0.001 0.3087Â±0.033
0.3503Â±0.006
Impr
ovement 8.18%
1.98% 7.91% 3.27%
15.98% 36.46%
28.50% 36.33% 0.56%
65.32% 21.11%
12.30% 21.09% 2.37%
35.69%
Table 4: Ablation study of variants on both performance and fairness. Â¬means the variant without the following module.
Performance(â†‘) Fairness(â†“)
V
ariants HR@{10,15,20} NDCG@{10,15,20} PREC@{10,15,20} De
c. rHR rND Inc.
FairDGE 0.1256 0.1690 0.2025 0.0704 0.0823 0.0903 0.0126 0.0113 0.0101 - 0.1489 0.2075 -
FairDGEÂ¬
Lğ‘“ğ‘ğ‘–ğ‘Ÿ 0.0730 0.1068 0.1396 0.0391 0.0483 0.0562 0.0073 0.0071 0.0070 38.13% 0.1551 0.2699 17.12%
FairDGEÂ¬
Lğ‘ğ‘™ğ‘ğ‘ ğ‘  0.0940 0.1325 0.1672 0.0490 0.0595 0.0679 0.0094 0.0088 0.0084 23.49% 0.1536 0.2605 14.35%
FairDGEÂ¬
Lğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘ ğ‘¡ 0.0646 0.1024 0.1342 0.0334 0.0437 0.0513 0.0065 0.0068 0.0067 42.92% 0.1552 0.2728 17.85%
FairDGEÂ¬ Deg 0.0681 0.0932 0.1199 0.0361 0.0429 0.0493 0.0068 0.0062 0.0060 45.02% 0.1524 0.2282 6.16%
FairDGEÂ¬ GRU 0.0456 0.0681 0.0856 0.0254 0.0315 0.0357 0.0046 0.0045 0.0043 60.93% 0.1568 0.2792 19.93%
to separate disadvantaged vertices from all vertices, contributing
to the following fairness treatment.
FairDGEÂ¬Lğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘ ğ‘¡ denotes a variant without contrastive learn-
ing in the dual debiasing. The results show that contrastive learning
contributes most in FairDGE to both downstream task performance
and fairness because it assists in bringing closer the embeddings
with identical biased structural evolution and penalizing those with
different ones, further proving the effectiveness of contrastive learn-
ing on structural fairness.
The next variant is removing the degree evolving trend learn-
ing module introduced in Section 4.2.1 from the FairDGE, which
contributes to the second-best performance but slightly influences
fairness. It is because the supervised classification of biased struc-
tural evolutions takes more effort in bias detection, but degree
evolving trend learning is more about the dynamic graph embed-
ding backbone for biased structural evolution learning, which limits
its influence on performance and fairness.
The last variant is FairDGE without dynamic structural evo-
lution modeling, which is the GRU layers in the dynamic graph
embedding backbone. This variant models the data statically and
will not differentiate the biased structural evolutions. Obviously, it
performs the worst, demonstrating that dealing with the evolving
bias caused by structural changes in dynamic graphs is essential,
and our FairDGE solves this problem very well. In summary, each
module of FairDGE is indispensable and contributes to performance
and fairness to varying degrees.
5.4 Hyperparameter Study
To study the influence of different hyperparameters on performance
and fairness, we conducted hyperparameter studies on the Ama-
zon Books dataset to test different numbers of snapshots, different
model dimensions, different head/tail ratio percentages, and dif-
ferent number of time-sliding windows. For each hyperparameter
(a) Snapshots numbers
 (b) Model dimensions
(c) Head/tail ratios
 (d) No. of time-sliding windows
Figure 2: Results of hyperparameter testing.
study, we present the average scores after five runs for a fair com-
parison. The x-axis of Figure 2 denotes different hyperparameters.
The left y-axis displays HR@10 and HR@20 to illustrate the per-
formance trend in recommendation tasks, while the right y-axis
exhibits the inversed fairness scores (1/rHR and 1/rND) for conve-
nient visualization. This maintains a consistent interpretation for
both sides of metrics, where higher hit rates and higher inversed
fairness scores indicate better performance and fairness.
Due to the page limit, we also report the additional hyperparam-
eter testing on loss hyperparameters in Section E.2 of the Appendix.
 
1707KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yicong Li et al.
5.4.1 Different Number of Snapshots. To reveal the influence of the
number of snapshots on performance and fairness, we report the
trend of performance and fairness in Figure 2a. The larger the num-
ber of snapshots, the shorter the time period within each snapshot.
We observe a slight decrease in the performance trend as the num-
ber of snapshots increases. The reason is that the increased number
of snapshots results in sparser snapshot graphs as the number of
edges in the snapshot graph decreases. Eventually, the snapshot
graph will become sparse, containing rare edge information and
deteriorating the performance of each snapshot. Additionally, we
use GRU in the dynamic graph embedding backbone, which is not
good at capturing long-term temporal evolutions. This also causes
the performance to drop with increasing snapshots. Fortunately,
leveraging more advanced dynamic graph embedding algorithms
in the backbone, which widely exist in the community, could solve
this problem and further improve the performance of our FairDGE.
From a fairness perspective, more snapshots allow us to obtain
finer granular data for capturing the structure evolution in the dy-
namic graph, helping FairDGE accurately train the degree-evolving
trend module to capture change across the evolution snapshots
better. Consequently, this benefits our model in effectively identify-
ing different biased vertex groups, eventually improving fairness.
Lastly, the performance and fairness trends reverse as the number
of snapshots increases, consistent with the widely accepted notion
that performance and fairness tend to be a trade-off.
5.4.2 Different Dimensions. Figure 2b illustrates the variations in
performance and fairness as the dimension of embeddings varies
in{8,16,32,64,128}. HR@{10,20} exhibits notably low values at
the dimension of 8 but experiences a steep increase after 32. Sub-
sequently, the performance reaches its peak at 64. Regarding the
fairness scores, it initially performs poorly at the lowest dimension
but reaches the best when the dimension of embeddings is 64. How-
ever, when the dimension is 128, the fairness scores decrease and
become the second-best due to over-training. As a result, we select
a default dimension setting of 64 for all the experiments.
5.4.3 Different head/tail ratio percentages. We vary the head ver-
tex group ratio ranges from 10% to 40% and test the impacts on
FairDGEâ€™s performance and fairness. Interestingly, we observe that
the performance remains consistent across different head/tail ra-
tios in Figure 2c, highlighting the stability and reliability of our
proposed FairDGE algorithm. Although there is a slight peak at a
20% head vertex split ratio, the overall performance remains unaf-
fected. In contrast, fairness consistently improves with higher head
vertex split ratios. By analyzing the proportions of T2H, FaT, and
SfH under different head vertex split ratios, we reveal the principle
behind this fairness trend. Higher head vertex split ratios result
in fewer T2H vertices, reducing the number of vertices used for
fairness comparison.
5.4.4 Different number of time-sliding windows. We conduct this
experiment to discuss the performance and fairness changing trend
if there is a time sliding window to narrow the focusing degree
changing range. Figure 2d reveals the performance and fairness
changing with the number of time-sliding windows. The time slid-
ing window length is the overall ğ‘‡timestamps. Similarly, if there
are{1,2,4,8}sliding windows and the number of timestamps is
(a) Training loss w.r.t epoch
 (b) Training time w.r.t data ratio
Figure 3: Convergence and scalability of FairDGE.
(a) GCN
 (b) FairDGE
Figure 4: Effectiveness of fairness loss Lğ‘“ğ‘ğ‘–ğ‘Ÿ.
fixed to 8, each time sliding window contains {8,4,2,1}snapshots,
respectively. The figure shows that the performance and fairness in-
crease as the number of sliding windows grows to 4. As the number
of time-sliding windows increases to 8, the model becomes static
with 1 snapshot per time-sliding window, resulting in the worst
performance and fairness.
5.5 Convergence and Scalability
The convergence curve of training FairDGE on the entire Amazon
Books dataset is presented in Figure 3a, showing that FairDGE
converges at approximately 60 epochs. The x-axis represents the
number of training epochs, while the y-axis represents the training
loss. Additionally, we test the scalability of FairDGE by randomly
selecting {20%, 40%, 60%, 80%, 100%} percentages of the training
data from the Amazon Books dataset to train FairDGE and report
the average training time per epoch in Figure 3b. As the volume
of training data increases, FairDGEâ€™s training time grows almost
linearly, demonstrating that FairDGE has good scalability.
5.6 Effectiveness Analysis of Fairness
In this section, we first discuss the effectiveness of fairness loss
Lğ‘“ğ‘ğ‘–ğ‘Ÿon the T2H and SfH vertex groups and then reveal the supe-
riority of capturing structural evolution for debiasing against the
conventional high- and low-degree-based fairness.
5.6.1 Effectiveness of Fairness Loss Lğ‘“ğ‘ğ‘–ğ‘Ÿon The T2H and SfH Vertex
Groups. To demonstrate the effectiveness of our proposed fairness
lossLğ‘“ğ‘ğ‘–ğ‘Ÿon the disadvantage group (T2H ) and advantage group
(SfH), we analyze the embedding performance in downstream tasks.
The closer the performance of T2H and SfH vertex groups, the
better the fairness. Specifically, we compare the HR@20 scores
of all the biased vertex groups with and without the fairness loss
Lğ‘“ğ‘ğ‘–ğ‘Ÿ on GCN and FairDGE. The results are shown in Figure 4,
where the x-axis denotes whether the fairness loss is used and the
 
1708Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
(a) GCN.
 (b) GAT.
Figure 5: Effectiveness of debiasing structural evolutions.
Table 5: Fairness of debiasing structural evolutions.
rHR (â†“) rND (â†“)
GCN w/o Fairness 0.1559 0.2627
w/ Degree Fairness 0.1553 (0.4%â†“)0.2578 (2%â†“)
w/Lğ‘“ğ‘ğ‘–ğ‘Ÿ 0.1547 (0.8%â†“)0.2551 (3%â†“)
GAT w/o Fairness 0.1569 0.2765
w/ Degree Fairness 0.1557 (0.8%â†“)0.2711 (2%â†“)
w/Lğ‘“ğ‘ğ‘–ğ‘Ÿ 0.1550 (1.2%â†“)0.2649 (4%â†“)
y-axis represents the HR@20 scores for performance comparison.
In each result set, the two bars represent the HR@20 scores of
T2H andSfH, respectively. We observe that, without Lğ‘“ğ‘ğ‘–ğ‘Ÿ, GCN
exhibits a significant performance gap between T2H andSfH, and
the performance is much close after equipping Lğ‘“ğ‘ğ‘–ğ‘Ÿ. A similar
phenomenon is observed in FairDGE. This indicates that the fairness
lossLğ‘“ğ‘ğ‘–ğ‘Ÿeffectively narrows the performance gap between the
T2H andSfHvertex groups, thereby improving fairness.
5.6.2 Effectiveness of Capturing Structural Evolution for Debiasing
against Degree Fairness. Degree fairness prevents the performance
disparity of head- and tail-degree vertex groups. To further vali-
date that capturing structural evolution for debiasing is better than
static degree fairness, We divide vertices into head- and tail-degree
vertex groups to train GCN and GAT with fairness loss Lğ‘“ğ‘ğ‘–ğ‘Ÿand
compare the performance with GCN and GAT trained on the T2H
and SfH vertex groups. The results in Figure 5 and Table 5 validate
that capturing structural evolution to debias dynamic graph embed-
ding is capable of achieving fairness without sacrificing and even
improving embedding performance, which degree fairness cannot.
These results also demonstrate that our debiasing method can be
used as a general fairness plug-in, enabling existing dynamic graph
embedding algorithms to achieve structural fairness.
6 RELATED WORK
6.1 Toward Fairness in Static Graph Learning
Although learning structurally fair dynamic graph embedding re-
mains an under-explored area, several studies have successfully
learned fair embeddings for static graphs [ 40], eliminating disparate
treatment or impacts to sensitive graph attributes and structures.
To deal with the sensitive graph attributes, various methodologies,
such as adversarial learning [ 7,41], resampling techniques [ 36,50],
and fair-aware loss constraints [ 9,10], have been developed to
mitigate bias and promote fairness. Specifically, [ 7,41] adopts ad-
versarial learning to make the discriminators ambiguous about thesensitive feature distinguish, resulting in a fair graph neural net-
work to treat different biased groups equally. To alleviate bias, [ 24]
resamples the vertices to balance the distribution of the sensitive
features. Some studies [ 9,10] propose adding fair constraints to the
loss for learning fair graph representations. However, none of them
address structure fairness, e.g., degree fairness, in graph learning.
To address the bias introduced by the graph structure, early work
revealed that the long-tail distribution of vertex degree caused fair-
ness issues due to the poor embedding performance of tail vertices
[16,19]. Few-shot learning [ 42,48], contrastive learning [ 39], re-
sample [ 38,50], data augmentation [ 47] approaches were proposed
to narrow the performance gap between head and tail vertices. Tail-
GNN [ 16] and Meta-Tail2vec [ 19] are the representative works that
improve the expressivity of GNN on tail vertices, which surpris-
ingly improves the fairness. Recently, DegFairGNN [ 17] defined
the degree fairness problem in static graph learning for the first
time and proposed a fairness constraint to debias the imbalanced
degrees of vertices. However, none of the existing studies account
for the problem of structure fairness in dynamic graph learning.
Our work fills this research gap.
6.2 Toward Fairness on Dynamic Euclidean Data
Fairness is a critical problem in many scenarios where time and
dynamics matter, including dynamic allocation [ 28], job prediction
[27], and so on. Therefore, some research works [ 27,28,36] alle-
viate the bias by dynamic solutions, including Markov Decision
Processes (MDPs) [ 51], adaptive threshold policy [ 29] and so on.
The main research solutions cover fairness accumulation across
timestamps [ 28] and long-term fairness increment [ 36]. However,
research on fair graph learning or graph embeddings in dynamic
scenarios, e.g., dynamic graph embedding [ 33], is scarce. Different
from the above-mentioned approaches that isolate the fairness for
each timestamp, our study takes into account the evolving trend
of verticesâ€™ degrees and incorporates graph structural evolution to
learn fair representations in dynamic graphs.
7 CONCLUSION
In this paper, we investigate the structure fairness problem in dy-
namic graph embedding for the first time. We empirically validate
that structural evolutions in a dynamic graph approximately follow
a long-tailed power-law distribution. This makes dynamic graph
embedding algorithms exhibit structure unfairness. We innovatively
propose a structurally Fair Dynamic Graph Embedding algorithm,
namely FairDGE, which first learns trend-aware structural evolu-
tions and then encodes structurally fair embeddings by a novel
dual debiasing approach. FairDGE can be used as a general fairness
plug-in, enabling existing dynamic graph learning algorithms to
generate structurally fair embeddings.
ACKNOWLEDGEMENT
This work was partially conducted at the Research Institute for
Artificial Intelligence of Things (RIAIoT) at PolyU. It is supported by
the Hong Kong Research Grants Council (RGC) under the Theme-
based Research Scheme with Grant No. T43-513/23-N and T41-
603/20-R, and under Research Impact Fund with Grant No. R5034-
18. This work is also supported by the Australian Research Council
(ARC) under Grant No. DP220103717, and LE220100078.
 
1709KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yicong Li et al.
REFERENCES
[1]Albert-LÃ¡szlÃ³ BarabÃ¡si and RÃ©ka Albert. 1999. Emergence of scaling in random
networks. science 286, 5439 (1999), 509â€“512.
[2]Solon Barocas and Andrew D Selbst. 2016. Big dataâ€™s disparate impact. California
law review (2016), 671â€“732.
[3]Derrick Blakely, Jack Lanchantin, and Yanjun Qi. 2021. Time and space complexity
of graph convolutional networks. Accessed on: Dec 31 (2021), 2021.
[4]Ines Chami, Zhitao Ying, Christopher RÃ©, and Jure Leskovec. 2019. Hyperbolic
graph convolutional neural networks. In Advances in Neural Information Process-
ing Systems. 4869â€“4880.
[5]Hongxu Chen, Yicong Li, Xiangguo Sun, Guandong Xu, and Hongzhi Yin. 2021.
Temporal meta-path guided explainable recommendation. In Proceedings of the
14th ACM international conference on web search and data mining. 1056â€“1064.
[6]Enyan Dai, Wei Jin, Hui Liu, and Suhang Wang. 2022. Towards robust graph
neural networks for noisy graphs with sparse labels. In Proceedings of the Fifteenth
ACM International Conference on Web Search and Data Mining. 181â€“191.
[7] Enyan Dai and Suhang Wang. 2021. Say no to the discrimination: Learning fair
graph neural networks with limited sensitive attribute information. In Proceedings
of the 14th ACM International Conference on WSDM. 680â€“688.
[8]Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard
Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd innovations in
theoretical computer science conference. 214â€“226.
[9]Zuohui Fu, Yikun Xian, Ruoyuan Gao, Jieyu Zhao, Qiaoying Huang, Yingqiang
Ge, Shuyuan Xu, Shijie Geng, Chirag Shah, Yongfeng Zhang, et al .2020. Fairness-
aware explainable recommendation over knowledge graphs. In Proceedings of
the 43rd International ACM SIGIR. 69â€“78.
[10] Yingqiang Ge, Juntao Tan, Yan Zhu, Yinglong Xia, Jiebo Luo, Shuchang Liu,
Zuohui Fu, Shijie Geng, Zelong Li, and Yongfeng Zhang. 2022. Explainable
fairness in recommendation. In Proceedings of the 45th International ACM SIGIR.
681â€“691.
[11] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph
convolutional networks. arXiv preprint arXiv:1609.02907 (2016).
[12] Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ashesh Rambachan. 2018.
Algorithmic fairness. In Aea papers and proceedings, Vol. 108. American Economic
Association 2014 Broadway, Suite 305, Nashville, TN 37203, 22â€“27.
[13] Ã–ykÃ¼ Deniz KÃ¶se and Yanning Shen. 2021. Fairness-aware node representation
learning. arXiv preprint arXiv:2106.05391 (2021).
[14] Haoyang Li and Lei Chen. 2023. EARLY: Efficient and Reliable Graph Neural
Network for Dynamic Graphs. Proceedings of the ACM on Management of Data 1,
2 (2023), 1â€“28.
[15] Yicong Li, Xiangguo Sun, Hongxu Chen, Sixiao Zhang, Yu Yang, and Guandong
Xu. 2024. Attention Is Not the Only Choice: Counterfactual Reasoning for Path-
Based Explainable Recommendation. IEEE TKDE (mar 2024), 1â€“14.
[16] Zemin Liu, Trung-Kien Nguyen, and Yuan Fang. 2021. Tail-GNN: Tail-Node
Graph Neural Networks. In Proceedings of the 27th ACM SIGKDD Conference on
Knowledge Discovery & Data Mining. 1109â€“1119.
[17] Zemin Liu, Trung Kien Nguyen, and Yuan Fang. 2023. On generalized degree
fairness in graph neural networks.(2023). In Proceedings of the 37th AAAI. 7â€“14.
[18] Zheyuan Liu, Chunhui Zhang, Yijun Tian, Erchi Zhang, Chao Huang, Yanfang
Ye, and Chuxu Zhang. 2023. Fair Graph Representation Learning via Diverse
Mixture of Experts. In The Web Conference.
[19] Zemin Liu, Wentao Zhang, Yuan Fang, Xinming Zhang, and Steven CH Hoi. 2020.
Towards locality-aware meta-learning of tail node embeddings on networks. In
Proceedings of the 29th ACM CIKM. 975â€“984.
[20] Maximillian Nickel and Douwe Kiela. 2017. PoincarÃ© embeddings for learning
hierarchical representations. NeurIPS 30 (2017).
[21] George Panagopoulos, Giannis Nikolentzos, and Michalis Vazirgiannis. 2021.
Transfer graph neural networks for pandemic forecasting. In Proceedings of the
AAAI Conference on Artificial Intelligence, Vol. 35. 4838â€“4845.
[22] Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura,
Hiroki Kanezashi, Tim Kaler, Tao Schardl, and Charles Leiserson. 2020. Evolvegcn:
Evolving graph convolutional networks for dynamic graphs. In Proceedings of
the AAAI conference on artificial intelligence, Vol. 34. 5363â€“5370.
[23] Manish Raghavan. 2021. The Societal Impacts of Algorithmic Decision-Making.
Ph. D. Dissertation. Cornell University.
[24] Tahleen Rahman, Bartlomiej Surma, Michael Backes, and Yang Zhang. 2019.
Fairwalk: towards fair graph embedding. In IJCAI. 3289â€“3295.
[25] Michael Rotman and Lior Wolf. 2021. Shuffling recurrent neural networks. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 9428â€“9435.
[26] Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. 2020.
Dysat: Deep neural representation learning on dynamic graphs via self-attention
networks. In Proceedings of the 13th international conference on WSDM. 519â€“527.
[27] Sebastian Scher, Simone Kopeinik, Andreas TrÃ¼gler, and Dominik Kowald. 2023.
Modelling the long-term fairness dynamics of data-driven targeted help on job
seekers. Scientific Reports 13, 1 (2023), 1727.
[28] Tareq Si Salem, Georgios Iosifidis, and Giovanni Neglia. 2022. Enabling long-term
fairness in dynamic resource allocation. Proceedings of the ACM on Measurementand Analysis of Computing Systems 6, 3 (2022), 1â€“36.
[29] Sean R Sinclair, Siddhartha Banerjee, and Christina Lee Yu. 2022. Sequential
fair allocation: Achieving the optimal envy-efficiency tradeoff curve. ACM
SIGMETRICS Performance Evaluation Review 50, 1 (2022), 95â€“96.
[30] Weihao Song, Yushun Dong, Ninghao Liu, and Jundong Li. 2022. Guide: Group
equality informed individual fairness in graph neural networks. In Proceedings
of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
1625â€“1634.
[31] Xiangguo Sun, Hong Cheng, Hang Dong, Bo Qiao, Si Qin, and Qingwei Lin. 2023.
Counter-Empirical Attacking based on Adversarial Reinforcement Learning for
Time-Relevant Scoring System. IEEE TKDE (2023).
[32] Xiangguo Sun, Hong Cheng, Bo Liu, Jia Li, Hongyang Chen, Guandong Xu,
and Hongzhi Yin. 2023. Self-supervised hypergraph representation learning for
sociological analysis. IEEE TKDE (2023).
[33] Haoran Tang, Shiqing Wu, Guandong Xu, and Qing Li. 2023. Dynamic graph
evolution learning for recommendation. In Proceedings of the 46th international
acm sigir conference on research and development in information retrieval. 1589â€“
1598.
[34] Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Jing Jiang, and Michael Blu-
menstein. 2020. Rethinking 1d-cnn for time series classification: A stronger
baseline. arXiv preprint arXiv:2002.10061 (2020), 1â€“7.
[35] Xianfeng Tang, Huaxiu Yao, Yiwei Sun, Yiqi Wang, Jiliang Tang, Charu Aggarwal,
Prasenjit Mitra, and Suhang Wang. 2020. Investigating and mitigating degree-
related biases in graph convoltuional networks. In ACM CIKM. 1435â€“1444.
[36] Zeyu Tang, Yatong Chen, Yang Liu, and Kun Zhang. 2023. Tier Balancing: Towards
Dynamic Fairness over Underlying Causal Factors. In International Conference
on Learning Representations (ICLR).
[37] Petar VeliÄkoviÄ‡, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
LiÃ², and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.
[38] Haohui Wang, Baoyu Jing, Kaize Ding, Yada Zhu, and Dawei Zhou. 2023. Charac-
terizing Long-Tail Categories on Graphs. arXiv preprint arXiv:2305.09938 (2023).
[39] Ruijia Wang, Xiao Wang, Chuan Shi, and Le Song. 2022. Uncovering the Struc-
tural Fairness in Graph Contrastive Learning. Advances in Neural Information
Processing Systems 35 (2022), 32465â€“32473.
[40] Xiangmeng Wang, Qian Li, Dianer Yu, Qing Li, and Guandong Xu. 2024. Re-
inforced path reasoning for counterfactual explainable recommendation. IEEE
Transactions on Knowledge and Data Engineering (2024).
[41] Yu Wang, Yuying Zhao, Yushun Dong, Huiyuan Chen, Jundong Li, and Tyler
Derr. 2022. Improving fairness in graph neural networks via mitigating sensi-
tive attribute leakage. In Proceedings of the 28th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining. 1938â€“1948.
[42] Han Wu, Jie Yin, Bala Rajaratnam, and Jianyuan Guo. 2022. Hierarchical Re-
lational Learning for Few-Shot Knowledge Graph Completion. In The Eleventh
International Conference on Learning Representations.
[43] Ke Yang and Julia Stoyanovich. 2017. Measuring fairness in ranked outputs. In
Proceedings of the 29th international conference on scientific and statistical database
management. 1â€“6.
[44] Yu Yang, Jiannong Cao, Milos Stojmenovic, Senzhang Wang, Yiran Cheng, Chun
Lum, and Zhetao Li. 2021. Time-capturing dynamic graph embedding for tempo-
ral linkage evolution. IEEE TKDE 35, 1 (2021), 958â€“971.
[45] Yu Yang, Hongzhi Yin, Jiannong Cao, Tong Chen, Quoc Viet Hung Nguyen,
Xiaofang Zhou, and Lei Chen. 2023. Time-aware dynamic graph embedding for
asynchronous structural evolution. IEEE TKDE (2023).
[46] Jiaxuan You, Tianyu Du, and Jure Leskovec. 2022. ROLAND: graph learning
framework for dynamic graphs. In Proceedings of the 28th ACM SIGKDD Confer-
ence on Knowledge Discovery and Data Mining. 2358â€“2366.
[47] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung
Nguyen. 2022. Are graph augmentations necessary? simple graph contrastive
learning for recommendation. In ACM SIGIR. 1294â€“1303.
[48] Chuxu Zhang, Huaxiu Yao, Chao Huang, Meng Jiang, Zhenhui Li, and Nitesh V
Chawla. 2020. Few-shot knowledge graph completion. In Proceedings of the AAAI
conference on artificial intelligence, Vol. 34. 3041â€“3048.
[49] Mengqi Zhang, Shu Wu, Xueli Yu, Qiang Liu, and Liang Wang. 2022. Dynamic
graph neural networks for sequential recommendation. IEEE Transactions on
Knowledge and Data Engineering 35, 5 (2022), 4741â€“4753.
[50] Hong Zhao, Shunxin Guo, and Yaojin Lin. 2021. Hierarchical classification of
data with long-tailed distributions via global and local granulation. Information
Sciences 581 (2021), 536â€“552.
[51] Matthieu Zimmer, Claire Glanois, Umer Siddique, and Paul Weng. 2021. Learning
fair policies in decentralized cooperative multi-agent reinforcement learning. In
International Conference on Machine Learning. PMLR, 12967â€“12978.
 
1710Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
APPENDIX
A AN APPLICATION OF FAIR DYNAMIC
GRAPH EMBEDDING
Learning fair embeddings for dynamic graphs is essential and has
wide real-world applications. Taking user-item recommendations
as an example, suppose we merely train a recommendation model
without considering the fairness between head (popular) and tail
(unpopular) groups of items in the long-tailed power-law distri-
bution. A handful of head (popular) items will easily dominate
the models, leading to a much higher probability of being recom-
mended than the tail (unpopular) ones. As a result, the variety of
items recommended to users is greatly reduced. Degree fair static
graph embedding solves this issue by minimizing the performance
disparity of head and tail items, making them have approximately
equal probability of being recommended. However, not all tail (un-
popular) items deserve the same recommendation probability as the
head (popular) ones. Some tail items are of poor quality and users
usually dislike them. If the model recommends these low-quality
items to users as frequently as it recommends high-quality items,
it will seriously impair the quality of service. Therefore, we ar-
gue that only a subset of high-quality tail items deserves the same
recommendation probability as the head (popular) items. These
high-quality tail items will gradually be liked by users and become
popular. In other words, they gradually move from tail to head.
This phenomenon is also observed in the Amazon Book dataset, as
the statistics of tail-to-head (T2H) vertices in Table 1 in Section 3.
Making T2H items have a similar recommendation probability as
the head ones can increase their exposure and shorten their time
to become popular. We abstract this as a structure fairness problem
in dynamic graph embedding.
B PERFORMANCE DEGRADATION OF
EXISTING STRUCTURAL FAIRNESS
METHODS IN DYNAMIC GRAPH
EMBEDDING
Given that the vertex degree of real-world graphs usually follows
a long-tailed power-law distribution, existing structural fairness
methods prevent the performance disparity of high- and low-degree
vertex groups in downstream graph mining tasks without consid-
ering the evolving trend of degree. When applying the structural
fairness methods in dynamic graph embedding, the tail-to-head
vertices will be treated as head ones. Due to the limited connection
information carried by the tail vertices, their embedding perfor-
mance is usually much worse than that of the head (including
tail-to-head) vertices and is difficult to boost. When the model min-
imizes the performance disparity between tail and head vertices to
achieve fairness, the performance of head vertices will significantly
drop close to the generally poorer embedding performance of the
tail vertices.
Our FairDGE first debiases the embeddings via contrastive learn-
ing, increasing the performance of fluctuation-at-tail (FaT) vertices
and resulting in a smaller performance gap with tail-to-head (T2H)
and starting-from-head (SfH) vertices. In addition, we eliminate
the performance disparity of T2H and SfH verticesâ€™ embeddings
in downstream tasks for a second debiasing. Notably, FaT verticesTable 6: HR@20 of existing structural fairness against trend-
aware fairness in dynamic graph embedding.
w/ Degree fairness w/Lğ‘“ğ‘ğ‘–ğ‘Ÿ
MPNN-LSTM 0.1285 0.1297
FairDGE 0.2010 0.2025
are excluded from the second debiasing so that they can pursue the
best performance in downstream tasks and avoid dragging down
the performance of T2H and SfH vertices. By making the embed-
ding performance of SfH and T2H vertices high and close while
improving the embedding performance of FaT vertices as much as
possible to narrow the gap with that of SfH and T2H, our approach
successfully achieves structure fairness without sacrificing or even
improving embedding effectiveness.
We conduct an experiment on the Amazon Books dataset to em-
pirically demonstrate the performance degradation of head (includ-
ing tail-to-head) vertices when applying existing degree fairness
methods in dynamic graph embedding. We set a degree threshold
of 4 to determine the head and tail vertices and annotate the FaT,
T2H, and SfH vertices in dynamic graphs. We first train MPNN-
LSTM [ 21], which is a dynamic graph embedding method, and
FairDGE on head- and tail-degree vertex groups and report the
HR@20 scores in the column of w/ Degree fairness in Table 6. Next,
we train MPNN-LSTM and FairDGE with our designed fairness
lossLğ‘“ğ‘ğ‘–ğ‘Ÿin Eq. (10) on FaT, T2H, and SfH groups. The HR@20
scores are shown in the column of w/ Lğ‘“ğ‘ğ‘–ğ‘Ÿin Table 6. The HR@20
scores of both MPNN-LSTM and FairDGE with traditional degree
fairness are lower than that of using our proposed fairness approach
which considers the evolving trend of degrees in the dynamic graph.
This validates the performance degradation when applying existing
structural fairness methods in dynamic graph embedding.
C SYMBOL DESCRIPTIONS
Table 7 is the symbol description used in this manuscript.
Table 7: Symbol descriptions.
Symb
ols Descriptions
Gğ‘¡=(
Vğ‘¡,Eğ‘¡)Static
snapshot graph, vertex set, edge set at time ğ‘¡
G=(V,E) D
ynamic graph, vertex set, edge set
â„âˆˆH A
representation vector (embedding)
Hğ‘‡2ğ»
VT
ail-to-head vertex representations
Hğ‘†ğ‘“ğ»
VStarting-fr
om-head vertex representations
ğ‘¡âˆˆğ‘‡ Timestamps
ğ‘ The
number of vertex groups
ğ‘‘ğ‘–ğ‘š Repr
esentation dimensions
âŠ• Stack
operator
ğœ› Head/tail
ratio threshold
ğ‘‘(Â·) Short-term
trend encoder
Ë†ğ‘‘(Â·) Long-term
trend encoder
ğ‘‘ğ‘’ğ‘”(Â·) Degr
ee of vertex
ğ‘¦âˆˆğ‘Œ Lab
els of biased structural evolution
(ğ‘£,ğ‘£+) Positiv
e vertex pair from same structural evolution group
(ğ‘£,ğ‘£âˆ’) Negativ
e vertex pair from different structural evolution groups
Lğ‘ğ‘™ğ‘ğ‘ ğ‘  Classification
loss
Lğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘ ğ‘¡ Contrastiv
e loss
Lğ·ğ‘† Do
wnstream task loss
Lğ‘“ğ‘ğ‘–ğ‘Ÿ Fairness
loss
ğ›¾1,ğ›¾2,ğ›¾3,ğ›¾4 Loss
hyperparameters
||Î˜||1,||Î˜||2â„“1,â„“2norm
of model parameters
ğ‘ğ‘’ Pr
obability of edge ğ‘’existing
ğ‘˜ T
opğ‘˜prediction list
 
1711KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Yicong Li et al.
D ANNOTATING ALGORITHM FOR FAT, T2H,
AND SFH
We devise a slope-based algorithm in Algorithm 1, identifying the
degree evolving trend to annotate FaT, T2H, and SfH. ğœŒis set to 0
in our experiments.
Algorithm 1 Slope-based Annotation Algorithm
Input: Vertex setV, timestamp range ğ‘‡, head/tail ratio threshold ğœ›, degree
variation threshold ğœŒ.
Output: Label setğ‘ŒforV, whereğ‘¦âˆˆ{ğ¹ğ‘ğ‘‡,ğ‘‡ 2ğ»,ğ‘†ğ‘“ğ»}is the label of
structural evolution for vertex ğ‘£âˆˆğ‘‰.
head_num =|V|Ã—ğœ›
head_group = sort(deg( V))[:head_num]
forvertexğ‘£inVdo
ifğ‘£ğ‘¡in head_group then
ğ‘¦ğ‘£=ğ‘†ğ‘“ğ» ;
else
ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥(ğ‘‘ğ‘’ğ‘”(ğ‘£ğ‘‡))//Find the time when ğ‘£has the biggest degree;
ğ‘ğ‘Ÿğ‘”ğ‘šğ‘–ğ‘›(ğ‘‘ğ‘’ğ‘”(ğ‘£ğ‘‡))//Find the time when ğ‘£has the smallest de-
gree;
ifğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥(ğ‘‘ğ‘’ğ‘”(ğ‘£ğ‘‡))âˆ’ğ‘ğ‘Ÿğ‘”ğ‘šğ‘–ğ‘›(ğ‘‘ğ‘’ğ‘”(ğ‘£ğ‘‡))>ğœŒthen
ğ‘¦ğ‘£=ğ‘‡2ğ»;
else
ğ‘¦ğ‘£=ğ¹ğ‘ğ‘‡;
end if
end if
end for
returnğ‘Œ
E EXPERIMENTS
E.1 Experiment Configurations and
Implementation Details
To ease reproductivity, we provide the experiment configurations
and implementation details of FairDGE.
For all fair graph learning baselines, including FairGNN, Fair-
VGNN, DegFairGNN, and TailGNN, we adopted the source code
released by the authors in GitHub and incorporated them into our
code framework. The GCN and GAT models are implemented by
theHGCN [4] framework, and the Euclidean space version is used.
For MPNN-LSTM and EvolveGCN, we adopted the implementation
in the PyTorch Geometric Temporal library. The hidden layer version
of EvolveGCN is used in the experiments. The default parameters
are employed for all baseline methods, but we tune the learning
rate for each baseline to get the best results.
Our proposed method, FairDGE, is implemented by PyTorch. The
learning rate is set to 5e-4 after parameter searching. The model
dimensions are set the same for FairDGE and all baselines, enabling
a fair comparison. The number of GNN layers in FairDGE is set
to 2. In addition to benchmarking the performance of FairDGE
against the original version of the baselines, we added our fair
lossLğ‘“ğ‘ğ‘–ğ‘Ÿto each baseline and further validated the effectiveness
of the fair loss. FairGNN and FairVGNN train a discriminator to
eliminate the performance diversity between the advantaged and
disadvantaged sensitive group of vertices. We align their methods
to train the discriminator for SfH, T2H, and FaT. Since DegFairGNNTable 8: Different loss hyperparameters.
Performance
(â†‘) Fairness
(â†“)
HR@20 NDCG@20 PREC@20 rHR rND
ğ›¾1(
Lğ·ğ‘†)0.25 0.2025 0.0903 0.0101 0.1489 0.2075
0.75 0.2037 0.0911 0.0102 0.1545 0.2548
2.5 0.2188 0.1009 0.0109 0.1548 0.2610
ğ›¾2(
Lğ¶ğ‘™ğ‘ğ‘ ğ‘ )0.25 0.2025 0.0903 0.0101 0.1489 0.2075
0.75 0.2077 0.0928 0.0104 0.1548 0.2627
2.5 0.2203 0.1013 0.0110 0.1537 0.2472
ğ›¾3(
Lğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘ ğ‘¡)0.25 0.2025 0.0903 0.0101 0.1489 0.2075
0.75 0.2052 0.0915 0.0103 0.1541 0.2551
2.5 0.2181 0.1038 0.0109 0.1561 0.2711
ğ›¾4(
Lğ‘“ğ‘ğ‘–ğ‘Ÿ)0.25 0.2025 0.0903 0.0101 0.1489 0.2075
0.75 0.2198 0.1019 0.0110 0.1543 0.2551
2.5 0.2205 0.1004 0.0110 0.1535 0.2447
and TailGNN We use each userâ€™s last interacted item in both datasets
as the test data.
E.2 Additional Hyperparameter Study
Additional hyperparameter testing on loss hyperparameters is pre-
sented in this section. The results reported in Table 8 test the impact
of different loss hyperparameters ğ›¾1,ğ›¾2,ğ›¾3,ğ›¾4in Eq. (12) on the per-
formance and fairness scores on the Amazon Book dataset. Specifi-
cally, we respectively tune ğ›¾1,ğ›¾2,ğ›¾3, andğ›¾4from{0.25,0.75,2.5}.
At each round, we only tune one and fix the remaining three to
0.25. For example, when tuning ğ›¾1from{0.25,0.75,2.5}, we fix
ğ›¾2=ğ›¾3=ğ›¾4=0.25. Results in Table 8 demonstrate that FairDGE is
not sensitive to ğ›¾on both performance and fairness. When all the
ğ›¾are 0.25, the results are the best on the fairness score.
F COMPLEXITY ANALYSIS
FairDGE consists of two modules, i.e., trend-aware structural evo-
lution learning and dual debiasing for encoding structurally fair
embeddings. We analyze the computational complexity of each
module, respectively.
Trend-aware structural evolution learning consists of long-short-
term degree trend encoding, structural evolution embedding, and a
bias classification task. The computational complexity is ğ‘‚(ğ‘šğ‘ğ‘¥(ğ¿Â·
|V|2,|ğ‘‡|Â·ğ‘‘ğ‘–ğ‘š2
â„ğ‘–ğ‘‘+|ğ‘‡|Â·ğ‘‘ğ‘–ğ‘šâ„ğ‘–ğ‘‘Â·ğ‘‘ğ‘–ğ‘š))according to [ 3,25].|V|
is the number of vertices, ğ¿is the number of GNN layers, |ğ‘‡|is
the number of snapshots of the dynamic graph G,ğ‘‘ğ‘–ğ‘šâ„ğ‘–ğ‘‘is the
hidden dimension of GRU and ğ‘‘ğ‘–ğ‘š is the representation dimension
of our model. Since |ğ‘‡| â‰ª |V| andğ¿â‰ª |V| , the overall com-
plexity of trend-aware structural evolution learning is ğ‘‚(|V|2),
approximately.
In the dual debiasing module, contrastive learning with nega-
tive sampling is first employed. Its computational complexity is
ğ‘‚(|V|2). The complexity of the followed fairness loss and the link
prediction task are both ğ‘‚(|E|) . Therefore, the complexity of the
dual debiasing module is ğ‘‚(ğ‘šğ‘ğ‘¥(|V|2,|E|)) .
Since the FairDGE trained in end-to-end manner, the overall
computational complexity is ğ‘‚(ğ‘šğ‘ğ‘¥(|V|2,|E|)) .
 
1712