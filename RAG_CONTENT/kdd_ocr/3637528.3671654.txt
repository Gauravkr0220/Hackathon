Text Matching Indexers in Taobao Search
Sen Liâˆ—
Alibaba Group
Hangzhou, China
lisen.lisen@taobao.comFuyu Lv
Alibaba Group
Hangzhou, China
fuyu.lfy@taobao.comRuqing Zhang
CAS Key Lab of Network Data
Science and Technology, ICT, CAS
Beijing, China
zhangruqing@ict.ac.cn
Dan Ou
Alibaba Group
Hangzhou, China
oudan.od@taobao.comZhixuan Zhang
Alibaba Group
Hangzhou, China
zhibing.zzx@taobao.comMaarten de Rijke
University of Amsterdam
Amsterdam, The Netherlands
m.derijke@uva.nl
ABSTRACT
Product search is an important service on Taobao, the largest e-
commerce platform in China. Through this service, users can easily
find products relevant to their specific needs. Coping with billion-
size query loads, Taobao product search has traditionally relied
on classical term-based retrieval models due to their powerful and
interpretable indexes. In essence, efficient retrieval hinges on the
proper storage of the inverted index. Recent successes involve re-
ducing the size (pruning) of the inverted index but the construction
and deployment of lossless static index pruning in practical product
search still pose non-trivial challenges.
In this work, we introduce a novel SMart INDexing ( SMIND )
solution in Taobao product search. SMIND is designed to reduce
information loss during the static pruning process by incorporating
user search preferences. Specifically, we first construct â€œuser-query-
itemâ€ hypergraphs for four different search preferences, namely
purchase, click, exposure, and relevance. Then, we develop an effi-
cient TermRank algorithm applied to these hypergraphs, to preserve
relevant items based on specific user preferences during the pruning
of the inverted indexer. Our approach offers fresh insights into the
field of product search, emphasizing that term dependencies in user
search preferences go beyond mere text relevance. Moreover, to
address the vocabulary mismatch problem inherent in term-based
models, we also incorporate an multi-granularity semantic retrieval
model to facilitate semantic matching. Empirical results from both
offline evaluation and online A/B tests showcase the superiority
ofSMIND over state-of-the-art methods, especially in commerce
metrics with significant improvements of 1.34% in Pay Order Count
and 1.50% in Gross Merchandise Value. Besides, SMIND effectively
mitigates the Matthew effect of user queries and has been in service
for hundreds of millions of daily users since November 2022.
âˆ—Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671654CCS CONCEPTS
â€¢Information systems â†’Top-k retrieval in databases.
KEYWORDS
Product search, Static pruning inverted index, Semantic matching
ACM Reference Format:
Sen Li, Fuyu Lv, Ruqing Zhang, Dan Ou, Zhixuan Zhang, and Maarten de
Rijke. 2024. Text Matching Indexers in Taobao Search. In Proceedings of the
30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3637528.3671654
1 INTRODUCTION
E-commerce platforms like Amazon and Taobao have become part
of peopleâ€™s daily lives. In Taobao, the product search engine serves
hundreds of millions of users, by providing the top- ğ‘˜personal-
ized relevant items from billion-scale candidate products, within
hundreds of milliseconds. The classic industry product search archi-
tecture, known as â€œindex-retrieval-prerank-rank-rerank," includes
three sequential steps: (1) indexing: to build an index for each item
in the corpus; (2) retrieval: to retrieve an initial set of candidate
items for a user query; and (3) prerank-rank-rerank: to calculate
a personalized relevance score of each candidate. Of these, the in-
dexing and retrieval stages are pivotal as they determine the upper
bounds of the search performance.
To handle billions of queries and products, Taobao predominantly
employs classical term-based matching techniques, emphasizing
interpretability andhigh search relevance. Specifically, in indexing,
we construct traditional inverted indexes for the text of each item.
During retrieval, we integrate the rewritten query [ 22] with the
original user query to mitigate vocabulary mismatches [ 32,39,51].
Subsequently, we perform exact matching between the query and
the items. To return all matched candidates, a popular method is
to employ a dynamic index pruning scheme [ 3,14]. However, in
practical scenarios, this approach can prove to be time, storage,
and computation-intensive. This is especially significant in Taobao
product search, where a substantial portion of latency is dedicated
to the â€œprerank-rank-rerankâ€ phase for personalization modeling.
Additionally, users tend to focus on a limited number of top- ğ‘˜items
for a query and often issue a new query if the initial results fail to
meet their expectations.
5339
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Sen Li et al.
Hence, in Taobao product search, a lightweight static pruning
inverted index scheme [ 3,4,38], a.k.a. static term-based pruning,
is widely employed, saving 50% of system resource. This scheme
comprises two parts: the pruned inverted index, denoted as ğ¼ğ‘ƒ, and
the full inverted index, denoted as ğ¼ğ¹.ğ¼ğ‘ƒconsists of the posting lists
(an occurrence of a term within the text an item is called a posting)
for each term but truncated with a given length, while ğ¼ğ¹is the
regular full posting lists. A common practice for pruning a posting
list is to consider term dependencies related to textual relevance.
In web search, Carmel et al . [4] proposed using the TF-IDF scoring
functionğ‘“(ğ‘¡,ğ‘–)to preserve the textually most relevant items for
reducing the truncation loss of each term. DeepCT [ 8], SPARTA [ 50],
and SPLADE [ 15,16], are recently proposed methods to provide
contextualized term dependencies of text relevance signal.
However, pruning based on the general textual relevance term
dependencies is not sufficient for product search. To elaborate,
many merchants employ search engine optimization (a.k.a. SEO) to
increase their visibility by using relevant and popular keywords to
describe their products . This practice, in turn, diminishes the effi-
cacy of textual relevance. Additionally, existing work overlooks the
term dependencies of User Search Preferences (USP), as discussed
in Section 4.5.4 and 4.5.5. This oversight results in the incapacity to
explicitly retain user-preferred items within the truncated postings
lists. Through an analysis of user logs, we found that the majority
of users made purchases based on specific query terms. To illustrate,
consider an item titled â€œ è•¾ä¸è–„æ¬¾è¿è¡£è£™ (Self-portrait Lace Thin
Dress).â€ Users did not click or purchase it with the textual relevant
term â€œè–„æ¬¾ (thin),â€ but with combinations of the remaining terms.
This phenomenon highlights the existence of higher-order term-
item dependencies within USP, transcending mere text relevance.
These higher-order term dependencies not only assist in mitigating
SEO practices by excluding certain textually relevant terms often
added by merchants, but also have the potential to minimize in-
formation loss by retaining user-preferred items. However, how
to explicitly capture and incorporate these dependencies into the
static pruning process while mitigating the noise inherent in user
logs, remains relatively unexplored.
Therefore, in this paper, we propose an efficient billion-scale
product search indexing solution, named SMart INDexing ( SMIND ).
The key idea is to minimize information loss during the static in-
verted index pruning process, by incorporating higher-order term
dependencies from user search preferences. Concretely, we first
investigate the user search process and define four basic prefer-
ence patterns, namely purchase, click, exposure, and relevance
preference pattern. Subsequently, we utilize extensive user logs
and employ ternary â€œuser-query-item (ğ‘¢,ğ‘,ğ‘–)â€ interactions to build
four hypergraphs [ 7], i.e., user search purchase, click, exposure,
and relevance preferences hypergraphs. We then decompose each
hypergraph(ğ‘¢,ğ‘,ğ‘–)into a term-level one (ğ‘¢,ğ‘ğ‘¡,ğ‘–ğ‘¡)by representing
the vertex of query ğ‘and itemğ‘–with their text terms. Then, we
devise an efficient TermRank algorithm to explicitly capture the
higher-order term-item dependencies within USP. Finally, during
the static pruning process, to alleviate the inherent noise in user
behavior, we formulate a user-aware term scoring function ğ‘“(ğ‘¡,ğ‘–)
by considering both the term dependencies within USP and an addi-
tional query-independent item quality factor, to rank items within
the postings lists and preserve the top items.Given the diverse nature of user demands, it is intractable for
query rewriting to address the vocabulary mismatch problem on its
own. For instance, when a user enters a query like â€œ è¡£æœ(clothes), â€
they may actually intend to purchase a â€œ è¿è¡£è£™ (dress).â€ Addition-
ally, the inconsistent contextual alignment between the query and
the item can lead to variations in the Chinese tokenization of the
same text. This may adversely affect the performance of both the
original user queries and their rewritten counterparts. To this end,
we further incorporate a multi-grained semantic neural retrieval
model to facilitate fine-grained contextualized interactions between
query and item representations. It is combined with the original user
queries and their rewritten versions to enhance semantic matching
capabilities, thereby improving recall for potentially missed items.
To the best of our knowledge, SMIND is the first solution to ex-
plore the use of term dependencies in user search preferences for
pruning inverted indexes, and effectively combines query rewriting
with an exact and fuzzy match indexer. The effectiveness of SMIND
is verified by extensive offline qualitative and quantitative analyses,
and large-scale online A/B tests. We observed that for torso and
tail queries, SMIND enables text matching indexers to deliver high-
quality items aligned with user search intentions. This prevents
users from shifting their queries to top queries, thereby alleviating
the Matthew effect [36] of user queries.
The main contributions of this work are as follows:
(1)We introduce SMIND , an efficient and effective billion-scale
product search indexing solution that includes a user search
preferences-aware pruning inverted indexer and a semantic
indexer, to enable the retrieval of relevant, high-quality items.
(2)We conduct a term-level analysis of multiple user search pref-
erences, represented as (ğ‘¢,ğ‘ğ‘¡,ğ‘–ğ‘¡)hypergraphs, which are em-
ployed to prune inverted indexes and bridge the gap between
user queries and pruned inverted indexes.
(3) We offer new insights that user search preferences encompass
higher-order term dependencies beyond text relevance.
(4)We evaluate SMIND â€™s performance through comprehensive of-
fline qualitative and quantitative analyses, as well as large-scale
online A/B tests conducted on Taobao Product Search.
2 RELATED WORK
2.1 Inverted Indexer
In a typical search engine efficient text/product retrieval is achieved
through the use of an inverted index structure [ 51], which asso-
ciates terms with relevant documents in the collection. For each
term in the document collection, a posting list of documents is
stored. The index file grows with increases in the size of the doc-
ument collection, which is problematic for fast and inexpensive
query evaluation in an online system [ 26]. Thus, effective prun-
ing techniques are needed to reduce the size of inverted indexes.
Such techniques generally fall into two categories, i.e., dynamic
and static. Dynamic pruning [ 3,11,14,41] decides, during query
evaluation, whether certain terms or document postings should be
included in the ranked list, until some stopping condition is met.
Static techniques [ 4,26,34,38] remove terms or items from the
full index in advance to take advantage of a two-tiered index. The
small, yet effective index that is left is called the pruned index. Static
and dynamic pruning techniques can complement each other, since
5340Text Matching Indexers in Taobao Search KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
searching the pruned index can be accelerated by dynamic pruning
for a specific query. Panigrahi and Gollapudi [35] exploit the struc-
tural characteristics of commerce search queries (i.e., from users
searching for products on the web) for the selection of documents,
which relies on manual labelling data to structure queries.
Our work focuses on static term-based index pruning at the
posting-level. It removes items from each term whose contribution
is so small that their removal has a minor impact on the retrieval
system. Carmel et al . [4] examine an idealized term-based pruning
algorithm. The score of a term for a document is formulated by term
dependencies of text relevance, i.e., TF-IDF [ 37] scoring function.
The pruned index has been proved, to some extent, to provide
results that are almost as good as search results derived from the
full index. Recently, learned sparse representation methods such as
DeepCT [ 8], SPARTA [ 50], and SPLADE [ 15,16], are being used to
provide contextualized term dependencies of text relevance signal.
However, they have been shown to frequently assign suboptimal
weights to terms [ 28,29,31], which may degrade search relevance
as we show below.
Long and Suel [26] propose to integrate global linked-based
ranking (e.g., PageRank [ 2]) and term-based text relevance ranking
as the final term-doc scoring function. Two optimized pruning
techniques, namely keyword-based and document-based pruning,
are studied by Ntoulas and Cho [34] to avoid any degradation
of result quality. Rossi et al . [38] combine the dynamic pruning
technique BMW [ 11] and a static two-tiered index (the pruned and
full index) to accelerate query evaluation.
To the best of our knowledge, existing studies into index prun-
ing are conducted primarily in the context of web search, where
text relevance and hyperlink analysis are key to the final term-
doc scoring function for pruning the postings lists. However, this
is far from sufficient in a product search setting. How to exploit
higher-order term dependencies of User Search Preferences (USP)
for pruning while mitigating the noise inherent in user logs has
not been addressed. Apart from using the term dependencies of
USP from user click logs to reduce the size of inverted index, there
are many graph-based dense retrieval works of modeling user click
logs [ 7,13,33]. However, they have difficulties in learning exact
matching signals, and thus tend to return irrelevant results when
users search for exact queries [6, 23].
2.2 Semantic Indexer
There is a rich literature [ 19,40,48] on capturing the semantics of
queries and documents for the first-stage retrieval. For an overview,
we refer to [17]. Building on this work, several large-scale deploy-
ments of semantic search systems have been reported. Nigam et al .
[32, Amazon ]develop a two-tower model to address the vocabu-
lary mismatch of a lexical matching engine. One side uses n-gram
query features and the other side exploits item features. Chang
et al. [5, Amazon ]use a tree-based extreme multi-label classifica-
tion model to improve inference latency. Huang et al . [18, Meta ]
describe their embedding-based retrieval system integrated with
term matching-based retrieval, which considers query texts and
searchersâ€™ context factors together. Liu et al . [25, Meta ]and Yu
et al. [47, Meta ]apply multi-modal learning and pre-training tech-
niques to their social product search. Also using pre-training, Liu
et al. [24, Baidu ]develop a retrieval model based on ERNIE [ 42],a state-of-the-art Chinese pre-training model. Recently, Magnani
et al. [30, Walmart ]have presented a hybrid retrieval system for
e-commerce retail search. They combine the full inverted index and
an embedding-based neural retrieval to better serve the traffic of tail
queries. However, the search setting of Walmart is relatively small,
withe million-scale query loads and a small collection of items.
With billion-scale products, the search scenario requires careful
trade-offs between efficiency and various cost factors. Below, we
discuss the billion-scale product search indexing solution in Taobao
Product Search.
3 PROPOSED METHOD
Here, we will detail the user search preferences-aware pruned in-
verted indexer and semantic indexer of SMIND shown in Figure 1,
respectively. The retrieval process is illustrated in Section B.1 of the
Appendix. For notation, let ğ‘ˆ={ğ‘¢1,...,ğ‘¢ğ‘}be a set ofğ‘users,
ğ‘„={ğ‘1,...,ğ‘ğ¿}the user queries, ğ¼={ğ‘–1,...,ğ‘–ğ‘€}a collection of
items, andğ‘‡={ğ‘¡1,...,ğ‘¡ğ¾}the unique terms of collection ğ¼. See
Section A of the Appendix for the problem definition.
3.1 User Search Preferences-Aware Pruned
Inverted Indexer
In this section, we study how to improve the static term-based
pruning by using higher-order term dependencies of user search
preference patterns USP and query-independent item quality fac-
torğ‘„. First, we construct four term-level ternary â€œuser-query-item
(ğ‘¢,ğ‘,ğ‘–)â€ interactions hypergraphs based on four basic patterns.
Then, we develop an efficient TermRank algorithm to capture mul-
tiple term dependencies of USP patterns. Finally, we integrate the
term dependencies of USP and ğ‘„into the final term-based scoring
function for pruning the posting lists of each term.
3.1.1 HyperGraph Construction. A hypergraph is a more general
topological structure than a bipartite graph, where an edge connects
two or more nodes, named hyperedge. Given some ternary (ğ‘¢,ğ‘,ğ‘–)
interactions, it is intractable to construct a simple graph to preserve
ternary relations [ 7], and we have a hypergraph ğº=(ğ‘‰,ğ¸)includ-
ing: (1) a node set ğ‘‰whose elements represent a user, query, item
(i.e.,ğ‘‰=ğ‘ˆâˆªğ‘„âˆªğ¼); and (2) a hyperedge set ğ¸whose elements rep-
resent a ternary relation depicting the existence of an interaction
among them. We construct multiple hypergraphs ğºfrom user logs
based on the defined patterns ğ‘“among ternary(ğ‘¢,ğ‘,ğ‘–), i.e.,
ğº=ğ‘“(ğ‘¢,ğ‘,ğ‘–), (1)
whereğ‘“establishes the hyperedge among (ğ‘¢,ğ‘,ğ‘–)according to a
certain pattern, as follows:
ğºğ‘ğ‘¢ğ‘Ÿ/ğºğ‘ğ‘™ğ‘˜/ğºğ‘’ğ‘¥ğ‘ğ‘œ for the user purchase/click/exposure prefer-
ence pattern ğ‘“ğ‘ğ‘¢ğ‘Ÿ/ğ‘“ğ‘ğ‘™ğ‘˜/ğ‘“ğ‘’ğ‘¥ğ‘ğ‘œ, each hyperedge represents how a user
initiates a query and then purchases/clicks/sees an item.
ğºğ‘Ÿğ‘’ğ‘™for the user relevance pattern ğ‘“ğ‘Ÿğ‘’ğ‘™, each hyperedge repre-
sents a relevant relation among (ğ‘¢,ğ‘,ğ‘–), whereğ‘–is an item, in the
rank phase of search system, is associated with a user and query.
Term-Level Decomposition. Becauseğºdescribe USP patterns at
the node-level(ğ‘¢,ğ‘,ğ‘–)rather than the term-level, we further decom-
pose each node into the term-level by replacing ğ‘‰â€™s query and item
elements with their terms ğ‘ğ‘¡andğ‘–ğ‘¡, i.e., for a query ğ‘2(Figure 2(b))
5341KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Sen Li et al.
Query Rewriting ModuleQuery PlannerQuery(Query, Rewrites)SMINDSemantic IndexerQueryMultiple Granularities LayerTransformer_EncoderItemItem TowerSampled SoftmaxEmbeddingEmbedding.CosineTerm1TermNANDOR
USP-aware Pruned/Full Inverted Index
Inverted IndexerQuery Evaluationâ€¦â€¦
Term-level User Search PerferencesShortest  Posting List PrincipleANDTerm1TermNQueryRewritten QueryIndexing
Figure 1: General structure of the proposed large-scale Smart Indexing ( SMIND ) hybrid indexer solution and its combinations of
query rewriting technique.
u1u2q1q2i1i2u3i3e2e3e1e4
(a)Hypergraph
q2t1i3t1i2t1u1u2q1t1u3e2e3e1i1t1i1t2q2t2e4 (b)Term-Level Hypergraph
q2t1i3t1i2t1u1u2q1t1u3e2e3e1i1t1i1t2q2t2e4 (c)TermRank
Figure 2: Given four interactions (ğ‘¢1,ğ‘1,ğ‘–1),(ğ‘¢2,ğ‘1,ğ‘–2),
(ğ‘¢2,ğ‘2,ğ‘–3)and(ğ‘¢3,ğ‘2,ğ‘–2). (a) A sample of hypergraph whose
hyperedge ğ‘’ğ‘–(ğ‘–=1,2,3,4)is a user-query-item interaction; (b)
Assuming ğ‘1={ğ‘¡1},ğ‘2={ğ‘¡1,ğ‘¡2},ğ‘–1={ğ‘¡1,ğ‘¡2},ğ‘–2={ğ‘¡1},ğ‘–3={ğ‘¡1}, we
decompose (a) into term-level; (c) Assuming ğ‘1ğ‘¡1=ğ‘–1ğ‘¡1=ğ‘–2ğ‘¡1=ğ‘2ğ‘¡2,
ğ‘2ğ‘¡1=ğ‘–3ğ‘¡1, we create value flow based on each term-level hy-
peredge(ğ‘¢,ğ‘ğ‘¡,ğ‘–ğ‘¡).
with two terms{ğ‘¡1,ğ‘¡2}, then the element is ğ‘2ğ‘¡1,ğ‘2ğ‘¡2instead of the
whole query ğ‘2. We do the same on the item side.
Now, the hyperedge is able to describe the exact term match
between the user queries and item titles. For each ternary (ğ‘¢,ğ‘,ğ‘–)
interaction, we iterate over the combinations of terms in query and
item and then establish a hyperedge (ğ‘¢,ğ‘ğ‘¡,ğ‘–ğ‘¡)if and only if their
terms are the same. Considering an interaction of ( ğ‘¢1,ğ‘1={ğ‘¡1},
ğ‘–1={ğ‘¡1,ğ‘¡2}), there will be two candidates (i.e., ( ğ‘¢1,ğ‘1ğ‘¡1,ğ‘–1ğ‘¡1) and
(ğ‘¢1,ğ‘1ğ‘¡1,ğ‘–1ğ‘¡2)). Assuming ğ‘1ğ‘¡1=ğ‘–1ğ‘¡1, we then establish a term-level
hyperedge ( ğ‘¢1,ğ‘1ğ‘¡1,ğ‘–1ğ‘¡1) as in Figure 2(b).
So far, we have constructed a term-level hypergraph G=(V,E)
including: (1) a node set Vwhose element represents ğ‘¢,ğ‘ğ‘¡,ğ‘–ğ‘¡;
and (2) a hyperedge set Ewhose element represents a ternary
relation ofğ‘¢-ğ‘ğ‘¡-ğ‘–ğ‘¡depicting how a user interacts with item via the
termğ‘¡. Obviously,Gdescribes what terms users prefer to use to
interact with an item, which is exactly the higher-order term-item
dependencies of USP. We apply the above term-level decomposition
process to four user search hypergraphs ğºğ‘ğ‘¢ğ‘Ÿ,ğºğ‘ğ‘™ğ‘˜,ğºğ‘’ğ‘¥ğ‘ğ‘œ, andğºğ‘Ÿğ‘’ğ‘™,
obtaining term-level hypergraphs Gğ‘ğ‘¢ğ‘Ÿ,Gğ‘ğ‘™ğ‘˜,Gğ‘’ğ‘¥ğ‘ğ‘œ, andGğ‘Ÿğ‘’ğ‘™.
3.1.2 TermRank. We introduce an efficient TermRank algorithm
to capture the term-item dependencies of USP from every G. First,
we transform the undirected graph Ginto a directed one. As shown
in Figure 2(c), for each hyperedge ( ğ‘¢,ğ‘ğ‘¡,ğ‘–ğ‘¡) ofG, we create a bidi-
rectional connection between ğ‘ğ‘¡andğ‘–ğ‘¡nodes (i.e.,ğ‘ğ‘¡â†”ğ‘–ğ‘¡), while
forğ‘¢andğ‘ğ‘¡nodes we only link a one-way edge (i.e., ğ‘¢â†’ğ‘ğ‘¡). As-
suming there is a value for each node, we then generate a directed
graph where values flow between nodes following hyperedge ğ‘’.
The idea is to obtain node ğ‘–ğ‘¡â€™s value because it describes how much
users prefer to use the term ğ‘¡to interact with item ğ‘–, i.e., term-itemdependencies of USP. The values of ğ‘–ğ‘¡andğ‘ğ‘¡are calculated by:
ğ‘£(ğ‘–ğ‘¡)=Ã
ğ‘’âˆˆEğ‘–ğ‘¡ğ‘£(ğ‘ğ‘¡)Â·ğ‘£(ğ‘¢)
Ã
ğ‘¡âˆˆğ‘–ğ‘£(ğ‘–ğ‘¡), (2)
ğ‘£(ğ‘ğ‘¡)=Ã
ğ‘’âˆˆEğ‘ğ‘¡ğ‘£(ğ‘–ğ‘¡)Â·ğ›¼ğ‘–Ã
ğ‘¡âˆˆğ‘ğ‘£(ğ‘ğ‘¡), (3)
whereğ‘£(Â·)is the value function. Eğ‘–ğ‘¡andEğ‘ğ‘¡denote the set of
hyperedges containing ğ‘–ğ‘¡andğ‘ğ‘¡, respectively. Empirically, ğ‘£(ğ‘¢)and
ğ›¼ğ‘–are the normalized values of the user ğ‘¢â€™s search times and item ğ‘–
exposure times. The denominator in Eqn. (2) and (3) normalizes the
values of all terms within an item/query for numerical stability.
Eqn. (2) and (3) are an alternate iterative process, which is de-
noted as the TermRank algorithm. However, since Gis a non-
strongly connected graph, when TermRank converges, the value
will accumulate to some hot attribute terms (e.g., brand/category
terms). This is not helpful to prune the postings lists. Therefore,
we set the number of iterations as a hyper-parameter. Finally, we
apply TermRank on four term-level hypergraphs Gğ‘ğ‘¢ğ‘Ÿ,Gğ‘ğ‘™ğ‘˜,Gğ‘’ğ‘¥ğ‘ğ‘œ,
Gğ‘Ÿğ‘’ğ‘™, obtaining term dependencies of user search purchase/click-
/exposure/relevance preferences of each node ğ‘–ğ‘¡, i.e.,Gğ‘ğ‘¢ğ‘Ÿ_ğ‘£(ğ‘–ğ‘¡),
Gğ‘ğ‘™ğ‘˜_ğ‘£(ğ‘–ğ‘¡),Gğ‘’ğ‘¥ğ‘ğ‘œ_ğ‘£(ğ‘–ğ‘¡),Gğ‘Ÿğ‘’ğ‘™_ğ‘£(ğ‘–ğ‘¡).
3.1.3 Integrating Term Dependencies of USP and Item Quality Factor
Q.The term dependencies of USP show which terms users prefer to
use to interact with items. There is some amount of noise inherent
in user logs [ 22,23], making the user search preference-aware trun-
cated posting lists less effective. To this end, we further include an
item quality factor ğ‘„into the final ğ‘“(ğ‘¡,ğ‘–)score function. Although
PageRank is popularly used to measure the quality of web sources,
it is not applied in e-commerce setting for items are considered to be
independent objects. We use the historical trading volume of each
item as a quality factor ğ‘„. Intuitively, the more transactions, the
better the item quality. Given a term ğ‘¡, we construct a user-aware
scoring function ğ‘“(ğ‘¡,ğ‘–), by mixing the term dependencies of USP
and a query-independent item quality factor Q, to truncate its full
posting lists ğ¼ğ‘¡_ğ‘“to a given length. Mathematically,
ğ‘¡_ğ‘–ğ‘ˆğ‘†ğ‘ƒ=Gğ‘ğ‘¢ğ‘Ÿ_ğ‘£(ğ‘–ğ‘¡)+Gğ‘ğ‘™ğ‘˜_ğ‘£(ğ‘–ğ‘¡)+Gğ‘’ğ‘¥ğ‘ğ‘œ_ğ‘£(ğ‘–ğ‘¡)+Gğ‘Ÿğ‘’ğ‘™_ğ‘£(ğ‘–ğ‘¡)(4)
ğ‘“(ğ‘¡,ğ‘–)=ğ‘¡_ğ‘–ğ‘ˆğ‘†ğ‘ƒÂ·ğ‘–ğ‘„, (5)
whereğ‘¡_ğ‘–ğ‘ˆğ‘†ğ‘ƒ andğ‘–ğ‘„denote the mixed USP score between the
termğ‘¡and the item ğ‘–, and the item ğ‘–â€™s quality, respectively. For
convenience, we use IVI-USP-Q to refer the pruned InVerted Index
based on USP and Q.
5342Text Matching Indexers in Taobao Search KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
3.2 Semantic Indexer
In this section, we introduce the semantic dense indexer to reduce
the mismatch between user queries and item. We will present query
tower, item tower and loss function, respectively.
3.2.1 Query Tower. Queries in Taobao product search are mainly
Chinese, which poses two challenge: (1) Because the context of
query and item are different, the Chinese tokenization of the same
text could be different; and (2) user queries are quite short. We train
a two-tower semantic indexer and represent the queries in multiple
semantic granularities to enrich its representations.
Multiple Granularities Layer. Specifically, for a query â€œ çº¢è‰²è¿è¡£
è£™, â€ we represent it as uni-gram {ğ‘1,...,ğ‘ğ‘š}({çº¢,è‰²,è¿,è¡£,è£™}), bi-
gram{ğ‘1ğ‘2,...,ğ‘ğ‘šâˆ’1ğ‘ğ‘š}({çº¢è‰² ,è‰²è¿ ,è¿è¡£ ,è¡£è£™ }), and semantic
word segmentation {ğ‘¡1,...,ğ‘¡ğ‘›}({çº¢è‰² ,è¿è¡£è£™ }) granularities. We
thus obtain four granular representations â„ğ‘âˆˆR4Ã—ğ‘‘by concate-
natingğ‘â€™s unigram mean-pooling representation â„ğ‘1_ğ‘”ğ‘Ÿğ‘ğ‘šâˆˆR1Ã—ğ‘‘,
2-gram mean-pooling representation â„ğ‘2_ğ‘”ğ‘Ÿğ‘ğ‘šâˆˆR1Ã—ğ‘‘, word seg-
mentation mean-pooling representation â„ğ‘ğ‘ ğ‘’ğ‘”âˆˆR1Ã—ğ‘‘, and mixed rep-
resentation â„ğ‘ğ‘šğ‘–ğ‘¥âˆˆR1Ã—ğ‘‘, i.e.,
â„ğ‘1_ğ‘”ğ‘Ÿğ‘ğ‘š=mean-pooling(â„ğ‘1,...,â„ğ‘ğ‘š), (6)
â„ğ‘2_ğ‘”ğ‘Ÿğ‘ğ‘š=mean-pooling(â„ğ‘1ğ‘2,...,â„ğ‘ğ‘šâˆ’1ğ‘ğ‘š), (7)
â„ğ‘ğ‘ ğ‘’ğ‘”=mean-pooling(â„ğ‘¡1,...,â„ğ‘¡ğ‘›), (8)
â„ğ‘ğ‘šğ‘–ğ‘¥=â„ğ‘1_ğ‘”ğ‘Ÿğ‘ğ‘š+â„ğ‘2_ğ‘”ğ‘Ÿğ‘ğ‘š+â„ğ‘ğ‘ ğ‘’ğ‘”, (9)
â„ğ‘=concat(â„ğ‘1_ğ‘”ğ‘Ÿğ‘ğ‘š,â„ğ‘2_ğ‘”ğ‘Ÿğ‘ğ‘š,â„ğ‘ğ‘ ğ‘’ğ‘”,â„ğ‘ğ‘šğ‘–ğ‘¥), (10)
whereâ„,ğ‘‘, mean-pooling, and concat denote the word embedding,
embedding size, average, and vertical concatenation operation.
We feed the abundant semantic representation â„ğ‘into the en-
coder of a transformer [ 45] to dynamically learn which semantic pat-
tern is useful for matching items, and we regard the [CLS] tokenâ€™s
representation as the query towerâ€™s representation ğ»ğ‘âˆˆR1Ã—ğ‘‘, i.e.,
ğ»ğ‘=Trm_Encoderğ¶ğ¿ğ‘†(â„ğ‘). (11)
3.2.2 Item Tower. For the item representation ğ»ğ‘–ğ‘¡ğ‘’ğ‘š, we use its
title segmentation result T={ğ‘¡1,...,ğ‘¡ğ‘}, and property set P=
{ğ‘1,...,ğ‘ğ‘€}includes category, brand, and so on. We embed Tand
Pinto feature vectors â„ğ‘¡âˆˆR1Ã—ğ‘‘andâ„ğ‘âˆˆR1Ã—ğ‘‘, and then sum
them to get the final representation ğ»ğ‘–ğ‘¡ğ‘’ğ‘šâˆˆR1Ã—ğ‘‘. Mathematically,
â„ğ‘¡=tanh 
ğ‘Šğ‘¡Â·Ãğ‘
ğ‘–=1ğ‘¡ğ‘–
ğ‘!
, (12)
ğ‘’ğ‘ğ‘–=ğ‘Šğ‘ğ‘–Â·ğ‘ğ‘–, (13)
â„ğ‘=sum-pooling({ğ‘’ğ‘ğ‘–|ğ‘ğ‘–âˆˆP}), (14)
ğ»ğ‘–ğ‘¡ğ‘’ğ‘š=â„ğ‘¡+â„ğ‘, (15)
whereğ‘Šğ‘¡andğ‘Šğ‘ğ‘–are the transformation matrices. Sum-pooling
and tanh are the average operation and activation function. Ap-
plying a transformer encoder to capture the context of the title is
not as effective as simple mean-pooling since the title is stacked by
keywords and lacks grammatical structure [23].
3.2.3 Loss Function. We adapt the sampled softmax cross-entropy
loss [ 20] as the training objective, achieving faster convergence
and a better performance than other pointwise and pairwise losses.Unlike many toy datasets, in the e-commerce setting, the ground
truth of relevant items is unknown, and there can be too many
relevant products for a given query. For example, a query â€œ çº¢è‰²
è¿è¡£è£™ (red dress)â€ has millions of relevant products. Note that
our neural index is used for retrieving items of both relevance and
user-preference to reduce information losses of truncation.
We use user feedback and a well-trained â€œquery-itemâ€ relevance
model [ 46] to select items for training. Specifically, given a query ğ‘,
its positive samples ğ‘–+are those that have been clicked in the past
and are rated as relevant by the relevance model. Following [ 23],
its negative samples ğ‘–âˆ’(ğ‘–âˆ’ğ‘Ÿâˆªğ‘–âˆ’
â„) include: (1) random negative
samplesğ‘–âˆ’ğ‘Ÿgenerated by sampling from the entire item pool ğ¼;
and (2) hard negative samples ğ‘–âˆ’
â„generated by linear interpolation
betweenğ‘–+and top-ğ‘˜cosine similarity scores with ğ‘ofğ‘–âˆ’ğ‘Ÿâ€™s repre-
sentations. By examining the user logs, we obtains a train data set
D={(ğ‘1,ğ‘–+
1,ğ‘–âˆ’
1),...,(ğ‘ğ‘,ğ‘–+
ğ‘,ğ‘–âˆ’
ğ‘)}. The loss is defined by:
ğ¿(âˆ‡)=âˆ’1
ğ‘âˆ‘ï¸
ğ‘ğ‘—âˆˆDlogexp(cos(ğ‘ğ‘—,ğ‘–+
ğ‘—)/ğœ)
Ã
ğ‘–âˆˆğ‘–âˆ’
ğ‘—exp(F(ğ‘ğ‘—,ğ‘–)/ğœ), (16)
whereğ‘–andğ‘denote the item towerâ€™s representation ğ»ğ‘–ğ‘¡ğ‘’ğ‘š and the
query towerâ€™s representation ğ»ğ‘, respectively; ğœis a temperature
parameter we set to 2. Note that the negative samples ğ‘–âˆ’are gen-
erated during training. Similar to [ 23,49], we use the same set of
random negative samples for every ğ‘in the current batch to reduce
computing resources. For convenience, we refer to our Multiple
Granularities Semantic Indexer as MGSI.
3.3 System Deployment
unique product setUser Search Preferences-aware Pruned Inverted IndexPersonal RetrievalSemantic Forward IndexUser QueryIndexingHybrid Retrieval SystemPre-RankingRelevance&Personal RankingReRankingRanking System
SMINDReturn
Rewritten Queries
Figure 3: Overview of the architecture of the Taobao search
engine with the proposed indexing system SMIND.
As shown in Figure 3, we deploy the proposed indexing system
SMIND to the retrieval system of the Taobao search engine. When a
user initiates a query, CLE-QR [ 22] will first rewrite it. We then use
a hybrid retrieval system ( SMIND andPersonal Retrieval [7,23])
to return a unique candidate set I, which is then ranked by a large-
scale deep-learning based ranking system. Finally, we expose the
top-ğ‘˜products to users. See Section B of the Appendix for more
details of deployment.
5343KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Sen Li et al.
4 EXPERIMENTS
We introduce evaluation metrics, datasets, compared methods, im-
plementation details, and offline and online quantitative and quali-
tative analyses of our method.
4.1 Evaluation Metrics
For offline evaluation, following [ 23], we use the metrics of Recall@ ğ¾
andğ‘ƒğ‘”ğ‘œğ‘œğ‘‘, which are defined as
ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @ğ¾=Ãğ¾
ğ‘–=1ğ‘–ğ‘–âˆˆğ‘‡
ğ‘, (17)
ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘=Ãğ¾
ğ‘–=1I(ğ‘–ğ‘–)
ğ¾, (18)
whereğ‘‡={ğ‘¡1,...,ğ‘¡ğ‘}is the items clicked or purchased by the
userğ‘¢andğ¼={ğ‘–1,...,ğ‘–ğ¾}is the top-ğ‘˜items returned by an indexer.
I(Â·)is an indicator function. When item ğ‘–is rated as good by our
well-trained â€œquery-itemâ€ relevance model (with an AUC of 0.92),
its value is 1, otherwise 0.
For online evaluation, we consider the two most valuable com-
merce metrics, GMV (Gross Merchandise Volume) and POC (Pay
Order Count). Additionally, we report four auxiliary system met-
rics, namely ğ‘µ ğ’–ğ’ ğ’“ğ’‚ğ’ğ’Œ ,ğ‘¹ğ’†ğ’„ğ’‚ğ’ğ’ ğ’„ğ’ğ’Œ,ğ‘¹ğ’†ğ’„ğ’‚ğ’ğ’ ğ’‘ğ’–ğ’“, and ğ‘·ğ’ˆğ’ğ’ğ’… . See Sec-
tion C of the Appendix for more details. Note that we also perform
a Wilcoxon signed-rank test [ 10] to measure the significance of the
difference.â€ andâ€¡indicate that the improvement is statistically
significant with ğ‘<0.05andğ‘<0.01, respectively.
4.2 Datasets
4.2.1 Large-scale Industrial Offline DataSet. For offline evaluation,
we randomly sample 1.5million search interaction records in the
next day. Following the online systemâ€™s setting (Section 4.2.2), the
size of the candidate item set of inverted index is about 2billion
and the semantic index is about 100million.
4.2.2 Online Dataset. We deploy a well-built SMIND in the Taobao
search production environment to serve hundreds of millions of
user query requests (Section 3.3). The size of the item candidate
set is about 2billion. Since the online inference of semantic index
needs more computational resources, we have to reduce its item
pool to the most active products, resulting in 100million.
4.3 Compared Methods
4.3.1 Offline Comparisons. Due to the differences in the item pools
of the inverted indexer and the semantic indexer, we report the
metrics of the two indexes separately.
Inverted Indexer. For the InVerted Indexer, following [ 43], we re-
port some strong baselines of static term-based pruning techniques,
such as TF-based, TF-IDF based, and item quality Q-based. We also
adapt DeepCT [ 8], SPARTA [ 50], and SPLADE [ 15,16] for a fair
comparison. Note that BM25 is an â€œquery-itemâ€ score function and
is not applicable in a static pruning setting where only single term
posting lists can be accessed offline. The details are as follow:
IVI-TF The truncated posting list of each term is based on the
scoring function ğ‘“(ğ‘¡,ğ‘–), which is instantiated as term fre-
quency (TF). Given a (term, item) pair, we get the TF valueby counting the number of times the term ğ‘¡appears in the
item title.
IVI-TF-IDF The scoring function ğ‘“(ğ‘¡,ğ‘–)is instantiated as classical
TF-IDF value.
IVI-Q For each term, we truncate its full item lists to a given length
according to the item quality Q value.
IVI-DeepCT The value of the scoring function ğ‘“(ğ‘¡,ğ‘–)is obtained
from DeepCT [8].
IVI-SPARTA ğ‘“(ğ‘¡,ğ‘–)â€™s value is obtained from SPARTA [50].
IVI-SPLADE ğ‘“(ğ‘¡,ğ‘–)â€™s value is obtained from SPLADE [15, 16].
IVI-USP The scoring function ğ‘“(ğ‘¡,ğ‘–)is instantiated by the Eq. (4),
which considers the user search preferences.
IVI-USP-Q The proposed scoring function ğ‘“(ğ‘¡,ğ‘–)(Eq. (5)), consid-
ering both user search preferences and item quality ğ‘„.
Semantic Indexer. For the Semantic Indexer, our contribution is
not to design any new model, but to combine query rewriting (QR)
to facilitate its semantic matching, by addressing the mismatch
problem mentioned earlier. Hence, we focus on the comparisons
between MGSI and its combination with QR. Note that MGSI can
be replaced by any semantic indexer mentioned in Section 2.2. The
details are as follows:
MGSI The proposed Multiple Granularities Semantic Indexer.
MGSI-QR In addition to triggering the MGSI with a userâ€™s original
queries, we use the rewritten queries of CLE-QR [22].
4.3.2 Online Comparisons. Our search engine is a complicated
system since it has been tuned by hundreds of engineers and scien-
tists for over ten years. We briefly introduce the our experimental
environment for the readersâ€™ interest. For text matching, we have al-
ready deployed query/product tagging matching methods based on
manual efforts and knowledge graphs [ 27] and the query rewriting
technique CLE-QR [ 22]. For personal retrieval, we have graph-based
methods [ 7,13,33] and an embedding-based method [ 23] online.
We cannot simply remove them from the online system for com-
parisons. Hence, we only replace the indexer of text matching with
SMIND . Since SMIND consists of IVI-USP-Q and MGSI, we report on
two ablations, as follows:
SMIND The proposed hybrid indexer solution. It is used with both
the userâ€™s original queries and rewrites of CLE-QR.
SMIND w/o IVIUSPQ We remove the user search preferences-aware
pruned inverted indexer from SMIND.
SMIND w/o MGSI We remove the semantic indexer from SMIND.
4.4 Implementation Details
We collect search logs from the online Mobile Taobao App to build
SMIND . Specifically, for the user search preferences-aware pruned
inverted indexer, the purchase hypergraph Gğ‘ğ‘¢ğ‘Ÿis built from one
month of(ğ‘¢,ğ‘,ğ‘–)purchase interactions. The click hypergraph Gğ‘ğ‘™ğ‘˜
contains two weeks of (ğ‘¢,ğ‘,ğ‘–)click interactions, about 10billion
records. The exposure hypergraph Gğ‘’ğ‘¥ğ‘ğ‘œ and relevance hypergraph
Gğ‘Ÿğ‘’ğ‘™contain one week(ğ‘¢,ğ‘,ğ‘–)exposure and relevance interactions,
about 350billion records. The TermRank algorithm is implemented
on our large-scale distributed system called Open Data Process-
ing Service (ODPS).1Its number of iterations is set to 1by cross-
validation. The execution sequence of TermRank is: (1) we first
1https://www.aliyun.com/product/odps
5344Text Matching Indexers in Taobao Search KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
initialize all ğ‘£(ğ‘–ğ‘¡)to1, and run Eq. (3); and (2) we then run Eq. (2)
to get the final value ğ‘£(ğ‘–ğ‘¡). The runtime ofGğ‘ğ‘¢ğ‘Ÿ,Gğ‘ğ‘™ğ‘˜,Gğ‘’ğ‘¥ğ‘ğ‘œ, and
Gğ‘Ÿğ‘’ğ‘™is about 1hour, 2h,6h and 6h, respectively. Once we finish
building the term-level search hypergraphs, users and items are
static. To capture dynamic changes of users and products, we re-run
TermRank periodically. Since our item set varies between days, we
do it every day.
For training the semantic indexer, we use distinct query click-
s/purchases of 7consecutive days, a total of 4.7billion records. The
dimensions of the query tower and item tower are all set to 128. The
batch size is 256. The setup of transformer encoder is 2layers and
8self-attention heads. All parameters are orthogonally initialized
and learned from scratch. The training processes are run on the
distributed TensorFlow platform [ 1] using 20parameter servers and
100GPU (Tesla P100) workers. We use the AdaGrad optimizer [ 12]
with an initial learning rate of 0.1, since it improves the robustness
of SGD for training large-scale networks [ 9]. We clip the gradient
norm less than 3. The running time is about 48h.
4.5 Offline Experimental Results
4.5.1 Comparison of Pruned Inverted Indexer. As mentioned in Sec-
tion 4.1, we report the metrics of ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @ğ¾andğ‘ƒğ‘”ğ‘œğ‘œğ‘‘ on1.5million
search interaction records. We set ğ¾to1,000.2As shown in Table 1,
the performance of IVI-TF and IVI-TF-IDF are the worst in terms of
the lowest metrics of ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @1000 andğ‘ƒğ‘”ğ‘œğ‘œğ‘‘, which verifies that
the search engine optimization (SEO) behavior of merchants make
the TF and TF-IDF less effective.
Table 1: Offline performance of term-based pruned inverted
indexers and ablation models.
Methods ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @1000ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘
IVI-TF 0.8076 0.8739
IVI-TF-IDF 0.8099 0.8754
IVI-DeepCT [8] 0.8201 0.8766
IVI-SPARTA [50] 0.8199 0.8768
IVI-SPLADE [16] 0.8244 0.8773
IVI-SPLADEv2 [15] 0.8316 0.8790
IVI-Q 0.8192 0.8689
IVI-USP 0.8376 0.8812
IVI-USP-Q 0.8510â€¡ 0.8870â€¡
We also use the value learnt by sparse retrieval models for prun-
ing. Specifically, DeepCT [ 8], SPARTA [ 50] and SPLADE [ 15,16] all
outperform TF and TF-IDF, indicating that they do provide stronger
term dependencies of textual relevance signal than TF and TF-IDF
and mitigate the effect of SEO. The ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @1000 score of IVI-USP
is higher than that of the learned sparse models, which means that
USP is more effective at capturing term dependencies than textual
relevance and thus retrieve more user-preferred products.
However, learned sparse models frequently assign â€œwackyâ€ weights
to terms [ 28,29,31]. Especially in our case, since the user search
logs are noisy (users may click/purchase items irrelevant to the
query) [ 22,23], it is hard to preserve high precision/relevance,
2The Top-1000 items are obtained by our ranking system.which leads to a lower value of ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘ than the proposed TermRank
method. Finally, the proposed IVI-USP-Q outperforms all other
methods in terms of ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @1000 andğ‘ƒğ‘”ğ‘œğ‘œğ‘‘, indicating that consid-
ering both USP and the item quality factor ğ‘„helps to return more
relevant items and better satisfy users.
4.5.2 Comparison of Semantic Indexer. As discussed in Section 4.3.1,
we here focus on the comparisons between MGSI and its com-
bination with query rewriting (QR). As shown in Table 2, when
combining the rewritten queries of QR with the semantic indexer,
MGSI-QR achieves higher ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @1000 scores, indicating that the
retrieval performance of QR and semantic index can be mutually
improved, by better addressing the vocabulary mismatch. The rele-
vant retrieval ability of MGSI-QR seems to be weaker in terms of
theğ‘ƒğ‘”ğ‘œğ‘œğ‘‘ metric, as it is reduced by 0.85%. However, it does retrieve
more user-preferred items than MGSI.
Table 2: Offline performance comparison between MGSI and
MGSI-QR.
Methods ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @1000ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘
MGSI 0.7876â€  0.7939â€¡
MGSI-QR 0.8219â€  0.7854â€¡
4.5.3 Qualitative Results of IVI-USP-Q. Table 3 shows the top 7
item categories and the corresponding number of products retained
in the truncated posting list of the term â€œredâ€ by the methods IVI-
Q and IVI-USP-Q. With the fixed truncated length, 4of the top
7categories are consistent (i.e., Dress, Wool sweater, Lady bags
and T-shirt), which shows that the item quality factor ğ‘„reflects
the user search preference to a certain extent. However, due to
different category preferences, the number of items in the four
same categories is inconsistent. IVI-USP-Q considers both USP
andğ‘„, which makes the truncated item set closer to the general
user search intention. Specifically, in the common categories, the
number of items of â€œdressâ€ and â€œlady bagsâ€ have increased by 141%
and 67.7%, and these items could previously not be retained in
â€œredâ€â€™s pruned posting list of IVI-Q due to a low ğ‘„value.
Table 3: With different term-based pruning methods, the
top7item categories and their numbers within the truncated
posting list of the term â€œçº¢è‰² (red).â€
term â€œçº¢è‰²(red)"
IVI-Q IVI-USP-Q
Category Num Category Num
æ¯›é’ˆç»‡è¡« (Wool sweater) 2,776 Dress 6,140
è¿è¡£è£™ (Dress) 2,552 Wool sweater 2,675
Tæ¤(T-shit) 2,465 Lady bags 2,231
è¿åŠ¨é‹ (Sneaker) 1,575 T-shirt 2,229
è¡¬è¡« (Shirt) 1,440å•é‹ (Shoes) 2,208
å¥³åŒ… (Lady bags) 1,330 æ–‡èƒ¸ (Bras) 1,580
è£¤å­ (Pants) 1,165ç¤¼æœ (Canonicals) 1,477
In the categories with differences, the number of items in the
categories of â€œShoes,â€ â€œBras,â€ and â€œCanonicalsâ€ has increased sig-
nificantly, and they have entered the top 7of IVI-USP-Q from the
5345KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Sen Li et al.
24-th, 28-th and 53-rd position of IVI-Q. The changes in these item
categories and numbers are in line with our intuition, since when
a user searches with term â€œred,â€ he/she expects to see dress, lady
bags, shoes, bras, and canonicals more.3
4.5.4 Case Study of Term Dependencies of USP. We use a small
number of case studies to examine the term dependencies of USP.
We randomly sampled 2items of dress, and checked the value of
each termğ‘£(ğ‘–ğ‘¡)(i.e., Eq. (2)) in their title from the term-level user
click hypergraphsGğ‘ğ‘™ğ‘˜. A bigger value of ğ‘£(ğ‘–ğ‘¡)indicates that users
more strongly prefer to use the term ğ‘¡to interact with item ğ‘–.
Chinese: ports(0.05) å®å§¿(0.60) è£™â¼¦(0.01) ç§‹å­£(0.01) æ—¶å°š(0.00) â½“è´¨(0.06) é€šå‹¤(0.00) ä¿®èº«(0.04) æ”¶è…°(0.02) è¿â¾è£™(0.21)English: ports(0.05) å®å§¿(0.60) skirt(0.01) autumn(0.01) fashion(0.00) temperament(0.06) commute(0.00) ï¬t(0.04) waist(0.02) dress (0.21)                      Item Title 
Chinese: self-portrait(0.21) â½”æº¶(0.09) è•¾ä¸(0.17) è¿â¾è£™(0.49) å¤å­£(0.01) è–„æ¬¾(0.00) ç´§èº«(0.01) æ³¡æ³¡è¢–(0.02) ä¸­â»“è£™(0.01)English: self-portrait(0.21) water soluble(0.09) lace(0.17) dress(0.49) summer(0.01) thin(0.00) tight(0.01) puï¬€ sleeves(0.02) midi skirt(0.01)Item1 
Item2 
Figure 4: Case study of term dependencies of USP. Values in
parentheses are calculated by TermRank.
As shown in Figure 4, although merchants perform SEO by stack-
ing many textually relevant words, only a few keywords of each
product will be searched by users. For item 1, the most important
keywords are â€œ å®å§¿â€ and â€œè¿è¡£è£™ (dress)â€ since their values are
bigger than others. Interestingly, item 1has a shared Chinese and
English keyword of the brand â€œPORTS,â€ but most users tend to
search it in Chinese. For item 2, its style is a puff sleeve lace dress,
but the value of â€œpuff sleevesâ€ (0 .02)â‰ªâ€œdressâ€ (0.49). On the one
hand, from the perspective of product textual relevance, â€œ æ³¡æ³¡
è¢–(puff sleeves)â€ and â€œ è¿è¡£è£™ (dress)â€ are equally important to
item 2. On the other hand, from the perspective of users, they rarely
initiate the term â€œpuff sleeveâ€ to search for item 2. Moreover, the
term â€œè–„æ¬¾ (thin)â€ is a textually relevant keyword of item 2since it is
item 2â€™s attribute. However, its value is 0, indicating that users have
never interacted with item 2using the term â€œthin.â€ Instead, users
use term â€œ è•¾ä¸(lace)â€ more. The above examples show that the
higher-order term dependencies of USP are crucial in e-commerce
product search.
4.5.5 Dependencies of USP on Various Term-Level Hypergraphs.
To further study the high-order term dependencies of user prefer-
ences, we show the value of each term in the title ( ğ‘£(ğ‘–ğ‘¡)) obtained
3The query â€œredâ€ represents joy and happiness in Chinese customs. For example, at
Chinese weddings, people wear red canonicals. Also, people give out red envelopes
during Chinese New Year. Hence, people get used to associate the appearance of objects
with the â€œred. â€ More important, most of our users are women. Therefore, for the query
â€œred,â€ products of dresses, lady bags, and shoes should be more hits.
Item Title Term self-portraitâ½”æº¶(water soluble)è•¾ä¸(lace)è¿â¾è£™(dress)å¤å­£(summer)è–„æ¬¾(thin)ç´§èº«(tight)æ³¡æ³¡è¢–(puï¬€ sleeves)ä¸­â»“è£™(midi skirt)0.210.090.170.490.010.000.010.020.010.120.030.090.690.030.010.010.010.010.440.000.220.340.000.000.000.000.000.100.080.070.380.040.090.060.080.10
Figure 5: Comparison of term dependencies of USP on term-
level hypergraphs. Values in the last four columns are calcu-
lated by TermRank.
from the term-level user search purchase/click/exposure/relevance
preferences hypergraphs, Gğ‘ğ‘¢ğ‘Ÿ,Gğ‘ğ‘™ğ‘˜,Gğ‘’ğ‘¥ğ‘ğ‘œ, andGğ‘Ÿğ‘’ğ‘™, respectively.
As shown in Figure 5, given the title of a product, from user
search relevanceâ†’exposureâ†’clickâ†’purchase preferences, the im-
portance of the title terms goes from divergence to convergence
to a few specific terms. Specifically, in the user search relevance
preferences hypergraph Gğ‘Ÿğ‘’ğ‘™, each term has a value indicating that
each term in the title is relevant. In the exposure hypergraph Gğ‘’ğ‘¥ğ‘ğ‘œ,
the values of terms like â€œ è–„æ¬¾ (thin)â€ and â€œ ç´§èº« (tight),â€ start to de-
crease and others are increasing. In the click hypergraph Gğ‘ğ‘™ğ‘˜, this
phenomenon is more apparent. Finally, in the purchase hypergraph
Gğ‘ğ‘¢ğ‘Ÿ, â€œself-portrait,â€ â€œ è•¾ä¸(lace),â€ and â€œ è¿è¡£è£™ (dress)â€ become
key terms, while the others are vanishing. This means that when
users purchase this product, they will only use the combination of
terms â€œself-portrait,â€ â€œ è•¾ä¸ (lace),â€ and â€œ è¿è¡£è£™ (dress)â€ to search.
A comparison of the purchase hypergraph Gğ‘ğ‘¢ğ‘Ÿand the relevance
hypergraphGğ‘Ÿğ‘’ğ‘™clearly tells us that the term dependencies in user
search preference are far more important than textual relevance in
product search.
4.6 Online Experimental Results
Beyond the offline experiments, we further conduct online evalua-
tion to verify the effectiveness of SMIND.
4.6.1 Ablation Study. As mentioned in Section 4.1, for online per-
formance analyses, we report the number of products considered in
the ranking stage (i.e., ğ‘ğ‘¢ğ‘šğ‘Ÿğ‘ğ‘›ğ‘˜), the recall metric of click/purchase
signal on the displayed item set ğ¼(i.e.,ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘™ğ‘˜andğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘¢ğ‘Ÿ), and
the proportion of products with good relevance on ğ¼(i.e.,ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘).
In addition to SMIND â€™s two ablation models ( SMIND w/o IVIUSPQ
andSMIND w/o MGSI discussed in Section 4.3.2, we also include the
performance of the previous online baseline for comparison. Due
to commercial confidentiality, we report relative values for some
metrics.
Table 4: Online analyses of SMIND and its ablation models.
The last three columns report relative values.
Metho
ds ğ‘ğ‘¢ğ‘šğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘™ğ‘˜ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘¢ğ‘Ÿğ‘ƒğ‘”ğ‘œğ‘œğ‘‘
Online
baseline 4351 â€“ â€“ â€“
SMIND w/o
IVIUSPQ 4480+2.68%+1.32%âˆ’0.45%
SMIND w/o MGSI 4552+4.24%+1.74% +1.62%
SMIND 4651 +5.45%â€¡ +2.81%â€¡ +1 .25%â€¡
5346Text Matching Indexers in Taobao Search KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
As shown in Table 4, the two ablation modules can retrieve
more item candidates that enter the ranking stage than the online
baseline (higher ğ‘ğ‘¢ğ‘šğ‘Ÿğ‘ğ‘›ğ‘˜), indicating the effectiveness of the pro-
posed indexer, IVI-USP-Q and MGSI, again. Specifically, MGSI (i.e.,
SMIND w/o IVIUSPQ) increases ğ‘ğ‘¢ğ‘šğ‘Ÿğ‘ğ‘›ğ‘˜ by3%and reduces ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘
by0.45%, showing that it improves the volume of user-preferred
items as well as introducing some less relevant results. This is
mainly because the personal ranking model scores â€œuser-query-
itemâ€ while the relevance model scores â€œquery-item.â€ There is a
discrepancy between the two metrics. However, MGSI does improve
theğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘™ğ‘˜andğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘¢ğ‘Ÿby2.68%and1.32%, which demonstrates
the dilemma of user preferences and uniform relevance criteria in
e-commerce search. As for IVI-USP-Q (i.e., SMIND w/o MGSI), it
improves all metrics, indicating that it retrieves more relevant and
user-preferred products. Finally, since the hybrid indexer SMIND
achieves the largest improvements, we conclude that its two ab-
lation indexers complement each other and SMIND serves online
users better.
Table 5: Online A/B test of SMIND on Mobile Taobao Search.
The improvements are averaged over 18days.
GMV POC CTR CVR
SMIND+1.50%â€¡+1.34%â€¡+0.02ğ‘ğ‘¡â€¡+0.02ğ‘ğ‘¡â€¡
4.6.2 Online A/B Tests. Finally, we report the 18-day average of
GMV and POC improvements (removing cheating traffic by the
business analyst) achieved by SMIND . We include two additional
metrics, click-through rate (CTR) and conversion rate (CVR).
Table 5 shows that SMIND improves GMV and POC by 1.50%
and1.34%, respectively, indicating that the daily increase income
is hundreds millions. CTR and CVR also increase by 0.02pt and
0.02pt, respectively, which demonstrates that SMIND better satisfies
users. We also deployed an unpruned inverted index for comparison,
which can bring a marginal increase of 0.2%in GMV and POC at
the cost of 50%increase in computing resources.
4.6.3 User Query Shift Phenomenon. Because SMIND achieves sig-
nificant improvements, we want to investigate its potential impact
on users by examining usersâ€™ search behavior versus their behavior
with the previous online system. We first sort all queries in a de-
scending order of their number of products recalled by the previous
online system, and categorize them into 7intervals, i.e., the smaller
the number, the more recalled products. We refer to queries in the
interval of No. 1â€“3 as top queries, those in the interval of No. 4, 5
as torso queries, and those in the interval of No. 6, 7 as tail queries.
With the same online traffic volume setting, we then count the
search frequency (SF) and item clicks (IC) in each interval.
Interestingly, as shown in Table 6, we find there is a user query
shift phenomenon. Overall, since SMIND and the previous system
have the same online traffic volume, their total SF are equal. But
SMIND increases IC by 0.64%, indicating that its retrieved product
collection better satisfies users, so that they are willing to click
more. Let us take a closer look. The SF and IC ratio of the tail
queries (No. 6â€“7) and the torso queries (No. 4â€“5) have increased
significantly, while the top query (No. 1â€“3) decreased significantly.
As the overall SF ratio of SMIND and previous system are equal, thisTable 6: The user search behavior with SMIND versus previous
online system.
Query Type No. Search Frequency (SF) Item Clicks (IC)
Overall â€“ 0.00%+0.64%
Top1âˆ’2.76%âˆ’2.18%
2âˆ’1.84%âˆ’1.37%
3âˆ’0.96%+0.01%
Torso4+1.69%+2.89%
5+1.42%+1.87%
Tail6+1.36%+1.33%
7+1.62%+1.11%
indicates that there is a user query shift phenomenon. Specifically,
in the previous retrieval system, when users initiate the torso/tail
queries and fail to see the desired product set, they rewrite their
own queries to top queries for viewing more products. However, on
the test traffic, SMIND improves the matching ability of the previous
indexing system, so that torso and tail queries can return more
products that users are willing to click/purchase, which prevents
users from rewriting queries to top queries and thus alleviating the
Matthew effect [36] of user queries.
5 CONCLUSION
This paper presents an efficient solution for indexing billions of
products, called SMart INDexing ( SMIND ), in Taobao search. SMIND
addresses the challenge of reducing information loss during the
static pruning of inverted indexes by integrating user search prefer-
ences (as discussed in Section 4.5.3) and mitigating the vocabulary
mismatch problem inherent in term-based models (as outlined in
Sections 4.5.2 and 4.6.1) that plagued the previous indexing system.
Our research demonstrates that understanding the term depen-
dencies among usersâ€™ search preferences is of paramount impor-
tance, surpassing textual relevance (as discussed in Sections 4.5.4,
and 4.5.5). Meanwhile, we share the lessons learned from improv-
ing the performance of text matching, including the design of a
pruning inverted indexer, a semantic indexer, its combination with
a query rewriting technique, its effect on a large-scale commerce
search system (Section 4.6.3), and its deployment scheme. Offline
experiments and online A/B tests verify the effectiveness of SMIND .
We have successfully deployed the proposed system on Taobao
Product Search, providing real-time services to hundreds of mil-
lions of users. In the future, we will incorporate term dependencies
in user search preferences into the ranking stage to improve search
personalization. Another aspect to investigate is the choice of se-
mantic indexers. In particular, our semantic indexer was trained
using only text corpora, whereas we also have rich image data.
Therefore, we believe that building a multi-modal semantic indexer
can further improve the performance of our system.
ACKNOWLEDGMENTS
The authors thank Prof. Qianli Ma and Ph.D. Qingwen Liu for their
helpful discussions and comments on early drafts. We would also
like to thank the anonymous reviewers for their helpful feedbacks.
5347KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Sen Li et al.
REFERENCES
[1]MartÃ­n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al .
2016. Tensorflow: A System for Large-scale Machine Learning. In 12th OSDI.
265â€“283.
[2]Sergey Brin and Lawrence Page. 1998. The Anatomy of a Large-Scale Hypertex-
tual Web Search Engine. Computer Networks 30 (1998), 107â€“117.
[3]Andrei Z. Broder, David Carmel, Michael Herscovici, Aya Soffer, and Jason Zien.
2003. Efficient Query Evaluation Using a Two-level Retrieval Process. In 12th
CIKM. 426â€“434.
[4]David Carmel, Doron Cohen, Ronald Fagin, Eitan Farchi, Michael Herscovici,
Yoelle S Maarek, and Aya Soffer. 2001. Static Index Pruning for Information
Retrieval Systems. In 24th SIGIR. 43â€“50.
[5]Wei-Cheng Chang, Daniel Jiang, Hsiang-Fu Yu, Choon Hui Teo, Jiong Zhang, Kai
Zhong, Kedarnath Kolluri, Qie Hu, Nikhil Shandilya, Vyacheslav Ievgrafov, et al .
2021. Extreme Multi-label Learning for Semantic Matching in Product Search. In
27th SIGKDD. 2643â€“2651.
[6]Xilun Chen, Kushal Lakhotia, Barlas Oguz, Anchit Gupta, Patrick Lewis, Stan
Peshterliev, Yashar Mehdad, Sonal Gupta, and Wen-tau Yih. 2022. Salient Phrase
Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?. In Findings
of the Association for Computational Linguistics: EMNLP 2022. 250â€“262.
[7]Dian Cheng, Jiawei Chen, Wenjun Peng, Wenqin Ye, Fuyu Lv, Tao Zhuang, Xiaoyi
Zeng, and Xiangnan He. 2022. IHGNN: Interactive Hypergraph Neural Network
for Personalized Product Search. In 31st WWW. 256265.
[8]Zhuyun Dai and Jamie Callan. 2020. Context-Aware Term Weighting For First
Stage Passage Retrieval. In 43rd SIGIR. 1533â€“1536.
[9]Jeffrey Dean, Greg S. Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Quoc V.
Le, Mark Z. Mao, Marcâ€™Aurelio Ranzato, Andrew Senior, Paul Tucker, Ke Yang,
and Andrew Y. Ng. 2012. Large Scale Distributed Deep Networks. In 25th NeurIPS.
1223â€“1231.
[10] Janez Demsar. 2006. Statistical Comparisons of Classifiers over Multiple Data
Sets. JMLR 7 (2006), 1â€“30.
[11] Shuai Ding and Torsten Suel. 2011. Faster Top-k Document Retrieval Using
Block-max Indexes. In 34th SIGIR. 993â€“1002.
[12] John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive Subgradient Methods
for Online Learning and Stochastic Optimization. JMLR 12, 7 (2011), 2121â€“2159.
[13] Lu Fan, Qimai Li, Bo Liu, Xiao-Ming Wu, Xiaotong Zhang, Fuyu Lv, Guli Lin,
Sen Li, Taiwei Jin, and Keping Yang. 2022. Modeling User Behavior with Graph
Convolution for personalized product search. In 31st WWW. 203â€“212.
[14] Marcus Fontoura, Vanja Josifovski, Jinhui Liu, Srihari Venkatesan, Xiangfei Zhu,
and Jason Zien. 2011. Evaluation Strategies for Top-k Queries over Memory-
resident Inverted Indexes. Proceedings of the VLDB Endowment 4, 12 (2011),
1213â€“1224.
[15] Thibault Formal, Carlos Lassance, Benjamin Piwowarski, and StÃ©phane Clinchant.
2022. From Distillation to Hard Negative Sampling: Making Sparse Neural IR
Models More Effective. In 45th SIGIR. 2353â€“2359.
[16] Thibault Formal, Benjamin Piwowarski, and StÃ©phane Clinchant. 2021. SPLADE:
Sparse Lexical and Expansion Model for First Stage Ranking. In 44th SIGIR. 2288â€“
2292.
[17] Jiafeng Guo, Yinqiong Cai, Yixing Fan, Fei Sun, Ruqing Zhang, and Xueqi Cheng.
2022. Semantic Models for the First-stage Retrieval: A Comprehensive Review.
ACM Transactions on Information Systems (TOIS) 40, 4 (2022), 1â€“42.
[18] Jui-Ting Huang, Ashish Sharma, Shuying Sun, Li Xia, David Zhang, Philip Pronin,
Janani Padmanabhan, Giuseppe Ottaviano, and Linjun Yang. 2020. Embedding-
based Retrieval in Facebook Search. In 26th SIGKDD. 2553â€“2561.
[19] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck.
2013. Learning Deep Structured Semantic Models for Web Search Using Click
through Data. In 22nd CIKM. 2333â€“2338.
[20] SÃ©bastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2014.
On Using Very Large Target Vocabulary for Neural Machine Translation. arXiv
preprint arXiv:1412.2007 (2014).
[21] Jeff Johnson, Matthijs Douze, and HervÃ© JÃ©gou. 2019. Billion-scale Similarity
Search with GPUs. IEEE Transactions on Big Data 7, 3 (2019), 535â€“547.
[22] Sen Li, Fuyu Lv, Taiwei Jin, Guiyang Li, Yukun Zheng, Tao Zhuang, Qingwen
Liu, Xiaoyi Zeng, James Kwok, and Qianli Ma. 2022. Query Rewriting in TaoBao
Search. In 31st CIKM. 3262â€“3271.
[23] Sen Li, Fuyu Lv, Taiwei Jin, Guli Lin, Keping Yang, Xiaoyi Zeng, Xiao-Ming Wu,
and Qianli Ma. 2021. Embedding-Based Product Retrieval in Taobao Search. In
27th SIGKDD. 3181â€”3189.
[24] Yiding Liu, Weixue Lu, Suqi Cheng, Daiting Shi, Shuaiqiang Wang, Zhicong
Cheng, and Dawei Yin. 2021. Pre-trained Language Model for Web-scale Retrieval
in Baidu Search. In 27th SIGKDD. 3365â€“3375.
[25] Yiqun Liu, Kaushik Rangadurai, Yunzhong He, Siddarth Malreddy, Xunlong Gui,
Xiaoyi Liu, and Fedor Borisyuk. 2021. Que2Search: Fast and Accurate Query and
Document Understanding for Search at Facebook. In 27th SIGKDD. 3376â€“3384.
[26] Xiaohui Long and Torsten Suel. 2003. Optimized Query Execution in Large
Search Engines with Global Page Ordering. In Proceedings 2003 VLDB Conference.Elsevier, 129â€“140.
[27] Xusheng Luo, Le Bo, Jinhang Wu, Lin Li, Zhiy Luo, Yonghua Yang, and Keping
Yang. 2021. AliCoCo2: Commonsense Knowledge Extraction, Representation
and Application in E-commerce. In 27th SIGKDD. 3385â€“3393.
[28] Joel Mackenzie, Andrew Trotman, and Jimmy Lin. 2021. Wacky Weights in
Learned Sparse Representations and the Revenge of Score-at-a-Time Query
Evaluation. arXiv preprint arXiv:2110.11540 (2021).
[29] Joel Mackenzie, Andrew Trotman, and Jimmy Lin. 2023. Efficient Document-at-a-
Time and Score-at-a-Time Query Evaluation for Learned Sparse Representations.
ACM Transactions on Information Systems 41, 4 (2023).
[30] Alessandro Magnani, Feng Liu, Suthee Chaidaroon, Sachin Yadav, Praveen
Reddy Suram, Ajit Puthenputhussery, Sijie Chen, Min Xie, Anirudh Kashi, Tony
Lee, et al. 2022. Semantic Retrieval at Walmart. In 28th SIGKDD. 3495â€“3503.
[31] Antonio Mallia, Omar Khattab, Torsten Suel, and Nicola Tonellotto. 2021. Learn-
ing Passage Impacts for Inverted Indexes. In 44th SIGIR. 17231727.
[32] Priyanka Nigam, Yiwei Song, Vijai Mohan, Vihan Lakshman, Weitian Ding, Ankit
Shingavi, Choon Hui Teo, Hao Gu, and Bing Yin. 2019. Semantic Product Search.
In25th SIGKDD. 2876â€“2885.
[33] Xichuan Niu, Bofang Li, Chenliang Li, Rong Xiao, Haochuan Sun, Hongbo Deng,
and Zhenzhong Chen. 2020. A Dual Heterogeneous Graph Attention Network to
Improve Long-Tail Performance for Shop Search in E-Commerce. In 26th SIGKDD.
3405â€“3415.
[34] Alexandros Ntoulas and Junghoo Cho. 2007. Pruning Policies for Two-Tiered
Inverted Index with Correctness Guarantee. In 30th SIGIR. 191â€“198.
[35] Debmalya Panigrahi and Sreenivas Gollapudi. 2013. Document Selection for
Tiered Indexing in Commerce Search. In 6th WSDM. 73â€“82.
[36] Matjaz Perc. 2014. The Matthew Effect in Empirical Data. Journal of the Royal
Society Interface 11, 98 (2014), 20140378â€“20140378.
[37] Joseph Rocchio. 1971. Relevance Feedback in Information Retrieval. In The Smart
Retrieval System-experiments in Automatic Document Processing. 313â€“323.
[38] Cristian Rossi, Edleno S. de Moura, Andre L. Carvalho, and Altigran S. da Silva.
2013. Fast Document-at-a-time Query Processing Using Two-tier Indexes. In
36th SIGIR. 183â€“192.
[39] Hinrich SchÃ¼tze, Christopher D. Manning, and Prabhakar Raghavan. 2008. Intro-
duction to Information Retrieval. Vol. 39. Cambridge University Press.
[40] Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and GrÃ©goire Mesnil. 2014.
Learning Semantic Representations Using Convolutional Neural Networks for
Web Search. In 23rd WWW. 373â€“374.
[41] Trevor Strohman, Howard Turtle, and W. Bruce Croft. 2005. Optimization Strate-
gies for Complex Queries. In 28th SIGIR. 219â€“225.
[42] Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin
Tian, Danxiang Zhu, Hao Tian, and Hua Wu. 2019. Ernie: Enhanced Representa-
tion Through Knowledge Integration. arXiv preprint arXiv:1904.09223 (2019).
[43] Nandan Thakur, Nils Reimers, Andreas RÃ¼cklÃ©, Abhishek Srivastava, and Iryna
Gurevych. 2021. BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of
Information Retrieval Models. In Thirty-fifth Conference on Neural Information
Processing Systems Datasets and Benchmarks Track.
[44] Howard Turtle and James Flood. 1995. Query Evaluation: Strategies and Opti-
mizations. Information Processing & Management 31, 6 (1995), 831â€“850.
[45] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is All
You Need. In 31st NeurIPS, Vol. 30.
[46] Shaowei Yao, Jiwei Tan, Xi Chen, Keping Yang, Rong Xiao, Hongbo Deng, and
Xiaojun Wan. 2021. Learning a Product Relevance Model from Click-Through
Data in E-Commerce. In 30th WWW. 2890â€“2899.
[47] Licheng Yu, Jun Chen, Animesh Sinha, Mengjiao Wang, Yu Chen, Tamara L Berg,
and Ning Zhang. [n. d.]. CommerceMM: Large-scale Commerce Multimodal
Representation Learning with Omni Retrieval. In 28th SIGKDD, pages=4433â€“4442,
year=2022.
[48] Han Zhang, Hongwei Shen, Yiming Qiu, Yunjiang Jiang, Songlin Wang, Sulong
Xu, Yun Xiao, Bo Long, and Wen-Yun Yang. 2021. Joint Learning of Deep Retrieval
Model and Product Quantization based Embedding Index. In 44th SIGIR. ACM,
17181722.
[49] Han Zhang, Songlin Wang, Kang Zhang, Zhiling Tang, Yunjiang Jiang, Yun Xiao,
Weipeng Yan, and Wen-Yun Yang. 2020. Towards Personalized and Semantic Re-
trieval: An End-to-End Solution for E-commerce Search via Embedding Learning.
In43rd SIGIR. 2407â€“2416.
[50] Tiancheng Zhao, Xiaopeng Lu, and Kyusong Lee. 2020. SPARTA: Efficient Open-
Domain Question Answering via Sparse Transformer Matching Retrieval. arXiv
preprint arXiv:2009.13013 (2020).
[51] Justin Zobel and Alistair Moffat. 2006. Inverted Files for Text Search Engines.
Comput. Surveys 38, 2 (2006), 6â€“es.
5348Text Matching Indexers in Taobao Search KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
A PROBLEM DEFINITION
For notation, let ğ‘ˆ={ğ‘¢1,...,ğ‘¢ğ‘}be a set ofğ‘users,ğ‘„={ğ‘1,...,ğ‘ğ¿}
the user queries, ğ¼={ğ‘–1,...,ğ‘–ğ‘€}a collection of items, and ğ‘‡=
{ğ‘¡1,...,ğ‘¡ğ¾}the unique terms that occur anywhere in the collection
ğ¼.
A.1 Pruned Inverted Indexer
To cope with the large query loads with limited response latency,
we prune the full inverted indexer at the posting level in advance.
We retain all terms but truncate each termâ€™s posting list to a given
lengthğ‘. Given a term ğ‘¡inğ‘‡,ğ¼ğ‘¡_ğ¹={ğ¼ğ‘¡_1,...,ğ¼ğ‘¡_ğ‘“}denotes its full
posting list, and ğ¼ğ‘¡_ğ‘ƒ={ğ¼ğ‘¡_1,...,ğ¼ğ‘¡_ğ‘}denotes its pruned posting
list. Typically, for each term ğ‘¡, we keep the top- ğ‘item candidates
fromğ¼ğ‘¡_ğ¹based on the scores ğ‘ between the term and items, i.e.,
ğ‘ =T(ğ‘¡,ğ¼ğ‘¡_ğ‘“), (19)
whereT(Â·) denotes the term-based scoring function and is instan-
tiated with the TermRank algorithm.
A.2 Semantic Indexer
Whenever a user submits a query ğ‘, we would like to return a set of
itemsğ‘–âˆˆğ¼that are associated with that query. Typically, we predict
the top-ğ‘˜item candidates from ğ¼based on the scores ğ‘ between the
query and items, i.e.,
ğ‘ =F(ğœ™(ğ‘),ğœ“(ğ‘–)), (20)
whereF(Â·) ,ğœ™(Â·),ğœ“(Â·)denote the scoring metric, query encoder,
and item encoder, respectively. For large-scale retrieval, we use the
two-tower neural model and instantiate Fwith the cosine function.
B ONLINE DEPLOYMENT
B.1 Retrieval Process Overview
As shown in Figure 1, when a user issues a query, the retrieval
process generally involves five stages.
(1)It first rewrites the user query using a module called Query
Planner (QP). For the query rewriting algorithms we used in
QP, see [22].
(2)Next, the rewriting queries and original query are used to ac-
cess the two indexers simultaneously. For the inverted index,
two-tiered indexes are stored, ğ¼ğ‘ƒandğ¼ğ¹.ğ¼ğ¹is the regular full
posting list of a term while ğ¼ğ‘ƒis the truncated one with a given
length. The semantic indexer comprises a query encoder neural
network and item embedding indexes. The latter are exported
by item encoder network in advance.
(3)During query evaluation by the inverted indexer, we use the
term whose full posting list is the shortest within a query to
accessğ¼ğ‘ƒ, and the remainders access ğ¼ğ¹. We call this strategy the
shortest posting list principle. Then we traverse all the posting
lists associated with the query and only return items that have
all the keywords (AND-semantics) to ensure high search rele-
vance (a.k.a. Document-At-A-Time strategy [ 44]). Besides, if the
relevant results are less than a few hundreds, we will do query
evaluation on all the ğ¼ğ¹again. Hence, ğ¼ğ‘ƒgreatly reduces both
the index access and the scoring costs while it may degrade
search quality.(4)While visiting the semantic indexer, the query embeddings are
predicted by the query encoder. And top- ğ‘˜results are returned
by a maximum inner product search (MIPS) [ 21] operation
between the query embedding and item embedding indexes.
(5)The results obtained from the two indexers are combined and
duplicates are removed as the final candidates for subsequent
ranking stages.
B.2 Indexer Deployment
Inverted Indexer. Due to the billion-scale item collection, we use
a number of partitions (called searchers ). Each contains an inverted
index, with pruned and full index, on a subset of the items. The
two-tiered indexes are created by an executor called index building
service. Thus, the inverted indexer is deployed with distribution on
machines of each searcher. Another kind of machines (called query
result service ) act as a query proxy that receives queries from the
users. They broadcast queries to searchers for fetching the top- ğ‘˜
results of each, and then merge the returned results into a distinct
candidate set that is sent back to the following ranking.
Semantic Indexer. All the item embeddings are exported from
the item tower by an index building service, and transmitted to an
approximate near neighbor (ANN) indexing module.4They are also
placed in multiple searchers because of their large number. Each
partition of the ANN builds indexes of embeddings by hierarchical
clustering (HC) algorithm with K-means and INT8 quantization to
promote storage and search efficiency. The training sample size of
HC is 4million, and the max scan ratio is 0.01. The query tower
is published to a real-time prediction platform for online inference.
The mechanism of the query result service is simultaneously used
for the semantic indexer. The final search results from SMIND are
as follow:
(Inverted Indexer results) OR (Semantic Indexer results)
B.3 Serving Policy
The user search preferences-aware pruned inverted indexer serves
all the query loads. For the semantic indexer, we propose to adapt an
â€œoffline&onlineâ€ mixed serving strategy to reduce latency. We only
feed the tail/new queries to online inference (real-time prediction ).
Despite the large number of tail and new queries, they account
for about 20%of online traffic. The remaining 80%of online traffic
is generated by millions of top queries, which typically remain
unchanged for a period of time. Hence, we run the query tower of
semantic indexer offline to export their embeddings, and then store
them in an online key-value graph engine (igraph ) for online ANN
indexing.
C EVALUATION DETAILS
C.1 Offline Evaluation
Evaluation in industry product search is non-trivial since we are
barely aware of the ground truth. We divide the evaluation into two
parts, offline and online evaluation. Offline evaluation is based on
sampled historical data, and online evaluation is based on daily new
4https://github.com/alibaba/proxima
5349KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Sen Li et al.
data. The common metrics used by offline and online evaluation
are Recall@ ğ¾andğ‘ƒğ‘”ğ‘œğ‘œğ‘‘.
Recall@ğ¾is used for evaluating the performance since it has a
positive correlation with the online income of Gross Merchandise
Volume (GMV) metric [ 23]. Specifically, given a query ğ‘ğ‘¢, the items
clicked or purchased by the user ğ‘¢are regarded as the target set
ğ‘‡={ğ‘¡1,...,ğ‘¡ğ‘}, and the top- ğ‘˜items returned by an indexer are
regarded as the retrieval set ğ¼={ğ‘–1,...,ğ‘–ğ¾}. Recall@ğ¾is defined
as:
ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ @ğ¾=Ãğ¾
ğ‘–=1ğ‘–ğ‘–âˆˆğ‘‡
ğ‘. (21)
Precision@K is not suitable for evaluation when the ground truth
is unknown. Instead, we use a well-trained â€œquery-itemâ€ relevance
model [ 46] (with an AUC of 0.92) to calculate the proportion of
products with good relevance (abbreviated as good rate and denoted
asğ‘ƒğ‘”ğ‘œğ‘œğ‘‘) in the retrieval set ğ¼, i.e.,
ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘=Ãğ¾
ğ‘–=1I(ğ‘–ğ‘–)
ğ¾, (22)
where I(Â·)is an indicator function. When item ğ‘–is rated as good by
the relevance model, its value is 1, otherwise 0. Note that ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘ is a
user search experience-related metric.C.2 Online Evaluation
Large-scale online tests are the most promising way to examine
system performance since they provide an open environment to
interact with users. We consider the two most valuable commerce
metrics, GMV (Gross Merchandise Volume) and POC (Pay Order
Count), which are defined as
ğºğ‘€ğ‘‰ =#pay amount , (23)
ğ‘ƒğ‘‚ğ¶=#pay order count . (24)
Besides GMV and POC, we report four auxiliary metrics, namely
ğ‘µ ğ’–ğ’ ğ’“ğ’‚ğ’ğ’Œ ,ğ‘¹ğ’†ğ’„ğ’‚ğ’ğ’ ğ’„ğ’ğ’Œ,ğ‘¹ğ’†ğ’„ğ’‚ğ’ğ’ ğ’‘ğ’–ğ’“, and ğ‘·ğ’ˆğ’ğ’ğ’… , which are defined
as follows:
ğ‘ğ‘¢ğ‘šğ‘Ÿğ‘ğ‘›ğ‘˜ Given a retrieval set ğ¼={ğ‘–1,...,ğ‘–ğ¾},ğ‘ğ‘¢ğ‘šğ‘Ÿğ‘ğ‘›ğ‘˜ is the
number of items entering the ranking stage. This reflects the
importance of an indexer in the search system.
ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘™ğ‘˜Eq. (21) is calculated on the item set ğ¼displayed to the
users and the target set ğ‘‡is the items clicked by users.
ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘¢ğ‘ŸIt is calculated similarly to ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘ğ‘™ğ‘˜, except that the
target setğ‘‡is the items purchased by users.
ğ‘ƒğ‘”ğ‘œğ‘œğ‘‘ Eq. (22) is calculated on the displayed item set ğ¼.
5350