Faster Accelerated First-order Methods for Convex
Optimization with Strongly Convex Function
Constraints
Zhenwei Lin
Shanghai University of Finance and Economics
zhenweilin@163.sufe.edu.cn
Qi Dengâˆ—
Antai College of Economics and Management
Shanghai Jiao Tong University
qdeng24@sjtu.edu.cn
Abstract
In this paper, we introduce faster accelerated primal-dual algorithms for minimizing
a convex function subject to strongly convex function constraints. Prior to our
work, the best complexity bound was O(1/Îµ), regardless of the strong convexity of
the constraint function. It is unclear whether the strong convexity assumption can
enable even better convergence results. To address this issue, we have developed
novel techniques to progressively estimate the strong convexity of the Lagrangian
function. Our approach, for the first time, effectively leverages the constraint strong
convexity, obtaining an improved complexity of O(1/âˆšÎµ). This rate matches the
complexity lower bound for strongly-convex-concave saddle point optimization
and is therefore order-optimal. We show the superior performance of our meth-
ods in sparsity-inducing constrained optimization, notably Googleâ€™s personalized
PageRank problem. Furthermore, we show that a restarted version of the proposed
methods can effectively identify the optimal solutionâ€™s sparsity pattern within a
finite number of steps, a result that appears to have independent significance.
1 Introduction
In this paper, we are interested in the following convex function-constrained problem:
minxâˆˆRnf(x) s.t. gi(x)â‰¤0,1â‰¤iâ‰¤m, (1)
where f:Rnâ†’Ris a convex continuous function and bounded from below and gi:Rnâ†’R,
i= 1,2, . . . , m , are strongly convex continuous functions. An important application of this problem,
commonly encountered in statistics and engineering, involves the objective f(x)as a proximal-
friendly regularizer and gi(x)as a data-driven loss function used to gauge model fidelity.
To apply first-order methods for the above function-constrained problems, a common strategy
involves a double-loop procedure that repeatedly employs fast first-order methods, such as Nesterovâ€™s
accelerated method, to solve specific strongly convex proximal subproblems. Popular methods among
this category include Augmented Lagrangian methods [ 18,33], level-set methods [ 21], penalty
methods [ 17]. When both f(x)andgi(x)are convex and smooth (or composite), it has been found
that these double-loop algorithms can attain an iteration complexity of O(1/Îµ)to achieve an Îµ-error
âˆ—Corresponding author
38th Conference on Neural Information Processing Systems (NeurIPS 2024).in both the optimality gap and constraint violation. When the objective is strongly convex, the
complexity can be further improved to O(1/âˆšÎµ)([33, 21]).
In contrast to these double-loop algorithms, single-loop algorithms remain popular due to their
simplicity in implementation. Along this research line, [32] developed a first-order algorithm based
on linearizing the augmented Lagrangian function, which obtains an iteration complexity of O(1/Îµ).
[34] extended the augmented Lagrangian method to stochastic function-constrained problems where
both objective and constraint exhibit an expectation form. Viewing (1)as a special case of the
min-max problem:
minxâˆˆRnmax yâˆˆRmL(x,y) :=f(x) +Pm
i=1yigi(x),s.t.yiâ‰¥0, i= 1,2, . . . , m, (2)
[11] proposed to solve (1)and(2)by an accelerated primal-dual method (APD), which generalizes
the primal-dual hybrid gradient method [ 6] initially developed for saddle point optimization with
bilinear coupling term. Under mild conditions, APD achieves the best iteration complexity of O(1/Îµ)
for general convex constrained problem and a further improved complexity of O(1/âˆšÎµ)when f(x)
is strongly convex. [ 4] proposed a unified constrained extrapolation method that can be applied to
both deterministic and stochastic constrained optimization problems.
Despite these recent progresses, to the best of our knowledge, all available algorithms are suboptimal
in the presence of strongly convex function constraints (1). Specifically, direct applications of previ-
ously discussed algorithms yield an O(1/Îµ)complexity, which is inferior to the O(1/âˆšÎµ)optimal
bound for the strongly-convex-concave saddle point problem [ 22]. It is somewhat unsatisfactory that
the strong convexity of g(x)has not been found helpful in further algorithmic acceleration. The core
underlying issue arises from the dynamics of saddle point optimization: it is the strong convexity
ofL(Â·,y)that offers more potential acceleration advantages, yet the strong convexity of L(Â·,y)is
substantially harder to estimate than that of g(x). This difficulty is compounded by the interplay
between g(x)and the varying dual sequence {yk}. The challenge naturally leads us to question: Is
it possible to further improve the convergence rate of first-order methods for solving the strongly
convex constrained problem (1)?
Key intuitions We make an assumption that the minimizer of f(x)is infeasible for the function
constraint gi(x)â‰¤0,1â‰¤iâ‰¤m. If this assumption were not made, we would be dealing with an
unconstrained optimization problem that would not depend on g(x). This assumption also implies
that the optimal dual variables are non-zero, and as a result, the Lagrangian function is strongly
convex with respect to x. By leveraging the strong convexity, we can use more aggressive step sizes
and achieve faster convergence rates compared to other state-of-the-art algorithms.
Applications in sparsity-constrained optimization We consider the constrained Lasso-type prob-
lem, which minimizes a sparsity-inducing regularizer while explicitly ensuring data-driven error
remains controlled:
minxâˆˆRnâˆ¥xâˆ¥1s.t.g(x)â‰¤0, (3)
where g(Â·)is a convex smooth loss term. A motivating application is the approximate personalized
PageRank problem [ 8], where g(x) =1
2âŸ¨x, QxâŸ© âˆ’ âŸ¨b,xâŸ©is strongly convex quadratic and Q
integrates the graph Laplacian with an identity matrix. Compared to the standard Lasso problem [ 30],
minxâˆˆRng(x)+Î»âˆ¥xâˆ¥1,the constrained problem (3)offers enhanced control over the data fitting error.
This advantage, however, is counterbalanced by the challenge of dealing with a nonlinear constraint.
Besides concerns about the efficiency in solving (3), it is often desired to show the active set (or
sparsity) identification, namely, the nonzero patterns of the optimal solution xâˆ—can be identified
by the solution sequence {xk}in a finite number of iterations. Identifying the embedded solution
structure within a broader context is referred to as the manifold identification problem [ 31,12].
Exploiting the sparsity pattern is particularly desirable in large-scale PageRank problems, as it could
result in significant runtime savings. For the regularized Lasso-type problem, it has been known
that proximal gradient methods (e.g. [ 14,19,24]) possess the finite active-set identification property.
Specifically, [ 24] introduced â€œactive set complexityâ€, which is defined as the number of iterations
required before an algorithm is guaranteed to have reached the optimal manifold, and they proved
the proximal gradient method with constant stepsize can identify the optimal manifold in a finite
number of iterations. However, for the problem (3), it remains unclear whether first-order methods
can identify the sparsity pattern in finite time.
2Contributions We address the theoretical questions about strongly convex constrained optimization
and the application of sparse optimization. Our contributions are summarized as follows.
First, we present a new accelerated primal-dual algorithm with progressive strong convexity estimation
(APDPro) for solving problem (1). APDPro employs a novel strategy to estimate the lower bound of
the dual variables, which leads to a gradually refined estimated strong convexity modulus of L(Â·,y).
With additional cut constraints on the dual update, APDPro is able to separate the dual search space
from the origin point, which is critical for maintaining the desired strong convexity over the entire
solution path. With these two important ingredients, APDPro exhibits an O 
(âˆ¥x0âˆ’xâˆ—âˆ¥+DY)/âˆšÎµ
complexity bound to obtain an Îµ-error on the function value gap and constraint violation, where DY
is a known upper-bound of âˆ¥y0âˆ’yâˆ—âˆ¥. Moreover, we show that for the last iterate to have an Îµerror
(i.e.,âˆ¥xKâˆ’xâˆ—âˆ¥2â‰¤Îµ), APDPro requires a total iteration of O 
(âˆ¥x0âˆ’xâˆ—âˆ¥+âˆ¥y0âˆ’yâˆ—âˆ¥)/âˆšÎµ
.
Both complexity results appear new in the literature for strongly convex-constrained optimization.
Second, we present a new restart algorithm (rAPDPro) which calls APDPro repeatedly with the input
parameters properly changing over time. Different from APDPro, rAPDPro dynamically adjusts the
iteration number of APDPro in each epoch based on the progressive strong convexity estimation. We
show that rAPDPro exhibits a complexity of O 
log(DX/âˆšÎµ) +DY/âˆšÎµ
to ensure Îµ-error in the
last iterate convergence where DXis the estimated diameter of the primal feasible domain. While
it is difficult to improve the overall O(1/âˆšÎµ)bound, rAPDPro appears to be more advantageous
when DXandDYare the same order of âˆ¥x0âˆ’xâˆ—âˆ¥andâˆ¥y0âˆ’yâˆ—âˆ¥, respectively, and DXâ‰«DY.
In addition, we show that a similar restart strategy can further accelerate the standard APD. The
multistage-accelerated primal dual method (msAPD) obtains a comparable O(1/âˆšÎµ)complexity of
APDPro without introducing additional cut constraint.
Third, we apply our proposed methods to the sparse learning problem (3). In view of the theoretical
analysis, all our methods converge at an O(1/âˆšÎµ)rate, which is substantially better than the rates of
state-of-the-art first-order algorithms. Moreover, we conduct a new analysis to show that the restart
algorithm rAPDPro has the favorable feature of identifying the optimal sparsity pattern. Note that
such active-set/manifold identification is substantially more challenging to prove due to the coupling
of dual variables and constraint functions. To establish the desired property, we develop asymptotic
convergence of the dual sequence to the optimal solution, which can be of independent interest.
Outline Section 2 sets notations and assumptions for the later analysis. Section 3 presents the
APDPro algorithm and develops its stepsize rule and complexity rate. Section 4 presents the
restart APDPro (rAPDPro) algorithm. Section 5 applies our proposed methods for sparsity-inducing
optimization and shows the sparsity identification result for rAPDPro. Section 6 empirically examine
the convergence performance and sparsity identification of our proposed algorithms. Finally, we draw
the conclusion in Section 7. All the missing proofs are provided in the appendix sections.
2 Preliminaries
We use bold letters like xto represent vectors. Suppose xâˆˆRn,qâ‰¥1, we use âˆ¥xâˆ¥q=
(Pn
i=1|x(i)|q)1/qto represent the lq-norm, where x(i)is the i-th element of x. For brevity, âˆ¥xâˆ¥stands
forl2-norm. For a matrix A, we denote the matrix norm induced by 2-norm as âˆ¥Aâˆ¥= supâˆ¥xâˆ¥â‰¤1âˆ¥Axâˆ¥.
The normal cone of Uatuis denoted as NU(u) :={v| âŸ¨v,xâˆ’uâŸ© â‰¤0,âˆ€xâˆˆ U} . LetB(x, r)be
the closed ball centered at xwith radius r >0, i.e.,B(x, r) ={y| âˆ¥yâˆ’xâˆ¥ â‰¤r}. We denote the
set of feasible solutions by XG:={x|gi(x)â‰¤0,âˆ€iâˆˆ[m]}and write the constraint function as
G(x) := [ g1(x), . . . , g m(x)]âŠ¤. We assume each gi(x)is aÂµistrongly convex function, and denote
Âµ:= [Âµ1, . . . , Âµ m]âŠ¤. Let [m] :={1, . . . , m }for integer m. We denote minimum and maximum
strongly convexity Âµ:= min jâˆˆ[m]{Âµj}, and Â¯Âµ:= max jâˆˆ[m]{Âµj}and the vector of elements 0 by 0.
The Lagrangian function of problem (1) is given by L(x,y) :=f(x) +âŸ¨y, G(x)âŸ©where yâˆˆRm
+.
Definition 1 (KKT condition) .We say that xâˆ—satisfies the KKT condition of(1)if there exists a
Lagrangian multiplier vector yâˆ—âˆˆRm
+such that 0âˆˆâˆ‚xL(xâˆ—,yâˆ—)andâŸ¨yâˆ—, G(xâˆ—)âŸ©= 0.
The KKT condition is necessary for optimality when a constraint qualification (CQ) holds at xâˆ—. We
assume Slaterâ€™s CQ (Assumption 1) holds, which guarantees that an optimal solution is also a KKT
point [3].
Assumption 1. There exists a strictly feasible point exâˆˆRnsuch that G(ex)<0.
3We use Ëœxto denote a strictly feasible point throughout the paper. Moreover, we require Assumption 2
to circumvent any trivial solution.
Assumption 2. For any xâˆ—
0âˆˆargminxâˆˆRnf(x), there exists an iâˆˆ[m]such that gi(xâˆ—
0)>0.
Remark 1. Assumption 2 is essential for our analysis. While verifying Assumption 2 can be indeed
challenging, it is achievable for the sparsity-inducing problem considered in our paper. In this
example, the solution xâˆ—
0=0is the single minimizer of the sparsity penalty.
Next, we give several useful properties about the optimal solutions of problem (1). Please refer to
Appendix D.1 for the proof of Proposition 1 and Appendix D.2 for the proof of Proposition 2.
Proposition 1. Suppose Assumption 1 holds. Then, for any optimal solution xâˆ—of problem (1), there
exists yâˆ—âˆˆRmsuch that KKT condition holds. Moreover, yâˆ—falls into set Y:=
y| âˆ¥yâˆ¥1â‰¤Â¯c	
,
where Â¯c:=f(ex)âˆ’minxâˆˆRnf(x)
miniâˆˆ[m]{âˆ’gi(ex)}.
Proposition 2. Under Assumption 2, xâˆ—is the unique solution of (1). Furthermore, set Yâˆ—=
argmaxyâˆˆRm
+L(xâˆ—,y)is convex and bounded.
In view of Assumption 2, Proposition 2, and closedness of the subdifferential set of proper con-
vex functions [ 2, Theorem 3.9], [ 27, Chapter 23], we know that dist(âˆ‚f(xâˆ—),0)>0,where
dist(âˆ‚f(xâˆ—),0) := min Î¾âˆˆâˆ‚f(xâˆ—)âˆ¥Î¾âˆ¥. Furthermore, we make the following assumption:
Assumption 3. Throughout the paper, suppose that a constant rsatisfying
dist(âˆ‚f(xâˆ—),0)â‰¥r >0, (4)
is known.
We give some important examples for which the lower bound rcan be estimated. Suppose f(x)is
a Lasso regularizer, i.e., f(x) =âˆ¥xâˆ¥1, then r= 1satisfies (4). More general, consider the group
Lasso regularizer, i.e., f(x) =PB
i=1piâˆ¥x(i)âˆ¥, where x(i)âˆˆRbiandPB
i=1bi=n,Bis the number
of blocks, then r= min iâˆˆ[B]{pi}when xâˆ—Ì¸=0. Another example is f(x) =câŠ¤x, then we have
r=âˆ¥câˆ¥.
Remark 2. Condition (4)is similar to the bounded gradient assumption that has been used for
accelerating the convergence of the Frank-Wolfe algorithm. See Appendix B for more discussions.
When considering the Lipschitz continuity of function in Rn, even quadratic functions are not
Lipschitz continuous. However, the Lipschitz continuity of gi(x)is crucial for algorithm convergence.
Therefore, we define the bounded feasible region in the following proposition, with its proof provided
in Appendix D.3.
Proposition 3. LetX:=B ex,miniâˆˆ[m]2q
âˆ’2gi(xâˆ—
i)
Âµi
, where xâˆ—
i= argminxâˆˆRngi(x). Then under
Assumptions 1 and 2, we have xâˆ—âˆˆintX.
Assumption 4. There exist LX, LG>0such that
âˆ¥âˆ‡G(x)âˆ’ âˆ‡G(Â¯x)âˆ¥ â‰¤LXâˆ¥xâˆ’Â¯xâˆ¥,âˆ€x,Â¯xâˆˆ X, (5)
âˆ¥G(x)âˆ’G(Â¯x)âˆ¥ â‰¤LGâˆ¥xâˆ’Â¯xâˆ¥,âˆ€x,Â¯xâˆˆ X, (6)
where âˆ‡G(x) := [âˆ‡g1(x),Â·Â·Â·,âˆ‡gm(x)]âˆˆRnÃ—mandXis defined in Proposition 3.
The Lipschitz smoothness of the Lagrangian function with respect to the primal variable xis crucial for
the convergence of algorithms. Given that the dual variable yis bounded from above, and considering
the smoothness of the constraint functions, we can derive the smoothness of the Lagrangian function.
Combining (5) and the fact âˆ¥yâˆ¥ â‰¤ âˆ¥yâˆ¥1â‰¤Â¯c,âˆ€yâˆˆ Y, we obtain that
âˆ¥âˆ‡G(x)yâˆ’ âˆ‡G(Â¯x)yâˆ¥ â‰¤LXYâˆ¥xâˆ’Â¯xâˆ¥ âˆ€x,Â¯xâˆˆ X,âˆ€yâˆˆ Y, (7)
where LXY= Â¯cLX. For set X,Y, we use DXandDYto denote their diameters, respectively, i.e.,
DX:= max x1,x2âˆˆXâˆ¥x1âˆ’x2âˆ¥andDY:= max y1,y2âˆˆYâˆ¥y1âˆ’y2âˆ¥.
4Algorithm 1 Accelerated Primal- Dual Algorithm with Progressive St rong Convexity Estimation
(APDPro)
Require: Ï„0>0, Ïƒ0>0,x0âˆˆ X,y0âˆˆ Y, Ï0â‰¥0, N > 0
1:Initialize: (xâˆ’1,yâˆ’1)â†(x0,y0),Â¯x0â†x0,Ïƒâˆ’1â†Ïƒ0, T0= 0
2:Setâˆ†XY=1
2Ï„0D2
X+1
2Ïƒ0D2
Y
3:fork= 0,1, . . . , N do
4: Ykâ†
yâˆˆRm
+| âˆ¥yâˆ¥1Â·Âµâ‰¥Ïk	TY,
5: zkâ†(1 +Ïƒkâˆ’1/Ïƒk)G(xk)âˆ’(Ïƒkâˆ’1/Ïƒk)G(xkâˆ’1)
6: yk+1â†argminyâˆˆYkâˆ¥yâˆ’(yk+Ïƒkzk)âˆ¥2
7: xk+1â†proxf,X(xkâˆ’Ï„kâˆ‡G(xk)yk+1, Ï„k)
8: Compute tk,Â¯xk+1â†(TkÂ¯xk+tkxk+1)/(Tk+tk),Tk+1â†Tk+tk
9: Update Ïk+1â†IMPROVE (xk,Â¯xk,Ïƒ0Ï„kâˆ’1âˆ†XY
Ïƒkâˆ’1,âˆ†XY
Tk,Ïk)
10: Update Ï„k+1andÏƒk+1depending on Ïk+1
11:end for
12:Output: xN+1,yN+1
13:procedure IMPROVE (x,Â¯x,Î²,Â¯Î²,Ïold)
14: Compute Ï=ÂµÂ·max
r
âˆ¥âˆ‡G(x)âˆ¥+LXâˆš2Î²âˆ’1,h
LX
rqÂ¯Î²
2Âµ+r
L2
XÂ¯Î²
2Âµr2+âˆ¥âˆ‡G(Â¯x)âˆ¥
riâˆ’2
15: SetÏnew= max {Ïold, Ï}
16: return Ïnew
17:end procedure
3 APD with progressive strong convexity estimation
We present the Accelerated Primal-Dual Algorithm with Progressive Strong Convexity Estimation
(APDPro) to solve problem (1). For problem (1), APDPro achieves the improved convergence rate
O(1/âˆšÎµ)without relying on the uniform strong convexity assumption [ 11,22]. For the rest of this
paper, we denote proxf,X(xâˆ’Î·z, Î·) := argminË†xâˆˆXf(Ë†x) +âŸ¨z,Ë†xâŸ©+1
2Î·âˆ¥Ë†xâˆ’xâˆ¥2as the proximal
mapping.
We describe APDPro in Algorithm 1. The main component of APDPro contains a dual ascent step
to update ykbased on the extrapolated gradient, followed by a primal proximal step to update xk.
Compared with standard APD [ 11], APDPro has two more steps. First, line 4 of Algorithm 1 applies
a novel cut constraint to separate the dual sequence {yk}from the origin, which allows us to leverage
the strong convexity of the Lagrangian function and hence obtain a faster rate of convergence than
APD. Second, to use the strong convexity more effectively, in line 9, we perform a progressive
estimation of the strong convexity by using the latest iterates xkandÂ¯xk. Throughout the algorithm
process, we use a routine IMPROVE to construct a non-decreasing sequence {Ïk}, which provides
increasingly refined lower bounds of the strong convexity of the Lagrangian function.
The IMPROVE step In order to estimate the strong convexity of the Lagrangian function, we
rely on the subdifferential separation (eq. (4)) to bound the dual variables. From the first-order
optimality condition in minimizing L(x,yâˆ—)and the fact that xâˆ—âˆˆintX(Proposition 3), we have
0âˆˆâˆ‚f(xâˆ—) +âˆ‡G(xâˆ—)yâˆ—+NX(xâˆ—) =âˆ‚f(xâˆ—) +âˆ‡G(xâˆ—)yâˆ—.It follows from (4) that
râ‰¤ âˆ¥âˆ‡ G(xâˆ—)yâˆ—âˆ¥ â‰¤ âˆ¥âˆ‡ G(xâˆ—)âˆ¥ Â· âˆ¥yâˆ—âˆ¥ â‰¤ âˆ¥yâˆ—âˆ¥1âˆ¥âˆ‡G(xâˆ—)âˆ¥, (8)
where the last inequality use the fact that âˆ¥ Â· âˆ¥ â‰¤ âˆ¥ Â· âˆ¥ 1. Note that the bound âˆ¥yâˆ—âˆ¥1â‰¥r/âˆ¥âˆ‡G(xâˆ—)âˆ¥
can not be readily used in the algorithm implementation because xâˆ—is generally unknown. To resolve
this issue, we develop more concrete dual lower bounds by using the generated solution Ë†xin the
proximity of xâˆ—. As we will show in the analysis, APDPro keeps track of two primal sequences
{xk}and{Â¯xk}, for which we can establish bounds on âˆ¥xkâˆ’xâˆ—âˆ¥2and(yâˆ—)âŠ¤ÂµÂ· âˆ¥Ë†xâˆ’xâˆ—âˆ¥2/2,
respectively. This drives us to develop the following lower bound property, with the proof provided
in Appendix E.1.
Proposition 4. Suppose Assumption 4 holds. Let yâˆ—âˆˆ Yâˆ—be a dual optimal solution.
1. Suppose that âˆ¥Ë†xâˆ’xâˆ—âˆ¥2â‰¤2Î², then we have
âˆ¥yâˆ—âˆ¥1â‰¥h1(Ë†x, Î²) :=r
âˆ¥âˆ‡G(Ë†x)âˆ¥+LXp
2Î²âˆ’1. (9)
52. Suppose (yâˆ—)âŠ¤ÂµÂ· âˆ¥Ë†xâˆ’xâˆ—âˆ¥2â‰¤2Î², then we have
âˆ¥yâˆ—âˆ¥1â‰¥h2(Ë†x, Î²) :=
LX
rq
Î²
2Âµ+r
L2
XÎ²
2Âµr2+âˆ¥âˆ‡G(Ë†x)âˆ¥
râˆ’2
. (10)
Our next goal is to conduct the convergence analysis for APDPro in Theorem 1 and Corollary 1.
Complete proof details are provided in Appendix E.2 and E.3.
Theorem 1. Suppose for any yâˆ—âˆˆ Yâˆ—,(yâˆ—)âŠ¤Âµâ‰¥Ï0holds, and let the sequence {Ï„k, Ïƒk, tk, Ïk+1}
generated by Algorithm 1 satisfy:
tk+1(Ï„âˆ’1
k+1âˆ’Ïk+1)â‰¤tkÏ„âˆ’1
k, t k+1Ïƒâˆ’1
k+1â‰¤tkÏƒâˆ’1
k, L XY+L2
GÏƒkâ‰¤Ï„âˆ’1
k. (11)
Then, the set Ykis nonempty and Yâˆ—âŠ† Yk. Letâˆ†(x,y) :=1
2Ï„0âˆ¥xâˆ’x0âˆ¥2+1
2Ïƒ0âˆ¥yâˆ’y0âˆ¥2,Â¯yK=
Tâˆ’1
KPKâˆ’1
s=0tsys. The sequence {Â¯xk,xk,Â¯yk}generated by APDPro satisfies
tKâˆ’1Ï„âˆ’1
Kâˆ’1
2TKâˆ¥xâˆ—âˆ’xKâˆ¥2+L(Â¯xK,yâˆ—)âˆ’ L(xâˆ—,Â¯yK)â‰¤1
TKâˆ†(xâˆ—,yâˆ—). (12)
Next, we develop more concrete complexity results in Corollary 1.
Corollary 1. Suppose that Ïƒk, Ï„k, tksatisfy:
Ï„âˆ’1
0â‰¥LXY+L2
GÏƒ0, tk=Ïƒk/Ïƒ0,
Ï„k+1=Ï„k/p
1 +Ïk+1Ï„k, Ïƒk+1=ÏƒkÏ„k/Ï„k+1(13)
Then we have
f(Â¯xK)âˆ’f(xâˆ—)â‰¤6
6+Ï„0ËœÏK(K+1)K
1
2Ï„0âˆ¥x0âˆ’xâˆ—âˆ¥2+D2
Y
2Ïƒ0
,
âˆ¥[G(Â¯xK)]+âˆ¥ â‰¤6
câˆ—(6+Ï„0ËœÏK(K+1)K)
1
2Ï„0âˆ¥x0âˆ’xâˆ—âˆ¥2+D2
Y
2Ïƒ0
,
1
2âˆ¥xKâˆ’xâˆ—âˆ¥2â‰¤3Ïƒ0
Ë†Ï2
KÏ„2
0K2+9(Ïƒ0/Ï„0)âˆ†(xâˆ—,yâˆ—).(14)
where câˆ—:= 
f(xâˆ—)âˆ’minxf(x)
/miniâˆˆ[m]{âˆ’gi(ex)}>0,ËœÏk= 2Pk
s=0Ë†Ïss/ 
k(k+ 1)
andËœÏk
satisfy the following condition, Ë†Ïk+1:=p
Ë†Ï2
kk2+ (3Ïk+1Ë†Ïk)k/(k+ 1),Ë†Ï1= 3p
Ï1/Ï„0.
Remark 3. In view of Corollary 1, APDPro obtains an iteration complexity of O(1/âˆšËœÏKÎµ), which
is substantially better than the O(1/Îµ)bound of APD [ 11] and ConEx [ 4] when the strong convexity
parameter ËœÏKis relatively large compared with Îµ.
Remark 4. Additionally, we argue that even when ËœÏK=O(Îµ),APDPro can obtain the
matching O(1/Îµ)bound of the state-of-the-art algorithms. Specifically, using the definition of
Ïƒk, Ï„k, we can easily derive the monotonicity of {Ïƒk}. It follows from Ïƒk+1=Ï„kÏƒk/Ï„k+1=
Ï„kÏƒk/ 
Ï„k/âˆš1 +Ïk+1Ï„k
â‰¥Ïƒk,thatTk=Pkâˆ’1
s=0tk=Ïƒâˆ’1
0Pkâˆ’1
s=0Ïƒkâ‰¥k. Using a sim-
ilar argument to that of Corollary 1, we obtain the bound f(Â¯xK)âˆ’f(xâˆ—)â‰¤ O (1/K)and
âˆ¥[G(Â¯xK)]+âˆ¥ â‰¤ O (1/K).
Remark 5. The implementation of APDPro requires knowing an upper bound on âˆ¥yâˆ—âˆ¥. When the
bound is unavailable, [ 11] developed an adaptive APD which still ensures the boundedness of dual
sequence via line search. Since our main goal of this paper is to exploit the lower-bound rather than
theupper bound ofâˆ¥yâˆ—âˆ¥, we leave the extension for the future work.
4 APDPro with a restart scheme
Note that in the worst case, APDPro exhibits an iteration complexity of O 
(DX+DY)/âˆšÎµ
, which
has a linear dependence on the diameter. While the O(1/âˆšÎµ)is optimal [ 25], it is possible to improve
the complexity with respect to the primal part from O 
DX/âˆšÎµ
toO 
log 
DX/âˆšÎµ
. To achieve
this goal, we propose a restart scheme (rAPDPro) that calls APDPro repeatedly and present the
details in Algorithm 2. Inspired by [ 16], we set the iteration number as a function of the estimated
strong convexity, detailed in the TERMINATE ITER procedure. For convenience in describing a
double-loop algorithm, we use superscripts for the number of epochs and subscripts for the number of
6Algorithm 2 Restarted APDPro (rAPDPro)
Require: Ïâˆ’1
Nâˆ’1â‰¥0,Â¯Ïƒ >0,Î½0âˆˆ(0,1),Î´âˆˆ(0,1),xâˆ’1
Nâˆ’1,yâˆ’1
Nâˆ’1, S
1:Compute Â¯Ï„= (1âˆ’Î½0) 
LXY+L2
GÂ¯Ïƒ/Î´âˆ’1
2:fors= 0,1, . . . , S do
3: Ï„s
0= Â¯Ï„, Ïƒs
0= Â¯Ïƒ,(xs
âˆ’1,ys
âˆ’1)â†(xsâˆ’1
Nsâˆ’1,ysâˆ’1
Nsâˆ’1),(xs
0,ys
0)â†(xsâˆ’1
Nsâˆ’1,ysâˆ’1
Nsâˆ’1), Ïs
0=Ïsâˆ’1
Nsâˆ’1
4: Setâˆ†XY=1
Ï„s
0D2
X+1
2Ïƒs
0D2
Y, Ïƒs
âˆ’1â†Ïƒs
0, Ts
0= 0, k= 0,Ë†Ïs
0= 1, Ns=âˆ
5: while k < N sdo
6: Run line 4-10 of APDPro with index set (s, k)
7: Update Ns,Ë†Ïs
k+1â†TERMINATE ITER(Ë†Ïs
k, Ïs
k+1, s, k ),kâ†k+ 1
8: end while
9:end for
10:Output: xS
NS,yS
NS11:procedure TERMINATE ITER(Ë†Ïold, Ï, s, k )
12: Compute Ë†Ïnew=(
1
k+1p
Ë†Ï2
oldk2+ 3ÏË†Ïoldk k > 1
3p
Ï/Ï„0 k= 1
13: Compute N=âŒˆmax{6(Ë†ÏnewÏ„s
0)âˆ’1,âˆš
2sÂ·3âˆš
2DY/ 
Ë†ÏnewDXpÏ„s
0Ïƒs
0
}âŒ‰
14: return N,Ë†Ïnew
15:end procedure
sub-iterations in parameters x,y, Ï„, Ïƒ , e.g., xS
1meaning the xoutput of first iterations at S-th epoch.
To avoid redundancy in the Algorithm 2, we call the APDPro iteration directly. Note that the notation
system here is identical to that of APDPro, with the only difference being the use of superscripts to
distinguish the number of epochs.
In Theorem 2, we show the overall convergence complexity of rAPDPro with the proof provided in
Appendix F.1.
Theorem 2. Let{xs
0}sâ‰¥0be the sequence generated by rAPDPro , then we have
âˆ¥xs
0âˆ’xâˆ—âˆ¥2â‰¤âˆ†sâ‰¡D2
XÂ·2âˆ’s,âˆ€sâ‰¥0. (15)
As a consequence, rAPDPro will find a solution xS
0such that âˆ¥xS
0âˆ’xâˆ—âˆ¥2â‰¤Îµfor any Îµâˆˆ(0, D2
X)
in at most S:=
log2(D2
X/Îµ)
epochs. Moreover, The iteration number of rAPDPro to find xS
0such
thatâˆ¥xS
0âˆ’xâˆ—âˆ¥2â‰¤Îµis bounded by
TÎµ:= 12
Ï–1Ï„s
0+ 2l
log2DXâˆšÎµ+ 1m
+ 6(âˆš
2+2)
Ï–2âˆš
Ï„s
0Ïƒs
0
Â· DYâˆšÎµ
, (16)
where Ï–1and Ï–2satisfyPS
s=0(Ë†Ïs
Ns)âˆ’1= ( Ï–1)âˆ’1(S+ 1) andPS
s=0âˆš
2s/Ë†Ïs
Ns=
(Ï–2)âˆ’1PS
s=0âˆš
2s, respectively.
Remark 6. The bound TÎµdepends on Îµ,Ï–1andÏ–2. IfÏ–1=O 
(âˆ’log2âˆšÎµ)âˆ’1
orÏ–2=O(âˆšÎµ),
then we have TÎµ=âˆ, which implies that we can not guarantee âˆ¥xs
0âˆ’xâˆ—âˆ¥ â‰¤Îµat finite iterations.
TÎµ=âˆimplies that there exists an epoch with infinite sub-iterations. Hence, rAPDPro is reduced to
APDPro if we only consider that epoch.
Remark 7. Comparison of rAPDPro and APDPro involves a number of factors. In particular,
rAPDPro compares favorably against APDPro ifâˆ¥x0âˆ’xâˆ—âˆ¥=eâ„¦(âˆšÎµlogDX). Moreover, the
complexity (16) can be slightly improved if DXis replaced by any tighter upper bound of âˆ¥xs
0âˆ’xâˆ—âˆ¥.
However, it is still unknown whether we can directly replace DXwithâˆ¥xs
0âˆ’xâˆ—âˆ¥in(16).
Dual Convergence For dual variables, we establish asymptotic convergence to the optimal solution,
a key condition for developing the active-set identification in the later section. For ease in notation, it
is more convenient to label the generated solution as a whole sequence using a single subscript index:
x1,x2, . . . ,xN;y1,y2, . . . ,yN. Hence, we use the index system jand(s, k)interchangeably. Note
that{xs+1
0,ys+1
0}and{xs
Ns+1,ys
Ns+1}correspond to the same pair of points. We present the dual
asymptotic result in the following theorem, with the proof provided in Appendix F.2.
Theorem 3. Assume Â¯Ï„âˆ’1>Ïand choose Î½0>0such that 1>infjâ‰¥0{Ïƒjâˆ’1/Ïƒj} â‰¥Î´+Î½0.We
have(xâˆ—,yâˆ—)satisfy the KKT condition, where yâˆ—is any limit point of {yj}generated by rAPDPro .
7Remark 8. To establish the asymptotic convergence of the dual variable, we introduce an addi-
tional constant Î´âˆˆ(0,1), which implies that the initial step size must meet a stricter requirement
than the convergence condition specified in Corollary 1. Since Ïƒs
k/Ïƒs
kâˆ’1=p1 +Ïs
kÏ„s
k,{Ïs
k}
is bounded due to the boundedness of the dual variable, {Ï„s
k}is monotonically decreasing, then
inf0â‰¤kâ‰¤Ns{Ïƒs
kâˆ’1/Ïƒs
k} â‰¥(1 +ÏÂ¯Ï„)âˆ’1/2. Hence, inequality, 1>infjâ‰¥0{Ïƒjâˆ’1/Ïƒj} â‰¥Î´+Î½0, is al-
ways satisfiable if we choose proper Î´, Î½0such that (1+ÏÂ¯Ï„)âˆ’1/2â‰¥Î´+Î½0. Furthermore, Assumption
(Â¯Ï„)âˆ’1>Ïis mild. Since we always choose Â¯Ïƒlarge enough in rAPDPro ,Â¯Ï„can be sufficiently small.
Remark 9. Both algorithms proposed previously require solving quadratic optimization with linear
constraints when updating dual variables, which may introduce implementation overheads when
the constraint number is high. Inspired by the multi-stage algorithm, we additionally propose an
algorithm (Multi-Stage APD, msAPD) that uses different step sizes in different stages and dynam-
ically adjusts the number of iterations in each stage by leveraging strong convexity, as detailed in
Appendix H.
5 Active-set identification in sparsity-inducing optimization
In this section, we apply our proposed algorithms to the aforementioned sparse learning problem:
minf(x),s.t.g(x)â‰¤0,x=x(1)Ã—. . .Ã—x(B),x(i)âˆˆRni,1â‰¤iâ‰¤B, (17)
where f(x) =PB
i=1piâˆ¥x(i)âˆ¥is the group Lasso regularizer and g(x)is a strongly convex function.
We use x(i)to express the i-th block coordinates of x. The goal of this section is to show that rAPDPro
can identify the sparsity pattern of the optimal solution of (17) in a finite number of iterations.
In general, suppose that f(x)has a separable structure f(x) =PB
i=1fi(x(i)), we define the active
setA(x)forf(x)byA(x) :={i:âˆ‚fi(x(i))is not a singleton }.Forf(x) =PB
i=1piâˆ¥x(i)âˆ¥, it
is easy to see that A(x)is the index set of the zero blocks: A(xâˆ—) =
i:xâˆ—
(i)=0	
. Next, we
describe one property for the optimal solution of (17) in Proposition 5 with the proof provided in
Appendix G.1.
Proposition 5. Under Assumptions 1 and 2, the KKT point for (17) is unique.
To identify the sparsity pattern (active set) of the optimal solution, it is common to assume the
existence of a non-degenerate optimal solution, which is stronger than the standard optimality
condition [ 24,29]. We say that xâˆ—is non-degenerate if 0âˆˆriâˆ‚L(xâˆ—,yâˆ—) =ri(âˆ‚f(xâˆ—)+âˆ‡g(xâˆ—)yâˆ—)
for the Lagrangian multiplier yâˆ—, where ristands for the relative interior. More specifically, (xâˆ—,yâˆ—)
satisfies the block-wise optimality condition
(
âˆ’[âˆ‡g(xâˆ—)yâˆ—](i)=âˆ‡fi(xâˆ—
(i)), ifi /âˆˆ A(xâˆ—),
âˆ’[âˆ‡g(xâˆ—)yâˆ—](i)âˆˆint 
âˆ‚fi(xâˆ—
(i))
,ifiâˆˆ A(xâˆ—).
Inspired by [ 24], we use the radius Î·:= min iâˆˆA(xâˆ—)
piâˆ’ âˆ¥[âˆ‡g(xâˆ—)yâˆ—](i)âˆ¥	
, which describes the
certain distance between the gradient and "subdifferential boundary" of the active set. We demonstrate
in the following theorem that the optimal sparsity pattern is identified when the iterates fall in a
neighborhood dependent on Î·, with the proof provided in Appendix G.2.
Theorem 4. SetX:=B
Ëœx,miniâˆˆ[m]2q
âˆ’2gi(xâˆ—
i)
Âµi+Î¶
withÎ¶ >0and3LXYÂ·(Â¯Ï„+(2LXY)âˆ’1)Â·Î¶ >
Î·Â¯Ï„inrAPDPro , then we have there exists a epoch Ë†S0such that xâˆ—
(i)=xs
k(i), sâ‰¥Ë†S0,âˆ€kâˆˆ[Ns],âˆ€iâˆˆ
A(xâˆ—).
Remark 10. The active-set identification result is achieved using the optimality condition at the next
iterate xk+1
i. To ensure xk+1
iâˆˆintX, we define an expanded region, which prevents cases where
the normal cone differs from {0}.
6 Numerical study
In this section, we examine the empirical performance of our proposed algorithms for solving the
sparse Personalized PageRank [ 8,9,23]. The constrained form of Personalized PageRank can be
80 1 2 3 4 5
1e41010
108
106
104
102
100
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0 1 2 3 4 5
1e3109
107
105
103
101
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e5106
104
102
100
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0 1 2 3 4 5
1e41010
108
106
104
102
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0 1 2 3 4 5
1e31011
109
107
105
103
101
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e51011
109
107
105
103
APD
Mirror-Prox
rAPDPro
msAPD
APD+restartFigure 1: The first row describes the convergence to optimum, where the y-axis re-
ports log10((âˆ¥D1/2xkâˆ¥1âˆ’ âˆ¥D1/2xâˆ—âˆ¥1)/âˆ¥D1/2xâˆ—âˆ¥1)for rAPDPro, and log10((âˆ¥D1/2Â¯xkâˆ¥1âˆ’
âˆ¥D1/2xâˆ—âˆ¥1)/âˆ¥D1/2xâˆ—âˆ¥1)for APD, APD+restart, msAPD and Mirror-Prox ( xâˆ—is computed by
MOSEK [ 1]). The second row describes feasibility violation, where y-axis reports the feasibility gap
log10(max{0, G(xk)})for rAPDPro, and log10(max{0, G(Â¯xk)})for APD, msAPD and Mirror-Prox.
Datasets (Left-Right order) correspond to bio-CE-HT, bio-CE-LC and econ-beaflw.
written as follows: minxâˆˆRnâˆ¥D1/2xâˆ¥1s.t.1
2âŸ¨x, QxâŸ© âˆ’Î±âŸ¨s, Dâˆ’1/2xâŸ© â‰¤b,where Q, D and
sare generated by graph. We implement both rAPDPro and msAPD. We skip APDPro as we
observe that the restart strategy consistently improves the algorithm performance. For comparison,
we consider the state-of-the-art accelerated primal-dual (APD) method [ 11], APD with restart
mechanism at fixed iterations (APD+restart) and Mirror-Prox [ 13]. 6 small to medium-scale datasets
from various domains in the Network Datasets [ 28] are selected in our experiments. All experiments
are implemented on Mac mini M2 Pro, 32GB. Due to the page limit, we only report results on three
datasets and leave more details in the last Appendix I.
We plot the relative function value gap |f(x)âˆ’f(xâˆ—)|/|f(xâˆ—)|and the feasibility violation
max{G(x),0}over the iteration number in Figure 1, respectively. Firstly, in terms of both op-
timality gap and constraint violation, the performance of rAPDPro and msAPD is significantly better
than that of APD, APD+restart and Mirror-Prox. Additionally, rAPDPro and msAPD often converge
to high-precision solutions. Secondly, based on the experimental results, it is indeed observed that
msAPD exhibits a periodic variation in convergence performance, which aligns with our algorithm
theory.
0 1 2 3 4 5
1e40.60.70.80.91.0
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0 1 2 3 4 5
1e30.8750.9000.9250.9500.9751.000
APD
Mirror-Prox
rAPDPro
msAPD
apd+restart
0.0 0.5 1.0 1.5 2.0
1e50.60.70.80.9
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
Figure 2: The experimental results on active-set identification. Datasets (Left-Right order) correspond
to bio-CE-HT, bio-CE-LC and econ-beaflw. The x-axis reports the iteration number and the y-axis
reports accuracy in active-set identification.
Next, we examine the algorithmâ€™s effectiveness in identifying sparsity patterns. We computed a nearly
optimal solution xâˆ—from MOSEK. Note that xâˆ—is a dense vector. For numerical consideration, we
truncate the coordinate values of xâˆ—to zero if the absolute value is below 10âˆ’8and perform the
same truncation to all the generated solutions of the compared algorithms. Then we use (|A(x)âˆ©
9A(xâˆ—)|+|Ac(x)âˆ© Ac(xâˆ—)|)/nto measure the accuracy of identifying the active set, where | Â· |
denotes the set cardinality. For rAPDPro, we consider the last iterate xkwhile for APD, msAPD
and Mirror-Prox, we plot the result on Â¯xk, as these are the solutions where the convergence rates are
established. Figure 2 plots the experiment result, from which we observe that rAPDPro and msAPD
are highly effective in identifying the active set. Often, they are able to recognize the structure of
the active set within a small number of iterations. Overall, the experimental results show the great
potential of our proposed algorithms in identifying the sparsity structure and are consistent with our
theoretical analysis.
7 Conclusion
The key contribution of this paper is that we develop several new first-order primal-dual algorithms
for convex optimization with strongly convex constraints. Using some novel strategies to exploit the
strong convexity of the Lagrangian function, we substantially improve the best convergence rate from
O(1/Îµ)toO(1/âˆšÎµ). In the application of constrained sparse learning problems, the experimental
study confirms the advantage of our proposed algorithms against state-of-the-art first-order methods
for constrained optimization. Moreover, we show that one of our proposed algorithms rAPDPro has
the favorable feature of identifying the sparsity pattern in the optimal solution. For future work, one
direction is to apply the adaptive strategy, such as line search, to our framework to deal with cases
when the dual bound is unavailable. Another interesting direction is to further exploit the active set
identification property in a general setting. For example, it would be interesting to incorporate our
algorithm with active constraint identification, which could be highly desirable when there are a large
number of constraints. It would also be interesting to consider a more general convex objective when
the proximal operator is not easy to compute.
Acknowledgement
This research is partially supported by the Major Program of National Natural Science Founda-
tion of China (Grant 72394360, 72394364), Natural Science Foundation of Shanghai (Grant No.
24ZR1421300). We sincerely thank all the reviewers for their valuable suggestions, which have
significantly improved the quality of our article.
References
[1]Mosek ApS. Mosek optimization toolbox for matlab. Userâ€™s Guide and Reference Manual,
Version , 4(1), 2019.
[2] Amir Beck. First-order methods in optimization . SIAM, 2017.
[3] Dimitri P. Bertsekas. Nonlinear programming . Athena Scientific, 1999.
[4]Digvijay Boob, Qi Deng, and Guanghui Lan. Stochastic first-order methods for convex and
nonconvex functional constrained optimization. Mathematical Programming , pages 1â€“65, 2022.
[5]GÃ¡bor Braun, Alejandro Carderera, Cyrille W Combettes, Hamed Hassani, Amin Karbasi,
Aryan Mokhtari, and Sebastian Pokutta. Conditional gradient methods. arXiv preprint
arXiv:2211.14103 , 2022.
[6]Antonin Chambolle and Thomas Pock. On the ergodic convergence rates of a first-order
primalâ€“dual algorithm. Mathematical Programming , 159(1):253â€“287, 2016.
[7]Joseph C Dunn. Rates of convergence for conditional gradient algorithms near singular and
nonsingular extremals. SIAM Journal on Control and Optimization , 17(2):187â€“211, 1979.
[8]Kimon Fountoulakis, Farbod Roosta-Khorasani, Julian Shun, Xiang Cheng, and Michael W
Mahoney. Variational perspective on local graph clustering. Mathematical Programming ,
174:553â€“573, 2019.
10[9]Kimon Fountoulakis and Shenghao Yang. Open problem: Running time complexity of acceler-
atedâ„“1-regularized pagerank. In Conference on Learning Theory , pages 5630â€“5632. PMLR,
2022.
[10] Dan Garber and Elad Hazan. Faster rates for the frank-wolfe method over strongly-convex sets.
InInternational Conference on Machine Learning , pages 541â€“549. PMLR, 2015.
[11] Erfan Yazdandoost Hamedani and Necdet Serhat Aybat. A primal-dual algorithm with line
search for general convex-concave saddle point problems. SIAM Journal on Optimization ,
31(2):1299â€“1329, 2021.
[12] Warren L Hare and Adrian S Lewis. Identifying active constraints via partial smoothness and
prox-regularity. Journal of Convex Analysis , 11(2):251â€“266, 2004.
[13] Niao He, Anatoli Juditsky, and Arkadi Nemirovski. Mirror prox algorithm for multi-term
composite minimization and semi-separable problems. Computational Optimization and Appli-
cations , 61(2):275â€“319, 2015.
[14] Franck Iutzeler and JÃ©rÃ´me Malick. Nonsmoothness in machine learning: specific structure,
proximal identification, and applications. Set-Valued and Variational Analysis , 28(4):661â€“678,
2020.
[15] Michel JournÃ©e, Yurii Nesterov, Peter RichtÃ¡rik, and Rodolphe Sepulchre. Generalized power
method for sparse principal component analysis. Journal of Machine Learning Research , 11(2),
2010.
[16] Guanghui Lan. First-order and stochastic optimization methods for machine learning . Springer,
2020.
[17] Guanghui Lan and Renato DC Monteiro. Iteration-complexity of first-order penalty methods
for convex programming. Mathematical Programming , 138(1):115â€“139, 2013.
[18] Guanghui Lan and Renato DC Monteiro. Iteration-complexity of first-order augmented la-
grangian methods for convex programming. Mathematical Programming , 155(1):511â€“547,
2016.
[19] Sangkyun Lee, Stephen J Wright, and LÃ©on Bottou. Manifold identification in dual averaging
for regularized stochastic online learning. Journal of Machine Learning Research , 13(6), 2012.
[20] Evgeny S Levitin and Boris T Polyak. Constrained minimization methods. USSR Computational
mathematics and mathematical physics , 6(5):1â€“50, 1966.
[21] Qihang Lin, Selvaprabu Nadarajah, and Negar Soheili. A level-set method for convex op-
timization with a feasible solution path. SIAM Journal on Optimization , 28(4):3290â€“3311,
2018.
[22] Tianyi Lin, Chi Jin, and Michael I Jordan. Near-optimal algorithms for minimax optimization.
InConference on Learning Theory , pages 2738â€“2779. PMLR, 2020.
[23] David MartÃ­nez-Rubio, Elias Wirth, and Sebastian Pokutta. Accelerated and sparse algorithms
for approximate personalized pagerank and beyond. arXiv preprint arXiv:2303.12875 , 2023.
[24] Julie Nutini, Mark Schmidt, and Warren Hare. â€œactive-set complexityâ€ of proximal gradient:
How long does it take to find the sparsity pattern? Optimization Letters , 13(4):645â€“655, 2019.
[25] Yuyuan Ouyang and Yangyang Xu. Lower complexity bounds of first-order methods for
convex-concave bilinear saddle-point problems. Mathematical Programming , 185(1):1â€“35,
2021.
[26] H. Robbins and D. Siegmund. A convergence theorem for non negative almost supermartingales
and some applications. In Jagdish S. Rustagi, editor, Optimizing Methods in Statistics , pages
233â€“257. Academic Press, 1971.
[27] R Tyrrell Rockafellar. Convex analysis , volume 18. Princeton university press, 1970.
11[28] Ryan A. Rossi and Nesreen K. Ahmed. The network data repository with interactive graph
analytics and visualization. In AAAI , 2015.
[29] Yifan Sun, Halyun Jeong, Julie Nutini, and Mark Schmidt. Are we there yet? manifold
identification of gradient-related proximal methods. In The 22nd International Conference on
Artificial Intelligence and Statistics , pages 1110â€“1119. PMLR, 2019.
[30] Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal
Statistical Society: Series B (Methodological) , 58(1):267â€“288, 1996.
[31] Stephen J Wright. Identifiable surfaces in constrained optimization. SIAM Journal on Control
and Optimization , 31(4):1063â€“1079, 1993.
[32] Yangyang Xu. First-order methods for constrained convex programming based on linearized
augmented lagrangian function. Informs Journal on Optimization , 3(1):89â€“117, 2021.
[33] Yangyang Xu. Iteration complexity of inexact augmented lagrangian methods for constrained
convex programming. Mathematical Programming , 185(1):199â€“244, 2021.
[34] Liwei Zhang, Yule Zhang, Jia Wu, and Xiantao Xiao. Solving stochastic optimization with
expectation constraints efficiently by a stochastic augmented lagrangian-type algorithm. IN-
FORMS Journal on Computing , 34(6):2989â€“3006, 2022.
12Appendix
A Limitations 14
B Comparison with Frank-Wolfe 14
C Auxiliary lemmas 14
D Proof details in Section 2 15
D.1 Proof of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
D.2 Proof of Proposition 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
D.3 Proof of Proposition 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
E Convergence analysis of APDPro 16
E.1 Proof of Proposition 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
E.2 Proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
E.3 Proof of Corollary 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
F Convergence analysis of rAPDPro 20
F.1 Proof of Theorem 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
F.2 Proof of Theorem 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
G Proof details for sparsity identification 23
G.1 Proof of Proposition 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
G.2 Proof of Theorem 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
H A multi-stage accelerated primal-dual algorithm 25
I Experiment details 27
Structure of the Appendix
The appendix is structured as follows: Appendix A introduces some limitations of our methods,
primarily concerning the application scenarios of our algorithm. Appendix B includes comparisons
between ours and some related Frank-Wolfe methods. We give some auxiliary lemmas in Appendix C,
which are very important for the proofs presented later. Appendix D, E, F and G present the proof
of conclusion in Section 2, 3, 4 and 5, respectively. Furthermore, Appendix H introduces a new
algorithm to obtain a convergence rate without complicated dual updating. Finally, Appendix I offers
more extensive details on our experiments.
13A Limitations
In this paper, we focus on the theoretical analysis of convex optimization. Although our proposed
algorithms for the convex optimization with strongly convex constraints can theoretically improve the
existing results from O(1/Îµ)toO(1/âˆšÎµ). However, we still need to point out that our optimization
algorithm has the following limitations. One is the algorithm needs a lower bound on the norm
of sub-gradients of the objective function in the optimal solution, which may not be satisfied for
all functions. On the other hand, we require consistent smoothness of the constraints to ensure
convergence, and how to use the line search method to ensure convergence is a future direction.
B Comparison with Frank-Wolfe
We note that the strongly convex function constraint in (1)is a special case of a strongly convex set
constraint, as demonstrated in [ 15]. Over the strongly convex set, it has been shown that Frank-Wolfe
Algorithm (FW) can obtain convergence rates substantially better than the worst-case O(1/Îµ)rate.
Under the bounded gradient assumption, [ 7,20] show that FW obtains linear convergence over a
strongly convex set. Nevertheless, the uniform bounded gradient assumption appears to be stronger
than ours, as we only impose the lower boundedness assumption on the optimal solution xâˆ—and allow
the objective to be non-differentiable. More recently, [ 10] shows that FW obtains an O(1/âˆšÎµ)rate
when the gradient is the order of the square root of the function value gap. For more recent progress,
please refer to [ 5]. Despite the attractive convergence property, FW exhibits certain limitations when
applied to the general function constraints (1)addressed in this paper. Specifically, FW involves a
sequence of linear optimization problems throughout the iterations. While linear optimization over
certain strongly convex sets, such as â„“p-ball, admits a closed-form solution, there exists no efficient
routine to handle general function constraints explored in this paper.
C Auxiliary lemmas
The following three-point property is important in the convergence analysis.
Lemma 1. Letf:Rnâ†’Râˆª{+âˆ}be a closed strongly convex function with modulus Âµâ‰¥0. Give
Â¯xâˆˆ X, where Xis a compact convex set and tâ‰¥0, letx+= argminxâˆˆXf(x) +t
2âˆ¥xâˆ’Â¯xâˆ¥2,then
for all xâˆˆ X, we have
f(x) +t
2âˆ¥xâˆ’Â¯xâˆ¥2â‰¥f(x+) +t+Âµ
2âˆ¥x+âˆ’xâˆ¥2+t
2âˆ¥x+âˆ’Â¯xâˆ¥2.
Proof. SinceXis a convex compact set, Ï•(x) :=IX(x)+f(x)+t
2âˆ¥xâˆ’Â¯xâˆ¥2is lower-semi-continuous
and(Âµ+t)-strongly convex, where IX(x) =0xâˆˆ X
âˆx/âˆˆ X. Using the optimality ( 0âˆˆÏ•(x+)) and
strong convexity, we have Ï•(x)â‰¥Ï•(x+) +âŸ¨0,xâˆ’x+âŸ©+t+Âµ
2âˆ¥x+âˆ’xâˆ¥2, for any xâˆˆ X. This
immediately gives the desired relation.
The following result is adjusted from the classic supermartingale convergence theorem [ 26, Theorem
1]. We give proof for completeness.
Lemma 2. Let(â„¦,F,P)be a probability space and F1âŠ‚ F 2âŠ‚ Â·Â·Â· be a sequence of sub- Ïƒ-algebras
ofF. For each j= 1,2,Â·Â·Â·, letaj, bjandcjbe non-negative Fn-measure random variables such
E[aj+1| Fj]â‰¤ajâˆ’bj+cj, then we have limjâ†’âˆaj<âˆexists andPâˆ
j=1bj<âˆa.s. whenPâˆ
j=1cj<âˆ.
Proof. Define dj=ajâˆ’Pjâˆ’1
l=1(clâˆ’bl)and for any Â¯a >0, define t= inf{t:Pt
l=1cl>Â¯a}. If
j < t , we have
E[dj+1| Fj] =E[aj+1âˆ’Pj
l=1(clâˆ’bl)| Fj](a)
â‰¤ajâˆ’Pjâˆ’1
l=1(clâˆ’bl) =:dj, (18)
where (a)holds by E[aj+1| Fj]â‰¤aj+cjâˆ’bj, and hence
E[dmin{t,(j+1)}| Fj] =dtI{tâ‰¤j}+E[dj+1| Fj]I{t>j}(a)
â‰¤dmin{t,j},
14where (a)holds by (18). Therefore, we have {dmin{t,(j+1)},Fj,1â‰¤jâ‰¤ âˆ} is a supermartingale.
Since
dmin{t,j}=amin{t,j}âˆ’Pmin{t,j}âˆ’1
l=1(clâˆ’bl)(a)
â‰¥ âˆ’Pmin{t,(jâˆ’1)}
l=1clâ‰¥ âˆ’Â¯a,
holds for all j, where (a)holds by amin{t,j}, blâ‰¥0. Then it follows from the martingale convergence
theorem that limjâ†’âˆdmin{t,j}exists and is finite a.s., i.e., limjâ†’âˆdjexists and is finite on {t=
âˆ}={Pâˆ
j=1cjâ‰¤Â¯a}. Since Â¯ais arbitrary, we see that limjâ†’âˆdjexists and is finite a.s. on
{Pâˆ
j=1cj<âˆ}. By dj=ajâˆ’Pjâˆ’1
l=1(clâˆ’bl), we have limjâ†’âˆajexists and is finite andPâˆ
j=1bj<âˆwhen{Pâˆ
j=1cj<âˆ}.
D Proof details in Section 2
D.1 Proof of Proposition 1
Proof. Under Slaterâ€™s CQ, it is standard to show that any optimal solution xâˆ—will also satisfy the
KKT condition. For example, one can refer to [3]. For any xâˆˆ XG, we have
f(x) +âŸ¨yâˆ—, G(x)âŸ© â‰¥f(xâˆ—) +âŸ¨yâˆ—, G(xâˆ—)âŸ©=f(xâˆ—),
where the equality is from the complementary slackness. In view of the above result and the Slaterâ€™s
condition (i.e., G(Ëœx)<0), we have
f(Ëœx)> f(Ëœx) +âŸ¨yâˆ—, G(Ëœx)âŸ© â‰¥f(xâˆ—). (19)
Combining with fact âˆ¥yâˆ—âˆ¥1miniâˆˆ[m]
âˆ’gi(Ëœx)	
â‰¤ âˆ’âŸ¨yâˆ—, G(Ëœx)âŸ©, then we have
âˆ¥yâˆ—âˆ¥ â‰¤ âˆ¥yâˆ—âˆ¥1â‰¤f(Ëœx)âˆ’f(xâˆ—)
miniâˆˆ[m]{âˆ’gi(Ëœx)}= Â¯c, (20)
where the last inequality is by f(xâˆ—)â‰¥minxâˆˆRnf(x).
D.2 Proof of Proposition 2
Proof. We prove the uniqueness property by contradiction. Suppose that there exist (xâˆ—,yâˆ—),(Ëœxâˆ—,Ëœyâˆ—)
satisfying the KKT condition, then from the complementary slackness, optimality of xâˆ—andËœxâˆ—, we
have
L(xâˆ—,yâˆ—) =f(xâˆ—) =f(Ëœxâˆ—) =L(Ëœxâˆ—,Ëœyâˆ—).
Moreover, we have L(Ëœxâˆ—,Ëœyâˆ—)â‰¤ L(xâˆ—,Ëœyâˆ—)â‰¤ L(xâˆ—,yâˆ—).Hence, we must have L(Ëœxâˆ—,Ëœyâˆ—) =
L(xâˆ—,Ëœyâˆ—). However, since Assumption 2 implies Ëœyâˆ—Ì¸=0, the strongly convex function L(Â·,Ëœyâˆ—)has
a unique optimizer. Therefore, we conclude that xâˆ—=Ëœxâˆ—.
Next, we show that the set of optimal dual variables for problem (1)is convex. Suppose that there
exist two optimal dual variables yâˆ—
1andyâˆ—
2for the unique primal variable xâˆ—, both satisfying the KKT
condition, then we have âŸ¨yâˆ—
1, G(xâˆ—)âŸ©=âŸ¨yâˆ—
2, G(xâˆ—)âŸ©= 0. This implies that any linear combination
ofyâˆ—
1andyâˆ—
2satisfy KKT condition, i.e., âŸ¨ayâˆ—
1+byâˆ—
2, G(xâˆ—)âŸ©= 0,âˆ€a, b. From Proposition 1, we
know any optimal dual variable falls into a bounded convex set Y. The intersection of two convex
sets is also a convex set. Hence, we complete our proof.
D.3 Proof of Proposition 3
Proof. From the strong convexity of gi(x), we have gi(x)â‰¥gi(xâˆ—
i) +Âµi
2âˆ¥xâˆ’xâˆ—
iâˆ¥2,which implies
âˆ¥Ëœxâˆ’xâˆ—
iâˆ¥2â‰¤(gi(Ëœx)âˆ’gi(xâˆ—
i))2
Âµi(a)
<âˆ’2gi(xâˆ—
i)
Âµi,
âˆ¥xâˆ—âˆ’xâˆ—
iâˆ¥2â‰¤(gi(xâˆ—)âˆ’gi(xâˆ—
i))2
Âµiâ‰¤âˆ’2gi(xâˆ—
i)
Âµi,(21)
where (a)holds by gi(Ëœx)<0. In view of the triangle inequality and the above result, we have
âˆ¥Ëœxâˆ’xâˆ—âˆ¥ â‰¤ âˆ¥xâˆ—
iâˆ’xâˆ—âˆ¥+âˆ¥Ëœxâˆ’xâˆ—
iâˆ¥<2q
âˆ’2gi(xâˆ—
i)
Âµi.
Hence, xâˆ—âˆˆintB
Ëœx,miniâˆˆ[m]2q
âˆ’2gi(xâˆ—
i)
Âµi
.
15E Convergence analysis of APDPro
E.1 Proof of Proposition 4
Proof. Using the triangle inequality and (5), we have
âˆ¥âˆ‡G(xâˆ—)âˆ¥ âˆ’ âˆ¥âˆ‡ G(Ë†x)âˆ¥ â‰¤ âˆ¥âˆ‡ G(xâˆ—)âˆ’ âˆ‡G(Ë†x)âˆ¥ â‰¤LXâˆ¥Ë†xâˆ’xâˆ—âˆ¥.
Combining the above inequality and (8), we obtain
r
âˆ¥yâˆ—âˆ¥1â‰¤LXâˆ¥Ë†xâˆ’xâˆ—âˆ¥+âˆ¥âˆ‡G(Ë†x)âˆ¥. (22)
Next, we develop more specific lower bounds on âˆ¥yâˆ¥1. i). Inequality (9)can be easily verified since
we have âˆ¥Ë†xâˆ’xâˆ—âˆ¥ â‰¤âˆš2Î². ii). Suppose (yâˆ—)âŠ¤ÂµÂ· âˆ¥Ë†xâˆ’xâˆ—âˆ¥2â‰¤2Î², then together with (22) we have
r
âˆ¥yâˆ—âˆ¥1â‰¤LXq
2Î²
(yâˆ—)âŠ¤Âµ+âˆ¥âˆ‡G(Ë†x)âˆ¥ â‰¤LXq
2Î²
Âµâˆ¥yâˆ—âˆ¥1+âˆ¥âˆ‡G(Ë†x)âˆ¥.
Note that the above inequality can be expressed as at2âˆ’btâˆ’câ‰¤0witht=âˆ¥yâˆ—âˆ¥âˆ’1/2
1 ,a=r, b=
LXq
2Î²/Âµ andc=âˆ¥âˆ‡G(Ë†x)âˆ¥. Standard analysis implies that tâ‰¤(b+âˆš
b2+ 4ac)/2a, which gives
the desired bound (10).
E.2 Proof of Theorem 1
Proof. First, it is easy to verify by our construction that {Yk}is a monotone sequence: Y1âŠ‡ Y 2âŠ‡
. . .âŠ‡ Yk. . .. Our goal is to show Yâˆ—âŠ† Ykholds for any kâ‰¥0by induction. Note that Yâˆ—âŠ† Y 0
immediately follows from our assumption that (yâˆ—)âŠ¤Âµâ‰¥Ï0, for any yâˆ—âˆˆ Yâˆ—. Suppose that
Yâˆ—âŠ† Ykholds for k= 0, . . . , K âˆ’1, we claim:
1. For any xâˆˆ X andyâˆˆ Yâˆ—, we have
L(Â¯xK,y)âˆ’ L(x,Â¯yK)â‰¤1
TKâˆ†(x,y)âˆ’tKâˆ’1Ï„âˆ’1
Kâˆ’1
2TKâˆ¥xâˆ’xKâˆ¥2. (23)
2.Yâˆ—âŠ† YK.
Part 1. For k= 0,1,2, . . . , K âˆ’1, taking âˆ’âŸ¨zk,Â·âŸ©andf(Â·) +âŸ¨âˆ‡G(xk)yk+1,Â·âŸ©in Lemma 1, the
following relations
âˆ’âŸ¨yk+1âˆ’y,zkâŸ© â‰¤Ak+1, (24)
f(xk+1) +
yk+1,âˆ‡G(xk)âŠ¤(xk+1âˆ’x)
â‰¤f(x) +Bk+1, (25)
where
Ak+1â‰œ1
2Ïƒk 
âˆ¥yâˆ’ykâˆ¥2âˆ’ âˆ¥yâˆ’yk+1âˆ¥2âˆ’ âˆ¥yk+1âˆ’ykâˆ¥2
, (26)
Bk+1â‰œ1
2Ï„k 
âˆ¥xâˆ’xkâˆ¥2âˆ’ âˆ¥xâˆ’xk+1âˆ¥2âˆ’ âˆ¥xk+1âˆ’xkâˆ¥2
, (27)
hold for any xâˆˆ X andyâˆˆT
0â‰¤sâ‰¤kYs. The existence of such yfollows from our induction
hypothesis. Since yâŠ¤
k+1G(Â·)isÏk-strongly convex, we have

yk+1,âˆ‡G(xk)âŠ¤(xk+1âˆ’x)
â‰¥
yk+1,âˆ‡G(xk)âŠ¤(xk+1âˆ’xk)
+âŸ¨yk+1, G(xk+1)âˆ’G(x)âŸ© âˆ’ âŸ¨yk+1, G(xk+1)âˆ’G(xk)âŸ©+Ïk
2âˆ¥xâˆ’xkâˆ¥2.
Combining this result and (25), we have
f(xk+1)âˆ’f(x) +âŸ¨yk+1, G(xk+1)âˆ’G(x)âŸ©
â‰¤Bk+1âˆ’
yk+1,âˆ‡G(xk)âŠ¤(xk+1âˆ’xk)
+âŸ¨yk+1, G(xk+1)âˆ’G(xk)âŸ© âˆ’Ïk
2âˆ¥xâˆ’xkâˆ¥2.(28)
On the other hand, by the definition of zk, we have
âŸ¨yâˆ’yk+1,zkâŸ©
=âŸ¨yâˆ’yk+1, G(xk)âˆ’G(xk+1)âŸ©+âŸ¨yâˆ’yk+1, G(xk+1)âŸ© (29)
+ (Ïƒkâˆ’1/Ïƒk)âŸ¨yâˆ’yk, G(xk)âˆ’G(xkâˆ’1)âŸ©+ (Ïƒkâˆ’1/Ïƒk)âŸ¨ykâˆ’yk+1, G(xk)âˆ’G(xkâˆ’1)âŸ©.
16Let us denote qk=G(xk)âˆ’G(xkâˆ’1)for brevity. Combining (24) and (29) yields
âŸ¨yâˆ’yk+1, G(xk+1)âŸ©
â‰¤Ak+1+âŸ¨yâˆ’yk+1, G(xk+1)âˆ’G(xk)âŸ© âˆ’(Ïƒkâˆ’1/Ïƒk)âŸ¨yâˆ’yk,qkâŸ© âˆ’(Ïƒkâˆ’1/Ïƒk)âŸ¨ykâˆ’yk+1,qkâŸ©.
(30)
Putting (28) and (30) together, we have
L(xk+1,y)âˆ’ L(x,yk+1)
â‰¤Ak+1+Bk+1âˆ’
yk+1,âˆ‡G(xk)âŠ¤(xk+1âˆ’xk)
+âŸ¨yk+1, G(xk+1)âˆ’G(xk)âŸ©
+âŸ¨yâˆ’yk+1,qk+1âŸ© âˆ’(Ïƒkâˆ’1/Ïƒk)âŸ¨yâˆ’yk,qkâŸ©+ (Ïƒkâˆ’1/Ïƒk)âŸ¨yk+1âˆ’yk,qkâŸ© âˆ’Ïk
2âˆ¥xâˆ’xkâˆ¥2
â‰¤Ak+1+Bk+1+LXY
2âˆ¥xk+1âˆ’xkâˆ¥2âˆ’Ïk
2âˆ¥xâˆ’xkâˆ¥2
+âŸ¨yâˆ’yk+1,qk+1âŸ© âˆ’(Ïƒkâˆ’1/Ïƒk)âŸ¨yâˆ’yk,qkâŸ©+ (Ïƒkâˆ’1/Ïƒk)âŸ¨yk+1âˆ’yk,qkâŸ©,
where the last inequality is by Lipschitz smoothness of âŸ¨yk+1, G(Â·)âŸ©.
Next, we bound the term âŸ¨qk,yk+1âˆ’ykâŸ©by Youngâ€™s inequality, which gives
âŸ¨yk+1âˆ’yk,qkâŸ© â‰¤1
2Ïƒkâˆ’1âˆ¥yk+1âˆ’ykâˆ¥2+Ïƒkâˆ’1
2âˆ¥qkâˆ¥2, (31)
It follows from (31) andÏƒk
2âˆ¥qk+1âˆ¥2â‰¤L2
GÏƒk
2âˆ¥xk+1âˆ’xkâˆ¥2that
L(xk+1,y)âˆ’ L(x,yk+1)
â‰¤Ï„âˆ’1
kâˆ’Ïk
2âˆ¥xâˆ’xkâˆ¥2âˆ’Ï„âˆ’1
k
2âˆ¥xâˆ’xk+1âˆ¥2+(Ïƒkâˆ’1/Ïƒk)Ïƒkâˆ’1
2âˆ¥qkâˆ¥2âˆ’Ïƒk
2âˆ¥qk+1âˆ¥2
+1
2Ïƒk 
âˆ¥yâˆ’ykâˆ¥2âˆ’ âˆ¥yâˆ’yk+1âˆ¥2
+âŸ¨yâˆ’yk+1,qk+1âŸ© âˆ’(Ïƒkâˆ’1/Ïƒk)âŸ¨yâˆ’yk,qkâŸ©
âˆ’Ïƒâˆ’1
kâˆ’(Ïƒkâˆ’1/Ïƒk)/Ïƒkâˆ’1
2âˆ¥yk+1âˆ’ykâˆ¥2+L2
GÏƒk
2âˆ¥xk+1âˆ’xkâˆ¥2âˆ’Ï„âˆ’1
kâˆ’LXY
2âˆ¥xk+1âˆ’xkâˆ¥2.(32)
Multiply both sides of the above relation by tkand sum up the result for k= 0,1, . . . , K âˆ’1. In
view of the parameter relation (11), we have
PKâˆ’1
k=0tk
L(xk+1,y)âˆ’ L(x,yk+1)
(a)
â‰¤t0(Ï„âˆ’1
0âˆ’Ï0)
2âˆ¥xâˆ’x0âˆ¥2âˆ’tKâˆ’1Ï„âˆ’1
Kâˆ’1
2âˆ¥xâˆ’xKâˆ¥2âˆ’tKâˆ’1ÏƒKâˆ’1
2âˆ¥qKâˆ¥2
+t0Ïƒâˆ’1
0
2âˆ¥yâˆ’y0âˆ¥2âˆ’tKâˆ’1Ïƒâˆ’1
Kâˆ’1
2âˆ¥yâˆ’yKâˆ¥2+tKâˆ’1âŸ¨yâˆ’yK,qKâŸ© âˆ’t0âŸ¨yâˆ’y0,q0âŸ©
(b)
â‰¤1
2Ï„0âˆ¥xâˆ’x0âˆ¥2+1
2Ïƒ0âˆ¥yâˆ’y0âˆ¥2âˆ’tKâˆ’1Ï„âˆ’1
Kâˆ’1
2âˆ¥xâˆ’xKâˆ¥2(33)
where (a)usesq0=0andxâˆ’1=x0, and (b)holds by Ï0= 0,t0= 1and
tKâˆ’1âŸ¨yâˆ’yK,qKâŸ© â‰¤tKâˆ’1
2ÏƒKâˆ’1âˆ¥yâˆ’yKâˆ¥2+tKâˆ’1
2/ÏƒKâˆ’1âˆ¥qKâˆ¥2.
SinceL(x,y)is convex in xand linear in y, we have
TK
L(Â¯xK,y)âˆ’ L(x,Â¯yK)
â‰¤PKâˆ’1
k=0tk
L(xk+1,y)âˆ’ L(x,yk+1)
, (34)
Combining (33) and (34), we obtain
TK
L(Â¯xK,y)âˆ’ L(x,Â¯yK)
â‰¤1
2Ï„0âˆ¥xâˆ’x0âˆ¥2âˆ’tKâˆ’1Ï„âˆ’1
Kâˆ’1
2âˆ¥xâˆ’xKâˆ¥2+1
2Ïƒ0âˆ¥yâˆ’y0âˆ¥2. (35)
Dividing both sides by TK,we obtain the desired result (23).
Part 2. Next we show Yâˆ—âŠ† YK. Letyâˆ—be any point in Yâˆ—. Since (35) holds for any xâˆˆ X and
yâˆˆ âˆ©0â‰¤kâ‰¤Kâˆ’1YkâŠ‡ Yâˆ—, we can place x=xâˆ—,y=yâˆ—âˆˆ Yâˆ—in (23) to obtain
tKâˆ’1Ï„âˆ’1
Kâˆ’1
2TKâˆ¥xâˆ—âˆ’xKâˆ¥2+L(Â¯xK,yâˆ—)âˆ’ L(xâˆ—,Â¯yK)â‰¤1
TKâˆ†(xâˆ—,yâˆ—).
Moreover, the strong convexity of L(Â·,yâˆ—)implies
L(Â¯xK,yâˆ—)â‰¥ L(xâˆ—,yâˆ—) +(yâˆ—)âŠ¤Âµ
2âˆ¥Â¯xKâˆ’xâˆ—âˆ¥2â‰¥ L(xâˆ—,Â¯yK) +(yâˆ—)âŠ¤Âµ
2âˆ¥Â¯xKâˆ’xâˆ—âˆ¥2.
17Applying the above two inequalities yields
(yâˆ—)âŠ¤Âµ
2âˆ¥Â¯xKâˆ’xâˆ—âˆ¥2â‰¤1
TKâˆ†(xâˆ—,yâˆ—),1
2âˆ¥xKâˆ’xâˆ—âˆ¥2â‰¤Ï„Kâˆ’1Ïƒ0
ÏƒKâˆ’1âˆ†(xâˆ—,yâˆ—). (36)
In view of (36) and Proposition 4, we have that
(yâˆ—)TÂµâ‰¥Âµâˆ¥yâˆ—âˆ¥1=Âµmax
h1(xK,Ïƒ0Ï„Kâˆ’1âˆ†XY
ÏƒKâˆ’1), h2(Â¯xK,âˆ†XY
TK)	
:= Ë†ÏK.
Moreover, since Yâˆ—âŠ† Y Kâˆ’1, we have (yâˆ—)TÂµâ‰¥ÏKâˆ’1. Hence we have (yâˆ—)TÂµâ‰¥ÏKwhere
ÏK= max {Ë†ÏK, ÏKâˆ’1}is the output of the IMPROVE procedure. Due to the construction of YK, we
immediately see that yâˆ—âˆˆ YK. This implies Yâˆ—âŠ† YKand completes our induction proof.
Next, we specify the stepsize selection in Lemma 3 and develop more concrete complexity results in
Corollary 1.
Lemma 3. LetË†Ïk+1:=âˆš
Ë†Ï2
kk2+(3Ïk+1Ë†Ïk)k
k+1forkâ‰¥1andË†Ï1= 3q
Ï1
Ï„0. Suppose Ïƒk, Ï„ksatisfy:
Ï„âˆ’1
0â‰¥LXY+L2
GÏƒ0, Ï„k+1=Ï„k(1 +Ïk+1Ï„k)âˆ’1
2, Ïƒk+1=Ï„kÏƒk
Ï„k+1. (37)
Then we have
1
Ï„2
kâ‰¥Ë†Ï2
k
9k2+1
Ï„2
0, Tkâ‰¥1 +Ï„0
6ËœÏk(k+ 1)k,Ë†Ïkâ‰¥min{Ï1,Ë†Ï1}, (38)
where ËœÏk= 2Pk
s=0Ë†Ïss
k(k+1)forkâ‰¥1. Moreover, suppose Â¯ÏÏ„0â‰¤2, where Â¯Ï= Â¯cÂ·Â¯Âµ, then we have
Ïƒ2
kâ‰¤Ïƒ2
0(k+ 1)2. (39)
Proof. We first use induction to show that1
Ï„2
kâ‰¥Ë†Ï2
k
9k2+1
Ï„2
0. It is easy to see that1
Ï„2
kâ‰¥Ë†Ï2
k
9k2+1
Ï„2
0
holds for k= 1by the definition Ë†Ï1= 3p
Ï1/Ï„0andÏ„1=Ï„0(1+Ï1Ï„0)âˆ’1
2. Assume1
Ï„2
kâ‰¥Ë†Ï2
k
9k2+1
Ï„2
0
holds for all k= 0, . . . , K , then we have
1
Ï„2
K+1=1
Ï„2
K+ÏK+1
Ï„K
â‰¥Ë†Ï2
K
9K2+1
Ï„2
0+ÏK+1r
Ë†Ï2
K
9K2+1
Ï„2
0
â‰¥Ë†Ï2
K
9K2+1
Ï„2
0+ÏK+1Ë†ÏKK
3
â‰¥Ë†Ï2
K+1
9(K+ 1)2+1
Ï„2
0,(40)
which completes our induction. It follows from1
Ï„2
kâ‰¥Ë†Ï2
k
9k2+1
Ï„2
0and the relation among Tk, tk, Ïƒk, Ï„k
that, for any kâ‰¥1
Tk=Pkâˆ’1
s=0ts= 1 +Pkâˆ’1
s=1tsâ‰¥1 +Pkâˆ’1
s=1Ïƒs
Ïƒ0= 1 +Pkâˆ’1
s=1Ï„0
Ï„sâ‰¥1 +Ï„0Pkâˆ’1
s=1r
Ë†Ï2
ss2
9+1
Ï„2
0
>1 +Ï„0Pkâˆ’1
s=1Ë†Ïss
3= 1 +Ï„0
6ËœÏk(k+ 1)k.
(41)
Similarly, we use induction to prove
Ë†Ïkâ‰¥min{Ï1,Ë†Ï1},âˆ€kâ‰¥1. (42)
It is easy to find that Ë†Ï1â‰¥min{Ï1,Ë†Ï1}. We assume that Ë†Ïkâ‰¥min{Ï1,Ë†Ï1},âˆ€kâ‰¥1holds for any
k= 1, . . . , K . Considering Ë†ÏK+1, we have
Ë†ÏK+1â‰¥1
K+1q
Ë†Ï2
KK2+ 3Ï1Ë†ÏKK
â‰¥1
K+1q
(min{Ï1,Ë†Ï1})2K2+ 3Ï1Â·min{Ï1,Ë†Ï1}Kâ‰¥min{Ï1,Ë†Ï1},
18which completes the induction. Moreover, we use induction to show Ïƒ2
kâ‰¤Ïƒ2
0(k+ 1)2. It is obvious
that the inequality holds for k= 0. Assume the inequality holds for all k= 0, . . . , K, then we have
Ïƒ2
K+1=Ïƒ2
K(1 +ÏK+1Ï„0Ïƒ0
ÏƒK)
=Ïƒ2
K+ÏK+1Ï„0Ïƒ0ÏƒK
â‰¤Ïƒ2
0 
(K+ 1)2+ÏK+1Ï„0(K+ 1)
â‰¤Ïƒ2
0(K+ 2)2,(43)
where the last inequality use the relation Ïkâ‰¤Â¯Ï,âˆ€k, and Â¯ÏÏ„0â‰¤2.
E.3 Proof of Corollary 1
Proof. First, we show that the sequences {Ï„k, Ïƒk, tk, Ïk}generated by APDPro satisfy the relation-
ship in (11) in Theorem 1. The first part of (11) can be derived using the monotonicity of {Ïk}as
follows:
tk+1 
Ï„âˆ’1
k+1âˆ’Ïk+1
=Ïƒâˆ’1
0 
Ïƒk+1Ï„k+1âˆ’Ïƒk+1Ïk+1
=Ïƒâˆ’1
0 
ÏƒkÏ„kÏ„âˆ’2
k+1âˆ’Ïƒk+1Ïk+1
=Ïƒâˆ’1
0 
Ïƒk(1 +Ïk+1Ï„k)/Ï„kâˆ’Ïƒk+1Ïk+1
=Ïƒâˆ’1
0 
Ïƒk/Ï„k+Ïk+1Ïƒkâˆ’Ïƒk+1Ïk+1
â‰¤tkÏ„âˆ’1
k
The second part of (11) can be easily verified using the parameters setting.
Next, we prove the last term in (11) by induction. Firstly, it easy to verify that for any Ïƒ0>0,
there exists Ï„0âˆˆ(0,(LXY+L2
GÏƒ0)âˆ’1]such that last term of (11) holds. Hence, when k= 0, the
last term of (11) is directly from the first term of (13). Suppose that the last term of (11) holds for
k= 0, . . . , K âˆ’1. From ÏƒKâˆ’1/ÏƒK=Ï„K/Ï„Kâˆ’1â‰¤1, we have
1
Ï„K=ÏƒK
Ï„Kâˆ’1ÏƒKâˆ’1â‰¥LXY
ÏƒKâˆ’1/ÏƒK+L2
GÏƒKâ‰¥LXY+L2
GÏƒK. (44)
Without loss of generality, place x=xâˆ—,y=y+:= (âˆ¥yâˆ—âˆ¥1+câˆ—)[G(Â¯xK)]+
âˆ¥[G(Â¯xK)]+âˆ¥in(23), and using
âˆ¥yâˆ—âˆ¥1â‰¤Â¯cin Proposition 1. It is easy to see âˆ¥y+âˆ¥=âˆ¥yâˆ—âˆ¥1+câˆ—â‰¤Â¯c, andâˆ¥y+âˆ¥1â‰¥ âˆ¥y+âˆ¥=
âˆ¥yâˆ—âˆ¥1+câˆ—â‰¥ âˆ¥yâˆ—âˆ¥1,Hence, we conclude that y+âˆˆ Yk,âˆ€kâ‰¥0.
Now observe that L(Â¯xK,yâˆ—)âˆ’ L(xâˆ—,yâˆ—)â‰¥0, which implies f(Â¯xK) +âŸ¨yâˆ—, G(Â¯xK)âŸ© âˆ’f(xâˆ—)â‰¥0.
In view of âŸ¨yâˆ—, G(Â¯xK)âŸ© â‰¤ âŸ¨yâˆ—,[G(Â¯xK)]+âŸ© â‰¤ âˆ¥yâˆ—âˆ¥ Â· âˆ¥[G(Â¯xK)]+âˆ¥, then we have
f(Â¯xK) +âˆ¥yâˆ—âˆ¥ Â· âˆ¥[G(Â¯xK)]+âˆ¥ âˆ’f(xâˆ—)â‰¥0. (45)
Moreover, it follows from âˆ¥yâˆ—âˆ¥1â‰¥ âˆ¥yâˆ—âˆ¥that
L(Â¯xK,y+)âˆ’ L(xâˆ—,Â¯yK)â‰¥ L(Â¯xK,y+)âˆ’ L(xâˆ—,yâˆ—)
â‰¥f(Â¯xK) + (âˆ¥yâˆ—âˆ¥+câˆ—)âˆ¥[G(Â¯xK)]+âˆ¥ âˆ’f(xâˆ—).(46)
Combining (45), (46) and (23), we obtain
max
câˆ—âˆ¥[G(Â¯xK)]+âˆ¥, f(Â¯xK)âˆ’f(xâˆ—)	
â‰¤1
TK 1
2Ï„0âˆ¥x0âˆ’xâˆ—âˆ¥2+D2
Y
2Ïƒ0
, (47)
In view of the bound in (38) and the relation between Ï„k, Ïƒk, we can get
Ï„k
Ïƒkâ‰¤3
Ë†Ï2
kÏ„2
0k2+9Ïƒ0/Ï„0. (48)
In view of (47) and (38), we have
max
câˆ—âˆ¥[G(Â¯xK)]+âˆ¥, f(Â¯xK)âˆ’f(xâˆ—)	
â‰¤6
6+Ï„0ËœÏK(K+1)K 1
2Ï„0âˆ¥x0âˆ’xâˆ—âˆ¥2+D2
Y
2Ïƒ0
.
Combining (23) and (48) yields1
2âˆ¥xKâˆ’xâˆ—âˆ¥2â‰¤3Ïƒ0âˆ†(xâˆ—,yâˆ—)/(Ë†Ï2
KÏ„2
0K2+ 9Ïƒ0/Ï„0).
19F Convergence analysis of rAPDPro
F.1 Proof of Theorem 2
Proof. First, we show that the choice of Ï„s
0= Â¯Ï„, Ïƒs
0= Â¯Ïƒ,âˆ€sâ‰¥0satisfy the condition (13) in
Corollary 1: (Ï„s
0)âˆ’1â‰¥(1âˆ’Î½0)(Ï„s
0)âˆ’1=LXY+cL2
GÏƒs
0/Î´â‰¥LXY+cL2
GÏƒs
0.
Next, we show (15) holds by induction. Clearly, (15) holds for s= 0. Assume âˆ¥xs
0âˆ’xâˆ—âˆ¥2â‰¤âˆ†s
holds for s= 0, . . . , S âˆ’1. Then by Theorem 1, we have
âˆ¥xS
0âˆ’xâˆ—âˆ¥2â‰¤ÏƒS
0Ï„S
NS
ÏƒS
NS
2
Ï„S
0âˆ†S+1
ÏƒS
0D2
Y
. (49)
In view of the first bound in (38) and the relation between Ï„s
Ns, Ïƒs
Ns, we can get
Ï„s
Ns
Ïƒs
Nsâ‰¤9
Ïƒs
0Ï„s
0(Ë†ÏNsNs)2. (50)
Combining (49) and (50) yields
âˆ¥xS
0âˆ’xâˆ—âˆ¥2â‰¤18
(Ë†ÏNsÏ„s
0Ns)2+9D2
Y
Ïƒs
0Ï„s
0(Ë†ÏNsNs)2.
Since the algorithm sets Ns=âŒˆmax{6(Ë†ÏNsÏ„s
0)âˆ’1,âˆš
2sÂ·3âˆš
2DY/ 
Ë†ÏNsDXpÏ„s
0Ïƒs
0
}âŒ‰, it follows
that
18
(Ë†ÏNsÏ„s
0Ns)2â‰¤18
(Ë†ÏNsÏ„s
0)2Â·(Ë†ÏNsÏ„s
0)2
36=1
2,
9D2
Y
Ïƒs
0Ï„s
0(Ë†ÏNsNs)2â‰¤9D2
Y
Ïƒs
0Ï„s
0Ë†Ï2
NsÂ·Ë†Ï2
NsÏƒs
0Ï„s
0D2
X
18D2
Y2s=1
2Â·2âˆ’sD2
X=1
2âˆ†S,
which implies the desired result (15).
Let the algorithm run for S=
log2(D2
X/Îµ)
epochs, then âˆ¥xS
0âˆ’xâˆ—âˆ¥2â‰¤D2
XÂ·2âˆ’Sâ‰¤Îµ. The total
iteration number required by Algorithm 2 for attaining a solution xS
0such that âˆ¥xS
0âˆ’xâˆ—âˆ¥2â‰¤Îµis
PS
s=0Nsâ‰¤PS
s=0n
6
Ë†Ïs
NsÏ„s
0+3âˆš
2DY
Ë†Ïs
NsDXâˆš
Ï„s
0Ïƒs
0âˆš
2s+ 1o
(a)=
6
Ï–1Ï„s
0+ 1
(S+ 1) +3âˆš
2DY
Ï–2DXâˆš
Ï„s
0Ïƒs
0PS
s=0âˆš
2s
â‰¤
12
Ï–1Ï„s
0+ 2l
log2DXâˆšÎµ+ 1m
+3âˆš
2DY
Ï–2DXâˆš
Ï„s
0Ïƒs
0Â·âˆš
2S+1âˆ’1âˆš
2âˆ’1
â‰¤
12
Ï–1Ï„s
0+ 2l
log2DXâˆšÎµ+ 1m
+3âˆš
2DY(âˆš
2+1)
Ï–2DXâˆš
Ï„s
0Ïƒs
0Â· âˆš
2log2(D2
X/Îµ)+2âˆ’1
â‰¤
12
Ï–1Ï„s
0+ 2l
log2DXâˆšÎµ+ 1m
+6DY(âˆš
2+2)
Ï–2âˆš
Ï„s
0Ïƒs
0Â·1âˆšÎµ,
where (a)holds byPS
s=0(Ë†Ïs
Ns)âˆ’1= (Ï–1)âˆ’1(S+ 1) andPS
s=0âˆš
2s/Ë†Ïs
Ns= (Ï–2)âˆ’1PS
s=0âˆš
2s.
Now, we give some proof details in dual convergence results. Let
Qj(x,y) :=(Ï„j)âˆ’1âˆ’Ïj
2âˆ¥xâˆ’xjâˆ¥2+1
2Ïƒjâˆ¥yâˆ’yjâˆ¥2+ (Ïƒjâˆ’1/Ïƒj)âŸ¨yjâˆ’y, G(xj)âˆ’G(xjâˆ’1)âŸ©
+(Ïƒjâˆ’1/Ïƒj)
2/Ïƒjâˆ’1âˆ¥G(xj)âˆ’G(xjâˆ’1)âˆ¥2,
then we establish an important property about the solution sequence in the following lemma.
Lemma 4. Assume Â¯Ï„âˆ’1>Ïand choose Î½0>0such that
1>inf
jâ‰¥0{Ïƒjâˆ’1/Ïƒj} â‰¥Î´+Î½0. (51)
Then there exists an Î½1>0such that for any jâ‰¥0and any KKT point (xâˆ—,Ëœyâˆ—):
0â‰¤tjQj(xâˆ—,Ëœyâˆ—)âˆ’tj+1Qj+1(xâˆ—,Ëœyâˆ—)âˆ’Î½1tjh
1
2Ï„jâˆ¥xj+1âˆ’xjâˆ¥2+1
2Ïƒjâˆ¥yj+1âˆ’yjâˆ¥2i
,
0< tjQj(xâˆ—,Ëœyâˆ—).
20Proof. First, we give some results that will be used repeatedly in the following. For notation
simplicity, we denote Î¸j=Ïƒjâˆ’1/Ïƒj. In view of Lemma 3, and the parameter ergodic sequence
generated by rAPDPro, we have
(Ï„s
k)âˆ’1, Ïƒs
k	
is monotonically increasing sequence in k,Â¯Ï„=
Ï„s
0,Â¯Ïƒ=Ïƒs
0, ts
0= 1,âˆ€sâ‰¥0, and there exist a Î½3>0such that Â¯Ïƒ+Î½3â‰¤Ïƒ:= min s{Ïƒs
Ns}. Now, for
rAPDPro, we claim that there exist Î½1, Î½2>0such that the following two conditions hold
1. For any jâ‰¥0, we have
min
1âˆ’Î´,(Ï„âˆ’1
jâˆ’LXYâˆ’L2
GÏƒj)Ï„j	
â‰¥Î½1>0, (52)
and
tjminn
Ï„âˆ’1
jâˆ’Ïj,1
Ïƒjâˆ’Î´
Ïƒjâˆ’1o
â‰¥Î½2>0. (53)
2. For any jâ‰¥0, we have
0â‰¤tjQj(xâˆ—,Ëœyâˆ—)âˆ’tj+1Qj+1(xâˆ—,Ëœyâˆ—)âˆ’Î½1tj 
(2Ï„j)âˆ’1âˆ¥xj+1âˆ’xjâˆ¥2+(2Ïƒj)âˆ’1âˆ¥yj+1âˆ’yjâˆ¥2
.(54)
Part 1. We first consider two subsequent points xjandxj+1within the same epoch, and assume
jâˆ¼(s, k). Then, it follows from Î¸s
k=Ïƒs
kâˆ’1/Ïƒs
kthat
(Ïƒs
k)âˆ’1âˆ’Î¸s
kÎ´(Ïƒs
kâˆ’1)âˆ’1= (Ïƒs
k)âˆ’1âˆ’Î´(Ïƒs
k)âˆ’1=1âˆ’Î´
Ïƒs
k(51)
â‰¥Î½0
Ïƒs
k. (55)
Next, we use induction to show
1âˆ’Î½0
Ï„s
kâ‰¥LXY+L2
GÏƒs
kÎ´âˆ’1. (56)
When k= 0, inequality (56) degenerates as the definition of Ï„s
0, Ïƒs
0. Suppose (56) holds for
k= 0,1, . . . , K âˆ’1. Then, from Î¸s
K=Ïƒs
Kâˆ’1/Ïƒs
K=Ï„s
K/Ï„s
Kâˆ’1â‰¤1, we have
(1âˆ’Î½0)(Ï„s
K)âˆ’1= (1âˆ’Î½0)(Ï„s
Kâˆ’1Î¸s
K)âˆ’1â‰¥LXY
Î¸s
K+L2
GÏƒs
Kâˆ’1Î´âˆ’1
Î¸s
Kâ‰¥LXY+L2
GÏƒs
KÎ´âˆ’1,
which completes our induction proof. Hence, combining (55) and (56), we have
min
1âˆ’Î´, 
(Ï„s
k)âˆ’1âˆ’LXYâˆ’L2
GÏƒs
k/Î´
Ï„s
k	
â‰¥Î½0,âˆ€kâˆˆ[Ns]. (57)
Furthermore, when switching to the next epoch (sâ†’s+ 1) , we have
Ïƒs+1
0((Ïƒs+1
0)âˆ’1âˆ’Î¸s+1
0Î´/Ïƒs
Ns)(a)
â‰¥Ïƒs+1
0((Ïƒs+1
0)âˆ’1âˆ’(Ïƒs
Ns)âˆ’1)(b)
â‰¥1âˆ’Ïƒs+1
0Ïƒâˆ’1= 1âˆ’Â¯ÏƒÏƒâˆ’1
((Ï„s+1
0)âˆ’1âˆ’LXYâˆ’L2
GÎ´âˆ’1Ïƒs+1
0)Ï„s+1
0(c)
â‰¥Î½0Ï„s+1
0=Î½0Â¯Ï„,
(58)
where (a)holds by Î¸s
0= 1,Î´ <1,(b)follows from (Ïƒs
Ns)âˆ’1â‰¥Ïƒâˆ’1. Hence, combining (55),(57)
and (58), we completes our proof of (52) by setting Î½1= min {1âˆ’Â¯ÏƒÏƒâˆ’1, Î½0Â¯Ï„, Î½0}.
Since rAPDPro reset the stepsize periodically and {ts
k,(Ï„s
k)âˆ’1}kâˆˆ[Ns]are two monotonically increas-
ing sequences, hence
inf
jâ‰¥0tj(Ï„âˆ’1
jâˆ’Ïj)â‰¥ts
0(Â¯Ï„âˆ’1âˆ’Ï) = Â¯Ï„âˆ’1âˆ’Ï. (59)
Consider infkâˆˆ[Ns]ts
kÏƒs
k(1âˆ’Î´Ïƒs
k/Ïƒs
kâˆ’1). Combining Î´+Î½0â‰¤infkâˆˆ[Ns]{Î¸s
k}, then
inf
kâˆˆ[Ns]ts
kÏƒs
k(1âˆ’Î´Ïƒs
k
Ïƒs
kâˆ’1) = inf
kâˆˆ[Ns]ts
kÏƒs
k(1âˆ’Î´/Î¸s
k)â‰¥Î½0Â¯Ïƒ. (60)
Furthermore, when switching to the next epoch (sâ†’s+ 1) , we have
inf
sâ‰¥0ts+1
0Ïƒs+1
0(1âˆ’Î´Ïƒs+1
0(Ïƒs
Ns)âˆ’1) = Â¯Ïƒ2inf
sâ‰¥0(Â¯Ïƒâˆ’1âˆ’Î´(Ïƒs
Ns)âˆ’1)â‰¥Â¯Ïƒ(1âˆ’Î´), (61)
where the last inequality holds by Â¯Ïƒ=Ïƒs
0â‰¤Ïƒs
Ns. Hence, it follows from (59),(60) and(61) that
there exist Î½2= min {Â¯Ï„âˆ’1âˆ’Ï, Î½0Â¯Ïƒ,Â¯Ïƒ(1âˆ’Î´)}such (53) holds.
21Part 2. for any jâ‰¥0,we have
tj+1Qj+1(xâˆ—,Ëœyâˆ—)â‰¤tj (Ï„j)âˆ’1
2âˆ¥xâˆ—âˆ’xj+1âˆ¥2+âŸ¨G(xj+1)âˆ’G(xj),yj+1âˆ’Ëœyâˆ—âŸ©
+ (2Ïƒj)âˆ’1âˆ¥Ëœyâˆ—âˆ’yj+1âˆ¥2+Ïƒj
2âˆ¥G(xj+1)âˆ’G(xj)âˆ¥2
.(62)
Consider kâˆˆ {0,1, . . . , N s}. Inequality (51) implies (11) holds (see proof of Corollary 1 in
Section E.3). Hence, for 0â‰¤kâ‰¤Ns,we have
tj+1Qj+1(xâˆ—,Ëœyâˆ—)â‰¤ts
k (Ï„s
k)âˆ’1
2âˆ¥xâˆ—âˆ’xs
k+1âˆ¥2+
G(xs
k+1)âˆ’G(xs
k),ys
k+1âˆ’Ëœyâˆ—
+1
2Ïƒs
kâˆ¥Ëœyâˆ—âˆ’ys
k+1âˆ¥2+Ïƒs
k
2Î´âˆ¥G(xs
k+1)âˆ’G(xs
k)âˆ¥2 (63)
where jcorresponds to (s, k). Furthermore, consider switching to next epoch (sâ†’s+ 1) . Since
ts
k(Ï„s
k)âˆ’1is an increasing sequence in k,Ïs+1
0>0, ts+1
0= 1, hence
ts
Ns(Ï„s
Ns)âˆ’1â‰¥ts+1
0(Ï„s+1
0)âˆ’1âˆ’Ïs+1
0ts+1
0,âˆ€sâ‰¥0. (64)
Next, we have
ts
Ns
Ïƒs
Ns(a)=ts+1
0
Ïƒs+1
0, ts
Ns(b)
â‰¥ts+1
0(c)=ts+1
0Î¸s+1
0, ts
NsÏƒs
Ns(b)
â‰¥ts+1
0Ïƒs+1
0(c)=ts+1
0Ïƒs+1
0Î¸s+1
0, (65)
where (a)holds by the definition of ts
k=Ïƒs
k
Ïƒs
0,(b)holds by {ts
k, Ïƒs
k}is an increasing sequence in k,
and(c)holds by Î¸s+1
0= 1. Hence, by (64) and (65), we have
tj+1Qj+1(xâˆ—,Ëœyâˆ—)â‰¤ts
Ns 1
2Ï„s
Nsâˆ¥xâˆ—âˆ’xs+1
0âˆ¥2+Ïƒs
Ns
2âˆ¥G(xs+1
0)âˆ’G(xs
Ns)âˆ¥2
+1
2Ïƒs
Nsâˆ¥Ëœyâˆ—âˆ’ys+1
0âˆ¥2+
G(xs+1
0)âˆ’G(xs
Ns),ys+1
0âˆ’Ëœyâˆ— (66)
where jcorresponds to (s, Ns). By putting (63) and (66) together, we complete the proof of (62).
Placing (x,y) = (xâˆ—,Ëœyâˆ—),(xk+1,yk+1) = (xj+1,yj+1)in(32) and multiplying tjon both sides,
we have
0â‰¤tj[L(xj+1,Ëœyâˆ—)âˆ’ L(xâˆ—,yj+1)]
â‰¤tjÏ„âˆ’1
jâˆ’Ïj
2âˆ¥xâˆ’xjâˆ¥2âˆ’Ï„âˆ’1
j
2âˆ¥xâˆ’xj+1âˆ¥2+Î¸j
2Î´/Ïƒjâˆ’1âˆ¥qjâˆ¥2âˆ’1
2Î´/Ïƒjâˆ¥qj+1âˆ¥2
+ (2Ïƒj)âˆ’1 
âˆ¥yâˆ’yjâˆ¥2âˆ’ âˆ¥yâˆ’yj+1âˆ¥2
+âŸ¨yâˆ’yj+1,qj+1âŸ© âˆ’Î¸jâŸ¨yâˆ’yj,qjâŸ©
âˆ’Ïƒâˆ’1
jâˆ’Î¸jÎ´/Ïƒjâˆ’1
2âˆ¥yj+1âˆ’yjâˆ¥2+L2
G
2Î´/Ïƒjâˆ¥xj+1âˆ’xjâˆ¥2âˆ’Ï„âˆ’1
jâˆ’LXY
2âˆ¥xj+1âˆ’xjâˆ¥2
â‰¤tjQj(xâˆ—,Ëœyâˆ—)âˆ’tj+1Qj+1(xâˆ—,Ëœyâˆ—)âˆ’Î½1tj[(2Ï„j)âˆ’1âˆ¥xj+1âˆ’xjâˆ¥2+ (2Ïƒj)âˆ’1âˆ¥yj+1âˆ’yjâˆ¥2],
(67)
where the last inequality holds by (62) and (52). It follows from (53), Ïƒjâˆ’1/Ïƒjâ‰¤1and
âŸ¨yjâˆ’Ëœyâˆ—,qjâŸ© â‰¥ âˆ’Ïƒjâˆ’1
2Î´âˆ¥qjâˆ¥2âˆ’Î´/Ïƒjâˆ’1
2âˆ¥Ëœyâˆ—âˆ’ykâˆ¥2
that
tjQj(xâˆ—,Ëœyâˆ—)â‰¥tj 
(2Ï„j)âˆ’1âˆ¥xâˆ—âˆ’xjâˆ¥2+ (2Ïƒj)âˆ’1âˆ¥Ëœyâˆ—âˆ’yjâˆ¥2âˆ’Î´
2Ïƒjâˆ’1âˆ¥yjâˆ’Ëœyâˆ—âˆ¥2
â‰¥Î½2 1
2âˆ¥xâˆ—âˆ’xjâˆ¥2+1
2âˆ¥yjâˆ’Ëœyâˆ—âˆ¥2
>0.(68)
Combining (67) and (68), we complete our proof of (54).
F.2 Proof of Theorem 3
Proof. Since
(xj,yj)	
located in set X Ã— Y is a bounded sequence, it must have a convergent
subsequence limnâ†’âˆ(xjn,yjn) = ( xâˆ—,yâˆ—), where yâˆ—is the limit point. We claim that limit
point (xâˆ—,yâˆ—)satisfies the KKT condition. Placing aj=tjQj(xâˆ—,Ëœyâˆ—),bj=Î½1tj[(2Ï„j)âˆ’1âˆ¥xj+1âˆ’
xjâˆ¥2+ (2Ïƒj)âˆ’1âˆ¥yj+1âˆ’yjâˆ¥2]andcj= 0 in Lemma 2. It follows from (54) in Lemma 4 that
ajâ‰¥0, bj>0. Hence, we havePâˆ
j=0âˆ¥xj+1âˆ’xjâˆ¥2<âˆ,andPâˆ
j=0âˆ¥yj+1âˆ’yjâˆ¥2<âˆ, which
22implies limnâ†’âˆâˆ¥xjnâˆ’xjn+1âˆ¥2= 0andlimnâ†’âˆâˆ¥yjnâˆ’yjn+1âˆ¥2= 0. There are two different
cases for Ï„jnwhen jnâ†’ âˆ , and we discuss the value of Bjn+1in(25) decided by Ï„jnin each of the
two cases below.
Case 1: Ï„âˆ’1
jn<âˆ. By the definition of Bjn+1in(27) andlimnâ†’âˆâˆ¥xjnâˆ’xjn+1âˆ¥2= 0, we have
Bjn+1â‰¤ âˆ¥xâˆ’xjn+1âˆ¥ Â· âˆ¥xjn+1âˆ’xjnâˆ¥/Ï„jnnâ†’âˆâˆ’â†’0.
Case 2: Ï„âˆ’1
jn=âˆ. It follows from (39) thatÏ„âˆ’1
jnincreases at order Î˜(k), where jnâˆ¼(s, k). By (23),
we obtain âˆ¥xâˆ’xjnâˆ¥decreases at order O(1/k)(jnâˆ¼(s, k)). Hence, combining limnâ†’âˆâˆ¥xjnâˆ’
xjn+1âˆ¥2= 0, we have Bjn+1â‰¤1
Ï„jn 
âˆ¥xâˆ’xjn+1âˆ¥âˆ¥xjn+1âˆ’xjnâˆ¥nâ†’âˆâˆ’â†’ 0. It follows from
limnâ†’âˆxjn=xâˆ—,limnâ†’âˆBjn+1= 0and (25) that
f(xâˆ—) +âŸ¨âˆ‡G(xâˆ—)yâˆ—,xâˆ—âŸ© â‰¤f(x) +âŸ¨âˆ‡G(xâˆ—)yâˆ—,xâŸ©,âˆ€xâˆˆ X.
Hence, according to the first-order optimality condition, we have
0âˆˆâˆ‚f(xâˆ—) +âˆ‡G(xâˆ—)yâˆ—+NX(xâˆ—). (69)
Next, we show the complementary slackness holds for (xâˆ—,yâˆ—). Since Ïƒâˆ’1
jnhas an upper bound Â¯Ïƒâˆ’1,
âˆ¥yâˆ’yjn+1âˆ¥ â‰¤DY,limnâ†’âˆâˆ¥yjnâˆ’yjn+1âˆ¥2= 0and the definition of Ajn+1in(26), hence we
obtain Ajn+1â‰¤1
Ïƒjn 
âˆ¥yjnâˆ’yjn+1âˆ¥âˆ¥yâˆ’yjn+1âˆ¥nâ†’âˆâˆ’â†’0.Combining above, limnâ†’âˆyjn=yâˆ—
and(24), we have 0â‰¤ âˆ’âŸ¨ G(xâˆ—),yâˆ—âŸ© â‰¤ âˆ’âŸ¨ G(xâˆ—),yâŸ©,âˆ€yâˆˆ Y. Moreover, due to the complementary
slackness, there exists an Ë†yâˆ—âˆˆ Yâˆ—âŠ† Y such that âˆ’âŸ¨G(xâˆ—),Ë†yâˆ—âŸ©= 0. Hence, we must have
âŸ¨G(xâˆ—),yâˆ—âŸ©= 0, which, together with (69), implies that (xâˆ—,yâˆ—)is KKT point.
G Proof details for sparsity identification
Our proof strategy of active-set identification in rAPDPro is similar to those in unconstrained
optimization [ 24]. Namely, we show that the optimal sparsity pattern is identified when the iterates
fall in a properly defined neighborhood dependent on Î·. The next lemma shows that the primal
and dual sequences indeed converge to the neighborhood of the optimal primal and dual solutions,
respectively, in a finite number of iterations.
Lemma 5. There exists an Ë†S1such that
âˆ¥xs
0âˆ’xâˆ—âˆ¥ â‰¤ âˆ¥xË†S1
0âˆ’xâˆ—âˆ¥andâˆ¥ys
0âˆ’yâˆ—âˆ¥ â‰¤ âˆ¥yË†S1
0âˆ’yâˆ—âˆ¥,âˆ€sâ‰¥Ë†S1, (70)
where (xâˆ—,yâˆ—)is the unique solution of problem (17). Moreover, there exists an epoch Ë†S0â‰¥Ë†S1such
thatâˆ€sâ‰¥Ë†S0,we have
âˆ¥ys
kâˆ’yâˆ—âˆ¥ â‰¤Î·
3âˆ¥âˆ‡g(xâˆ—)âˆ¥,âˆ¥xs
kâˆ’xâˆ—âˆ¥ â‰¤Î·
3LXYÏ„s
k
Ï„s
k+(2LXY)âˆ’1,âˆ€k= 0,1, . . . N s. (71)
Proof. From Theorem 2 and 3, we have limjâ†’âˆ(xj,yj) = (xâˆ—,yâˆ—), where jcorresponds to (s,0).
It implies that there exists an epoch Ë†S1such that (70) holds.
It follows from (35) thatâˆ¥xs
1âˆ’xâˆ—âˆ¥ â‰¤p
Ïƒs
0Ï„s
0/Ïƒs
1(âˆ¥xs
0âˆ’xâˆ—âˆ¥2/Ï„s
0+âˆ¥ys
0âˆ’yâˆ—âˆ¥2/Ïƒs
0). Hence, in
order to prove âˆ¥xs
1âˆ’xâˆ—âˆ¥ â‰¤Î·
3LXYÂ·Ï„s
k
Ï„s
k+(2LXY)âˆ’1, we need to prove
q
Ïƒs
0Ï„s
0
Ïƒs
1(1
Ï„s
0âˆ¥xs
0âˆ’xâˆ—âˆ¥2+1
Ïƒs
0âˆ¥ys
0âˆ’yâˆ—âˆ¥2)â‰¤Î·
3LXYÏ„s
1
Ï„s
1+(2LXY)âˆ’1. (72)
From Corollary 1 and Theorem 2, 3, we know that the left hand side of (72) converges to 0and
right hand side of (72) is a positive constant. Hence, there exist a Ë†S2such that (72) holds, which
implies (71) holds for k= 1, s=Ë†S2. Now we use induction to prove, for âˆ€kâˆˆ[NË†S2], we have
 ÏƒË†S2
0Ï„Ë†S2
k
ÏƒË†S2
k(1
Ï„Ë†S2
0âˆ¥xË†S2
0âˆ’xâˆ—âˆ¥2+1
ÏƒË†S2
0âˆ¥yË†S2
0âˆ’yâˆ—âˆ¥2)1/2â‰¤Î·
3LXYÏ„Ë†S2
k
Ï„Ë†S2
k+(2LXY)âˆ’1. (73)
23When k= 1, inequality (73) coincides with (72) withs=Ë†S2. Now, assume (73) holds for k, we aim
to prove (73) holds for k+ 1. It follows from (35) that
âˆ¥xË†S2
k+1âˆ’xâˆ—âˆ¥(a)
â‰¤s
Ï„Ë†S2
k+1
ÏƒË†S2
k+1Â·ÏƒË†S2
k
Ï„Ë†S2
kÂ·Î·
3LXYÂ·Ï„Ë†S2
k
Ï„Ë†S2
k+(2LXY)âˆ’1(b)=Î·
3LXYÂ·Ï„Ë†S2
k+1
Ï„Ë†S2
k+(2LXY)âˆ’1
(c)
â‰¤Î·
3LXYÂ·Ï„Ë†S2
k+1
Ï„Ë†S2
k+1+(2LXY)âˆ’1,
where (a)follows from induction, (b)holds by Ï„Ë†S2
kÏƒË†S2
k=Ï„Ë†S2
k+1ÏƒË†S2
k+1and(c)holds by Ï„Ë†S2
k+1â‰¤Ï„Ë†S2
k.
Hence, we complete our proof of (73). From Theorem 2, we have âˆ¥xs
0âˆ’xâˆ—âˆ¥2â‰¤D2
XÂ·2âˆ’s, which
implies that there exists a Ë†S3=
2 log2
DX(Î·
3LXYÂ·Â¯Ï„
Â¯Ï„+(2LXY)âˆ’1)âˆ’1	
such that âˆ¥xË†S3
0âˆ’xâˆ—âˆ¥ â‰¤
DXÂ·âˆš
2âˆ’Ë†S3â‰¤Î·
3LXYÂ¯Ï„
Â¯Ï„+(2LXY)âˆ’1, which implies that âˆ¥xs
0âˆ’xâˆ—âˆ¥ â‰¤D2
XÂ·2âˆ’sâ‰¤Î·
3LXYÂ¯Ï„
Â¯Ï„+(2LXY)âˆ’1
holds for any sâ‰¥Ë†S3.
It follows from the definition of Ë†S1in(70) and stepsize will be reset at different epoch, then we
have (72) holds for sâ‰¥max{Ë†S1,Ë†S2}, which implies that (73) holds with substituting Ë†S2as any
sâ‰¥max{Ë†S1,Ë†S2}. Furthermore, it follows from Theorem 3 that limjâ†’âˆyj=yâˆ—, where j
corresponds to (s, k). Then there exists a Ë†S4such that the first term in (71) holds. Hence, we can
obtain that there exist a Ë†S0= max {Ë†S1,Ë†S2,Ë†S3,Ë†S4}such that (71) holds.
It is worth noting that the primal neighborhood defined by the second term of (71) is a bit different
from the fixed neighborhood in the standard analysis [ 24], which involves a constant stepsize. As
APDPro sets Ï„s
k=O(1/k), both the point distance and neighborhood radius decay at the same
O(1/k)rate. Hence, we use a substantially different analysis to show the sparsity identification in
the constrained setting.
G.1 Proof of Proposition 5
Proof. The uniqueness of primal optimal solution xâˆ—follows from Proposition 2. The KKT condition
(ensured by Slaterâ€™s CQ) implies
0âˆˆâˆ‚f(xâˆ—) +âˆ‡g(xâˆ—)yâˆ—. (74)
According to Assumption 2, we have xâˆ—Ì¸=0, hence Ac(xâˆ—) ={1,2, . . . , B } \ A (xâˆ—)Ì¸=âˆ…. In view
of (74), for any iâˆˆ Ac(x), we have pixâˆ—
(i)/âˆ¥xâˆ—
(i)âˆ¥=âˆ’âˆ‡(i)g(xâˆ—)yâˆ—, which gives a unique yâˆ—.
G.2 Proof of Theorem 4
Proof. It follows from the Lipschitz smoothness of g(Â·)and property (71) that for any sâ‰¥Ë†S0, we
have 
âˆ‡g(xs
k)ys
k+1
(i)âˆ’
âˆ‡g(xâˆ—)ys
k+1
(i)
â‰¤âˆ‡g(xs
k)ys
k+1âˆ’ âˆ‡g(xâˆ—)ys
k+1
â‰¤LXYxs
kâˆ’xâˆ—â‰¤Î·
3Ï„s
k
Ï„s
k+(2LXY)âˆ’1, k= 0, . . . N s.(75)
Recall that the primal update has the following form
xs
k+1= argmin
xâˆˆXnPB
i=1piâˆ¥x(i)âˆ¥+
âˆ‡g(xs
k)ys
k+1,x
+1
2Ï„s
kâˆ¥xâˆ’xs
kâˆ¥2o
.
Since Ï„s
k/(Ï„s
k+ (2LXY)âˆ’1)is monotonically increasing with respect to Ï„s
k, for the strictly feasible
point Ëœx, we have
âˆ¥xs
k+1âˆ’Ëœxâˆ¥(a)
â‰¤Î·
3LXYÂ·Â¯Ï„
Â¯Ï„+(2LXY)âˆ’1+âˆ¥xâˆ—âˆ’Ëœxâˆ¥
(b)
< Î¶+ min iâˆˆ[m]2q
âˆ’2gi(xâˆ—
i)
Âµi,(76)
24where (a)holds by (71),Â¯Ï„â‰¥Ï„s
kand(b)follows from the definition of xâˆ—,ËœxandÎ¶. Inequality (76)
implies that xs
k+1âˆˆintX, and hence NX(xs
k+1) ={0}. In view of the optimality condition, we
have h
1
Ï„s
k(xs
kâˆ’xs
k+1)âˆ’ âˆ‡g(xs
k)ys
k+1i
(i)âˆˆpiâˆ‚âˆ¥[xs
k+1](i)âˆ¥,1â‰¤iâ‰¤B. (77)
Our next goal is to show [xS
k+1](i)=xâˆ—
(i)satisfies condition (77) foriâˆˆ A(xâˆ—). Placing x(i)=xâˆ—
(i)
in
âˆ‡g(xS
k)yS
k+1+1
Ï„s
k(xâˆ’xs
k)
(i), we have

âˆ‡g(xs
k)ys
k+1+1
Ï„s
k(xâˆ—âˆ’xs
k)
(i)
â‰¤
âˆ‡g(xs
k)ys
k+1
(i)âˆ¥+âˆ¥1
Ï„s
k(xâˆ—
(i)âˆ’xs
k(i))
(a)
â‰¤Î·
3Ï„s
k
Ï„s
k+(2LXY)âˆ’1+
âˆ‡g(xâˆ—)ys
k+1
(i)+Î·
3(LXY)âˆ’1
Ï„s
k+(2LXY)âˆ’1
(b)
â‰¤Î·
3Ï„s
k+2(2LXY)âˆ’1
Ï„s
k+(2LXY)âˆ’1+ 1
+[âˆ‡g(xâˆ—)yâˆ—](i)
< Î·+[âˆ‡g(xâˆ—)yâˆ—](i)(c)
â‰¤pi,âˆ€iâˆˆ A(xâˆ—).(78)
In above, (a)follows from (71) and (75), (b)follows from
âˆ¥[âˆ‡g(xâˆ—)yS
k+1](i)âˆ¥ âˆ’ âˆ¥ [âˆ‡g(xâˆ—)yâˆ—](i)âˆ¥ â‰¤ âˆ¥yS
k+1âˆ’yâˆ—âˆ¥âˆ¥âˆ‡g(xâˆ—)âˆ¥ â‰¤Î·
3,
and(c)holds by the definition of Î·. Combining (77) and(78), we have A(xâˆ—)âŠ† A(xs
k+1), sâ‰¥
Ë†S0,âˆ€kâˆˆ[Ns], which completes our proof.
Table 1: Datasets description and parameter settings
dataset Node(n) Edge b Î±
bio-CE-HT 2617 3K -0.04 0.4
bio-CE-LC 1387 2K -0.05 0.4
econ-beaflw 502 53K -0.01 0.995
DD68 775 2K -0.005 0.4
DD242 1284 3K -0.05 0.4
peking-1 3341 13.2K -0.001 0.4
H A multi-stage accelerated primal-dual algorithm
Both the previous algorithms need to solve a complicated dual problem that involves a linear cut
constraint, posing a potential issue: the associated sub-problem might lack a closed-form solution.
To resolve this issue, we present the Multi-Stage Accelerated Primal-Dual Algorithm (msAPD) in
Algorithm 3, which obtains the same O(1/âˆšÎµ)complexity without introducing a new cut constraint.
Our new method is a double-loop procedure for which an accelerated primal-dual algorithm with a
pending sub-iteration number (APDPi) is running in each stage. While both APDPi and APDPro
employ the IMPROVE step to estimate the dual lower bound, APDPi only relies on the lower bound
estimation to change the inner-loop iteration number adaptively, but not the stepsize selection.
We develop the convergence property of APDPi, which paves the path to proving our main theorem.
For the convergence analysis, it suffices to verify that the initial stepsize parameter Ï„s
0, Ïƒs
0satisfy
assumptions in Theorem 5.
Theorem 5. Let{Â¯xs
k,Â¯ys
k}be the sequence generated by APDPi , then we have
L(Â¯xs
K,yâˆ—)âˆ’ L(xâˆ—,Â¯ys
K)â‰¤1
Kâˆ†s(xâˆ—,yâˆ—),1
2âˆ¥Â¯xs
Kâˆ’xâˆ—âˆ¥2â‰¤1
(yâˆ—)âŠ¤ÂµKâˆ†s(xâˆ—,yâˆ—),(79)
where âˆ†s(xâˆ—,yâˆ—)â‰œ1
2Ï„s
0âˆ¥xs
0âˆ’xâˆ—âˆ¥2+1
2Ïƒs
0âˆ¥ys
0âˆ’yâˆ—âˆ¥2and(xâˆ—,yâˆ—)is a KKT point.
250.0 0.2 0.4 0.6 0.8 1.0
1e5107
105
103
101
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.2 0.4 0.6 0.8 1.0
1e51010
108
106
104
102
100
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e4106
104
102
100
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.2 0.4 0.6 0.8 1.0
1e51011
109
107
105
103
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.2 0.4 0.6 0.8 1.0
1e51011
109
107
105
103
101
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e41010
109
APD
Mirror-Prox
rAPDPro
msAPD
APD+restartFigure 3: The first row is the results of objective convergence to optimum, where the y-axis
reports log10((âˆ¥D1/2xkâˆ¥1âˆ’ âˆ¥D1/2xâˆ—âˆ¥1)/âˆ¥D1/2xâˆ—âˆ¥1)for rAPDPro, and log10((âˆ¥D1/2Â¯xkâˆ¥1âˆ’
âˆ¥D1/2xâˆ—âˆ¥1)/âˆ¥D1/2xâˆ—âˆ¥1)for APD, msAPD and Mirror-Prox. The second row is the results of
feasibility violation, where y-axis reports the feasibility gap log10(max{0, G(xk)})for rAPDPro,
andlog10(max{0, G(Â¯xk)})for APD, APD+restart msAPD and Mirror-Prox. Datasets (Left-Right
order) correspond to DD68, DD242 and peking-1.
Algorithm 3 Multi- Stage APD (msAPD)
Require: Â¯x0âˆˆ X,Â¯y0âˆˆ Y,ËœÏƒ, S
1:Initialize: Ï0
0= 0
2:fors= 0, . . . , S do
3: Compute Ï„s
0= 
LXY+L2
GËœÏƒÂ·2s
2âˆ’1, Ïƒs
0= ËœÏƒÂ·2s
2
4: (Â¯xs+1,Â¯ys+1, Ïs+1
0)â†APDP I(Ï„s
0, Ïƒs
0,Â¯xs,Â¯ys, Ïs
0, s)
5:end for
6:Output: Â¯xS+1,Â¯yS+1
7:procedure APDP I(Ï„s
0, Ïƒs
0,x0,y0, Ïs
0, s)
8: Initialize: (xâˆ’1,yâˆ’1)â†(x0,y0),Â¯x0=x0, k= 0, Ns=âˆ,âˆ†XY=1
2Ï„s
0D2
X+1
2Ïƒs
0D2
Y
9: while k < N sdo
10: zkâ†2G(xk)âˆ’G(xkâˆ’1)
11: yk+1â†argminyâˆˆYâˆ¥yâˆ’(yk+Ïƒkzk)âˆ¥2
12: xk+1â†proxf,X(xkâˆ’Ï„s
0âˆ‡G(xk)yk+1, Ï„s
0)
13: Â¯xk+1â†(kÂ¯xk+xk+1)/(k+ 1),
14: Ïs
k+1â†IMPROVE (xk,Â¯xk,1
2D2
X,âˆ†XY
k, Ïs
k)
15: Compute Ns=âŒˆmax4
Ïs
k+1Ï„s
0,D2
Y
Ïs
k+1Ïƒs
0D2
XÂ·2s+1	
âŒ‰
16: kâ†k+ 1
17: end while
18: return Â¯xNs,Â¯yNs, Ïs
k
19:end procedure
Proof. The stepsize Ï„s
k=Ï„s
0, Ïƒs
k=Ïƒs
0are unchanged at one epoch, which implies that Ïk+1= 0,
i.e.,(37) are satisfied. By the definition of Ï„s
0andÏƒs
0, we have (Ï„s
0)âˆ’1=LXY+L2
GËœÏƒâˆš
2s=
LXY+L2
GÏƒs
0,which means equality holds at the first term in (37).
Since gi(x)is a strongly convex function with modulus Âµi, then we have
L(Â¯xK,yâˆ—)â‰¥ L(xâˆ—,yâˆ—) +(yâˆ—)âŠ¤Âµ
2âˆ¥Â¯xKâˆ’xâˆ—âˆ¥2,L(xâˆ—,yâˆ—)â‰¥ L(xâˆ—,Â¯yK).
Summing up the two inequalities above, we can get
L(Â¯xK,yâˆ—)âˆ’ L(xâˆ—,Â¯yK)â‰¥(yâˆ—)âŠ¤Âµ
2âˆ¥Â¯xKâˆ’xâˆ—âˆ¥2. (80)
26Combining (79) and (80), we can obtain the second term of (79).
We show msAPD obtains an O(1/âˆšÎµ)convergence rate, which matches the complexity of APDPro.
Theorem 6. Let{Â¯xs
0}be the sequence computed by msAPD . Then, we have
âˆ¥Â¯xs
0âˆ’xâˆ—âˆ¥2â‰¤âˆ†sâ‰¡D2
XÂ·2âˆ’s,âˆ€sâ‰¥0. (81)
For any Îµâˆˆ(0, D2
X),msAPD will find a solution Â¯xs
0âˆˆ X such that âˆ¥Â¯xs
0âˆ’xâˆ—âˆ¥2â‰¤Îµin at most
log2D2
X/Îµ
epochs. Moreover, the overall iteration number performed by msAPD to find such a
solution is bounded by
TÎµ=
8LXY
Ï0
N0+ 2l
log2DXâˆšÎµ+ 1m
+ (2 +âˆš
2)
ËœÏƒL2
G+2D2
Y
Ï0
N0ËœÏƒD2
X
DXâˆšÎµ.
Proof. We first show that (81) holds by induction. It is easy to verify that (81) holds for s= 0.
Assume âˆ¥Â¯xs
0âˆ’xâˆ—âˆ¥2â‰¤âˆ†s=D2
XÂ·2âˆ’sholds for s= 0, . . . , S âˆ’1. By Theorem 5, we have
âˆ¥Â¯xS
0âˆ’xâˆ—âˆ¥2â‰¤1
(yâˆ—)âŠ¤ÂµNSâˆ’1 2
Ï„Sâˆ’1
0âˆ†S+1
ÏƒSâˆ’1
0D2
Y
.
As the algorithm sets NSâˆ’1=
max
4/(ÏSâˆ’1
NSâˆ’1Ï„Sâˆ’1
0),2D2
Y/(ÏSâˆ’1
NSâˆ’1ÏƒSâˆ’1
0âˆ†S)	
, the following
inequalities hold:
2 
(yâˆ—)âŠ¤ÂµNSâˆ’1Ï„Sâˆ’1
0âˆ’1â‰¤2 
ÏSâˆ’1
NSâˆ’1NSâˆ’1Ï„Sâˆ’1
0âˆ’1â‰¤1
2,
D2
Y 
(yâˆ—)âŠ¤ÂµNSâˆ’1ÏƒSâˆ’1
0âˆ’1â‰¤D2
Y 
ÏSâˆ’1
NSâˆ’1NSâˆ’1ÏƒSâˆ’1
0âˆ’1â‰¤1
2âˆ†S.
Putting these pieces together, we have âˆ¥Â¯xSâˆ’xâˆ—âˆ¥2â‰¤1
2âˆ†S+1
2âˆ†S= âˆ† S. Suppose the algorithm
runs for Sepochs to achieve the desired accuracy Îµ, i.e.,âˆ¥xS
0âˆ’xâˆ—âˆ¥2â‰¤D2
XÂ·2âˆ’Sâ‰¤Îµ. Then the
overall iteration number can be bounded by
PS
s=0Ns(a)
â‰¤PS
s=0n
4
Ï0
N0Ï„Sâˆ’1
0+2D2
Y
Ï0
N0ÏƒSâˆ’1
0âˆ†S+ 1o
(b)
â‰¤PS
s=0n
4LXY
Ï0
N0+ 1
+
ËœÏƒL2
G+2D2
Y
Ï0
N0ËœÏƒD2
Xâˆš
2so
â‰¤
8LXY
Ï0
N0+ 2l
log2DXâˆšÎµ+ 1m
+ (2 +âˆš
2)
ËœÏƒL2
G+2D2
Y
Ï0
N0ËœÏƒD2
X
DXâˆšÎµ,
where (a)holds by Ïs
NSâ‰¥Ï0
N0,âˆ€sâ‰¥0,(b)follows from the definition of Ï„s
0andÏƒs
0.
Remark 11. Theorem 6 shows that msAPD obtains a worst-case complexity of O 
log(DX/âˆšÎµ) +
(DX+D2
Y/DX)/âˆšÎµ
, which is an upper bound of the complexity of rAPDPro (see Theorem 2). The
complexities of msAPD andrAPDPro match when DX= â„¦(1) DY. Otherwise, rAPDPro appears
to be much better in terms of dependence on DX/âˆšÎµ. On the other hand, msAPD has a simpler
subproblem, which does not involve an additional cut constraint on the dual update.
I Experiment details
We examine the empirical performance for solving sparse Personalized PageRank. Let G= (V, E)
be a connected undirected graph with nvertices. Denote the adjacency matrix of GbyA, that is,
Ai,j= 1ifiâˆ¼jand0otherwise. Let D= diag( d1, . . . , d n)be the matrix with the degrees {di}n
i=1
in its diagonal. Then the constrained form of Personalized PageRank can be written as follows:
min
xâˆˆRnâˆ¥D1/2xâˆ¥1s.t.1
2âŸ¨x, QxâŸ© âˆ’Î±âŸ¨s, Dâˆ’1/2xâŸ© â‰¤b, (82)
where Q=Dâˆ’1/2 
Dâˆ’1âˆ’Î±
2(D+A)
Dâˆ’1/2,Î±âˆˆ(0,1),sâˆˆâˆ†nis a teleportation distribution
over the nodes of the graph Gandbis a pre-specific target level.
270.0 0.2 0.4 0.6 0.8 1.0
1e50.60.70.80.91.0
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.2 0.4 0.6 0.8 1.0
1e50.60.70.80.91.0
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e40.60.70.80.91.0
APD
Mirror-Prox
rAPDPro
msAPD
APD+restartFigure 4: The experimental results on active-set identification. Datasets (Left-Right order) correspond
to DD68, DD242 and peking-1. The x-axis reports the iteration number and the y-axis reports
accuracy in active-set identification.
Datasets We selected 6 small-to-median scale datasets from various domains in the Network
Datasets [ 28]. We skip large-scale networks as MOSEK struggles to achieve the optimal solution,
making it unsuitable for subsequent comparison of the optimality gap. We briefly describe these
datasets in Table 1. For more details, please refer to the network repository.
Parameter tuning For all experiments, we set r= min iâˆˆ[n]|di|,Âµ=Î»min(Q)andLX=
Î»max(Q), with Î»min(Â·), Î»max(Â·)denoting the smallest and largest eigenvalue, respectively. For
msAPD, we have made additional parameter adjustments. Based on our observations, due to a
small estimated strongly convex coefficient, msAPD could not switch to the next cycle searly
enough. To prevent msAPD from degrading to APD, we iterate according to the predefined number
of sub-iterations and manually switch to the next set of parameters. We divide Ï„byâˆš
2, multiply
Ïƒbyâˆš
2, and increase the number of sub-iterations in the next period by a factor ofâˆš
2. For all
experiments, we tune the stepsize Ï„, Ïƒ, Î³ from
0.0001,0.0005,0.001,0.005,0.01	
, where Ï„, Ïƒare
the initial stepsizes of rAPDPro, msAPD and APD, Î³is the constant stepsize of Mirror-Prox. All
algorithms start with the primal variables initialized as zero vectors and the dual variables initialized
as ones.
Additional experiment results Figure 3 and Figure 4 describe the convergence performance and
active set identification results on the last three datasets: DD68, DD242 and peking-1. Furthermore,
we report the time consumption for the Personalized PageRank problem in Table 2. The table
indicates that, although rAPDPro and msAPD require moderately complex computations to determine
the lower bound of the strong convexity parameter, the two methods still accelerate the algorithmâ€™s
convergence and can significantly reduce the overall convergence time.
Table 2: Time summary when max{|f(x)âˆ’f(xâˆ—)|/|f(xâˆ—)|,max{G(x),0}} â‰¤ 10âˆ’3. All experi-
ments were conducted five times, and the results are reported as mean (standard deviation). âˆ—means
that upon completion of all iterations, the algorithms still fails to meet the criteria for both error
measures.
dataset APD APD+restart rAPDPro Mirror-Prox msAPD mosek
bio-CE-HT 187.15 (0.86)* 115.95 (1.04) 136.92 (0.92) 370.50 (1.80)* 77.21 (0.67) 0.21
bio-CE-LC 2.58 (0.16)* 0.65 (0.01) 0.44 (0.01) 4.74 (0.33)* 0.65 (0.03) 0.1
econ-beaflw 72.28 (0.59)* 87.12 (0.43)* 18.42 (0.44) 116.13 (1.15)* 66.70 (0.76) 0.16
DD242 43.29 (1.20)* 10.27 (0.39) 6.30 (0.08) 79.16 (0.60)* 10.33 (0.62) 0.16
DD68 36.55 (0.42)* 19.07 (0.66) 22.35 (0.75) 67.73 (1.39)* 15.69 (0.37) 0.24
peking-1 122.37 (2.99)* 11.55 (0.69) 4.86 (0.09) 243.45 (7.20)* 11.24 (0.15) 0.21
Nonetheless, we observe that Mosek achieves significantly faster computational efficiency for
small-scale problems than our algorithm. Therefore, we test the efficiency of rAPDPro on some
large-scale instances. For large-scale instances, we consider the following problem minxâˆˆRnâˆ¥xâˆ’
1âˆ¥1s.t.1
2xâŠ¤Qix+câŠ¤
ix+diâ‰¤0, i= 1, . . . , m, where Qiare dense and positive definite matrix
and generated randomly and ciare generated randomly. Furthermore, we set proper dito make the
feasible region is non-empty. When n= 5000 andm > 10, MOSEK crashes on our computer, which
means we can not get xâˆ—for calculating the optimality gap. Therefore, we report the time required
28for the algorithm to satisfy max{|f(x)âˆ’f(xâˆ—)|/|f(xâˆ—)|,max{G(x),0}} â‰¤ 10âˆ’3and the time
taken by the algorithm to complete 10,000 iterations. On this problem, results from small datasets
indicate that the performance of the 10,000-step algorithm should be sufficient to meet our specified
termination criteria.
Table 3: Comparison of computational time in seconds between rAPDPro and MOSEK
m rAPDPro MOSEK
8 24.612 50.38
10 53.997 67.99
12 392 -
29NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: We state the complete contributions in the Introduction section.
Guidelines:
â€¢The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss the limitations of our work in Appendix A.
Guidelines:
â€¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
â€¢The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
â€¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
â€¢While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
30Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We give all assumptions needed for the theorems we are proving, such as
Assumption 1, 2, 3 and 4, to ensure the conclusion is correct.
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢All assumptions should be clearly stated or referenced in the statement of any theorems.
â€¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
â€¢Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Our experimental reproduction scripts have been placed in the attachment.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
â€¢Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
â€¢While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
31In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: Our experiments use entirely publicly available datasets, and we are committed
to making our code completely open source.
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢While we encourage the release of code and data, we understand that this might not be
possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
â€¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: All details can be found in the paper and supplemental material.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
â€¢The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
32Justification: Since our algorithm is deterministic, our experimental results do not report
standard deviation correlation results, but we have experimented on a wide range of datasets
to demonstrate the robustness of our algorithm.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
â€¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
â€¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
â€¢It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
â€¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
â€¢For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: All experiments are run on Mac mini M2 Pro, 32GB.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
â€¢The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: The code in submission is fully compliant with the NeurIPS code of Ethics.
Guidelines:
â€¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
33â€¢The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification:
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
â€¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
â€¢The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
â€¢Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
â€¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
34Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: The creators or original owners of assets are properly credited, and the license
and terms of use are explicitly mentioned and respected in the paper.
Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
â€¢For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
â€¢If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: We provide a complete document of our code.
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢The paper should discuss whether and how consent was obtained from people whose
asset is used.
â€¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
35â€¢Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
â€¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
â€¢We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
36