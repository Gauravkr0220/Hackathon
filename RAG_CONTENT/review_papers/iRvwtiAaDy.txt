Under review as submission to TMLR
EffectofRandomLearningRate: TheoreticalAnalysisofSGD
Dynamics in Non-Convex Optimization via Stationary Distri-
bution
Anonymous authors
Paper under double-blind review
Abstract
We consider a variant of the stochastic gradient descent (SGD) with a random learning rate and
revealitsconvergenceproperties. SGDisawidelyusedstochasticoptimizationalgorithminmachine
learning,especiallydeeplearning. NumerousstudiesrevealtheconvergencepropertiesofSGDand
its simplified variants. Among these, the analysis of convergence using a stationary distribution of
updated parameters provides generalizable results. However, to obtain a stationary distribution, the
updatedirectionoftheparametersmustnotdegenerate,whichlimitstheapplicablevariantsofSGD.
In this study, we consider a novel SGD variant, Poisson SGD, which has degenerated parameter
update directions and instead utilizes a random learning rate. Consequently, we demonstrate that
a distribution of a parameter updated by Poisson SGD converges to a stationary distribution under
weakassumptionsonalossfunction. Basedonthis,wefurthershowthatPoissonSGDfindsglobal
minima in non-convex optimization problems and also evaluate the generalization error using this
method. As a proof technique, we approximate the distribution by Poisson SGD with that of the
bouncy particle sampler (BPS) and derive its stationary distribution, using the theoretical advance
of the piece-wise deterministic Markov process (PDMP).
1 Introduction
Stochastic gradient descent (SGD) stands out as a widely employed optimization algorithm in machine learning. It
fallsunderthecategoryofstochasticoptimization,whereparametersareupdatedwithrandomnessfromthemini-batch
sampling. SGD is valued for two main reasons in optimization: (i) it is memory-efficient and requires only low
computational resources by updating parameters from a fraction of the training data at each iteration (Bottou, 1991),
and (ii) models optimized with SGD have less generalization error than those optimized by other algorithms such as
gradient descent (GD) for neural networks (Wu et al., 2020; Zhu et al., 2019). Owing to these advantages, SGD has
beenoneofthestandardmethodsfortrainingdeeplearningmodels(Hofferetal.,2017;Keskaretal.,2016;Zhuetal.,
2019).
To understand the properties of SGD, the characteristics of parameters updated by SGD or its variants have been
actively studied. As for the usual SGD, Garrigos & Gower (2023) surveyed the results about the convergence rate of
SGD in convex and non-convex settings. It also mentions the global convergence property of SGD under the strong
convexity setting. Li et al. (2017); Jastrzebski et al. (2017) clarified that the parameter updating process of SGD can
be approximated by a stochastic differential equation. Zhu et al. (2019); Nguyen et al. (2019) discussed the relation
betweentherandomnoiseofSGDandtheescapeefficiencyfromthesharpminimaofthelossfunction. Oneexample
ofavariantofSGDisstochasticgradientLangevindynamics(SGLD),whichisanextensionofSGDthataddsGaussian
noise to the update formula of SGD. Raginsky et al. (2017) analyzed the dynamics of stochastic gradient Langevin
dynamics (SGLD) as a variant of SGD and proved the parameters optimized by SGLD converge to the global minima
ofthegeneralizationerror. Asanotherexample,Jastrzebskietal.(2017);Heetal.(2019);Mandtetal.(2017)analyzed
thedynamicsofSGDwithaconstantlearningrateundertheassumptionsthatthenoiseofSGDonthegradientinduced
by the mini-batch sampling is isotropic, and derived the probability distribution of the parameters obtained by SGD.
Latz (2021) analyze SGD both in the case of the constant learning rate and of the decreasing learning rate.
1Under review as submission to TMLR
Among the methods analyzing the properties of SGD, one of the most general approaches is to study a stationary
distribution of parameters updated by SGD and its variants. The stationary distribution is a distribution that remains
unchangedwhentheparameterisupdatedbyonestep. Itisusefulintheoreticalanalysis,because(i)itcananalyzethe
global dynamics of the optimization algorithm, and (ii) it can be applied to a wide range of loss functions regardless
of its shape. For these reasons, we can use it to investigate the optimization of complex loss functions such as those
used for training deep neural networks. For example, (Dieuleveut et al., 2020) studied the stationary distribution of
the parameter optimized by SGD when the loss function is strongly convex, and (Raginsky et al., 2017) studied the
stationary distribution of SGLD when the loss function is non-convex.
Despitetheaboveadvantages,therearenotmanySGDvariantstowhichstationarydistributionanalysiscanbeapplied.
Thisisbecause,tousetheanalysisbyastationarydistribution,itisrequiredthatthedirectionofparameterupdatesby
analgorithmdoesnotdegenerate;inotherwords,theremustbenodirectionsthatarenotbeingexplored. Examplesof
suchvariantsare(i)SGLD(Welling&Teh,2011;Dalalyan,2017;Durmus&Moulines,2016),whichaddsaGaussian
noise to the parameter update of SGD and (ii) Gaussian SGD (Jastrzebski et al., 2017; He et al., 2019; Mandt et al.,
2017), which assumes that the noise of SGD on the gradient induced by the mini-batch sampling is non-degenerate
Gaussian. In contrast, the parameter update of SGD degenerates in many practical cases, such as deep learning (Zhu
et al., 2019; Nguyen et al., 2019; Simsekli et al., 2019). We remark that we focus on the degeneracy of the update
directionofSGD,notonthedistributionofitsincethereisnoclearagreementthatgradientnoisefollowsaparticular
distribution (the mathematical definition of degeneracy is in Remark 2). Hence, there is a gap between the variants of
SGDconsideredinthetheoreticalanalysisandtheempiricalfactsaboutSGD.Thisgapfostersthefollowingquestion:
Do parameters optimized by a variant of SGD have a stationary distribution
even if the update direction degenerates - and if so, what is the form of it?
1.1 Our Contribution
We theoretically prove that a variant of SGD has a stationary distribution even if the update direction degenerates.
Specifically,wedevelopanovelSGDvariantwitha randomlearningrate ,whichfollowsthePoissonprocessdepending
on a mini-batch gradient. We call the variant Poisson SGD , and prove that the distribution of a parameter updated
by Poisson SGD converges to a stationary distribution. As a result, we provide a positive answer to the question
posed above: even with a degenerated parameter update, it is possible to construct a variant of SGD that reaches a
stationarydistributionbyusingarandomlearningrate. Wenotethatourlearningratehasaroleofefficientlyexploring
parameters, which differs from conventional methods with adaptive step size such as Adam.
Ourspecificcontributionsareasfollows. Weconsidertheempiricalriskminimizationproblemandprovethefollowing
results under weak assumptions on the loss function such as absolute continuity: (i) the distribution of the parameters
updated by Poisson SGD converges to a stationary distribution, and (ii) an output of Poisson SGD converges to the
global minima of the empirical risk, applying the stationary distribution while controlling the inverse-temperature
parameter. Furthermore,weevaluatethegeneralizationerroroftheupdatedparameterforpredictionwithunseendata
by studying an expectation of the risk function in terms of the obtained stationary distribution.
Onthetechnicalside,weutilizeanalgorithmcalledtheBouncyParticleSampler(BPS)todemonstratetheconvergence
tothestationarydistributionbyPoissonSGD.BPSisapiecewisedeterministicMarkovprocess(PDMP)thatachieves
ergodicity using stochastically occurring jumps (Davis, 1984; 1993). In our proof, we show that the distribution
of parameters updated by Poisson SGD can be well approximated by that of BPS, and we concretely construct the
stationary distribution using the theory of BPS.
1.2 Related Work
There are many works which investigate the stationary distribution of SGD or its variants. Dieuleveut et al. (2020);
Chen et al. (2022) derived the stationary distribution of the parameters obtained by SGD when the loss function is
strongly-convex,throughthetheoriesaboutMarkovprocesses. TheparametersobtainedthroughtheSGLDalgorithm
aretheoreticallyproventoconvergetotheGibbsdistributionandgeneralizewell(Raginskyetal.,2017). Heetal.(2019)
andMandtetal.(2017)assumedthenoiseofSGDisGaussianwhosecovariancematrixisconstantandapproximatethe
process of optimization through SGD by Ornstein-Uhlenbeck process and derive its stationary distribution. Gradient
Langevindynamics(GLD),whichisafull-batchversionofSGLD,canalsobeseenasavariantofSGDwhichassumes
2Under review as submission to TMLR
that the noise of SGD is Gaussian with a covariance matrix of constant multiples of the identity matrix. Like SGLD,
it converges to a stationary distribution even in non-convex scenarios (Dalalyan, 2017; Durmus & Moulines, 2016).
Intermsofarandomlearningrate,thereareseveralempiricalstudies. Musso(2020)investigatedthedynamicsofSGD
with a random learning rate by analyzing the stochastic differential equation and its Fokker-Planck equation. Blier
et al. (2019) showed experimentally that SGD with random learning rates performs well in optimizing deep neural
networks. We remark that these studies and ours have several major differences. The first difference is in the design
of a learning rate. Our method considers Poisson processes, whereas existing methods consider uniform distributions
and heterogeneous learning rates for each subneural network. The second difference is the objective of the study. We
aim to evaluate global convergence, whileexisting studies aim at interpretability, speed of convergence, etc., and have
very different motivations.
As for BPS, (Deligiannidis et al., 2019; Durmus et al., 2020) proved that the parameters updated by continuous-time
BPSconvergetoastationarydistributionandderivedtheconcreteformofthestationarydistributionanditsconvergence
rate. (Sherlock & Thiery, 2022) clarified the relation between discrete-time BPS and continuous-time BPS.
1.3 Notation
For a natural number ğ‘âˆˆN, we define[ğ‘]:={1,2,...,ğ‘}. For a realğ‘§âˆˆR,âŒŠğ‘§âŒ‹denotes the largest integer which is
nomore than ğ‘§.ğ¼ğ‘‘isağ‘‘-dimensionalidentity matrix. âŸ¨ğ‘,ğ‘âŸ©meansthe innerproductin Euclidspace, i.e.,sum ofthe
product of each component. âˆ¥Â·âˆ¥ 1andâˆ¥Â·âˆ¥mean the vector norms which represent 1-norm and 2-norm respectively.
Sğ‘‘âˆ’1is a unit sphere in Rğ‘‘. For probability measures ğ‘ƒ,ğ‘ƒâ€²onRğ‘‘andğ‘âˆˆ [1,âˆ], theğ‘âˆ’Wasserstein distance
is defined asWğ‘(ğ‘ƒ,ğ‘ƒâ€²):=infğœ‹âˆˆÎ (ğ‘ƒ,ğ‘ƒâ€²)(âˆ«
Rğ‘‘âˆ¥ğ‘§âˆ’ğ‘§â€²âˆ¥ğ‘
ğ‘ğ‘‘ğœ‹(ğ‘§,ğ‘§â€²))1/ğ‘, whereÎ (ğ‘ƒ,ğ‘ƒâ€²)is a set of coupling measure
betweenğ‘ƒandğ‘ƒâ€².âˆ¥ğ‘ƒâˆ’ğ‘ƒâ€²âˆ¥TVdenotes the total variation of ğ‘ƒâˆ’ğ‘ƒâ€².Î“:Râ†’Rdenotes the gamma function, i.e.,
Î“(ğ‘§)=âˆ«âˆ
0ğ‘¡ğ‘§âˆ’1ğ‘’âˆ’ğ‘¡ğ‘‘ğ‘¡.B :RÃ—Râ†’Rdenotesthebetafunction, i.e.,B(ğ‘¥,ğ‘¦)=âˆ«1
0ğ‘¡ğ‘¥âˆ’1(1âˆ’ğ‘¡)ğ‘¦âˆ’1ğ‘‘ğ‘¡. Foracompactset
Î˜,wedenote diam(Î˜)=supğœƒ1,ğœƒ2âˆˆÎ˜âˆ¥ğœƒ1âˆ’ğœƒ2âˆ¥. Forarandomvariable ğ‘‹âˆˆX,Eğ‘‹[ğ‘‹]denotestheexpectedvaluewith
regard toğ‘‹,i.e.,âˆ«
Xğ‘¥ğ‘‘ğœ‡ğ‘‹(ğ‘‘ğ‘¥), whereğœ‡ğ‘‹is the probability measure of ğ‘‹. 1[Â·]denotes an indicator function, which
takes 1if the condition in the bracket is satisfied, and 0otherwise. We denote ğ‘+=max{0,ğ‘}.
2 Preliminary
2.1 Problem Setup: Empirical Risk Minimization
We consider the following stochastic optimization problem. Let Zbe a compact sample space, and consider a
probability measure ğ‘ƒâˆ—onZ. Suppose that we observe ğ‘›samplesz={ğ‘§1,...,ğ‘§ğ‘›}âŠ‚Z, that are independently and
identically generated from the measure ğ‘ƒâˆ—. Using the samples, we consider an empirical risk with a loss function.
LetÎ˜âŠ‚Rğ‘‘be a compact parameter space, and define ğ‘Š:=diam(Î˜). With a (potentially non-convex) loss function
â„“:ZÃ—Î˜â†’R, we consider the following empirical risk with the samples:
ğ¿z(ğœƒ)=1
ğ‘›ğ‘›âˆ‘ï¸
ğ‘–=1â„“(ğ‘§ğ‘–;ğœƒ), ğœƒâˆˆÎ˜. (1)
Ourgoalistofindaglobalminimumoftheempiricalrisk ğ¿z(Â·),whichisdefinedasaparameter ğœƒâˆ—âˆˆÎ˜whichsatisfies
ğ¿z(ğœƒâˆ—)=min
ğœƒâ€²âˆˆÎ˜ğ¿z(ğœƒâ€²). (2)
In this study, we consider a torus as the parameter space Î˜in order to skip the argument of constraining parameter
updates to a compact set. If we consider another compact parameter space such as a hypercube, a projection onto the
spaceneedstobeadded. Wealsomentionthattheboundednessofparameterspacesisanacceptedsettinginprevious
studies on SGD, e.g. Ljung (1977); Kushner & Yin (2003); Bonnabel (2013); Tripuraneni et al. (2018); Lan (2020);
Boumal (2023).
3Under review as submission to TMLR
2.2 Gradient Descent Algorithm and Variants
To find the global minimum ğœƒâˆ—as defined in (2), we often use the optimization algorithm called stochastic gradient
descent (SGD) with momentum.
2.2.1 General Form of Stochastic Gradient Descent
WegiveaformaldefinitionofSGDwithamomentumtermassociatedwithempiricalrisk ğ¿z(ğœƒ)in(1). Letğ¾âˆˆNbe
the number of iterations. The SGD with momentum generates a sequence of Î˜-valued random parameters ğœƒ1,...,ğœƒğ¾
andRğ‘‘-valued random vectors ğ‘£1,...,ğ‘£ğ¾, by the following procedure.
Letğœƒ0âˆˆÎ˜be an arbitrary parameter for the initialization, ğ‘£0âˆˆRğ‘‘as an initial velocity vector, and ğ‘šâˆˆ[ğ‘›]be a
numberofsub-samples,i.e.,thebatchsize. Supposethatweobservethe ğ‘›samplesğ‘§:={ğ‘§1,...,ğ‘§ğ‘›},i.e.,thefull-batch.
Forğ‘˜=1,...,ğ¾, we uniformly sample ğ‘šintegersğ¼(ğ‘˜)={ğ‘–1,ğ‘–2,...,ğ‘–ğ‘š}from[ğ‘›], which is called mini-batch sampling
with the batch-size ğ‘š. We define an associated mini-batch risk as
bğ¿(ğ‘˜)
z(ğœƒ):=1
ğ‘šâˆ‘ï¸
ğ‘–âˆˆğ¼(ğ‘˜)â„“(ğ‘§ğ‘–;ğœƒ). (3)
Then, with initial values ğœƒ0âˆˆÎ˜andğ‘£0âˆˆRğ‘‘, the SGD with momentum generates the parameter and the velocity
vector by the following recursive formula for ğ‘˜=1,...,ğ¾:
ğœƒğ‘˜=ğœƒğ‘˜âˆ’1+ğœ‚ğ‘˜ğ‘£ğ‘˜âˆ’1,and
ğ‘£ğ‘˜=ğ‘£ğ‘˜âˆ’1âˆ’ğ›¼ğ‘˜âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜), (4)
whereğœ‚ğ‘˜>0is a learning rate and ğ›¼ğ‘˜âˆˆRis a momentum coefficient. This form is generic and can be identical to
other forms of SGD with momentum (Qian, 1999; Sutskever et al., 2013) by adjusting the parameters ğœ‚andğ›¼.
Remark 1 (Gradient Noise) .For the sake of technical discussions below, we define a notion of gradient noise
ğœ‰(ğ‘š,ğ‘›)
ğ‘˜(ğœƒ):=âˆ‡bğ¿(ğ‘˜)
z(ğœƒ)âˆ’âˆ‡ğ¿z(ğœƒ)forğ‘˜=1,...,ğ‘andğœƒâˆˆÎ˜, which is caused by sub-sampling of the SGD. If one
assumes that ğœ‰(ğ‘š,ğ‘›)
ğ‘˜(ğœƒ)follows a centered Gaussian distribution with an identity covariance, the SGD corresponds to
thegradientLangevindynamics(GLD).However,itisempiricallyobservedthatthecovariancematrixofthegradient
noise often degenerates (Zhu et al., 2019; Cheng et al., 2020; HaoChen et al., 2021). In addition, there is still much
discussion on a distribution that gradient noise follows, e.g. Simsekli et al. (2019) and Battash et al. (2024) reports
the non-Gaussianity of the gradient noise in empirical studies. Due to these situations, we do not consider a full-rank
covariance matrix nor a particular distribution of the gradient noise.
Remark 2 (Degeneracy of the gradient noise) .We briefly explain the degeneracy of the gradient noise. Since the
covariance matrix of the gradient noise with the batch-size ğ‘šis written as
1
ğ‘šğ‘šâˆ‘ï¸
ğ‘–=1(âˆ‡â„“(ğ‘§ğ‘–;ğœƒ)âˆ’âˆ‡ğ¿z(ğœƒ))(âˆ‡â„“(ğ‘§ğ‘–;ğœƒ)âˆ’âˆ‡ğ¿z(ğœƒ))âŠ¤,
whereeachterminthesumisarank-1matrix,therankofatotalcovariancematrixisnogreaterthan ğ‘š. Hence,inthe
over-parameterized models like neural networks, the matrix becomes rank-deficient, which we refer to as degeneracy
of the noise.
3 Our SGD Variant: Poisson SGD
Inthissection,weintroduceouralgorithm, PoissonSGD ,whichisavariantofSGDwitharandomlearningrate ğœ‚and
momentumcoefficient ğ›¼. Wedesignourmethodsothattheparametercansearchthewholeparameterspaceowingto
the design.
Wedescribetherandomlearningrate. Inpreparation,wedefinethefollowingexponentialdistributionfunctionwitha
functionğ‘“:Î˜â†’Rğ‘‘and parameters ğœƒâˆˆÎ˜,ğ‘£âˆˆSğ‘‘âˆ’1:
ğ¸(ğ‘“(Â·),ğœƒ,ğ‘£):=exp
âˆ’âˆ«ğ‘¡
0{max{âŸ¨ğ‘“(ğœƒ+ğ‘Ÿğ‘£),ğ‘£âŸ©,0}+ğ¶ğ‘ƒ}ğ‘‘ğ‘Ÿ
,
4Under review as submission to TMLR
Algorithm 1 Poisson SGD
1:Initialize(ğœƒ0,ğ‘£0)asâˆ¥ğ‘£0âˆ¥=1.
2:forğ‘˜=1,2,...,ğ¾do
3:Sampleğ¼(ğ‘˜)âŠ‚[ğ‘›]and obtainâˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)as (3).
4:Sampleğœ‚ğ‘˜as (5).
5:Obtainğœƒğ‘˜asğœƒğ‘˜=ğœƒğ‘˜âˆ’1+ğœ‚ğ‘˜ğ‘£ğ‘˜âˆ’1.
6:Obtainğ‘£ğ‘˜asğ‘£ğ‘˜=ğ‘£ğ‘˜âˆ’1âˆ’ğ›¼ğ‘˜âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)withğ›¼ğ‘˜as (6).
7:end for
8:Return(ğœƒğ¾,ğ‘£ğ¾).
whereğ¶ğ‘ƒ>0is some constant. Then, for each update ğ‘˜=1,...,ğ¾, we design the random learning rate ğœ‚ğ‘˜following
the exponential distribution:
ğ‘ƒ(ğœ‚ğ‘˜â‰¥ğ‘¡)=ğ¸(ğ›½âˆ‡bğ¿(ğ‘˜)
z(Â·),ğœƒğ‘˜âˆ’1,ğ‘£ğ‘˜âˆ’1), (5)
whereğ›½>0is the hyper-parameter of Poisson SGD, called an inverse temperature parameter.
Second, we select the momentum coefficient ğ›¼ğ‘˜for eachğ‘˜=1,...,ğ¾as
ğ›¼ğ‘˜=2âŸ¨âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜),ğ‘£ğ‘˜âˆ’1âŸ©
âˆ¥âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)âˆ¥2+ğ¶ğ›¼, (6)
whereğ¶ğ›¼â‰¥0is the hyper-parameter. While ğ¶ğ›¼has the function of enhancing the effect of the gradient for practical
use, we setğ¶ğ›¼=0in the theoretical analysis of this paper (in experiments in Section 7, we set ğ¶ğ›¼>0). This setup
keepsthelengthofthevelocityvectorconstantas âˆ¥ğ‘£ğ‘˜âˆ¥=1foreveryğ‘˜(SeeProposition7inAppendix),andonlyuses
itsangletoupdatetheparameters. Weupdatetheparameterbychanging ğœ‚ğ‘˜andğ›¼ğ‘˜ineveryiteration. Thepseudo-code
of Poisson SGD is shown in Algorithm 1.
The algorithm is designed to effectively explore large regions of the parameter space Î˜. Specifically, the update
directionisdeterminedbythevelocityvector ğ‘£ğ‘˜normalisedby ğ›¼ğ‘˜as(6),andthesizeoftheupdateisrandomlysetby
therandomlearningrate ğœ‚ğ‘˜as(5). Whenthegradient âˆ‡bğ¿(ğ‘˜)
z(Â·)issmall,thelearningrate ğœ‚ğ‘˜ischosentobelarge,thus
the updated parameter tends to escape local minima or saddle points. Figure 1 illustrates that Poisson GD, which we
refer to as the full-batch version of Poisson SGD explores a wider parameter space and discovers the global minimum
owing to the random learning rate, while the parameters updated by GD converge to the local minimum. Here, we set
the learning rate of GD as ğœ‚=0.02and the hyper-parameter of Poisson GD as ğ¶ğ‘ƒ=100andğ›½=10000.
Remark 3 (Moments of Poisson SGD) .We claim that even if the learning rate is random, the actual updates are
not too large, by studying its moments. That is, if ğ¶ğ‘ƒis sufficiently large, there is little chance of sampling a
large learning rate ğœ‚, since the first and second moments of ğœ‚ğ‘˜are given as E[ğœ‚ğ‘˜]â‰¤âˆ«âˆ
0exp(âˆ’ğ¶ğ‘ƒğ‘¡)ğ‘‘ğ‘¡=1
ğ¶ğ‘ƒand
E[ğœ‚2
ğ‘˜]âˆ’E[ğœ‚ğ‘˜]2â‰¤âˆ«âˆ
02ğ‘ exp(âˆ’ğ¶ğ‘ƒğ‘ )ğ‘‘ğ‘ âˆ’1
ğ¶2
ğ‘ƒ=1
ğ¶2
ğ‘ƒ. By this property, we can avoid the case in which ğœ‚ğ‘˜diverges. In
addition,evenifalarge ğœ‚ğ‘˜issampled,theparameterdoesnotexitfromtheparameterspacesinceweconsideratorus
as the parameter space.
4 Convergence Theory for Poisson SGD
We provide theoretical results on the convergence of Poisson SGD (Algorithm 1). Our main interest is a distribution
of the generated parameter ğœƒğ¾by Poisson SGD associated with the empirical risk minimization problem (2).
4.1 Stationary Distribution of Poisson SGD
In this section, we show that the parameter ğœƒğ¾by the Poisson SGD follows a stationary distribution. Formally, we
define the stationary distribution of the Markov process. In preparation, we utilize the notion of transition probability
ğ‘„(ğœƒ,ğ‘‘ğ‘¤)from a distribution ğ‘0(ğœƒ)to anotherğ‘1(ğœƒ)onÎ˜, that is,ğ‘1(ğ‘¤)=âˆ«
Î˜ğ‘„(ğœƒ,ğ‘‘ğ‘¤)ğ‘0(ğ‘‘ğœƒ)holds.
5Under review as submission to TMLR
Figure 1: The comparison of the trajectories of GD (with a fixed learning rate) and Poisson GD (with the random
learning rate) in optimizing the function ğ‘§=ğ‘¥4âˆ’4ğ‘¥3âˆ’36ğ‘¥2+ğ‘¦2. Poisson GD represents replacing the mini-batch
lossbğ¿zby the full-batch loss ğ¿zin Poisson SGD, where we set ğ¿z(ğ‘¥,ğ‘¦)=ğ‘¥4âˆ’4ğ‘¥3âˆ’36ğ‘¥2+ğ‘¦2. The point(âˆ’3,0)
representsalocalminimumandthepoint (6,0)isidentifiedastheglobalminimum. Agreenpointindicatestheinitial
position, a black line represents the trajectory of GD, and a red line represents the trajectory of Poisson GD.
Definition1. Letğ‘„(ğœƒ,ğ‘‘ğ‘¤)bethetransitionprobabilityofaMarkovprocessin Î˜. Ifthefollowingequationholds,we
call the probability distribution ğœ‹(ğœƒ)stationary distribution of the Markov process:
ğœ‹(ğ‘‘ğ‘¤)=âˆ«
Î˜ğ‘„(ğœƒ,ğ‘‘ğ‘¤)ğœ‹(ğ‘‘ğœƒ).
A stationary distribution is an useful notion to represent a limit of the parameter distribution, and it enables us
to analyze where the parameter converges by algorithms. For example, see the theoretical framework to analyze
stochastic optimization algorithms by (Raginsky et al., 2017).
4.1.1 Assumption
We provide several principal assumptions. First, we consider the basis assumptions on the loss function â„“(Â·;Â·). The
followingconditionsarefairlygeneralfortheanalysisofstochasticoptimizationalgorithms,e.g. Bertazzietal.(2022).
Assumption 1 (Loss function) .The loss function â„“:ZÃ—Î˜â†’Râ‰¥0satisfies the following conditions:
â€¢â„“(ğ‘§;ğœƒ)is absolutely continuous and differentiable with respect to ğœƒâˆˆÎ˜for everyğ‘§âˆˆZ.
â€¢âˆ‡ğœƒâ„“(ğ‘§;ğœƒ)is continuous in ğœƒandğ‘§for allğœƒâˆˆÎ˜andğ‘§âˆˆZ.
The first condition is satisfied by a large class of models, such as linear regression model, or deep neural networks
whose activation function is ReLU or sigmoid function. From the second condition, we define an upper bound
ğ‘€â„“:=maxğœƒâˆˆÎ˜,ğ‘§âˆˆZâˆ¥âˆ‡ğœƒâ„“(ğ‘§;ğœƒ)âˆ¥sinceÎ˜andZare compact.
4.1.2 Statement of Convergence
Letğœ‡z,ğ¾beadistributionoftheoutput ğœƒğ¾fromthePoissonSGDinAlgorithm1withthegivendataset z. Wediscuss
the convergence of ğœ‡z,ğ¾asğ¾increases.
In preparation, we define a probability measure on Î˜for arbitrary ğ›½,ğœ€> 0, whose density is written as follows:
ğœ‡(ğ›½,ğœ€)
z(ğ‘‘ğœƒ)âˆ
ğ›½ğ‘€â„“+1
ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥
exp(âˆ’ğ›½ğ¿z(ğœƒ))ğ‘‘ğœƒ, (7)
6Under review as submission to TMLR
whereğ‘ğ‘‘:= Î“(ğ‘‘/2)/(âˆšğœ‹Î“(ğ‘‘/2+1/2)). The probability measure (7) is concentrated around the global minima
ofğ¿z(ğœƒ), since the dominant exponential term exp(âˆ’ğ›½ğ¿z(ğœƒ))in (7) increases in ğ¿z(ğœƒ). In addition, as the inverse
temperature parameter ğ›½increases, the measure ğœ‡(ğ›½,ğœ€)
zconcentrates more around the global minimum.
Weshowourresultsontheconvergenceofthestationarydistribution. ThediscrepancyismeasuredbytheWasserstein
distanceW1(Â·,Â·). We remark that this theorem is the integration of Theorem 3 and Theorem 4 appearing later in
Section 5. Recall that we defined ğ‘Š:=diam(Î˜).
Theorem1 (StationarydistributionofPoissonSGD) .Fixarbitrary ğ›½,ğœ€> 0. SupposeAssumption1holds. Wesetthe
hyper-parameter of Poisson SGD as ğ¶ğ‘ƒ=1/ğœ€. Then, for any ğ¾âˆˆN, the distribution ğœ‡z,ğ¾satisfies
W1(ğœ‡z,ğ¾,ğœ‡(ğ›½,ğœ€)
z)â‰¤4âˆš
ğ‘‘ğ¾ğœ€+ğ‘ŠÂ·ğœ…(ğ›½,ğœ€,ğ‘‘)ğ¾, (8)
where 0<ğœ…(ğ›½,ğœ€,ğ‘‘)<1is a constant.
Moreover, if ğœ…(ğ›½,ğœ€,ğ‘‘)satisfies limğ¾â†’âˆğœ…(ğ›½,ğ›¿/ğ¾,ğ‘‘)ğ¾=0with someğ›¿ >0, there exists a sequence ğœ€=ğœ€ğ¾â†˜0as
ğ¾â†’âˆsuch thatW1(ğœ‡z,ğ¾,ğœ‡(ğ›½,ğœ€)
z)=ğ‘œ(1)asğ¾â†’âˆholds.
Thistheoremshowsthattheparameterdistribution ğœ‡z,ğ¾byPoissonSGDconvergestothestationarydistribution ğœ‡(ğ›½,ğœ€)
z
owingtotherandomlearningrate(5). ThisiscontrasttoordinarySGD,whichisnotshowntoconvergetoastationary
distribution. Further, Poisson SGD does not make any assumptions on the gradient noise ğœ‰(ğ‘›,ğ‘š)
ğ‘˜in Remark 1, unlike
SGLD, which converges to a stationary distribution by introducing Gaussianity in the gradient noise.
The right-hand side in (8) shows an approximation-complexity trade-off of Poisson SGD described as follows. In
preparation, we will introduce a certain stochastic process to achieve the stationary distribution ğœ‡(ğ›½,ğœ€)
z(detail is in
Section5). Thefirsttermof(8)describesanapproximationerrorofPoissonSGDtothestochasticprocess. Thesecond
term of (8) denotes a convergence error of the stochastic process to the stationary distribution ğœ‡(ğ›½,ğœ€)
z, which reflects
the complexity of the stochastic process. ğœ€is a parameter for the stochastic process and controls the balance between
the approximation error and the complexity error.
Wefurtherdiscusstheadditionalassumption limğ¾â†’âˆğœ…(ğ›½,ğ›¿/ğ¾,ğ‘‘)ğ¾=0. Thisconditionisrelatedtotheconvergence
rateoftheapproximatedstochasticprocessofPoissonSGD.Althoughtheexplicitformof ğœ…(ğ›½,ğ›¿/ğ¾,ğ‘‘)isnotclarified
inourcase,thereisacommonexamplehavingitsexplicitform. OneexampleisSGLD:Raginskyetal.(2017)shows
that a form of ğœ…(ğ›½,ğ›¿/ğ¾,ğ‘‘)can be calculated, because SGLD is reduced to the Langevin process.
Remark 4 (Form ofğœ…(ğ›½,ğœ€,ğ‘‘)).We discuss a form of ğœ…(ğ›½,ğœ€,ğ‘‘)of other related algorithms, although we could not
achievetheexplicitformof ğœ…(ğ›½,ğœ€,ğ‘‘)ofPoissonSGD.InthecaseofLangevindynamicswiththesettingofRaginsky
et al. (2017), ğœ…(ğ›½,ğœ€,ğ‘‘)isÎ©(ğ‘ğ¿ğ‘†ğ‘˜ğœ‚/ğ›½(ğ›½+ğ‘‘)), whereğ‘ğ¿ğ‘†is the logarithmic Sobolev constant. On the other hand,
explicitly deriving ğœ…(ğ›½,ğœ€,ğ‘‘)for a class of PDMP is a challenging task as described in Deligiannidis et al. (2019);
Durmus et al. (2020), as well as that of Poisson-SGD.
Remark 5 (Comparison with SGLD) .We discuss the difference between Poisson SGD and SGLD, which is another
method achieving a stationary distribution. First, while SGLD adds a Gaussian noise to the update formula of SGD,
Poisson SGD does not have an additive noise. The second difference is the form of the stationary distribution. A
stationary distribution of SGLD is the Gibbs distribution, and that of Poisson SGD has the different form (7). This
difference is derived from the random learning rate of Poisson SGD.
Remark 6 (Relation to flat minima) .From Theorem 1, we can state the property of Poisson SGD being easier to go
totheflatminimathanthesharpminima. Weconsidertheprobabilityofexistencearoundaflatminimum ğœƒ1âˆˆÎ˜and
a sharp minimum ğœƒ2âˆˆğœƒ, when we find that, due to the shape of the distribution, a measure of an ğœ–-neighborhood of
ğœƒ1is greater than that within an ğœ–-neighborhood of ğœƒ2. Hence, we can claim that Poisson SGD also tends to favor flat
minima.
4.2 Global Convergence
We discuss the global convergence statement, that is, the empirical risk ğ¿z(ğœƒğ¾)with Poisson SGD is minimized with
high probability. We consider the additional assumption for the loss function â„“:
Assumption 2. With someğ‘1>0,supğ‘§âˆˆZâˆ¥âˆ‡â„“(ğ‘§;ğœƒ1)âˆ’âˆ‡â„“(ğ‘§;ğœƒ2)âˆ¥â‰¤ğ‘1âˆ¥ğœƒ1âˆ’ğœƒ2âˆ¥holds for every ğœƒ1â‰ ğœƒ2âˆˆÎ˜.
7Under review as submission to TMLR
Then,weobtainthefollowingglobalconvergencetheorem. Wedefine ğµ:=supğ‘§âˆˆZâˆ¥âˆ‡â„“(ğ‘§; 0)âˆ¥byfollowingAssump-
tion 1.
Theorem 2 (Global convergence of Poisson SGD on empirical risk) .Fix arbitrary ğ›½,ğœ€ > 0. Consider Poisson SGD
in whichğ¶ğ‘ƒ=1/ğœ€. Let the upper bound of W1(ğœ‡z,ğ¾,ğœ‡(ğ›½,ğœ€)
z)obtained in Theorem 1 be ğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘). Also, suppose
that Assumption 1 and 2 hold. Then, it holds that
Eğœƒğ¾âˆ¼ğœ‡z,ğ¾[ğ¿z(ğœƒğ¾)]âˆ’min
ğœƒâˆˆÎ˜ğ¿z(ğœƒ)
â‰¤(ğ‘1ğ‘Š+ğµ)âˆšï¸
ğ‘Šğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘)+1
ğ›½ğ‘‘
2logğ‘’ğ‘Š2ğ‘1ğ›½
ğ‘‘+log
1+ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘€â„“
. (9)
Theorem2statesthatwecanmake E[ğ¿z(ğœƒğ¾)]bearbitrarilycloseto minğœƒâˆˆÎ˜ğ¿z(ğœƒ)byselectinglarge ğ›½,providedthat
we can make ğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘)arbitrarily small by the choice of ğœ€andğ¾in spite ofğ›½. Intuitively, Poisson SGD achieves
global convergence by appropriately adjusting the learning rate and momentum coefficient based on the shape of the
loss function at the current location. Poisson SGD achieves the global convergence by the similar approach of global
convergence of SGLD by Raginsky et al. (2017).
The right-hand side of (9) is divided into two terms. The first term expresses the distance between the parameter and
its stationary distribution. The second represents the degree of concentration of the stationary distribution ğœ‡(ğ›½,ğœ€)
zon
the global optima. The higher the inverse temperature ğ›½, the more the term decreases.
5 Proof Outline
5.1 Overview
We give an overview of a proof of Theorem 1. In preparation, we present several key concepts: (i) the property of
thepiece-wise deterministic Markov process (PDMP) (Davis, 1984; 1993), and (ii) the ergodicity of bouncy particle
sampler(BPS) (Peters & de With, 2012). The PDMP is a class of Markov processes that behave deterministically for
someperiodandjumpsrandomly,whicheasilyconvergestoastationarydistribution. BPSisastochasticalgorithmin
the class of the PDMP.
We show the statement by the following steps:
(I) We show that the distribution of the parameter by Poisson SGD is sufficiently close to that of a parameter by
BPS. We show this claim by using the approximation theory on PDMP (Theorem 3).
(II) We derive a stationary distribution and the ergodicity of BPS, following previous researches (Theorem 4).
5.2 Design of BPS
We introduce BPS, which is one of the most popular algorithms in PDMPs, and actively studied in terms of MCMC
algorithm(Deligiannidisetal.,2019;Bouchard-CÃ´tÃ©etal.,2018). BPSgeneratesasequenceofparameters {bğœƒğ‘˜}ğ¾
ğ‘˜=1âŠ‚Î˜
andvelocityvectors {bğ‘£ğ‘˜}ğ¾
ğ‘˜=1âŠ‚Rğ‘‘initsrecursivemanner,asshowninAlgorithm2. Let (bğœƒ0,bğ‘£0)betheinitialization.
For theğ‘˜-th iteration, BPS generates a learning rate bğœ‚ğ‘˜from an exponential distribution whose intensity depends on
the previous pair(bğœƒğ‘˜âˆ’1,bğ‘£ğ‘˜âˆ’1)and the positive constants Î›refandğ¶ğµ. After obtaining the parameter bğœƒğ‘˜, we consider
the stochastic update of the velocity vector. That is, with the probability
bğ‘ğ‘˜:=ğ›½âŸ¨âˆ‡ğ¿z(bğœƒğ‘˜),bğ‘£ğ‘˜âˆ’1âŸ©++ğ¶ğµ
ğ›½âŸ¨âˆ‡ğ¿z(bğœƒğ‘˜),bğ‘£ğ‘˜âˆ’1âŸ©++Î›ref+ğ¶ğµ, (10)
weupdatethevelocityvectorwiththegradientofthefull-batchloss âˆ‡ğ¿z,otherwisewiththesamplefromtheuniform
distribution on Sğ‘‘âˆ’1. The former update is called reflection, and the latter is refreshment . We remark thatâˆ¥bğ‘£ğ‘˜âˆ¥is
constant forğ‘˜=1,2,...,ğ¾in the same way as Poisson SGD (See Proposition 7 in Appendix).
5.3 Connect Poisson SGD and BPS
WeshowthattheoutputdistributionofPoissonSGDandthatofBPSaresufficientlycloseasinthefollowingstatement:
8Under review as submission to TMLR
Algorithm 2 Bouncy Particle Sampler
1:Initialize(bğœƒ0,bğ‘£0)asâˆ¥bğ‘£0âˆ¥=1.
2:forğ‘˜=1,2,...,ğ¾do
3:Sample bğœ‚ğ‘˜asbğœ‚ğ‘˜âˆ¼ğ‘ƒ(bğœ‚ğ‘˜â‰¥ğ‘¡)=exp
âˆ’âˆ«ğ‘¡
0{ğ›½âŸ¨âˆ‡ğ¿z(bğœƒğ‘˜âˆ’1+ğ‘Ÿbğ‘£ğ‘˜âˆ’1),bğ‘£ğ‘˜âˆ’1âŸ©++Î›ref+ğ¶ğµ}ğ‘‘ğ‘Ÿ
4:Update bğœƒğ‘˜asbğœƒğ‘˜=bğœƒğ‘˜âˆ’1+bğœ‚ğ‘˜bğ‘£ğ‘˜âˆ’1
5:With probability bğ‘ğ‘˜as (10), update bğ‘£ğ‘˜as
bğ‘£ğ‘˜=bğ‘£ğ‘˜âˆ’1âˆ’2âŸ¨âˆ‡ğ¿z(bğœƒğ‘˜),bğ‘£ğ‘˜âˆ’1âŸ©
âˆ¥âˆ‡ğ¿z(bğœƒğ‘˜)âˆ¥2âˆ‡ğ¿z(bğœƒğ‘˜)
Otherwise, update bğ‘£ğ‘˜as
bğ‘£ğ‘˜âˆ¼Unif(Sğ‘‘âˆ’1)
6:end for
7:Return(bğœƒğ¾,bğ‘£ğ¾)
Theorem3 (DistancebetweenPoissonSGDandBPS) .Fixarbitrary ğ›½,ğœ€> 0. AsforPoissonSGD,weset ğ¶ğ‘ƒ=1/ğœ€.
As for BPS, we set Î›refandğ¶ğµasÎ›ref+ğ¶ğµ=ğ›½ğ‘€â„“+1/ğœ€. Let the distribution of the obtained parameter by Poisson
SGD and BPS be ğœ‡z,ğ¾andbğœ‡z,ğ¾respectively. We set the same initial value between Poisson SGD and BPS. Then, the
following holds:
W1(ğœ‡z,ğ¾,bğœ‡z,ğ¾)â‰¤4âˆš
ğ‘‘ğ¾ğœ€.
For proving this theorem, we calculate the distance between Poisson SGD and BPS by a one-step update. Then, we
simplyaccumulatethiserrorfor ğ¾times. Inthisdiscussion,wemainlyusethepropertythatiflearningrate ğœ‚ğ‘˜andbğœ‚ğ‘˜
are small, the difference of ğ‘£ğ‘˜andbğ‘£ğ‘˜is also made to be small. This type of discussion is also used in Raginsky et al.
(2017).
5.4 The Stationary Distribution and Ergodicity of BPS
In this section, we investigate the stationary distribution and ergodicity of BPS. First, we define the term ergodicity .
Definition 2 (Ergodicity) .We consider the discrete-time Markov process. If the process converges to a unique
stationary distribution, we call the process has the ergodicity. Especially, if the ergodic process converges to its
stationary distribution by the exponential rate about the number of iteration ğ‘˜, the process is called exponentially
ergodic.
Without ergodicity, the stochastic process may converge to more than one stationary distribution, or not converge to
any stationary distribution due to stacking to a saddle point in the parameter space. So we have to prove this property
when we try to analyze the stationary distribution of a stochastic process.
Now, we show our result about BPS.
Theorem 4 (Stationary Distribution of BPS) .Suppose that Assumption 1 holds. Set the parameter of BPS, Î›refand
ğ¶ğµas in Theorem 3. Then, the distribution bğœ‡z,ğ¾of the obtained parameters bğœƒğ¾by BPS satisfies the following:
âˆ¥bğœ‡z,ğ¾âˆ’ğœ‡(ğ›½,ğœ€)
zâˆ¥TVâ‰¤ğœ…(ğ›½,ğœ€,ğ‘‘)ğ¾,
whereğœ…(ğ›½,ğœ€,ğ‘‘)is a positive constant less than 1.
In the proof of this theorem, we use the discussion in Deligiannidis et al. (2019) which showed that continuous-time
BPS converges to the unique stationary distribution ğœ‹(ğœƒ)âˆexp(âˆ’ğ‘ˆ(ğœƒ))by the exponential rate in TV distance.
6 Generalization Error Analysis
We define an expected risk of ğœƒâˆˆÎ˜, also known as the generalization error
ğ¿(ğœƒ):=Eğ‘§âˆ¼ğ‘ƒâˆ—[â„“(ğ‘§;ğœƒ)],
9Under review as submission to TMLR
which measures a prediction performance with unseen data. We calculate the generalization error of the parameter
obtained by the Poisson SGD, using the discussion in Raginsky et al. (2017).
Now, we give our results. We define ğ´:=supğ‘§âˆˆZ|â„“(ğ‘§; 0)|by following Assumption 1.
Theorem 5 (Generalization Error of Poisson SGD) .Suppose that Assumption 1 and 2 hold. Let ğœƒğ¾be the parameter
obtained by Poisson SGD with ğ¶ğ‘ƒ=1/ğœ€. Then, we obtain the following bound:
Ezâˆ¼ğ‘ƒğ‘›âˆ—[Eğœƒğ¾âˆ¼ğœ‡z,ğ¾[ğ¿(ğœƒğ¾)]]âˆ’ min
ğœƒâˆˆÎ˜ğ¿(ğœƒ)
â‰¤(ğ‘1ğ‘Š+ğµ) âˆšï¸
ğ‘Šğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘)+2ğ‘Š ğ¶ğ‘‘+ğ›½ğ¶
ğ‘›1
2
+ğ¶ğ‘‘+ğ›½ğ¶
ğ‘›1
4!!
+1
ğ›½ğ‘‘
2logğ‘’ğ‘Š2ğ‘1ğ›½
ğ‘‘+log
1+ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘€â„“
,
whereğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘)is the upper bound of the Wasserstein distance in Theorem 1, ğ¶ğ‘‘=4ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)/ğ‘€â„“, and
ğ¶=ğ‘1ğ‘Š2+2ğµğ‘Š+2ğ´.
Theorem5statesthattheexpectedvalueofthegeneralizationerrorofPoissonSGDcanbearbitrarilyclosetoitsglobal
optima inğœƒâˆˆÎ˜, by selecting small ğœ€, largeğ¾, largeğ›½, and largeğ‘›, provided that ğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘)can be arbitrarily small
only by the choice of ğœ€andğ¾.
We further discuss a way of improve an order of the generalization bound in Theorem 5. While our bound has the
orderğ‘‚((1/ğ‘›)1/4), we can obtain an order ğ‘‚(1/ğ‘›)by using the dissipativity condition of the loss function, which is
used in Raginsky et al. (2017) for SGLD. The dissipativity condition allows us to derive log-Sobolev inequality for
ğ¿z(ğœƒ), which leads the improved sample complexity. We state this fact in the following proposition.
Proposition6. SupposethatthesameconditionandsettingasTheorem5hold. Inaddition,weassumethattheGibbs
distributionğœˆ(ğ›½)
zâˆexp(âˆ’ğ›½ğ¿ z(ğœƒ))satisfies the log-Sobolev inequality for any dataset z={ğ‘§1,...,ğ‘§ğ‘›}, that is,
E[ğ‘“(ğœƒ)2logğ‘“(ğœƒ)2]âˆ’E[ğ‘“(ğœƒ)2]logE[ğ‘“(ğœƒ)2]â‰¤ğ‘(ğ›½)
LSE[âˆ¥âˆ‡ğ‘“(ğœƒ)âˆ¥2]
holds for all smooth functions ğ‘“and any data z={ğ‘§1,...,ğ‘§ğ‘›}, whereğœƒâˆ¼ğœˆ(ğ›½)
zandğ‘(ğ›½)
LS<âˆis a constant. Then, the
following holds:
Ezâˆ¼ğ‘ƒğ‘›âˆ—[Eğœƒğ¾âˆ¼ğœ‡z,ğ¾[ğ¿(ğœƒğ¾)]]âˆ’ min
ğœƒâˆˆÎ˜ğ¿(ğœƒ)
â‰¤(ğ‘1ğ‘Š+ğµ) âˆšï¸
ğ‘Šğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘)+2ğ‘(ğ›½)
LSğ›½ğ‘€â„“
ğ‘›!
+ğ‘Šâˆšï¸ƒ
2ğ‘(ğ›½)
LSlog(1+ğ‘ğ‘‘ğ›½ğœ€ğ‘€â„“)+ğ‘‘
2ğ›½logğ‘’ğ‘Š2ğ‘1ğ›½
ğ‘‘
.
7 Experiments
Wegiveseveralexperimentalresulttovalidateourtheoreticalclaim. Specifically,weshowthatPoissonSGDcanlearn
parameters in a practical situation. Note that our aim is not to develop an effective method with high generalisation
performance, but to develop a method that can evaluate the global convergence.
7.1 MNIST Dataset
We conducted experiments with the MNIST dataset (Deng, 2012). We consider a 4-layer fully connected neural
networkwith 200unitsofhiddenlayersareall 200andthesigmoidactivationfunction. Wecomparetheperformance
ofPoissonSGDwithSGD,SGDwithMomentum,SGLD.Wesetthebatchsizeas 256,thelearningrateoftheSGD,
the SGD with momentum and SGLD as 0.01, and the momentum coefficient as 0.9. We choose the hyper-parameter
ofPoissonSGDas ğ¶ğ‘ƒ=100,ğ¶ğ›¼=100,andğ›½=10000. Wealsouse ğ›½=10000forSGLD.Weuse 60000imagesfor
training and 10000images for validation.
Figure 2 shows the result. The vertical line shows the misclassification ratio (%) and the horizontal line shows the
number of epochs. We can see that Poisson SGD achieves sufficiently low errors, suggesting that it achieves a good
minimum. In addition, Poisson SGD converges faster than other methods.
10Under review as submission to TMLR
Figure2: ThecomparisonofthetrainerrorrateandvaliderrorratewhenoptimizedbyPoissonSGD,SGD,SGDwith
momentum, and SGLD for 4-Layer DNN on MNIST.
7.2 CIFAR-10 Dataset
We conducted experiments with the CIFAR-10 dataset (Krizhevsky et al., 2009). We trained a convolutional neural
network of 3layers with the ReLU activation function, a 3Ã—3kernel, and the dropout rate 0.25. We compare the
performanceofPoissonSGDwithSGD,SGDwithMomentum,SGLD.Wesetthebatchsizeas256,thelearningrateof
SGD,SGDwithmomentumandSGLDas0.01,andthemomentumcoefficientas0.9. Wechoosethehyper-parameter
of Poisson SGD as ğ¶ğ‘ƒ=100,ğ¶ğ›¼=1, andğ›½=10000. We also use ğ›½=10000for SGLD. We use 45000 data for
training and 5000 data for validation.
Figure 3 shows the result. The vertical line shows the misclassification ratio (%) and the horizontal line shows the
numberofepochs. AlthoughPoissonSGDisnotthebestmethod,itachievessufficientlylowerrors,suggestingthatit
achieves a good minimum. In addition, it also achieves good accuracy comparable to that of SGD.
Figure3: ThecomparisonofthetrainerrorrateandvaliderrorratewhenoptimizedbyPoissonSGD,SGD,SGDwith
momentum, and SGLD for CNN on Cifar-10.
8 Conclusion
We developed a new variant of SGD, Poisson SGD, whose search direction degenerates and derived its stationary
distribution by incorporating a modification on the learning rate. The parameters trained by Poisson SGD are close
enough to the global minima to take advantage of convergence to the stationary distribution. The generalization error
is also evaluated. We believe that our work leads to the analysis of the actual SGD dynamics, not variants of it in the
future.
11Under review as submission to TMLR
Broader Impact Statement
The paper aims to provide a theoretical understanding of machine learning methods, which in itself has no direct
negative impact on society.
References
DominiqueBakry,IvanGentil,andMichelLedoux. AnalysisandGeometryofMarkovDiffusionOperators . Springer,
2014.
Barak Battash, Lior Wolf, and Ofir Lindenbaum. Revisiting the noise model of stochastic gradient descent. In
International Conference on Artificial Intelligence and Statistics , 2024.
Andrea Bertazzi, Joris Bierkens, and Paul Dobson. Approximations of piecewise deterministic markov processes and
their convergence properties. Stochastic Processes and their Applications , 154:91â€“153, 2022.
LÃ©onard Blier, Pierre Wolinski, and Yann Ollivier. Learning with random learning rates. In ECML PKDD , 2019.
FranÃ§ois Bolley and CÃ©dric Villani. Weighted csiszÃ¡r-kullback-pinsker inequalities and applications to transportation
inequalities. Annales de la FacultÃ© des sciences de Toulouse: MathÃ©matiques , 14(3):331â€“352, 2005.
SilvereBonnabel. Stochasticgradientdescentonriemannianmanifolds. IEEETransactionsonAutomaticControl ,58:
2217â€”2229, 2013.
LÃ©on Bottou. Stochastic gradient learning in neural networks. Proceedings of Neuro-NÄ±mes , 91(8):12, 1991.
Alexandre Bouchard-CÃ´tÃ©, Sebastian J Vollmer, and Arnaud Doucet. The bouncy particle sampler: A nonreversible
rejection-freemarkovchainmontecarlomethod. JournaloftheAmericanStatisticalAssociation ,113(522):855â€“867,
2018.
Nicolas Boumal. An Introduction to Optimization on Smooth Manifolds . Cambridge University Press, 2023.
ZaiweiChen,ShancongMou,andSivaThejaMaguluri. Stationarybehaviorofconstantstepsizesgdtypealgorithms:
Anasymptoticcharacterization. ProceedingsoftheACMonMeasurementandAnalysisofComputingSystems ,6(1)
(19):1â€“24, 2022.
XiangCheng,DongYin,PeterBartlett,andMichaelJordan.Stochasticgradientandlangevinprocesses.In International
Conference on Machine Learning , 2020.
ArnakDalalyan. Furtherandstrongeranalogybetweensamplingandoptimization: Langevinmontecarloandgradient
descent. In Conference on Learning Theory , 2017.
M.H.ADavis. Piecewise-deterministicmarkovprocesses: Ageneralclassofnon-diffusionstochasticmodels. Journal
of the Royal Statistical Society , Series B (Methodological)(46):353â€“388, 1984.
M.H.A Davis. Markov Models and Optimization . Chapman & Hall/CRC Monographs on Statistics & Applied
Probability. Taylor & Francis, 1993.
George Deligiannidis, Alexandre Bouchard-CÃ´tÃ©, and Arnaud Doucet. Exponential ergodicity of the bouncy particle
sampler.The Annals of Statistics , 47:1268â€“1287, 2019.
Li Deng. The mnist database of handwritten digit images for machine learning research. IEEE Signal Processing
Magazine , 29(6):141â€“142, 2012.
AymericDieuleveut,AlainDurmus,andFrancisBach. Bridgingthegapbetweenconstantstepsizestochasticgradient
descent and markov chains. The Annals of Statistics , 48(3):1348â€“1382, 2020.
Alain Durmus and Ã‰ric Moulines. Sampling from a strongly log-concave distribution with the unadjusted langevin
algorithm. HAL preprint hal-01304430v1 , 2016.
12Under review as submission to TMLR
Alain Durmus, Arnaud Guillin, and Pierre MonmarchÃ©. Geometric ergodicity of the bouncy particle sampler. Annals
of Applied Probability , 30:2069â€“2098, 2020.
Guillaume Garrigos and Robert M. Gower. Handbook of convergence theorems for (stochastic) gradient methods.
arXiv preprint arXiv:2301.11235 , 2023.
Alison L. Gibbs and Francis Edward Su. On choosing and bounding probability metrics. International Statistical
Review / Revue Internationale de Statistique , 70(3):419â€“435, 2002.
Jeff Z. HaoChen, Colin Wei, Jason D. Lee, and Tengyu Ma. Shape matters: Understanding the implicit bias of the
noise covariance. In Conference On Learning Theory , 2021.
Fengxiang He, Tongliang Liu, and Dacheng Tao. Control batch size and learning rate to generalize well: Theoretical
and empirical evidence. In Advances in Neural Information Processing Systems , 2019.
Elad Hoffer, Itay Hubara, and Daniel Soudry. Train longer, generalize better: closing the generalization gap in large
batch training of neural networks. Advances in neural information processing systems , 30, 2017.
Stanislaw Jastrzebski, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio, and Amos
Storkey. Three factors influencing minima in sgd. arXiv preprint arXiv:1711.04623 , 2017.
NitishShirishKeskar,DheevatsaMudigere,JorgeNocedal,MikhailSmelyanskiy,andPingTakPeterTang. Onlarge-
batch training for deep learning: Generalization gap and sharp minima. In International Conference on Learning
Representations , 2016.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
Harold J. Kushner and G. George Yin. Stochastic Approximation and Recursive Algorithms . Springer, 2003.
Guanghui Lan. First-order and Stochastic Optimization Methods for Machine Learning . Springer, 2020.
Jonas Latz. Analysis of stochastic gradient descent in continuous time. Statistics and Computing , 31(39), 2021.
QianxiaoLi,ChengTai,andWeinanE. Stochasticmodifiedequationsandadaptivestochasticgradientalgorithms. In
International Conference on Machine Learning , 2017.
LennartLjung. Analysisofrecursivestochasticalgorithm. IEEEtransactionsonautomaticcontrol ,22:551â€“575,1977.
Stephan Mandt, Matthew D. Hoffman, and David M. Blei. Stochastic gradient descent as approximate bayesian
inference. Journal of Machine Learning Research , 18:1â€“35, 2017.
Daniele Musso. Stochastic gradient descent with random learning rate. arXiv preprint arXiv:2003.06926 , 2020.
Thanh Huy Nguyen, Umut Simsekli, Mert GÃ¼rbÃ¼zbalaban, and GaÃ«l Richard. First exit time analysis of stochastic
gradient descent under heavy-tailed gradient noise. Advances in neural information processing systems , 32, 2019.
E.A.J.F.PetersandG.deWith. Rejection-freemontecarlosamplingforgeneralpotentials. PhysicalReviewE ,2012.
Feng Qi and Qiu-Ming Luo. Bounds for the ratio of two gamma functions: from Wendelâ€™s asymptotic relation to
ElezoviÄ‡-Giordano-PeÄariÄ‡â€™s theorem. Journal of Inequalities and Applications , 2013(1):542, November 2013.
Ning Qian. On the momentum term in gradient descent learning algorithms. Neural Networks , pp. 145â€“151, 1999.
Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex learning via stochastic gradient langevin
dynamics: a nonasymptotic analysis. In Conference On Learning Theory , 2017.
Chris Sherlock and Alexandre H. Thiery. A discrete bouncy particle sampler. Biometrika , 109:335â€“349, 2022.
Umut Simsekli, Levent Sagun, and Mert Gurbuzbalaban. A tail-index analysis of stochastic gradient noise in deep
neural networks. In International Conference on Machine Learning , pp. 5827â€“5837. PMLR, 2019.
13Under review as submission to TMLR
IlyaSutskever,JamesMartens,GeorgeDahl,andGeoffreyHinton. Ontheimportanceofinitializationandmomentum
in deep learning. In International Conference on Machine Learning , 2013.
Nilesh Tripuraneni, Nicolas Flammarion, Francis Bach, and Michael I. Jordan. Averaging stochastic gradient descent
on riemannian manifolds. In Conference On Learning Theory , 2018.
Max Welling and Yee Whye Teh. Bayesian learning via stochastic gradient langevin dynamics. In International
Conference on Machine Learning , 2011.
Jingfeng Wu, Wenqing Hu, Haoyi Xiong, Jun Huan, Vladimir Braverman, and Zhanxing Zhu. On the noisy gradient
descent that generalizes as sgd. In International Conference on Machine Learning , 2020.
Zhanxing Zhu, Jingfeng Wu, Bing Yu, Lei Wu, and Jinwen Ma. The anisotropic noise in stochastic gradient descent:
Its behavior of escaping from sharp minima and regularization effects. In International Conference on Machine
Learning, 2019.
A Supportive Information
WeverifythatthevelocityvectorisnormalizedbythechoiceofthemomentumcoefficientforPoissonSGDandBPS.
Proposition7. Considertheupdate (4)forğ‘£ğ‘˜withitsmomentumcoefficient (6). Then,forâˆ€ğ‘˜âˆˆ{1,2,...,ğ¾},wehave
âˆ¥ğ‘£ğ‘˜âˆ¥=1. Further, for bğ‘£ğ‘˜defined in Algorithm 2, we obtain âˆ¥bğ‘£ğ‘˜âˆ¥=1for everyğ‘˜=1,...,ğ¾.
Proof.We first consider ğ‘£ğ‘˜with the Poisson SGD case. Simply, we have
âˆ¥ğ‘£ğ‘˜âˆ¥=ğ‘£ğ‘˜âˆ’1âˆ’2âŸ¨âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜),ğ‘£ğ‘˜âˆ’1âŸ©
âˆ¥âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)âˆ¥2âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)
= 
ğ¼ğ‘‘âˆ’2âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)âŠ¤
âˆ¥âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)âˆ¥2!
ğ‘£ğ‘˜âˆ’1
=vut
ğ‘£âŠ¤
ğ‘˜âˆ’1 
ğ¼ğ‘‘âˆ’2âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)âŠ¤
âˆ¥âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜)âˆ¥2!2
ğ‘£ğ‘˜âˆ’1
=âˆ¥ğ‘£ğ‘˜âˆ’1âˆ¥.
Since we setâˆ¥ğ‘£0âˆ¥=1for initialization, the statement holds.
Forbğ‘£ğ‘˜with the BPS case, the reflection does not change the norm of bğ‘£ğ‘˜in the same way, and the refreshment also
keepsâˆ¥bğ‘£ğ‘˜âˆ¥=1, which completes the proof. â–¡
B Proof of Theorem 1
Proof.By Theorem 3 and 4, we can bound the approximation error
W1(ğœ‡z,ğ¾,bğœ‡z,ğ¾)â‰¤4âˆš
ğ‘‘ğ¾ğœ€,
and the convergence error of BPS as
âˆ¥bğœ‡z,ğ¾âˆ’ğœ‡(ğ›½,ğœ€)
zâˆ¥TVâ‰¤ğœ…(ğ›½,ğœ€,ğ‘‘)ğ¾.
From Theorem 4 in Gibbs & Su (2002) (explicit form is Theorem 13 in Appendix H), we can bound the Wasserstein
distance by the total variation, then obtain
W1(bğœ‡z,ğ¾,ğœ‡(ğ›½,ğœ€)
z)â‰¤ğ‘Šâˆ¥bğœ‡z,ğ¾âˆ’ğœ‡(ğ›½,ğœ€)
zâˆ¥TVâ‰¤ğ‘Šğœ…(ğ›½,ğœ€,ğ‘‘)ğ¾.
The triangle inequality completes the proof. â–¡
14Under review as submission to TMLR
C Proof of Theorem 3
Proof.From the definition of Wasserstein distance,
W1(ğœ‡z,ğ‘˜,bğœ‡z,ğ‘˜)= inf
ğœ‹âˆˆÎ (ğœ‡z,ğ‘˜,bğœ‡z,ğ‘˜)Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’bğœƒğ‘˜âˆ¥1]
holds,sowestudythedistancebetween ğœƒğ‘˜andbğœƒğ‘˜intermsofthenorm âˆ¥Â·âˆ¥1. Sinceâˆ¥ğ‘£ğ‘˜âˆ¥=âˆ¥ğ‘£ğ‘˜âˆ’1âˆ¥=âˆ¥bğ‘£ğ‘˜âˆ¥=âˆ¥bğ‘£ğ‘˜âˆ’1âˆ¥=1
holds by Proposition 7, we have
Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’bğœƒğ‘˜âˆ¥1]=Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’1+ğœ‚ğ‘˜ğ‘£ğ‘˜âˆ’1âˆ’(bğœƒğ‘˜âˆ’1+bğœ‚ğ‘˜bğ‘£ğ‘˜âˆ’1)âˆ¥1]
â‰¤Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’1âˆ’bğœƒğ‘˜âˆ’1âˆ¥1]+Eğœ‹[âˆ¥(bğœ‚ğ‘˜âˆ’ğœ‚ğ‘˜)bğ‘£ğ‘˜âˆ’1+ğœ‚ğ‘˜(bğ‘£ğ‘˜âˆ’1âˆ’ğ‘£ğ‘˜âˆ’1)âˆ¥1]
â‰¤Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’1âˆ’bğœƒğ‘˜âˆ’1âˆ¥1]+Eğœ‹[âˆ¥(bğœ‚ğ‘˜âˆ’ğœ‚ğ‘˜)bğ‘£ğ‘˜âˆ’1âˆ¥1]+Eğœ‹[âˆ¥ğœ‚ğ‘˜(bğ‘£ğ‘˜âˆ’1âˆ’ğ‘£ğ‘˜âˆ’1)âˆ¥1]
â‰¤Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’1âˆ’bğœƒğ‘˜âˆ’1âˆ¥1]+âˆš
ğ‘‘Eğœ‹[|ğœ‚ğ‘˜âˆ’bğœ‚ğ‘˜|]+2âˆš
ğ‘‘Eğœ‹[ğœ‚ğ‘˜], (11)
where we useâˆ¥Â·âˆ¥ 1â‰¤âˆš
ğ‘‘âˆ¥Â·âˆ¥in the last inequality.
We first evaluate the second term of (11). There exists a coupling ğœ‹such that
Eğœ‹[|ğœ‚ğ‘˜âˆ’bğœ‚ğ‘˜|]=W1(ğ‘ƒğœ‚ğ‘˜,ğ‘ƒbğœ‚ğ‘˜)
holds,where ğ‘ƒğœ‚ğ‘˜andğ‘ƒbğœ‚ğ‘˜denotethedistributionof ğœ‚ğ‘˜andbğœ‚ğ‘˜respectively. Weusesuchacouplingas ğœ‹. Inevaluating
W1(ğ‘ƒğœ‚ğ‘˜,ğ‘ƒbğœ‚ğ‘˜), we consider the following analysis. ğœ‚ğ‘˜andbğœ‚ğ‘˜are 1-dimensional and their cumulative distribution
function is written as
ğ¹1(ğ‘¡)=1âˆ’exp
âˆ’âˆ«ğ‘¡
0(ğ›½âŸ¨âˆ‡bğ¿(ğ‘˜)
z(ğœƒ+ğ‘Ÿğ‘£),ğ‘£âŸ©++ğ¶ğ‘ƒ)ğ‘‘ğ‘Ÿ
,
ğ¹2(ğ‘¡)=1âˆ’exp
âˆ’âˆ«ğ‘¡
0(ğ›½âŸ¨âˆ‡ğ¿z(ğœƒ+ğ‘Ÿğ‘£),ğ‘£âŸ©++ğ¶ğµ+Î›ref)ğ‘‘ğ‘Ÿ
,
respectively, and we also have
ğ›½âŸ¨âˆ‡bğ¿(ğ‘˜)
z(ğœƒ+ğ‘Ÿğ‘£),ğ‘£âŸ©++ğ¶ğ‘ƒâ‰¥ğ¶ğ‘ƒ,
ğ›½âŸ¨âˆ‡ğ¿z(ğœƒ+ğ‘Ÿğ‘£),ğ‘£âŸ©++ğ¶ğµ+Î›refâ‰¥ğ¶ğµ+Î›ref,and
|(ğ›½âŸ¨âˆ‡bğ¿(ğ‘˜)
z(ğœƒ+ğ‘Ÿğ‘£),ğ‘£âŸ©++ğ¶ğ‘ƒ)âˆ’(ğ›½âŸ¨âˆ‡ğ¿z(ğœƒ+ğ‘Ÿğ‘£),ğ‘£âŸ©++ğ¶ğµ+Î›ref)|
â‰¤max{|âˆ’ğ›½ğ‘€â„“+ğ¶ğ‘ƒâˆ’(ğ¶ğµ+Î›ref)|,|ğ›½ğ‘€â„“+ğ¶ğ‘ƒâˆ’(ğ¶ğµ+Î›ref)|}.
Hence, we can use Lemma 8 and obtain
W1(ğ‘ƒğœ‚ğ‘˜,ğ‘ƒbğœ‚ğ‘˜)â‰¤max{|âˆ’ğ›½ğ‘€â„“+ğ¶ğ‘ƒâˆ’(ğ¶ğµ+Î›ref)|,|ğ›½ğ‘€â„“+ğ¶ğ‘ƒâˆ’(ğ¶ğµ+Î›ref)|}
ğ¶ğ‘ƒ(ğ¶ğµ+Î›ref). (12)
Next, we evaluate the third term of (11). We have
E[ğœ‚ğ‘˜]=âˆ«âˆ
0ğ‘ƒ(ğœ‚ğ‘˜â‰¥ğ‘¡)ğ‘‘ğ‘¡
=âˆ«âˆ
0exp
âˆ’âˆ«ğ‘¡
0{ğ›½âŸ¨âˆ‡bğ¿(ğ‘˜)
z(ğœƒğ‘˜âˆ’1+ğ‘Ÿğ‘£ğ‘˜âˆ’1),ğ‘£ğ‘˜âˆ’1âŸ©++ğ¶ğ‘ƒ}ğ‘‘ğ‘Ÿ
ğ‘‘ğ‘¡
â‰¤âˆ«âˆ
0exp(âˆ’ğ¶ğ‘ƒğ‘¡)ğ‘‘ğ‘¡
=1
ğ¶ğ‘ƒ. (13)
Substituting (12) and (13) into (11), we have
Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’bğœƒğ‘˜âˆ¥1]â‰¤Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’1âˆ’bğœƒğ‘˜âˆ’1âˆ¥1] (14)
15Under review as submission to TMLR
+âˆš
ğ‘‘max{|âˆ’ğ›½ğ‘€â„“+ğ¶ğ‘ƒâˆ’(ğ¶ğµ+Î›ref)|,|ğ›½ğ‘€â„“+ğ¶ğ‘ƒâˆ’(ğ¶ğµ+Î›ref)|}
ğ¶ğ‘ƒ(ğ¶ğµ+Î›ref)+2âˆš
ğ‘‘
ğ¶ğ‘ƒ.
Sincewetake ğ¶ğ‘ƒinPoissonSGDas ğ¶ğ‘ƒ=1/ğœ€andğ¶ğµandÎ›refinBPSasğ¶ğµ+Î›ref=ğ›½ğ‘€â„“+1/ğœ€,(14)canbewritten
as
Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’bğœƒğ‘˜âˆ¥1]â‰¤Eğœ‹[âˆ¥ğœƒğ‘˜âˆ’1âˆ’bğœƒğ‘˜âˆ’1âˆ¥1]+4âˆš
ğ‘‘ğœ€.
Hence, solving this recursive inequality with ğœƒ0=bğœƒ0, we have
Eğœ‹[âˆ¥ğœƒğ¾âˆ’bğœƒğ¾âˆ¥1]â‰¤4âˆš
ğ‘‘ğ¾ğœ€,
which is the desired conclusion. â–¡
Lemma 8. Letğ‘1andğ‘2beR-valued random variables whose cumulative distribution functions are
ğ¹1(ğ‘¡)=1âˆ’exp
âˆ’âˆ«ğ‘¡
0ğ‘“1(ğ‘Ÿ)ğ‘‘ğ‘Ÿ
,andğ¹2(ğ‘¡)=1âˆ’exp
âˆ’âˆ«ğ‘¡
0ğ‘“2(ğ‘Ÿ)ğ‘‘ğ‘Ÿ
,
respectively, where ğ‘“1, ğ‘“2:Râ†’Rare continuous functions. Let the distributions of ğ‘1andğ‘2beğ‘ƒ1andğ‘ƒ2
respectively. Supposethat thereexists ğ‘€,ğ‘š 1,ğ‘š2>0suchthat|ğ‘“2(ğ‘¡)âˆ’ğ‘“1(ğ‘¡)|â‰¤ğ‘€,ğ‘š1â‰¤ğ‘“1(ğ‘¡), andğ‘š2â‰¤ğ‘“2(ğ‘¡)hold
forâˆ€ğ‘¡âˆˆR. Then, the Wasserstein distance between ğ‘ƒ1andğ‘ƒ2satisfies
W1(ğ‘ƒ1,ğ‘ƒ2)â‰¤ğ‘€
ğ‘š1ğ‘š2.
Proof.Sinceğ‘1andğ‘2are 1-dimensional, we have
W1(ğ‘ƒ1,ğ‘ƒ2)=âˆ«1
0ğ¹âˆ’1
1(ğ‘)âˆ’ğ¹âˆ’1
2(ğ‘)ğ‘‘ğ‘.
We introduce several notation ğ›¿(ğ‘Ÿ)=ğ‘“2(ğ‘Ÿ)âˆ’ğ‘“1(ğ‘Ÿ),ğ‘¡=ğ¹âˆ’1
1(ğ‘), andğ‘¡â€²=ğ¹âˆ’1
2(ğ‘), then
âˆ«ğ‘¡
0ğ‘“1(ğ‘Ÿ)ğ‘‘ğ‘Ÿ=log1
1âˆ’ğ‘
âˆ«ğ‘¡â€²
0(ğ‘“1(ğ‘Ÿ)+ğ›¿(ğ‘Ÿ))ğ‘‘ğ‘Ÿ=log1
1âˆ’ğ‘
holds. So, we obtain
âˆ«ğ‘¡
ğ‘¡â€²ğ‘“1(ğ‘Ÿ)ğ‘‘ğ‘Ÿ=âˆ«ğ‘¡â€²
0ğ›¿(ğ‘Ÿ)ğ‘‘ğ‘Ÿ.
Hence, we have
âˆ«ğ‘¡
ğ‘¡â€²ğ‘“1(ğ‘Ÿ)ğ‘‘ğ‘Ÿ=âˆ«max{ğ‘¡,ğ‘¡â€²}
min{ğ‘¡,ğ‘¡â€²}ğ‘“1(ğ‘Ÿ)ğ‘‘ğ‘Ÿâ‰¤ğ‘€ğ‘¡â€².
In addition,âˆ«max{ğ‘¡,ğ‘¡â€²}
min{ğ‘¡,ğ‘¡â€²}ğ‘“1(ğ‘Ÿ)ğ‘‘ğ‘Ÿâ‰¥ğ‘š1|ğ‘¡âˆ’ğ‘¡â€²|holds, so we have
|ğ‘¡âˆ’ğ‘¡â€²|â‰¤ğ‘€ğ‘¡â€²
ğ‘š1.
We have the upper bound of ğ‘¡â€²as
log1
1âˆ’ğ‘=âˆ«ğ‘¡â€²
0ğ‘“2(ğ‘Ÿ)ğ‘‘ğ‘Ÿâ‰¥ğ‘š2ğ‘¡â€²,
16Under review as submission to TMLR
so we have
|ğ‘¡âˆ’ğ‘¡â€²|â‰¤ğ‘€
ğ‘š1ğ‘š2log1
1âˆ’ğ‘.
Sinceâˆ«1
0|log(1âˆ’ğ‘)|ğ‘‘ğ‘=1holds, we obtain
âˆ«1
0ğ¹âˆ’1
1(ğ‘)âˆ’ğ¹âˆ’1
2(ğ‘)ğ‘‘ğ‘â‰¤ğ‘€
ğ‘š1ğ‘š2.
â–¡
D Proof of Theorem 4
We prove this theorem by two steps. First, we prove that BPS has ğœ‡(ğ›½,ğœ€)
zas one of its stationary distributions in
section D.1. At this stage, BPS may have other forms of stationary distribution or may not converge to its stationary
distribution. Second,weprovethatBPShasauniquestationarydistributionandconvergestoitsstationarydistribution
at exponential rate, in other words, it has the exponential ergodicity, in section D.2.
D.1 The form of the stationary distribution
In this section, we check that BPS has ğœ‡(ğ›½,ğœ€)
zas a stationary distribution. In the proof, we define ğœ†(ğœƒ,ğ‘£):=
ğ›½âŸ¨âˆ‡ğ¿z(ğœƒ),ğ‘£âŸ©+,Â¯ğœ†(ğœƒ,ğ‘£):=ğœ†(ğœƒ,ğ‘£)+Î›ref,andğ‘…z(ğœƒ):=ğ¼ğ‘‘âˆ’2âˆ‡ğ¿z(ğœƒ)âˆ‡ğ¿z(ğœƒ)âŠ¤
âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥2. Weremarkthat ğ‘…zisasymmetricmatrix
and satisfies ğ‘…z(ğœƒ)2=ğ¼ğ‘‘, so it is also an orthogonal matrix.
From the proof of Lemma 1 in the supplementary material of Deligiannidis et al. (2019), we can write the transition
probability bğ‘„of BPS as following for arbitrary measurable sets ğ´âŠ‚Î˜andğµâŠ‚Sğ‘‘âˆ’1:
bğ‘„((ğœƒ,ğ‘£),ğ´Ã—ğµ)=âˆ«âˆ
0exp
âˆ’âˆ«ğ‘ 
0 Â¯ğœ†(ğœƒ+ğ‘¢ğ‘£,ğ‘£)+ğ¶ğµğ‘‘ğ‘¢
Ã— Â¯ğœ†(ğœƒ+ğ‘¢ğ‘£,ğ‘£)+ğ¶ğµğ¾((ğœƒ+ğ‘ ğ‘£,ğ‘£),ğ´Ã—ğµ)ğ‘‘ğ‘ , (15)
where a transition kernel ğ¾is expressed as
ğ¾((ğœƒ,ğ‘£),ğ´Ã—ğµ)=ğœ†(ğœƒ,ğ‘£)+ğ¶ğµ
Â¯ğœ†(ğœƒ,ğ‘£)+ğ¶ğµ1[ğœƒâˆˆğ´] 1[ğ‘…z(ğœƒ)ğ‘£âˆˆğµ] (16)
+Î›ref
Â¯ğœ†(ğœƒ,ğ‘£)+ğ¶ğµ1[ğœƒâˆˆğ´]ğœ‡unif(ğµ),
whereğœ‡unifis the uniform probability measure on Sğ‘‘âˆ’1.
Lemma 9. Under Assumption 1, a probability measure on Î˜Ã—Sğ‘‘âˆ’1
bğœ‡z(ğ´Ã—ğµ)âˆâˆ«
ğ´Ã—ğµ Â¯ğœ†(ğœƒ,âˆ’ğ‘£)+ğ¶ğµexp(âˆ’ğ›½ğ¿ z(ğœƒ))ğ‘‘ğœƒğœ‡ unif(ğ‘‘ğ‘£)
is the stationary distribution induced from the transition probability bğ‘„as(15).
Proof.Our proof is almost the same as the proof of Lemma 1 in Deligiannidis et al. (2019). Let ğœ‹z(ğ‘‘ğœƒ,ğ‘‘ğ‘£)=
exp(âˆ’ğ›½ğ¿z(ğœƒ))ğ‘‘ğœƒğœ‡ unif(ğ‘‘ğ‘£).
First, we proveâˆ«
(Â¯ğœ†(ğœƒ,ğ‘£)+ğ¶ğµ)ğœ‹z(ğ‘‘ğœƒ,ğ‘‘ğ‘£)ğ¾((ğœƒ,ğ‘£),ğ´Ã—ğµ)âˆbğœ‡z(ğ´Ã—ğµ). (17)
Substituting (16), the left side of (17) is rewritten as
âˆ«
ğœ‹z(ğ‘‘ğœƒ,ğ‘‘ğ‘£)(ğœ†(ğœƒ,ğ‘£)+ğ¶ğµ) 1[ğœƒâˆˆğ´] 1[ğ‘…z(ğœƒ)ğ‘£âˆˆğµ]+âˆ«
ğœ‹z(ğ‘‘ğœƒ,ğ‘‘ğ‘£)Î›ref 1[ğœƒâˆˆğ´]ğœ‡unif(ğµ).
17Under review as submission to TMLR
Weconsiderchangingthevariableas ğ‘£â€²=ğ‘…z(ğœƒ)ğ‘£. Sinceğ‘…z(ğœƒ)âˆ’1=ğ‘…z(ğœƒ)holds,weget ğœ†(ğœƒ,ğ‘…z(ğœƒ)âˆ’1ğ‘£â€²)=ğœ†(ğœƒ,âˆ’ğ‘£â€²).
In addition, since|det(ğ‘…z(ğœƒ))|=1, andğœ‡unif(ğ‘…z(ğœƒ)âˆ’1ğ‘‘ğ‘£â€²)=ğœ‡unif(ğ‘‘ğ‘£â€²)hold due to the rotational invariance of ğœ‡unif,
we obtain âˆ«
ğ´Ã—ğµğœ‹z(ğ‘‘ğœƒ,ğ‘‘ğ‘£â€²)(ğœ†(ğœƒ,âˆ’ğ‘£â€²)+ğ¶ğµ)+âˆ«
ğ´Ã—ğµğœ‹z(ğ‘‘ğœƒ,ğ‘‘ğ‘£â€²)Î›ref,
which is proportional to the right side of (17) from the definition of bğœ‡z.
Second, we proveâˆ«bğ‘„((ğœƒ,ğ‘£),(ğ‘‘ğ‘¦,ğ‘‘ğ‘¤))bğœ‡z(ğ‘‘ğœƒ,ğ‘‘ğ‘£)=bğœ‡z(ğ‘‘ğ‘¦,ğ‘‘ğ‘¤). We have
âˆ«
bğ‘„((ğœƒ,ğ‘£),(ğ‘‘ğ‘¦,ğ‘‘ğ‘¤))bğœ‡z(ğ‘‘ğœƒ,ğ‘‘ğ‘£)
âˆâˆ«âˆ
0exp
âˆ’âˆ«ğ‘ 
0{Â¯ğœ†(ğœƒ+ğ‘¢ğ‘£,ğ‘£)+ğ¶ğµ}ğ‘‘ğ‘¢
{Â¯ğœ†(ğœƒ+ğ‘ ğ‘£,ğ‘£)+ğ¶ğµ}
Ã—ğ¾((ğœƒ+ğ‘ ğ‘£,ğ‘£),(ğ‘‘ğ‘¦,ğ‘‘ğ‘¤)){Â¯ğœ†(ğœƒ,âˆ’ğ‘£)+ğ¶ğµ}ğœ‹z(ğ‘‘ğœƒ,ğ‘‘ğ‘£)ğ‘‘ğ‘ .
If we change ğœƒasğ‘¡=ğœƒ+ğ‘ ğ‘£, then this integral becomes
âˆ«âˆ
0exp
âˆ’âˆ«ğ‘ 
0{Â¯ğœ†(ğ‘¡+(ğ‘¢âˆ’ğ‘ )ğ‘£,ğ‘£)+ğ¶ğµ}ğ‘‘ğ‘¢
{Â¯ğœ†(ğ‘¡,ğ‘£)+ğ¶ğµ}
Ã—ğ¾((ğ‘¡,ğ‘£),(ğ‘‘ğ‘¦,ğ‘‘ğ‘¤)){Â¯ğœ†(ğ‘¡âˆ’ğ‘ ğ‘£,âˆ’ğ‘£)+ğ¶ğµ}ğœ‹z(ğ‘‘ğœƒ,ğ‘‘ğ‘£)ğ‘‘ğ‘ .
Sinceğ¿z(ğœƒ)is absolutely continuous,
exp(âˆ’ğ›½ğ¿z(ğ‘¡âˆ’ğ‘ ğ‘£))=exp
âˆ’ğ›½ğ¿z(ğ‘¡)âˆ’âˆ«ğ‘ 
0ğœ†(ğ‘¡âˆ’ğ‘¤ğ‘£,âˆ’ğ‘£)ğ‘‘ğ‘¤+âˆ«ğ‘ 
0ğœ†(ğ‘¡âˆ’ğ‘¤ğ‘£,ğ‘£)ğ‘‘ğ‘¤
holds in the same way as Deligiannidis et al. (2019). Substituting it into ğœ‹z(ğ‘‘ğ‘¥,ğ‘‘ğ‘£)and changing ğ‘¢asğ‘¢âˆ’ğ‘ =âˆ’ğ‘¤,
âˆ«âˆ
0exp
âˆ’âˆ«ğ‘ 
0{Â¯ğœ†(ğ‘¡âˆ’ğ‘¤ğ‘£,âˆ’ğ‘£)+ğ¶ğµ}ğ‘‘ğ‘¤
{Â¯ğœ†(ğ‘¡âˆ’ğ‘ ğ‘£,âˆ’ğ‘£)+ğ¶ğµ}ğ‘‘ğ‘ 
Ã—{Â¯ğœ†(ğ‘¡,ğ‘£)+ğ¶ğµ}ğ¾((ğ‘¡,ğ‘£),(ğ‘‘ğ‘¦,ğ‘‘ğ‘¤))ğœ‹z(ğ‘‘ğ‘¡,ğ‘‘ğ‘£)
holds. The first line can be calculated ash
âˆ’exp
âˆ’âˆ«ğ‘ 
0{Â¯ğœ†(ğ‘¡âˆ’ğ‘¤ğ‘£,âˆ’ğ‘£)+ğ¶ğµ}ğ‘‘ğ‘¤iâˆ
0=1, so it is equal to
âˆ«
{Â¯ğœ†(ğ‘¡,ğ‘£)+ğ¶ğµ}ğ¾((ğ‘¡,ğ‘£),(ğ‘‘ğ‘¦,ğ‘‘ğ‘¤))ğœ‹z(ğ‘‘ğ‘¡,ğ‘‘ğ‘£).
Using (17), it is proportional to bğœ‡z(ğ‘‘ğ‘¦,ğ‘‘ğ‘¤), which completes the proof. â–¡
Bythefollowingproposition,weprovethat ğœ‡(ğ›½,ğœ€)
zisoneofthestationarydistributionsofBPS.Recallthatwedefined
ğ‘ğ‘‘:=Î“(ğ‘‘/2)/(âˆšğœ‹Î“(ğ‘‘/2+1/2)).
Proposition 10. The marginal distribution of the stationary distribution expressed in Lemma 9 is written as
bğœ‡z(ğ‘‘ğœƒ)âˆ(Î›ref+ğ¶ğµ+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥)exp(âˆ’ğ›½ğ¿ z(ğœƒ))ğ‘‘ğœƒ.
Hence, if we put Î›refandğ¶ğµasÎ›ref+ğ¶ğµ=ğ›½ğ‘€â„“+1/ğœ€, it corresponds to ğœ‡(ğ›½,ğœ€)
z.
Proof.We only need to integrate with ğ‘£the distribution bğœ‡zexpressed in Lemma 9. We have
bğœ‡z(ğ‘‘ğœƒ)âˆâˆ«
ğ‘£âˆˆSğ‘‘âˆ’1(Î›ref+ğ¶ğµ+ğ›½âŸ¨âˆ‡ğ¿z(ğœƒ),âˆ’ğ‘£âŸ©+)exp(âˆ’ğ›½ğ¿z(ğœƒ))ğ‘‘ğœƒğœ‡ unif(ğ‘‘ğ‘£)
=(Î›ref+ğ¶ğµ)exp(âˆ’ğ›½ğ¿z(ğœƒ))ğ‘‘ğœƒ+exp(âˆ’ğ›½ğ¿z(ğœƒ))ğ‘‘ğœƒğ›½Eğ‘£âˆ¼ğœ‡unif[âŸ¨âˆ‡ğ¿z(ğœƒ),ğ‘£âŸ©+].
18Under review as submission to TMLR
We can calculate the expected value in the last term as
Eğ‘£âˆ¼ğœ‡unif[âŸ¨âˆ‡ğ¿z(ğœƒ),ğ‘£âŸ©+]=Eğ‘£âˆ¼ğœ‡unif[âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥(cosğœ™)+]=âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥Eğ‘£âˆ¼ğœ‡unif[(cosğœ™)+],
whereğœ™âˆˆRis a random variable dependent on ğ‘£which satisfies
cosğœ™=âˆ‡ğ¿z(ğœƒ)
âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥,ğ‘£
. (18)
From the symmetry of the uniform distribution, we can calculate Eğ‘£âˆ¼ğœ‡unif[(cosğœ™)+]by replacingâˆ‡ğ¿z(ğœƒ)
âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥in (18) by
(1,0,Â·Â·Â·,0). Hence,
Eğ‘£âˆ¼ğœ‡unif[(cosğœ™)+]=Eğ‘£âˆ¼ğœ‡unif[(ğ‘£1)+]=Eï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°Â©Â­Â­
Â«ğ‘¥1âˆšï¸ƒ
ğ‘¥2
1+Â·Â·Â·+ğ‘¥2
ğ‘‘ÂªÂ®Â®
Â¬+ï£¹ï£ºï£ºï£ºï£ºï£ºï£»
holds, where ğ‘£1is the first component of ğ‘£andğ‘¥ğ‘–(ğ‘–=1,...,ğ‘‘)isi.i.d.standard Gaussian variables.
For(ğ‘¥1,...,ğ‘¥ğ‘‘)âˆ¼N( 0,ğ¼ğ‘‘), we have
Eï£®ï£¯ï£¯ï£¯ï£¯ï£°vt
ğ‘¥2
1
ğ‘¥2
1+Â·Â·Â·+ğ‘¥2
ğ‘‘ï£¹ï£ºï£ºï£ºï£ºï£»=âˆ«
Rğ‘‘vt
ğ‘§2
1
ğ‘§2
1+Â·Â·Â·+ğ‘§2
ğ‘‘1
(2ğœ‹)ğ‘‘/2exp 
âˆ’ğ‘§2
1+Â·Â·Â·+ğ‘§2
ğ‘‘
2!
ğ‘‘ğ‘§1Â·Â·Â·ğ‘‘ğ‘§ğ‘‘
=âˆ«
[0,âˆ)2âˆšï¸‚ğ‘Ÿ
ğ‘Ÿ+ğ‘ ğ‘Ÿâˆ’1/2exp(âˆ’ğ‘Ÿ/2)âˆš
2ğœ‹ğ‘ (ğ‘‘âˆ’1)/2âˆ’1exp(âˆ’ğ‘ /2)
Î“((ğ‘‘âˆ’1)/2)2(ğ‘‘âˆ’1)/2ğ‘‘ğ‘Ÿğ‘‘ğ‘ 
=âˆ«
[0,1]ğ‘¡1/2ğ‘¡1/2âˆ’1(1âˆ’ğ‘¡)(ğ‘‘âˆ’1)/2âˆ’1
B(1/2,(ğ‘‘âˆ’1)/2)ğ‘‘ğ‘¡
=B(1,(ğ‘‘âˆ’1)/2)
B(1/2,(ğ‘‘âˆ’1)/2)
=Î“(1)Î“((ğ‘‘âˆ’1)/2)Î“(ğ‘‘/2)
Î“(1/2)Î“((ğ‘‘âˆ’1)/2)Î“(ğ‘‘/2+1/2)
=Î“(ğ‘‘/2)âˆšğœ‹Î“(ğ‘‘/2+1/2).
Note that for all ğ‘‘â‰¥2,
1âˆšï¸
ğ‘‘/2â‰¤Î“(ğ‘‘/2)
Î“(ğ‘‘/2+1/2)â‰¤1âˆšï¸
ğ‘‘/2âˆ’1/2
holds (e.g., see Qi & Luo (2013)). Therefore, for all ğ‘‘â‰¥2, we have
Eï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°Â©Â­Â­
Â«ğ‘¥1âˆšï¸ƒ
ğ‘¥2
1+Â·Â·Â·+ğ‘¥2
ğ‘‘ÂªÂ®Â®
Â¬+ï£¹ï£ºï£ºï£ºï£ºï£ºï£»=Î“(ğ‘‘/2)
2âˆšğœ‹Î“(ğ‘‘/2+1/2)âˆˆ"
1âˆš
2ğœ‹ğ‘‘,1âˆšï¸
2ğœ‹(ğ‘‘âˆ’1)#
.
â–¡
D.2 The exponential ergodicity of BPS
The next proposition is on the minorization condition of the 2-skeletons of BPS on the restricted domains. In short,
minorizationmeansthatthestochasticprocesscangofromanymeasurablesettoanymeasurablesetintheparameter
space,whichisasufficientconditionfortheexponentialergodicityinthecompactparameterspace. 2-Skeletonmeans
2 step of the stochastic process. This proposition completes the proof of Theorem 4.
19Under review as submission to TMLR
Proposition 11. Under Assumption 1, the 2-skeletons of BPS satisfies the minorization condition; that is, for some
ğ‘>0, for all(ğœƒ,ğ‘£)âˆˆÎ˜Ã—Sğ‘‘âˆ’1and all measurable ğ¸âŠ‚Î˜Ã—Sğ‘‘âˆ’1, we have
bğ‘„2((ğœƒ,ğ‘£),ğ¸)â‰¥ğ‘âˆ«
Î˜âˆ«
Sğ‘‘âˆ’11[(ğœƒ,ğ‘£)âˆˆğ¸]ğ‘‘ğœƒğœ‡ unif(ğ‘‘ğ‘£).
Moreover, BPS is exponentially ergodic in total variation distance.
Proof.We partially follow the proof of Lemma 4 in Deligiannidis et al. (2019).
Letğ‘“:Î˜Ã—Sğ‘‘âˆ’1â†’ [ 0,âˆ)be a non-negative and bounded function. We also use the notation ğ‘€â€²=
sup(ğœƒ,ğ‘£)âˆˆÎ˜Ã—Sğ‘‘âˆ’1(Â¯ğœ†(ğœƒ,ğ‘£)+ğ¶ğµ)<âˆ. By considering the event where the first update of ğ‘£isrefreshment from
Unif(Sğ‘‘âˆ’1), we see that for any (ğœƒ0,ğ‘£0)âˆˆÎ˜Ã—Sğ‘‘âˆ’1,
âˆ«
Î˜Ã—Sğ‘‘âˆ’1ğ‘“(ğœƒ,ğ‘£)bğ‘„2((ğœƒ0,ğ‘£0),(ğ‘‘ğœƒ,ğ‘‘ğ‘£))
=âˆ«
Î˜Ã—Sğ‘‘âˆ’1âˆ«
Î˜Ã—Sğ‘‘âˆ’1ğ‘“(ğœƒ,ğ‘£)bğ‘„((ğœƒ1,ğ‘£1),(ğ‘‘ğœƒ,ğ‘‘ğ‘£))bğ‘„((ğœƒ0,ğ‘£0),(ğ‘‘ğœƒ1,ğ‘‘ğ‘£ 1))
â‰¥Î›ref
ğ‘€â€²inf
ğœƒ1âˆˆÎ˜âˆ«
Î˜Ã—Sğ‘‘âˆ’1ğ‘“(ğœƒ,ğ‘£)bğ‘„((ğœƒ1,ğ‘£1),(ğ‘‘ğœƒ,ğ‘‘ğ‘£))ğœ‡unif(ğ‘‘ğ‘£1)
holds. We also obtain that for ğ‘‡âˆ¼Exp(ğ‘€â€²),ğ‘‰1,ğ‘‰2âˆ¼i.i.d.Unif(Sğ‘‘âˆ’1), we have
inf
ğœƒ1âˆˆÎ˜âˆ«
Î˜Ã—Sğ‘‘âˆ’1ğ‘“(ğœƒ,ğ‘£)bğ‘„((ğœƒ1,ğ‘£1),ğ‘‘ğœƒğ‘‘ğ‘£)ğœ‡unif(ğ‘‘ğ‘£1)
â‰¥inf
ğœƒ1âˆˆÎ˜Î›ref
ğ‘€â€²E[ 1[ğœƒ1+ğ‘‡ğ‘‰1âˆˆÎ˜]ğ‘“(ğœƒ1+ğ‘‡ğ‘‰1,ğ‘‰2)]
â‰¥inf
ğœƒ1âˆˆÎ˜Î›2
ref
ğ‘€â€²âˆ«
[0,âˆ)Ã—Sğ‘‘âˆ’11[ğœƒ1+ğ‘¡ğ‘£1âˆˆÎ˜]ğ‘’âˆ’ğ‘€â€²ğ‘¡ğ‘“(ğœƒ1+ğ‘¡ğ‘£1,ğ‘£)ğ‘‘ğ‘¡ğœ‡ unif(ğ‘‘ğ‘£1)ğœ‡unif(ğ‘‘ğ‘£)
â‰¥inf
ğœƒ1âˆˆÎ˜Î›2
refğ‘’âˆ’ğ‘€â€²diam(Î˜)
ğ‘€â€²âˆ«
[0,âˆ)Ã—Sğ‘‘âˆ’11[ğœƒ1+ğ‘¡ğ‘£1âˆˆÎ˜]ğ‘“(ğœƒ1+ğ‘¡ğ‘£1,ğ‘£)ğ‘‘ğ‘¡ğœ‡ unif(ğ‘‘ğ‘£1)ğœ‡unif(ğ‘‘ğ‘£)
=inf
ğœƒ1âˆˆÎ˜Î›2
refğ‘’âˆ’ğ‘€â€²diam(Î˜)
ğ‘€â€²âˆ«
Î˜Ã—Sğ‘‘âˆ’11[ğœƒâˆˆÎ˜]ğ‘“(ğœƒ,ğ‘£)âˆ¥ğœƒâˆ’ğœƒ1âˆ¥1âˆ’ğ‘‘ğ‘‘ğœƒğœ‡ unif(ğ‘‘ğ‘£)
â‰¥Î›2
refğ‘’âˆ’ğ‘€â€²diam(Î˜)
ğ‘€â€²diam(Î˜)ğ‘‘âˆ’1âˆ«
Î˜Ã—Sğ‘‘âˆ’1ğ‘“(ğœƒ,ğ‘£)ğ‘‘ğœƒğœ‡ unif(ğ‘‘ğ‘£),
where the second last equality uses a change of coordinates. Since ğ‘“is generic, the minorization condition holds.
Harrisâ€™s theorem thus gives the exponential ergodicity of BPS. â–¡
E Proof of Theorem 5
Proof.We prove in the same way as the proof of Theorem 2.1 in Raginsky et al. (2017). Let ğœƒğœ‡be a random variable
satisfyingğœƒğœ‡âˆ¼ğœ‡(ğ›½,ğœ€)
z,whereğœ‡(ğ›½,ğœ€)
zisdefinedin(7). Wedenote ğœƒğ¾âˆ¼ğœ‡z,ğ¾astheoutputofPoissonSGD(Algorithm
1). We have
Ez[Eğœƒğ¾[ğ¿(ğœƒğ¾)]]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿(ğœƒ)
=Ez[Eğœƒğ¾[ğ¿(ğœƒğ¾)]âˆ’Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]]+{ Ez[Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿(ğœƒ)},
and the second term of right-hand side is written as
Ez[Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿(ğœƒ)
20Under review as submission to TMLR
=Ez[Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]]âˆ’Ez[Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]]+
Ez[Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿(ğœƒ)
.
Lettingğœƒâ—¦=argminğœƒâˆˆÎ˜ğ¿(ğœƒ), the second part of the right-hand side in the equation above is
Ez[Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿(ğœƒ)=Ez[Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿z(ğœƒ)]+
Ez
inf
ğœƒâˆˆÎ˜ğ¿z(ğœƒ)âˆ’ğ¿z(ğœƒâ—¦)
â‰¤Ez[Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿z(ğœƒ)].
As a result, we have
Ez[Eğœƒğ¾[ğ¿(ğœƒğ¾)]]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿(ğœƒ)â‰¤Ez[Eğœƒğ¾[ğ¿(ğœƒğ¾)]âˆ’Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]] (19)
+Ez[Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]âˆ’Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]] (20)
+Ez[Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿z(ğœƒ)]. (21)
Toevaluatetheterms(19),(20),and(21),wepreparethefollowinglemmatocalculatetheupperboundofthedifference
between two expected value by the Wasserstein distance.
Lemma12. Considerprobabilitymeasures ğœ‡andğœˆonÎ˜. Supposethat supğ‘§âˆˆZ|â„“(ğ‘§; 0)|â‰¤ğ´andsupğ‘§âˆˆZâˆ¥âˆ‡â„“(ğ‘§; 0)âˆ¥â‰¤
ğµhold. Then, we obtain
Eğœƒ1âˆ¼ğœ‡[â„“(ğ‘§;ğœƒ1)]âˆ’Eğœƒ2âˆ¼ğœˆ[â„“(ğ‘§;ğœƒ2)]â‰¤(ğ‘1ğ‘Š+ğµ)âˆšï¸
ğ‘ŠW1(ğœ‡,ğœˆ),and (22)
Eğœƒ1âˆ¼ğœ‡[ğ¿(ğœƒ1)]âˆ’Eğœƒ2âˆ¼ğœˆ[ğ¿(ğœƒ2)]â‰¤(ğ‘1ğ‘Š+ğµ)âˆšï¸
ğ‘ŠW1(ğœ‡,ğœˆ). (23)
Proof.Under the assumption, Lemma 3.1 in Raginsky et al. (2017) holds. Hence, we have
âˆ¥âˆ‡â„“(ğ‘§;ğœƒ)âˆ¥â‰¤ğ‘1âˆ¥ğœƒâˆ¥+ğµ,âˆ€ğœƒâˆˆÎ˜,âˆ€ğ‘§âˆˆZ (24)
â„“(ğ‘§;ğœƒ)â‰¤ğ‘1
2âˆ¥ğœƒâˆ¥2+ğµâˆ¥ğœƒâˆ¥+ğ´,âˆ€ğœƒâˆˆÎ˜,âˆ€ğ‘§âˆˆZ. (25)
Moreover, from Lemma 3.5 in Raginsky et al. (2017), for arbitrary two probability measures ğœ‡andğœˆ, if we let
ğœ2=max{Eğœƒ1âˆ¼ğœ‡[âˆ¥ğœƒ1âˆ¥2],Eğœƒ2âˆ¼ğœˆ[âˆ¥ğœƒ2âˆ¥2]},
then we haveEğœƒ1âˆ¼ğœ‡[â„“(ğ‘§;ğœƒ1)]âˆ’Eğœƒ2âˆ¼ğœˆ[â„“(ğ‘§;ğœƒ2)]â‰¤(ğ‘1ğœ+ğµ)W 2(ğœ‡,ğœˆ).
Obviously, it also holds that
Eğœƒ1âˆ¼ğœ‡[ğ¿(ğœƒ1)]âˆ’Eğœƒ2âˆ¼ğœˆ[ğ¿(ğœƒ2)]â‰¤(ğ‘1ğœ+ğµ)W 2(ğœ‡,ğœˆ).
Since we have ğœâ‰¤ğ‘ŠandW2(ğœ‡,ğœˆ)=infğœ‹âˆˆÎ (ğœ‡,ğœˆ)(âˆ«
Î˜âˆ¥ğ‘§âˆ’ğ‘§â€²âˆ¥2ğ‘‘ğœ‹(ğ‘§,ğ‘§â€²))1/2â‰¤infğœ‹âˆˆÎ (ğœ‡,ğœˆ)(âˆ«
Î˜ğ‘Šâˆ¥ğ‘§âˆ’
ğ‘§â€²âˆ¥1ğ‘‘ğœ‹(ğ‘§,ğ‘§â€²))1/2=âˆšï¸
ğ‘ŠW1(ğœ‡,ğœˆ), we obtain the statement. â–¡
We start evaluating each of the terms (19), (20), and (21).
First, we study (19). From (23) in Lemma 12, we have
Eğœƒğ¾[ğ¿(ğœƒğ¾)]âˆ’Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]â‰¤(ğ‘1ğ‘Š+ğµ)âˆšï¸ƒ
ğ‘ŠW1(ğœ‡z,ğ¾,ğœ‡(ğ›½,ğœ€)
z)
â‰¤(ğ‘1ğ‘Š+ğµ)âˆšï¸
ğ‘Šğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘). (26)
Second, we evaluate (20) using the same approach as Raginsky et al. (2017). Here, we need to evaluate
Eğœƒğœ‡[â„“(ğ‘§;ğœƒğœ‡)]âˆ’Eğœƒğœ‡â€²[â„“(ğ‘§;ğœƒğœ‡â€²)],
21Under review as submission to TMLR
whereğ‘§âˆˆZis an arbitrary sampled data, ğœƒğœ‡â€²âˆ¼ğœ‡(ğ›½,ğœ€)
zâ€²andğœ‡(ğ›½,ğœ€)
zâ€²is the stationary distribution of BPS when one
of the datağ‘§ğ‘–is changed to arbitrary Â¯ğ‘§ğ‘–âˆˆZandzâ€²is a dataset with replacing ğ‘§ğ‘–toÂ¯ğ‘§ğ‘–, andğ¿zâ€²be its corresponding
empirical risk. From (22) in Lemma 12, we have
Eğœƒğœ‡[â„“(ğ‘§;ğœƒğœ‡)]âˆ’Eğœƒğœ‡â€²[â„“(ğ‘§;ğœƒğœ‡â€²)]â‰¤(ğ‘1ğ‘Š+ğµ)W 2(ğœ‡(ğ›½,ğœ€)
z,ğœ‡(ğ›½,ğœ€)
zâ€²)
â‰¤(ğ‘1ğ‘Š+ğµ)ğ¶ğœ‡â€²ï£®ï£¯ï£¯ï£¯ï£¯ï£°âˆšï¸ƒ
ğ·(ğœ‡(ğ›½,ğœ€)
z||ğœ‡(ğ›½,ğœ€)
zâ€²)+ 
ğ·(ğœ‡(ğ›½,ğœ€)
z||ğœ‡(ğ›½,ğœ€)
zâ€²)
2!1
4ï£¹ï£ºï£ºï£ºï£ºï£»,
whereğ·(Â·||Â·)is KL-divergence and
ğ¶ğœ‡â€²:=2 inf
ğœ†>01
ğœ†3
2+logâˆ«
Î˜ğ‘’ğœ†âˆ¥ğœƒâˆ¥2ğœ‡(ğ›½,ğœ€)
zâ€²(ğ‘‘ğœƒ) 1
2
,
which is from Corollary 2.3 in Bolley & Villani (2005) (explicit form is Theorem 14 in Section H). Also, since we
haveâˆ¥ğœƒâˆ¥â‰¤ğ‘Š,ğ¶ğœ‡â€²â‰¤2ğ‘Šholds. We denote the density functions of ğœ‡(ğ›½,ğœ€)
z,ğœ‡(ğ›½,ğœ€)
zâ€²asğ‘z,ğ‘zâ€², and the normalization
constants asÎ›z,Î›zâ€²respectively. Let us calculate ğ·(ğœ‡(ğ›½,ğœ€)
z||ğœ‡(ğ›½,ğœ€)
zâ€²). We have
ğ‘z(ğœƒ)
ğ‘zâ€²(ğœƒ)=Î›zâ€²
Î›zÂ·ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥
ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿zâ€²(ğœƒ)âˆ¥exp(âˆ’ğ›½(ğ¿z(ğœƒ)âˆ’ğ¿zâ€²(ğœƒ))), (27)
so inorder toobtain theupper boundof ğ·(ğœ‡(ğ›½,ğœ€)
z||ğœ‡(ğ›½,ğœ€)
zâ€²), wesuppress eachof thethree termsof theright-hand side
of (27). First, we suppress the second term.
âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥=âˆ‡ğ¿zâ€²(ğœƒ)+1
ğ‘›(âˆ‡â„“(ğ‘§ğ‘–;ğœƒ)âˆ’âˆ‡â„“(Â¯ğ‘§ğ‘–;ğœƒ)
â‰¤âˆ¥âˆ‡ğ¿zâ€²(ğœƒ)âˆ¥+1
ğ‘›âˆ¥âˆ‡â„“(ğ‘§ğ‘–;ğœƒ)âˆ’âˆ‡â„“(Â¯ğ‘§ğ‘–;ğœƒ)âˆ¥
â‰¤âˆ¥âˆ‡ğ¿zâ€²(ğœƒ)âˆ¥+2
ğ‘›(ğ‘1âˆ¥ğœƒâˆ¥+ğµ),
where the last inequality is from (24). Hence,
ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥
ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿zâ€²(ğœƒ)âˆ¥â‰¤ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½
âˆ¥âˆ‡ğ¿zâ€²(ğœƒ)âˆ¥+2
ğ‘›(ğ‘1âˆ¥ğœƒâˆ¥+ğµ)
ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿zâ€²(ğœƒ)âˆ¥
â‰¤1+2ğ‘ğ‘‘ğ›½(ğ‘1ğ‘Š+ğµ)
ğ‘›(ğ›½ğ‘€â„“+1/ğœ€)
â‰¤1+2ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘›ğ‘€â„“(28)
holds. Second, we suppress the third term. We have
exp(âˆ’ğ›½(ğ¿z(ğœƒ)âˆ’ğ¿zâ€²(ğœƒ)))=exp
âˆ’ğ›½1
ğ‘›(â„“(ğ‘§ğ‘–;ğœƒ)âˆ’â„“(Â¯ğ‘§ğ‘–;ğœƒ))
â‰¤expğ›½
ğ‘›ğ‘1âˆ¥ğœƒâˆ¥2
2+ğµâˆ¥ğœƒâˆ¥+ğ´
â‰¤expğ›½
ğ‘›ğ‘1ğ‘Š2
2+ğµğ‘Š+ğ´
, (29)
where we use (25). Finally, we suppress the first term. Using (28) and (29), we have
Î›zâ€²
Î›z=âˆ«
ğœƒâˆˆÎ˜(ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿zâ€²(ğœƒ)âˆ¥)exp(âˆ’ğ›½ğ¿zâ€²(ğœƒ))ğ‘‘ğœƒ
âˆ«
ğœƒâˆˆÎ˜(ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿ğ‘§(ğœƒ)âˆ¥)exp(âˆ’ğ›½ğ¿ğ‘§(ğœƒ))ğ‘‘ğœƒ
22Under review as submission to TMLR
â‰¤
1+2ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘›ğ‘€â„“
expğ›½
ğ‘›ğ‘1ğ‘Š2
2+ğµğ‘Š+ğ´
. (30)
Combining (28), (29) and (30), we have
logğ‘z(ğœƒ)
ğ‘zâ€²(ğœƒ)â‰¤2 log
1+2ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘›ğ‘€â„“
+2ğ›½
ğ‘›ğ‘1ğ‘Š2
2+ğµğ‘Š+ğ´
â‰¤1
ğ‘›4ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘€â„“+ğ›½(ğ‘1ğ‘Š2+2ğµğ‘Š+2ğ´)
,
so
ğ·(ğœ‡(ğ›½,ğœ€)
z||ğœ‡(ğ›½,ğœ€)
zâ€²)â‰¤1
ğ‘›4ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘€â„“+ğ›½(ğ‘1ğ‘Š2+2ğµğ‘Š+2ğ´)
holds. We set ğ¶ğ‘‘=4ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)/ğ‘€â„“andğ¶=ğ‘1ğ‘Š2+2ğµğ‘Š+2ğ´, then we have
(20)â‰¤2ğ‘Š(ğ‘1ğ‘Š+ğµ) ğ¶ğ‘‘+ğ›½ğ¶
ğ‘›1
2
+ğ¶ğ‘‘+ğ›½ğ¶
ğ‘›1
4!
. (31)
Finally, we evaluate (21). Let us denote
Î›z(ğœƒ)=Î›
ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥
Î›=âˆ«
ğœƒâˆˆÎ˜(ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥)ğ‘’âˆ’ğ›½ğ¿z(ğœƒ)ğ‘‘ğœƒ.
Since the distribution of ğœƒğœ‡is
ğœ‡(ğ›½,ğœ€)
z(ğ‘‘ğœƒ)âˆ
ğ›½ğ‘€â„“+1
ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥
exp(âˆ’ğ›½ğ¿z(ğœƒ)),
we have
Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]=âˆ’1
ğ›½
Eğœƒğœ‡
logğ‘’âˆ’ğ›½ğ¿z(ğœƒğœ‡)
Î›z(ğœƒğœ‡)
+Eğœƒğœ‡[logÎ›z(ğœƒğœ‡)]
=1
ğ›½
Eğœƒğœ‡[âˆ’logğ‘z(ğœƒğœ‡)]âˆ’Eğœƒğœ‡[logÎ›z(ğœƒğœ‡)]
.
Since we have Eğœƒğœ‡[âˆ¥ğœƒğœ‡âˆ¥2]â‰¤ğ‘Š2, we can calculate the upper bound of Eğœƒğœ‡[âˆ’logğ‘z(ğœƒğœ‡)]by the differential entropy
of Gaussian distribution in the same way as the discussion of Section 3.5 in Raginsky et al. (2017):
Eğœƒğœ‡[âˆ’logğ‘z(ğœƒğœ‡)]â‰¤ğ‘‘
2log2ğœ‹ğ‘’
ğ‘‘ğ‘Š2
.
Using (24), we have
logÎ›z(ğœƒ)â‰¥logÎ›
ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½(ğ‘1ğ‘Š+ğµ)).
In addition,
logÎ›=logâˆ«
ğœƒâˆˆÎ˜(ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥)ğ‘’âˆ’ğ›½ğ¿z(ğœƒ)ğ‘‘ğœƒ
â‰¥logâˆ«
ğœƒâˆˆÎ˜(ğ›½ğ‘€â„“+1/ğœ€)ğ‘’âˆ’ğ›½ğ¿z(ğœƒ)ğ‘‘ğœƒ
=log(ğ›½ğ‘€â„“+1/ğœ€)+logâˆ«
ğœƒâˆˆÎ˜ğ‘’âˆ’ğ›½ğ¿z(ğœƒ)ğ‘‘ğœƒ
23Under review as submission to TMLR
â‰¥log(ğ›½ğ‘€â„“+1/ğœ€)âˆ’ğ›½ğ¿âˆ—
z+ğ‘‘
2log2ğœ‹
ğ‘1ğ›½
holds,wherethelastinequalityisfromtheequation(3.21)inRaginskyetal.(2017). Here,wedenote ğ¿âˆ—
z=infğœƒâˆˆÎ˜ğ¿z(ğœƒ).
Hence, we have
(21)â‰¤1
ğ›½ğ‘‘
2log2ğœ‹ğ‘’
ğ‘‘ğ‘Š2
+logğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½(ğ‘1ğ‘Š+ğµ)
ğ›½ğ‘€â„“+1/ğœ€+ğ›½ğ¿âˆ—
zâˆ’ğ‘‘
2log2ğœ‹
ğ‘1ğ›½
âˆ’ğ¿âˆ—
z
â‰¤1
ğ›½ğ‘‘
2logğ‘’ğ‘Š2ğ‘1ğ›½
ğ‘‘+log
1+ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘€â„“
. (32)
We combine the result (26), (31), and (32), then obtain the statement. â–¡
F Proof of Proposition 6
Proof.Letğœƒğœ‡andğœƒğœˆbe the random variable which obey the distributions ğœ‡(ğ›½,ğœ€)
zandğœˆ(ğ›½)
zrespectively.
In the same way as Theorem 5, we have
Eğ‘§[Eğœƒğ¾[ğ¿(ğœƒğ¾)]]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿(ğœƒ)â‰¤Eğ‘§[Eğœƒğ¾[ğ¿(ğœƒğ¾)]âˆ’Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]] (33)
+Eğ‘§[Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]âˆ’Eğœƒğœˆ[ğ¿(ğœƒğœˆ)]] (34)
+Eğ‘§[Eğœƒğœˆ[ğ¿(ğœƒğœˆ)]âˆ’Eğœƒğœˆ[ğ¿z(ğœƒğœˆ)]] (35)
+Eğ‘§[Eğœƒğœˆ[ğ¿z(ğœƒğœˆ)]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿z(ğœƒ)]. (36)
(33) can be evaluated in the same as Theorem 5.
First, we evaluate (34). We have
Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]âˆ’Eğœƒğœˆ[ğ¿(ğœƒğœˆ)]â‰¤ğ‘ŠW2(ğœ‡(ğ›½,ğœ€)
z,ğœˆ(ğ›½)
z)
from the same discussion in the proof of Theorem 5. Since both ğœƒğœ‡andğœƒğœˆsatisfy the log-Sobolev inequality, we can
use Otto-Villani theorem (Bakry et al., 2014) (explicit form is Theorem 15 in Section H), and
W2(ğœ‡(ğ›½,ğœ€)
z,ğœˆ(ğ›½)
z)â‰¤âˆšï¸ƒ
2ğ‘(ğ›½)
LSğ·(ğœ‡(ğ›½,ğœ€)
z||ğœˆ(ğ›½)
z)
holds, where ğ·denotes the KL-divergence and ğ‘(ğ›½)
LSis the log-Sobolev constant of ğœˆ(ğ›½)
z. We have
ğ·(ğœ‡(ğ›½,ğœ€)
z||ğœˆ(ğ›½)
z)=Eğœƒâˆ¼ğœ‡
log(ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥)exp(âˆ’ğ›½ğ¿z(ğœƒ))/Î›ğœ‡
exp(âˆ’ğ›½ğ¿z(ğœƒ))/Î›ğœˆ
â‰¤Eğœƒâˆ¼ğœ‡
log(ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½ğ‘€â„“)Î›ğœˆ
Î›ğœ‡
,
whereÎ›ğœ‡andÎ›ğœˆare normalizing constants of the density functions of ğœ‡(ğ›½,ğœ€)
zandğœˆ(ğ›½)
zrespectively. We have
Î›ğœˆ
Î›ğœ‡=âˆ«
Î˜exp(âˆ’ğ›½ğ¿z(ğœƒ))ğ‘‘ğœƒ
âˆ«
Î˜(ğ›½ğ‘€â„“+1/ğœ€+ğ‘ğ‘‘ğ›½âˆ¥âˆ‡ğ¿z(ğœƒ)âˆ¥)exp(âˆ’ğ›½ğ¿z(ğœƒ))ğ‘‘ğœƒâ‰¤1
ğ›½ğ‘€â„“+1/ğœ€,
hence we have
ğ·(ğœ‡(ğ›½,ğœ€)
z||ğœˆ(ğ›½)
z)â‰¤log(1+ğ‘ğ‘‘ğ›½ğœ€ğ‘€â„“).
As a result, we obtain
Eğœƒğœ‡[ğ¿(ğœƒğœ‡)]âˆ’Eğœƒğœˆ[ğ¿(ğœƒğœˆ)]â‰¤ğ‘Šâˆšï¸ƒ
2ğ‘(ğ›½)
LSlog(1+ğ‘ğ‘‘ğ›½ğœ€ğ‘€â„“). (37)
24Under review as submission to TMLR
Second, we evaluate (35). Let ğœˆ(ğ›½)
zâ€²be the Gibbs distribution when one of the data ğ‘§ğ‘–is replaced by ğ‘§â€²
ğ‘–. In the same
way as Section 3.6 in Raginsky et al. (2017), we have
W2(ğœˆ(ğ›½)
z,ğœˆ(ğ›½)
zâ€²)â‰¤2ğ‘(ğ›½)
LSğ›½ğ‘€â„“
ğ‘›.
Hence, we have
Eğœƒğœˆ[ğ¿(ğœƒğœˆ)]âˆ’Eğœƒğœˆ[ğ¿z(ğœƒğœˆ)]â‰¤(ğ‘1ğ‘Š+ğµ)2ğ‘(ğ›½)
LSğ›½ğ‘€â„“
ğ‘›. (38)
Finally,weevaluate(36). ThistermcanbeevaluatedonthesamewayasProposition3.4inRaginskyetal.(2017)and
we have
Eğœƒğœˆ[ğ¿z(ğœƒğœˆ)]âˆ’ inf
ğœƒâˆˆÎ˜ğ¿z(ğœƒ)â‰¤1
ğ›½ğ‘‘
2log2ğœ‹ğ‘’ğ‘Š2
ğ‘‘
âˆ’ğ‘‘
2log2ğœ‹
ğ‘1ğ›½
=ğ‘‘
2ğ›½logğ‘’ğ‘Š2ğ‘1ğ›½
ğ‘‘
. (39)
We combine the result (37), (38), and (39), then obtain the statement. â–¡
G Proof of Theorem 2
Proof.Letğœƒğ¾,ğœƒğœ‡betherandomvariableswhosedistributionis ğœ‡(ğ›½,ğœ€)
z,ğ¾andğœ‡(ğ›½,ğœ€)
zrespectively. Let ğ¿âˆ—
z=minğœƒâˆˆÎ˜ğ¿z(ğœƒ).
We have
Eğœƒğ¾[ğ¿z(ğœƒğ¾)]âˆ’ğ¿âˆ—
z=(Eğœƒğ¾[ğ¿z(ğœƒğ¾)]âˆ’Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)])+( Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]âˆ’ğ¿âˆ—
z).
As the first term of the right-hand side, we can use the Wasserstein distance in the same way as the proof of Theorem
5 as in (26). Hence, we have
Eğœƒğ¾[ğ¿z(ğœƒğ¾)]âˆ’Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]â‰¤(ğ‘1ğ‘Š+ğµ)âˆšï¸
ğ‘Šğ‘‘ğ¾(ğ›½,ğœ€,ğ‘‘).
Further, using (32) in the Proof of Theorem 5,
Eğœƒğœ‡[ğ¿z(ğœƒğœ‡)]â‰¤1
ğ›½ğ‘‘
2logğ‘’ğ‘Š2ğ‘1ğ›½
ğ‘‘+log
1+ğ‘ğ‘‘(ğ‘1ğ‘Š+ğµ)
ğ‘€â„“
+ğ¿âˆ—
z
holds, which completes the proof. â–¡
H Explicit citation of the existing theorems
Theorem13 (Theorem4,Gibbs&Su(2002)) .Onthecompactset Î©,theWassersteinmetric ğ‘‘ğ‘Šandthetotalvariation
distanceğ‘‘ğ‘‡ğ‘‰satisfy the following relation:
ğ‘‘ğ‘Šâ‰¤diam(Î©)Â·ğ‘‘ğ‘‡ğ‘‰,
where diam(Î©)=sup{ğ‘‘(ğ‘¥,ğ‘¦)|ğ‘¥,ğ‘¦âˆˆÎ©}.
Theorem 14 (Corollary 2.3, Bolley & Villani (2005)) .Letğ‘‹be a measurable space equipped with a measurable
distanceğ‘‘, letğ‘â‰¥1and letğœˆbe a probability measure on ğ‘‹. Assume that there exist ğ‘¥0âˆˆğ‘‹andğ›¼ > 0such thatâˆ«
ğ‘’ğ›¼ğ‘‘(ğ‘¥0,ğ‘¥)ğ‘ğ‘‘ğœˆ(ğ‘¥)is finite. Then,âˆ€ğœ‡âˆˆğ‘ƒ(ğ‘‹),
ğ‘Šğ‘(ğœ‡,ğœˆ)â‰¤ğ¶"
ğ»(ğœ‡|ğœˆ)1
ğ‘+ğ»(ğœ‡|ğœˆ)
21
2ğ‘#
,
where
ğ¶=2 inf
ğ‘¥0âˆˆğ‘‹,ğ›¼> 01
ğ›¼3
2+logâˆ«
ğ‘’ğ›¼ğ‘‘(ğ‘¥0,ğ‘¥)ğ‘ğ‘‘ğœˆ(ğ‘¥) 1
ğ‘
<âˆ.
25Under review as submission to TMLR
Theorem 15 (Theorem 9.6.1, Bakry et al. (2014)) .Letğœ‡be a probability measure on ğ‘€. Ifğœ‡satisfies a logarithmic
Sobolev inequality ğ¿ğ‘†(ğ¶)for some constant ğ¶ > 0, then it satisfies following for every probability measure ğœˆonğ‘€:
W2(ğœ‡,ğœˆ)2â‰¤2ğ¶Â·ğ·(ğœˆ||ğœ‡),
whereW2denotes the Wasserstein-2 distance and ğ·denotes the Kullback-Leibler divergence.
26