Exact Gradients for Stochastic Spiking Neural
Networks Driven by Rough Signals
Christian Holberg
Department of Mathematics
University of Copenhagen
c.holberg@math.ku.dkCristopher Salvi
Department of Mathematics
Imperial College London
c.salvi@imperial.ac.uk
Abstract
We introduce a mathematically rigorous framework based on rough path theory
to model stochastic spiking neural networks (SSNNs) as stochastic differential
equations with event discontinuities (Event SDEs) and driven by c√†dl√†g rough
paths. Our formalism is general enough to allow for potential jumps to be present
both in the solution trajectories as well as in the driving noise. We then identify a
set of sufficient conditions ensuring the existence of pathwise gradients of solution
trajectories and event times with respect to the network‚Äôs parameters and show
how these gradients satisfy a recursive relation. Furthermore, we introduce a
general-purpose loss function defined by means of a new class of signature kernels
indexed on c√†dl√†g rough paths and use it to train SSNNs as generative models.
We provide an end-to-end autodifferentiable solver for Event SDEs and make its
implementation available as part of the diffrax library. Our framework is, to
our knowledge, the first enabling gradient-based training of SSNNs with noise
affecting both the spike timing and the network‚Äôs dynamics.
1 Introduction
Stochastic differential equations exhibiting event discontinuities (Event SDEs) and driven by noise
processes with jumps are an important modelling tool in many areas of science. One of the most
notable examples of such systems is that of stochastic spiking neural networks (SSNNs). Several
models for neuronal dynamics have been proposed in the computational neuroscience literature with
thestochastic leaky integrate-and-fire (SLIF) model being among the most popular choices [ 19,56].
In its simplest form, given some continuous input current iton[0, T], the dynamics of a single SLIF
neuron consist of an Ornstein-Uhlenbeck process describing the membrane potential as well as a
threshold for spike triggering and a resetting mechanism [ 33]. In particular, between spikes, the
dynamics of the membrane potential vtis given by the following SDE
dvt=¬µ(it‚àívt)dt+œÉdB t, (1)
where ¬µ >0is a parameter and Btis a standard Brownian motion. The neuron spikes whenever the
membrane potential vhits the threshold œà >0upon which vis reset to 0. Alternatively, one can
model the spike times as a Poisson process with intensity Œª:R‚ÜíR+depending on the membrane
potential vt. A common choice is Œª(v) = exp(( v‚àíœà)/Œ≤)[50, 26, 27, 24].
A notorious issue for calibrating Event SDEs such as SSNNs is that the implicitly defined event
discontinuities, e.g., the spikes, make it difficult to define derivatives of the solution trajectories and
of the event times with respect to the network‚Äôs parameters using classical calculus rules. This issue
is exacerbated when the dynamics are stochastic in which case the usual argument relying on the
implicit function theorem, used for instance in [6, 25], is no longer valid.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).1.1 Contributions
In this paper, we introduce a mathematically rigorous framework to model SSNNs as SDEs with
event discontinuities and driven by c√†dl√†g rough paths, without any prior knowledge of the timing of
events. The mathematical formalism we adopt is that of rough path theory [38], a modern branch
of stochastic analysis providing a robust solution theory for stochastic dynamical systems driven by
noisy, possibly discontinuous, rough signals . Although Brownian motion is a prototypical example,
these signals can be far more irregular (or rougher) than semimartingales [17, 16, 39].
Equipped with this formalism, we proceed to identify sufficient conditions under which the solution
trajectories and the event times are differentiable with respect to the network‚Äôs parameters and obtain
a recursive relation for the exact pathwise gradients in Theorem 3.2. This is a strict generalization
of the results presented in [ 6] and [ 25] which only deal with ordinary differential equations (ODEs).
Furthermore, we define Marcus signature kernels as extensions of continuous signature kernels [ 52]
to c√†dl√†g rough paths and show their characteristicness. We then make use of this class of kernels
indexed on discontinuous trajectories to define a general-purpose loss function enabling the training
of SSNNs as generative models. We provide an end-to-end autodifferentiable solver for Event SDEs
(Algorithm 1) and make its implementation available as part of the diffrax library [28].
Our framework is, to our knowledge, the first allowing for gradient-based training of a large class of
SSNNs where a noise process can be present in both the spike timing and the network‚Äôs dynamics. In
addition, we believe this work is the first enabling the computation of exact gradients for classical
SNNs whose solutions are approximated via a numerical solver (not necessarily based on a Euler
scheme). In fact, previous solutions are based either on surrogate gradients [ 46] or follow an optimise-
then-discretise approach deriving adjoint equations [ 56], the latter yielding exact gradients only in the
scenario where solutions are available in closed form and not approximated via a numerical solver.1
Finally, we discuss how our results lead to bioplausible learning algorithms akin to e-prop [2].
2 Related work
Neural stochastic differential equations (NSDEs) The intersection between differential equations
and deep learning has become a topic of great interest in recent years. A neural ordinary differential
equation (NODE) is an ODE of the form dyt=fŒ∏(yt)dtstarted at y0‚ààReusing a parametric
Lipschitz vector field fŒ∏:Re‚ÜíRe, usually given by a neural network [ 5]. Similarly, a neural
stochastic differential equation (NSDE) is an SDE of the form dyt=¬µŒ∏(yt)dt+œÉŒ∏(yt)dBtdriven
by a d-dimensional Brownian motion B, started at y0‚ààRe, and with parametric vector field
¬µŒ∏:Re‚ÜíReandœÉŒ∏:Re‚ÜíRe√ódthat are Lip1and Lip2+œµcontinuous respectively2. Rough path
theory offers a way of treating ODEs, SDEs, and more generally differential equations driven by
signals or arbitrary (ir)regularity, under the unified framework of rough differential equations (RDEs)
[44, 22]. For an account on applications of rough path theory to machine learning see [4, 14, 51].
Training techniques for NSDEs Training a NSDE amounts to minimising over model parameters
an appropriate notion of statistical divergence between a distribution of continuous trajectories
generated by the NSDE and an empirical distribution of observed sample paths. Several approaches
have been proposed in the literature, differing mostly in the choice of discriminating divergence. SDE-
GANs, introduced in [ 29], use the 1-Wasserstein distance to train a NSDE as a Wasserstein-GAN [ 1].
Latent SDEs [ 36] train a NSDE with respect to the KL divergence via variational inference and can be
interpreted as variational autoencoders. In [ 23] the authors propose to train NSDEs non-adversarially
using a class of maximum mean discrepancies (MMD) endowed with signature kernels [ 30,52].
Signature kernels are a class of characteristic kernels indexed on continuous paths that have received
increased attention in recent years thanks to their efficiency for handling path-dependent problems
[35,54,10,53,9,48,41]. For a treatment of this topic we refer the interested reader to [ 4, Chapter 2].
These kernels are not applicable to sample trajectories of SSNNs because of the lack of continuity.
Backpropagation through NSDEs Once a choice of discriminator has been made, training NSDEs
amounts to perform backpropagation through the SDE solver. There are several ways to do this. The
1The point here is actually a little more subtle. It is in fact possible to obtain exact gradients using the adjoint
method as long as one uses reversible (or adjoint) solvers in the forward pass.
2These are standard regularity conditions to ensure existence and uniqueness of a strong solution.
2first option is simply to backpropagate through the solver‚Äôs internal operations. This method is known
asdiscretise-then-optimise ; it is generally speaking fast to evaluate and produces accurate gradients,
but it is memory-inefficient, as every internal operation of the solver must be recorded. A second
approach, known as optimise-then-discretise , computes gradients by deriving a backwards-in-time
differential equation, the adjoint equation , which is then solved numerically by another call to the
solver. Not storing intermediate quantities during the forward pass enables model training at a
memory cost that is constant in depth. Nonetheless, this approach produces less accurate gradients
and is usually slower to evaluate because it requires recalculating the forward solutions to perform the
backward pass. A third way of backpropagating through NDEs is given by algebraically reversible
solvers , offering both memory and accuracy efficiency. We refer to [28] for further details.
Differential equations with events Many systems are not adequately modelled by continuous
differential equations because they experience jump discontinuities triggered by the internal state of
the system. Examples include a bouncing ball or spiking neurons. Such systems are often referred
to as (stochastic) hybrid systems [21,37]. When the differential equation is an ODE, there is a rich
literature on sensitivity analysis aimed at computing derivatives using the implicit function theorem
[11,12]. If, additionally, the vector fields describing the hybrid system are neural networks, [ 6] show
that NODEs solved up until first event time can be implemented as autodifferentiable blocks and [ 25]
derive the corresponding adjoint equations. Nonetheless, none of these works cover the more general
setting of SDEs. The only work, we are familiar with, dealing with sensitivity analysis in this setting
is [47], although focused on the problem of optimal control.
Training techniques for SNNs Roughly speaking, these works can be divided into two strands. The
first, usually referred to as backpropagation through time (BPTT), starts with a Euler approximation
of the SNN and does backpropagation by unrolling the computational graph over time; it then
uses surrogate gradients as smooth approximations of the gradients of the non-differentiable terms.
[58,46,40]. This approach is essentially analogous to discretise-then-optimise where the backward
pass uses custom gradients for the non-differentiable terms. The second strand computes exact
gradients of the spike times using the implicit function theorem. These results are equivalent to
optimise-then-discretise and can be used to define adjoint equations as in [ 56] or to derive forward
sensitivities [ 34]. However, we note that, unless solution trajectories and spike times of the SNN
are computed exactly, neither method provides the actual gradients of the implemented solver.
Furthermore, the BPTT surrogate gradient approach only covers the Euler approximation whereas
many auto-differentiable differential equation solvers are available nowadays, e.g. in diffrax .
Finally, there is a lot of interest in developing bioplausible learning algorithms where weights can be
updated locally and in an online fashion. Notable advances in this direction include [ 2,57]. To the
best of our knowledge, none of these works cover the case of stochastic SNNs where the neuronal
dynamics are modeled as SDEs instead of ODEs.
3 Stochastic spiking neural networks as Event SDEs
We shall in this paper be concerned with SDEs where solution trajectories experience jumps triggered
by implicitly defined events, dubbed Event SDEs . The prototypical example that we come back to
throughout is the SNN model composed of SLIF neurons. Here the randomness appears both in the
inter-spike dynamics as well as in the firing mechanism. To motivate the general definitions and
concepts we start with an informal introduction of SSNNs.
3.1 Stochastic spiking neural networks
To achieve a more bioplausible model of neuronal behaviour, one can extend the simple deterministic
LIF model by adding two types of noise: a diffusion term in the differential equation describing
inter-spike behaviour [ 33] and stochastic firing [ 50,27]. That is, the potential is modelled by eq. (1).
Instead of firing exactly when the membrane potential hits a set threshold, we model the spike times
(event times) by an inhomogenous Poisson process with intensity Œª:Re‚ÜíR+which is assumed
to be bounded by some constant C > 0. This can be phrased as an Event SDE (note that this is
essentially the reparameterisation trick) by introducing the additional state variable stsatisfying
dst=Œª(vt‚àí)dt, s 0= log u
3where u‚àºUnif(0,1). The neuron spikes whenever sthits0from below at which point the membrane
potential is reset to a resting level and we sample a new initial condition for st. We can denote this
first spike time by œÑ1and repeat the procedure to generate a sequence of spike times œÑ1< œÑ2< ... In
practice, we reinitialize statlogu‚àíŒ±for some Œ± >0. It can then be shown that
P(t < œÑ n+1|FœÑn) = min
1,exp
Œ±‚àíZt
œÑnŒª(vt‚àí)dt
fort‚àà[œÑn, œÑn+1).
It follows that œÑn+1‚àíœÑn‚â•Œ±/C a.s., i.e. Œ±controls the refractory period after spikes, a large value
indicating a long resting period.
We can then build a SSNN by connecting such SLIF neurons in a network. In particular, apart from
the membrane potential, we now also model the input current of each neuron as affected by the other
neurons in the network. Let K‚â•1denote the total number of neurons. We model neuron k‚àà[K]
be the three dimensional vector yk= (vk, ik, sk)the dynamic of which in between spikes is given by
dvk
t=¬µ1 
ik
t‚àívk
t
dt+œÉ1dBk
t, dik
t=‚àí¬µ2ik
tdt+œÉ2dBk
t, dsk
t=Œª(vk
t;Œæ)dt, (2)
where Bkis a standard two-dimensional Brownian motion, œÉ= (œÉ1, œÉ2)‚ààR2√ó2,¬µ= (¬µ1, ¬µ2)‚àà
R2, and Œª(¬∑;Œæ) :R‚ÜíR+is an intensity function. As before, neuron kfires (or spikes) whenever
skhits zero from below. Apart from resetting the membrane potential, this event also causes spikes
to propagate through the network in a such a way that a spike in neuron kwill increment the input
current of neuron jbywkj. Here w‚ààRK√óKis a matrix of weights representing the synaptic
weights in the neural network. If one is only interested in specific network architectures such as, e.g.,
feed-forward, this can be achieved by fixing the appropriate entries in wat 0.
As presented here, there is no way to model information coming into the network. But this would
only require a minor change. Indeed, by adding a suitable control term to eq. (2) we can model all
relevant scenarios. Since this does not change the theory in any meaningful way (the general theory
in Appendix B covers RDEs so an extra smooth control is no issue), we only discuss the more simple
model given without any additional input currents.
3.2 Model definition
Definition 3.1 (Event SDE) .LetN‚ààNbe the number of events. Let y0‚ààRebe an initial condition.
Let¬µ:Re‚ÜíReandœÉ:Re‚ÜíRe√ódbe the drift and diffusion vector fields. Let E:Re‚ÜíRand
T:Re‚ÜíRebe an event and transition function respectively. We say that 
y,(œÑn)N
n=1
is a solution
to the Event SDE parameterised by (y0, ¬µ, œÉ,E,T, N)ifyT=yN
T,
yt=NX
n=0yn
t1[œÑn,œÑn+1)(t), œÑ n= inf
t > œÑ n‚àí1:E(yn‚àí1
t) = 0	
, (3)
withE(yn
œÑn)Ã∏= 0and
dy0
t=¬µ(y0
t)dt+œÉ(y0
t)dBt,started at y0
0=y0, (4)
dyn
t=¬µ(yn
t)dt+œÉ(yn
t)dBt,started at yn
œÑn=T 
yn‚àí1
œÑn
, (5)
where Btis ad-dimensional Brownian motion and (4), (5) are Stratonovich SDEs.
In words, we initialize the system at y0, evolve it using (4)until the first time œÑ1at which an event
happens E(y0
œÑ1) = 0 . We then transition the system according to y1
œÑ1=T 
y0
œÑ1‚àí
and evolve it
according to (5)until the next event is triggered. We note that Definition 3.1 can be generalised to
multiple event and transition functions. Also, the transition function can be randomised by allowing
it to have an extra argument u‚àºUnif([0,1]). As part of the definition we require that there are only
finitely many events and that an event is not immediately triggered upon transitioning.
Existence of strong solutions to Event SDEs driven by continuous semimartingales has been studied
in [31, Theorem 5.2] and [ 32]. Under sufficient regularity of ¬µandœÉ, a unique solution to (4)exists.
We need the following additional assumptions:
Assumption 3.1.There exists c > 0such that for all s‚àà(0, T)anda‚ààimTit holds that
inf{t > s :E(yt) = 0}> cwhere ytis the solution to 4 started at ys=a
4Assumption 3.2.It holds that T(kerE)‚à© E=‚àÖ.
Assumptions 3.1 and 3.2 simply ensure that an event cannot be triggered immediately upon tran-
sitioning. This holds in most settings of interest. For example, for the usual deterministic LIF
neuron imT= 0andkerE= 1and the duration of the refractory period is directly linked to cin
Assumption 3.1.
Theorem 3.1 (Theorem 5.2, [ 31]).Under Assumptions 3.1-3.2 and with ¬µ‚ààLip1andœÉ‚ààLipŒ≥for
Œ≥ >2, there exists a unique solution (y,(œÑn)N
n=1)to the Event SDE of Definition 3.1.
The definitions and results of this section can be extended to differential equations driven by random
rough paths, and in particular, to cases where the driving noise exhibits jumps. In the latter case, it
is important to note that the resulting Event SDE will exhibit two types of jumps: the ones given
apriori by the driving noise and the ones that are implicitly defined through the solution (what we
callevents ). In fact, we develop the main theory of Event RDEs in Appendix A in the more general
setting of RDEs driven by c√†dl√†g rough paths. The rough path formalism enables a unified treatment
of differential equations driven by noise signals of arbitrary (ir-)regularity, and makes all proofs
simple and systematic. In particular, it allows us to handle cases where the diffusion term is driven by
a finite activity L√©vy process (e.g, a homogeneous Poisson processes highly relevant in the context of
SNNs).
3.3 Backpropagation
We are interested in optimizing a continuously differentiable loss function Lwhose input is the
solution of a parameterised Event SDE. As for Neural ODEs, the vector fields, ¬µ, œÉ, and the event
and transition functions E,T, might depend on some learnable parameters Œ∏. We can move the
parameters Œ∏of the Event RDE inside the initial condition y0by augmenting the dynamics with the
additional state variable Œ∏tsatisfying dŒ∏t= 0andŒ∏0=Œ∏. Thus, as long as we can compute gradients
with respect to y0, these will include gradients with respect to such parameters. We then require the
gradients ‚àÇy0L, if they exist. For this, we need to be able to compute the Jacobians ‚àÇyn
t:=‚àÇy0yn
tof
the inter-event flows associated to the dynamics of yn
tand the derivatives ‚àÇœÑn:=‚àÇy0œÑn. We assume
that the event and transition functions EandTare continuously differentiable.
Apriori, it is not clear under what conditions such quantities exist and even less how to compute them.
This shall be the focus of the present section. We will need the following running assumptions.
Assumption 3.3.œÉ(T(y))‚àí ‚àáT (y)œÉ(y) = 0 for all y‚ààkerE.
Assumption 3.4.‚àáE(y)œÉ(y) = 0 for all y‚ààkerE.
Assumption 3.5.‚àáE(y)¬µ(y)Ã∏= 0for all y‚ààkerE.
Assumption 3.4 and 3.5 ensure that the event times are differentiable. Intuitively, they state that the
event condition is hit only by the drift part of the solution. Assumption 3.4 holds for example if the
event functions depend only on a smooth part of the system. Assumption 3.3 is what allows us to
differentiate through the event transitions.
Theorem 3.2. Let Assumptions 3.1-3.5 be satisfied and (y,(œÑn)N
n=1)the solution to the Event SDE
parameterized by (y0, ¬µ, œÉ,E,T, N). Then, almost surely, for any n‚àà[N], the derivatives ‚àÇœÑnand
the Jacobians ‚àÇyn
texist and admit the following recursive expressions
‚àÇœÑn=‚àí‚àáE(yn‚àí1
œÑn)‚àÇyn‚àí1
œÑn
‚àáE(yn‚àí1œÑn)¬µ(yn‚àí1œÑn)(6)
‚àÇyn
t= (‚àÇynœÑnyn
t)
‚àáT(yn‚àí1
œÑn)‚àÇyn‚àí1
œÑn‚àí 
¬µ(yn
œÑn)‚àí ‚àáT (yn‚àí1
œÑn)¬µ(yn‚àí1
œÑn)
‚àÇœÑn
. (7)
where ‚àÇyn
tand‚àÇœÑnare the total derivatives of yt
nandœÑnwith respect to the initial condition y0,
‚àÇynœÑnyn
tdenotes the partial derivative of the flow map of eq. (5)with respect to its initial condition,
and‚àáT ‚àà Re√óeand‚àáE ‚àà R1√óeare the Jacobians of TandE.
Remark 3.1.If the diffusion term is absent we recover the gradients in [ 6]. In this case, the
assumptions of the theorem are trivially satisfied. Note however, that the result, as stated here, is
slightly different since we are considering repeated events.
Remark 3.2.The recursive nature of (6)-(7)suggest a way to update gradients in an online fashion
by computing the forward sensitivity along with the state of the Event SDE. In traditional machine
5learning applications (e.g. NDEs) forward mode automatic differentiation is usually avoided due
to the fact that the output dimension tends to be orders of magnitude smaller than the number of
parameters [28]. However, for (S)SNNs this issue can be partly avoided as discussed in Section 4.4.
Returning now to the SSNN model introduced in Section 3.1 we find that it is an Event SDE with K
different event functions given by Ek(y) =skand corresponding transition functions given by
Tk(y) = 
T1
k(y1), . . . ,TK
k(yK)
where Tj
k(yj) = ( vj, ij+wkj, sj)ifjÃ∏=kandTk
k(yk) = ( vk‚àívreset, ik,logu‚àíŒ±)where
vreset>0is a constant determining by what amount the membrane potential is reset. The addition of
the constant Œ± >0controlling the refractory period ensures that Assumption 3.2 and 3.2 are satisfied.
Stochastic firing smooths out the event triggering so that Assumption 3.5 and 3.4 hold. Finally, one
can check that the combination of constant diffusion terms and the given transition functions satisfies
Assumptions 3.3. Note that setting vk
texactly to 0 upon spiking would break Assumption 3.3. If one
is interested in such a resetting mechanism it suffices to pick a diffusion term œÉ1(yk)that satisfies
œÉ(0) = 0 . To sum up, solutions (in the sense of Def. 3.1) of the SSNNs exist and are unique. In
addition, the trajectories and spike times are almost surely differentiable satisfying (6) and (7).
3.4 Numerical solvers
Theorem 3.2 gives an expression for the gradients of the event times as well as the Event SDE
solution. In practice, analytical expressions for gradients are often not available and one has to resort
to numerical solvers. Three solutions suggest themselves:
1.There are multiple autodifferentiable differential equation solvers (such as diffrax [28])
that provide differentiable numerical approximations of the flows ‚àÇynœÑnyn
t. We shall
write SDESolve (y0, ¬µ, œÉ, s, t )for a generic choice of such a solver. Furthermore, if
RootFind (y0, f)is a differentiable root finding algorithm (here f: (y, t)7‚ÜíRshould be dif-
ferentiable in both arguments and RootFind (y0, f)returns t‚àó‚ààRsuch that f(y0, t‚àó) = 0 ),
then we can define a differentiable map E:y07‚Üíy‚àóby
t‚àó=RootFind (y0,E(SDESolve (¬∑, ¬µ, œÉ, s, ¬∑))), y‚àó=SDESolve (y0, ¬µ, œÉ, s, t‚àó).
Consequently, EventSDESolve (y0, ¬µ, œÉ,E,T, N)can be implemented as subsequent com-
positions of T ‚ó¶E(see Algorithm 1). This is a discretise-then-optimise approach [28].
2.Alternatively, one can use the formulas (6)and(7)directly as a replacement of the derivatives.
This is the approach taken in e.g. [ 6]. To be precise, one would replace all the derivatives of
the flow map (terms of the sort ‚àÇyn
œÑnyn
t) with the derivatives of the given numerical solver.
This approach is a solution between discretise-then-optimise and optimise-then-discretise.
3.Finally, one could apply the adjoint method (or optimise-then-discretise) as done for de-
terministic SNNs in [ 56] by deriving the adjoint equations. These adjoint equations define
another SDE with jumps which is solved backwards in time. Between events the dynamics
are exactly as in the continuous case so one just needs to specify the jumps of the adjoint
process. This can be done by referring to (6) and (7).
Remark 3.3.One thing to be careful of with the discretise-then-optimise approach is that the SDE
solver will compute time derivatives in the backward pass, although the modelled process is not time
differentiable. Assumptions 3.4 and 3.3 should in principle guarantee that these derivatives cancel out
(see Appendix B), yet this might not necessarily happen at the level of the numerical solver because of
precision issues. This is essentially due to the fact that approximate solutions provided by numerical
solvers are in general not flows . Thus, when the path driving the diffusion term is very irregular, the
gradients can become unstable. In practice we found this could be fixed by setting the gradient with
respect to time of the driving Brownian motion to 0and picking a step size sufficiently small.
Remark 3.4.In the context of SNNs, Algorithm 1 is actually a version of exact backpropagation
through time (BPTT) of the unrolled numerical solution. Contrary to popular belief, this illustrates
that one can compute exact gradients of numerical approximations of SNNs without the need to resort
to surrogate gradient functions. Of course, this does not alleviate the so-called dead neuron problem .
However, this ceases to be a problem when stochastic firing is introduced. In fact, surrogate gradients
can be related to stochastic firing mechanisms and expected gradients [20].
6Remark 3.5.One the one hand, the EventSDESolve algorithm as presented here scales poorly in the
number of events since it requires doing a full SDESolve and an additional RootFind each time an
event occurs. This problem becomes especially prevalent for SSNNs with a large number of neurons
since in this case an event is triggered every time a single neuron spikes and the inter-spike SDE that
needs to be solved is high-dimensional. On the other hand, there are multiple ways to mitigate this
issue. Firstly, one could relax the root-finding step and simply trigger a spike as soon as e‚â•0and
take this as the spike time. For the backward pass one could then solve the adjoint equations (for
which you need need to store the spike times in the forward pass). The resulting algorithm would be
similar to the one derived in [55] for deterministic SNNs. Secondly, for special architectures such
as a feed-forward network, given the spikes from the previous layer, one could solve the EventSDE
for each neuron in the current layer independently of all other neurons. This would imply that a
forward (or backward) pass of the entire SSNN scales as O(KS)where Sis the cost of the forward
(or backward) pass of a single neuron and Kis the number of neurons.
Algorithm 1 EventSDESolve
Input y0, ¬µ, œÉ,E,T, N, t 0,‚àÜt, T
1:y‚Üêy0
2:n‚Üê0
3:e‚Üê E(y)
4:while n < N andt0< T do
5: while e <0do ‚ñ∑We assume for simplicity that e‚â§0
6: y0‚Üêy
7: y‚ÜêSDESolveStep (y0, ¬µ, œÉ, t 0,‚àÜt)
8: t0‚Üêt0+ ‚àÜt
9: e‚Üê E(y) ‚ñ∑Update value of event function
10: end while
11: t‚àó
n+1‚ÜêRootFind (y0,E(SDESolveStep (¬∑, ¬µ, œÉ, t 0‚àí‚àÜt,¬∑))) ‚ñ∑Find exact event time
12: y‚àó
n+1‚ÜêSDESolveStep (y0, ¬µ, œÉ, t 0‚àí‚àÜt, t‚àó
n+1) ‚ñ∑Compute state at event time
13: y‚Üê T(y‚àó
n+1) ‚ñ∑Apply transition function
14: n‚Üên+ 1
15:end while
Return (t‚àó
n)n‚â§N,y
4 Training stochastic spiking neural networks
4.1 A loss function based on signature kernels for c√†dl√†g paths
To train SSNNs we will adopt a similar technique as in [ 23], where the authors propose to train
NSDEs non-adversarially using a class of maximum mean discrepancies (MMD) endowed with
signature kernels [ 52] indexed on spaces of continuous paths as discriminators. However, as we
mentioned in the introduction, classical signature kernels are not directly applicable to the setting
of SSNNs as the solution trajectories not continuous. To remedy this issue, in Appendix C, we
generalise signature kernels to Marcus signature kernels indexed on discontinuous (or c√†dl√†g) paths.
We note that our numerical experiments only concern learning from spike trains, which are c√†dl√†g
paths of bounded variation. Yet, the Marcus signature kernel defined in Appendix C can handle more
general c√†dl√†g rough paths.
The main idea goes as follows. If xis a c√†dl√†g path, one can define the Marcus signature S(x)in
the spirit of Marcus SDEs [ 42,43] as the signature of the Marcus interpolation ofx. The general
construction is given in Appendix A. The Marcus signature kernel is defined as the inner product
k(x, y) =‚ü®S(x), S(y)‚ü©of Marcus signatures S(x), S(y)of two c√†dl√†g paths x, y. As stated in the
first part of Theorem C.1, this kernel is characteristic on regular Borel measures supported on compact
sets of c√†dl√†g paths. In particular, this implies that the resulting maximum mean discrepancy (MMD)
dk(¬µ, ŒΩ)2=Ex,x‚Ä≤‚àº¬µk(x, x‚Ä≤)‚àí2Ex,y‚àº¬µ√óŒΩk(x, x‚Ä≤) +Ey,y‚Ä≤‚àºŒΩk(y, y‚Ä≤)
satisfies the property dk(¬µ, ŒΩ)2= 0‚áê‚áí ¬µ=ŒΩfor any two compactly supported measures ¬µ, ŒΩ.
Nonetheless, characteristicness ceases to hold when one considers measures on c√†dl√†g paths that
are not compactly supported. In [ 8] the authors address this issue for continuous paths by using the
7so-called robust signature . They introduce a tensor normalization Œõensuring that the range of the
robust signature Œõ‚ó¶Sremains bounded. The robust signature kernel is then defined as the inner
product kŒõ(x, y) =‚ü®Œõ‚ó¶S(x),Œõ‚ó¶S(y)‚ü©. This normalization can be applied analogously to the
Marcus signature resulting in a robust Marcus signature kernel . In the second part of Theorem C.1,
we prove characteristicness of kŒõfor possibly non-compactly supported Borel measures on c√†dl√†g
paths. The resulting MMD is denoted by dkŒõ.
There are several ways of evaluating signature kernels. The most naive is to simply truncate the
signatures at some finite level and then take their inner product. Another amounts to solve a path-
dependent wave equation [52]. Our experiments are compatible with both of these methods.
Given a collection of observed c√†dl√†g trajectories {xi}m
i=1‚àº¬µtruesampled from an underlying
unknown target measure ¬µtrue, we can train an Event SDE by matching the generated c√†dl√†g trajec-
tories{yi}n
i=1‚àº¬µŒ∏using an unbiased empirical estimator of dk(ordkŒõ), i.e. minimising over the
parameters Œ∏of the Event SDE the following loss function
L=1
m(m‚àí1)X
jÃ∏=ik(xi, xj)‚àí2
mnX
i,jk(xi, yj) +1
n(n‚àí1)X
jÃ∏=ik(yi, yj).
In the context of SSNNs, the observed and generated trajectories xi‚Äôs and yi‚Äôs correspond to spike
trains, which are c√†dl√†g paths of bounded variation.
4.2 Input current estimation
The first example is the simple problem of estimating the constant input current c >0based on a
sample of spike trains in the single SLIF neuron model,
dvt=¬µ(c‚àívt)dt+œÉdB t, ds t=Œª(vt)dt,
where Œª(v) = exp(5( v‚àí1),¬µ= 15 andœÉvaries. Throughout we fix the true c= 1.5and set
vreset = 1.4andŒ±= 0.03. We run stochastic gradient descent for 1500 steps for two choices of the
diffusion constant œÉ. The loss function is the signature kernel MMD between a simulated batch and
the sample of spike trains.3. The test loss is the mean absolute error between the first three average
spike times. Results are given in Fig. 1. For additional details regarding the experiments, we refer to
Appendix E.
In all cases backpropagation through Algorithm 1 is able to learn the underlying input current after
around 600 steps up to a small estimation error. In particular, the convergence is fastest for the largest
sample size and the true cis recovered for both levels of noise.
4.3 Synaptic weight estimation
Next we consider the problem of estimating the weight matrix in a feed-forward SSNN with input
dimension 4, 1 hidden layer of dimension 16, and output dimension 2. The rest of the parameters are
fixed throughout. We run stochastic gradient descent for 1500 steps with a batch size of 128 and for a
sample size of 256,512, and 1024 respectively. Learning rate is decreased from 0.003to0.001after
1000 steps. The results are given in Fig. 2 in Appendix E. For a sample size of 512and1024 we are
able to reach a test loss of practically 0, that is, samples from the learned model and the underlying
model are more or less indistinguishable. Also, in all cases the estimated weight matrix approaches
the true weight matrix. Interestingly, for the largest sample size, the model reaches the same test loss
as the model trained on a sample size of 512, but their estimated weight matrices differ significantly.
4.4 Online learning
In the case of SSNNs, equations (6)-(7)lead to a formula for the forward sensitivity where any
propagation of gradients between neurons only happens at spike times and only between connected
neurons (see Proposition D.1). Since the forward sensitivities are computed forward in time together
with the solution of the SNN, gradients can be updated online as new data appears. As a result,
between spikes of pre-synaptic neurons, we can update the gradient flow of the membrane potential
3For simplicity we only compute an approximation of the true MMD by truncating the signatures at depth 3
and taking the average across the batch/sample size.
80 250 500 750 1000 1250 150001234Test lossœÉ= 0.25
Sample size
16
32
64
128
0 250 500 750 1000 1250 15000.60.81.01.21.4cœÉ= 0.25
0 250 500 750 1000 1250 1500
Step01234Test lossœÉ= 0.5
Sample size
16
32
64
128
0 250 500 750 1000 1250 1500
Step0.60.81.01.21.4cœÉ= 0.5Figure 1: Test loss and cestimate across four sample sizes and for two levels of noise œÉ. On the left: MAE for
the three first average spike times on a hold out test set. On the right: estimated value of cat the current step.
and input current of each neuron using information exclusively from that neuron. For general network
structures and loss functions, however, this implies that each neuron needs to store on the order of
K2gradient flows (one for each weight in the network).
On the other hand, if the adjacency matrix of the weight matrix forms a directed acyclic graph (DAG),
three-factor Hebbian learning rules like those in [ 57,2] are easily derived from Proposition D.1. For
simplicity, consider the SNN consisting of deterministic LIF neurons and let Nk
tdenote the spike
train of neuron k, i.e., Nk
tis c√†dl√†g path equal to the number of spikes of neuron kat time t. We
letœÑk(t)(orœÑkfor short) denote the last spike of neuron kbefore time t. We shall assume that the
instantaneous loss function Ltdepends only on the most recent spike times œÑ1, . . . , œÑK. Then,
‚àÇwjkLt=‚àÇœÑkLtajk
œÑk
¬µ1(vk
œÑk‚àíik
œÑk)
where ajk
tis the eligibility trace and the first term can be viewed as a global modulator , that is, a
top-down learning signal propagating the error from the output neurons.4The eligibility trace satisfies
dajk
t=¬µ1
bjk
t‚àíajk
t
dt+vresetajk
t
¬µ1(ik
t‚àívk
t)dNk
t, dbjk
t=‚àí¬µ2bjk
t+dNj
t,
where the dNterms are to be understood in the Riemann-Stieltjes sense. In other words, the eligibility
trace can be updated exclusively from the activity of the pre- and post-synaptic neurons. We note
the similarity to the results derived in [ 2] only our result gives the exact gradients with no need to
introduce surrogate gradient functions. A similar equation for deterministic SNNs was derived in
[49] (see, in particular, Chapter 5). For general network structures one can use the eligibility traces as
proxies for the the true derivatives ‚àÇwijœÑk.
5 Conclusion
We introduced a mathematical framework based on rough path theory to model SSNNs as SDEs
exhibiting event discontinuities and driven by c√†dl√†g rough paths. After identifying sufficient
4Note that in the case of stochastic SNNs this term is not necessarily well-defined since semi-martingales are
in general not differentiable wrt. time.
9conditions for differentiability of solution trajectories and event times, we obtained a recursive
relation for the pathwise gradients in Theorem 3.2, generalising the results presented in [ 6] and
[25] which only deal with the case of ODEs. Next, we introduced Marcus signature kernels as
extensions of continuous signature kernels from [ 52] to c√†dl√†g rough paths and used them to define
a general-purpose loss function on the space of c√†dl√†g rough paths to train SSNNs where noise is
present in both the spike timing and the network‚Äôs dynamics. Based on these results, we also provided
an end-to-end autodifferentiable solver for SDEs with event discontinuities (Algorithm 1) and made
its implementation available as part of the diffrax repository. Finally, we discussed how our results
lead to bioplausible learning algorithms akin to e-prop [2] but in the context of spike time gradients.
The primary objective of the paper was to lay out the theoretical foundations of gradient-based
learning with stochastic SNNs. Although we provided an initial implementation, which is well-suited
for low dimensional examples, a robust version that scales to a high number of neurons is beyond the
scope of the paper. Examples that require a much higher number of neurons than the two examples
already discussed will be hard to handle with the discretize-then-optimize approach for the reasons
given in Remark 3.5.
We think there are still many interesting research directions left to explore. For instance, it would be
of interest to implement the adjoint equations or to use reversible solvers and compare the results.
Similarly, since our Algorithm 1 differs from the usual approach with surrogate gradients even
in the deterministic setting, questions remain on how these methods compare for training SNNs.
Furthermore, it would be interesting to understand to what extent the inclusion of different types
of driving noises in the dynamics of SSNNs would be beneficial for learning tasks compared to
deterministic SNNs. Finally, it remains to be seen whether the discussion in Section 4.4 could lead to
a bio-plausible learning algorithm with comparable performance to state-of-the-art backpropagation
methods and implementable on neuromorphic hardware.
Acknowledgements . Christian Holberg gratefully acknowledges financial support from Novo Nordisk
Foundation through Grant NNF20OC0062958 and from Independent Research Fund Denmark |
Natural Sciences through Grant 9040-00215B.
References
[1]Martin Arjovsky, Soumith Chintala, and L√©on Bottou. Wasserstein generative adversarial
networks. In International conference on machine learning , pages 214‚Äì223. PMLR, 2017.
[2]Guillaume Bellec, Franz Scherr, Anand Subramoney, Elias Hajek, Darjan Salaj, Robert Leg-
enstein, and Wolfgang Maass. A solution to the learning dilemma for recurrent networks of
spiking neurons. Nature communications , 11(1):3625, 2020.
[3]Alain Berlinet and Christine Thomas-Agnan. Reproducing kernel Hilbert spaces in probability
and statistics . Springer Science & Business Media, 2011.
[4]Thomas Cass and Cristopher Salvi. Lecture notes on rough paths and applications to machine
learning. arXiv preprint arXiv:2404.06583 , 2024.
[5]Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary
differential equations. Advances in neural information processing systems , 31, 2018.
[6]Ricky TQ Chen, Brandon Amos, and Maximilian Nickel. Learning neural event functions for
ordinary differential equations. In International Conference on Learning Representations , 2020.
[7]Ilya Chevyrev and Peter K Friz. Canonical rdes and general semimartingales as rough paths.
The Annals of Probability , 47(1):420‚Äì463, 2019.
[8]Ilya Chevyrev and Harald Oberhauser. Signature moments to characterize laws of stochastic
processes. Journal of Machine Learning Research , 23(176):1‚Äì42, 2022.
[9]Nicola Muca Cirone, Maud Lemercier, and Cristopher Salvi. Neural signature kernels as infinite-
width-depth-limits of controlled resnets. In International Conference on Machine Learning ,
pages 25358‚Äì25425. PMLR, 2023.
10[10] Thomas Cochrane, Peter Foster, Varun Chhabra, Maud Lemercier, Terry Lyons, and Cristopher
Salvi. Sk-tree: a systematic malware detection algorithm on streaming trees via the signature
kernel. In 2021 IEEE international conference on cyber security and resilience (CSR) , pages
35‚Äì40. IEEE, 2021.
[11] Sebastien Corner, Corina Sandu, and Adrian Sandu. Modeling and sensitivity analysis method-
ology for hybrid dynamical system. Nonlinear Analysis: Hybrid Systems , 31:19‚Äì40, 2019.
[12] Sebastien Corner, Adrian Sandu, and Corina Sandu. Adjoint sensitivity analysis of hybrid
multibody dynamical systems. Multibody System Dynamics , 49:395‚Äì420, 2020.
[13] Christa Cuchiero, Francesca Primavera, and Sara Svaluto-Ferro. Universal approximation
theorems for continuous functions of c \adl\ag paths and l \‚Äôevy-type signature models. arXiv
preprint arXiv:2208.02293 , 2022.
[14] Adeline Fermanian, Terry Lyons, James Morrill, and Cristopher Salvi. New directions in the
applications of rough path theory. IEEE BITS the Information Theory Magazine , 2023.
[15] Peter Friz and Atul Shekhar. General rough integration, l√©vy rough paths and a l√©vy‚Äìkintchine-
type formula. Annals of probability: An official journal of the Institute of Mathematical
Statistics , 45(4):2707‚Äì2765, 2017.
[16] Peter K Friz and Martin Hairer. A course on rough paths . Springer, 2020.
[17] Peter K Friz and Nicolas B Victoir. Multidimensional stochastic processes as rough paths:
theory and applications , volume 120. Cambridge University Press, 2010.
[18] Peter K Friz and Huilin Zhang. Differential equations driven by rough paths with jumps. Journal
of Differential Equations , 264(10):6226‚Äì6301, 2018.
[19] Wulfram Gerstner and Werner M Kistler. Spiking neuron models: Single neurons, populations,
plasticity . Cambridge university press, 2002.
[20] Julia Gygax and Friedemann Zenke. Elucidating the theoretical underpinnings of surrogate
gradient learning in spiking neural networks. arXiv preprint arXiv:2404.14964 , 2024.
[21] Thomas A Henzinger. The theory of hybrid automata. In Proceedings 11th Annual IEEE
Symposium on Logic in Computer Science , pages 278‚Äì292. IEEE, 1996.
[22] Melker H√∂glund, Emilio Ferrucci, Camilo Hern√°ndez, Aitor Muguruza Gonzalez, Cristopher
Salvi, Leandro S√°nchez-Betancourt, and Yufei Zhang. A neural rde approach for continuous-
time non-markovian stochastic control problems. In ICML Workshop on New Frontiers in
Learning, Control, and Dynamical Systems , 2023.
[23] Zacharia Issa, Blanka Horvath, Maud Lemercier, and Cristopher Salvi. Non-adversarial training
of neural sdes with signature kernel scores. Advances in Neural Information Processing Systems ,
2023.
[24] Hyeryung Jang and Osvaldo Simeone. Multisample online learning for probabilistic spiking
neural networks. IEEE Transactions on Neural Networks and Learning Systems , 33(5):2034‚Äì
2044, 2022.
[25] Junteng Jia and Austin R Benson. Neural jump stochastic differential equations. Advances in
Neural Information Processing Systems , 32, 2019.
[26] Danilo Jimenez Rezende and Wulfram Gerstner. Stochastic variational learning in recurrent
spiking networks. Frontiers in computational neuroscience , 8:38, 2014.
[27] Hiroshi Kajino. A differentiable point process with its application to spiking neural networks.
InInternational Conference on Machine Learning , pages 5226‚Äì5235. PMLR, 2021.
[28] Patrick Kidger. On Neural Differential Equations . PhD thesis, University of Oxford, 2021.
[29] Patrick Kidger, James Foster, Xuechen Li, Harald Oberhauser, and Terry Lyons. Neural sdes as
infinite-dimensional gans. arXiv preprint arXiv:2102.03657 , 2021.
11[30] Franz J Kir√°ly and Harald Oberhauser. Kernels for sequentially ordered data. Journal of
Machine Learning Research , 20(31):1‚Äì45, 2019.
[31] Jaroslav Krystul and HAP Blom. Generalised stochastic hybrid processes as strong solutions of
stochastic differential equations. Hybridge report D , 2, 2005.
[32] Jaroslav Krystul, Henk AP Blom, and Arunabha Bagchi. Stochastic differential equations on
hybrid state spaces. Stochastic Hybrid Systems , 24(15-45):170, 2006.
[33] Petr Lansky and Susanne Ditlevsen. A review of the methods for signal estimation in stochastic
diffusion leaky integrate-and-fire neuronal models. Biological cybernetics , 99(4-5):253‚Äì262,
2008.
[34] Jane H Lee, Saeid Haghighatshoar, and Amin Karbasi. Exact gradient computation for spiking
neural networks via forward propagation. In International Conference on Artificial Intelligence
and Statistics , pages 1812‚Äì1831. PMLR, 2023.
[35] Maud Lemercier, Cristopher Salvi, Theodoros Damoulas, Edwin Bonilla, and Terry Lyons.
Distribution regression for sequential data. In International Conference on Artificial Intelligence
and Statistics , pages 3754‚Äì3762. PMLR, 2021.
[36] Xuechen Li, Ting-Kam Leonard Wong, Ricky TQ Chen, and David K Duvenaud. Scalable
gradients and variational inference for stochastic differential equations. In Symposium on
Advances in Approximate Bayesian Inference , pages 1‚Äì28. PMLR, 2020.
[37] John Lygeros and Maria Prandini. Stochastic hybrid systems: a powerful framework for
complex, large scale applications. European Journal of Control , 16(6):583‚Äì594, 2010.
[38] Terry J Lyons. Differential equations driven by rough signals. Revista Matem√°tica Iberoameri-
cana , 14(2):215‚Äì310, 1998.
[39] Terry J Lyons, Michael Caruana, and Thierry L√©vy. Differential equations driven by rough
paths . Springer, 2007.
[40] Gehua Ma, Rui Yan, and Huajin Tang. Exploiting noise as a resource for computation and
learning in spiking neural networks. Patterns , 4(10), 2023.
[41] Georg Manten, Cecilia Casolo, Emilio Ferrucci, S√∏ren Wengel Mogensen, Cristopher Salvi,
and Niki Kilbertus. Signature kernel conditional independence tests in causal discovery for
stochastic processes. arXiv preprint arXiv:2402.18477 , 2024.
[42] Steven Marcus. Modeling and analysis of stochastic differential equations driven by point
processes. IEEE Transactions on Information theory , 24(2):164‚Äì172, 1978.
[43] Steven I Marcus. Modeling and approximation of stochastic differential equations driven by
semimartingales. Stochastics: An International Journal of Probability and Stochastic Processes ,
4(3):223‚Äì245, 1981.
[44] James Morrill, Cristopher Salvi, Patrick Kidger, and James Foster. Neural rough differential
equations for long time series. In International Conference on Machine Learning , pages
7829‚Äì7838. PMLR, 2021.
[45] Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Bernhard Sch√∂lkopf, et al. Kernel
mean embedding of distributions: A review and beyond. Foundations and Trends ¬Æin Machine
Learning , 10(1-2):1‚Äì141, 2017.
[46] Emre O Neftci, Hesham Mostafa, and Friedemann Zenke. Surrogate gradient learning in spiking
neural networks: Bringing the power of gradient-based optimization to spiking neural networks.
IEEE Signal Processing Magazine , 36(6):51‚Äì63, 2019.
[47] Ali Pakniyat and Peter E Caines. On the stochastic minimum principle for hybrid systems. In
2016 IEEE 55th Conference on Decision and Control (CDC) , pages 1139‚Äì1144. IEEE, 2016.
[48] Alexandre Pannier and Cristopher Salvi. A path-dependent pde solver based on signature
kernels. arXiv preprint arXiv:2403.11738 , 2024.
12[49] Christian Pehle. Adjoint equations of spiking neural networks . PhD thesis, Universit√§t Heidel-
berg, 2021.
[50] Jean-Pascal Pfister, Taro Toyoizumi, David Barber, and Wulfram Gerstner. Optimal spike-
timing-dependent plasticity for precise action potential firing in supervised learning. Neural
computation , 18(6):1318‚Äì1348, 2006.
[51] Cristopher Salvi. Rough paths, kernels, differential equations and an algebra of functions on
streams . PhD thesis, University of Oxford, 2021.
[52] Cristopher Salvi, Thomas Cass, James Foster, Terry Lyons, and W. Y . The signature kernel is
the solution of a Goursat PDE. SIAM Journal on Mathematics of Data Science , 3(3):873‚Äì899,
2021.
[53] Cristopher Salvi, Maud Lemercier, Thomas Cass, Edwin V Bonilla, Theodoros Damoulas, and
Terry J Lyons. Siggpde: Scaling sparse gaussian processes on sequential data. In International
Conference on Machine Learning , pages 6233‚Äì6242. PMLR, 2021.
[54] Cristopher Salvi, Maud Lemercier, Chong Liu, Blanka Horvath, Theodoros Damoulas, and
Terry Lyons. Higher order kernel mean embeddings to capture filtrations of stochastic processes.
Advances in Neural Information Processing Systems , 34:16635‚Äì16647, 2021.
[55] Bernhard Sch√∂lkopf and Alexander J Smola. Learning with kernels: support vector machines,
regularization, optimization, and beyond . MIT press, 2002.
[56] Timo C Wunderlich and Christian Pehle. Event-based backpropagation can compute exact
gradients for spiking neural networks. Scientific Reports , 11(1):12829, 2021.
[57] Mingqing Xiao, Qingyan Meng, Zongpeng Zhang, Di He, and Zhouchen Lin. Online training
through time for spiking neural networks. Advances in neural information processing systems ,
35:20717‚Äì20730, 2022.
[58] Friedemann Zenke and Tim P V ogels. The remarkable robustness of surrogate gradient learning
for instilling complex function in spiking neural networks. Neural computation , 33(4):899‚Äì925,
2021.
13Appendix
The appendix is structured as follows. Section A covers the basic concepts of c√†dl√†g rough paths
based on [ 7] extended with a few of our own definitions and results. It culminates with the definition
of Event RDEs which can be viewed as generalizations of Event SDEs. Section B covers the proof of
the main result, Theorem 3.2, but in the setting of Event RDEs as well as some preliminary technical
lemmas needed for the proof. Section C gives a brief overview of the main concepts in kernel learning
and presents our results on Marcus signature kernels along with their proofs. Section D derives the
forward sensitivities of a SSNN. Finally, Section E covers all the technical details of the simulation
experiments that were not discussed in the main body of the paper.
A C√†dl√†g rough paths
Marcus integration developed in [ 7] preserves the chain rule and thus serves as an analog to
Stratonovich integration for semi-martingales with jump discontinuities. In particular, it allows
to define a canonical lift under which c√†dl√†g semi-martingales are a.s. geometric rough paths and
many of the results from the continuous case, such as universal limit theorems and stability results,
carry over under suitably defined metrics.We briefly review some of the important concepts here by
following the same setup as in [7].
LetC([0, T], E)andD([0, T], E)be the space of continuous and c√†dl√†g paths respectively on
[0, T]with values in a metric space (E, d). For p‚â•1, letCp([0, T], E)andDp([0, T], E)be the
corresponding subspaces of paths with finite p-variation. For any N‚â•1, Let GN(Rd)be the
step-Nfree nilpotent Lie group over Rdendowed with the Carnot-Carath√©odory metric d. Let
‚Ñ¶C
p(Rd) := Cp([0, T], G‚åäp‚åã(Rd))and‚Ñ¶D
p(Rd) := Dp([0, T], G‚åäp‚åã(Rd))be the space of weakly
geometric continuous and c√†dl√†g p-rough paths respectively with the homogeneous p-variation metric
dp(x,y) = max
1‚â§k‚â§‚åäp‚åãsup
D‚äÇ[0,T] X
Dd(xti,ti+1,yti,ti+1)p
k!k
p
.
Define the log-linear path function
œï:GN(Rd)√óGN(Rd)‚ÜíC([0,1], GN(Rd))
(a,b)7‚Üíexp((1 ‚àí ¬∑) loga+¬∑logb).
where logandexpare the (truncated) tensor logarithm and exponential maps on GN(Rd). IfN= 1,
thenGN(Rd)‚àº=R‚äïRdandœï(a, b)t= (1,(1‚àít)a+tb)is a straight line connecting atobin unit
time. For any x‚ààD([0, T], GN(Rd))we can construct a continuous path ÀÜx‚ààC([0, T], GN(Rd))
by adding fictitious time and interpolating through the jumps using the log-linear path function
according to the following definition.
Definition A.1 (Marcus interpolation) .LetN‚â•1. Forx‚ààD([0, T], GN(Rd)), letœÑ1, œÑ2, . . . , œÑ m
be the jump times of xordered such that d(xœÑ1‚àí,xœÑ1)‚â•d(xœÑ2‚àí,xœÑ2)‚â• ¬∑¬∑¬∑ ‚â• d(xœÑm‚àí,xœÑm),
where 0‚â§m‚â§ ‚àû is the number of jumps. Let (rk)be a sequence of positive scalars rk>0such
thatr=Pm
k=1rk<+‚àû. Define the discontinuous reparameterisation Œ∑: [0, T]‚Üí[0, T+r]by
Œ∑(t) =t+mX
k=1rk1{œÑk‚â§t}.
The Marcus augmentation xM‚ààC([0, T+r], GN(Rd))ofxis the path
xM
s=xt, ifs=Œ∑(t)for some t‚àà[0, T],
œï(xœÑk‚àí,xœÑk)(s‚àíŒ∑(œÑk‚àí))/rk, ifs‚àà[Œ∑(œÑk‚àí), Œ∑(œÑk))for1‚â§k < m + 1.
The Marcus interpolation ÀÜx‚ààC([0, T], GN(Rd))ofxis the path ÀÜx=xM‚ó¶Œ∑rwhere Œ∑r(t) =
t(T+r)/Tis a reparameterisation from [0, T]to[0, T+r]. We can recover xfromÀÜxviax=ÀÜx‚ó¶Œ∑x
by considering the reparameterisation Œ∑x=Œ∑‚àí1
r‚ó¶Œ∑.
Once the Marcus interpolation is defined we can state what we mean by a solution to a differential
equation driven by a geometric c√†dl√†g rough path.
14Definition A.2 (Marcus RDE) .Letx‚àà‚Ñ¶D
p(Rd)andf= (f1, . . . , f d)beLipŒ≥vector fields on Re
withŒ≥ > p . For an initial condition a‚ààRe, letÀÜy‚ààCp([0, T],Re)be the solution to the classical
RDE driven by the Marcus interpolation ÀÜx‚àà‚Ñ¶C
p(Rd)
dÀÜyt=f(ÀÜyt)dÀÜxt,ÀÜy0=a.
Define the solution y‚ààDp([0, T],Re)to the Marcus RDE
dyt=f(yt)‚ãÑdxt, y 0=a (8)
to be y= ÀÜy‚ó¶Œ∑x, where Œ∑xis the reparameterisation introduced in Definition A.1.
A.1 Metrics on the space of c√†dl√†g rough paths
Chevyrev and Friz [7]introduce a metric Œ±pon‚Ñ¶D
p(Rd)with respect to which 1) geometric c√†dl√†g
rough paths can be approximated with a sequence of continuous paths [ 7, Section 3.2] and 2) the
solution map (y0,x)7‚Üí(x, y)of the Marcus RDE (8) is locally Lipschitz continuous [ 7, Theorem
3.13].
We write Œõfor the set of increasing bijections from [0, T]to itself. For a Œª‚ààŒõwe let |Œª|=
supt‚àà[0,T]|Œª(t)‚àít|. We first define the Skorokhod metric as well as a Skorokhod version of the
usual p-variation metric.
Definition A.3. Forp‚â•1andx,y‚ààDp([0, T], E), we define
œÉ‚àû(x,y) = inf
Œª‚ààŒõmax(
|Œª|,sup
t‚àà[0,T]d((x‚ó¶Œª)t,yt))
,
œÉp(x,y) = inf
Œª‚ààŒõmax{|Œª|, dp(x‚ó¶Œª,y)}.
It turns out that the topology induced by œÉpis too strong. In particular, it is not possible to approximate
paths with jump discontinuities with a sequence of continuous paths (see Section 3.2 in [ 7]). For
x‚àà‚Ñ¶D
p(Rd)andf= (f1, . . . , f d)a family of vector fields in LipŒ≥‚àí1(Re)with Œ≥ > p , let
Œ¶f(y, s, t ;x)denote the solution to the Marcus RDE dyt=f(yt)‚ãÑdxtinitialized at ys=yand
evaluated at time t. We define the set
Jf=n
((a, b),(a‚Ä≤, b‚Ä≤))|a,a‚Ä≤‚ààG‚åäp‚åã(Re),Œ¶f(b,0,1;œï(a,a‚Ä≤)) =b‚Ä≤o
.
and, on it, the path function
œïf((a, b),(a‚Ä≤, b‚Ä≤))t= (œï(a,a‚Ä≤),Œ¶f(b,0,1;œï(a,a‚Ä≤)t)).
Finally, we let Df
p([0, T], G‚åäp‚åã(Rd)√óRe)be the space of c√†dl√†g paths z= (x, y)onG‚åäp‚åã(Rd)√óRe
of bounded p-variation such that (zt‚àí,zt)‚ààJffor all jump times tofz. To keep notation simple,
we shall write Df
pwhen this does not cause any confusion. Naturally, if yis the solution to the
Marcus RDE dyt=f(yt)‚ãÑdxt, we have (x, y)‚ààDf
p. For a z= (x, y)‚ààDf
pwe may define the
Marcus interpolation by interpolating the jumps using œïf. Let ÀÜzŒ¥denote this interpolation but with
rkreplaced by Œ¥rkforŒ¥ >0and similarly for ÀÜxŒ¥withx‚àà‚Ñ¶D
p(Rd).
Definition A.4. Forf= (f1, . . . , f d)a family of vector fields in LipŒ≥‚àí1(Re)withŒ≥ > p , let
z,z‚Ä≤‚ààDf
pwithz= (x, y)andz‚Ä≤= (x‚Ä≤, y‚Ä≤)and define
Œ±p(x,x‚Ä≤) = lim
Œ¥‚Üí0œÉp(ÀÜxŒ¥,ÀÜx‚Ä≤Œ¥),
Œ±p(z,z‚Ä≤) = lim
Œ¥‚Üí0œÉp(ÀÜzŒ¥,ÀÜz‚Ä≤Œ¥).
Remark A.1.It is proven in [ 7] that in both cases the limit in Œ±pexists, is independent of the choice
ofrk, and that it is indeed a metric on ‚Ñ¶D
p(Rd)resp. Df
p.
Theorem A.1 (Theorem 3.13 + Proposition 3.18, [ 7]).Letf= (f1, . . . , f d)be a family of vector
fields in LipŒ≥‚àí1(Re)withŒ≥ > p . Then,
151. The solution map
Re√ó(‚Ñ¶D
p(Rd), Œ±p)‚Üí(Df
p, Œ±p)
(y0,x)7‚Üíz= (x, y)
of the Marcus RDE dyt=f(yt)‚ãÑdxtinitialized at y0‚ààReis locally Lipschitz.
2. On sets of bounded p-variation, the solution map
Re√ó(‚Ñ¶D
p(Rd), œÉ‚àû)‚Üí(Dp([0, T],Re), œÉ‚àû)
(y0,x)7‚Üíy
of the Marcus RDE dyt=f(yt)‚ãÑdxtinitialized at y0‚ààReis continuous.
Now, let C1
0(Rd)be the space of absolutely continuous functions on Rd.
Definition A.5. We define the space of geometric c√†dl√†g p-rough paths ‚Ñ¶D
0,p(Rd)as the closure of
C1
0(Rd)in‚Ñ¶D
p(Rd)under the metric Œ±p.
Remark A.2.A c√†dl√†g semi-martingale x‚ààDp([0, T],Rd)can be canonically lifted to a geometric
c√†dl√†g p-rough path, with p‚àà[2,3), by enhancing it with its two-fold iterated Marcus integrals, i.e.
xs,t= (1, xs,t,Z
s,t(xs‚àíxu)‚äó ‚ãÑdxu)‚ààG2(Rd)
where the integral is defined in a similar spirit to Definition A.2 (see, for example, [ 18] for more
information). The solution to the corresponding Marcus RDE agrees a.s. with the solution to the
usual c√†dl√†g Marcus SDE which, in turn, if xhas a.s. continuous sample paths, agrees a.s. with the
solution to the Stratonovich SDE. See, e.g., Proposition 4.16 in [7].
A.2 Signature
The extended tensor algebra over Rdis given by
T  
Rd
=‚àûY
n=0 
Rd‚äón
equipped with the usual addition +and tensor multiplication ‚äó. An element a‚ààT  
Rd
is
a formal series of tensors a= (a0,a1, . . .)such that an‚àà(Rd)‚äón. We define the projections
œÄn:T  
Rd
‚Üí(Rd)‚äóngiven by œÄn(a) =an. Let ÀúT((Rd))be the subset of T((Rd))such that
theœÄ0(a) = 1 for all a‚ààÀúT((Rd)). Finally, we define the set of group-like elements,
G(‚àó)=n
a‚ààÀúT  
Rd
|œÄn(a)‚ààGN 
Rd
for all n‚â•0o
Definition A.6. Letp‚â•1andx‚àà‚Ñ¶D
p(Rd). The signature of xis the path S(x) : [0, T]7‚ÜíG(‚àó)
such that, for each N‚â•0,
dS(x)N
t=S(x)N
t‚äó ‚ãÑdxt, S(x)N
0=1‚ààGN 
Rd
. (9)
Remark A.3.Uniqueness and existence of the signature follow from the continuous analog. Indeed,
by definition, (9) is equivalent to a continuous linear RDE.
Remark A.4.The signature, as defined here, is also known as the minimal jump extension of xand
was first introduced in [ 15]. It was further explored in [ 13] where it was also shown that it acts as a
universal feature map.
In the continuous case, it is well known that the signature characterizes paths up to tree-like equiv-
alence . Two continuous paths x,yare said to be tree-like equivalent if there exists a continuous
non-negative map h: [0, T]‚ÜíR+such that h(0) = h(T)and
‚à•xs,t‚àíys,t‚à• ‚â§h(s) +h(t)‚àí2 inf
u‚àà[s,t]h(u).
This can be generalized to c√†dl√†g paths in the following way. We say that two c√†dl√†g paths x,y
are tree-like equivalent, or x‚àºty, if their their Marcus interpolations (see Def. A.1), ÀÜxandÀÜy,
are tree-like equivalent. It is straightforward to check that this indeed is an equivalence relation on
‚Ñ¶D
p(Rd). Perhaps more interestingly, we obtain the following result. For ease of notation we shall
henceforth mean S(x)Twhen omitting the subscript from the signature.
16Proposition A.1. Letp‚â•1. The map S(¬∑) : ‚Ñ¶D
p(Rd)‚ÜíG(‚àó)is injective up to tree-like equivalence,
i.e.,S(x) =S(y)iffx‚àºty.
Proof. The result follows from the continuous case upon realizing that S(x) =S(ÀÜx)and analogously
fory.
A.3 Young pairing
In many cases, given a geometric c√†dl√†g rough path x‚àà‚Ñ¶D
0,p(Rd)withp‚àà[2,3)and a path
h‚ààD1([0, T],Re)of bounded variation one is interested in constructing a new rough path y‚àà
‚Ñ¶D
0,p(Rd+e)such that the first level of yis given by y= (x, h). In the continuous case this can be
done by using the level two information x2andR
dh‚äódhto fill in the corresponding terms in y2
and using the well-defined Young cross-integrals to fill in the rest. The resulting level 2 rough path is
called the Young pairing ofxandhand we will denote it by y=P(x, h). The canonical example
to keep in the mind is when ht=t, that is, we want to augment the rough path with an added time
coordinate (see Def. A.8). In the c√†dl√†g case one needs to be more careful in defining the appropriate
Marcus lift.
Definition A.7 (Definition 3.21 [ 7]).Letx‚àà‚Ñ¶D
0,p(Rd)withp‚â•1andh‚ààD1([0, T],Re). Define
the path z= (x, h)and the corresponding Marcus lift ÀÜz= (ÀÜx,ÀÜh). The Young pairing of xandhis
thep-rough path P(x, h)‚àà‚Ñ¶D
p(Rd+e)such that
P(x, h) =P(ÀÜx,ÀÜh)‚ó¶Œ∑z
where P(ÀÜx,ÀÜh)is the usual Young pairing of a continuous rough path and a continuous bounded
variation path (see Def. 9.27 in [17]).
We can then construct the time augmented rough path as the rough path obtained by the Young pairing
with the simple continuous bounded variation path ht=t. It turns out that this pairing is continuous
as a map from ‚Ñ¶D
0,p(Rd)to‚Ñ¶D
0,p(Rd+1).
Definition A.8. Letx‚àà‚Ñ¶D
0,p(Rd). The time augmented version of xis the unique rough path
Àúx‚àà‚Ñ¶D
0,p(Rd+1)obtained by the Young pairing P(x, h)ofxwith the continuous bounded variation
pathht=t.
Proposition A.2. Letp‚àà[1,3). Then, the map x7‚ÜíÀúxis continuous and injective as a map from
‚Ñ¶D
0,p(Rd)to‚Ñ¶D
0,p(Rd+1).
Proof. LetX= ‚Ñ¶D
0,p(Rd)be a metric space when equipped with Œ±p. Fixx‚àà X and let xnbe a
sequence of absolutely continuous paths converging in Xtox. We shall first show that Àúxnthen
converges to Àúx. Since xndoes not have any jumps and any reparameterisation of xnis still absolutely
continuous, we may assume that
Œ±p(x, xn) = lim
Œ¥‚Üí0dp(ÀÜxŒ¥, xn)‚Üí0
forn‚Üí ‚àû . Define z= (x, h)andÀÜzd= (ÀÜxŒ¥,ÀÜhŒ¥)the Marcus interpolation with Œ∑x,Œ¥the reparam-
eterisation such that z=ÀÜzŒ¥‚ó¶Œ∑x,Œ¥. Furthermore, let P(x, h)be the Young pairing of xandh. By
definition,
Œ±p(P(x, h), P(xn, h)) = lim
Œ¥‚Üí0œÉp
P(ÀÜxŒ¥,ÀÜhŒ¥), P(xn, h)
‚â§lim
Œ¥‚Üí0dp
P(ÀÜxŒ¥,ÀÜhŒ¥), P(xn, h)
‚â§lim
Œ¥‚Üí0C
dp(ÀÜxŒ¥, xn) +d1(ÀÜhŒ¥, h)
‚Üí0
forn‚Üí ‚àû where Cis just some generic constant depending only on p. The last inequality follows
from 9.32 in [ 17]. Thus, if y‚àà X is such that Œ±p(x,y)< œµ, we can choose another sequence ynof
absolutely continuous paths and N‚â•1large enough so that
Œ±p(P(x, h), P(y, h))‚â§2œµ+Œ±p(P(xn, h), P(yn, h)),
17Œ±p(xn, yn)‚â§2œµ
for all n‚â•N. By Remark 3.6 in [ 7], we then have that, up to choosing a large N,dp(xn, yn)‚â§œµ
for all n‚â•Nand therefore, once more appealing to Theorem 9.32 in [17],
Œ±p(P(xn, h), P(yn, h))‚â§2Cœµ.
In conclusion, Œ±p(P(x, h), P(y, h))‚â§2(1 + C)œµwhich proves the result.
Injectivity follows from [13].
A.4 Event RDEs
The results of Section 3.3 hold in more generality. In fact, we can define Event RDEs similar to
Definition 3.1 where the inter-event dynamics are given by Marcus RDEs driven by c√†dl√†g rough
paths. Utilizing the correspondence between solutions to Marcus RDEs and Marcus SDEs, it then
follows that the results in the main body of the paper are a special case of the results given below.
Definition A.9 (Event RDE) .Letp‚â•1andN‚ààNbe the number of events. Let x‚àà‚Ñ¶D
p(Rd)and
f= (f1, . . . , f d)be a family of LipŒ≥onRewithŒ≥ > p . LetE:Re‚ÜíRandT:Re‚ÜíRebe an
event and transition function respectively. We say that 
y,(œÑn)N
n=1
is a solution to the Event RDE
parameterised by (y0,x, f,E,T, N)ifyT=yN
T,
yt=NX
n=0yn
t1[œÑn,œÑn+1)(t), œÑ n= inf
t > œÑ n‚àí1:E(yn‚àí1
t‚àí) = 0	
, (10)
withE(yn
œÑn)Ã∏= 0and
dy0
t=f(y0
t)‚ãÑdxt,started at y0
0=y0, (11)
dyn
t=f(yn
t)‚ãÑdxt,started at yn
œÑn=T 
yn‚àí1
œÑn‚àí
. (12)
Existence and uniqueness of solutions to Event RDEs is proven in the same way as for Event SDEs.
Indeed, under the usual assumption that the vector fields fareLipŒ≥, forŒ≥ > p , a unique solution
to(11) exists. In fact, the solution map ys√ó(s, t)7‚Üíytis a diffeomorphism for every fixed
0‚â§s < t‚â§T(see, e.g., Theorem 3.13 in [ 7]). It follows that we can iteratively define a unique
sequence of solutions yn‚ààDp([tn, T],Rd). Finally, as mentioned in Remark A.2, if the driving
rough path xis the Marcus lift of a semi-martingale, the inter-event solutions agree almost surely
with the solutions to the corresponding Marcus SDE.
Theorem A.2. Under Assumptions 3.1-3.2, there exists a unique solution (y,(œÑn)N
n=1)to the Event
RDE of Definition A.9. Furthermore, if xis the Marcus lift of a Brownian motion, the solution
coincides almost surely with the solution to the corresponding Event SDE as given in Def. 3.1.
Hence, the Event SDEs considered in the main text are special cases of Event RDEs driven by the
Marcus lift of a Brownian motion. Yet, the more general formulation of Event RDEs allows to treat,
using the same mathematical machinery of rough path theory a much larger family of driving noises
such as fractional Brownian motion or even smooth controls. Also, since the driving rough path
is allowed to be c√†dl√†g, the model class given by Def. A.9 includes cases where the inter-event
dynamics are given by Marcus SDEs driven by general semi-martingales.
B Proof of Theorem 3.2
The proof of Theorem 3.2 presented below covers the case where (y,(œÑn)N
n=1)is the solution to an
Event RDE. Throughout we consider vector fields ¬µ‚ààLip1, œÉ‚ààLip2+œµand specialise to Event
RDEs where the inter-event dynamics are given by
dyn
t=¬µ(yn
t)dt+œÉ(yn
t)‚ãÑdxt, (13)
where x‚àà‚Ñ¶D
p(Rd). The notation above deserves some clarification. One can define the vector field
f= (¬µ, œÉ)and the Young pairing Àúxtofxandht=t. Assuming ¬µ‚ààLip2+œµwe can then view yn
tas
the unique solution to the Marcus RDE
dyn
t=f(yn
t)‚ãÑÀúxt.
18Alternatively, if one is not ready to impose the added regularity on the drift ¬µ, one can view 13
as a RDE with drift as in Ch. 12 in [ 17]. To accommodate this more general case where the path
driving the diffusion term might be 1) c√†dl√†g and 2) is not restricted to be the rough path lift of a
semi-martingale, we shall need the following two additional assumptions:
Assumption B.1.For any n‚àà[N], there exists a non-empty interval In= (œÑn‚àíŒ¥n, œÑn+Œ¥n)such
thatxis continuous over In. In other words, the c√†dl√†g rough path x, does not jump in small intervals
around the event times (œÑn).
Assumption B.2.For all 0‚â§n‚â§Nwe define sn=œÑn‚àíŒ¥n/2andtn=œÑn+1+Œ¥n+1/2. It holds
thatx‚àà‚Ñ¶D
0,p([sn, tn],Rd), i.e.,xis a geometric p-rough path on the intervals [sn, tn].
Remark B.1.Note that Assumption B.1 trivially holds if xis continuous. Otherwise, it is enough to
assume, e.g., that xis the Marcus lift of a finite activity L√®vy process. Furthermore, by the properties
of the metric Œ±p, ifxis the canonical Marcus lift of a semi-martingale x‚ààDp([s, t],Rd‚àí1), then
there exists a sequence (xm)of piece-wise linear paths xm‚ààC1
0([0, T],Rd‚àí1)such that
Œ±p,[sn,tn](xm,x)‚Üí0asm‚Üí ‚àû a.s.
See, e.g. [ 7, Example 4.21]. The setting of Section 3.3 is therefore a special case of the setting
considered here and Theorem 3.2 follows from the proof below.
We shall need two technical lemmas for the proof of 3.2
Lemma B.1. Assume that Assumptions 3.1-3.5 and B.1-B.2 are satisfied. Then, there exists an open
ballB0‚äÇOsuch that the following holds:
1. For all a‚ààB0,|œÑ(a)|=N.
2. For any n‚àà[N], the maps
B0‚àãa7‚Üí
œÑn(a), yn‚àí1
œÑn(a)(a)
are continuous.
3.For the sequence (xm)as given in Assumption B.2 and (ym,(œÑm
n)N
n=1)the corresponding
Event RDE solution, for all n‚àà[N], it holds that
lim
m‚Üí‚àûsup
a‚ààB0
|œÑm
n(a)‚àíœÑn(a)|+ym,n‚àí1
œÑmn(a)(a)‚àíyn‚àí1
œÑn(a)(a)
= 0.
Proof. Recall that Œ¶(y, s, t ;x)is the solution map or flow of the differential equation
dyu=f(yu)‚ãÑdÀúxu, y s=y
evaluated at time t. The first step will be to prove continuity at y0. In particular, let ym
0‚ààO
approach y0formgoing to infinity and denote the solutions to the corresponding Event RDEs by
ym,(œÑm
n)Nm
n=1
. We claim that limm‚Üí‚àûNm=Nand
lim
m‚Üí‚àûœÑm
n=œÑn,lim
m‚Üí‚àûym,n‚àí1
œÑmn=yn
œÑn.
To see this, note that, by Theorem A.1, there exists a sequence Œªm‚ààŒõof continuous reparameterisa-
tions such that |Œªm| ‚Üí0and
sup
(s,t)‚àà‚àÜT|Œ¶(y0, s, t;x)‚àíŒ¶(ym
0, Œªm(s), Œªm(t);x)| ‚Üí0 (14)
form‚Üí ‚àû . Note, furthermore, that Œ¶(ym
0, s, t;x‚ó¶Œªm) = Œ¶( ym
0, Œªm(s), Œªm(t);x)for all (s, t)‚àà
‚àÜT. We let
Àúym,(ÀúœÑm
n)Nm
n=1
be the solution to the Event RDE where (y0,x)is replaced by (ym
0,x‚ó¶
Œªm). It suffices to prove that, for all 1‚â§n‚â§N,
lim
m‚Üí‚àûÀúœÑm
n=œÑn,lim
m‚Üí‚àûÀúym,n‚àí1
ÀúœÑmn=yn
œÑn. (15)
Indeed, since ÀúœÑm
n=Œª‚àí1
m(œÑm
n)and|Œªm| ‚Üí0, it then follows that œÑm
n‚ÜíœÑnform‚Üí ‚àû . Furthermore,
we have Àúym,n‚àí1
ÀúœÑmn=ym,n‚àí1
œÑmn.
19We shall proof (15) using an inductive argument. We have that
y0
t= Œ¶(y0,0, t;x),‚àÄt‚àà[0, œÑ1],
Àúym,0
t= Œ¶(ym
0,0, t;x‚ó¶Œªm),‚àÄt‚àà[0,ÀúœÑm
1].
Now fix some 0< œµ < Œ¥ 1where Œ¥1is given in Assumption B.1. Note that |E(y0
t)|>0for all
t‚àà[0, œÑ1‚àíœµ]and therefore, by (14), it follows that there exists an m0‚ààNsuch that, for all m‚â•m0,
inf
t‚àà[0,œÑ1‚àíœµ]|E(Œ¶(ym
0,0, t;x‚ó¶Œªm))|>0
so that ÀúœÑm
1‚â•œÑ1‚àíœµ. Next, for some small 0< Œ∑ < œµ , Assumption 3.4 and the Mean Value Theorem
imply the existence of a+
Œ∑=r+
Œ∑y0
œÑ1‚àí(1‚àír+
Œ∑)y0
œÑ1+Œ∑, and a‚àí
Œ∑=r‚àí
Œ∑y0
œÑ1‚àíŒ∑+ (1‚àír‚àí
Œ∑)y0
œÑ1with
r+
Œ∑, r‚àí
Œ∑‚àà(0,1)such that
E 
y0
œÑ1+Œ∑
=E 
y0
œÑ1
+‚àáE(a+
Œ∑)ZœÑ1+Œ∑
œÑ1¬µ(y0
s)dys,
E 
y0
œÑ1‚àíŒ∑
=E 
y0
œÑ1
‚àí ‚àáE (a‚àí
Œ∑)ZœÑ1
œÑ1‚àíŒ∑¬µ(y0
s)dys,
But then, by Assumption 3.5 and the fact that E(y0
œÑ1) = 0 , forŒ∑small enough, E(y0
œÑ1+Œ∑)andE(y0
œÑ1‚àíŒ∑)
must lie on different sides of 0. Assumption B.1 and eq. (14) then yield the existence of a m1‚â•m0
such that ÀúœÑm
1‚â§œÑ1+Œ∑‚â§œÑ1+œµandinft‚àà[0,œÑ1+Œ∑]|E(Àúym,0
t)|>0for all m‚â•m1. It follows that
ÀúœÑm
1‚ÜíœÑ1. Finally, note that
Àúym,0
ÀúœÑm
1‚àíy0
œÑ1‚â§Àúym,0
ÀúœÑm
1‚àíy0
ÀúœÑm
1+y0
ÀúœÑm
1‚àíy0
œÑ1.
Another application of (14) shows that the first term on the right hand side goes to 0 for m‚Üí ‚àû and
second term vanishes by Assumption B.1.
To prove the inductive step, assume that (15) holds for i‚â§n. For all t‚àà[œÑn, œÑn+1]it holds that
Àúym,n
t= Œ¶
T
Àúym,n‚àí1
ÀúœÑmn
,ÀúœÑm
n, t;x‚ó¶Œªm
, yn
t= Œ¶ 
T 
yn‚àí1
œÑn
, œÑn, t;x
and, since Àúym,n‚àí1
ÀúœÑmn‚Üíyn‚àí1
œÑn,ÀúœÑm
n‚ÜíœÑn, andTis continuous,
lim
m‚Üí‚àûsup
t‚àà[œÑn,T]Œ¶
T
Àúym,n‚àí1
ÀúœÑmn
,ÀúœÑm
n, t;x‚ó¶Œªm
‚àíŒ¶ 
T 
yn‚àí1
œÑn
, œÑn, t;x= 0
whence the same argument as above proves that (15) also holds for n+ 1. This completes the proof
of the claim.
Now, by continuity at y0, it follows that there exists some small r >0such that for all a‚ààBr(y0)
it holds that |œÑ(a)|=NandœÑn(a)‚àà(œÑn‚àíŒ¥n/2, œÑn+Œ¥n/2)for all n‚àà[N]where Œ¥nis as in
Assumption B.1. Furthermore, since Assumption 3.1-3.5 and B.1-B.2 still hold for a‚ààBr(y0), the
same argument as above can be applied to show that œÑn(a)andyn‚àí1
œÑn(a)(a)are continuous at a. This
proves parts 1 and 2.
To prove part 3 we employ a similar induction argument to the one above. First, note that, by Theorem
A.1, there exists a constant C >0not depending on xsuch that
Œ±p,[0,t0] 
ym,0(a), y0(a)
‚â§CŒ±p,[0,t0](xm,x).
Since the latter term does not depend on yand goes to 0 for mgoing to infinity, we find that
lim
m‚Üí‚àûsup
a‚ààBr(y0)Œ±p,[0,t1] 
ym,0(a), y0(a)
= 0. (16)
Recall, yŒ¥,0(a)is the continuous path obtained by the Marcus interpolation with Œ¥rkinstead of rk
and similarly for ym,Œ¥,0(a). Note that ym,Œ¥,0(a) =ym,0(a)by continuity. Letting œÑm
1(a)andœÑŒ¥
1(a)
denote the first event time of ym,0(a)andyŒ¥,0(a)respectively, we have, for all m‚ààN
sup
a‚ààBr(x0)|œÑm
1(a)‚àíœÑ1(a)| ‚â§ sup
a‚ààBr(y0)lim
Œ¥‚Üí0 œÑm
1(a)‚àíœÑŒ¥
1(a)+œÑŒ¥
1(a)‚àíœÑ1(a)
.
20Now, let B0=Br(y0). Since œÑ1(a)‚àà(œÑ1‚àíŒ¥1/2, œÑ1+Œ¥1/2)for all a‚ààB0andxis continuous over
this interval, it follows thatœÑŒ¥
1(a)‚àíœÑ1(a)goes to 0 as Œ¥‚Üí0for each a‚ààB0. Furthermore, by
definition of the metric Œ±p, eq. (16), and the fact that ym,0
0(a) =a=y0
0(a), for each a‚ààB0, a similar
argument as the one employed in the beginning of the proof then shows that |œÑm
1(a)‚àíœÑŒ¥
1(a)| ‚Üí0as
Œ¥‚Üí0and, thus, limm‚Üí‚àûsupa‚ààB0|œÑm
1(a)‚àíœÑ1(a)|= 0. Finally, starting from the inequalityym,0
œÑm
1(a)(a)‚àíy0
œÑ1(a)(a)‚â§ym,0
œÑm
1(a)(x)‚àíyŒ¥,0
œÑŒ¥
1(a)(a)+yŒ¥,0
œÑŒ¥
1(a)(a)‚àíy0
œÑ1(a)(a)
and taking the limit as Œ¥‚Üí0and then the supremum over x‚ààB0on both sides, we can argue in
exactly the same way to show that part 3 holds for n= 1. We can then argue by induction, just as in
the first part of the proof, to show that it holds for all subsequent event times as well. Thus, the set
B0satisfies all the stated requirements.
Lemma B.2. Let Assumption B.1 hold and xmbe as in Assumption B.2. Then, for all n‚àà[N]and
p‚Ä≤> p,
lim
m‚Üí‚àûdp‚Ä≤,[s,t](xm,x) = 0 ,for any œÑn‚àíŒ¥n/2‚â§s < t‚â§œÑn+Œ¥n/2.
Proof. Fix some n‚àà[N],p‚Ä≤> pandœÑn‚àíŒ¥n/2‚â§s < t‚â§œÑn+Œ¥n/2. Note that, for any continuous
reparameterisation Œª‚ààŒõ,m‚ààN, and Œ¥ >0, it holds that
dp‚Ä≤,[s,t](xm,x)‚â§dp‚Ä≤,[s,t](xm, xm‚ó¶Œª) +dp‚Ä≤,[sn,tn](xm‚ó¶Œª,ÀÜxŒ¥) +dp‚Ä≤,[s,t](ÀÜxŒ¥,x),
where ÀÜxŒ¥is the Marcus interpolation of xover the interval [sn, tn]. Taking the infimum over Œª‚ààŒõ
and the limit as Œ¥‚Üí0on both sides, we obtain
dp‚Ä≤,[s,t](xm,x)‚â§Œ±p‚Ä≤,[sn,tn](xm,x) + lim
Œ¥‚Üí0dp‚Ä≤,[s,t](ÀÜxŒ¥,x).
The first term on the right hand side goes to 0 as m‚Üí ‚àû by Assumption B.2. Furthermore, since, by
Assumption B.1, xis continuous on (œÑn‚àíŒ¥n, œÑn+Œ¥n), it follows that d‚àû,[s,t](ÀÜxŒ¥,x)goes to 0 for
Œ¥‚Üí ‚àû . But the result then follows from Proposition 8.15 and Lemma 8.16 in [17].
Proof of Theorem 3.2. Step 1: Assume that x‚ààC1([0, T],Rd‚àí1). By [ 17, Theorem 4.4], the
Jacobian ‚àÇy0
texists and satisfies (7)for all t‚àà[0, œÑ1). We shall prove that relations (6)and(7)
hold for all n‚àà[N]by induction. Thus, assume that ‚àÇyk
tand‚àÇœÑkexist for all t‚àà[œÑk, œÑk+1)and
k‚â§n‚àí1and satisfy the stated relations. To emphasise the dependence on the initial condition, we
will sometimes use the notation yn=yn(y0)andœÑn=œÑn(y0)for the solution of the Event RDE
started at y0. We want to show that, for arbitrary h‚ààRe, the following limits
lim
œµ‚Üí0œÑœµ
n‚àíœÑn
œµand lim
œµ‚Üí0yn,œµ
t‚àíyn
t
œµfort‚àà[œÑn, œÑn+1)
exist and satisfy the stated expressions, where œÑœµ
n=œÑn(y0+hœµ)andyn,œµ=yn(y0+hœµ).
For any œµ >0, because Eis continuously differentiable, the Mean Value Theorem implies that there
exists cœµ‚ààReon the line connecting yn‚àí1
œÑntoyn‚àí1
œÑœµnand another c‚Ä≤
œµ‚ààReon the line connecting
yn‚àí1,œµ
œÑœµntoyn‚àí1
œÑœµnsuch that
E 
yn‚àí1
œÑn
=E
yn‚àí1
œÑœµn
+‚àáE(cœµ)
yn‚àí1
œÑn‚àíyn‚àí1
œÑœµn
=E
yn‚àí1
œÑœµn
+‚àáE(cœµ) 
¬µ(yn‚àí1
œÑn)(œÑn‚àíœÑœµ
n) +œÉ 
yn‚àí1
œÑn
(xœÑn‚àíxœÑœµn) +o(|œÑn‚àíœÑœµ
n|)
,
E
yn‚àí1,œµ
œÑœµn
=E
yn‚àí1
œÑœµn
+‚àáE(c‚Ä≤
œµ)
yn‚àí1,œµ
œÑœµn‚àíyn‚àí1
œÑœµn
=E
yn‚àí1
œÑœµn
+‚àáE(c‚Ä≤
œµ) 
œµ 
‚àÇyn‚àí1
œÑn
h+o(œµ)
,
where the last equality follows from the induction hypothesis. We have E(yn‚àí1
œÑn) = 0 = E(yn‚àí1,œµ
œÑœµn).
Thus, by rearranging, we find that
œÑœµ
n‚àíœÑn
œµ=‚àí‚àáE(yn‚àí1
œÑn)‚àÇyn‚àí1
œÑnh
‚àáE(yn‚àí1œÑn)
¬µ(yn‚àí1œÑn) +œÉ(yn‚àí1œÑn)xœÑn‚àíxœÑœµn
œÑn‚àíœÑœµn+o(1)
=‚àí‚àáE(yn‚àí1
œÑn)‚àÇyn‚àí1
œÑnh
‚àáE(yn‚àí1œÑn)¬µ(yn‚àí1œÑn)+o(1)
21where the second equality follows from Assumptions 3.4 and 3.5.
Assume for now that œÑœµ
n< œÑn. By another application of the Mean Value Theorem, there exists
cœµ‚ààReon the line connecting yn‚àí1
œÑntoyn‚àí1
œÑœµnsuch that
yn,œµ
œÑn‚àíyn
œÑn=yn,œµ
œÑn‚àí T 
yn‚àí1
œÑn
=yn,œµ
œÑn‚àí T
yn‚àí1
œÑœµ
n
‚àí ‚àáT (cœµ)(yn‚àí1
œÑn‚àíyn‚àí1
œÑœµ
n)
=yn,œµ
œÑœµn+¬µ(yn,œµ
œÑn)(œÑn‚àíœÑœµ
n) +œÉ 
yn,œµ
œÑn
(xœÑn‚àíxœÑœµn)‚àí T
yn‚àí1
œÑœµn
‚àí ‚àáT (cœµ) 
¬µ(yn‚àí1
œÑn)(œÑn‚àíœÑœµ
n) +œÉ 
yn‚àí1
œÑn
(xœÑn‚àíxœÑœµn) +o(|œÑn‚àíœÑœµ
n|)
=T
yn‚àí1,œµ
œÑœµn
‚àí T
yn‚àí1
œÑœµn
+ 
¬µ(yn,œµ
œÑn)‚àí ‚àáT (cœµ)¬µ(yn‚àí1
œÑn)
(œÑn‚àíœÑœµ
n)
+ 
œÉ(yn
œÑn)‚àí ‚àáT (cœµ)œÉ(yn‚àí1
œÑn)
(xœÑn‚àíxœÑœµn) +o(|œÑn‚àíœÑœµ
n|)
Therefore
yn,œµ
œÑn‚àíyn
œÑn
œµ=‚àáT(yn‚àí1
œÑn)‚àÇyn‚àí1
œÑnh+ 
¬µ(yn
œÑn)‚àí ‚àáT (yn‚àí1
œÑn)¬µ(yn‚àí1
œÑn)
‚àÇœÑnh+o(1)
where we used Assumption 3.3, the chain rule and the existence of ‚àÇœÑn. Finally, for any t‚àà(œÑn, œÑn+1],
equation (7)follows from the fact that we can write yn
t= Œ¶( yn
s, s, t, x )for all œÑn‚â§s < t . In
particular, by the chain rule, we find that
‚àÇyn
t=
‚àÇynsŒ¶(yn
s, s, t)‚àÇyn
s
s=œÑn=‚àÇynœÑnyn
t[‚àÇyn
s]s=œÑn.
Step 2: Consider now the general case of x‚àà‚Ñ¶p(Re)and let (ym,(œÑm
nm)Nmnm)denote the solution
to the Event RDE where xis replaced by the piece-wise linear approximation xm. With ‚àÇyn,m
tand
‚àÇœÑm
ndenoting the corresponding derivatives, we saw in the previous step that both exist and satisfy
(6)-(7). We let Rn
tandœÅndenote the right hand side of (7)and(6)respectively. This step consists of
proving that, for n‚àà[N]andt‚àà(œÑn, tn),
lim
m‚Üí‚àû{|œÑm
n‚àíœÑn|+|ym,n
t‚àíyn
t|}= 0 (17)
and for some open ball B0around y0
lim
m‚Üí‚àûsup
a‚ààB0{|‚àÇœÑm
n(a)‚àíœÅn(a)|+‚à•‚àÇym,n
t(a)‚àíRn
t(a)‚à•}= 0. (18)
By Lemma B.1 and continuity of Twe have that T(ym,n‚àí1
œÑmn)converges to T(yn‚àí1
œÑn)andœÑm
n
converges to œÑnasm‚Üí+‚àû. Then, because yn
t= Œ¶(T(yn‚àí1
œÑn), œÑn, t;x)andym,n
t =
Œ¶(T(ym,n‚àí1
œÑmn), œÑm
n, t;xm), equation (17) follows from, Lemma B.2 and Corollary 11.16 in [ 17].
In fact, since B0was constructed in Lemma B.1 in such a way that œÑn(a)< tnfor all a‚ààB0we
also get that
lim
m‚Üí‚àûsup
a‚ààB0‚àÇyn
œÑn(a)(a)Œ¶
yn
œÑn(a)(a), œÑn(a), t;x
‚àí‚àÇym,n
œÑmn(a)(a)Œ¶
ym,n
œÑmn(a)(a), œÑm
n(a), t;xm= 0.
by the same corollary in [17]. Thus, to prove (18), it suffices to show that, for all n‚àà {1, ..., N},
lim
m‚Üí‚àûsup
a‚ààB0‚àÇym,n‚àí1
œÑmn(a)(a)‚àíRn‚àí1
œÑn(a)(a)= 0.
We shall prove it using another inductive argument starting with n= 1. In this case it suffices to
show that
lim
m‚Üí‚àûsup
a‚ààB0‚à•‚àÇaŒ¶ (a,0, œÑ1(a);x)‚àí‚àÇaŒ¶ (a,0, œÑm
1(a);xm)‚à•= 0.
By [7, Theorem 3.3] we know that the above holds if œÑm
1(a)andœÑ1(a)are replaced by œÑ1+Œ¥1/2.
Now let Œ¶‚àí1be the reverse of the flow map Œ¶, that is,
Œ¶‚àí1(a1, s, t;x) =a0‚áîŒ¶(a0, s, t;x) =a1.
22From Lemma B.1 it follows that y0
œÑ1(a)(a) = Œ¶‚àí1(y0
t0(a), œÑ1(a), t0;x)and, for mlarge enough,
ym,0
œÑm
1(a)(a) = Œ¶‚àí1(ym,0
t0(a), œÑm
1(a), t0;xm). But the result then follows from Lemma B.2 and [ 17,
Corollary 11.16]. To prove the inductive step, assume that (18) holds for all i‚â§n‚àí1. Again, by
inspecting (6) and (7) and using the inductive assumption, one finds that it is enough to show that
lim
m‚Üí‚àûsup
a‚ààB0‚àÇyn‚àí1
œÑn‚àí1Œ¶
yn‚àí1
œÑn‚àí1, œÑn‚àí1, œÑn;x
‚àí‚àÇym,n‚àí1
œÑm
n‚àí1Œ¶
ym,n‚àí1
œÑm
n‚àí1, œÑm
n‚àí1, œÑm
n;xm= 0,
where we suppressed the dependence on afor notational simplicity. This is done exactly as for y0
and completes the proof of Step 2.
Step 3: The third and final step is to combine Step 1 and 2 to finish the proof. So far we have
proven that 1) the theorem holds for continuous paths of bounded variation and 2) (œÑm
n, ym,n
t)
converges to (œÑn, yn
t)and(‚àÇœÑm
n(a), ‚àÇym,n
t(a))converges uniformly to (œÅn(a), Rn
t(a))overa‚ààB0
for all t‚àà(œÑn, tn)andn‚àà[N]. From these results it immediately follows that (œÑn(a), yn
t(a))is
differentiable at a=y0with derivatives given by (œÅn(y0), Rt(y0))for all t‚àà(œÑn, tn). What is left
to show then, is that this also holds for all other t. But this follows immediately from the chain rule
upon realizing that, for any œÑn< s < œÑ n+Œ¥n/2< t < œÑ n+1,
yn
t= Œ¶(yn
s, s, t;x)‚áí‚àÇyn
t=‚àÇynsŒ¶(yn
s, s, t;x)Rn
s(y0) =Rn
t(y0).
C Kernel methods
We give here a brief outline of some of the most central concepts related to kernel methods. For
a more in-depth introduction we refer the reader to [ 45,55,3]. LetXbe a topological space. We
shall in this paper only be concerned with positive definite kernels, that is, symmetric functions
k:X √ó X ‚Üí Rfor which the Gram matrix is positive definite. To such a kernel one may associate a
feature map X ‚ÜíRXsuch that x7‚Üíkx=k(x,¬∑). A reproducing kernel Hilbert space (RKHS) is a
Hilbert space H ‚äÇRXsuch that the evaluation functionals, evx:f7‚Üíf(x), are bounded for each
x‚àà X. For all positive definite kernels there is a unique RKHS H ‚äÇRXsuch that f(x) =‚ü®kx, f‚ü©H
for all f‚àà H andx‚àà X. This is also known as the reproducing property . Furthermore, with H
denoting the linear span of {kx|x‚àà X} , it holds that ¬ØH=H, i.e., His dense in H. Two important
properties of kernels are characteristicness anduniversality .
Definition C.1. Letk:X √ó X ‚Üí Rbe a positive definite kernel. Denote by Hthe linear span
of{kx|x‚àà X} and let F ‚äÇRXbe a topological vector space containing Hand such that the
inclusion map Œπ:H‚Üí F is continuous.
‚Ä¢We say that kis universal to Fif the embedding of Œπ:H‚Üí F is dense.
‚Ä¢We say that kis characteristic to F‚Ä≤if the embedding ¬µ:F‚Ä≤‚ÜíH‚Ä≤,D7‚ÜíD|His injective
Remark C.1.This definition is the one used in [ 8] and is more general then the one usually encountered.
Note that in many cases (all the cases considered here, in fact) F‚Ä≤will contain the set of probability
measures on Xin which case kbeing characteristic implies that the kernel mean embedding ¬µ7‚Üí
EX‚àº¬µkX(¬∑)is injective.
Remark C.2.Often times, instead of starting with the kernel function kand then obtaining the RKHS,
one starts with a feature map F:X ‚Üí H into a RKHS and then defines the kernel as the inner
product in that Hilbert space, i.e., k(x, y) =‚ü®F(x), F(y)‚ü©H. In such cases, it makes sense to ask
whether there are equivalent notions of Fbeing universal and characteristic. This is indeed the case
and the definition is almost the same as above. We refer to Definition 6 in [ 8] for a precise statement.
C.1 Marcus signature kernel
The definition of the signature kernel requires an initial algebraic setup. Let ‚ü®¬∑,¬∑‚ü©1be the Euclidean
inner product on Rd. Denote by ‚äóthe standard outer product of vector spaces. For any n‚ààN,
we denote by ‚ü®¬∑,¬∑‚ü©non(Rd)‚äónthe canonical Hilbert-Schmidt inner product defined for any a=
(a1, . . . , a n)andb= (b1, . . . , b n)in(Rd)‚äónas‚ü®a,b‚ü©n=Qn
i=1‚ü®ai, bi‚ü©1. The inner product ‚ü®¬∑,¬∑‚ü©n
23on(Rd)‚äóncan then be extended by linearity to an inner product ‚ü®¬∑,¬∑‚ü©onÀúT((Rd))defined for any
a= (1, a1, . . .)andb= (1, b1, . . .)inÀúT((Rd))as‚ü®a,b‚ü©= 1 +P‚àû
n=1‚ü®an, bn‚ü©n.
To begin with, let X=D1([0, T],Rd). Ifx‚àà X is c√†dl√†g path, we can define the Marcus signature
in the spirit of Marcus SDEs [ 42,43] as the signature of the Marcus interpolation ofx. This
interpolation, denoted by ÀÜx, is the continuous path on [0, T]obtained from xby linearly traversing
the jumps of xover added fictitious time r >0and then reparameterising so that the path runs over
[0, T]instead of [0, T+r]. The general construction is given in Appendix A. If xis continuous, x
andÀÜxcoincide; thus, without any ambiguity, we can define the Marcus signature S(x)of a general
bounded variation c√†dl√†g path as the tensor series described above, but replacing xwithÀÜx(see also
the definition in A.2).
Since the signature is invariant to certain reparameterisations (Proposition A.1), it is not an injective
map. Injectivity is a crucial property required to ensure characteristicness of the resulting signature
kernel that we will introduce next. One way of overcome this issue is to to augment a path xwith
a time coordinate resulting in the path Àúx= (x, t)5. The Marcus signature kernel is then naturally
defined as the map k:X √ó X ‚Üí Rsuch that k(x, y) =‚ü®S(Àúx), S(Àúy)‚ü©for any x, y‚àà X. As stated in
Theorem C.1, this kernel is universal on compact subsets K‚äÇ X and, equivalently, characteristic to
the space of regular Borel measures on K. However, these properties do not generalize to the whole
space Cb(X,R)of bounded continuous functions from XtoR.
In [8] the authors address this issue in the case of continuous paths by introducing the so-called robust
signature . They define a tensor normalization as a continuous injective map
Œõ :ÀúT  
Rd
‚Üín
a‚ààÀúT  
Rd
| ‚à•a‚à• ‚â§Ro
for some R >0and such that Œõ(a) = (a0, Œª(a)a1, Œª(a)2a2, . . .)for some Œª:ÀúT  
Rd
‚Üí(0,‚àû).
Now, let p‚àà[1,3)and take C1
0(Rd)to be the space of absolutely continuous functions on Rd.
Recall that ‚Ñ¶D
0,p(Rd)is the closure of C1
0(Rd)in‚Ñ¶D
p(Rd)under the metric Œ±p. Throughout we let
X= ‚Ñ¶D
0,p(Rd)be a metric space equipped with Œ±p. Naturally, we can then define the signature
kernel on Xbyk(x,y) =‚ü®S(Àúx), S(Àúy)‚ü©and, similarly, the robust signature kernel kŒõ(x,y) =
‚ü®Œõ(S(Àúx)),Œõ(S(Àúy))‚ü©where Œõis a tensor normalisation.
Theorem C.1. Letp‚â•1,Œõa tensor normalization, and K‚äÇ X compact under Œ±p. Then,
(i)The signature kernel kis universal to F=C(K,R)equipped with the uniform topology
and characteristic to the dual F‚Ä≤, the space of regular Borel measures on K.
(ii)The robust signature kernel kŒõis universal to F=Cb(X,R)equipped with the strict
topology and characteristic to the dual F‚Ä≤, the space of all finite Borel measures on X.
Proof of Theorem C.1. Part(i)follows directly from the proof of Proposition 3.6 in [ 13]. For part
(ii)we shall proof that the feature map F= Œõ‚ó¶Sis universal and characteristic. The result
then follows from Proposition 29 in [ 8]. We start by defining P=X/‚àºtwhere the equivalence
relation ‚àºtis defined in Appendix A.2. We equip Pwith the topology induced by the embedding
S:P ‚Üí ÀúT((Rd+1)). By Proposition A.1, Fis a continuous and injective map from Pinto a
bounded subset of ÀúT((Rd+1)). Thus, H={‚ü®‚Ñì, F‚ü© |‚Ñì‚ààT((Rd+1))‚Ä≤}is a subset of Fthat separates
points. Furthermore, since Ftakes values in the set of group-like elements, His a subalgebra of F
(under the shuffle product). It then follows from Theorem 7 and Theorem 9 in [ 8] that Fis universal
and characteristic. The fact that F‚Ä≤is the space of all finite Borel measures on Xis part (iii) of
Theorem 9 in the same paper. Finally, as per Appendix A.3, the map x7‚ÜíÀúxis a continuous and
injective embedding of XintoPfrom which the result then follows.
Withdkdenoting the MMD for a given kernel k:X √óX ‚Üí R, the following is a direct consequence
of Theorem C.1.
Corollary C.1. Letp‚â•1,Œõa tensor normalization, and K‚äÇ X compact under Œ±p. Then, dkis a
metric on M(K)anddkŒõis a metric on M(X).
5Ifxis a c√†dl√†g rough path, this is done via a Young pairing which results in a c√†dl√†g p-rough path, Àúx, where
the first level is given by (xt, t). For more information, we refer to Appendix A.3.
24D Forward sensitivities for SLIF network
In the general SSNN model, Theorem 3.2 gives the following result.
Proposition D.1. Fix some weight wij‚ààw, a neuron k‚àà[K]and let Gk
tdenote the gradient of
(vk, ik)wrt.wijat time t. Furthermore, define Œ≥:{0,1} ‚ÜíR2such that Œ≥0= (¬µ1,‚àí¬µ2)wlk,
Œ≥1= (¬µ1,0)vreset , and let Œì‚ààR2√ó2be the drift matrix in the inter-spike SDE of (vk, ik). Then,
Gk
t=eŒì(t‚àís) 
Gk
s‚àíŒ≥Œ¥lk‚àÇwijs+Œ¥ilŒ¥jke2
, (19)
where en‚ààR2is the n‚Äôth unit vector, lis the neuron in Pak‚à™ {k}with the most recent spike time
before t, and we denote this spike time by s. Iftis a spike time of neuron kit therefore follows that
‚àÇwijt=Œª(vk
tprev)‚àÇwijtprev‚àíRt
tprev‚àáŒª(vk
r)eT
1Gk
rdr
Œª(vk
t), (20)
where tprev is the previous spike time of neuron k. In the case of a deterministic SNN, formula (20)
is replaced by
‚àÇwijt=‚àíeT
1Gk
t
¬µ1(ik
t‚àívk
t). (21)
Proof. Throughout we fix some t >0and let s < t denote most recent event time preceding twithl
the index of the neuron firing at time s. We define the process dwt= 0dtwithw0=wijand with a
slight abuse of notation we shall write yk
t= (vk
t, ik
t, sk
t, wt). We will leave out the event index nfor
notational simplicity. Since yk
tdepends on ysonly through yk
sand‚àáTlis block diagonal, a direct
consequence of eq. (7) is
Gk
t= (I0)‚àÇyksyk
t 
‚àáTl
j(yk
s‚àí)‚àÇwijyk
s‚àí‚àí 
¬µ(yk
s)‚àí ‚àáTk
l(yk
s‚àí)¬µ(yk
s‚àí)
‚àÇwijs
where ¬µ(v, i, s, w ) = ( ¬µ1(i‚àív),‚àí¬µ2i, Œª(v),0). Ifl‚ààPak‚à™ {k}, then Tk
l=idand therefore
Gk
t= (I0)‚àÇyksyk
t‚àÇwijyk
s. One can then reapply the formula above until l‚ààPak‚à™ {k}. By the
flow property, it follows that we may assume without loss of generality that l‚ààPak‚à™ {k}. This
leaves us with two cases. We define zk
t= (vk
t, ik
t)so that (I0)‚àÇyksyk
t=‚àÇzkszk
tand‚àÇwijzk
t=Gk
t.
Furthermore, let a=Œ¥ilŒ¥jk.
Case 1, l‚ààPak:In this case Tk
l(v, i, s, w ) = (v, i+aw+ (1‚àía)c, s, w )where cis a constant. As
a result
‚àÇzkszk
t‚àáTk
l(yk
s‚àí)‚àÇyk
s‚àí=‚àÇzkszk
tGk
t+a‚àÇikszk
t,
‚àÇzkszk
t 
¬µ(yk
s)‚àí ‚àáTk
l(yk
s‚àí)¬µ(yk
s‚àí)
=‚àÇzkszk
tŒ≥0,
In total,
Gk
t=‚àÇzkszk
t 
Gk
t‚àíŒ≥0‚àÇwijs+ae2
.
Case 2, l=k:In this case Tk
l(v, i, s, w ) = (v‚àívreset, i,logu‚àíŒ±, w)so that
‚àÇzkszk
t‚àáTk
l(yk
s‚àí)‚àÇyk
s‚àí=‚àÇzkszk
tGk
t,
‚àÇzkszk
t 
¬µ(yk
s)‚àí ‚àáTk
l(yk
s‚àí)¬µ(yk
s‚àí)
=‚àÇzkszk
tŒ≥1,
and, thus,
Gk
t=‚àÇzkszk
tGk
t‚àí‚àÇzkszk
tŒ≥0‚àÇwijs.
Note that zk
tis an Ornstein-Uhlenbeck process initialized at zk
sand with drift and diffusion matrices
Œì =
‚àí¬µ1¬µ1
0‚àí¬µ2
,Œ£ =
œÉ10
0œÉ2
.
As a result, we can directly compute ‚àÇzkszk
t=e(t‚àís)Œì. This proves that eq. (19) holds. Eq. (20) then
follows directly from (6) and the fact that Ek(y) =sk.
25From this the results of Section 4.4 follow since the terms ‚àÇwijsvanish whenever sis the spike time
of a neuron lthat is not a descendant of neuron j. Thus, equation (19) only includes terms depending
on the activity of the pre- and post-synaptic neuron. In particular, there is no need to store the gradient
pathGk
tfor each combination of neuron kand synapse ij, but each neuron only needs to keep track
of the paths for its incoming synapses. This reduces the memory requirements from the order of K3
to only K2(which is needed anyway to store the weight matrix). In general, the gradient paths can
be approximated by simply omitting the terms ‚àÇwijs.
E Experiments
E.1 Input current estimation
6For each combination of sample size and œÉwe sample a data set of spike trains using Algorithm 1
withN= 3, i.e., up until the first three spikes are generated. We use diffrax to solve the inter-Event
SDE with a step size of 0.01and the numerical solver is the simple Euler-Maruyama method. We then
sample an initial guess c‚àºUnif([0.5,2.5])and run stochastic gradient descent using the approach
described in 4.1. That is, for each step, we generate a batch of the same size as the sample size
and use dkto compare the generated batch to the data. For each step we also compare the absolute
error between the average spike time of the first three spikes of the generated sample to a hold a
out test set of the same size as the sample. We use the RMSProp algorithm with a decay rate of 0.7
and a momentum of 0.3 which we found to work well in practice. The learning rate is 0.001. The
experiment was run locally on CPU with an Apple M1 Pro chip with 8 cores and 32 GB of ram. The
entire experiment took approximately 3-6 hours to run. For the exact details of this experiment we
refer to the notebook snnax/notebooks/single_neuron.ipynb in the supplementary material.
E.2 Synaptic weight estimation
As above, for each sample size D‚àà {256,512,1024}we sample a data set of spike trains using
Algorithm 1 with T= 1and with the same differential equation solver setup as above. Thus, in this
case, the number of spikes varies across each sample path. The parameters are chosen as follows:
‚Ä¢vreset = 1.2
‚Ä¢Œª(v) = exp(5( v‚àí1)
‚Ä¢¬µ= (6,5)
‚Ä¢œÉ=I2/4
For each sample size the data was generated using the same randomly sampled weight matrix w
which represents a feed-forward network of the dimensions described in Section 4 and which was
constructed as follows: for the weight matrix from layer lto layer l+ 1, say wl, we sample each
entry from Unif([0.5,1.5])and then normalize by 3/Klwhere Klis the number of neurons in layer l.
The normalisation makes sure that the spike rate for the neurons in each layer is appropriate.
For each data set (each sample size) we then train a spiking neural net of the same network structure
to match the observed spike trains. This is done using stochastic gradient descent with a batch size of
B= 128 and by computing dkon a generated batch and a batch sampled from the data set at each
step. In order to avoid local minimums7we match the number of spikes between the generated spike
trains and the ones sampled from the data set. Also, we sample from the data set without replacement
so that we loop through the whole data set every D/B steps. We run RMSProp for 1500 steps with a
momentum of 0.3 and a learning rate of 0.003 for the first 1000 steps and 0.001 for the last 500 steps.
This experiment was run in the cloud using Azure AI Machine Learning Studio on a NVIDIA Tesla
V100 GPU with 6 cores and 112 GB of RAM. The entire experiment took around 12-16 hours to run.
For the exact details we refer to the notebook snnax/notebooks/spiking_neural_net.ipynb
in the supplementary material.
6For an updated version of some of the experiments and a general implementation of SSNNs in diffrax we
refer to github.com/cholberg/snnax.
7Note that the loss landscape is inherently discontinuous since whenever the parameters are altered in such a
way that an additional spike appears, the expected signature will jump.
260 250 500 750 1000 1250 1500
Step1020304050Test loss
0 250 500 750 1000 1250 1500
Step0.280.300.320.340.360.38/bardblÀÜwstep‚àíwtrue/bardbl
Sample size
256
512
1024Figure 2: We estimate the synaptic weights wacross three different sample sizes using the signature kernel
MMD truncated at depth 3 and stochastic gradient descent with a batch size of 128. On the left we report the
loss on a hold out test set. On the right is the mean absolute error between the entries of the currently estimated
weight matrix ÀÜwstepand the true weight matrix wtrue.
NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper‚Äôs contributions and scope?
Answer: [Yes]
Justification: The claims are clearly stated in Section 1.1 which also references where to
find the key results.
Guidelines:
‚Ä¢The answer NA means that the abstract and introduction do not include the claims
made in the paper.
‚Ä¢The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
‚Ä¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
‚Ä¢It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: There is a dedicated section (Section 5) clearly discussing what is lacking and
what can be explored in future work.
Guidelines:
‚Ä¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
‚Ä¢ The authors are encouraged to create a separate "Limitations" section in their paper.
‚Ä¢The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
‚Ä¢The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
27‚Ä¢The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
‚Ä¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
‚Ä¢If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
‚Ä¢While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren‚Äôt acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Rigorous proofs are provided in Appendix B and the assumptions are an
integral part of the paper.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include theoretical results.
‚Ä¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
‚Ä¢All assumptions should be clearly stated or referenced in the statement of any theorems.
‚Ä¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
‚Ä¢Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
‚Ä¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We clearly describe the main algorithm used in both experiments (Algorithm 1)
as well as the experimental setups. Additionally, the code is provided in the supplementary
material with clear instructions on how to setup the correct environment.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include experiments.
‚Ä¢If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
‚Ä¢If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
‚Ä¢Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
28instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
‚Ä¢While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: Code is provided in the supplementary material. The two main experiments can
be reproduced by running the two notebooks in the snnax folder as referenced in Appendix
E.
Guidelines:
‚Ä¢ The answer NA means that paper does not include experiments requiring code.
‚Ä¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
‚Ä¢While we encourage the release of code and data, we understand that this might not be
possible, so ‚ÄúNo‚Äù is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
‚Ä¢The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
‚Ä¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
‚Ä¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
‚Ä¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
‚Ä¢Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimiser, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We provide the most important aspects in Section 4. The full details are given
in Appendix E.
29Guidelines:
‚Ä¢ The answer NA means that the paper does not include experiments.
‚Ä¢The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
‚Ä¢The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: We did not prioritise running multiple iterations of the experiments since the
main contributions are of a more theoretical nature.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include experiments.
‚Ä¢The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
‚Ä¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
‚Ä¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
‚Ä¢ The assumptions made should be given (e.g., Normally distributed errors).
‚Ä¢It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
‚Ä¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
‚Ä¢For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
‚Ä¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: This information is also given in Appendix E.
Guidelines:
‚Ä¢ The answer NA means that the paper does not include experiments.
‚Ä¢The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
‚Ä¢The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
‚Ä¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn‚Äôt make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
30Answer: [Yes]
Justification: We have reviewed and made sure that our paper conforms with the code of
ethics.
Guidelines:
‚Ä¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
‚Ä¢If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
‚Ä¢The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: The work in the paper is of a theoretical nature and there are no clear links to
immediate applications with broader societal impacts.
Guidelines:
‚Ä¢ The answer NA means that there is no societal impact of the work performed.
‚Ä¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
‚Ä¢Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
‚Ä¢The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
‚Ä¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
‚Ä¢If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification:
Guidelines:
‚Ä¢ The answer NA means that the paper poses no such risks.
‚Ä¢Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
‚Ä¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
31‚Ä¢We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We have followed the citation guidelines for referencing diffrax which is
the main asset used for the current work.
Guidelines:
‚Ä¢ The answer NA means that the paper does not use existing assets.
‚Ä¢ The authors should cite the original paper that produced the code package or dataset.
‚Ä¢The authors should state which version of the asset is used and, if possible, include a
URL.
‚Ä¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
‚Ä¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
‚Ä¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
‚Ä¢For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
‚Ä¢If this information is not available online, the authors are encouraged to reach out to
the asset‚Äôs creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification:
Guidelines:
‚Ä¢ The answer NA means that the paper does not release new assets.
‚Ä¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
‚Ä¢The paper should discuss whether and how consent was obtained from people whose
asset is used.
‚Ä¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification:
Guidelines:
‚Ä¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
‚Ä¢Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
32‚Ä¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification:
Guidelines:
‚Ä¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
‚Ä¢Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
‚Ä¢We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
‚Ä¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
33