KG-FIT: Knowledge Graph Fine-Tuning Upon
Open-World Knowledge
Pengcheng Jiang Lang Cao Cao Xiaoâ€ Parminder Bhatiaâ€ Jimeng Sun Jiawei Han
University of Illinois at Urbana-Champaignâ€ GE HealthCare
{pj20, langcao2, jimeng, hanj}@illinois.edu danicaxiao@gmail.com
Abstract
Knowledge Graph Embedding (KGE) techniques are crucial in learning compact
representations of entities and relations within a knowledge graph, facilitating
efficient reasoning and knowledge discovery. While existing methods typically
focus either on training KGE models solely based on graph structure or fine-tuning
pre-trained language models with classification data in KG, KG-FIT leverages
LLM-guided refinement to construct a semantically coherent hierarchical struc-
ture of entity clusters. By incorporating this hierarchical knowledge along with
textual information during the fine-tuning process, KG-FIT effectively captures
both global semantics from the LLM and local semantics from the KG. Extensive
experiments on the benchmark datasets FB15K-237, YAGO3-10, and PrimeKG
demonstrate the superiority of KG-FIT over state-of-the-art pre-trained language
model-based methods, achieving improvements of 14.4%, 13.5%, and 11.9% in
the Hits@10 metric for the link prediction task, respectively. Furthermore, KG-FIT
yields substantial performance gains of 12.6%, 6.7%, and 17.7% compared to the
structure-based base models upon which it is built. These results highlight the
effectiveness of KG-FIT in incorporating open-world knowledge from LLMs to
significantly enhance the expressiveness and informativeness of KG embeddings.
Previous: Fine-tune LLM with KGKG-FIT: Fine-tune KG with LLM
Open-Source LLMs/PLMs<SpaceX, launched, Starlink><Elon Musk, founder of, Google> <Twitter, renamed to, X>â‹®Classification Data
Any LLMsi. Entity Descriptionâ‹®
Entity Knowledge<Pikachu, â€œPikachu is a fictional species of the PokÃ©mon media franchise â€¦ â€>ii. Entity Hierarchy
KGs
KGs
Knowledge SharingLLM
KG
400500600
PLM-basedKGE-basedKG-FITAvg. Hits@10 on FB15K-237
600700800
PLM-basedKGE-basedKG-FITAvg. Hits@10 on PrimeKG
Figure 1: â€œFine-tune LLM with KGâ€ vs â€œFine-tune KG with LLMâ€.
1 Introduction
Knowledge graph (KG) is a powerful tool for representing and storing structured knowledge, with ap-
plications spanning a wide range of domains, such as question answering [ 1,2,3,4], recommendation
systems [ 5,6,7], drug discovery [ 8,9,10], and clinical prediction [ 11,12,13]. Constituted by entities
and relations, KGs form a graph structure where nodes denote entities and edges represent relations
among them. To facilitate efficient reasoning and knowledge discovery, knowledge graph embedding
38th Conference on Neural Information Processing Systems (NeurIPS 2024).(KGE) methods [ 14,15,16,17,18,19,20,21] have emerged, aiming to derive low-dimensional
vector representations of entities and relations while preserving the graphâ€™s structural integrity.
While current KGE methods have shown success, many are limited to the graph structure alone,
neglecting the wealth of open-world knowledge surrounding entities not explicitly depicted in the
KG, which is manually created in most cases. This oversight inhibits their capacity to grasp the
complete semantics of entities and relations, consequently resulting in suboptimal performance across
downstream tasks. For instance, a KG might contain entities such as â€œAlbert Einsteinâ€ and â€œTheory
of Relativityâ€, along with a relation connecting them. However, the KG may lack the rich context
and background information about Einsteinâ€™s life, his other scientific contributions, and the broader
impact of his work. In contrast, pre-trained language models (PLMs) and LLMs, having been trained
on extensive literature, can provide a more comprehensive understanding of Einstein and his legacy
beyond the limited scope of the KG. While recent studies have explored fine-tuning PLMs with KG
triples [ 22,23,24,25,26,27,28,29], this approach is subject to several limitations. Firstly, the
training and inference processes are computationally expensive due to the large number of parameters
in PLMs, making it challenging to extend to more knowledgeable LLMs. Secondly, the fine-tuned
PLMs heavily rely on the restricted knowledge captured by the KG embeddings, limiting their ability
to fully leverage the extensive knowledge contained within the language models themselves. As
a result, these approaches may not adequately capitalize on the potential of LLMs to enhance KG
representations, as illustrated in Fig. 1. Lastly, small-scale PLMs (e.g., BERT) contain outdated and
limited knowledge compared to modern LLMs, requiring re-training to incorporate new information,
which hinders their ability to keep pace with the rapidly evolving nature of todayâ€™s language models.
To address the limitations of current approaches, we propose KG-FIT (Knowledge Graph FIne-
Tuning), a novel framework that directly incorporates the rich knowledge from LLMs into KG
embeddings without the need for fine-tuning the LMs themselves. The term â€œfine-tuningâ€ is used
because the initial entity embeddings are from pre-trained LLMs, initially capturing global semantics.
KG-FIT employs a two-stage approach: (1) generating entity descriptions from the LLM and per-
forming LLM-guided hierarchy construction to build a semantically coherent hierarchical structure of
entities, and (2) fine-tuning the KG embeddings by integrating knowledge from both the hierarchical
structure and textual embeddings, effectively merging the open-world knowledge captured by the
LLM into the KG embeddings. This results in enriched representations that integrate both global
knowledge from LLMs and local knowledge from KGs.
The main contributions of KG-FIT are outlined as follows:
(1)We introduce a method for automatically constructing a semantically coherent entity hierarchy
using agglomerative clustering and LLM-guided refinement.
(2)We propose a fine-tuning approach that integrates knowledge from the hierarchical structure and
pre-trained text embeddings of entities, enhancing KG embeddings by incorporating open-world
knowledge captured by the LLM.
(3)Through an extensive empirical study on benchmark datasets, we demonstrate significant im-
provements in link prediction accuracy over state-of-the-art baselines.
2 Related Work
Structure-Based Knowledge Graph Embedding. Knowledge Graph Embedding methods that rely
solely on graph structure aim to learn low-dimensional vector representations of entities and relations
while preserving the graphâ€™s structural properties. TransE [ 14] models relations as translations in the
embedding space. DistMult [ 15] is a simpler model that uses a bilinear formulation for link prediction.
ComplEx [ 16] extends TransE to the complex domain, enabling the modeling of asymmetric relations.
ConvE [ 17] employs a convolutional neural network to model interactions between entities and
relations. TuckER [ 18] utilizes a Tucker decomposition to learn embeddings for entities and relations
jointly. RotatE [ 19] represents relations as rotations in a complex space, which can capture various
relation patterns, and HAKE [ 21] models entities and relations in an implicit hierarchical and polar
coordinate system. These structure-based methods have proven effective in various tasks [ 30] but do
not leverage the rich entity information available outside the KG itself.
PLM-Based Knowledge Graph Embedding. Recent studies have explored integrating pre-trained
language models (PLMs) with knowledge graph embeddings to leverage the semantic information
2Text Emb. ğ¯!Non-Alcoholic Beveragep"Tea
Coffeeğ«:	Is frequently used to makeTea-basedCoffee-basedMilk-basedCocktailBeverage p#
ğœâ€²ğ!ğğ’‹ğğ’ğ’‹
ğœğ!p"ğ!p#WineStep 1. Entity Embedding Initialization
Output: Text EmbeddingEntity ğ’†ğ’ŠBlack tea  
Emb. RetrievalEmb. RetrievalâŠ•vğ’Šğ’†vğ’Šğ’…â€¦Input:KG EntityEntity ğ’†|ğ‘¬|â€¦
â€¦â€¦v|ğ‘¬|vğ’Šprocess
Step 2. Seed Hierarchy Construction
(ğ’‰ğ’Šğ’ˆğ’‰ğ’†ğ’“	ğ’•ğ’‰ğ’“ğ’†ğ’”ğ’‰ğ’ğ’ğ’…ğ’”)Hierarchical ClusteringSilhouette ScorerOutputStep 3. LLM-Guided Hierarchy Refinement
process
â€¦InputStep 4. Global Knowledge-Guided Local KG Fine-TuningMinimizationMaximizationRelational Transition
Black tea  Highest ScoreSeed Hierarchyâ€¦(ğ’ğ’ğ’˜ğ’†ğ’“	ğ’•ğ’‰ğ’“ğ’†ğ’”ğ’‰ğ’ğ’ğ’…ğ’”)Inputsuggest
XPARENTMERGESPLITINCLUDELEAF MERGELLM SuggestionsRefined Hierarchy
Refineâ€œBlack tea is a fully oxidized tea with a robust flavor and higher caffeine â€¦ â€Descriptionğ’…ğ’ŠOutput
Sub-tree Iteration BeverageCoffeeTeaCocktailWineNon-Alc.â€œBriefly describe ğ’†ğ’Šâ€Input
Output: KG-FIT EmbeddingFigure 2: Overview of KG-FIT .Input andOutput are highlighted at each step. Step 1 : Obtain text embeddings
for all entities in the KG, achieved by merging word embeddings with description embeddings retrieved from
LLMs. Step 2 : Hierarchical clustering is applied iteratively to all entity embeddings over various distance
thresholds, monitored by a Silhouette scorer to identify optimal clusters, thus constructing a seed hierarchy
where each leaf node represents a cluster of semantically similar entities. Step 3 : Leveraging LLM guidance, the
seed hierarchy is iteratively refined bottom-up through a series of suggested actions, aiming for a more accurate
organization of KG entities with LLMâ€™s knowledge. Step 4 : Use the refined hierarchy along with KG triples and
the initial entity embeddings to fine-tune the embeddings under a series of distance constraints.
captured by PLMs. KG-BERT [ 22], PKGC [ 28], TagReal [ 29], and KG-LLM [ 31] train PLMs/LLMs
with a full set of classification data and prompts. However, these approaches are computationally
expensive due to the need to iterate over all possible positive/negative triples. LMKE [ 26] and
SimKGC [ 27] adopt contrastive learning frameworks to tackle issues like expensive negative sampling
and enable efficient learning for text-based KGC. KG-S2S [ 24] and KGT5 [ 25] employ sequence-
to-sequence models to generate missing entities or relations in the KG. StAR [ 23] and CSProm-KG
[32] fuse embeddings from graph-based models and PLMs. However, they are limited to small-scale
PLMs and do not leverage the hierarchical and clustering information reflecting the LLMâ€™s knowledge
of entities. Fully LLM prompting-based methods [ 33,34] are costly and not scalable. In contrast,
our proposed KG-FIT approach can be applied to any LLM, incorporating its knowledge through
a semantically coherent hierarchical structure of entities. This enables efficient exploitation of the
extensive knowledge within LLMs, while maintaining the efficiency of structure-based methods.
3 KG-FIT Framework
We present KG-FIT (as shown in Fig. 2), a framework for fine-tuning KG embeddings leveraging
external hierarchical structures and textual information based on open knowledge. This framework
comprises two primary components: (1) LLM-Guided Hierarchy Construction : This phase
establishes a semantically coherent hierarchical structure of entities, initially constructing a seed
hierarchy and then refining it using LLM-guided techniques, and (2) Knowledge Graph Fine-Tuning :
This stage enhances the KG embeddings by integrating the constructed hierarchical structure, textual
embeddings, and multiple constraints. The two stages combined to enrich KG embeddings with
open-world knowledge, leading to more comprehensive and contextually rich representations. Below
we present more tecnical details. A table of notations is placed in Appendix L .
3.1 LLM-Guided Hierarchy Construction
We initiate the process by constructing a hierarchical structure of entities through agglomerative
clustering, subsequently refining it using an LLM to enhance semantic coherence and granularity.
3Step 1: Entity Embedding Initialization is the first step of this process, where we are given a set of
entities E={e1, . . . , e |E|}within a KG, and will enrich their semantic representations by generating
descriptions using an LLM. Specifically for each entity ei, we prompt the LLM with a template
(e.g.,Briefly describe [entity] with the format â€œ[entity] is a [description]â€.
(detailed in Appendix E.1)) prompting it to describe the entity from the KG dataset, thereby yielding
a concise natural language description di. Subsequently, the entity embedding ve
iâˆˆRdim(f)and
description embedding vd
i=f(di)âˆˆRdim(f)are obtained using an embedding model fand
concatenated to form the enriched entity representation vi:
vi= [ve
i;vd
i]. (1)
Step 2: Seed Hierarchy Construction follows after entity embedding initialization. Here we
choose agglomerative hierarchical clustering [ 35] over flat clustering methods like K-means [ 36] for
establishing the initial hierarchy. This choice is based on the robust hierarchical information provided
by agglomerative clustering, which serves as a strong foundation for LLM refinement. Using this
hierarchical structure reduces the need for numerous LLM iterations to discern relationships between
flat clusters, thereby lowering computational costs and complexity. Agglomerative clustering balances
computational efficiency with providing the LLM a meaningful starting point for refinement. The
clustering process operates on enriched entity representations V={v1, . . . , vl} âˆˆR|E|Ã—2dim(f)
using cosine distance and average linkage. The optimal clustering threshold Ï„âˆ—is determined by
maximizing the silhouette score [37] Sâˆ—across a range of thresholds [Ï„min, Ï„max]âˆˆ[0,1]:
Ï„optim= arg maxÏ„âˆˆ[Ï„min,Ï„max]Sâˆ—(V,labels Ï„) (2)
where labels Ï„are the clustering results at threshold Ï„. This ensures that the resulting clusters are
compact and well-separated based on semantic similarity. The constructed hierarchy forms a fully
binary tree where each leaf node represents an entity. We use a top-down algorithm (detailed in
Appendix F.1) to replace the first encountered entity with its cluster based on the optimal threshold
Ï„optim. This process eliminates other entity leaves within the same cluster, forming the seed hierarchy
Hseed, where each leaf node is a cluster of entities defined by labels Ï„optim.
Step 3: LLM-Guided Hierarchy Refinement (LHR) is then applied to improve the quality of the
knowledge representation. As the seed hierarchy Hseedis a binary tree, which may not optimally
represent real-world entity knowledge, we further refine it using the LLM. The LLM transforms the
seed hierarchy into the LLM-guided refined hierarchy HLHRthrough actions described below:
i. Cluster Splitting: For each leaf cluster Coriginalâˆˆ C leaf(Hseed), the LLM recursively splits it into
two subclusters using the prompt PSPLIT (Fig. 8 in Appendix E.2 ):
Csplit=LLM (PSPLIT(Coriginal )), C originalâ†’Csplit={C1, C2, . . . , C k}, (3)
where Ci={ei
1, ei
2, . . . , ei
|Ci|},Pk
i=1|Ci|=|Coriginal|=|Csplit|,kis the total number of subclusters
after recursively splitting Coriginal in a binary manner. This procedure iterates until LLM indicates no
further splitting or each subcluster has minimal entities, resulting in an intermediate hierarchy Hsplit.
ii. Bottom-Up Refinement: In the bottom-up refinement phase, the LLM iteratively refines the
intermediate hierarchy Hsplitproduced by the cluster splitting step. The refinement process starts
from the leaf level of the hierarchy and progresses upwards, considering each parent-child triple
(Pâˆ—, Pl, Pr), where Pâˆ—represents the grandparent cluster, and PlandPrrepresent the left and
right child clusters of Pâˆ—, respectively. Let {Cl
1, Cl
2, Cl
3, . . . , Cl
|Pl|}denote the children of Pl, and
{Cr
1, Cr
2, Cr
3, . . . , Cr
|Pr|}denote the children of Pr.
For each parent-child triple, the LLM is prompted with PREFINE (Pâˆ—, Pl, Pr)(Fig. 9in Appendix E.2),
which provides the names and entities of the grandparent and child clusters. The LLM then suggests
a refinement action to update the triple based on its understanding of the relationships between the
clusters. The refinement options are:
1.NO UPDATE : The triple remains unchanged, i.e., (Pâ€²
âˆ—, Pâ€²
l, Pâ€²
r) = (Pâˆ—, Pl, Pr).
2.PARENT MERGE : All the children of PlandPrare merged into the grandparent cluster Pâˆ—,
resulting in Pâ€²
âˆ—={Cl
1, Cl
2, Cl
3, . . . , Cl
|Pl|, Cr
1, Cr
2, Cr
3, . . . , Cr
|Pr|}. The original child clusters Pl
andPrare removed from the hierarchy.
3.LEAF MERGE :Pâ€²
âˆ—={e1, e2, . . . , e p}, Pâ€²
l=âˆ…, Pâ€²
r=âˆ…,where {e1, e2, . . . , e p}=PlâˆªPr.
44.INCLUDE : One of the child clusters is absorbed into the other, while the grandparent cluster
remains unchanged. This can happen in two ways:
â€¢Pâ€²
âˆ—=Pâ€²
l={Cl
1, Cl
2, Cl
3, . . . , Cl
|Pl|, Pr}, and Pâ€²
r=âˆ…, or
â€¢Pâ€²
âˆ—=Pâ€²
r={Pl, Cr
1, Cr
2, Cr
3, . . . , Cr
|Pr|}, and Pâ€²
l=âˆ….
The LLM determines the most appropriate refinement action based on the semantic similarity
and hierarchical relationships between the clusters. The refinement process continues bottom-up,
iteratively updating the triples until the root of the hierarchy is reached. The resulting refined hierarchy
is denoted as HLHR. We place more details of the process in Appendix E.2 and F.2 .
3.2 Global Knowledge-Guided Local Knowledge Graph Fine-Tuning
Step 4:KG-FIT fine-tunes the knowledge graph embeddings by incorporating the hierarchical
structure, text embeddings, and three main constraints: the hierarchical clustering constraint, text
embedding deviation constraint, and link prediction objective.
Initialization of Entity and Relation Embeddings: To integrate the initial text embeddings ( viâˆˆ
Rdim(f)) into the model, the entity embedding eiâˆˆRnis initialized as a linear combination of a
random embedding eâ€²
iâˆˆRnand the sliced text embedding vâ€²
i= [ve
i[:n
2];vd
i[:n
2]]âˆˆRn. The
relation embeddings, on the other hand, are initialized randomly:
ei=Ïeâ€²
i+ (1âˆ’Ï)vâ€²
i,rjâˆ¼N(0, Ïˆ2) (4)
where Ïis a hyperparameter controlling the ratio between the random embedding and the sliced
text embedding. rjâˆˆRmis the embedding of relation j, and Ïˆis a hyperparameter controlling the
standard deviation of the normal distribution N. This initialization ensures that the entity embeddings
start close to their semantic descriptions but can still adapt to the structural information in the KG
during training. The random initialization of relation embeddings allows the model to flexibly capture
the structural information and patterns specific to the KG.
Hierarchical Clustering Constraint: The hierarchical constraint integrates the structure and rela-
tionships derived from the adaptive agglomerative clustering and LLM-guided refinement process.
This optimization enhances the embeddings for hierarchical coherence and distinct semantic clarity.
The revised constraint consists of three tailored components:
Lhier=X
eiâˆˆE
Î»1d(ei,c)|{z}
Cluster Cohesionâˆ’Î»2X
Câ€²âˆˆSm(C)d(ei,câ€²)
|Sm(C)|
| {z }
Inter-level Cluster Separationâˆ’Î»3hâˆ’1X
j=1Î²j(d(ei,pj+1)âˆ’d(ei,pj))
hâˆ’1
| {z }
Hierarchical Distance Maintenance
(5)
where: eiandeirepresent the entity and its embedding. Cis the cluster that entity eibelongs to.
Sm(C)represents the set of neighbor clusters of Cwhere mis the number of nearest neighbors
(determined by lowest common ancestor (LCA) [ 38] in the hierarchy). candcâ€²denote the cluster
embeddings of CandCâ€², which is computed by averaging all the embedding of entities under them
(i.e.,c=1
|C|P
eiâˆˆCeiâˆˆRn).pjandpj+1are the embeddings of the parent nodes along the path
from the entity (at depth h) to the root, indicating successive parent nodes in ascending order. Each
parent node is computed by averaging the cluster embeddings under it ( p=1
|P|P
CiâˆˆPciâˆˆRn).
d(Â·,Â·)is the distance function used to measure distances between embeddings. As higher levels of
abstraction encompass a broader range of concepts, and thus a strict maintenance of hierarchical
distance may be less critical at these levels, we introduce Î²j=Î²0Â·eâˆ’Ï•jwhere Î²0is the initial weight
for the closest parent, typically a larger value, Ï•is the decay rate, a positive constant that dictates
how rapidly the importance decreases. Î»1,Î»2, and Î»3are hyperparameters. In Eq 5,Inter-level
Cluster Separation aims to maximize the distance between an entity and neighbor clusters, enhancing
the differentiation and reducing potential overlap in the embedding space. This separation ensures
that entities are distinctly positioned relative to non-member clusters, promoting clearer semantic
divisions. Hierarchical Distance Maintenance encourages the distance between an entity and its
parent nodes to be proportional to their respective levels in the hierarchy, with larger distances for
higher-level parent nodes. This reflects the increasing abstraction and decreasing specificity, aligning
the embeddings with the hierarchical structure of the KG. Cluster Cohesion enhances intra-cluster
similarity by minimizing the distance between an entity and its own cluster center, ensuring that
entities within the same cluster are closely embedded, maintaining the integrity of clusters.
5Semantic Anchoring Constraint: To preserve the semantic integrity of the embeddings, we introduce
the semantic anchoring constraint, which is formulated as:
Lanc=âˆ’X
eiâˆˆEd(ei,vâ€²
i) (6)
where Eis the set of all entities, eiis the fine-tuned embedding of entity ei,vâ€²
iis the sliced text
embedding of entity ei, and d(Â·,Â·)is a distance function. This constraint is crucial for large clusters,
where the diversity of entities may cause the fine-tuned embeddings to drift from their original
semantic meanings. This is also important when dealing with sparse KGs, as the constraint helps
prevent overfitting to the limited structural information available. By acting as a regularization term,
it mitigates overfitting and enhances the robustness of the embeddings [39].
Score Function-Based Fine-Tuning: KG-FIT is a general framework applicable to existing KGE
models [ 14,15,16,17,18,19,20]. These models learn low-dimensional vector representations of
entities and relations in a KG, aiming to capture the semantic and structural information within the
KG itself. In our work, we perform link prediction to enhance the modelâ€™s ability to accurately predict
relationships between entities within the KG. Its loss is defined as:
Llink=âˆ’X
(ei,r,ej)âˆˆD
logÏƒ(Î³âˆ’fr(ei,ej))âˆ’1
|Nj|X
njâˆˆNjlogÏƒ(Î³âˆ’fr(ei,enj))
(7)
where Dis the set of all triples in the KG, Ïƒis sigmoid function. fr(Â·,Â·)is the scoring function
(detailed in Appendix GandK) defined by the chosen KGE model that measures the compatibility
between the head entity embedding eiand the tail entity embedding ejgiven the relation r,Njis
the set of negative tail entities sampled for the triple (ei, r, ej),enjis the embedding of the negative
tail entity nj, and Î³is a margin hyperparameter. The link prediction-based fine-tuning minimizes
the scoring function for the true triples (ei, r, ej)while maximizing the margin between the scores
of true triples and negative triples (ei, r, n j). This encourages the model to assign higher scores to
positive (true) triples and lower scores to negative triples, thereby enriching the embeddings with the
local semantics in KG.
Training Objective: The objective function of KG-FIT integrates three constraints:
L=Î¶1Lhier+Î¶2Lanc+Î¶3Llink (8)
where Î¶1,Î¶2, and Î¶3are hyperparameters that assign weights to the constraints.
Note : During fine-tuning, the time complexity per epoch is O((|E|+|T |)Â·n)where|E|is the number
of entities, |T |is the number of triples, and nis the embedding dimension. In contrast, classic
PLM-based methods [ 22,28,29,23] have a time complexity of O(|T | Â·LÂ·nPLM)per epoch during
fine-tuning, where Lis the average sequence length and nPLMis the hidden dimension of the PLM.
This is typically much higher than KG-FIT â€™s fine-tuning time complexity, as |T | Â·Lâ‰«(|E|+|T |).
4 Experiment
4.1 Experimental Setup
We describe our experimental setup as follows. Table 2: Datasets statistics. #Ent./#Rel: number of
entities/relations. #Train/#Valid/#Test: number of triples
contained in the training/validation/testing set.
Dataset #Ent. #Rel. #Train #Valid #Test
FB15k-237 14,541 237 272,115 17,535 20,466
YAGO3-10 123,182 37 1,079,040 5,000 5,000
PrimeKG 10,344 11 100,000 3,000 3,000Datasets . We consider datasets that encompass
various domains and sizes, ensuring comprehen-
sive evaluation of the proposed model. Specif-
ically, we consider three datasets: (1) FB15K-
237[40] (CC BY 4.0 ) is a subset of Freebase
[41], a large collaborative knowledge base, fo-
cusing on common knowledge; (2) YAGO3-10
[42] is a subset of YAGO [ 43] (CC BY 4.0 ), which is a large knowledge base derived from multiple
sources including Wikipedia, WordNet, and GeoNames; (3) PrimeKG [44] (CC0 1.0 ) is a biomedical
KG that integrates 20 biomedical resources, detailing 17,080 diseases through 4,050,249 relation-
ships. Our study focuses on a subset of PrimeKG, extracting 106,000 triples from the whole set, with
processing steps outlined in Appendix B . Table 2 shows the statistics of these datasets.
6Table 1: Link Prediction Performance Comparison . Results are averaged values (of ten runs for FB15K-
237/PrimeKG and of three runs for YAGO3-10) of head/tail entity predictions. Top-3 results for each metric are
highlighted . â€œ*â€ indicates the results taken from methodâ€™s original paper. KG-FIT consistently outperforms
both PLM-based models and structure-based base models across all datasets and metrics, demonstrating its
effectiveness in incorporating open-world knowledge from LLMs for enhancing KG embeddings.
FB15K-237 YAGO3-10 PrimeKG
PLM-based Embedding Methods
Model PLM MR MRR H@1 H@5 H@10 MR MRR H@1 H@5 H@10 MR MRR H@1 H@5 H@10
KG-BERT [22]* BERT 153 .245 .158 â€“ .420 â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“
StAR [23]* RoBERTa 117 .296 .205 â€“ .482 â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“
PKGC [28] RoBERTa 184 .342 .236 .441 .525 1225 .501 .426 .596 .660 219 .485 .391 .565 .625
C-LMKE [26]* BERT 141 .306 .218 â€“ .484 â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“
KGT5 [25]* T5 â€“ .276 .210 â€“ .414 â€“ .426 .368 â€“ .528 â€“ â€“ â€“ â€“ â€“
KG-S2S [24]* T5 â€“ .336 .257 â€“ .498 â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“ â€“
SimKGC [27] BERT â€“ .336 .249 â€“ .511 â€“ â€“ â€“ â€“ â€“ 168 .527 .524 .679 .742
CSProm-KG [32] BERT â€“ .358 .269 â€“ .538 1145 .488 .451 .624 .675 157 .540 .492 .652 .745
LLM Emb. (zero-shot)TE-3-S 2044 .023 .002 .035 .068 22741 .009 .000 .016 .024 5581 .000 .000 .000 .000
TE-3-L 1818 .030 .004 .048 .085 18780 .015 .000 .019 .032 4297 .001 .000 .000 .000
Structure-based Embedding Methods
Model Frame H MR MRR H@1 H@5 H@10 MR MRR H@1 H@5 H@10 MR MRR H@1 H@5 H@10
TransEBase [14] â€” 233 .287 .192 .389 .478 1250 .500 .398 .626 .685 182 .048 .000 .043 .124
KG-FITSeed 142 .345 .242 .457 .547 952 .520 .429 .638 .700 80 .298 .000 .315 .516
LHR 122 .362 .264 .478 .568 529 .544 .463 .650 .705 69 .334 .000 .342 .536
DisMultBase [15] â€” 283 .260 .163 .349 .437 5501 .451 .365 .553 .615 174 .577 .475 .699 .782
KG-FITSeed 184 .316 .198 .415 .512 963 .486 .413 .591 .673 107 .589 .495 .715 .799
LHR 154 .331 .226 .433 .529 861 .527 .441 .636 .682 78 .617 .526 .747 .813
ComplExBase [16] â€” 347 .252 .161 .344 .439 6681 .463 .384 .560 .612 202 .614 .522 .728 .789
KG-FITSeed 201 .325 .223 .436 .523 997 .491 .422 .603 .669 94 .638 .548 .767 .823
LHR 151 .344 .247 .458 .551 842 .544 .460 .646 .697 82 .651 .566 .772 .835
ConvEBase [17] â€” 341 .312 .224 .401 .508 1105 .529 .451 .619 .673 144 .516 .456 .645 .760
KG-FITSeed 181 .318 .237 .411 .521 912 .535 .455 .628 .685 93 .627 .534 .757 .812
LHR 177 .318 .241 .415 .525 885 .541 .461 .647 .695 72 .648 .547 .767 .824
TuckERBase [18] â€” 363 .320 .230 .417 .505 1110 .529 .454 .633 .690 171 .543 .442 .663 .737
KG-FITSeed 175 .330 .241 .433 .521 874 .538 .458 .651 .703 77 .640 .542 .770 .805
LHR 144 .349 .255 .448 .543 838 .545 .466 .654 .708 62 .648 .550 .779 .820
pRotatEBase[19] â€” 188 .310 .205 .399 .502 974 .477 .385 .573 .655 118 .491 .399 .593 .681
KG-FITSeed 160 .355 .257 .461 .558 910 .525 .436 .622 .693 75 .635 .538 .745 .809
LHR 119 .371 .277 .483 .572 829 .550 .464 .648 .710 69 .649 .574 .779 .833
RotatEBase [19] â€” 190 .333 .241 .428 .528 1620 .495 .402 .550 .670 57 .539 .447 .646 .727
KG-FITSeed 141 .354 .261 .464 .555 790 .529 .440 .643 .708 46 .622 .517 .740 .805
LHR 120 .369 .274 .488 .570 744 .563 .475 .658 .722 34 .645 .532 .758 .817
HAKEBase [20] â€” 184 .344 .247 .435 .538 1220 530 .431 .634 .681 95 .595 .515 .708 .760
KG-FITSeed 162 .358 .268 .470 .563 854 .541 .455 .647 .703 82 .638 .540 .747 .808
LHR 137 .362 .275 .485 .572 810 .568 .474 .662 .718 42 .682 .605 .785 .835
Metrics. Following previous works, we use Mean Rank (MR), Mean Reciprocal Rank (MRR), and
Hits@N (H@N) to evaluate link prediction. MR measures the average rank of true entities, lower
the better. MRR averages the reciprocal ranks of true entities, providing a normalized measure less
sensitive to outliers. Hits@N measures the proportion of true entities in the top Npredictions.
Baselines . To benchmark the performance of our proposed model, we compared it against the state-
of-the-art PLM-based methods including KG-BERT [ 22], StAR [ 23], PKGC [ 28], C-LMKE [ 26],
KGT5 [ 25], KG-S2S [ 24], SimKGC [ 27], and CSProm-KG [ 32], and structure-based methods
including TransE [ 14], DistMult [ 15], ComplEx [ 16], ConvE [ 17], TuckER [ 18], pRotatE [ 19],
RotatE [19], and HAKE [20].
Experimental Strategy: For most PLM-based models, due to their high training cost, we use
the results reported in their respective papers.. We reproduce PKGC [ 28] for all three datasets,
SimKGC [ 27] and CSProm-KG [ 32] for PrimeKG. In addition, we evaluate the capabilities of LLM
embeddings (TE-3-S/L: text-embedding-3-small/large ) for zero-shot link prediction by ranking the
cosine similarity between (ei+r)andej. For structure-based KGE models, we assess and present
their best performance using optimal settings (shown in Table 12). ForKG-FIT , we provide a detailed
hyperparameter study in Table 13. We use OpenAIâ€™s GPT-4o as the LLM for entity description
generation and for LLM-guided hierarchy refinement. text-embedding-3-large is used for entity
embedding initialization, which preserves semantics with flexible embedding slicing [ 45]. We set
Ï„min= 0.15andÏ„max= 0.85for seed hierarchy construction. The values of Ï„optim for FB15K-237,
7YAGO3-10, and PrimeKG are 0.52, 0.49, and 0.33, respectively. The statistics of the seed and LHR
hierarchies are placed in Appendix F.3. For LCA, we designate the root as the grandparent (i.e.,
two levels above) source cluster node and set m= 5. We set Ï= 0.5,Î²0= 1.2,Ï•= 0.4, and use
cosine distance for fine-tuning. Filtered setting [ 14,19] is applied for link prediction evaluation.
Hyperparameter studies and computational cost are detailed in Appendix I and H , respectively.
4.2 Results
We conduct experiments to evaluate the performance on link prediction. The results in Table 1are
averaged values from multiple runs with random seeds: ten runs for FB15K-237 and PrimeKG, and
three runs for YAGO3-10. These averages reflect the performance of head/tail entity predictions.
0 20k 40k 60k 80k 100k 120k 140k0.000.050.100.150.200.250.300.35Validation MRRValid MRR vs Training Steps on FB15K-237
DistMult (Base)
KG-FIT-DistMultComplEx (Base)
KG-FIT-ComplEx
030k 60k 90k 120k 150k 180k 210k 240k
Training Steps0.00.10.20.30.40.5Validation Hits@10Valid Hits@10 vs Training Steps on PrimeKG
TransE-1024 (Base)
KG-FIT-TransE-1024
TransE-2048 (Base)
KG-FIT-TransE-2048
Figure 3: KG-FIT can mitigate
overfitting (upper) and underfitting
(lower) of structure-based models.Main Results. Table 1shows that our KG-FIT framework con-
sistently outperforms state-of-the-art PLM-based and traditional
structure-based models across all datasets and metrics. This
highlights KG-FIT â€™s effectiveness in leveraging LLMs to en-
hance KG embeddings. Specifically, KG-FIT HAKE surpasses
CSProm-KG by 6.3% and HAKE by 6.1% on FB15K-237 in
Hits@10; KG-FIT RotatE outperforms CS-PromKG by 7.0% and
TuckER by 4.6% on YAGO3-10; KG-FIT ComplEx exceeds PKGC
by 11.0% and ComplEx by 5.8% on PrimeKG. Additionally, with
LLM-guided hierarchy refinement (LHR), KG-FIT achieves per-
formance gains of 12.6%, 6.7%, and 17.8% compared to the
base models, and 3.0%, 1.9%, and 2.2% compared to KG-FIT
with seed hierarchy, on FB15K-237, YAGO3-10, and PrimeKG,
respectively. All these findings highlight the effectiveness of
KG-FIT for significantly improving the quality of structure-based
KG embeddings.
Figure 3further illustrates the robustness of KG-FIT , showing
superior validation performance across training steps compared
to the corresponding base models, indicating its ability to fix both
overfitting and underfitting issues of some structure-based KG
embedding models.
Effect of Constraints. We conduct an ablation study to evaluate the proposed constraints in Eq. 5and
6, with results summarized in Table 4. This analysis underscores the importance of each constraint: (1)
Hierarchical Distance Maintenance is crucial for both datasets. Its removal significantly degrades
performance across all metrics, highlighting the necessity of preserving the hierarchical structure in
the embedding space. (2) Semantic Anchoring proves more critical for the denser YAGO3-10 graph,
where each cluster contains more entities, making it harder to distinguish between them based solely
on cluster cohesion. The sparser FB15K-237 dataset is less impacted by the absence of this constraint.
Similar to the semantics anchoring, the removal of (3) Inter-level Cluster Separation significantly
affects the denser YAGO3-10 more than FB15K-237. Without this constraint, entities in YAGO3-10
may not be well-separated from other clusters, whereas FB15K-237 is less influenced. Interestingly,
removing (4) Cluster Cohesion has a larger impact on the sparser FB15K-237 than on YAGO3-10.
This difference suggests that sparse graphs rely more on the prior information provided by entity
clusters, while denser graphs can learn this information more effectively from their abundant data.
Table 3: Model efficiency on
PrimeKG. T/Ep and Inf denote train-
ing time/epoch and inference time.
KG-FIT outperforms all the PLM-
based models.
Method LM T/Ep Inf
KG-BERT RoBERTa 170m 2900m
PKGC RoBERTa 190m 50m
TagReal LUKE 190m 50m
StAR RoBERTa 125m 30m
KG-S2S T5 30m 110m
SimKGC BERT 20m 0.5m
CSProm-KG BERT 15m 0.2m
KG-FIT (ours) Any LLM 1.2m 0.1m
Structure-based â€” 0.2m 0.1mEffect of Knowledge Sources. We explore the impact of the qual-
ity of LLM-refined hierarchies and pre-trained text embeddings
on final performance, as illustrated in Figures 4and5. The results
indicate that hierarchies constructed and text embeddings retrieved
from more advanced LLMs consistently lead to improved perfor-
mance. This finding underscores KG-FIT â€™s capacity to leverage
and evolve with ongoing advancements in LLMs, effectively uti-
lizing the increasingly comprehensive entity knowledge captured
by these models.
Efficiency Evaluation. We evaluate the efficiency performance
in Table 3. While pure structure-based models are the fastest, our
model significantly outperforms all PLM-based models in both
8Table 4: Ablation study for the proposed constraints. SA,HDM ,ICS,CCdenote Semantic Anchoring,
Hierarchical Distance Maintenance, Inter-level Cluster Separation, and Cluster Cohesion, respectively. We use
TransE and HAKE as the base models for KG-FIT on FB15K-237 and YAGO3-10, respectively.
HDM SA ICS CCFB15K-237 (KG-FIT TransE ) YAGO3-10 (KG-FIT HAKE )
MRR H@1 H@5 H@10 MRR H@1 H@5 H@10
âœ“ âœ“ âœ“ âœ“ .362 .264 .478 .568 .568 .474 .662 .718
âœ— âœ“ âœ“ âœ“ .345 (â†“.017).248 (â†“.016).454 (â†“.024).542 (â†“.026).558 (â†“.010).467 (â†“.007).654 (â†“.008).709 (â†“.009)
âœ— âœ— âœ“ âœ“ .335 (â†“.027).241 (â†“.023).444 (â†“.034).533 (â†“.035).545 (â†“.023).452 (â†“.022).640 (â†“.022).695 (â†“.023)
âœ— âœ“ âœ— âœ“ .343 (â†“.019).244 (â†“.020).449 (â†“.029).538 (â†“.030).544 (â†“.024).453 (â†“.021).643 (â†“.019).691 (â†“.027)
âœ— âœ“ âœ“ âœ— .332 (â†“.030).239 (â†“.025).437 (â†“.041).529 (â†“.039).558 (â†“.010).465 (â†“.009).656 (â†“.006).711 (â†“.007)
âœ— âœ— âœ— âœ— .287 (â†“.075).192 (â†“.072).389 (â†“.089).478 (â†“.090).530 (â†“.038).431 (â†“.043).634 (â†“.028).681 (â†“.037)
None Seed G3.5 G4303234363840TransE - MRR
None Seed G3.5 G4202224262830TransE - H@1
None Seed G3.5 G4505254565860TransE - H@10
None Seed G3.5 G4303234363840pRotatE - MRR
None Seed G3.5 G4202224262830pRotatE - H@1
None Seed G3.5 G4505254565860pRotatE - H@10
Figure 4: KG-FIT on FB15K-237 with different hierarchy types. None indicates no hierarchical information
input. Seed denotes the seed hierarchy. G3.5/G4 denotes the LHR hierarchy constructed by GPT-3.5/4o. LHR
hierarchies outperform the seed hierarchy, with more advanced LLMs constructing higher-quality hierarchies.
BT RBT ada2 te3303234363840TransE - MRR
BT RBT ada2 te3202224262830TransE - H@1
BT RBT ada2 te3505254565860TransE - H@10
BT RBT ada2 te3303234363840pRotatE - MRR
BT RBT ada2 te3202224262830pRotatE - H@1
BT RBT ada2 te3505254565860pRotatE - H@10
Figure 5: KG-FIT on FB15K-237 with different text embedding. BT,RBT,ada2 , and te3are BERT, RoBERTa,
text-embedding-ada-002, and text-embedding-3-large, respectively. Seed hierarchy is used for all settings. It is
observed that pre-trained text embeddings from LLMs are substantially better than those from small PLMs.
training and inference speed, consistent with our previous analysis. It achieves 12 times the training
speed of CSProm-KG, the fastest PLM-based method. Moreover, KG-FIT can integrate knowledge
from any LLMs, unlike previous methods that are limited to small-scale PLMs, underscoring its
superiority.
Visualization. Figure 6demonstrates the effectiveness of KG-FIT in capturing both global and local
semantics. The embeddings generated by KG-FIT successfully preserve the global semantics at both
intra- and inter-levels. Additionally, KG-FIT excels in representing local semantics compared to the
original HAKE model.
5 Conclusion
In this paper, we introduced KG-FIT , a novel framework for enhancing knowledge graph (KG)
embeddings by leveraging the wealth of open-world knowledge captured by large language models
(LLMs). KG-FIT seamlessly integrates LLM-derived entity knowledge into the KG embedding
process through a two-stage approach: LLM-guided hierarchy construction and global knowledge-
guided local KG fine-tuning. By constructing a semantically coherent hierarchical structure of entities
and incorporating this hierarchical knowledge along with textual information during fine-tuning,
KG-FIT effectively captures both global semantics from the LLM and local semantics from the
KG. Extensive experiments on benchmark datasets demonstrate the superiority of KG-FIT over
state-of-the-art methods, highlighting its effectiveness in integrating open-world knowledge from
LLMs to significantly enhance the expressiveness and informativeness of KG embeddings. A key
advantage of KG-FIT is its flexibility to incorporate knowledge from any LLM, enabling it to evolve
and improve with ongoing advancements in language models. This positions KG-FIT as a powerful
and future-proof framework for knowledge-infused learning on graphs. Moreover, the enriched
KG embeddings produced by KG-FIT have the potential to boost performance on a wide array of
downstream tasks, such as question answering, recommendation systems, and drug discovery, among
others. Our code and data are available at https://github.com/pat-jj/KG-FIT .
910.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.010.0
7.5
5.0
2.5
0.02.55.07.510.0Maraviroc
CAA
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.010.0
7.5
5.0
2.5
0.02.55.07.510.0Cladribine
Exertional dyspnea
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.010.0
7.5
5.0
2.5
0.02.55.07.510.0Maraviroc
CAA
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.010.0
7.5
5.0
2.5
0.02.55.07.510.0Cladribine
Exertional dyspnea
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.010.0
7.5
5.0
2.5
0.02.55.07.510.0Maraviroc
CAA
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.010.0
7.5
5.0
2.5
0.02.55.07.510.0Cladribine
Exertional dyspnea
10
 5
 0 5 103
2
1
01234Initial Text Embedding
4
 2
 0 2 44
2
024HAKE's Embedding
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.56
4
2
0246KG-FITHAKE's Embedding
HIV Drugs
Purine AnalogsAnticoagulant Drugs
Alkylating AgentsHemophilia Drugs
Targeted Therapy: TKIsArterial Disorders
Respiratory InsufficienciesCerebral Vascular Disorders
Chronic Lung DiseasesCardiac Abnormalities
Chest DeformitiesFigure 6: Visualization of Entity Embedding (left to right: initial text embedding, HAKE embedding, and
KG-FIT HAKE embedding). Upper (local) : Embeddings (dim=2048) of <Maraviroc, drug_effect, CAA (Coronary
artery atherosclerosis)> and<Cladribine, drug_effect, Exertional dyspnea> , two parent-child triples selected
from PrimeKG, in polar coordinate system. In the polar coordinate system, the normalized entity embedding
Â¯eis split to e1=Â¯e[:n
2]ande2=Â¯e[n
2+ 1 :] where nis the hidden dimension, which serves as values on
the x-axis and y-axis, respectively, which is consistent with Zhang et al. [ 20]â€™s visualization strategy. Lower
(global) : t-SNE plots of different embeddings of sampled entities, with colors indicating clusters (e.g., Maraviroc
belongs to the HIV Drugs cluster). Triangles indicate the positions of â–²Maraviroc ,â–²CAA ,â–²Cladribine , and
â–²Exertional dyspnea .Observations :While the initial text embeddings capture global semantics, they fail to
delineate local parent-child relationships within the KG, as seen in the intermingled polar plots. In contrast,
HAKE shows more distinct grouping by modulus on the polar plots, capturing hierarchical local semantics, but
fails to adequately capture global semantics. Our KG-FIT , notably, incorporates prior information from LLMs
and is fine-tuned on the KG, maintains global semantics from pre-trained text embeddings while better capturing
local KG semantics, demonstrating its superior representational power across local and global scales.
6 Limitations
Although KG-FIT outperforms state-of-the-art PLM-based models on the FB15K-237, YAGO3-
10, and PrimeKG datasets, it does not outperform pure PLM-based methods on a lexical dataset
WN18RR, as shown in Table 5. This limitation is discussed with details in Appendix C. As a future
work, we will explore the integration of contrastive learning into the KG-FIT framework to enhance
its capability to capture semantic relationships more effectively.
Moreover, KG-FIT â€™s performance is influenced by the quality of the constructed hierarchy, particularly
the seed hierarchy. To address this, we propose an automatic selection of the optimal binary tree
based on the silhouette score. However, if the initial clustering is suboptimal, it may result in a
lower-quality hierarchy that affects KG-FIT â€™s performance. Additionally, the bottom-up refinement
process in our proposed LHR approach updates each parent-child triple with only a single operation
(within four), which prioritizes efficiency and simplicity over performance. In future work, we plan
to explore cost-efficient methods for refining the hierarchy that integrate multiple operations for each
triple update, striking a better balance between efficiency and performance.
7 Acknowledgement
The research was supported in part by US DARPA INCAS Program No. HR0011-21-C0165 and
BRIES Program No. HR0011-24-3-0325, National Science Foundation IIS-19-56151, the Molecule
Maker Lab Institute: An AI Research Institutes program supported by NSF under Award No.
2019897, and the Institute for Geospatial Understanding through an Integrative Discovery Environ-
ment (I-GUIDE) by NSF under Award No. 2118329. Any opinions, findings, and conclusions or
recommendations expressed herein are those of the authors and do not necessarily represent the views,
either expressed or implied, of DARPA or the U.S. Government.
10References
[1]Xiao Huang, Jingyuan Zhang, Dingcheng Li, and Ping Li. Knowledge graph embedding based
question answering. In Proceedings of the twelfth ACM international conference on web search
and data mining , pages 105â€“113, 2019.
[2]Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang, and Jure Leskovec. Qa-gnn:
Reasoning with language models and knowledge graphs for question answering. arXiv preprint
arXiv:2104.06378 , 2021.
[3]Weiguo Zheng, Hong Cheng, Lei Zou, Jeffrey Xu Yu, and Kangfei Zhao. Natural language
question/answering: Let users talk with the knowledge graph. In Proceedings of the 2017 ACM
on Conference on Information and Knowledge Management , pages 217â€“226, 2017.
[4]Michihiro Yasunaga, Antoine Bosselut, Hongyu Ren, Xikun Zhang, Christopher D Manning,
Percy S Liang, and Jure Leskovec. Deep bidirectional language-knowledge graph pretraining.
Advances in Neural Information Processing Systems , 35:37309â€“37323, 2022.
[5]Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. Het-
erogeneous graph attention network. In The world wide web conference , pages 2022â€“2032,
2019.
[6]Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, and Minyi Guo. Knowledge graph convolu-
tional networks for recommender systems. In The world wide web conference , pages 3307â€“3313,
2019.
[7]Janneth Chicaiza and Priscila Valdiviezo-Diaz. A comprehensive survey of knowledge graph-
based recommender systems: Technologies, development, and contributions. Information ,
12(6):232, 2021.
[8]Sameh K Mohamed, VÃ­t NovÃ¡ Ë‡cek, and Aayah Nounu. Discovering protein drug targets using
knowledge graph embeddings. Bioinformatics , 36(2):603â€“610, 08 2019.
[9]Pengcheng Jiang, Cao Xiao, Tianfan Fu, and Jimeng Sun. Bi-level contrastive learning for
knowledge-enhanced molecule representations, 2024.
[10] Payal Chandak, Kexin Huang, and Marinka Zitnik. Building a knowledge graph to enable
precision medicine. Scientific Data , 10(1):67, 2023.
[11] Junyi Gao, Chaoqi Yang, Joerg Heintz, Scott Barrows, Elise Albers, Mary Stapel, Sara Warfield,
Adam Cross, and Jimeng Sun. Medml: fusing medical knowledge and machine learning models
for early pediatric covid-19 hospitalization and severity prediction. Iscience , 25(9), 2022.
[12] Ricardo MS Carvalho, Daniela Oliveira, and Catia Pesquita. Knowledge graph embeddings for
icu readmission prediction. BMC Medical Informatics and Decision Making , 23(1):12, 2023.
[13] Pengcheng Jiang, Cao Xiao, Adam Richard Cross, and Jimeng Sun. Graphcare: Enhancing
healthcare predictions with personalized knowledge graphs. In The Twelfth International
Conference on Learning Representations , 2024.
[14] Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko.
Translating embeddings for modeling multi-relational data. In C.J. Burges, L. Bottou,
M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural Information
Processing Systems , volume 26. Curran Associates, Inc., 2013.
[15] Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and
relations for learning and inference in knowledge bases. arXiv preprint arXiv:1412.6575 , 2014.
[16] ThÃ©o Trouillon, Johannes Welbl, Sebastian Riedel, Ã‰ric Gaussier, and Guillaume Bouchard.
Complex embeddings for simple link prediction. In International conference on machine
learning , pages 2071â€“2080. PMLR, 2016.
[17] Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. Convolutional 2d
knowledge graph embeddings. In Proceedings of the AAAI conference on artificial intelligence ,
volume 32, 2018.
[18] Ivana BalaÅ¾evi Â´c, Carl Allen, and Timothy Hospedales. Tucker: Tensor factorization for
knowledge graph completion. In Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on Natural Language
Processing (EMNLP-IJCNLP) , pages 5185â€“5194, 2019.
11[19] Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. Rotate: Knowledge graph em-
bedding by relational rotation in complex space. In International Conference on Learning
Representations , 2018.
[20] Zhanqiu Zhang, Jianyu Cai, Yongdong Zhang, and Jie Wang. Learning hierarchy-aware
knowledge graph embeddings for link prediction. In Proceedings of the AAAI conference on
artificial intelligence , volume 34, pages 3065â€“3072, 2020.
[21] Yushi Bai, Zhitao Ying, Hongyu Ren, and Jure Leskovec. Modeling heterogeneous hierarchies
with relation-specific hyperbolic cones. Advances in Neural Information Processing Systems ,
34:12316â€“12327, 2021.
[22] Liang Yao, Chengsheng Mao, and Yuan Luo. Kg-bert: Bert for knowledge graph completion.
arXiv preprint arXiv:1909.03193 , 2019.
[23] Bo Wang, Tao Shen, Guodong Long, Tianyi Zhou, Ying Wang, and Yi Chang. Structure-
augmented text representation learning for efficient knowledge graph completion. In Proceed-
ings of the Web Conference 2021 , pages 1737â€“1748, 2021.
[24] Chen Chen, Yufei Wang, Bing Li, and Kwok-Yan Lam. Knowledge is flat: A seq2seq generative
framework for various knowledge graph completion. In Proceedings of the 29th International
Conference on Computational Linguistics , pages 4005â€“4017, 2022.
[25] Apoorv Saxena, Adrian Kochsiek, and Rainer Gemulla. Sequence-to-sequence knowledge
graph completion and question answering. In Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers) , pages 2814â€“2828, 2022.
[26] Xintao Wang, Qianyu He, Jiaqing Liang, and Yanghua Xiao. Language models as knowledge
embeddings. arXiv preprint arXiv:2206.12617 , 2022.
[27] Liang Wang, Wei Zhao, Zhuoyu Wei, and Jingming Liu. Simkgc: Simple contrastive knowledge
graph completion with pre-trained language models. In Proceedings of the 60th Annual Meeting
of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 4281â€“4294,
2022.
[28] Xin Lv, Yankai Lin, Yixin Cao, Lei Hou, Juanzi Li, Zhiyuan Liu, Peng Li, and Jie Zhou. Do
pre-trained models benefit knowledge graph completion? a reliable evaluation and a reasonable
approach. Association for Computational Linguistics, 2022.
[29] Pengcheng Jiang, Shivam Agarwal, Bowen Jin, Xuan Wang, Jimeng Sun, and Jiawei Han. Text
augmented open knowledge graph completion via pre-trained language models. In Findings of
the Association for Computational Linguistics: ACL 2023 , pages 11161â€“11180, 2023.
[30] Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and Philip S. Yu. A survey on
knowledge graphs: Representation, acquisition, and applications. IEEE Transactions on Neural
Networks and Learning Systems , 33(2):494â€“514, 2022.
[31] Liang Yao, Jiazhen Peng, Chengsheng Mao, and Yuan Luo. Exploring large language models
for knowledge graph completion. arXiv preprint arXiv:2308.13916 , 2023.
[32] Chen Chen, Yufei Wang, Aixin Sun, Bing Li, and Kwok-Yan Lam. Dipping plms sauce:
Bridging structure and text for effective knowledge graph completion via conditional soft
prompting. In Findings of the Association for Computational Linguistics: ACL 2023 , pages
11489â€“11503, 2023.
[33] Yanbin Wei, Qiushi Huang, Yu Zhang, and James Kwok. KICGPT: Large language model with
knowledge in context for knowledge graph completion. In Houda Bouamor, Juan Pino, and
Kalika Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023 ,
pages 8667â€“8683, Singapore, December 2023. Association for Computational Linguistics.
[34] Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, and Xueqi Cheng. Lpnl: Scalable link
prediction with large language models. arXiv preprint arXiv:2401.13227 , 2024.
[35] Daniel MÃ¼llner. Modern hierarchical, agglomerative clustering algorithms. arXiv preprint
arXiv:1109.2378 , 2011.
[36] K Krishna and M Narasimha Murty. Genetic k-means algorithm. IEEE Transactions on Systems,
Man, and Cybernetics, Part B (Cybernetics) , 29(3):433â€“439, 1999.
[37] Peter J. Rousseeuw. Silhouettes: A graphical aid to the interpretation and validation of cluster
analysis. Journal of Computational and Applied Mathematics , 20:53â€“65, 1987.
12[38] Baruch Schieber and Uzi Vishkin. On finding lowest common ancestors: Simplification and
parallelization. SIAM Journal on Computing , 17(6):1253â€“1262, 1988.
[39] Jay Pujara, Eriq Augustine, and Lise Getoor. Sparsity and noise: Where knowledge graph
embeddings fall short. In Martha Palmer, Rebecca Hwa, and Sebastian Riedel, editors, Pro-
ceedings of the 2017 Conference on Empirical Methods in Natural Language Processing ,
pages 1751â€“1756, Copenhagen, Denmark, September 2017. Association for Computational
Linguistics.
[40] Kristina Toutanova and Danqi Chen. Observed versus latent features for knowledge base and
text inference. In Proceedings of the 3rd workshop on continuous vector space models and their
compositionality , pages 57â€“66, 2015.
[41] Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a
collaboratively created graph database for structuring human knowledge. In Proceedings of the
2008 ACM SIGMOD international conference on Management of data , pages 1247â€“1250, 2008.
[42] Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. Yago: a core of semantic
knowledge. In Proceedings of the 16th International Conference on World Wide Web , WWW
â€™07, page 697â€“706, New York, NY , USA, 2007. Association for Computing Machinery.
[43] Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. Yago: a core of semantic knowl-
edge. In Proceedings of the 16th international conference on World Wide Web , pages 697â€“706,
2007.
[44] Payal Chandak, Kexin Huang, and Marinka Zitnik. Building a knowledge graph to enable
precision medicine. Nature Scientific Data , 2023.
[45] Aditya Kusupati, Gantavya Bhatt, Aniket Rege, Matthew Wallingford, Aditya Sinha, Vivek Ra-
manujan, William Howard-Snyder, Kaifeng Chen, Sham Kakade, Prateek Jain, et al. Matryoshka
representation learning. Advances in Neural Information Processing Systems , 35:30233â€“30249,
2022.
[46] George A Miller. Wordnet: a lexical database for english. Communications of the ACM ,
38(11):39â€“41, 1995.
[47] Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron
Maschinot, Ce Liu, and Dilip Krishnan. Supervised contrastive learning. Advances in neural
information processing systems , 33:18661â€“18673, 2020.
[48] Kun Xu, Liwei Wang, Mo Yu, Yansong Feng, Yan Song, Zhiguo Wang, and Dong Yu. Cross-
lingual knowledge graph alignment via graph matching neural network. In Proceedings of the
57th Annual Meeting of the Association for Computational Linguistics , pages 3156â€“3161, 2019.
[49] Bayu Distiawan Trisedya, Jianzhong Qi, and Rui Zhang. Entity alignment between knowl-
edge graphs using attribute embeddings. In Proceedings of the AAAI conference on artificial
intelligence , volume 33, pages 297â€“304, 2019.
[50] Qingheng Zhang, Zequn Sun, Wei Hu, Muhao Chen, Lingbing Guo, and Yuzhong Qu. Multi-
view knowledge graph embedding for entity alignment. arXiv preprint arXiv:1906.02390 ,
2019.
[51] Hailin Wang, Ke Qin, Rufai Yusuf Zakari, Guoming Lu, and Jin Yin. Deep neural network-based
relation extraction: an overview. Neural Computing and Applications , pages 1â€“21, 2022.
[52] Zhengyan He, Shujie Liu, Mu Li, Ming Zhou, Longkai Zhang, and Houfeng Wang. Learning
entity representation for entity disambiguation. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Volume 2: Short Papers) , pages 30â€“34, 2013.
13Contents of Appendix
A Ethics and Broader Impacts 15
B PrimeKG Dataset Processing & Subset Construction 15
C Results on WN18RR Dataset 16
D Supplemental Implementation Details 17
D.1 KG-FIT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
D.2 Baseline Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
D.2.1 PLM-based Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
D.2.2 Sturcture-based Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
E Prompts 19
E.1 Prompt for Entity Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
E.2 Prompts for LLM-Guided Hierarchy Refinement . . . . . . . . . . . . . . . . . . 19
F Details of KG-FIT Hierarchy Construction 22
F.1 Seed Hierarchy Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
F.2 LLM-Guided Hierarchy Refinement . . . . . . . . . . . . . . . . . . . . . . . . . 23
F.3 Statistics of Constructed Hierarchies . . . . . . . . . . . . . . . . . . . . . . . . . 24
F.4 Examples of LLM-Guided Hierarchy Refinement . . . . . . . . . . . . . . . . . . 25
G Score Functions 26
H Computational Cost 27
H.1 Hardware and Software Configuration . . . . . . . . . . . . . . . . . . . . . . . . 27
H.2 Cost of Close-Source LLM APIs . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
I Hyperparameter Study 27
J Downstream Applications of KG-FIT 29
K Interpreting Score Functions in KG-FIT 30
L Notation Table 33
14A Ethics and Broader Impacts
KG-FIT is a framework for enhancing knowledge graph embeddings by incorporating open knowledge
from large language models. As a foundational research effort, KG-FIT itself does not have direct
societal impacts. However, the enriched knowledge graph embeddings produced by KG-FIT could
potentially be used in various downstream applications, such as question answering, recommendation
systems, and drug discovery.
The broader impacts of KG-FIT depend on how the enhanced knowledge graph embeddings are
used. On the positive side, KG-FIT could lead to more accurate and comprehensive knowledge
representations, enabling better performance in beneficial applications like medical research and
personalized recommendations. However, as with any powerful technology, there is also potential for
misuse. The enriched knowledge could be used to build systems that spread disinformation or make
unfair decisions that negatively impact specific groups.
To mitigate potential negative impacts, we encourage responsible deployment of KG-FIT and the
enhanced knowledge graph embeddings it produces. This includes carefully monitoring downstream
applications for fairness, robustness, and truthfulness. Additionally, when releasing KG-FIT-enhanced
knowledge graph embeddings, we recommend providing usage guidelines and deploying safeguards
to prevent misuse, such as gated access and safety filters, as appropriate.
As KG-FIT relies on large language models, it may inherit biases present in the language modelsâ€™
training data. Further research is needed to understand and mitigate such biases. We also encourage
future work on building knowledge graph embeddings that are more inclusive and less biased.
Overall, while KG-FIT is a promising framework for advancing knowledge graph embeddings, it is
important to consider its limitations and potential broader impacts. Responsible development and
deployment will be key to realizing its benefits while mitigating risks. We are committed to fostering
an open dialogue on these issues as KG-FIT and related technologies progress.
B PrimeKG Dataset Processing & Subset Construction
We describe the process of constructing a subset of the PrimeKG1[44] (version: V2, license: CC0
1.0) dataset. The goal is to create a highly-focused subset while leveraging additional information
from the entire knowledge graph to assess KG embedding modelsâ€™ abilities on predicting drug-disease
relationships.
The dataset construction process involves several detailed steps to ensure the creation of balanced
training, validation, and testing sets from PrimeKG.
Validation/Testing Set Creation: We begin by selecting triples from the original PrimeKG where
the type of the head entity is "drug" and the type of the tail entity is "disease." This selection
yields a subset containing 42,631 triples, 2,579 entities, and 3 relations ( "contraindication,"
"indication," "off-label use" ). From this subset, we randomly select 3,000 triples each for
the validation and testing sets, ensuring no overlap between the two.
Training Set Creation: We first extract the unique entities present in the validation and testing sets.
These entities are used to ensure comprehensive coverage in the training set.
For each triple in the validation/testing set, we search for triples involving either its head or tail entity
across the entire PrimeKG dataset, for the training set construction:
Step 1 involves searching for 1-hop triples within the specified relations ( "contraindication,"
"indication," "off-label use" ).
Step 2 randomly enriches the training set with triples involving other relations, with a limit of up to
10 triples per entity.
Step 3 involves removing redundant triples and any triples that are symmetric to those in the
validation/testing set, enhancing the challenge posed by the dataset. If the training set contains fewer
than 100,000 triples, we return to Step 2 and continue the process until the desired size is achieved.
1https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IXA7BM
15Following our methodology, we construct a subset of the PrimeKG dataset that emphasizes
drug-disease relations while incorporating broader context from the entire dataset. This
subset is then split into training, validation, and testing sets, ensuring proper files are gen-
erated for training and evaluating knowledge graph embedding (KGE) models. The dataset
contains 10,344 entities with 11 types of relations :disease_phenotype_positive,
drug_effect, indication, contraindication, disease_disease, disease_protein,
disease_phenotype_negative, exposure_disease, drug_protein, off-label use,
drug_drug . The testing and validation sets include three specific relations ( "contraindication,"
"indication," "off-label use" ).
C Results on WN18RR Dataset
Table 5: Link Prediction Results on WN18RR . Results are averaged values of ten independent runs of
head/tail entity predictions. Top-6 results for each metric are highlighted in bold. â€œ*â€ indicates the results taken
from the methodâ€™s original paper.
WN18RR
PLM-based Embedding Methods
Model PLM MR MRR H@1 H@5 H@10
KG-BERT [22]* BERT 97 .216 .041 â€“ .524
StAR [23]* RoBERTa 51 .401 .243 â€“ .709
PKGC [28] RoBERTa 160 .464 .441 .522 .540
C-LMKE [26]* BERT 79 .619 .523 â€“ .789
KGT5 [25]* T5 â€“ .508 .487 â€“ .544
KG-S2S [24]* T5 â€“ .574 .531 â€“ .661
SimKGC [27]* BERT â€“ .666 .587 â€“ .800
CSProm-KG [32]* BERT â€“ .575 .522 â€“ .678
OpenAI-Emb (zero-shot)TE-3-S 1330 .141 .075 .205 .271
TE-3-L 1797 .127 .074 .178 .235
Structure-based Embedding Methods
Model Frame H MR MRR H@1 H@5 H@10
pRotatEBase[19] â€” 2924 .460 .416 .506 .552
KG-FITSeed 165 .566 .498 .584 .696
LHR 78 .590 .511 .615 .722
RotatEBase [19] â€” 3365 .476 .429 .523 .572
KG-FITSeed 144 .554 .501 .571 .712
LHR 75 .589 .519 .600 .719
HAKEBase [20] â€” 3680 .490 .452 .535 .579
KG-FITSeed 267 .541 .484 .590 .660
LHR 172 .553 .488 .595 .695
Combination
PKGC w/ KG-FIT pRotatE â€™s recall ( X= 20 ) 70 .625 .540 .655 .791
KG-FIT pRotatE w/ SimKGCâ€™s Graph-Based Re-Ranking 73 .624 .532 .652 .745
In this section, we present our results and findings on the WN18RR dataset. WN18RR [ 17] is derived
from WordNet [ 46], a comprehensive lexical knowledge graph for the English language. This subset
addresses the test leakage problems identified in WN18. The statistics of WN18RR are shown in
Table 6 .Ï„optim we found for the seed hierarchy construction on WN18RR is 0.44.
Our experiments reveal that although KG-FIT did not surpass the performance of C-LMKE and
SimKGC, its integration with PKGC [ 28], employing KG-FIT as a recall model followed by re-
ranking with PKGC, yielded comparable results to these leading models.
Several factors contribute to these observations:
(1) WN18RR, being a lexical dataset, benefits significantly from pre-trained language model (PLM)
based methods, which assimilate extensive lexical knowledge during fine-tuning. KG-FIT , relying
on static knowledge graph embeddings, lacks this capability. However, as shown in Table 5,its
combination with PKGC leverages the strengths of both models, resulting in markedly improved
performance.
16Table 6: Statistics of WN18RR. #Ent./#Rel: number of entities/relations. #Train/#Valid/#Test: number of
triples contained in the set.
Dataset #Ent. #Rel. #Train #Valid #Test
WN18RR 40,943 11 86,835 3,034 3,134
(2)WN18RR has a very close semantic similarity between the head and tail entities . The dataset
is full of lexical relations such as â€œhypernymâ€, â€œmember_meronymâ€, â€œverb_groupâ€, etc. C-LMKE
and SimKGC, both utilizing contrastive learning [ 47] with PLMs , effectively exploit this semantic
proximity during training. This ability to discern subtle semantic nuances contributes to their superior
performance over other PLM-based approaches.
(3)SimKGC implements a â€œGraph-based Re-rankingâ€ strategy that narrows the candidate pool
to the k-hop neighbors of the source entity from the training set. This approach intuitively boosts
performance by focusing on more relevant candidates. For a fair comparison, our experiments did
not adopt this specific setting across all datasets. In Table 5, we showcase how this strategy could
boost the performance for KG-FIT as well.
As a future work, we will explore the integration of contrastive learning into the KG-FIT framework
to enhance its capability to capture semantic relationships more effectively.
D Supplemental Implementation Details
In this section, we provide more implementation details of both KG-FIT and baseline models, to
improve the reproducibility of our work.
D.1 KG-FIT
Pre-computation. In ourKG-FIT framework, there is a pre-computation step to avoid overhead
during the fine-tuning phase. The data we need to pre-compute includes:
1.Cluster embeddings c: These are computed by averaging the all initial entity embeddings ( vi)
within each cluster.
2.Neighbor cluster IDs ( Sm(C)in Eq. 5): These are computed using the lowest common ancestor
(LCA) approach, where we set the ancestor as the grandparent (i.e., two levels above the node)
and search for at most m= 5neighbor clusters.
3.Parent node IDs: These represent the node IDs along the path from a cluster (leaf node) to the root
of the hierarchy.
The pre-computed data is then used to efficiently locate the embeddings of clusters ( c,câ€²) and parent
nodes ( p) for the hierarchical clustering constraint during fine-tuning. With this pre-computation, we
significantly speed up the training process, as the necessary information is readily available and does
not need to be calculated on-the-fly.
Distance Function. We employ cosine distance as the distance metric for computing the hierarchical
clustering constraint (Eq. 5) and the semantic anchoring constraint (Eq. 6). Cosine distance effectively
captures the semantic similarity between embeddings, making it well-suited for maintaining the
semantic meaning of the entity embeddings during fine-tuning. Cosine distance is also invariant to
the magnitude of the embeddings, allowing the fine-tuned embeddings to adapt their magnitude based
on the link prediction objective while preserving their semantic orientation with respect to the frozen
reference embeddings. Moreover, cosine distance is independent of the link prediction objective,
focusing on preserving the semantic properties of the embeddings.
Alternative distance metrics, such as Euclidean distance or L1 norm, were considered but deemed
much slower in KG-FIT framework, aligning with the descriptions in OpenAIâ€™s document on the
embedding models2.
Constraint Computation Options. During fine-tuning, each training step involves a batch composed
of one positive triple and bnegative samples, where bis the negative sampling size. We provide two
options for computing the constraints along with the link prediction score:
2https://platform.openai.com/docs/guides/embeddings/frequently-asked-questions
171.Full Constraint Computation : This option computes the distances for both the positive triple
and the negative triples. For the positive triple, distances are computed for both the source and
target entities. For the negative triples, distances are computed only for the source entities. The
advantage of this option is that it allows the model to converge in fewer steps and generally
achieves better performance after fine-tuning. However, the drawback is that the computation for
each batch is nearly doubled, as positive and negative triples are separately fed into the model for
score computation.
2.Partial Constraint Computation : This option computes the distances only for the source entities
in the negative batch. It is faster than the full constraint computation option and can achieve
comparable results based on our observations.
D.2 Baseline Implementation
D.2.1 PLM-based Methods
PKGC. For PKGC on FB15K-237, we use the templates the authors constructed and released3for
FB15K-237-N, and use RoBERTa-Large as the base pre-trained langauge model. For YAGO3-10
and PrimeKG, we manually created templates for relations. For example, we converted the relation
â€œisLeaderOfâ€ to â€œ[X] is a leader of [Y].â€ for YAGO3-10 and converted the relation â€œdrug_effectâ€ â€œdrug
[X] has effect [Y]â€. We choose TuckER as PKGCâ€™s backbone KGE recall model with hyperparameter
X= 100 for its overall great performance across all datasets. This means that we select top 50 results
from TuckER and feed the shuffled entities into PKGC for re-ranking. We set batch size as 256 and
run on 1 NVIDIA A6000 GPU for both training and testing.
SimKGC. For SimKGC on PrimeKG, for fairness, we do not use the â€œgraph-based re-rankingâ€
strategy introduced in their paper [ 27], which adds biases to the scores of known entities (in the
training set) within k-hop of the source entity. The released code4was used for experiments. We set
batch size as 256 and run on 1 NVIDIA A6000 GPU for both training and testing.
CSProm-KG. For CSProm-KG on PrimeKG, we use ConvE as the backbone graph model, which is
the best Hits@N performed model. The other settings we use are the same as what reported in the
paper. We use the code5released by the authors to conduct the experiments.
D.2.2 Sturcture-based Methods
TuckER and ConvE. For TuckER, we use its release code6to run the experiments. For ConvE, we
use its PyTorch implementation in PKGCâ€™s codebase7, provided in the same framework as TuckER.
It is worth noting that we do not use their proposed â€œlabel smoothingâ€ setting for fair comparison.
TransE, DistMult, ComplEx, pRotatE, RotatE. For those KGE models, we reuse the code base8
released by RotatE [ 19]. As it provides a unified framework and environment to run all those models,
enabling a fair comparison. Our code (â€œ code/model_common.py â€) also adapts this framework as
the foundation.
HAKE. HAKEâ€™s code9was built upon RotatEâ€™s repository described above. In our work, we integrate
the implementation of HAKE into our framework, which is also based on RotatEâ€™s.
The hyperparameters we used are presented in Appendix I .
18# When hint is availableâ€˜â€˜â€˜Please provide a brief description of the entity '{entity}' in the following format:{entity} is a [description].For example:apple is a round fruit with red, green, or yellow skin and crisp, juicy flesh.HINT:{hint}Now, describe {entity}:â€™â€™â€™# When there is no hintâ€˜â€˜â€˜Please provide a brief description of the entity '{entity}' in the following format:{entity} is a [description].For example:apple is a round fruit with red, green, or yellow skin and crisp, juicy flesh.Now, describe {entity}:â€™â€™â€™Figure 7: Prompt for Entity Description.
E Prompts
E.1 Prompt for Entity Description
Figure 7showcases the prompts we used for entity description. In the prompt, we instruct the LLM
to provide a brief and concrete description of the input entity. We include an example, such as â€œapple
is a round fruit with red, green, or yellow skin and crisp, juicy fleshâ€ to illustrate that the description
should be concise yet cover multiple aspects. Conciseness is crucial to minimize noise. For datasets
like FB15K-237 and WN18RR, where descriptions are already available [ 23], we use the original
description as a hint and ask the LLM to output the description in a unified format.
E.2 Prompts for LLM-Guided Hierarchy Refinement
Fig. 8 and 9 show the main prompts we used for LLM-Guided Hierarchy Refinement (LHR).
Prompt for Cluster Splitting ( PSPLIT ): This prompt is designed to guide the LLM in identifying
and splitting a given cluster into meaningful subclusters based on the characteristics of the entities.
The prompt works as follows:
1.Input Entities: The entities from the specified cluster are provided as input.
2.Analysis and Grouping: The LLM is tasked with analyzing the entities to determine if they can
be grouped into distinct subclusters based on common attributes like characteristics, themes, or
genres.
3https://github.com/THU-KEG/PKGC
4https://github.com/intfloat/SimKGC
5https://github.com/chenchens190009/CSProm-KG
6https://github.com/ibalazevic/TuckER
7https://github.com/THU-KEG/PKGC/blob/main/TuckER/model.py
8https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding
9https://github.com/MIRALab-USTC/KGE-HAKE
19Given entities from the cluster '{cluster_name}'.Analyze the entities and determine if they can be grouped into distinct and meaningful sub-clusters based on their characteristics, themes, or genres.If sub-clusters can be formed, provide a clear and concise name for each sub-cluster that represents the common attribute of its entities.Each sub-cluster should be given a new name that uniformly describes its entities. There needs to be differentiation in the names of different clusters.The number of sub-clusters should be two.If the entities are already well-grouped and don't require further sub-clustering, simply provide the original cluster.Provide the output in the following JSON format:```json{{"Sub-cluster 1 Name": ["Entity 1", "Entity 2", ...],"Sub-cluster 2 Name": ["Entity 3", "Entity 4", ...]}}```Example:Cluster: MoviesEntities: The Godfather, The Shawshank Redemption, The Dark Knight, Forrest Gump, Inception, The MatrixOutput:{{"Drama": ["The Godfather", "The Shawshank Redemption", "Forrest Gump"],"Action": ["The Dark Knight", "Inception", "The Matrix"]}}Cluster: {cluster_name}Entities: {entities}Output: Figure 8: Prompt of LLM_SPLIT_CLUSTER.
3.Sub-cluster Naming: If subclusters are formed, the LLM provides clear and concise names for
each subcluster that represent the common attributes of their entities. Each subcluster is given a
unique name that uniformly describes its entities, ensuring differentiation between clusters.
4.Control of Sub-cluster Count: The prompt instructs the LLM to control the number of subclusters
between 1 and 5. If the entities are already well-grouped, no further sub-clustering is needed, and
the original cluster is returned.
The output format ensures structured and consistent results, facilitating easy integration into the
hierarchy refinement process.
Prompt for Bottom-Up Refinement ( PREFINE ): This prompt guides the LLM in refining the parent-
child triples within the hierarchy. The refinement process involves several key steps:
1. Input Clusters: Two clusters, A and B, along with their entities, are provided as input.
2. Analysis of Clusters: The LLM analyzes the two clusters and their entities to determine the most
appropriate update mode. The alignment of update modes to the actions described in the methodology
section is as follows:
â€¢Update Mode 1 (Create New Cluster C): Aligns with NOUPDATE . These two clusters cannot be
merged, and no cluster belongs to any other.
â€¢Update Mode 2 (Merge Cluster A and B): Aligns with PARENT MERGE &LEAF MERGE . These
two nodes can be merged. The name of the new merged node should be similar to both nodes.
20Given the cluster A '{cluster_name_1}': [{entities_1}];and the cluster B '{cluster_name_2}': [{entities_2}].Analyze two clusters and their entities and determine the update mode:Update Mode 1 -Create New Cluster C: these two clusters cannot be merged, and no cluster belongs to any other.Update Mode 2 -Merge Cluster A and B: these two clusters can be merged. The name of two clusters should be similar and entities from two clusters should be similar.Update Mode 3 -Cluster A Covers Cluster B: cluster B belongs to cluster A. cluster B is a subcluster of cluster A. The name of cluster A should uniformly describe the entities from cluster A and the name of cluster B.Update Mode 4 -Cluster B Covers Cluster A: cluster A belongs to cluster B. cluster A is a subcluster of cluster B. The name of cluster B should uniformly describe the entities from cluster B and the name of cluster A.You need to select a update mode based on two clusters.If you select mode 1, you should also suggest a name of new cluster. The new cluster name should uniformly describe two clusters.If you select mode 2, you should suggest a name of merged cluster. The new name should be similar to cluster A and B.Example:Cluster A 'Thermal Insulators': [cork, fiberglass, foam];Cluster B 'Electrical Conductors': [copper, aluminum, gold];Select Mode 1.Cluster A 'Sedans': [Toyota Camry, Honda Accord, Ford Fusion];Cluster B 'SUVs': [Honda CR-V, Toyota RAV4, Ford Escape];Select Mode 2.Cluster A 'Feline Species': [lions, tigers, cheetahs];Cluster B 'House Cats': [Siamese, Persian, Maine Coon];Select Mode 3.Cluster A 'Leafy Vegetables': [lettuce, spinach, kale];Cluster B 'Root Vegetables': [carrots, potatoes, beets];Select Mode 4.Provide the output in the following JSON format:```json{{"update_mode": 1 or 2 or 3 or 4,"name": "merged cluster name or new cluster name"}}```Output: Figure 9: Prompt of LLM_UPDATE.
â€¢Update Mode 3 & 4 (Cluster A Covers Cluster B): Aligns with INCLUDE where Pâ€²=PâˆªR, Lâ€²=
L, Râ€²=âˆ…. Cluster B belongs to cluster A. Cluster B is a subcluster of cluster A. The name of
cluster A should uniformly describe the entities from both clusters.
3. Output Format: The output includes the selected update mode and the suggested name for the
new or merged cluster, ensuring clarity and consistency in the hierarchy refinement process.
21These prompts, illustrated in Fig. 8and Fig. 9, are essential for transforming the seed hierarchy into
a more refined and accurate LLM-guided hierarchy, enabling better hierarchical representation to be
learned by KG-FIT .
F Details of KG-FIT Hierarchy Construction
F.1 Seed Hierarchy Construction
Algorithm 1 Seed Hierarchy Construction
Require: Enriched entity representations V, range of thresholds [Ï„min, Ï„max]
Ensure: Seed hierarchy Hseed
1:
2://Step 1: Agglomerative Hierarchical Clustering
3:forÏ„âˆˆ[Ï„min, Ï„max]do
4: labels Ï„â†AgglomerativeClustering (V, Ï„)
5: SÏ„â†SilhouetteScore (V,labels Ï„)
6:end for
7:Ï„optimâ†arg max( SÏ„)
8:
9://Step 2: Constructing the Initial Hierarchy
10:Hinitâ†ConstructBinaryTree (labels Ï„optim)
11:
12://Step 3: Top-Down Entity Replacement
13:visited_clusters â† âˆ…
14:ReplaceEntitiesWithClusters (Hinit,labels Ï„optim,visited_clusters )
15:
16://Step 4: Refinement Steps
17:Hseedâ†Refine (Hinit)
18:
19:return Hseed
20:
21:function REPLACE ENTITIES WITHCLUSTERS (H,labels ,visited_clusters)
22: fornodeâˆˆ H do
23: ifnode is a leaf then
24: entityâ†GetEntity (node)
25: cluster â†GetCluster (entity ,labels )
26: ifcluster âˆˆvisited_clusters then
27: Remove node from H
28: else
29: Replace node with cluster
30: visited_clusters â†visited_clusters âˆª {cluster}
31: end if
32: else
33: ReplaceEntitiesWithClusters (node,labels ,visited_clusters )
34: end if
35: end for
36:end function
This section details the seed hierarchy construction mentioned in Section 3.1. Algorithm 1shows the
pseudo code for this process.
The process begins with the agglomerative hierarchical clustering of the enriched entity representa-
tionsVusing a range of thresholds [Ï„min, Ï„max]. For each threshold Ï„, the clustering labels ( labels Ï„)
are obtained, and the silhouette score ( SÏ„) is calculated. The optimal threshold Ï„optim is determined
by selecting the threshold that maximizes the silhouette score.
22Next, the initial hierarchy Hinitis constructed based on the clustering labels obtained using the optimal
threshold ( labels Ï„optim). The ConstructBinaryTree function builds a binary tree structure where each
leaf node represents an entity.
The top-down entity replacement algorithm is then applied to the initial hierarchy Hinit. It traverses
the hierarchy in a top-down manner, starting from the root node. For each node encountered during
the traversal:
â€¢ If the node is a leaf, the entity associated with the node is retrieved using the GetEntity function.
â€¢The cluster to which the entity belongs is obtained using the GetCluster function and the labels Ï„optim.
â€¢If the cluster has already been visited (i.e., it exists in the visited_clusters set), the leaf node is
removed from the hierarchy.
â€¢If the cluster has not been visited, the leaf node is replaced with the cluster, and the cluster is added
to the visited_clusters set.
â€¢ If the node is not a leaf, the algorithm recursively applies the same process to its child nodes.
This top-down approach ensures that entities are included in their respective clusters as early as
possible during the traversal of the hierarchy. By keeping track of the visited clusters, the algorithm
avoids duplicating clusters in the hierarchy, resulting in a more compact and coherent representation.
Finally, the refinement steps ( Refine function) are applied to the modified hierarchy to obtain the
final seed hierarchy Hseed. The refinement steps include handling empty dictionaries, single-entry
dictionaries, and updating cluster assignments.
The resulting seed hierarchy Hseedrepresents a hierarchical organization of the entities, where each
node is either a cluster containing a list of entities or a sub-hierarchy representing a more fine-
grained grouping of entities. This seed hierarchy serves as a starting point for further refinement and
incorporation of external knowledge in the subsequent steps of the KG-FIT framework.
F.2 LLM-Guided Hierarchy Refinement
LLM-Guided Hierarchy Refinement (LHR) is used to further refine the seed hierarchy, which can
better reflect relationships among entities. The process of LLM-Guided Hierarchy Refinement can
be divided into two steps: LLM-Guided Cluster Splitting and LLM-Guided Bottom-Up Hierarchy
Refinement.
As described in Algorithm 2, the LLM-Guided Cluster Splitting algorithm is designed to iteratively
split clusters in a hierarchical structure with the guidance of a large language model (LLM). The
algorithm begins with an initial hierarchy seed Hseedand outputs a split hierarchy Hsplit. Initially, the
current cluster ID is set to 0. The recursive procedure RECURSION_SPLIT_CLUSTER is then defined
to manage the splitting process. If the root of the current cluster is a list and its length is less than
a predefined minimum number of entities in a leaf node ( MIN_ENTITIES_IN_LEAF ), the function
returns, indicating no further splitting is necessary. Otherwise, the root clusterâ€™s entities are passed to
the LLM, which names the cluster and splits it into smaller clusters. If the split results in only one
cluster, the function returns. For each resulting subcluster, the entities are assigned a new cluster ID,
and the splitting process is recursively applied. If the root is not a list, the function iterates over each
subcluster and applies the splitting procedure. Finally, the algorithm initiates the recursive splitting
on the initial hierarchy seed and returns the modified hierarchy as Hsplit.
The LLM-Guided Bottom-Up Hierarchy Refinement algorithm (Algorithm 3) refines a previously
split hierarchy Hsplitto produce a more coherent and meaningful hierarchy HLHR. This process is also
guided by an LLM. The algorithm defines a recursive procedure RECURSION_REFINE_HIERARCHY ,
which starts by checking if the root of the current cluster is a list. If it is, the LLM is used to name
the cluster, and the updated hierarchy is returned. Otherwise, the procedure recursively refines the
left and right child nodes. The children of these nodes are then evaluated, and the LLM suggests an
update mode based on the names and children of the right and left nodes. Depending on the suggested
update mode, the algorithm may add the right node under the left children, the left node under the
right children, or merge the left and right clusters. If no update is suggested, the procedure continues.
The updated hierarchy is returned after applying the necessary refinements. The algorithm initiates
the refinement process on the split hierarchy Hsplitand outputs the refined hierarchy HLHR.
23Algorithm 2 LLM-Guided Cluster Splitting
1:Input: Hseed
2:Output: Hsplit
3:current_cluster_id â†0
4:procedure RECURSION _SPLIT _CLUSTER (root)
5: ifroot is a list then
6: iflength of root < MIN_ENTITIES_IN_LEAF then
7: return
8: end if
9: cluster_entities â†root
10: cluster_name â†LLM_NAME _CLUSTER (cluster_entities)
11: splitted_clusters â†LLM_SPLIT _CLUSTER (cluster_name, cluster_entities)
12: iflength of splitted_clusters == 1 then
13: return
14: end if
15: foreach (name, entities) in splitted_clusters do
16: root[current_cluster_id] â†entities
17: current_cluster_id â†current_cluster_id + 1
18: RECURSION _SPLIT _CLUSTER (root[current_cluster_id])
19: end for
20: else
21: foreach (key, subcluster) in root do
22: RECURSION _SPLIT _CLUSTER (subcluster)
23: end for
24: end if
25:end procedure
26: RECURSION _SPLIT _CLUSTER (Hseed)
27:Hsplitâ† H seed
28:return Hsplit
F.3 Statistics of Constructed Hierarchies
Table 7: Statistics of the hierarchies constructed by KG-FIT on different datasets.
FB15K-237 YAGO3-10 PrimeKG WN18RR
Seed LHR Seed LHR Seed LHR Seed LHR
# Cluster 5,226 5,073 31,832 30,465 4,048 3,459 16,114 14,230
# Node 10,452 8,987 63,664 52,751 8,096 5,918 32,228 26,186
# Entity in a ClusterMax 115 115 1,839 1,839 72 72 40 58
Min 1 1 1 1 1 1 1 1
Avg 2.78 2.81 3.87 4.04 2.56 2.99 2.54 2.88
Cluster DepthMax 46 40 81 70 33 26 57 43
Min 3 3 4 4 4 3 5 3
Avg 25.52 18.64 38.86 28.72 20.35 12.39 25.91 22.5
# Branch of a NodeMax 2 74 2 135 2 34 2 37
Min 1 1 1 1 1 1 1 1
Avg 2 2.3 2 2.37 2 2.41 2 2.19
Table 7presents the statistics of the hierarchies constructed by KG-FIT on four different datasets:
FB15K-237, YAGO3-10, PrimeKG, and WN18RR. The table compares the seed hierarchy (Seed)
with the LLM-Guided Refined hierarchy (LHR) to show the changes and improvements after applying
the LLM-guided hierarchy refinement process.
The number of clusters decreases across all datasets after refinement. For instance, in the FB15K-237
dataset, the clusters reduce from 5226 to 5073. Similarly, the number of nodes also decreases;
for FB15K-237, nodes go from 10452 to 8987. The number of entities within each cluster sees a
24Algorithm 3 LLM-Guided Bottom-Up Hierarchy Refinement
1:Input: Hsplit
2:Output: HLHR
3:procedure RECURSION _REFINE _HIERARCHY (root)
4: ifroot is a list then
5: updated_hierarchy â†LLM_NAME _CLUSTER (root)
6: return updated_hierarchy
7: else
8: left_node â†RECURSION _REFINE _HIERARCHY (left_node)
9: right_node â†RECURSION _REFINE _HIERARCHY (right_node)
10: left_children â†Children(left_node)
11: right_children â†Children(right_node)
12: update_mode â†LLM_UPDATE (names and children of right and left node)
13: ifupdate_mode == no update then
14: continue
15: else if update_mode == merge left and right then
16: Merge left and right clusters
17: update hierarchy name and children
18: else if update_mode == left include right then
19: Add right_node under left_children
20: update hierarchy name and children
21: else if update_mode == right include left then
22: Add left_node under right_children
23: update hierarchy name and children
24: end if
25: return updated_hierarchy
26: end if
27:end procedure
28:HLRHâ†RECURSION _REFINE _HIERARCHY (Hsplit)
29:return HLHR
slight increase in the average number, with the maximum and minimum values remaining fairly
constant. For example, the average number of entities per cluster in FB15K-237 increases from 2.78
to 2.81. The depth of the hierarchies shows a noticeable reduction, with the maximum and average
depths decreasing. In FB15K-237, the maximum depth goes from 46 to 40, and the average depth
drops from 25.52 to 18.64. The branching factor of nodes also increases slightly, indicating a more
interconnected structure; in FB15K-237, the average number of branches per node rises from 2 to 2.3.
Similar patterns are observed in other datasets.
Overall, Table 7illustrates that the refinement process effectively reduces the number of clusters and
nodes, slightly increases the number of entities per cluster, decreases the depth of the hierarchy, and
increases the branching factor. These changes suggest that the refinement process results in a more
compact and interconnected hierarchy, better reflecting relationships among entities. The general
effect of the refinement is the creation of a more streamlined and coherent hierarchical structure.
F.4 Examples of LLM-Guided Hierarchy Refinement
Table 8: An example of LLM-Guided Cluster Splitting.
Sub-cluster Name Sub-cluster Entities
Universities and Colleges Princeton University, Yale University, Harvard University, Brown University, Dartmouth College, Harvard College, Yale College
Medical Schools Yale School of Medicine, Harvard Medical School
Examples in Table 8and Table 9illustrate how the LLM-guided hierarchy refinement process
updates and organizes clusters and sub-clusters to create a more coherent and meaningful hierarchical
structure.
Table 8provides examples of sub-clusters within a cluster in the process of cluster splitting. Each
sub-cluster is given a name and lists the associated entities. For instance, one sub-cluster named
25Table 9: Examples of LLM-Guided Bottom-Up Hierarchy Refinement.
Case Cluster A Name Cluster A Entities Cluster B Name Cluster B Entities Update
1 Washington D.C. Sports Teams Washington Wizards, . . . Detroit Sports Teams Detroit Red Wings, . . . No Update
2 New York Regional Entities New York Island Entities, . . . New York Locations and Cities New York Locations, . . . Parent Merge
3 Football Positions running back, halfback, . . . Football Positions tight end, defensive end, . . . Leaf Merge
4 Los Angeles Region Los Angeles, Southern California West Los Angeles Suburbs Inglewood, Torrance A Includes B
5 The Bryan Brothers Bob Bryan, Mike Bryan Tennis Athletes Williams Sisters, . . . B Includes A
â€œUniversities and Collegesâ€ includes entities such as Princeton University and Harvard College.
Additionally, a sub-cluster named â€œMedical Schoolsâ€ includes entities such as Yale School of
Medicine. The cluster of â€œUniversities and Collegesâ€ will be divided into the sub-clusters of
â€œUniversitiesâ€ and â€œCollegesâ€ in the next step. This example shows that LLM can divide the original
large cluster into multiple smaller, refined ones.
Table 9demonstrates various cases of cluster updates in LLM-Guided Bottom-Up Hierarchy Refine-
ment. Each case lists two clusters (Cluster A and Cluster B) along with their entities and the type of
update applied. In some cases, no update is needed, and both clusters remain unchanged. In others,
Cluster B is merged into Cluster A, indicating a hierarchical relationship. There are instances where
entities from Cluster B are integrated into Cluster A. Additionally, some updates involve Cluster
A including all entities of Cluster B, making Cluster B a subset of Cluster A, or vice versa. These
examples all show that the LLM correctly fixes the errors in the original seed hierarchy and refines
the hierarchical structure to better reflect world knowledge.
Overall, these examples demonstrate how clusters are refined to better represent the relationships
between entities, leading to a more organized and efficient structure. These examples highlight the
detailed organization of entities into meaningful sub-clusters, reflecting their natural groupings and
relationships. The refinement process not only improves the overall structure but also enhances the
clarity and accessibility of the hierarchy.
G Score Functions
Table 10: Score functions defined by the KGE methods tested in this work.
Model Score Function fr(h,t) Parameters
TransE âˆ’âˆ¥h+râˆ’tâˆ¥1/2 h,r,tâˆˆRk
DistMult hâŠ¤diag(r)t h,r,tâˆˆRk
ComplEx Re(hâŠ¤diag(r)t) h,r,tâˆˆCk
ConvE f(vec(f(hâˆ—Ï‰))W)t h,r,tâˆˆRk
TuckER W Ã— 1hÃ—2wrÃ—3t wrâˆˆRdr
pRotatE âˆ’2Csin
Î¸h+Î¸râˆ’Î¸t
2
1h,r,tâˆˆCk
RotatE âˆ’âˆ¥hâ—¦râˆ’tâˆ¥2 h,r,tâˆˆCk,|ri|= 1
HAKE âˆ’âˆ¥hmâ—¦rmâˆ’tmâˆ¥2âˆ’Î»âˆ¥sin((hp+rpâˆ’tp)/2)âˆ¥1hm,tmâˆˆRk,tmâˆˆRk
+,
hp,rp,tpâˆˆ[0,2Ï€)k, Î»âˆˆR
The score functions defined by the structure-based KG embedding methods [ 14,15,16,17,18,19,
20,21] we tested in this papaer are shown in Table 10. Here is a paragraph explaining each notation
in the table, with all explanations inline:
The table presents the score functions fr(h,t)used by various knowledge graph embedding (KGE)
methods, where h,r, andtrepresent the head entity, relation, and tail entity embeddings, respectively.
TransE uses a translation-based score function with either L1 or L2 norm, denoted by âˆ¥ Â· âˆ¥ 1/2,
where the embeddings are in real space Rk. DistMult employs a bilinear score function with a
diagonal relation matrix diag(r), and the embeddings are also in Rk. ComplEx extends DistMult
by using complex-valued embeddings in Ckand takes the real part of the score, denoted by Re(Â·).
ConvE applies a 2D convolution operation, where his the 2D reshaping of h,âˆ—represents the
26convolution, Ï‰is a set of filters, vec(Â·)is a vectorization operation, and Wis a linear transformation
matrix. TuckER uses a Tucker decomposition with a core tensor Wand relation-specific weights
wrâˆˆRdr, where Ã—ndenotes the tensor product along the n-th mode. pRotatE and RotatE employ
rotation-based score functions in complex space, with â—¦representing the Hadamard product and
|ri|= 1constraining the relation embeddings to have unit modulus. HAKE combines a modulus
part (hm,tmâˆˆRk,tmâˆˆRk
+) and a phase part ( hp,rp,tpâˆˆ[0,2Ï€)k) in its score function, with a
hyperparameter Î»âˆˆRbalancing the two parts.
H Computational Cost
H.1 Hardware and Software Configuration
Based on the dataset size, we hybridly use two machines:
For FB15K-237, PrimeKG, and WN18RR, experiments are conducted on a machine equipped with
two AMD EPYC 7513 32-Core Processors, 528GB RAM, eight NVIDIA RTX A6000 GPUs, and
CUDA 12.4 and the NVIDIA driver version 550.76.
For YAGO3-10, due to its large size, experiments are conducted on a machine equipped with two
AMD EPYC 7513 32-Core Processors, 528GB RAM, and eight NVIDIA A100 80GB PCIe GPUs.
The system uses CUDA 12.2 and the NVIDIA driver version 535.129.03.
With a single GPU, it takes about 2.5, 4.5, 2.0, and 1.1 hours for a KG-FIT model to achieve good
performance on FB15K-237, YAGO3-10, PrimeKG, and WN18RR, respectively.
H.2 Cost of Close-Source LLM APIs
The costs of GPT-4o for entity description generation are$3.0,$24.8 ,$2.1, and $8.6 for FB15K-
237, YAGO3-10, PrimeKG, and WN18RR, respectively, proportional to their numbers of entities.
The cost of text embedding models (text-embedding-3-large) for entity embedding initialization
was totally about $0.8 to process all the KG datasets.
The costs of GPT-4o for LLM-Guided Hierarchy Refinement on FB15K-237, YAGO3-10,
PrimeKG, and WN18RR are $10.0 ,$74.5 ,$8.7, and $34.4 , respectively. This cost is almost propor-
tional to the nodes consisted in the seed hierarchy.
I Hyperparameter Study
This section presents a comprehensive hyperparameter study for both structure-based base models
and our proposed KG-FIT framework across different datasets. Table 11outlines the range of
hyperparameter values explored during the study. Table 12showcases the optimal hyperparameter
configurations for the base models that yielded the best performance. Similarly, Table 13presents the
best-performing hyperparameter settings for KG-FIT .
The hyperparameter study aims to provide insights into the sensitivity of the models to various
hyperparameters and to identify the optimal configurations that maximize their performance on
each dataset. By conducting a thorough exploration of the hyperparameter space, we ensure a fair
comparison between the base models and KG-FIT , and demonstrate the robustness and effectiveness
of our proposed framework across different settings.
Table 11: Summary of hyperparameters we explored for both base models and KG-FIT .
Hyper-parameter Studied Values
Batch Size {64, 128, 256, 1024}
Negative Sampling Size ( |Nj|in Eq 7 ) {64, 128, 256, 400, 512, 1024}
Hidden Dimension Size n {512, 768, 1024, 2048}
Score Margin Î³ {6.0, 9.0, 10.0, 12.0, 24.0, 60.0, 200.0}
Learning Rate {5e-5, 2e-4, 1e-4, 5e-4, 1e-3, 2e-3, 4e-3, 5e-3, 1e-2, 2e-2, 5e-2}
Î»1,Î»2,Î»3 in range of [0.1, 1.0]
Î¶1,Î¶2,Î¶3 in range of [0.1, 10.0]
27Table 12: Best hyperparameters grid-searched for base models on different datasets.
FB15K-237
TransE DistMult ComplEx ConvE TuckER pRotatE RotatE HAKE
Batch Size 1024 1024 1024 512 512 1024 1024 1024
Learning Rate 5e-4 1e-2 1e-2 5e-3 5e-3 5e-4 5e-4 1e-3
Negative Sampling 256 256 256 â€“ â€“ 256 256 256
Hidden Dimension 1024 2048 1024 512 1024 2048 2048 2048
Î³ 9.0 200.0 200.0 â€“ â€“ 9.0 9.0 9.0
YAGO3-10
TransE DistMult ComplEx ConvE TuckER pRotatE RotatE HAKE
Batch Size 512 512 512 128 128 256 1024 1024
Learning Rate 2e-3 1e-3 1e-4 5e-5 1e-4 5e-4 2e-3 2e-3
Negative Sampling 256 256 256 â€“ â€“ 512 400 256
Hidden Dimension 1024 1024 1024 512 1024 1024 1024 1024
Î³ 24.0 24.0 24.0 â€“ â€“ 24.0 24.0 24.0
PrimeKG
TransE DistMult ComplEx ConvE TuckER pRotatE RotatE HAKE
Batch Size 512 512 512 128 128 512 512 512
Learning Rate 5e-4 2e-2 2e-3 5e-4 5e-5 1e-4 1e-4 1e-4
Negative Sampling 512 512 512 â€“ â€“ 1024 1024 512
Hidden Dimension 1024 1024 1024 512 1024 2048 2048 2048
Î³ 24.0 200.0 200.0 â€“ â€“ 24.0 24.0 6.0
Table 13: Hyperparameters we used for KG-FIT with different base models on different datasets.
FB15K-237
TransE DistMult ComplEx ConvE TuckER pRotatE RotatE HAKE
Batch Size 512 512 512 256 256 256 256 256
Learning Rate 1e-3 1e-3 1e-3 1e-4 1e-4 5e-4 1e-3 5e-4
Negative Sampling 512 512 512 â€“ â€“ 512 512 512
Hidden Dimension 1024 512 512 512 1024 2048 2048 2048
Î³ 24.0 60.0 60.0 â€“ â€“ 9.0 9.0 9.0
Î»1, Î»2, Î»3 (1.0, 0.4, 0.5) (0.5, 0.5, 0.5) (0.5, 0.5, 0.5) (0.8, 0.6, 0.2) (0.8, 0.6, 0.2) (1.0, 0.4, 0.5) (1.0, 0.4, 0.5) (1.0, 0.4, 0.5)
Î¶1, Î¶2, Î¶3 (0.5, 0.5, 3.5) (0.5, 0.5, 2.0) (0.5, 0.5, 2.0) (0.5, 0.5, 2.0) (0.5, 0.5, 2.0) (0.5, 0.5, 4.0) (0.5, 0.5, 3.5) (0.5, 0.5, 3.5)
YAGO3-10
TransE DistMult ComplEx ConvE TuckER pRotatE RotatE HAKE
Batch Size 256 256 256 128 128 256 256 256
Learning Rate 1e-3 1e-3 1e-4 5e-5 1e-4 5e-4 1e-3 2e-3
Negative Sampling 256 256 256 â€“ â€“ 512 256 512
Hidden Dimension 1024 1024 1024 512 1024 1024 1024 1024
Î³ 24.0 24.0 24.0 â€“ â€“ 24.0 24.0 24.0
Î»1, Î»2, Î»3 (1.0, 0.4, 0.5) (0.5, 0.5, 0.5) (1.0, 0.4, 0.5) (1.0, 0.6, 0.3) (0.8, 0.6, 0.2) (1.0, 0.4, 0.5) (1.0, 0.4, 0.5) (1.0, 0.4, 0.5)
Î¶1, Î¶2, Î¶3 (0.5, 0.5, 2.0) (0.5, 0.5, 2.0) (0.2, 0.2, 3.0) (0.2, 0.5, 2.0) (0.2, 0.5, 2.0) (1.0, 1.0, 9.0) (1.0, 1.0, 9.0) (1.0, 1.0, 8.0)
PrimeKG
TransE DistMult ComplEx ConvE TuckER pRotatE RotatE HAKE
Batch Size 256 512 256 128 128 256 512 512
Learning Rate 5e-4 2e-2 2e-3 5e-4 5e-5 1e-4 1e-4 1e-4
Negative Sampling 256 1024 512 â€“ â€“ 256 512 512
Hidden Dimension 1024 1024 2048 512 1024 2048 2048 2048
Î³ 24.0 200.0 200.0 â€“ â€“ 24.0 10.0 10.0
Î»1, Î»2, Î»3 (1.0, 0.4, 0.5) (0.8, 0.4, 0.5) (0.8, 0.4, 0.2) (1.0, 0.6, 0.2) (1.0, 0.6, 0.2) (0.8, 0.8, 0.3) (0.8, 0.4, 0.2) (0.8, 0.4, 0.2)
Î¶1, Î¶2, Î¶3 (0.5, 0.5, 1.8) (0.5, 0.5, 2.0) (0.2, 0.2, 5.0) (0.5, 0.5, 6.0) (0.5, 0.5, 6.0) (0.5, 0.5, 1.8) (1.0, 1.0, 7.0) (1.0, 1.0, 9.0)
28J Downstream Applications of KG-FIT
Fundamental KG Tasks
BeverageQ: â€œCan drinking black teahelp reduce the risk of cardiovascular diseases?â€chronic diseasesDiseases
black teacardiovascular diseasespotentially beneficial to Speed & Proximal Relationship Search for Retrieval Augmented Generation (RAG)
flavonoids-rich drinkmay treatsupportive informationinKGA: â€œDrinking black tea, which is rich in flavonoids, may help reduce the risk of cardiovascular diseases. Flavonoids are known for their antioxidant properties, which can offer protective benefits against such conditions.â€
â€¦Entity Matching Across KGsGlobalTech Inc.KG AKG BSmartVision 3000launchedSmart Home Devices aproduct inHome Automation Solutionbelongs toreleasedGlobal Tech IndustriesSV3000 CameraLink Prediction???Tail PredictionHead PredictionRelation PredictionTriple ClassificationTrueFalse
Figure 10: Applications of KG-FIT .
The enhanced knowledge graph embeddings produced by KG-FIT can enable improved performance
on various downstream tasks. As shown in Fig. 10 , potential areas of application include:
â€¢Tasks transformed to fundamental KG tasks. KG-FIT â€™s strong performance on link predic-
tion can directly benefit fundamental KG tasks like knowledge graph-based question answering
(KGQA) [ 1,2,4]. For example, given the question "Can drinking black tea help reduce the risk
of cardiovascular diseases?", a KGQA system powered by KG-FIT embeddings could effectively
traversely perform triple classification task for triples such as <black tea, potentially beneficial
to, cardiovascular diseases> ,<black tea, is a, flavonoids-rich drink> ,<flavonoids, may treat,
cardiovascular diseases> , and provide an accurate answer based on the classification results.
â€¢Entity Matching Across KGs. KG-FIT â€™s ability to capture both global and local semantics
facilitates accurate entity matching across different knowledge graphs [ 48,49,50]. Consider
two KGs, A and B, containing information about a companyâ€™s products. KG A lists the entity
â€œGlobalTech Incâ€ launched â€œSmartVision 3000â€, which is a product in â€œSmart Home Devicesâ€,
while KG B mentions "SV3000 Camera" is released by "Global Tech Industries" in the category of
"Home Automation Solution". By generating semantically rich embeddings that encode textual,
hierarchical and relational information, KG-FIT can help identify that â€œSmartVision 3000â€ and
â€œSV3000 Cameraâ€, â€œGlobalTech Inc.â€ and â€œGlobal Tech Industriesâ€ likely refer to the same entities,
despite differences in surface form and graph structure.
â€¢Retrieval Augmented Generation with Graphs. The hierarchical nature of KG-FIT â€™s embeddings
enables efficient search for relevant information to augment language model-based text generation.
In a retrieval augmented generation setup, a language modelâ€™s output can be enhanced by retrieving
and conditioning on pertinent information. KG-FIT â€™s embeddings allow for quick identification
of relevant entities and relationships via proximity search in the semantic space. Moreover, by
traversing the KG-FIT hierarchy, the system can gather additional context about an entity of interest.
For instance, if the generation task involves the cardiovascular benefits of black tea, searching
theKG-FIT hierarchy may surface related information on flavonoids and antioxidant properties,
providing valuable context to guide the language model in producing an informed and factually
grounded response.
â€¢Other Tasks. KG-FIT â€™s embeddings can also be leveraged for tasks such as relation extraction [ 51]
and entity disambiguation [ 52]. By providing high-quality embeddings that encode both local and
global information, KG-FIT can improve the accuracy and efficiency of these tasks. For example,
in relation extraction, KG-FIT â€™s embeddings can help identify the most likely relation between two
entities given their positions in the hierarchy and their semantic proximity. In entity disambiguation,
KG-FIT â€™s embeddings can be used to disambiguate between multiple entities with the same name
by considering their relationships and positions within the knowledge graph hierarchy.
In summary, KG-FIT â€™s robust embeddings, capturing both local and global semantics in a hierarchical
structure, can significantly enhance a variety of downstream applications, from fundamental KG tasks
to entity matching and retrieval augmented generation. By providing semantically rich and efficiently
searchable representations of KG entities and relationships, KG-FIT enables knowledge-infused AI
systems that can better understand and reason over complex domains.
29K Interpreting Score Functions in KG-FIT
In this section, we analyze how the entity embeddings in KG-FIT are interpreted in the (transitional)
score functions defined by different base models.
Leth,r,tâˆˆRdimdenote the head entity, relation, and tail entity embeddings, respectively. In
KG-FIT, the entity embeddings handtare initialized as follows:
h= [hn;hd],t= [tn;td] (9)
where hn,tnâˆˆRdim/2represent the entity name embeddings and hd,tdâˆˆRdim/2represent the
entity description embeddings, obtained from the pre-trained text embeddings.
The inclusion of both hnandhd(similarly for tnandtd) enhances the expressiveness of the entity
representation. Starting from these embeddings, KG-FIT effectively captures a more comprehensive
understanding of each entity, leading to improved link prediction performance.
TransE: The TransE score function is defined as:
fr(h,t) =âˆ’âˆ¥h+râˆ’tâˆ¥p (10)
where âˆ¥ Â· âˆ¥pdenotes the Lpnorm.
Expanding the score function using the KG-FIT embeddings:
fr(h,t) =âˆ’âˆ¥[hn;hd] +râˆ’[tn;td]âˆ¥p
=âˆ’âˆ¥[hn+rnâˆ’tn;hd+rdâˆ’td]âˆ¥p(11)
where r= [rn;rd]is the relation embedding learned during fine-tuning.
Interpretation:
â€¢hn+rnâˆ’tn: This term represents the distance in the embedding space between the head and tail
entitiesâ€™ name embeddings, adjusted by the relation embedding.
â€¢hd+rdâˆ’td: This term represents the distance in the embedding space between the head and tail
entitiesâ€™ description embeddings, adjusted by the relation embedding.
The TransE score function considers the global semantic information by computing the translation
distance between the head and tail entity embeddings, taking into account both the entity name and
description embeddings.
DistMult: In the DistMult model, the score function is defined as the tri-linear dot product between
the head entity embedding h, the relation embedding r, and the tail entity embedding t:
fr(h,t) =âŸ¨h,r,tâŸ© (12)
In KG-FIT, the entity embeddings are initialized by concatenating the entity name embedding and
the entity description embedding:
h= [hn;hd],t= [tn;td] (13)
Now, letâ€™s expand the DistMult score function by substituting the KG-FIT entity embeddings:
fr(h,t) =âŸ¨[hn;hd],r,[tn;td]âŸ©
=âŸ¨hn,rn,tnâŸ©+âŸ¨hd,rd,tdâŸ©
=dim/2X
i=1(hn,iÂ·rn,iÂ·tn,i) +dimX
i=dim/2+1(hd,iÂ·rd,iÂ·td,i) (14)
where r= [rn;rd]is the relation embedding learned during fine-tuning.
Interpretation :
â€¢âŸ¨hn,rn,tnâŸ©: This term captures the multiplicative interaction between the head entityâ€™s name
embedding, the relation embedding, and the tail entityâ€™s name embedding.
30â€¢âŸ¨hd,rd,tdâŸ©: This term captures the multiplicative interaction between the head entityâ€™s description
embedding, the relation embedding, and the tail entityâ€™s description embedding.
The DistMult score function captures the global semantic information by computing the tri-linear dot
product between the head entity, relation, and tail entity embeddings. The dot product considers the
interactions between the entity name embeddings and the entity description embeddings separately,
allowing the model to capture the global semantic relatedness and attributional similarities.
ComplEx: In the ComplEx model, the score function is defined as:
fr(h,t) =Re(âŸ¨h,r,tâŸ©)
=âŸ¨Re(h),Re(r),Re(t)âŸ©+âŸ¨Im(h),Re(r),Im(t)âŸ©
+âŸ¨Re(h),Im(r),Im(t)âŸ© âˆ’ âŸ¨ Im(h),Im(r),Re(t)âŸ© (15)
where Re(Â·)andIm(Â·)denote the real part and imaginary part of a complex number, and trepresents
the complex conjugate of t.
In KG-FIT, the entity embeddings are initialized as follows:
h=hn+ihd,t=tn+itd (16)
where hn,tnâˆˆRdim/2represent the entity name embeddings (real part) and hd,tdâˆˆRdim/2
represent the entity description embeddings (imaginary part).
The relation embedding ris also a complex-valued vector:
r=rr+iri (17)
where rr,riâˆˆRdim/2are learned embeddings that capture the intricate semantics of the relation in
the complex space.
Thus, the score function using the KG-FIT embeddings becomes:
fr(h,t) =Re(âŸ¨h,r,tâŸ©)
=âŸ¨hn,rr,tnâŸ©+âŸ¨hd,rr,tdâŸ©+âŸ¨hn,ri,tdâŸ© âˆ’ âŸ¨hd,ri,tnâŸ©
=hnâ—¦rrâ—¦tn+hdâ—¦rrâ—¦td+hnâ—¦riâ—¦tdâˆ’hdâ—¦riâ—¦tn (18)
Interpretation:
â€¢hnâ—¦rrâ—¦tnandhdâ—¦rrâ—¦td: These terms represent the fundamental interactions between the head
and tail entity name embeddings modulated by the real part of the relation. They capture symmetric
relationships where the semantic integrity of the relation is maintained irrespective of the direction.
â€¢hnâ—¦riâ—¦tdandâˆ’hdâ—¦riâ—¦tn: These cross-terms incorporate the imaginary part of the relation
embedding, introducing a unique capability to model antisymmetric relations. The inclusion of the
imaginary components allows the score function to account for relations where the direction or the
orientation between entities significantly alters the meaning or the context of the relation.
RotatE: In the RotatE model, each relation is represented as a rotation in the complex plane. The
score function is defined as:
fr(h,t) =âˆ’âˆ¥hâ—¦râˆ’tâˆ¥
= (Re(h)â—¦Re(r)âˆ’Im(h)â—¦Im(r)âˆ’Re(t)) +
+ (Re(h)â—¦Im(r) +Im(h)â—¦Re(r)âˆ’Im(t)) (19)
In RotatE with KG-FIT embeddings, we have:
h=hn+ihd,t=tn+itd (20)
and the relation embedding is:
r= cos( Î¸r) +isin(Î¸r) (21)
where Î¸ris the learned rotation angle for the relation.
31Expanding the RotatE score function using KG-FIT embeddings, we have:
fr(h,t) =âˆ’âˆ¥hâ—¦râˆ’tâˆ¥
=âˆ’[(hnâ—¦cos(Î¸r)âˆ’hdâ—¦sin(Î¸r)âˆ’tn) + (hnâ—¦sin(Î¸r) +hdâ—¦cos(Î¸r)âˆ’td)]
=âˆ’[(hnâ—¦cos(Î¸r)âˆ’tn) + (hdâ—¦cos(Î¸r)âˆ’td) + (hnâ—¦sin(Î¸r))âˆ’(hdâ—¦sin(Î¸r))]
(22)
Interpretation:
â€¢hnâ—¦cos(Î¸r)âˆ’tnandhdâ—¦cos(Î¸r)âˆ’td: These terms represent the rotated head entity name and
description embeddings respectively, which are then compared with the corresponding tail entity
name and description embeddings. The cosine of the relation angle Î¸rscales the embeddings,
effectively capturing the strength of the relationship between the entities.
â€¢hnâ—¦sin(Î¸r)andâˆ’hdâ—¦sin(Î¸r): These terms introduce a phase shift in the entity embeddings
based on the relation angle. The sine of the relation angle Î¸rallows for modeling more com-
plex interactions between the head and tail entities, considering both the name and description
information.
pRotatE: In the pRotatE model, the modulus of the entity embeddings is constrained such that
|hi|=|ti|=C, and the distance function is defined as:
fr(h,t) =âˆ’2CsinÎ¸h+Î¸râˆ’Î¸t
2
1(23)
where Î¸h,Î¸r, and Î¸trepresent the phases of the head entity, relation, and tail entity embeddings,
respectively. For KG-FIT embeddings, the entity embeddings are complex and represented as:
h= [hn;hd],t= [tn;td] (24)
The phases can be calculated as:
Î¸h= arg([ hn;hd]), Î¸ t= arg([ tn;td]), Î¸ r= arg([ r1;r2]) (25)
where r1,r2âˆˆRdim/2are the learned relation embeddings.
Thus, the pRotatE score function using KG-FIT embeddings becomes:
fr(h,t) =âˆ’2Csinarg([hn;hd]) + arg([ r1;r2])âˆ’arg([tn;td])
2
1(26)
Interpretation:
In pRotatE with KG-FIT, the entity phases Î¸handÎ¸tare computed using both the name and description
embeddings, while the relation phase Î¸ris learned through the relation embeddings r1andr2.
The model aims to minimize the phase differencesin Î¸h+Î¸râˆ’Î¸t
2
1for valid triples, considering
both the entity name and description information. This allows pRotatE to capture the complex
interactions between entities and relations in the knowledge graph.
HAKE: In the HAKE (Hierarchy-Aware Knowledge Graph Embedding) model, entities are embedded
into polar coordinate space to capture hierarchical structures. The score function is a combination of
radial and angular distances:
fr(h,t) =âˆ’Î±âˆ¥hmodâ—¦rmodâˆ’tmodâˆ¥2âˆ’Î²sinhphase+rphaseâˆ’tphase
2
1(27)
In KG-FIT, hmod=hd,tmod=td,hphase= arg( hn), and tphase= arg( tn). The learned relation
embedding is r= [rn;rd].
Thus, the HAKE score function using KG-FIT embeddings becomes:
fr(h,t) =âˆ’Î±âˆ¥hdâ—¦rdâˆ’tdâˆ¥2âˆ’Î²sinarg(hn) + arg( rn)âˆ’arg(tn)
2
1(28)
Interpretation:
In HAKE with KG-FIT, the entity description embeddings are used to determine the modulus, while
the entity name embeddings are used to determine the phase. This approach seamlessly utilizes the
information from both types of embeddings from pre-trained language models.
32L Notation Table
Table 14provides a comprehensive list of the notations used throughout this paper, along with their
corresponding descriptions. This table serves as a quick reference to help readers better understand
the concepts presented in our work.
Table 14: Notations and Descriptions in KG-FIT
Notation Description
E Set of entities in the knowledge graph
ei|di Thei-th entity in the knowledge graph | Text description of entity ei
f Text embedding model
ve
i|vd
i Text embedding of entity ei| Text embedding of description di
vi Concatenated embedding of entity eiand description di
Ï„ Clustering threshold
Ï„min, Ï„max|Ï„optim Minimum and maximum clustering thresholds | Optimal clustering threshold
Sâˆ—Silhouette score
labels Ï„ Clustering results at distance threshold Ï„
Hseed Seed hierarchy constructed by agglomerative clustering
Coriginal |Csplit Original cluster in the seed hierarchy | New clusters after splitting Cold
Cleaf Set of leaf clusters in the seed hierarchy
Ci Thei-th new cluster after splitting
k Number of new clusters after splitting
Hsplit Intermediate hierarchy after cluster splitting
THsplit Set of parent-child triples in the intermediate hierarchy
(Pâˆ—, Pl, Pr) Parent-child triple (sub-tree) in the hierarchy
HLHR LLM-guided refined hierarchy
vâ€²
i Sliced text embedding of entity ei
eâ€²
i Randomly initialized embedding of entity ei
Ï Hyperparameter controlling the density of randomized embedding
ei KG-FIT embedding of entity ei
rj Embedding of relation j
n|m Dimension of entity embedding ei| Dimension of relation embedding rj
Ïˆ Hyperparameter controlling the standard deviation
C|Câ€²Cluster that an entity belongs to | Neighbor cluster of C
c|câ€²Cluster embedding of C| Cluster embedding of Câ€²
Sm(C) Set of mnearest neighbor clusters of C
P Parent nodes
pj,pj+1 Embeddings of successive parent nodes along the path from an entity to the root
d(Â·,Â·) Distance function for measuring distances between embeddings
Î²j Weight for the distance to the j-th parent node
Î²0 Initial weight for the closest parent node
Ï• Decay rate for hierarchical distance maintenance
Î»1, Î»2, Î»3 Hyperparameters for the hierarchical clustering constraint
D Set of all triples in the knowledge graph
Ïƒ Sigmoid function
Î³ Margin hyperparameter for link prediction
fr(Â·,Â·) Scoring function defined by structure-based models
Nj Set of negative tail entities sampled for a triple (ei, r, ej)
nj Negative tail entity
enj Embedding of the negative tail entity nj
Î¶1, Î¶2, Î¶3 Hyperparameters for weighting the training objectives
L Average sequence length in PLM-based methods
nPLM Hidden dimension of the PLM in PLM-based methods
33NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: Section 4 .
Guidelines:
â€¢The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Appendix A .
Guidelines:
â€¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
â€¢The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
â€¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
â€¢While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [NA]
34Justification: the paper does not include theoretical results
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢All assumptions should be clearly stated or referenced in the statement of any theorems.
â€¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
â€¢Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Please refer to Section 4and Appendix Ito reproduce our results. We also
release all the code and data.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
â€¢Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
â€¢While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
35Answer: [Yes]
Justification: We release our code and data in the uploaded zipped supplementary materials.
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢While we encourage the release of code and data, we understand that this might not be
possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
â€¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: Section 4 and Appendix I
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
â€¢The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Section 4 .
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
â€¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
â€¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
â€¢It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
36â€¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
â€¢For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: In Appendix H .
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
â€¢The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We have reviewed the NeurIPS Code of Ethics. The research conducted in this
paper conform with it.
Guidelines:
â€¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
â€¢The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: In Appendix A .
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
â€¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
37â€¢The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [Yes]
Justification: In Appendix A .
Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
â€¢Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
â€¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: Section 4 and Appendix B .
Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
â€¢For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
38â€¢If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: In this paper, we provide a subset of PrimeKG, which is described in Appendix
B, and we do not release new assets. We shared an anonymized URL to our code and data.
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢The paper should discuss whether and how consent was obtained from people whose
asset is used.
â€¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: This paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
â€¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
â€¢We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
39