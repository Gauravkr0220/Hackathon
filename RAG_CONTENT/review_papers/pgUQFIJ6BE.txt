Near-Optimal Distributed Minimax Optimization
under the Second-Order Similarity
Qihao Zhou
School of Data Science, Fudan University
zhouqh20@fudan.edu.cnHaishan Ye
School of Management, Xiâ€™an Jiaotong University
SGIT AI Lab, State Grid Corporation of China
yehaishan@xjtu.edu.cn
Luo Luoâˆ—
School of Data Science, Fudan University
Shanghai Key Laboratory for Contemporary Applied Mathematics
luoluo@fudan.edu.cn
Abstract
This paper considers the distributed convex-concave minimax optimization under
the second-order similarity. We propose stochastic variance-reduced optimistic
gradient sliding (SVOGS) method, which takes the advantage of the finite-sum
structure in the objective by involving mini-batch client sampling and variance
reduction. We prove SVOGS can achieve the Îµ-duality gap within communication
rounds of O(Î´D2/Îµ), communication complexity of O(n+âˆšnÎ´D2/Îµ), and local
gradient calls of ËœO(n+ (âˆšnÎ´+L)D2/Îµlog(1/Îµ)), where nis the number of
nodes, Î´is the degree of the second-order similarity, Lis the smoothness parameter,
andDis the diameter of the constraint set. We can verify that all of above
complexity (nearly) matches the corresponding lower bounds. For the specific
Âµ-strongly-convex- Âµ-strongly-convex case, our algorithm has the upper bounds
on communication rounds, communication complexity, and local gradient calls of
O(Î´/Âµlog(1/Îµ)),O((n+âˆšnÎ´/Âµ ) log(1 /Îµ)), and ËœO(n+(âˆšnÎ´+L)/Âµ) log(1 /Îµ))
respectively, which are also nearly tight. Furthermore, we conduct the numerical
experiments to show the empirical advantages of the proposed method.
1 Introduction
We study the distributed minimax optimization problem
min
xâˆˆXmax
yâˆˆYf(x, y) :=1
nnX
i=1fi(x, y), (1)
where fiis the differentiable local function associated with the i-th node, and X âŠ†RdxandY âŠ†Rdy
are the constraint sets. We are interested in the centralized setting, where there are one server node
andnâˆ’1client nodes that collaboratively solve the minimax problem. Without loss of generality,
we assume the function f1is located on the server node and the functions f2, . . . , f nare located on
the client nodes. This formulation is a cornerstone in the study of game theory, aiming to achieve
the Nash equilibrium [ 12,44]. It covers a lot of applications such as signal processing [ 23], optimal
control [41], adversarial learning [44], robust regression [15, 35] and portfolio management [52].
âˆ—The corresponding author
38th Conference on Neural Information Processing Systems (NeurIPS 2024).We focus on the first-order optimization methods for solving convex-concave minimax problem.
The classical full-batch approaches including extra-gradient (EG) method [ 24], forward-backward-
forward (FBF) [ 51], optimistic gradient descent ascent (OGDA) [ 43], dual extrapolation [ 39] and so
forth [ 33,34,38] achieve the optimal first-order oracle complexity under the assumption of Lipschitz
continuous gradient [ 17,42,55]. For the objective with finite-sum structure, the stochastic variance
reduced methods [ 1,10,14,30,53] can reduce the cost of per iteration by using the inexact gradient
and lead to the better overall computational cost than full-batch methods. It is natural to design
the parallel iteration schemes by directly using above ideas to reduce the computational time in
distributed setting.
The communication complexity is a primary bottleneck in distributed optimization. The local
functions in machine learning applications typically exhibit homogeneity [ 3,15,18], which is helpful
to improve the communication efficiency. One common measure used to describe relationships among
local functions is the second-order similarity, e.g., the Hessian of each local function differs by a finite
quantity from the Hessian of global objective. Based on such characterization, several communication
efficient distributed optimization methods have been established [ 4,5,8,19,20,25,29,46,48,50,56].
The highlight of these methods is their communication complexity bounds mainly depend on the
degree of second-order similarity, which is potentially much tighter than the results depend on the
smoothness parameter [6, 7, 11, 13, 16, 21, 22, 25, 26, 28, 32, 36, 37, 47].
Recently, Khaled and Jin [20], Lin et al. [29] showed iterations with partial participation can further
reduce the communication complexity, improving the dependence on the number of nodes. They pro-
posed stochastic variance reduced proximal point methods for convex optimization, which allow only
one of clients to participate into the communication in the most of rounds. Additionally, Beznosikov
et al. [8]combined partial participation with forward-backward-forward based method, reducing
volume of communication complexity for minimax optimization. However, these methods [ 8,20,29]
increase the communication rounds, which result in more expensive time cost in communication than
the full participation strategies [ 5,25]. In other words, the partial participation methods [ 8,20,29]
only reduce the overall volume of information exchanged among the nodes, while the advantage of
parallel communication enjoyed in full participation methods is damaged.
In this paper, we propose a novel distributed minimax optimization method, called stochastic variance-
reduced optimistic gradient sliding (SVOGS), which uses the mini-batch client sampling to balance
communication rounds, communication complexity, and computational complexity. We prove
SVOGS simultaneously achieves the (near) optimal communication complexity, communication
rounds, and local gradient calls for convex-concave minimax problem under the assumption of
second-order similarity. We also conduct numerical experiments to show the superiority of SVOGS.
2 Preliminaries
We focus on the distributed optimization in client-sever framework for solving minimax problem (1).
The notation fipresents the local function on the i-th node. We assume the function f1is located on
the server and the other individuals are located on clients. We stack variables xâˆˆRdxandyâˆˆRdy
as the vector z= [x;y]âˆˆRd, where d=dx+dy. We let Z:=X Ã— Y âŠ† Rdand define the
projection operator PZ(v) := arg minzâˆˆZâˆ¥zâˆ’vâˆ¥for given vâˆˆRd. We also denote the vector
functions Fi:Rdâ†’RdandF:Rdâ†’Rdas
Fi(z) :=
âˆ‡xfi(x, y)
âˆ’âˆ‡yfi(x, y)
and F(z) :=1
nnX
i=1Fi(z).
We consider the following common assumptions for our minimax problem.
Assumption 1. We suppose the constraint set Z âŠ†Rdis a non-empty, closed, and convex.
Assumption 2. We suppose the constraint set Z âŠ†Rdis bounded by diameter D > 0, i.e., we
haveâˆ¥z1âˆ’z2âˆ¥ â‰¤Dfor all z1, z2âˆˆ Z.
Assumption 3. We suppose each local function fi:RdxÃ—Rdyâ†’Ris smooth, i.e., there exists L >0
such that âˆ¥Fi(z1)âˆ’Fi(z2)âˆ¥ â‰¤Lâˆ¥z1âˆ’z2âˆ¥for all iâˆˆ[n]andz1, z2âˆˆRd.
Assumption 4. We suppose each differentiable local function fi:RdxÃ—Rdyâ†’Ris convex-concave,
i.e., we have fi(x, y)â‰¥fi(xâ€², y) +âŸ¨âˆ‡xfi(xâ€², y), xâˆ’xâ€²âŸ©andfi(y)â‰¤fi(yâ€²) +âŸ¨âˆ‡yfi(yâ€²), yâˆ’yâ€²âŸ©
for all iâˆˆ[n],x, xâ€²âˆˆRdxandy, yâ€²âˆˆRdy.
2Assumption 5. We suppose the global objective f:RdxÃ—Rdyâ†’Ris strongly-convex-strongly-
concave, i.e., there exists Âµ >0such that the function f(x, y)âˆ’Âµ
2âˆ¥xâˆ¥2+Âµ
2âˆ¥yâˆ¥2is convex-concave.
Besides, we introduce the assumption of second-order similarity to measure the homogeneity in local
functions [5, 8, 19, 20].
Assumption 6. The local functions f1, . . . , f n:RdxÃ—Rdyâ†’Rare twice differentiable and hold
theÎ´-second-order similarity, i.e., there exists Î´ >0such that
âˆ‡2fi(x, y)âˆ’ âˆ‡2f(x, y)â‰¤Î´
for all iâˆˆ[n],xâˆˆRdxandyâˆˆRdy.
We measure the sub-optimality of the approximate solution z= (x, y)âˆˆ Z by duality gap, that is
Gap( x, y) := max
yâ€²âˆˆYf(x, yâ€²)âˆ’min
xâ€²âˆˆXf(xâ€², y).
We also consider the criterion of the gradient mapping for given z= (x, y)âˆˆ Z [31,40,54], that is,
FÏ„(z) =zâˆ’ PZ(zâˆ’Ï„F(z))
Ï„,
where Ï„ > 0. The gradient mapping FÏ„(z)is a natural extension of gradient operator F(z).
Noticing that we have FÏ„(z) =F(z)if the problem is unconstrained (i.e., Z=Rd), and the
condition FÏ„(z) = 0 is equivalent to the point zis a solution of the problem. Compared with the
duality gap, the norm of gradient mapping is a more popular measure in empirical studied since it is
easy to achieve in practice.
For the specific strongly-convex-strongly-concave case, we can also measure the sub-optimality by
the square of Euclidean distance to the unique solution zâˆ—= (x, y)âˆˆ Z, that is
âˆ¥zâˆ’zâˆ—âˆ¥2=âˆ¥xâˆ’xâˆ—âˆ¥2+âˆ¥yâˆ’yâˆ—âˆ¥2.
Moreover, we use notations O(Â·),Î˜(Â·)andâ„¦(Â·)to hide constants which do not depend on parameters
of the problem, and notations ËœO(Â·),ËœÎ˜(Â·), and Ëœâ„¦(Â·)to additionally hide the logarithmic factors of n,
L,ÂµandÎ´.
3 Related Work
For convex-concave minimax optimization, the full batch first-order methods [ 24,33,34,38,39,43,
51] can achieve Îµ-duality gap within at most O(LD2/Îµ)iterations. Applying these idea to distributed
setting naturally leads to the communication rounds of O(LD2/Îµ)and each round requires all of
thennodes to compute and communicate their local gradient.
In a seminar work, Beznosikov et al. [5]proposed Star Min-Max Data Similarity (SMMDS) algorithm,
which additionally consider the second-orders similarity (Assumption 6) by involving gradient sliding
technique [ 27,45]. The SMMDS requires communication rounds of O(Î´D2/Îµ), which benefits from
the homogeneity in local functions. Each round of this method needs to communicate/compute the
local gradient of all nnodes, and perform the local updates on the server within ËœO(L/Î´log(1/Îµ))
local iterations, which results in the overall communication complexity of O(nÎ´D2/Îµ)and local
gradient complexity of ËœO((nÎ´+L)D2/Îµlog(1/Îµ)). Later, Kovalev et al. [25] introduced extra-
gradient sliding (EGS), which further improves the local gradient complexity to O((nÎ´+L)D2/Îµ).
It is worth pointing out that the communication rounds of O(Î´D2/Îµ)achieved by SMMDS and EGS
matches the lower complexity bound under the second-order similarity assumption [ 5]. However,
these methods enforce all nodes to participate into communication in every round, which does not
sufficiently take the advantage of finite-sum structure in the objective.
Recently, Beznosikov et al. [8]proposed Three Pillars Algorithm with Partial Participation (TPAPP),
which uses the variance-reduced forward-backward-forward method [ 1,10] to encourage only one of
clients participate into the communication in most of the rounds. The TPAPP can achieve point zâˆˆRd
such that E[âˆ¥F(z)âˆ¥2]â‰¤Îµfor unconstrained case within the communication rounds of O(nÎ´2D2/Îµ),
3Table 1: The complexity of achieving E[Gap( x, y)]â‰¤Îµin convex-concave case.
Methods Communication Rounds Communication Complexity Local Gradient Complexity
EG [24] O LD2
Îµ
O nLD2
Îµ
O nLD2
Îµ
SMMDS [5] O Î´D2
Îµ
O nÎ´D2
ÎµËœO (nÎ´+L)D2
Îµlog1
Îµ
EGS [25] O Î´D2
Îµ
O nÎ´D2
Îµ
O (nÎ´+L)D2
Îµ
SVOGS
(Algorithm 1)O Î´D2
Îµ
O 
n+âˆšnÎ´D2
ÎµËœO 
n+(âˆšnÎ´+L)D2
Îµlog1
Îµ
Lower Bounds
(Theorem 3,4,5)â„¦ Î´D2
Îµ
â„¦ 
n+âˆšnÎ´D2
Îµ
â„¦ 
n+(âˆšnÎ´+L)D2
Îµ
Table 2: The complexity of achieving E[âˆ¥xâˆ’xâˆ—âˆ¥2+âˆ¥yâˆ’yâˆ—âˆ¥2]â‰¤Îµin the strongly-convex-strongly-
concave case.â€ These methods use permutation compressors [ 49], which require the assumption of
d > n .â™¯The complexity of TPAPP depends on local iterations number H, where â€œTPAPP (a)â€ and
â€œTPAPP (b)â€ correspond to H=âŒˆL/(âˆšnÎ´)âŒ‰andH=âŒˆ8 log(40 nL/Âµ )âŒ‰respectively.
Methods Communication Rounds Communication Complexity Local Gradient Complexity
EG [24] O L
Âµlog1
Îµ
O nL
Âµlog1
Îµ
O nL
Âµlog1
Îµ
SMMDS [5] O Î´
Âµlog1
Îµ
O nÎ´
Âµlog1
ÎµËœO nÎ´+L
Âµlog1
Îµ
EGS [25] O Î´
Âµlog1
Îµ
O nÎ´
Âµlog1
Îµ
O nÎ´+L
Âµlog1
Îµ
OMASHA [4]â€ O L
Âµlog1
Îµ
O  
n+âˆšnÎ´+L
Âµ
log1
Îµ
O nL
Âµlog1
Îµ
TPA [8]â€ O  
n+âˆšnÎ´
Âµ
log1
Îµ
O  
n+âˆšnÎ´
Âµ
log1
Îµ
O  
n+âˆšnL
Î´+L
Âµ
log1
Îµ
TPAPP (a) [8]â™¯O  
n+âˆšnÎ´
Âµ
log1
Îµ
O  
n+âˆšnÎ´
Âµ
log1
Îµ
O  
n+âˆšnL
Î´+L
Âµ
log1
Îµ
TPAPP (b) [8]â™¯O  
n+âˆšnÎ´+L
Âµ
log1
Îµ
O  
n+âˆšnÎ´+L
Âµ
log1
ÎµËœO  
n+âˆšnÎ´+L
Âµ
log1
Îµ
SVOGS
(Algorithm 1)O Î´
Âµlog1
Îµ
O  
n+âˆšnÎ´
Âµ
log1
ÎµËœO  
n+âˆšnÎ´+L
Âµ
log1
Îµ
Lower Bounds
([5, 8], Theorem 7)â„¦ Î´
Âµlog1
Îµ
â„¦  
n+âˆšnÎ´
Âµ
log1
Îµ
â„¦  
n+âˆšnÎ´+L
Âµ
log1
Îµ
communication complexity of O(nÎ´2D2/Îµ), and local gradient complexity of O(n2Î´4L2D6Îµâˆ’3).2
The theoretical analysis of TPAPP for the constrained problem requires the objective being strongly-
convex-strongly-concave. In addition, we can also reduce the communication complexity by using
the permutation compressors [ 49] for high-dimensional problem [ 4,8], which achieves the similar
complexity to existing partial participation methods [8].
We present the complexity of existing methods and compare them with our results in both general
convex-concave case and strongly-convex-strongly-concave case in Table 1-3.
4 Stochastic Variance-Reduced Optimistic Gradient Sliding
We propose stochastic variance-reduced optimistic gradient sliding (SVOGS) method in Algorithm 1.
The design of our algorithm starts from reformulating problem (1) as follows
min
xâˆˆXmax
yâˆˆYf(x, y) :=1
nnX
i=1(fi(x, y)âˆ’f1(x, y))
| {z }
g(x,y):=f(x,y)âˆ’f1(x,y)+f1(x, y). (3)
The idea of gradient sliding [ 27] on minimax optimization can be viewed as iteratively solving the
surrogate of problem (3) within the quadratic approximation of g(x, y)[5,8,25]. Recall that the
2Although the complexity of TPAPP for achieving E[âˆ¥F(z)âˆ¥]2â‰¤Îµis established for the unconstrained
case, its analysis additionally assume that the sequences generated by the algorithm are bounded by D > 0[8,
Theorem 5.12].
4Table 3: The complexity of achieving E[âˆ¥FÏ„(x, y)âˆ¥2]â‰¤Îµin convex-concave case.Â§The TPAPP
additionally assumes Z=Rdand the sequence generated by the algorithm is bounded by D > 0.
Methods Communication Rounds Communication Complexity Local Gradient Complexity
TPAPP [8]Â§O nÎ´2D2
Îµ
O nÎ´2D2
Îµ
O n2Î´4L2D6
Îµ3
SVOGS
(Algorithm 1)ËœO Î´DâˆšÎµlog1
ÎµËœO  
n+âˆšnÎ´DâˆšÎµ
log1
ÎµËœO  
n+(âˆšnÎ´+L)DâˆšÎµ
log1
Îµ
Algorithm 1 Stochastic Variance-Reduced Optimistic Gradient Sliding (SVOGS)
1:Input: initial point z0= (x0, y0)âˆˆ Z, step size Î·, accuracy {Îµk}K
k=1, communication rounds K,
mini-batch size b, probability pâˆˆ(0,1], weights Î±, Î³âˆˆ(0,1);
2:Initialization: wâˆ’1=zâˆ’1=w0=z0= (x0, y0)âˆˆ Z,z0
i=z0for all iâˆˆ[n];
3:fork= 0,1,2, . . .,Kâˆ’1do
4: Â¯zk= (1âˆ’Î³)zk+Î³wk;
5: Sample Sk={jk
1, . . . , jk
b}uniformly and independently from [n];
6: Î´k=F(wkâˆ’1)âˆ’F1(wkâˆ’1) +1
bX
jâˆˆSk 
Fj(zk)âˆ’F1(zk)âˆ’Fj(wkâˆ’1) +F1(wkâˆ’1)
+Î±
bX
jâˆˆSk 
Fj(zk)âˆ’F1(zk)âˆ’Fj(zkâˆ’1) +F1(zkâˆ’1)
;
7: vk= Â¯zkâˆ’Î·Î´k;
8: FindukâˆˆRdsuch that âˆ¥ukâˆ’Ë†ukâˆ¥2â‰¤Îµk, where Ë†ukis the solution of the problem
min
Ë†xâˆˆXmax
Ë†yâˆˆY
f1(Ë†x,Ë†y) +1
2Î·âˆ¥Ë†xâˆ’vk
xâˆ¥2âˆ’1
2Î·âˆ¥Ë†yâˆ’vk
yâˆ¥2
; (2)
9: zk+1=uk;
10: wk+1=zk+1with probability p,
wkwith probability 1âˆ’p.
11:end for
optimistic gradient descent ascent (OGDA) method [34, 43] iterates with
zk+1=PZ 
zkâˆ’Î·(F(zk) +F(zk)âˆ’F(zkâˆ’1)| {z }
optimistic gradient)
, (4)
where Î· >0is the step size. It is well-known that OGDA achieves optimal convergence rate under the
first-order smoothness assumption [ 42,55], which motivated us construct the quadratic approximation
ofg(x, y)by using the optimistic gradient of gat(xk, yk)in the linear terms, that is
g(x, y)â‰ˆË†g(x, y)
=g(xk, yk) +âŸ¨âˆ‡xg(xk, yk) +âˆ‡xg(xk, yk)âˆ’ âˆ‡ xg(xkâˆ’1, ykâˆ’1)| {z }
optimistic gradient with respect to x, xâˆ’xkâŸ©+1
2Î·xâˆ’xk2
+âŸ¨âˆ‡yg(xk, yk) +âˆ‡yg(xk, yk)âˆ’ âˆ‡ yg(xkâˆ’1, ykâˆ’1)| {z }
optimistic gradient with respect to y, yâˆ’ykâŸ© âˆ’1
2Î·yâˆ’yk2.(5)
Applying approximation (5) to formulation (3), we obtain the optimistic gradient sliding (OGS),
which iteratively solve the sub-problem
(xk+1, yk+1)â‰ˆarg min
Ë†xâˆˆXmax
Ë†yâˆˆYË†g(Ë†x,Ë†y) +f1(Ë†x,Ë†y). (6)
5We can verify function g(x, y)isÎ´-smooth under Assumption 6, which indicates taking Î·= Î˜(1 /Î´)
and solving the sub-problem sufficiently accurate can find an Îµ-suboptimal solution within the
iteration numbers of O(Î´D2/Îµ)andO(Î´/Âµlog(1/Îµ))for the convex-concave case and the strongly-
convex-strongly-concave case respectively (see Section 5). The dependence on Î´implies OGS
benefits from the second-order similarity in local functions, while each of its iteration requires the
communication and the computation of the exact gradient of f(x, y)within the complexity of O(n).
The key idea to improve the cost in each iteration is involving the mini-batch client sampling and
variance reduction with momentum [ 2,26]. Specifically, we estimate the optimistic gradient in
formulation (5) as follows
G(zk) +G(zk)âˆ’G(zkâˆ’1)â‰ˆ1
|Sk|X
jâˆˆSk 
G(wkâˆ’1) +Gj(zk)âˆ’Gj(wkâˆ’1) +Î±(Gj(zk)âˆ’Gj(zkâˆ’1))| {z }
momentum term
,
(7)
where G(z) :=F(z)âˆ’F1(z),SkâŠ†[n]is the random index set, wkis the snapshot point which
is updated infrequently in iterations, and Î±âˆˆ(0,1)is the momentum parameter. Applying the
optimistic gradient estimation (7) to formulations (5)-(6), we achieve our stochastic variance-reduced
optimistic gradient sliding (SVOGS) method (Algorithm 1).
The proposed SVOGS enjoys the mini-batch partial participation in the steps communication and
computation in most of rounds, which is the main difference between SVOGS and existing methods
[5,8,26]. Concretely, taking the mini-batch size |Sk|= Î˜(âˆšn)for SVOGS can simultaneously
balance communication rounds, communication complexity and local gradient complexity. The
SVOGS keeps both the benefit of parallel communication like full participation methods (i.e.,
SMMDS [ 5] and EGS [ 25]) and the low communication cost like existing participation methods
(i.e., TPAPP [ 8]). Additionally, the communication advantage of SVOGS also makes the algorithm
achieves better local gradient complexity than state-of-the-arts [5, 8, 26].
5 The Complexity Analysis
In this section, we provide the complexity analysis of proposed SVOGS (Algorithm 1) to show its
superiority. In particular, we let Âµ= 0for the convex-concave case to the ease of presentation.
We analyze the convergence of SVOGS (Algorithm 1) by establishing the Lyapunov function
Î¦k:=1âˆ’Î³
Î·+Âµ
2
âˆ¥zkâˆ’zâˆ—âˆ¥2+ 2âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâˆ—âŸ©
+1
64Î·âˆ¥zkâˆ’zkâˆ’1âˆ¥2+Î³
4Î·âˆ¥wkâˆ’1âˆ’zkâˆ¥2+(2Î³+Î·Âµ)
2pÎ·âˆ¥wkâˆ’zâˆ—âˆ¥2,(8)
where we take weight Î³â‰¤1/8and the step size Î·â‰¤1/(32Î´)which always guarantees Î¦kâ‰¥0by
using Youngâ€™s inequality and the similarity assumption (see detailed proof in Appendix B).
We show that the decrease of Lyapunov function in expectation as follows.
Lemma 1. Suppose Assumptions 1, 3, 4, and 6 hold with 0â‰¤Âµâ‰¤Î´â‰¤L, running SVOGS (Algo-
rithm 1) with Î·â‰¤min{1/Âµ,1/(32Î´)},Î±= max {1âˆ’Î·Âµ/(6(1âˆ’Î³)),1âˆ’pÎ·Âµ/(2Î³+Î·Âµ)},Î³â‰¤
1/8,256Î·2Î´2Î±2(b+ 1)/bâ‰¤Î±,4Î·Î´2/bâ‰¤Î±Î³/(4Î·), and Îµkâ‰¤câˆ’1min
âˆ¥Ë†ukâˆ’zkâˆ¥,âˆ¥Ë†ukâˆ’zkâˆ¥2	
for some c= poly( Âµ, Î´), then we have
E[Î¦k+1]â‰¤max
1âˆ’Î·Âµ
6(1âˆ’Î³),1âˆ’pÎ·Âµ
2Î³+Î·Âµ
E[Î¦k]âˆ’1
16Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
.
(9)
5.1 The Convex-Concave Case
For the convex-concave case, we use Jensenâ€™s inequality and the convexity (concavity) to bound the
duality gap at uK
avg=1
KPKâˆ’1
k=0ukas follows
Gap( uK
avg)â‰¤max
(xâ€²,yâ€²)âˆˆZ1
KKâˆ’1X
k=0 
f(uk
x, yâ€²)âˆ’f(xâ€², uk
y)
â‰¤max
zâˆˆZ1
KKâˆ’1X
k=0âŸ¨F(uk), ukâˆ’zâŸ©.(10)
6Applying Lemma 1 by summing over inequality (9), we can bound the right-hand side of (10) via the
terms ofPKâˆ’1
k=0E
âˆ¥zkâˆ’Ë†ukâˆ¥2
andPKâˆ’1
k=0E
âˆ¥wkâˆ’Ë†ukâˆ¥2
, and achieve the following theorem.
Theorem 1. Suppose Assumptions 1, 2, 3, 4 and 6 hold with 0< Î´â‰¤LandD > 0, we
run Algorithm 1 with b=âŒˆâˆšnâŒ‰,Î³=p= 1/(âˆšn+ 8),Î·= minâˆšÎ³b/(4Î´),1/(32Î´)	
,
Î±= 1, andÎµk= min
Î¶,Ë†câˆ’1min
âˆ¥Ë†ukâˆ’zkâˆ¥,âˆ¥Ë†ukâˆ’zkâˆ¥2		
for some Î¶= poly( L, Î´, n, D, Îµ )and
Ë†c= poly( Î´). Then we have
E"
max
zâˆˆZ1
KKâˆ’1X
k=0âŸ¨F(uk), ukâˆ’zâŸ©#
â‰¤10D2
Î·K+Îµ
2,where uK
avg=1
KKâˆ’1X
k=0uk.
Theorem 1 shows we can run SVOGS with step size Î·= Î˜(1 /Î´)and communication rounds
ofK=O(Î´D/Îµ )to achieve the Îµ-sub-optimality in expectation. Additionally, each communication
round contains the expected communication complexity of b(1âˆ’p) +np=O(âˆšn), leading to the
overall communication complexity of O(n+âˆšnÎ´D2/Îµ).
The sub-problem (2) in SVOGS (line 8 of Algorithm 1) is a minimax problem with (L+1/Î·)-smooth
and(1/Î·)-strongly-convex- (1/Î·)-strongly-concave objective. Therefore, the setting of ÎµkandÎ·in
the theorem indicates the condition âˆ¥ukâˆ’Ë†ukâˆ¥2â‰¤Îµkcan be achieved by the local iterations number
ofO((L+Î´)/Î´log(Îµk)) = ËœO(L/Î´log(1/Îµ))on the server (e.g., use EG [ 24]). Additionally, each
round of SVOGS contains the expected local gradient complexity of b(1âˆ’p) +np=O(âˆšn)to
achieve the (mini-batch) optimistic gradient Î´k. Hence, the overall local gradient complexity of
SVOGS is ËœO(K(âˆšn+L/Î´log(1/Îµ))) = ËœO(n+ (âˆšnÎ´+L)D2/Îµlog(1/Îµ)). We formally present
the upper complexity bounds of SVOGS for the convex-concave case as follows.
Corollary 1. Following the setting of Theorem 1, we can achieve E[Gap( uK
avg)]â‰¤Îµwithin commu-
nication rounds of O(Î´D2/Îµ), communication complexity of O(n+âˆšnÎ´D2/Îµ), and local gradient
complexity of ËœO(n+ (âˆšnÎ´+L)D2/Îµlog(1/Îµ)), where uK
avg=1
KPKâˆ’1
k=0uk.
5.2 The Strongly-Convex-Strongly-Concave Case
By appropriate settings of SVOGS, Lemma 1 leads to the following linear convergence of our
Lyapunov function in the strongly-convex-strongly-concave case.
Theorem 2. Suppose Assumptions 1, 3, 4, 5 and 6 hold with 0< Âµâ‰¤Î´â‰¤L, we run Algorithm 1 with
b=âŒˆmin{âˆšn, Î´/Âµ}âŒ‰,Î³=p= 1/(min{âˆšn, Î´/Âµ}+ 8),Î·= minâˆšÎ±Î³b/ (4Î´),1/(32Î´)	
,Î±=
max{1âˆ’Î·Âµ/(6(1âˆ’Î³)),1âˆ’pÎ·Âµ/(2Î³+Î·Âµ)}, and Îµk=câˆ’1min
âˆ¥Ë†ukâˆ’zkâˆ¥,âˆ¥Ë†ukâˆ’zkâˆ¥2	
for
some c= poly( Âµ, Î´). Then we have
E[Î¦K]â‰¤max
1âˆ’Î·Âµ
6(1âˆ’Î³),1âˆ’pÎ·Âµ
2Î³+Î·ÂµK
Î¦0.
We then apply Theorem 2 with K=O(Î´/Âµlog(1/Îµ))and analyze the complexity like the discussion
after Theorem 1, which results in the upper complexity bounds as follows.
Corollary 2. Following the setting of Theorem 2, we can achieve E
âˆ¥zKâˆ’zâˆ—âˆ¥2
â‰¤Îµwithin
communication rounds of O(Î´/Âµlog(1/Îµ)), communication complexity of O((n+âˆšnÎ´/Âµ ) log(1 /Îµ)),
and local gradient complexity of ËœO((n+ (âˆšnÎ´+L)/Âµ) log(1 /Îµ)).
5.3 Making the Gradient Mapping Small
For the convex-concave case (under the assumptions of Theorem 1), we can achieve the points with
small gradient mapping by solving the regularized problem
min
xâˆˆXmax
yâˆˆYË†f(x, y) :=f(x, y) +Î»
2xâˆ’x02âˆ’Î»
2yâˆ’y02(11)
for some Î» > 0. Noticing that the function Ë†f(x, y)is(L+Î»)-smooth, Î»-strongly-convex- Î»-
strongly-concave and Î´-similarity. Then Corollary 2 implies running SVOGS (Algorithm 1) by
iterations number K=O(Î´D/âˆšÎµlog(L/Îµ))to solve problem (11) with Î»=O(âˆšÎµ/D)can
7achieve E[âˆ¥FÏ„(zK)âˆ¥2]â‰¤Îµ, which results in the complexity shown in Table 3. For the strongly-
convex-strongly-concave case, the complexity of achieving E[âˆ¥FÏ„(zK)âˆ¥2
â‰¤Îµnearly matches the
complexity of achieving E
âˆ¥zKâˆ’zâˆ—âˆ¥2]â‰¤Îµ. We defer the detailed derivation for these results of
making the gradient mapping small to Appendix G.
6 The Optimality of SVOGS
In this section, we provide the lower complexity bounds for solving our minimax problems by using
distributed first-order oracle (DFO) methods. The class of algorithms considered in our analysis
follows the definition of Beznosikov et al. [8], which is formally described in Appendix D. Compared
with existing lower bound analysis for second-order similarity only focusing on communication [ 5,8],
we additionally study the computation complexity by considering the local gradient calls. The results
in this section imply the complexity of proposed SVOGS (nearly) matches the lower bounds on the
communication rounds, the communication complexity and the local gradient calls simultaneously.
6.1 The Lower Bounds for Convex-Concave Case
We first provide the following lower bounds for convex-concave case.
Theorem 3. For any 0< Î´â‰¤L,nâ‰¥3,D > 0andÎµâ‰¤Î´D2/(12âˆš
2 ), there exist L-smooth and
convex-concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity, and closed convex
setZ=X Ã— Y with diameter D. In order to find an approximate solution z= (x, y)of problem (1)
such that E[Gap( z)]â‰¤Îµ, any DFO algorithm needs at least â„¦(Î´D2/Îµ)communication rounds.
Theorem 4. For any 0< Î´â‰¤L,nâ‰¥2,D > 0andÎµâ‰¤Î´D2/(16âˆš
2n), there exist L-smooth and
convex-concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity, and closed convex
setZ=X Ã— Y with diameter D. In order to find an approximate solution z= (x, y)of problem (1)
such that E[Gap( z)]â‰¤Îµ, any DFO algorithm needs at least â„¦(n+âˆšnÎ´D2/Îµ)communication
complexity and â„¦(n+âˆšnÎ´D2/Îµ)local gradient calls.
The lower bounds on communication round and communication complexity shown in Theorem 3 and 4
match the corresponding upper bounds of SVOGS shown in Corollary 1. However, the lower bound
on local gradient complexity shown in Theorem 4 only nearly matches the result of Corollary 1 in
the case ofâˆšnÎ´â‰¥â„¦(L). Therefore, we also provide the following lower bound on local gradient
complexity to show the tightness of dependence on the smoothness parameter L.
Lemma 2. For any L > 0,nâˆˆN,D > 0andÎµâ‰¤Î´D2/(4âˆš
2), there exist L-smooth and
convex-concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity, and closed convex
setZ=X Ã— Y with diameter D. In order to find an approximate solution z= (x, y)of problem (1)
such that E[Gap( z)]â‰¤Îµ, any DFO algorithm needs at least â„¦(n+LD2/Îµ)local gradient calls.
Combining the results of Theorem 4 and Lemma 2, we achieve the following lower bound on local
gradient complexity, which nearly matches the corresponding upper bound shown in Corollary 1.
Theorem 5. For any 0< Î´â‰¤L,nâ‰¥2,D > 0andÎµâ‰¤Î´D2/(16âˆš
2n), there exist L-smooth and
convex-concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity, and closed convex
setZ=X Ã— Y with diameter D. In order to find an approximate solution z= (x, y)of problem (1)
such that E[Gap( z)]â‰¤Îµ, any DFO algorithm needs at least â„¦(n+ (âˆšnÎ´+L)D2/Îµ)local gradient
calls.
The constructions in our lower bound analysis is based on the modifications on the blinear functions
provided by Han et al. [14], which are originally used to analyze the minimax optimization in non-
distributed setting. We provide detailed proofs in Appendix E. In related work, Beznosikov et al. [5]
also provide the lower bound of â„¦(Î´D2/Îµ)(matching the result of Theorem 3) for communication
rounds by using the regularized function, which is different from our construction in the proof of
Theorem 3. In addition, our lower bounds on the communication complexity and the local gradient
complexity shown in Theorem 4 and 5 are new.
80 50 100 150 200
Communication Rounds106
104
102
100Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGS
02500 5000 7500 10000 12500
Communication Complexity106
104
102
100Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGS
0 20000 40000 60000 80000
Local Gradient Calls106
104
102
100Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGSFigure 1: Results for convex-concave minimax problem (12) on a9a.
0 10 20 30 40 50
Communication Rounds108
106
104
102
||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
0 10000 20000 30000
Communication Complexity108
106
104
102
||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
0 25000 50000 75000 100000
Local Gradient Calls108
106
104
102
||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
Figure 2: Results for strongly-convex-strongly-concave minimax problem (13) on a9a.
6.2 The Lower Bounds for Strongly-Convex-Strongly-Concave Case
The tight lower bound on communication rounds in strongly-convex-strongly-concave case has been
provided by Beznosikov et al. [5, Theorem 1]. We present the result as follows.
Theorem 6 ([5]).For any Âµ, Î´, L > 0withLâ‰¥max{Âµ, Î´}andnâ‰¥3, there exist L-smooth and
convex-concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity such that the function
f(x, y) =1
nPn
i=1fi(x, y)isÂµ-strongly-convex- Âµ-strongly-concave. In order to find a solution of
problem (1) such that E[âˆ¥zâˆ’zâˆ—âˆ¥2]â‰¤Îµ, any DFO algorithm needs at least â„¦(Î´/Âµlog(1/Îµ))
communication rounds.
The tight lower bound on communication complexity has been provided by Beznosikov et al. [8]. We
follow their construction to establish the lower bound on local gradient complexity, nearly matching
the corresponding upper bound of our SVOGS. We formally present these lower bounds as follows.
Theorem 7. For any Âµ, Î´, L > 0withLâ‰¥max{Âµ, Î´}andnâ‰¥2, there exist L-smooth and convex-
concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity such that the function
f(x, y) =1
nPn
i=1fi(x, y)isÂµ-strongly-convex- Âµ-strongly-concave. In order to find a solution of
problem (1) such that E[âˆ¥zâˆ’zâˆ—âˆ¥2]â‰¤Îµ, any DFO algorithm needs at least â„¦((n+âˆšnÎ´/Âµ ) log(1 /Îµ))
communication complexity and â„¦((n+ (âˆšnÎ´+L)/Âµ) log(1 /Îµ))local gradient calls.
7 Experiments
We conduct the experiment on robust linear regression [ 5,15,35]. Concretely, we consider the
constrained convex-concave minimax problem
min
âˆ¥xâˆ¥1â‰¤Rxmax
âˆ¥yâˆ¥â‰¤Ry1
2NNX
i=1 
xâŠ¤(ai+y)âˆ’bi2, (12)
and the unconstrained strongly-convex-strongly-concave minimax problem
min
xâˆˆRdâ€²max
yâˆˆRdâ€²1
2NNX
i=1 
xâŠ¤(ai+y)âˆ’bi2+Î»
2âˆ¥xâˆ¥2âˆ’Î²
2âˆ¥yâˆ¥2, (13)
where xcontains the weights of the model, ydescribes the noise, and {(ai, bi)}N
i=1is the training set.
90 20 40 60 80 100
Communication Rounds1014
1012
1010
108
106
104
102
100Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGS
0 5000 10000 15000 20000
Communication Complexity1014
1012
1010
108
106
104
102
100Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGS
0 20000 40000 60000 80000 100000
Gradient Calls1014
1012
1010
108
106
104
102
100Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGSFigure 3: Results for convex-concave minimax problem (12) on w8a.
0 10 20 30 40 50
Communication Rounds108
106
104
102
||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
0 5000 10000 15000 20000 25000
Communication Complexity108
106
104
102
||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
0 20000 40000 60000 80000 100000
Gradient Calls108
106
104
102
||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
Figure 4: Results for strongly-convex-strongly-concave minimax problem (13) on w8a.
We compare the proposed SVOGS (Algorithm 1) with baselines Extra-Gradient method (EG) [ 24],
Star Min-Max Data Similarity algorithm (SMMDS) [ 5], Extra-Gradient Sliding (EGS) [ 25]), and
Three Pillars Algorithm with Partial Participation (TPAPP) [ 8]. We test the algorithms on real-
world datasets â€œa9aâ€ ( N= 32 ,561,dâ€²= 123 ), â€œw8aâ€ ( N= 49 ,749,dâ€²= 300 ) and â€œcovtypeâ€
(N= 581 ,012,dâ€²= 54 ) from LIBSVM repository [ 9] and set the nodes number be n= 500 . For
problem (12), we set Rx= 2andRy= 0.05, respectively.
We implement all of the methods by Python 3.9 with NumPy and run on a machine with AMD
Ryzen(TM) 7 4800H 8 core with Radeon Graphics 2.90 GHz CPU with 16GB RAM. We solve the
sub-problem in SVOGS (Algorithm 1), SMMDS [ 5], EGS [ 25], and TPAPP [ 8] by Extra-Gradient
method of Korpelevich [24]. We tune the step-size Î·of SVOGS from {0.01,0.1,1}. The probability
pis tuned from {p0,5p0,10p0}, where p0= 1/min{âˆšn+Î´/Âµ}. The batch size bis determined from
{âŒŠb0/10âŒ‹,âŒŠb0/5âŒ‹,âŒŠb0âŒ‹}, with b0= 1/p0. We set the other parameters by following our theoretical
analysis. We set the average weight as Î³= 1âˆ’p. For the momentum parameter, we set Î±= 1for
convex-concave case and Î±= max {1âˆ’Î·Âµ/(6(1âˆ’Î³)),1âˆ’pÎ·Âµ/(2Î³+Î·Âµ)}for strongly-convex-
strongly-concave case, where we estimate Âµbymax{Î», Î²}for problem (13). For the sub-problem
solver, we set its step-size according to the smoothness parameter of sub-problem, i.e., 1/(L+ 1/Î·).
In addition, we estimate the smooth parameter Land the similarity parameter Î´by following the
strategy in Appendix C of Beznosikov et al. [5].
We present the experimental results in Figure 1 to 4 for datasets â€œa9aâ€ and â€œw8aâ€. The results for
dataset â€œcovtypeâ€ is displayed in Appendix H due to the space limitation. We can observe that
our SVOGS outperforms all baselines in terms of the local gradient complexity. Additionally, the
SVOGS requires less communication rounds than classical EG and existing partial participation
method TPAPP, and it requires significantly less communication complexity than full participation
methods EG, SMMDS and EGS. All of these empirical results support our theoretical analysis.
8 Conclusion
This paper presents a novel distributed optimization method named SVOGS, which use the second-
order similarity in local functions and the finite-sum structure in objective to solve the convex-concave
minimax problem within the near-optimal complexity. Our theoretical results are also validated by
the numerical experiments. In future work, it is interesting to use our ideas to improve the efficiency
of distributed nonconvex minimax optimization under the second-order similarity.
10Acknowledgments and Disclosure of Funding
Luo and Zhou is supported by the Major Key Project of Pengcheng Laboratory (No. PCL2024A06),
National Natural Science Foundation of China (No. 62206058), Shanghai Sailing Program
(22YF1402900), and Shanghai Basic Research Program (23JC1401000). Ye is supported in part by
the National Natural Science Foundation of China under Grant 12101491 and in part by the National
Key Research and Development Project of China under Grant 2022YFA1004002.
References
[1]Ahmet Alacaoglu and Yura Malitsky. Stochastic variance reduction for variational inequality
methods. In Conference on Learning Theory , 2022.
[2]Zeyuan Allen-Zhu. Katyusha: The first direct acceleration of stochastic gradient methods.
Journal of Machine Learning Research , 18(221):1â€“51, 2018.
[3]Yossi Arjevani and Ohad Shamir. Communication complexity of distributed convex learning
and optimization. Advances in Neural Information Processing Systems , 2015.
[4]Aleksandr Beznosikov and Alexander Gasnikov. Compression and data similarity: Combination
of two techniques for communication-efficient solving of distributed variational inequalities. In
International Conference on Optimization and Applications , 2022.
[5]Aleksandr Beznosikov, Gesualdo Scutari, Alexander Rogozin, and Alexander Gasnikov. Dis-
tributed saddle-point problems under data similarity. Advances in Neural Information Processing
Systems , 2021.
[6]Aleksandr Beznosikov, Pavel Dvurechenskii, Anastasiia Koloskova, Valentin Samokhin, Se-
bastian U Stich, and Alexander Gasnikov. Decentralized local stochastic extra-gradient for
variational inequalities. Advances in Neural Information Processing Systems , 2022.
[7]Aleksandr Beznosikov, Peter RichtÃ¡rik, Michael Diskin, Max Ryabinin, and Alexander Gas-
nikov. Distributed methods with compressed communication for solving variational inequalities,
with theoretical guarantees. Advances in Neural Information Processing Systems , 2022.
[8]Aleksandr Beznosikov, Martin TakÃ¡c, and Alexander Gasnikov. Similarity, compression and
local steps: three pillars of efficient communications for distributed variational inequalities.
Advances in Neural Information Processing Systems , 2023.
[9]Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a library for support vector machines. ACM
transactions on intelligent systems and technology (TIST) , 2(3):1â€“27, 2011.
[10] Tatjana Chavdarova, Gauthier Gidel, FranÃ§ois Fleuret, and Simon Lacoste-Julien. Reducing
noise in GAN training with variance reduced extragradient. Advances in Neural Information
Processing Systems , 2019.
[11] Yuyang Deng and Mehrdad Mahdavi. Local stochastic gradient descent ascent: Convergence
analysis and communication efficiency. In International Conference on Artificial Intelligence
and Statistics , 2021.
[12] Bahman Gharesifard and Jorge CortÃ©s. Distributed continuous-time convex optimization on
weight-balanced digraphs. IEEE Transactions on Automatic Control , 59(3):781â€“786, 2014.
[13] Eduard Gorbunov, Filip Hanzely, and Peter RichtÃ¡rik. Local SGD: Unified theory and new
efficient methods. In International Conference on Artificial Intelligence and Statistics , 2021.
[14] Yuze Han, Guangzeng Xie, and Zhihua Zhang. Lower complexity bounds of finite-sum
optimization problems: The results and construction. Journal of Machine Learning Research ,
25(2):1â€“86, 2024.
[15] Hadrien Hendrikx, Lin Xiao, Sebastien Bubeck, Francis Bach, and Laurent Massoulie. Statisti-
cally preconditioned accelerated gradient method for distributed optimization. In International
conference on machine learning , 2020.
11[16] Charlie Hou, Kiran K. Thekumparampil, Giulia Fanti, and Sewoong Oh. Efficient algorithms
for federated saddle point optimization. arXiv preprint:2102.06333 , 2021.
[17] Adam Ibrahim, WaÄ±ss Azizian, Gauthier Gidel, and Ioannis Mitliagkas. Linear lower bounds
and conditioning of differentiable games. In International conference on machine learning ,
2020.
[18] Peter Kairouz, H. Brendan McMahan, Brendan Avent, AurÃ©lien Bellet, Mehdi Bennis, Ar-
jun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings,
et al. Advances and open problems in federated learning. Foundations and trends Â®in machine
learning , 14(1â€“2):1â€“210, 2021.
[19] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. SCAFFOLD: Stochastic controlled averaging for federated learning.
InInternational conference on machine learning , 2020.
[20] Ahmed Khaled and Chi Jin. Faster federated optimization under second-order similarity. In
International Conference on Learning Representations , 2023.
[21] Ahmed Khaled, Konstantin Mishchenko, and Peter RichtÃ¡rik. First analysis of local GD on
heterogeneous data. arXiv preprint:1909.04715 , 2019.
[22] Ahmed Khaled, Konstantin Mishchenko, and Peter RichtÃ¡rik. Tighter theory for local SGD on
identical and heterogeneous data. In International Conference on Artificial Intelligence and
Statistics , 2020.
[23] Seung-Jean Kim and Stephen Boyd. A minimax theorem with applications to machine learning,
signal processing, and finance. In IEEE Conference on Decision and Control , 2007.
[24] Galina M. Korpelevich. The extragradient method for finding saddle points and other problems.
Matecon , 12:747â€“756, 1976.
[25] Dmitry Kovalev, Aleksandr Beznosikov, Ekaterina Borodich, Alexander Gasnikov, and Gesualdo
Scutari. Optimal gradient sliding and its application to optimal distributed optimization under
similarity. Advances in Neural Information Processing Systems , 2022.
[26] Dmitry Kovalev, Aleksandr Beznosikov, Abdurakhmon Sadiev, Michael Persiianov, Peter
RichtÃ¡rik, and Alexander Gasnikov. Optimal algorithms for decentralized stochastic variational
inequalities. Advances in Neural Information Processing Systems , 2022.
[27] Guanghui Lan. Gradient sliding for composite optimization. Mathematical Programming , 159:
201â€“235, 2016.
[28] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence
of FedAvg on non-iid data. International Conference on Learning Representations , 2019.
[29] Dachao Lin, Yuze Han, Haishan Ye, and Zhihua Zhang. Stochastic distributed optimization un-
der average second-order similarity: Algorithms and analysis. Advances in Neural Information
Processing Systems , 36, 2024.
[30] Luo Luo, Cheng Chen, Yujun Li, Guangzeng Xie, and Zhihua Zhang. A stochastic proximal
point algorithm for saddle-point problems. arXiv preprint:1909.06946 , 2019.
[31] Luo Luo, Guangzeng Xie, Tong Zhang, and Zhihua Zhang. Near optimal stochastic algorithms
for finite-sum unbalanced convex-concave minimax optimization. arXiv preprint:2106.01761 ,
2021.
[32] Grigory Malinovsky, Kai Yi, and Peter RichtÃ¡rik. Variance reduced ProxSkip: algorithm, theory
and application to federated learning. Advances in Neural Information Processing Systems ,
2022.
[33] Yu Malitsky. Projected reflected gradient methods for monotone variational inequalities. SIAM
Journal on Optimization , 25(1):502â€“520, 2015.
12[34] Yura Malitsky and Matthew K. Tam. A forward-backward splitting method for monotone
inclusions without cocoercivity. SIAM Journal on Optimization , 30(2):1451â€“1472, 2020.
[35] Ulysse Marteau-Ferey, Francis Bach, and Alessandro Rudi. Globally convergent newton
methods for ill-conditioned generalized self-concordant losses. Advances in Neural Information
Processing Systems , 2019.
[36] Konstantin Mishchenko, Grigory Malinovsky, Sebastian Stich, and Peter RichtÃ¡rik. ProxSkip:
Yes! local gradient steps provably lead to communication acceleration! finally! In International
Conference on Machine Learning , pages 15750â€“15769. PMLR, 2022.
[37] Aritra Mitra, Rayana Jaafar, George J. Pappas, and Hamed Hassani. Linear convergence in
federated learning: Tackling client heterogeneity and sparse gradients. Advances in Neural
Information Processing Systems , 2021.
[38] Arkadi Nemirovski. Prox-method with rate of convergence O(1/t)for variational inequali-
ties with lipschitz continuous monotone operators and smooth convex-concave saddle point
problems. SIAM Journal on Optimization , 15:229â€“251, 2004.
[39] Yurii Nesterov. Dual extrapolation and its applications to solving variational inequalities and
related problems. Mathematical Programming , 109(2):319â€“344, 2007.
[40] Yurii Nesterov. Introductory lectures on convex optimization: A basic course , volume 87.
Springer Science & Business Media, 2013.
[41] Ivano Notarnicola, Mauro Franceschelli, and Giuseppe Notarstefano. A duality-based approach
for distributed minâ€“max optimization. IEEE Transactions on Automatic Control , 64(6):2559â€“
2566, 2019.
[42] Yuyuan Ouyang and Yangyang Xu. Lower complexity bounds of first-order methods for
convex-concave bilinear saddle-point problems. Mathematical Programming , 185(1):1â€“35,
2021.
[43] Leonid Denisovich Popov. A modification of the arrow-hurwicz method for search of saddle
points. Mathematical notes of the Academy of Sciences of the USSR , 28:845â€“848, 1980.
[44] Meisam Razaviyayn, Tianjian Huang, Songtao Lu, Maher Nouiehed, Maziar Sanjabi, and
Mingyi Hong. Nonconvex min-max optimization: Applications, challenges, and recent theoreti-
cal advances. IEEE Signal Processing Magazine , 37(5):55â€“66, 2020.
[45] Alexander Rogozin, Aleksandr Beznosikov, Darina Dvinskikh, Dmitry Kovalev, Pavel
Dvurechensky, and Alexander Gasnikov. Decentralized distributed optimization for saddle point
problems. arXiv preprint:2102.07758 , 2021.
[46] Ohad Shamir, Nati Srebro, and Tong Zhang. Communication-efficient distributed optimization
using an approximate newton-type method. In International conference on machine learning ,
2014.
[47] Sebastian U. Stich. Local SGD converges fast and communicates little. arXiv
preprint:1805.09767 , 2018.
[48] Ying Sun, Gesualdo Scutari, and Amir Daneshmand. Distributed optimization based on gradient
tracking revisited: Enhancing convergence rate via surrogation. SIAM Journal on Optimization ,
32(2):354â€“385, 2022.
[49] RafaÅ‚ Szlendak, Alexander Tyurin, and Peter RichtÃ¡rik. Permutation compressors for provably
faster distributed nonconvex optimization. arXiv preprint:2110.03300 , 2021.
[50] Ye Tian, Gesualdo Scutari, Tianyu Cao, and Alexander Gasnikov. Acceleration in distributed op-
timization under similarity. In International Conference on Artificial Intelligence and Statistics ,
2022.
[51] Paul Tseng. A modified forward-backward splitting method for maximal monotone mappings.
SIAM Journal on Control and Optimization , 38(2):431â€“446, 2000.
13[52] Panos Xidonas, George Mavrotas, Christis Hassapis, and Constantin Zopounidis. Robust
multiobjective portfolio optimization: A minimax regret approach. European Journal of
Operational Research , 262(1):299â€“305, 2017.
[53] Guangzeng Xie, Luo Luo, Yijiang Lian, and Zhihua Zhang. Lower complexity bounds for
finite-sum convex-concave minimax optimization problems. In International Conference on
Machine Learning , 2020.
[54] Junchi Yang, Siqi Zhang, Negar Kiyavash, and Niao He. A catalyst framework for minimax
optimization. Advances in Neural Information Processing Systems , 33:5667â€“5678, 2020.
[55] Junyu Zhang, Mingyi Hong, and Shuzhong Zhang. On lower iteration complexity bounds for
the convex concave saddle point problems. Mathematical Programming , 194(1):901â€“935, 2022.
[56] Yuchen Zhang and Xiao Lin. DiSCO: Distributed optimization for self-concordant empirical
loss. In International Conference on Machine Learning , 2015.
14Appendix
The appendix contains additional details supporting the main text. Section A starts with some basic
results. Section B shows the non-negativity of our Lyapunov function. Section C provides the proof
of upper bounds for the proposed method. Section D formally defines the algorithm class in our
lower bound analysis. Section E and F provide the lower complexity bound for both convex-concave
and strongly-convex-strongly-concave cases. Section G demonstrates the complexity of making the
gradient mapping small. Section H presents more experimental results.
A Some Basic Results
We introduce the following lemmas for our later analysis.
Lemma 3 (Lin et al. [29, Proposition B.1 ]).If the local functions f1, . . . , f n:RdxÃ—Rdyâ†’Rhold
theÎ´-second-order similarity, then each (Fiâˆ’F)(Â·)isÎ´-Lipschitz continuous, i.e., we have
âˆ¥(Fiâˆ’F)(z1)âˆ’(Fiâˆ’F)(z2)âˆ¥ â‰¤Î´âˆ¥z1âˆ’z2âˆ¥
for all z1, z2âˆˆRdandiâˆˆ[n].
Lemma 4 (Alacaoglu and Malitsky [1, Section 8 ]).LetF={Fk}kâ‰¥0be a filtration and {rk}be
a stochastic process adapted to FwithE[rk+1|Fk] = 0 . Then for any KâˆˆN,x0âˆˆ Z, and any
compact set C âŠ‚ Z , we have
E"
max
xâˆˆCKâˆ’1X
k=0âŸ¨rk+1, xâŸ©#
â‰¤max
xâˆˆC1
2âˆ¥x0âˆ’xâˆ¥2+1
2Kâˆ’1X
k=0Eâˆ¥rk+1âˆ¥2.
In related work, Beznosikov et al. [8, Assumption 4.3 ]considers the following second-order similarity
assumption that is slightly different from our Assumption 6.
Assumption 7. The local functions f1, . . . , f n:RdxÃ—Rdyâ†’Rare twice differentiable and hold
theÎ´-average-second-order similarity, i.e., there exists Î´ >0such that
1
nnX
i=1âˆ‡2fi(x, y)âˆ’ âˆ‡2fj(x, y)2â‰¤Î´2
for all xâˆˆRdx,yâˆˆRdy, and jâˆˆ[n], .
We present the relationship between Î´-average-second-order similarity (Assumption 7) and Î´-second-
order-similarity (Assumption 6).
Proposition 1. For twice differentiable local functions f1, . . . , f n:RdxÃ—Rdyâ†’R, we have
â€¢If functions {fi}n
i=1hold the Î´-average-second-order similarity, then they also hold the Î´-second-
order similarity.
â€¢If functions {fi}n
i=1hold the Î´-second-order similarity, then they hold the 2Î´-average-second-
order similarity.
Proof. If functions {fi}n
i=1hold the Î´-average-second-order similarity, then for all jâˆˆ[n], we have
âˆ¥âˆ‡2fj(x, y)âˆ’ âˆ‡2f(x, y)âˆ¥2
2=1
nnX
i=1
âˆ‡2fj(x, y)âˆ’ âˆ‡2fi(x, y)2
2
â‰¤1
nnX
i=1âˆ¥âˆ‡2fj(x, y)âˆ’ âˆ‡2fi(x, y)âˆ¥2
2â‰¤Î´2,
where we use the convexity of âˆ¥ Â· âˆ¥2
2. This implies functions {fi}n
i=1also hold the Î´-second-order
similarity.
If functions {fi}n
i=1hold the Î´second-order similarity, then for all jâˆˆ[n], we have
1
nnX
i=1âˆ¥âˆ‡2fj(x, y)âˆ’ âˆ‡2fi(x, y)âˆ¥2
2
â‰¤1
nnX
i=1 
2âˆ¥âˆ‡2fj(x, y)âˆ’ âˆ‡2f(x, y)âˆ¥2
2+ 2âˆ¥âˆ‡2f(x, y)âˆ’ âˆ‡2fi(x, y)âˆ¥2
2
â‰¤(2Î´)2,
15where we use the Youngâ€™s inequality for the matrix 2-norm. This implies functions {fi}n
i=1hold the
2Î´-average-second-order similarity.
B The Non-Negativity of Lyapunov Function
Our convergence analysis is based on the following Lyapunov function
Î¦k=1âˆ’Î³
Î·+Âµ
2
âˆ¥zkâˆ’zâˆ—âˆ¥2+ 2âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâˆ—âŸ©
+1
64Î·âˆ¥zkâˆ’zkâˆ’1âˆ¥2+Î³
2Î·âˆ¥wkâˆ’1âˆ’zkâˆ¥2+(2Î³+Î·Âµ)
2pÎ·âˆ¥wkâˆ’zâˆ—âˆ¥2.
Noticing that we can always guarantees Î¦kâ‰¥0by taking Î·â‰¤1/(32Î´), because the Youngâ€™s
inequality and Lemma 3 indicates
Î¦kâ‰¥1âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2âˆ’1
64Î·Î´2âˆ¥F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk)âˆ¥2
âˆ’64Î·Î´2âˆ¥zkâˆ’zâˆ—âˆ¥2+1
64Î·âˆ¥zkâˆ’zkâˆ’1âˆ¥2
â‰¥1âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2âˆ’1
64Î·Î´2Î´2âˆ¥zkâˆ’zkâˆ’1âˆ¥2âˆ’64Î·Î´2âˆ¥zkâˆ’zâˆ—âˆ¥2+1
64Î·âˆ¥zkâˆ’zkâˆ’1âˆ¥2
â‰¥1
2Î·(1âˆ’128Î·2Î´2)âˆ¥zkâˆ’zâˆ—âˆ¥2â‰¥0,
where we also use Î³â‰¤1/8.
C The Proofs for Upper Complexity Bounds
We provide the proofs for results in Section 5.
C.1 Proof of Lemma 1
In later analysis, we denote Ek[Â·]as the expectation with respect to the random sampled set Skin
round kand denote Ek+1/2[Â·]as the expectation with respect to the random update of the snapshot
point wkin round k. Specifically, we take the constant
c:= 100 +64Î·Î´2
Âµ+ 2048 Î·2Î´2+ 96Î·Âµ+ 64p
2Î·Î¦0 (14)
for the statement of Lemma 1.
We first provide several lemmas that will be used in the proof of Lemma 1.
Lemma 5. Under the setting of Lemma 1, we have
âˆ’2E
âŸ¨Î´kâˆ’Ek[Î´k],Ë†ukâˆ’zkâŸ©
â‰¤1
2Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
+4Î·Î´2
bE
âˆ¥zkâˆ’wkâˆ’1âˆ¥2
+4Î·Î´2Î±2
bE
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
,
and
âˆ’2E
âŸ¨Ek[Î´k] +F1(Ë†uk)âˆ’F(zâˆ—),Ë†ukâˆ’zâˆ—âŸ©
â‰¤2Î´2
ÂµE
âˆ¥Ë†ukâˆ’ukâˆ¥2
+Âµ
2E
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
âˆ’2ÂµE
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
+1
64Î·E
âˆ¥zkâˆ’zk+1âˆ¥2
+ 64Î·Î´2E
âˆ¥Ë†ukâˆ’ukâˆ¥2
âˆ’2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
+1
4Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
+ 4Î·Î´2Î±2E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
âˆ’2Î±E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâˆ—âŸ©
.
16Proof. Firstly note that
Ek[Î´k] =F(zk)âˆ’F1(zk) +Î± 
F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1)
.
According to the uniform and independent sampling and Lemma 3 we have
E
âˆ¥Î´kâˆ’Ek[Î´k]âˆ¥2
â‰¤2E1
bX
jâˆˆSk 
Fj(zk)âˆ’Fj(wkâˆ’1)
âˆ’ 
F(zk)âˆ’F(wkâˆ’1)2
+ 2EÎ±
bX
jâˆˆSk 
Fj(zk)âˆ’Fj(zkâˆ’1)
âˆ’ 
F(zk)âˆ’F(zkâˆ’1)2
=2
b2Eï£®
ï£°X
jâˆˆSk 
Fj(zk)âˆ’Fj(wkâˆ’1)
âˆ’ 
F(zk)âˆ’F(wkâˆ’1)2ï£¹
ï£»
+2Î±2
b2Eï£®
ï£°X
jâˆˆSk 
Fj(zk)âˆ’Fj(zkâˆ’1)
âˆ’ 
F(zk)âˆ’F(zkâˆ’1)2ï£¹
ï£»
â‰¤2
nbEï£®
ï£°nX
j=1 
Fj(zk)âˆ’Fj(wkâˆ’1)
âˆ’ 
F(zk)âˆ’F(wkâˆ’1)2ï£¹
ï£»
+2Î±2
nbEï£®
ï£°nX
j=1 
Fj(zk)âˆ’Fj(zkâˆ’1)
âˆ’ 
F(zk)âˆ’F(zkâˆ’1)2ï£¹
ï£»
â‰¤2Î´2
bE
âˆ¥zkâˆ’wkâˆ’1âˆ¥2
+2Î´2Î±2
bE
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
.
According to the above bound on E
âˆ¥Î´kâˆ’Ek[Î´k]âˆ¥2
, we achieve the first result as follows
âˆ’2E
âŸ¨Î´kâˆ’Ek[Î´k],Ë†ukâˆ’zkâŸ©
â‰¤1
2Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
+ 2Î·E
âˆ¥Î´kâˆ’Ek[Î´k]âˆ¥2
â‰¤1
2Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
+4Î·Î´2
bE
âˆ¥zkâˆ’wkâˆ’1âˆ¥2
+4Î·Î´2Î±2
bE
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
.
Again using Lemma 3, we achieve the second result as follows
âˆ’2E
âŸ¨Ek[Î´k] +F1(Ë†uk)âˆ’F(zâˆ—),Ë†ukâˆ’zâˆ—âŸ©
=âˆ’2E
âŸ¨F(zk)âˆ’F1(zk) +Î± 
F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1)
,Ë†ukâˆ’zâˆ—âŸ©
âˆ’2E
âŸ¨F1(Ë†uk)âˆ’F(zâˆ—),Ë†ukâˆ’zâˆ—âŸ©
=âˆ’2E
âŸ¨F(uk)âˆ’F1(uk)âˆ’F(Ë†uk) +F1(Ë†uk),Ë†ukâˆ’zâˆ—âŸ©
âˆ’2E
âŸ¨F(Ë†uk)âˆ’F(zâˆ—),Ë†ukâˆ’zâˆ—âŸ©
âˆ’2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1),Ë†ukâˆ’zk+1âŸ©
âˆ’2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
âˆ’2Î±E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1),Ë†ukâˆ’zkâŸ©
âˆ’2Î±E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâˆ—âŸ©
â‰¤2Î´2
ÂµE
âˆ¥Ë†ukâˆ’ukâˆ¥2
+Âµ
2E
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
âˆ’2ÂµE
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
+1
64Î·E
âˆ¥zkâˆ’zk+1âˆ¥2
+ 64Î·Î´2E
âˆ¥Ë†ukâˆ’ukâˆ¥2
âˆ’2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
+1
4Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
+ 4Î·Î´2Î±2E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
âˆ’2Î±E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâˆ—âŸ©
.
17Lemma 6. Under setting of Lemma 1, we have
âˆ’1
8Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
âˆ’Î³
Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
âˆ’3Âµ
2E
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
â‰¤ âˆ’1
16Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
âˆ’1
32Î·E
âˆ¥zk+1âˆ’zkâˆ¥2
+1
8Î·+ 3Âµ
E
âˆ¥Ë†ukâˆ’ukâˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
âˆ’Î³
4Î·E
âˆ¥wkâˆ’zk+1âˆ¥2
âˆ’ÂµE
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
.
Proof. From the facts âˆ¥a+bâˆ¥2â‰¥1
2âˆ¥aâˆ¥2âˆ’ âˆ¥bâˆ¥2and3
2âˆ¥a+bâˆ¥2â‰¥ âˆ¥aâˆ¥2âˆ’3âˆ¥bâˆ¥2, we have
âˆ’1
8Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
â‰¤ âˆ’1
16Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
âˆ’1
32Î·E
âˆ¥zk+1âˆ’zkâˆ¥2
+1
16Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥2
,
âˆ’Î³
Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
â‰¤ âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
âˆ’Î³
4Î·E
âˆ¥wkâˆ’zk+1âˆ¥2
+Î³
2Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥2
â‰¤ âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
âˆ’Î³
4Î·E
âˆ¥wkâˆ’zk+1âˆ¥2
+1
16Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥2
,
and
âˆ’3Âµ
2E
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
â‰¤ âˆ’ÂµE
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+ 3ÂµE
âˆ¥Ë†ukâˆ’ukâˆ¥2
,
where we use the setting Î³â‰¤1/8in the second inequality.
Lemma 7. Under setting of Lemma 1, we have
1âˆ’Î³
Î·+Âµ
2
E
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+ 2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
+1
64Î·E
âˆ¥zk+1âˆ’zkâˆ¥2
+Î³
4Î·E
âˆ¥wkâˆ’zk+1âˆ¥2
+Î³+1
2Î·Âµ
pÎ·E
âˆ¥wk+1âˆ’zâˆ—âˆ¥2
â‰¤1âˆ’Î³
Î·E
âˆ¥zkâˆ’zâˆ—âˆ¥2
+ 2Î±E
âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâˆ—âŸ©
+Î±1
64Î·E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+4Î·Î´2
bE
âˆ¥wkâˆ’1âˆ’zkâˆ¥2
âˆ’1
16Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
+
âˆ’7
8Î·+2Î´2
Âµ+ 64Î·Î´2+ 3Âµ
E
âˆ¥Ë†ukâˆ’ukâˆ¥2
+2
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥zk+1âˆ’zâˆ—âˆ¥
+
1âˆ’pÎ·Âµ
2Î³+Î·Âµ(Î³+1
2Î·Âµ)
pÎ·E
âˆ¥wkâˆ’zâˆ—âˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
.
Proof. The optimality of Ë†ukimplies
âŸ¨Î·F1(Ë†uk) + Ë†ukâˆ’vk, zâˆ—âˆ’Ë†ukâŸ© â‰¥0. (15)
Combine equation (15) with the update rule in Line 7 of Algorithm 1 and âŸ¨âˆ’Î³F(zâˆ—), zâˆ—âˆ’Ë†ukâŸ© â‰¥0,
we achieve
âˆ’1
Î·âŸ¨Â¯zkâˆ’Ë†ukâˆ’Î·Î´k,Ë†ukâˆ’zâˆ—âŸ© â‰¤ âˆ’âŸ¨ F1(Ë†uk)âˆ’F(zâˆ—),Ë†ukâˆ’zâˆ—âŸ©. (16)
18Using the result of equation (16), we have
1
Î·âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2=1
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2+2
Î·âŸ¨Ë†ukâˆ’zk,Ë†ukâˆ’zâˆ—âŸ© âˆ’1
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2
=1
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2+2Î³
Î·âŸ¨wkâˆ’zk,Ë†ukâˆ’zâˆ—âŸ© âˆ’2âŸ¨Î´k,Ë†ukâˆ’zâˆ—âŸ©
âˆ’1
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2âˆ’2
Î·âŸ¨Â¯zkâˆ’Ë†ukâˆ’Î·Î´k,Ë†ukâˆ’zâˆ—âŸ©
â‰¤1
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2+2Î³
Î·âŸ¨wkâˆ’zk,Ë†ukâˆ’zâˆ—âŸ© âˆ’2âŸ¨Î´k,Ë†ukâˆ’zâˆ—âŸ©
âˆ’1
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2âˆ’2âŸ¨F1(Ë†uk)âˆ’F(zâˆ—),Ë†ukâˆ’zâˆ—âŸ©
=1
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ—âˆ¥2âˆ’Î³
Î·âˆ¥wkâˆ’Ë†ukâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2
âˆ’1âˆ’Î³
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2âˆ’2âŸ¨Î´kâˆ’Ek[Î´k],Ë†ukâˆ’zk+zkâˆ’zâˆ—âŸ©
âˆ’2âŸ¨Ek[Î´k] +F1(Ë†uk)âˆ’F(zâˆ—),Ë†ukâˆ’zâˆ—âŸ©.
Taking the expectation on above result and using the fact
E
âŸ¨Î´kâˆ’Ek[Î´k], zkâˆ’zâˆ—âŸ©
=E
Ek
âŸ¨Î´kâˆ’Ek[Î´k], zkâˆ’zâˆ—âŸ©
= 0,
we obtain
1
Î·E
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
â‰¤E1
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ—âˆ¥2âˆ’Î³
Î·âˆ¥wkâˆ’Ë†ukâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2
âˆ’E1âˆ’Î³
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2
âˆ’2E
âŸ¨Î´kâˆ’Ek[Î´k],Ë†ukâˆ’zkâŸ©
âˆ’2E
âŸ¨Ek[Î´k] +F1(Ë†uk)âˆ’F(zâˆ—),Ë†ukâˆ’zâˆ—âŸ©
.(17)
Applying Lemma 5 to bound the term âˆ’2E
âŸ¨Î´kâˆ’Ek[Î´k],Ë†ukâˆ’zkâŸ©
in equation (17), we obtain
1
Î·E
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
â‰¤E1
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ—âˆ¥2âˆ’Î³
Î·âˆ¥wkâˆ’Ë†ukâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ—âˆ¥2âˆ’1/4âˆ’Î³
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2
+4Î·Î´2
bE
âˆ¥zkâˆ’wkâˆ’1âˆ¥2
+4Î·Î´2Î±2
bE
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+2Î´2
ÂµE
âˆ¥Ë†ukâˆ’ukâˆ¥2
âˆ’3
2ÂµE
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
+1
64Î·E
âˆ¥zkâˆ’zk+1âˆ¥2
+ 64Î·Î´2E
âˆ¥Ë†ukâˆ’ukâˆ¥2
âˆ’2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
+ 4Î·Î´2Î±2E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
âˆ’2Î±E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâˆ—âŸ©
â‰¤1
Î·E
âˆ¥zkâˆ’zâˆ—âˆ¥2
+Î³
Î·E
âˆ¥wkâˆ’zâˆ—âˆ¥2
âˆ’Î³
Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
âˆ’Î³
Î·E
âˆ¥zkâˆ’zâˆ—âˆ¥2
âˆ’1
8Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
+1
64Î·E
âˆ¥zkâˆ’zk+1âˆ¥2
+4Î·Î´2
bE
âˆ¥zkâˆ’wkâˆ’1âˆ¥2
+4Î·Î´2Î±2
b+ 4Î·Î´2Î±2
E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+2Î´2
Âµ+ 64Î·Î´2
E
âˆ¥Ë†ukâˆ’ukâˆ¥2
(18)
âˆ’2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
âˆ’3Âµ
2E
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
âˆ’2Î±E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâˆ—âŸ©
,
where we use the setting Î³â‰¤1/8in the second inequality.
19Then we consider the terms related to Ë†u. Firstly, we have
1
Î·E
âˆ¥Ë†ukâˆ’zâˆ—âˆ¥2
=1
Î·E
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+1
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥2
âˆ’2
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥zk+1âˆ’zâˆ—âˆ¥
.
(19)
Applying Lemma 6 and plugging equation (19) into equation (18), we have
1
Î·E
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+ 2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
+1
64Î·E
âˆ¥zk+1âˆ’zkâˆ¥2
+Î³
4Î·E
âˆ¥wkâˆ’zk+1âˆ¥2
â‰¤1
Î·E
âˆ¥zkâˆ’zâˆ—âˆ¥2
+ 2Î±E
âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâˆ—âŸ©
+Î±
64Î·E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+Î³
Î·E
âˆ¥wkâˆ’zâˆ—âˆ¥2
âˆ’Î³
Î·E
âˆ¥zkâˆ’zâˆ—âˆ¥2
âˆ’ÂµE
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+4Î·Î´2
bE
âˆ¥zkâˆ’wkâˆ’1âˆ¥2
+2
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥zk+1âˆ’zâˆ—âˆ¥
âˆ’1
16Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
+
âˆ’7
8Î·+2Î´2
Âµ+ 64Î·Î´2+ 3Âµ
E
âˆ¥Ë†ukâˆ’ukâˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
,
(20)
where we use the fact that 256Î·2Î´2Î±2/b+ 256 Î·2Î´2Î±2â‰¤Î±to bound the coefficient before the term
ofE
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
.
Then we add the term
ÂµE
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+Î³+1
2Î·Âµ
pÎ·E
âˆ¥wk+1âˆ’zâˆ—âˆ¥2(21)
to both sides of equation (20) and use the update rule in Line 10 of Algorithm 1 to obtain
Î³+1
2Î·Âµ
pÎ·E
âˆ¥wk+1âˆ’zâˆ—âˆ¥2
=Î³+1
2Î·Âµ
pÎ·E
Ewk+1
âˆ¥wk+1âˆ’zâˆ—âˆ¥2
=Î³+1
2Î·Âµ
Î·E
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+(Î³+1
2Î·Âµ)(1âˆ’p)
pÎ·E
âˆ¥wkâˆ’zâˆ—âˆ¥2
,
and
Î³
Î·+(Î³+1
2Î·Âµ)(1âˆ’p)
pÎ·=
1âˆ’p+pÎ³
(Î³+1
2Î·Âµ)(Î³+1
2Î·Âµ)
pÎ·=
1âˆ’pÎ·Âµ
2Î³+Î·Âµ(Î³+1
2Î·Âµ)
pÎ·.
Combining all above results, we achieve
1âˆ’Î³
Î·+Âµ
2
E
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+ 2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
+1
64Î·E
âˆ¥zk+1âˆ’zkâˆ¥2
+Î³
4Î·E
âˆ¥wkâˆ’zk+1âˆ¥2
+Î³+1
2Î·Âµ
pÎ·E
âˆ¥wk+1âˆ’zâˆ—âˆ¥2
â‰¤1âˆ’Î³
Î·E
âˆ¥zkâˆ’zâˆ—âˆ¥2
+ 2Î±E
âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâˆ—âŸ©
+Î±
64Î·E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+4Î·Î´2
bE
âˆ¥wkâˆ’1âˆ’zkâˆ¥2
âˆ’1
16Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
+
âˆ’7
8Î·+2Î´2
Âµ+ 64Î·Î´2+ 3Âµ
E
âˆ¥Ë†ukâˆ’ukâˆ¥2
+2
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥zk+1âˆ’zâˆ—âˆ¥
+
1âˆ’pÎ·Âµ
2Î³+Î·Âµ(Î³+1
2Î·Âµ)
pÎ·E
âˆ¥wkâˆ’zâˆ—âˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
.
20Lemma 8. Under setting of Lemma 1, we additionally assume E[Î¦k]â‰¤Î¦0holds, then we have
E[Î¦k+1]â‰¤max
1âˆ’Î·Âµ
6(1âˆ’Î³),1âˆ’pÎ·Âµ
2Î³+Î·Âµ
E[Î¦k]âˆ’1
16Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
.
Proof. Recall that the definition of our Lyapunov function is
Î¦k=1âˆ’Î³
Î·+Âµ
2
âˆ¥zkâˆ’zâˆ—âˆ¥2+ 2âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâˆ—âŸ©
+1
64Î·âˆ¥zkâˆ’zkâˆ’1âˆ¥2+Î³
4Î·âˆ¥wkâˆ’1âˆ’zkâˆ¥2+(2Î³+Î·Âµ)
2pÎ·âˆ¥wkâˆ’zâˆ—âˆ¥2.(22)
Recall that we take constant cby equation (14), then the condition
Îµkâ‰¤câˆ’1min
âˆ¥Ë†ukâˆ’zkâˆ¥,âˆ¥Ë†ukâˆ’zkâˆ¥2	
guarantees
E
âˆ¥Ë†ukâˆ’ukâˆ¥
â‰¤ËœÎ¶kmin
E
âˆ¥Ë†ukâˆ’zkâˆ¥
,E
âˆ¥Ë†ukâˆ’zkâˆ¥2	
,
where
ËœÎ¶k=1
32Î·1
9
8Î·+2Î´2
Âµ+ 64Î·Î´2+ 3Âµ+2
Î·+ 2q
2E[Î¦k]
Î·
=1
100 +64Î·Î´2
Âµ+ 2048 Î·2Î´2+ 96Î·Âµ+ 64p
2Î·E[Î¦k]
â‰¥1
100 +64Î·Î´2
Âµ+ 2048 Î·2Î´2+ 96Î·Âµ+ 64p
2Î·Î¦0=1
c.(23)
The inequality (23) is based on the assumption E[Î¦k]â‰¤Î¦0.
Note that we have âˆ¥zk+1âˆ’zâˆ—âˆ¥ â‰¤ âˆ¥ ukâˆ’Ë†ukâˆ¥+âˆ¥Ë†ukâˆ’zkâˆ¥+âˆ¥zkâˆ’zâˆ—âˆ¥, then
âˆ’7
8Î·+2Î´2
Âµ+ 64Î·Î´2+ 3Âµ
E
âˆ¥Ë†ukâˆ’ukâˆ¥2
+2
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥zk+1âˆ’zâˆ—âˆ¥
â‰¤9
8Î·+2Î´2
Âµ+ 64Î·Î´2+ 3Âµ
E
âˆ¥Ë†ukâˆ’ukâˆ¥2
+2
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥Ë†ukâˆ’zkâˆ¥
+2
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥zkâˆ’zâˆ—âˆ¥
â‰¤9
8Î·+2Î´2
Âµ+ 64Î·Î´2+ 3Âµ
E
âˆ¥Ë†ukâˆ’ukâˆ¥2
+2
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥Ë†ukâˆ’zkâˆ¥
+ 2s
2E[Î¦k]
Î·E
âˆ¥Ë†ukâˆ’ukâˆ¥
â‰¤1
32Î·E
âˆ¥Ë†ukâˆ’zkâˆ¥2
.
According to Lemma 7, we have1âˆ’Î³
Î·+Âµ
2
E
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+ 2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
+1
64Î·E
âˆ¥zk+1âˆ’zkâˆ¥2
+Î³
4Î·E
âˆ¥wkâˆ’zk+1âˆ¥2
+Î³+1
2Î·Âµ
pÎ·E
âˆ¥wk+1âˆ’zâˆ—âˆ¥2
â‰¤1âˆ’Î³
Î·E
âˆ¥zkâˆ’zâˆ—âˆ¥2
+ 2Î±E
âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâˆ—âŸ©
+Î±1
64Î·E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+4Î·Î´2
bE
âˆ¥wkâˆ’1âˆ’zkâˆ¥2
+1
32Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
âˆ’1
16Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
+
1âˆ’pÎ·Âµ
2Î³+Î·Âµ(Î³+1
2Î·Âµ)
pÎ·E
âˆ¥wkâˆ’zâˆ—âˆ¥2
.
21From the fact that Î·Âµâ‰¤1, we have
1âˆ’Î³
Î·â‰¤
1âˆ’Î·Âµ
6(1âˆ’Î³)1âˆ’Î³
Î·+Âµ
2
,
and according to the fact that 4Î·Î´2/bâ‰¤Î±Î³/(4Î·), we obtain
1âˆ’Î³
Î·+Âµ
2
E
âˆ¥zk+1âˆ’zâˆ—âˆ¥2
+ 2E
âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâˆ—âŸ©
+1
64Î·E
âˆ¥zk+1âˆ’zkâˆ¥2
+Î³
4Î·E
âˆ¥wkâˆ’zk+1âˆ¥2
+Î³+1
2Î·Âµ
pÎ·E
âˆ¥wk+1âˆ’zâˆ—âˆ¥2
â‰¤
1âˆ’Î·Âµ
6(1âˆ’Î³)1âˆ’Î³
Î·+Âµ
2
E
âˆ¥zkâˆ’zâˆ—âˆ¥2
+
1âˆ’pÎ·Âµ
2Î³+Î·Âµ(Î³+1
2Î·Âµ)
pÎ·E
âˆ¥wkâˆ’zâˆ—âˆ¥2
+ 2Î±E
âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâˆ—âŸ©
+Î±1
64Î·E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+Î±Î³
2Î·E
âˆ¥wkâˆ’1âˆ’zkâˆ¥2
âˆ’1
16Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
.
The definition (22) and the setting Î±= max {1âˆ’Î·Âµ/(6(1âˆ’Î³)),1âˆ’pÎ·Âµ/(2Î³+Î·Âµ)}implies
E[Î¦k+1]â‰¤Î±E[Î¦k]âˆ’1
16Î·E
âˆ¥zkâˆ’Ë†ukâˆ¥2
âˆ’Î³
2Î·E
âˆ¥wkâˆ’Ë†ukâˆ¥2
. (24)
Then we provide the proof of Lemma 1.
Proof. We firstly use the induction to prove
E[Î¦k]â‰¤Î¦0
holds for all kâˆˆN.
Note that it holds for k= 0. Assume we have E[Î¦k]â‰¤Î¦0holds, then Lemma 8 means it holds
E[Î¦k+1]â‰¤max
1âˆ’Î·Âµ
6(1âˆ’Î³),1âˆ’pÎ·Âµ
2Î³+Î·Âµ
E[Î¦k]â‰¤E[Î¦k]â‰¤Î¦0,
which finish the induction.
The result of above induction implies the condition of Lemma 8 always holds. Therefore, we can
apply Lemma 8 to achieve equation (24), which finishes the proof of Lemma 1.
C.2 Proof of Theorem 1
We firstly introduce the following quantities for our analysis
e11(z, k) :=2Î·
bX
jâˆˆSkâŸ¨F(zk)âˆ’Fj(zk)âˆ’F(wkâˆ’1) +Fj(wkâˆ’1),Ë†ukâˆ’zâŸ©,
e12(z, k) :=2Î·Î±
bX
jâˆˆSkâŸ¨F(zk)âˆ’Fj(zk)âˆ’F(zkâˆ’1) +Fj(zkâˆ’1),Ë†ukâˆ’zâŸ©,
e2(z, k) :=âˆ¥wk+1âˆ’zâˆ¥2âˆ’pâˆ¥zkâˆ’zâˆ¥2âˆ’(1âˆ’p)âˆ¥wkâˆ’zâˆ¥2,
Î¨k(z) := (1 âˆ’Î³)âˆ¥zk+1âˆ’zâˆ¥2+Î³
pâˆ¥wkâˆ’zâˆ¥2+1
16âˆ¥zkâˆ’zkâˆ’1âˆ¥2.(25)
Specifically, we take the constant
Î¶:= minÎ·2Îµ2
16(9Î·LD + 3Î·max iâˆˆ[n]âˆ¥Fi(z0)âˆ¥+D)2,Î·Îµ
4(12Î·2Î´2+ 1)
(26)
22and
Ë†c:= 100 + 2048 Î·2Î´2+ 64p
2Î·Î¦0â‰¤102 + 16p
Î¦0/Î´ (27)
for the statement Theorem 1. We then provide several lemmas that will be used in the proof of
Theorem 1.
Lemma 9. Under the setting of Theorem 1, we have
âˆ’2âŸ¨Ek[Î´k] +F1(Ë†uk),Ë†ukâˆ’zâŸ©
â‰¤4LDâˆ¥ukâˆ’Ë†ukâˆ¥+ 2âŸ¨F(uk), zâˆ’ukâŸ©+ (8LD+ 6DF)âˆ¥Ë†ukâˆ’ukâˆ¥+1
16Î·âˆ¥zkâˆ’zk+1âˆ¥2
+ 16Î·Î´2âˆ¥Ë†ukâˆ’ukâˆ¥2âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©
+1
2Î·âˆ¥zkâˆ’Ë†ukâˆ¥2+ 2Î·Î´2Î±2âˆ¥zkâˆ’zkâˆ’1âˆ¥2
âˆ’2Î±âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâŸ©,
where DF:= max iâˆˆ[n]supzâˆˆZâˆ¥Fi(z)âˆ¥.
Proof. Note that the sequence {âˆ¥Fi(z)âˆ¥}n
i=1is bounded on zâˆˆ Z, since we have
DF= max
iâˆˆ[n]sup
zâˆˆZâˆ¥Fi(z)âˆ¥ â‰¤max
iâˆˆ[n]sup
zâˆˆZ(âˆ¥Fi(z)âˆ’Fi(z0)âˆ¥+âˆ¥Fi(z0)âˆ¥)â‰¤LD+ max
iâˆˆ[n]âˆ¥Fi(z0)âˆ¥.
(28)
The Lipschitz continuity of F(Â·)impies
âˆ¥F1(Ë†uk)âˆ¥ âˆ’DFâ‰¤ âˆ¥F1(Ë†uk)âˆ¥ âˆ’ âˆ¥ F1(z)âˆ¥ â‰¤ âˆ¥ F1(Ë†uk)âˆ’F1(z)âˆ¥ â‰¤LD,
then we have
âˆ’2âŸ¨Ek[Î´k] +F1(Ë†uk),Ë†ukâˆ’zâŸ©
=âˆ’2âŸ¨F(zk)âˆ’F1(zk) +Î± 
F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1)
+F1(Ë†uk),Ë†ukâˆ’zâŸ©
=âˆ’2âŸ¨F(uk)âˆ’F1(uk)âˆ’F(Ë†uk) +F1(Ë†uk),Ë†ukâˆ’zâŸ©
âˆ’2âŸ¨F(Ë†uk),Ë†ukâˆ’zâŸ©
âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1),Ë†ukâˆ’zk+1âŸ©
âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©
âˆ’2Î±âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1),Ë†ukâˆ’zkâŸ©
âˆ’2Î±âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâŸ©
â‰¤4LDâˆ¥ukâˆ’Ë†ukâˆ¥+ 2âŸ¨F(uk), zâˆ’ukâŸ©+ (8LD+ 6DF)âˆ¥Ë†ukâˆ’ukâˆ¥+1
16Î·âˆ¥zkâˆ’zk+1âˆ¥2
+ 16Î·Î´2âˆ¥Ë†ukâˆ’ukâˆ¥2âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©
+1
2Î·âˆ¥zkâˆ’Ë†ukâˆ¥2+ 2Î·Î´2Î±2âˆ¥zkâˆ’zkâˆ’1âˆ¥2
âˆ’2Î±âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâŸ©.(29)
Lemma 10. Under the setting of Theorem 1, the quantities defined in equation (25) hold
max
zâˆˆZÎ¨0(z) +E"
max
zâˆˆZKâˆ’1X
k=0e11(z, k) +e12(z, k) +Î³
pe2(z, k)#
â‰¤max
zâˆˆZ4âˆ¥z0âˆ’zâˆ¥2+4Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥zkâˆ’Ë†ukâˆ¥2
+
2p+4Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥wkâˆ’Ë†ukâˆ¥2
+
2p+8Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥Ë†ukâˆ’ukâˆ¥2
.
23Proof. Applying Lemma 4 with x0=z0,F0=Ïƒ(S0),Fk=Ïƒ(S0, . . . ,Skâˆ’1, wk)forkâ‰¥1, and
rk+1=2Î·
bP
jâˆˆSkFj(zk)âˆ’F(zk)âˆ’Fj(wkâˆ’1) +F(wkâˆ’1)and using Ek[rk+1] = 0 , we have
E"
max
zâˆˆZKâˆ’1X
k=0e11(z, k)#
=E"
max
zâˆˆZKâˆ’1X
k=0âŸ¨rk+1, zâŸ©#
â‰¤max
zâˆˆZ1
2âˆ¥z0âˆ’zâˆ¥2+1
2Kâˆ’1X
k=0E
âˆ¥rk+1âˆ¥2
â‰¤max
zâˆˆZ1
2âˆ¥z0âˆ’zâˆ¥2+2Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥zkâˆ’wkâˆ’1âˆ¥2
.
Similarly we can obtain
E"
max
zâˆˆZKâˆ’1X
k=0e12(z, k)#
â‰¤max
zâˆˆZ1
2âˆ¥z0âˆ’zâˆ¥2+2Î·2Î±2Î´2
bKâˆ’1X
k=0E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
.
Applying Lemma 4 with x0=z0,F0=Ïƒ(S0),Fk=Ïƒ(S0, . . . ,Skâˆ’1, wk)forkâ‰¥1, and
rk+1=pzk+1+(1âˆ’p)wkâˆ’wk+1and using the fact that E[âˆ¥wk+1âˆ¥2âˆ’pâˆ¥zk+1âˆ¥2âˆ’(1âˆ’p)âˆ¥wkâˆ¥2] = 0
andEk[rk+1] = 0 , we have
E"
max
zâˆˆZKâˆ’1X
k=0e2(z, k)#
= 2E"
max
zâˆˆZKâˆ’1X
k=0âŸ¨rk+1, zâŸ©#
â‰¤max
zâˆˆZâˆ¥z0âˆ’zâˆ¥2+Kâˆ’1X
k=0E
âˆ¥rk+1âˆ¥2
â‰¤max
zâˆˆZâˆ¥z0âˆ’zâˆ¥2+p(1âˆ’p)Kâˆ’1X
k=0E
âˆ¥zk+1âˆ’wkâˆ¥2
,
where we use
E
âˆ¥rk+1âˆ¥2
=E
Ek+1/2âˆ¥Ek+1/2[wk+1]âˆ’wk+1âˆ¥2
=E
Ek+1/2[âˆ¥wk+1âˆ¥2]âˆ’ âˆ¥Ek+1/2[wk+1]âˆ¥2
=E
pâˆ¥zk+1âˆ¥2+ (1âˆ’p)âˆ¥wkâˆ¥2âˆ’ âˆ¥pzk+1+ (1âˆ’p)wkâˆ¥2
=p(1âˆ’p)E
âˆ¥zk+1âˆ’wkâˆ¥2
.
Note that zk=ukâˆ’1, then we have
max
zâˆˆZÎ¨0(z) +E"
max
zâˆˆZKâˆ’1X
k=0e11(z, k) +e12(z, k) +Î³
pe2(z, k)#
â‰¤4 max
zâˆˆZâˆ¥z0âˆ’zâˆ¥2+2Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥zkâˆ’wkâˆ’1âˆ¥2
+2Î·2Î±2Î´2
bKâˆ’1X
k=0E
âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+p(1âˆ’p)Kâˆ’1X
k=0E
âˆ¥zk+1âˆ’wkâˆ¥2
â‰¤4 max
zâˆˆZâˆ¥z0âˆ’zâˆ¥2+4Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥Ë†ukâˆ’1âˆ’wkâˆ’1âˆ¥2
+4Î·2Î±2Î´2
bKâˆ’1X
k=0E
âˆ¥Ë†ukâˆ’1âˆ’zkâˆ’1âˆ¥2
+ 2pKâˆ’1X
k=0E
âˆ¥Ë†ukâˆ’wkâˆ¥2
+4Î·2Î´2
b+4Î·2Î±2Î´2
b+ 2pKâˆ’1X
k=0E
âˆ¥Ë†ukâˆ’ukâˆ¥2
â‰¤4 max
zâˆˆZâˆ¥z0âˆ’zâˆ¥2+4Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥zkâˆ’Ë†ukâˆ¥2
+
2p+4Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥wkâˆ’Ë†ukâˆ¥2
+
2p+8Î·2Î´2
bKâˆ’1X
k=0E
âˆ¥Ë†ukâˆ’ukâˆ¥2
,
where we use Youngâ€™s inequality and Î±â‰¤1.
24Now we provide the proof of Theorem 1.
Proof. The optimality of Ë†ukimplies for all zâˆˆ Z, we have
âŸ¨Î·F1(Ë†uk) + Ë†ukâˆ’vk, zâˆ’Ë†ukâŸ© â‰¥0. (30)
Combine equation (30) with the update rule in Line 7 of Algorithm 1 , we achieve
âˆ’1
Î·âŸ¨Â¯zkâˆ’Ë†ukâˆ’Î·Î´k,Ë†ukâˆ’zâŸ© â‰¤ âˆ’âŸ¨ F1(Ë†uk),Ë†ukâˆ’zâŸ©. (31)
Then we have
1
Î·âˆ¥Ë†ukâˆ’zâˆ¥2=1
Î·âˆ¥zkâˆ’zâˆ¥2+2
Î·âŸ¨Ë†ukâˆ’zk,Ë†ukâˆ’zâŸ© âˆ’1
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2
=1
Î·âˆ¥zkâˆ’zâˆ¥2+2Î³
Î·âŸ¨wkâˆ’zk,Ë†ukâˆ’zâŸ© âˆ’2âŸ¨Î´k,Ë†ukâˆ’zâŸ©
âˆ’1
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2âˆ’2
Î·âŸ¨Â¯zkâˆ’Ë†ukâˆ’Î·Î´k,Ë†ukâˆ’zâŸ©
â‰¤1
Î·âˆ¥zkâˆ’zâˆ¥2+2Î³
Î·âŸ¨wkâˆ’zk,Ë†ukâˆ’zâŸ© âˆ’2âŸ¨Î´k,Ë†ukâˆ’zâŸ© âˆ’1
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2
âˆ’2âŸ¨F1(Ë†uk),Ë†ukâˆ’zâŸ©
=1
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ¥2âˆ’Î³
Î·âˆ¥wkâˆ’Ë†ukâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2âˆ’1âˆ’Î³
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2
âˆ’2âŸ¨Î´k+F1(Ë†uk),Ë†ukâˆ’zâŸ©
=1
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ¥2âˆ’Î³
Î·âˆ¥wkâˆ’Ë†ukâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2âˆ’1âˆ’Î³
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2
âˆ’2âŸ¨EÎ´k+F1(Ë†uk),Ë†ukâˆ’zâŸ©+1
Î·e11(z, k) +1
Î·e12(z, k),
(32)
Combining the results of equation (32) with Lemma 9, we have
1
Î·âˆ¥Ë†ukâˆ’zâˆ¥2â‰¤1
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ¥2âˆ’Î³
Î·âˆ¥wkâˆ’Ë†ukâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2
âˆ’1âˆ’Î³
Î·âˆ¥Ë†ukâˆ’zkâˆ¥2âˆ’2âŸ¨EÎ´k+F1(Ë†uk),Ë†ukâˆ’zâŸ©+1
Î·e11(z, k) +1
Î·e12(z, k)
â‰¤1
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ¥2âˆ’Î³
Î·âˆ¥wkâˆ’Ë†ukâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2âˆ’1
4Î·âˆ¥Ë†ukâˆ’zkâˆ¥2
+ 2âŸ¨F(uk), zâˆ’ukâŸ©+ (12 LD+ 6DF)âˆ¥Ë†ukâˆ’ukâˆ¥+1
16Î·âˆ¥zkâˆ’zk+1âˆ¥2
+ 16Î·Î´2âˆ¥Ë†ukâˆ’ukâˆ¥2âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©
+ 2Î·Î´2Î±2âˆ¥zkâˆ’zkâˆ’1âˆ¥2âˆ’2Î±âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâŸ©
+1
Î·e11(z, k) +1
Î·e12(z, k),
(33)
where we use the fact Î³â‰¤1/4.
From the fact that âˆ¥a+bâˆ¥2â‰¥1
2âˆ¥aâˆ¥2âˆ’ âˆ¥bâˆ¥2and3
2âˆ¥a+bâˆ¥2â‰¥ âˆ¥aâˆ¥2âˆ’3âˆ¥bâˆ¥2, we have
âˆ’1
4Î·âˆ¥Ë†ukâˆ’zkâˆ¥2â‰¤ âˆ’1
8Î·âˆ¥zk+1âˆ’zkâˆ¥2+1
4Î·âˆ¥Ë†ukâˆ’ukâˆ¥2,
âˆ’Î³
Î·âˆ¥wkâˆ’Ë†ukâˆ¥2â‰¤ âˆ’Î³
2Î·âˆ¥wkâˆ’zk+1âˆ¥2+Î³
Î·âˆ¥Ë†ukâˆ’ukâˆ¥2.(34)
25Plugging equation (34) into equation (33), we achieve
1
Î·âˆ¥Ë†ukâˆ’zâˆ¥2â‰¤1
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2âˆ’1
8Î·âˆ¥zk+1âˆ’zkâˆ¥2
+1
4Î·âˆ¥Ë†ukâˆ’ukâˆ¥2+ 2âŸ¨F(uk), zâˆ’ukâŸ©+ (12 LD+ 6DF)âˆ¥Ë†ukâˆ’ukâˆ¥
+1
16Î·âˆ¥zkâˆ’zk+1âˆ¥2âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©
+ 16Î·Î´2âˆ¥Ë†ukâˆ’ukâˆ¥2âˆ’2Î±âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâŸ©
+ 2Î·Î´2Î±2âˆ¥zkâˆ’zkâˆ’1âˆ¥2âˆ’Î³
2Î·âˆ¥wkâˆ’zk+1âˆ¥2+Î³
Î·âˆ¥Ë†ukâˆ’ukâˆ¥2
+1
Î·e11(z, k) +1
Î·e12(z, k)
â‰¤1
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2âˆ’1
16Î·âˆ¥zk+1âˆ’zkâˆ¥2
âˆ’Î³
2Î·âˆ¥wkâˆ’zk+1âˆ¥2+ 2âŸ¨F(uk), zâˆ’ukâŸ©+ (12 LD+ 6DF)âˆ¥Ë†ukâˆ’ukâˆ¥
âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©+ 2Î·Î´2Î±2âˆ¥zkâˆ’zkâˆ’1âˆ¥2
âˆ’2Î±âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâŸ©
+
16Î·Î´2+1
2Î·
âˆ¥Ë†ukâˆ’ukâˆ¥2+1
Î·e11(z, k) +1
Î·e12(z, k).
Note that the fact
1
Î·âˆ¥Ë†ukâˆ’zâˆ¥2=1
Î·âˆ¥zk+1âˆ’zâˆ¥2+1
Î·âˆ¥Ë†ukâˆ’ukâˆ¥2âˆ’2
Î·âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥zk+1âˆ’zâˆ¥,
then we have
2âŸ¨F(uk), ukâˆ’zâŸ© â‰¤ âˆ’1
Î·âˆ¥zk+1âˆ’zâˆ¥2âˆ’1
Î·âˆ¥Ë†ukâˆ’ukâˆ¥2+2
Î·âˆ¥Ë†ukâˆ’ukâˆ¥âˆ¥zk+1âˆ’zâˆ¥
+1
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2âˆ’1
16Î·âˆ¥zk+1âˆ’zkâˆ¥2
âˆ’Î³
2Î·âˆ¥wkâˆ’zk+1âˆ¥2+ (12 LD+ 6DF)âˆ¥Ë†ukâˆ’ukâˆ¥+ 2Î·Î´2Î±2âˆ¥zkâˆ’zkâˆ’1âˆ¥2
âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©
âˆ’2Î±âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zkâˆ’1) +F1(zkâˆ’1), zkâˆ’zâŸ©
+
16Î·Î´2+1
2Î·
âˆ¥Ë†ukâˆ’ukâˆ¥2+1
Î·e11(z, k) +1
Î·e12(z, k)
â‰¤ âˆ’1
Î·âˆ¥zk+1âˆ’zâˆ¥2âˆ’1
16Î·âˆ¥zk+1âˆ’zkâˆ¥2âˆ’Î³
2Î·âˆ¥zk+1âˆ’wkâˆ¥2
âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©
+1
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·âˆ¥wkâˆ’zâˆ¥2âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2+ 2Î·Î´2Î±2âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+ 2Î±âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâŸ©
+
12LD+ 6DF+2D
Î·
âˆ¥Ë†ukâˆ’ukâˆ¥+ 16Î·Î´2âˆ¥Ë†ukâˆ’ukâˆ¥2
+1
Î·e11(z, k) +1
Î·e12(z, k)
â‰¤ âˆ’1âˆ’Î³
Î·âˆ¥zk+1âˆ’zâˆ¥2âˆ’Î³
Î·pâˆ¥wk+1âˆ’zâˆ¥2âˆ’1
16Î·âˆ¥zk+1âˆ’zkâˆ¥2
âˆ’2âŸ¨F(zk)âˆ’F1(zk)âˆ’F(zk+1) +F1(zk+1), zk+1âˆ’zâŸ©
26+1âˆ’Î³
Î·âˆ¥zkâˆ’zâˆ¥2+Î³
Î·pâˆ¥wkâˆ’zâˆ¥2+ 2Î·Î´2Î±2âˆ¥zkâˆ’zkâˆ’1âˆ¥2
+ 2Î±âŸ¨F(zkâˆ’1)âˆ’F1(zkâˆ’1)âˆ’F(zk) +F1(zk), zkâˆ’zâŸ©
+
12Lâ„¦ + 6 DF+2D
Î·
âˆ¥Ë†ukâˆ’ukâˆ¥+ 16Î·Î´2âˆ¥Ë†ukâˆ’ukâˆ¥2
+1
Î·
e11(z, k) +e12(z, k) +Î³
pe2(z, k)
âˆ’Î³
2Î·âˆ¥zk+1âˆ’wkâˆ¥2.
The parameters settings implies 2Î·Î´2Î±2â‰¤1/(16Î·), then we have
2Î·KE"
max
zâˆˆZ1
KKâˆ’1X
k=0âŸ¨F(uk), ukâˆ’zâŸ©#
â‰¤max
zâˆˆZÎ¨0(z) +E"
max
zâˆˆZKâˆ’1X
k=0e11(z, k) +e12(z, k) +Î³
pe2(z, k)#
+Kâˆ’1X
k=0 
(12Î·LD + 6Î·DF+ 2D)âˆ¥Ë†ukâˆ’ukâˆ¥+ 16Î·2Î´2âˆ¥ukâˆ’Ë†ukâˆ¥2
.(35)
Recall that we take Ë†cby equation (27), then the setting
Îµk= min
Î¶,Ë†câˆ’1min
âˆ¥Ë†ukâˆ’zkâˆ¥,âˆ¥Ë†ukâˆ’zkâˆ¥2		
satisfies the condition on Îµkin Lemma 1. Then we apply Lemma 1 with Âµ= 0andÎ±= 1and sum
over equation (9) with k= 0, . . . , K âˆ’1to obtain
Kâˆ’1X
k=01
32E
âˆ¥zkâˆ’Ë†ukâˆ¥2
+Î³
2E
âˆ¥wkâˆ’Ë†ukâˆ¥2
â‰¤
1 +Î³
p
âˆ¥z0âˆ’zâˆ—âˆ¥2. (36)
Note that parameter settings Î³=p= 1/(âˆšn+ 8) ,b=âŒˆâˆšnâŒ‰, and Î·= minâˆšÎ³b/(4Î´),1/(32Î´)	
satisfy
4Î·2Î´2
bâ‰¤Î³
4â‰¤8Â·1
32,2p+4Î·2Î´2
bâ‰¤2p+4Î´2
bÎ³b
16Î´2â‰¤5Â·Î³
2and 1 +Î³
p= 2. (37)
Substituting equations (36) and (37) into equation (35) and applying Lemma 10, we obtain
E"
max
zâˆˆZ1
KKâˆ’1X
k=0âŸ¨F(uk), ukâˆ’zâŸ©#
â‰¤1
2Î·K(4 + 8 Â·2) max
zâˆˆZâˆ¥z0âˆ’zâˆ¥2
+1
2Î·KKâˆ’1X
k=0
(12Î·LD + 6Î·DF+ 2D)âˆ¥Ë†ukâˆ’ukâˆ¥+
16Î·2Î´2+8Î·2Î´2
b+ 2p
âˆ¥ukâˆ’Ë†ukâˆ¥2
â‰¤10D2
Î·K+6Î·LD + 3Î·DF+D
Î·p
Î¶+12Î·2Î´2+ 1
Î·Î¶
â‰¤10D2
Î·K+9Î·LD + 3Î·max iâˆˆ[n]âˆ¥Fi(z0)âˆ¥+D
Î·p
Î¶+12Î·2Î´2+ 1
Î·Î¶,
where we use the equation (28) to bound DF.
Recall that we take constant Î¶by equation (26), then we get the bound
E"
max
zâˆˆZ1
KKâˆ’1X
k=0âŸ¨F(uk), ukâˆ’zâŸ©#
â‰¤10D2
Î·K+Îµ
2.
27C.3 Proof of Corollary 1
Proof. Theorem 1 means we can achieve E[Gap( uK
avg)]â‰¤Îµby taking the communication rounds of
K=20D2
ÎµÎ·
=OD2
ÎµÎ·
=OÎ´D2
Îµ
.
Consider that the expected communication complexity in each round is O(b(1âˆ’p) +np) =O(âˆšn)
and the server need to communicate with all client in initialization within the communication
complexity of O(n), the overall communication complexity is
O(n) +KÂ· O(âˆšn) =O
n+âˆšnÎ´D2
Îµ
.
Note that the objective of the sub-problem in Line 8 of Algorithm 1 is (L+ 1/Î·)-smooth- (1/Î·)-
strongly-convex- (1/Î·)-strongly-concave, the local gradient complexity for solving the sub-problem
isO((1 + Î·L) log(max {Î¶âˆ’1,Ë†c}). Therefore, the overall local gradient complexity is
O(n) +KÂ· 
O(âˆšn) +O 
(1 +Î·L) log( Î¶âˆ’1+ Ë†c)
=O(n) +OÎ´D2
Îµ
Â· 
O(âˆšn) +O 
1 +L
Î´
log 
LD+DF
Îµ+r
Î¦0
Î´!!!
=ËœO
n+(âˆšnÎ´+L)D2
Îµlog1
Îµ
.
C.4 Proof of Theorem 2
Proof. We can verify that the parameter setting of Theorem 2 satisfies the condition of Lemma 1.
Then we can apply Lemma 1 to obtain
E[Î¦K]â‰¤max
1âˆ’Î·Âµ
6(1âˆ’Î³),1âˆ’pÎ·Âµ
2Î³+Î·ÂµK
Î¦0. (38)
C.5 Proof of Corollary 2
Proof. Recall that we set the parameters as
Î³=p=1
minnâˆšn,Î´
Âµo
+ 8, b=
minâˆšn,Î´
Âµ
,
Î·= minâˆšÎ³b
4Î´,1
32Î´
, Î± = max
1âˆ’Î·Âµ
6(1âˆ’Î³),1âˆ’pÎ·Âµ
2Î³+Î·Âµ
.
We can lower bound Î±as
Î±â‰¥1âˆ’pÎ·Âµ
2Î³+Î·Âµ= 1âˆ’pÎ·Âµ
2p+Î·Âµ= 1âˆ’1
2
Î·Âµ+1
pâ‰¥7
8. (39)
Then the number of communication rounds is
K=O
1 +1
Î·Âµ+Î³+Î·Âµ
pÎ·Âµ
log1
Îµ
=O1
p+1
Î·Âµ
log1
Îµ
=O1
p+1
Âµ
32Î´+32Î´âˆšÎ±Î³b
log1
Îµ
=O1
p+Î´
Âµ+1âˆšpbÎ´
Âµ
log1
Îµ
.
28Note that
1
p+1âˆšpbÎ´
Âµâ‰¤minâˆšn,Î´
Âµ
+ 8 +Î´
Âµvuuutminnâˆšn,Î´
Âµo
+ 8
minnâˆšn,Î´
Âµo
= minâˆšn,Î´
Âµ
+ 8 +Î´
Âµs
1 + 8 max1âˆšn,Âµ
Î´
=OÎ´
Âµ
,
then we have K=O(Î´/Âµlog(1/Îµ)).
Consider that the expected communication complexity in each round is
O(b(1âˆ’p) +np) =Oâˆšn+nÂµ
Î´
,
and the server need to communicate with all client in initialization within the communication
complexity of O(n), the overall communication complexity is
O(n) +KÂ· Oâˆšn+nÂµ
Î´
=O
n+âˆšnÎ´
Âµ
log1
Îµ
.
Note that the objective of the sub-problem in Line 8 of Algorithm 1 is (L+ 1/Î·)-smooth- (1/Î·)-
strongly-convex- (1/Î·)-strongly-concave, the local gradient complexity for solving the sub-problem
isO((1 + Î·L) log( c)). Therefore, the overall local gradient complexity is
O(n) +KÂ·
Oâˆšn+nÂµ
Î´
+O((1 + Î·L) log( c))
=O(n) +OÎ´
Âµlog1
Îµ
Â·
Oâˆšn+nÂµ
Î´
+O
1 +L
Î´
logÎ´
Âµ
=O
n+âˆšnÎ´
Âµ+L
ÂµlogÎ´
Âµ
log1
Îµ
=ËœO
n+âˆšnÎ´+L
Âµ
log1
Îµ
.
D The Algorithm Class
We formally define the distributed first-order oracle (DFO) algorithm as follows.
Definition 1 (DFO Algorithm) .Each node ihas its own local memories Mx
iandMy
ifor the x-
andy-variables with initialization Mx
i=My
i={0}for all iâˆˆ[n]. Specifically, the server has
memories Mx
1andMy
1. These memories {Mx
i}n
i=1and{My
i}n
i=1can be updated as follows:
â€¢Communication from clients to server : During one communication round, we sample uniformly
and independently batch Sof any size band ask client with number from Sto share some vector
of their local memories with the server, i.e. can add points xâ€²
1, yâ€²
1to the local memories of the
server according to the next rule:
xâ€²
1âˆˆspan(
x1,[
iâˆˆSxi)
and yâ€²
1âˆˆspan(
y1,[
iâˆˆSyi)
where xiâˆˆ Mx
iandyiâˆˆ My
i. If the batch size is equal to bwe say that it costs bcommunication
complexity from clients to the server. Batch of the size nis equal to the situation, when all clients
send their memories to the server.
â€¢Communication from server to clients : During one communication round, we sample uniformly
and independently batch Sof any size band ask the server to share some vector of its local
29memories with the clients with numbers from S, i.e. can add points xâ€²
i, yâ€²
ito the corresponding
local memories of client ias
xâ€²
iâˆˆspan{x1, xi} and yâ€²
iâˆˆspan{y1, yi},
where xiâˆˆ Mx
iandyiâˆˆ My
i, and we say that it costs bcommunication complexity.
â€¢Local computations : During local computations each client ican make any computations using
fi, i.e. can add points xâ€²
i, yâ€²
ito the corresponding local memory of client ias
xâ€²
iâˆˆspan{xâ€²,âˆ‡xfi(xâ€²â€², yâ€²â€²)} and yâ€²
iâˆˆspan{yâ€²,âˆ‡yfi(xâ€²â€², yâ€²â€²)},
for given xâ€², xâ€²â€²âˆˆ Mx
iandyâ€², yâ€²â€²âˆˆ My
i. And we use local gradient calls to count the times
whenâˆ‡xandâˆ‡yare applied to any one of {fi}.
The final global output is calculated as Ë†xâˆˆ Mx
1,Ë†yâˆˆ My
1.
Our Definition 1 follows the algorithm class of Beznosikov et al. [8, Definition C.7 ], but additionally
take the communication from the server to the clients into considerations.
E Proofs for Lower Bounds in Convex-Concave Case
In this section, we provide the proofs of the lower bounds for solving the problem
min
xâˆˆXmax
yâˆˆYf(x, y) =1
nnX
i=1fi(x, y) (40)
by DFO algorithms, where the diameters of closed convex sets XandYareRxandRyrespectively.
We define the subspaces {Fk}d
k=0as
Fk=span{e1, . . . , e k}, for1â‰¤kâ‰¤d,
{0d}, fork= 0,
which is used in the following proofs of lower bounds.
E.1 Proof of Theorem 3
We first define the function set with one server ( i= 1) and nâˆ’1clients ( i= 2, . . . , n âˆ’1) as follows
fi(x, y) =ï£±
ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£³Î´
4xâŠ¤A1yâˆ’Î´Ry
2âˆš
deâŠ¤
1x, i âˆ’1â‰¡1 (mod 3) ,
Î´
4xâŠ¤A2y, i âˆ’1â‰¡2 (mod 3) ,
0, otherwise .(41)
Then corresponding global objective is
f(x, y) =Î´
6xâŠ¤Ayâˆ’Î´Ry
6âˆš
deâŠ¤
1x, (42)
where
A1=ï£«
ï£¬ï£¬ï£¬ï£¬ï£­1 0
1âˆ’2
......
1 0
1ï£¶
ï£·ï£·ï£·ï£·ï£¸, A2=ï£«
ï£¬ï£¬ï£¬ï£¬ï£­1âˆ’2
1 0
......
1âˆ’2
1ï£¶
ï£·ï£·ï£·ï£·ï£¸, A=ï£«
ï£¬ï£¬ï£¬ï£¬ï£­1âˆ’1
1âˆ’1
......
1âˆ’1
1ï£¶
ï£·ï£·ï£·ï£·ï£¸.
(43)
Proposition 2. For any dâ‰¥3, the functions fi(x, y)andf(x, y)defined by equations (41) and (42)
satisfy
301.The function fiisL-smooth with Lâ‰¥Î´and convex-concave for all iâˆˆ[n], and the function
set{fi}n
i=1holds Î´-second-order similarity. Thus, the function fis also convex-concave.
2. For 1â‰¤kâ‰¤dâˆ’1, we have
min
(x,y)âˆˆZâˆ©F2
kGap( x, y) = min
xâˆˆXâˆ©F kmax
yâˆˆYf(x, y)âˆ’max
yâˆˆYâˆ©F kmin
xâˆˆXf(x, y)â‰¥Î´RxRy
6p
d(k+ 1).(44)
Proof. The smoothness and the convexity (concavity) are easy to verify. The similarity holds because
âˆ‡2
xxf1(x, y)âˆ’ âˆ‡2
xxf(x, y) =âˆ‡2
xxf2(x, y)âˆ’ âˆ‡2
xxf(x, y) =âˆ‡2
xxf3(x, y)âˆ’ âˆ‡2
xxf(x, y) = 0;
âˆ‡2
yyf1(x, y)âˆ’ âˆ‡2
yyf(x, y) =âˆ‡2
yyf2(x, y)âˆ’ âˆ‡2
yyf(x, y) =âˆ‡2
yyf3(x, y)âˆ’ âˆ‡2
yyf(x, y) = 0;
âˆ¥âˆ‡2
xyf1(x, y)âˆ’ âˆ‡2
xyf(x, y)âˆ¥ â‰¤ âˆ¥âˆ‡2
xyf1(x, y)âˆ¥+âˆ¥âˆ‡2
xyf(x, y)âˆ¥ â‰¤Î´
3â‰¤Î´;
âˆ¥âˆ‡2
xyf2(x, y)âˆ’ âˆ‡2
xyf(x, y)âˆ¥ â‰¤ âˆ¥âˆ‡2
xyf2(x, y)âˆ¥+âˆ¥âˆ‡2
xyf(x, y)âˆ¥ â‰¤Î´5
8+1
3
â‰¤Î´;
âˆ¥âˆ‡2
xyf3(x, y)âˆ’ âˆ‡2
xyf(x, y)âˆ¥ â‰¤ âˆ¥âˆ‡2
xyf3(x, y)âˆ¥+âˆ¥âˆ‡2
xyf(x, y)âˆ¥ â‰¤Î´5
8+1
3
â‰¤Î´.
The function f(x, y)defined by our equation (42) is identical to the function fCC(x, y)defined by
Han et al. [14, Proposition 3.31 ]3by replacing their notation Lwith our Î´and taking n= 3. Then
Proposition 3.31 of Han et al. [14] directly prove the result of equation (44).
The structure of A1andA2results the following lemma.
Lemma 11. For the function set (41), all (x, y)âˆˆ FkÃ— Fkandk= 0, . . . , d âˆ’1, we have
âˆ‡fi(x, y)âˆˆFk+1Ã— Fk+1, (i, k)âˆˆ I1âˆª I2,
FkÃ— Fk, otherwise,
where the index sets are defined as I1:={(i, k) :iâˆ’1â‰¡1 (mod 3) , kâ‰¡0 (mod 2) }and
I2:={(i, k) :iâˆ’1â‰¡2 (mod 3) , kâ‰¡1 (mod 2) }.
Now we provide the proof of Theorem 3.
Proof. Consider the minimax problem (40) with functions (41) and (42), Rx=Ry=D,nâ‰¥3and
d=âŒŠÎ´D2/(3âˆš
2Îµ)âŒ‹ âˆ’1. Then the assumption Îµâ‰¤Î´D2/(12âˆš
2)implies dâ‰¥3. Lemma 11 means
that we need at least one communication round to increase the number of non-zero coordinate, i.e.
(x, y)âˆˆ Z âˆ©F2
K. Running any DFO algorithm with communication rounds of K=âŒŠ(dâˆ’1)/2âŒ‹ â‰¥1,
we have d/2â‰¤(K+ 1)â‰¤(d+ 1)/2and Proposition 2 implies
E[Gap( x, y)]â‰¥ min
(x,y)âˆˆZâˆ©F2
KGap( x, y)â‰¥Î´D2
6p
d(K+ 1)â‰¥Î´D2
6âˆš
2(K+ 1)â‰¥Î´D2
3âˆš
2(d+ 1)â‰¥Îµ.
Hence, we achieve the lower bound on the communication rounds of
K=Î´D2
6âˆš
2Îµ
âˆ’1 = â„¦Î´D2
Îµ
.
E.2 Proof of Theorem 4
We first define the function set with one server ( i= 1) and nâˆ’1clients ( i= 2, . . . , n âˆ’1) as follows
fi(x, y) =ï£±
ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£³âˆ’âˆšnÎ´R y
8âˆš
deâŠ¤
1x, i = 1,
âˆšnÎ´
8xâŠ¤"X
jâ‰¡(iâˆ’1)mod( nâˆ’1)ejaâŠ¤
j#
y, i â‰¥2.(45)
3We follow the notation of Han et al. [14]â€™s arXiv version: https://arxiv.org/pdf/2103.08280v1
31Then corresponding global objective is
f(x, y) =Î´
8âˆšnxâŠ¤Ayâˆ’Î´Ry
8âˆš
ndeâŠ¤
1x, (46)
where ejis the j-th basis column vector, aâŠ¤
jis the j-th row of A,Ai=P
jâ‰¡(iâˆ’1) mod ( nâˆ’1)ejaâŠ¤
j,
A1= 0andAis defined in equation (43).
We provide the following proposition and lemmas for the proof of Theorem 4.
Proposition 3. For any dâ‰¥3,fi(x, y)andf(x, y)defined as equations (45) and (46) satisfy
1.fiisL-smooth with Lâ‰¥âˆšnÎ´/4and convex-concave, function set {fi}n
i=1hasÎ´second-order
similarity. Thus, fis convex-concave.
2. For 1â‰¤kâ‰¤dâˆ’1, we have
min
(x,y)âˆˆZâˆ©F2
kGap( x, y) = min
xâˆˆXâˆ©F kmax
yâˆˆYf(x, y)âˆ’max
yâˆˆYâˆ©F kmin
xâˆˆXf(x, y)â‰¥Î´RxRy
8p
nd(k+ 1).
(47)
Proof. The smoothness and convexity (concavity) are easy to check. And the similarity can be
verified following the methods of Beznosikov et al. [8, Lemma C.8 ]. The function f(x, y)defined by
our equation (46) is identical to the function fCC(x, y)defined by Han et al. [14, Proposition 3.31 ]by
replacing their notation Lwith ourâˆšnÎ´/4. Then Proposition 3.31 of Han et al. [14] directly prove
the result of equation (47).
Lemma 12. Consider the minimax problem (40) with functions (45) and (46), Rx=Ry=D,
d=âŒŠÎ´D2/(4âˆš
2nÎµ)âŒ‹ âˆ’1andÎµâ‰¤Î´D2/(16âˆš
2n). We let M=âŒŠ(dâˆ’1)/2âŒ‹ â‰¥â„¦(Î´D2/(âˆšnÎµ)),
then any point (x, y)âˆˆ Z âˆ© F2
Msatisfies Gap( x, y)â‰¥Îµ.
Proof. The assumptions on ÎµandMimply dâ‰¥3. and d/2â‰¤(M+ 1)â‰¤(d+ 1)/2. Then
Proposition 3 means
Gap( x, y)â‰¥ min
(x,y)âˆˆZâˆ©F2
MGap( x, y)â‰¥Î´D2
8p
nd(M+ 1)â‰¥Î´D2
8âˆš
2n(M+ 1)â‰¥Î´D2
4âˆš
2n(d+ 1)â‰¥Îµ.
Lemma 13. Consider the minimax problem (40) with functions (45) and (46) and run any DFO
algorithm with Vcommunication complexity and Clocal gradient calls. In expectation, only the first
Mâ‰¤min{2V/n, 2C/n}coordinates of the final output can be non-zero while the rest of the dâˆ’M
coordinates are strictly equal to zero.
Proof. At initialization, Mx
i=My
i=F0. Letâ€™s analyze how Mx
iandMy
ichange through local
computations. For the i-th client, we add the following points to Mx
iandMy
ias
xâˆˆspan{xâ€², Aiyâ€²},and yâˆˆspan
e1Â·I{i= 1}, yâ€², AâŠ¤
ixâ€²	
,
where xâ€²âˆˆ Mx
iandyâ€²âˆˆ My
i.
It is easy to see that the server can make the first coordinate of ynon-zero using e1, and broadcast
this progress to other clients. Only updates of the type Aiyâ€²orAâŠ¤
ixâ€²will help in this regard. Since
Aionly contains rows from the matrix Asuch as the (iâˆ’1)-th row, (n+iâˆ’1)-th row, etc., to make
the first coordinate of xin the global output non-zero, we need and can only use the A2matrix. It can
be noted that by using A2, we can also make the second coordinate of ynon-zero after making the
first coordinate of xnon-zero. Furthermore, to make more progress, we need to use A3and so on.
We conclude that we must constantly transfer progress from the node currently needed (to make the
next coordinate of xnon-zero; then of y) to the server, and then to other nodes.
By definition, one communication round involves communication with all clients or only with
batches of some uniform and independent clients. When we sample without replacement, the success
probability of a communication round on clients with batch size b(i.e., making one coordinate
32non-zero) isb
nâˆ’1(or 1 when b=n), which is also the expected number of non-zero coordinates that
can be obtained with bcommunication complexity and at least blocal gradient calls (as each use of
the matrix Anecessarily comes from a gradient call). When we sample with replacement by a batch
sizeb, it is equivalent to that we sample without replacement by batch size 1forbtimes. Assuming
that we have communication rounds with batch sizes (sampling without replacement) of 1,2, . . . , n
fors1, s2, . . . , s ntimes, then the communication complexity we spent is V=Pn
j=1jsjand the
minimum gradient calls we spent is C=Pn
j=1jsj. This implies the expected number of non-zero
coordinates is M=Pnâˆ’1
j=1j
nâˆ’1sj+sn. Therefore, the expected total number of non-zero coordinates
in the global output is at most MforyandMâˆ’1forx(or we can say M). By comparing expressions
ofV,CandM, we can have Mâ‰¤2V/n andMâ‰¤2C/n, completing the proof.
Then we can prove Theorem 4 by combining Lemma 12 and 13.
E.3 Proof of Lemma 2
We choose the function set as
f(x, y) =fi(x, y) =L
2xâŠ¤Ayâˆ’LRy
2âˆš
deâŠ¤
1x,âˆ€iâˆˆ[n], (48)
where Ais defined as equation (43). The structure of Aresults the following lemma.
Lemma 14. For the function set (48), all (x, y)âˆˆ FkÃ— Fkandk= 0, . . . , d âˆ’1, we have
âˆ‡fi(x, y)âˆˆ Fk+1Ã— Fk+1.
One can follow the similar method as the proof of Theorem 4 to prove the following proposition and
lemma for the proof of Lemma 2.
Proposition 4. For any dâ‰¥3,fi(x, y)andf(x, y)defined as equation (48) satisfy
1.fiisL-smooth and convex-concave, function set {fi}n
i=1hasÎ´second-order similarity for any
Î´ >0. Thus, fis convex-concave.
2. For 1â‰¤kâ‰¤dâˆ’1, we have
min
(x,y)âˆˆZâˆ©F2
kGap( x, y) = min
xâˆˆXâˆ©F kmax
yâˆˆYf(x, y)âˆ’max
yâˆˆYâˆ©F kmin
xâˆˆXf(x, y)â‰¥LRxRy
2p
d(k+ 1).
Lemma 15. Consider the minimax problem (40) with the function set (48), Rx=Ry=D,
d=âŒŠÎ´D2/(âˆš
2Îµ)âŒ‹ âˆ’1andÎµâ‰¤Î´D2/(4âˆš
2). We let M=âŒŠ(dâˆ’1)/2âŒ‹ â‰¥ â„¦(LD2/Îµ), then
any point (x, y)âˆˆ Z âˆ© F2
Msatisfies Gap( x, y)â‰¥Îµ.
Then we can prove Lemma 2 by combining Lemma 14 and 15.
E.4 Proof of Theorem 5
Proof. In the case ofâˆšnÎ´â‰¥â„¦(L), the problem with with functions (45) and (46) in Theorem 4
implies the lower bound on the local gradient complexity of
â„¦
n+âˆšnÎ´D2
Îµ
= â„¦
n+(âˆšnÎ´+L)D2
Îµ
.
In the case of Lâ‰¥â„¦(âˆšnÎ´), the problem with function (48) in Lemma 2 implies the lower bound
on the local gradient complexity of â„¦(LD2/Îµ) = â„¦( n+ (âˆšnÎ´+L)D2/Îµ). Combining these two
cases, we achieve the lower bound on the local gradient complexity of â„¦(n+ (âˆšnÎ´+L)D2/Îµ).
F Proofs for Lower Bounds in Strongly-Convex-Strongly-Concave Case
We follow similar steps as in Appendix E to prove Theorem 7. Firstly we divide it into several
detailed theorems and lemmas as below and prove them one by one.
33Theorem 8. For any Âµ, Î´, L > 0withLâ‰¥max{Âµ, Î´}andnâ‰¥2, there exist L-smooth and convex-
concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity such that the function
f(x, y) =1
nPn
i=1fi(x, y)isÂµ-strongly-convex- Âµ-strongly-concave. In order to find a solution of
problem (1) such that E[âˆ¥zâˆ’zâˆ—âˆ¥2]â‰¤Îµ, any DFO algorithm needs at least â„¦((n+âˆšnÎ´/Âµ ) log(1 /Îµ))
communication complexity and â„¦((n+âˆšnÎ´/Âµ ) log(1 /Îµ))local gradient calls.
Lemma 16. For any Âµ, Î´, L > 0withLâ‰¥max{Âµ, Î´}andnâ‰¥2, there exist L-smooth and convex-
concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity such that the function
f(x, y) =1
nPn
i=1fi(x, y)isÂµ-strongly-convex- Âµ-strongly-concave. In order to find a solution of
problem (1) such that E[âˆ¥zâˆ’zâˆ—âˆ¥2]â‰¤Îµ, any DFO algorithm needs at least â„¦(L/Âµlog(1/Îµ))local
gradient calls.
Theorem 9. For any Âµ, Î´, L > 0with Lâ‰¥max{Âµ, Î´}andnâ‰¥2, there exist L-smooth
and convex-concave functions f1, . . . , f n:RdxÃ—RdywithÎ´-second-order similarity such that
the function f(x, y) =1
nPn
i=1fi(x, y)isÂµ-strongly-convex- Âµ-strongly-concave. In order to
find a solution of problem (1) such that E[âˆ¥zâˆ’zâˆ—âˆ¥2]â‰¤Îµ, any DFO algorithm needs at least
â„¦((n+ (âˆšnÎ´+L)/Âµ) log(1 /Îµ))local gradient calls.
F.1 Proof of Theorem 8
We introduce the function set as in [8], which is similar to equation (45) that
fi(x, y) =ï£±
ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£³Âµ
2âˆ¥xâˆ¥2âˆ’Âµ
2âˆ¥yâˆ¥2+Î´2
16ÂµeâŠ¤
1y, i = 1,
Î´âˆšn
4xâŠ¤"X
jâ‰¡(iâˆ’1) mod ( nâˆ’1)ejaâŠ¤
j#
y+Âµ
2âˆ¥xâˆ¥2âˆ’Âµ
2âˆ¥yâˆ¥2, i > 2.(49)
Then corresponding global objective is
f(x, y) =Î´
4âˆšnxâŠ¤Ay+Âµ
2âˆ¥xâˆ¥2âˆ’Âµ
2âˆ¥yâˆ¥2+Î´2
16nÂµeâŠ¤
1y, (50)
where all the notation keeps the same as the former section. We point out that the global objective
function (50) with local functions (49) satisfies Assumptions 1, 3, 4, 5, and 6, with constant Âµ,Î´, and
Lâ‰¥Î´. See Lemma C.8 of Beznosikov et al. [8] for details.
We provide the following lemmas for the proof of Theorem 8.
Lemma 17. Consider the minimax problem (40) with functions (49) and (50) and run any DFO
algorithm with Vcommunication complexity and Clocal gradient calls. In expectation, only the first
Mâ‰¤min{2V/n, 2C/n}coordinates of the final output can be non-zero while the rest of the dâˆ’M
coordinates are strictly equal to zero.
Proof. Follow the proof of Lemma 13.
Lemma 18 (Beznosikov et al. [8, Theorem C.10 ]).LetÂµ, Î´ > 0,nâˆˆN,MâˆˆN. There exists
a centralized distributed saddle-point problem with functions (49) and (50), in which zâˆ—Ì¸= 0and
dâ‰¥max{2 logq(Î±/(4âˆš
2)),2M}where Î±= 16nÂµ2/Î´2andq= (2 + Î±âˆ’âˆš
Î±2+ 4Î±)/2âˆˆ(0,1).
Then for any output (Ë†x,Ë†y)of any DFO algorithm leaving dâˆ’Mcoordinates zero, one can obtain
the following estimate:
âˆ¥Ë†xâˆ’xâˆ—âˆ¥2+âˆ¥Ë†yâˆ’yâˆ—âˆ¥2= â„¦ï£«
ï£­expï£«
ï£­âˆ’16
1 +q
Î´2
16Âµ2n+ 1Â·Mï£¶
ï£¸âˆ¥y0âˆ’yâˆ—âˆ¥2ï£¶
ï£¸.
Then we can prove Theorem 8 by combining Lemma 17 and 18 and noting that to reach a solution of
Îµ-accuracy requires
min2V
n,2C
n
â‰¥M= â„¦
1 +Î´âˆšnÂµ
log1
Îµ
.
34F.2 Proof of Lemma 16
We introduce the function set as
f(x, y) =fi(x, y) =L
2xâŠ¤ËœAy+Âµ
2âˆ¥xâˆ¥2âˆ’Âµ
2âˆ¥yâˆ¥2+L2
4ÂµeâŠ¤
1y,âˆ€iâˆˆ[n], (51)
where
ËœA=ï£«
ï£¬ï£¬ï£­1
1âˆ’1...
...
1âˆ’1ï£¶
ï£·ï£·ï£¸.
Note that since all the nodes have the same function, this function set (51) satisfies Assumptions 1, 3,
4, 5, and 6 for L, Âµ and any Î´ >0. The structure of ËœAresults the following lemma.
Lemma 19. For the function set (51), all (x, y)âˆˆ FkÃ— Fkandk= 0, . . . , d âˆ’1, we have
âˆ‡fi(x, y)âˆˆ Fk+1Ã— Fk+1.
Lemma 20. LetÂµ, Î´, L > 0,nâˆˆN,CâˆˆN. There exists a centralized distributed saddle-point
problem with functions (51), in which zâˆ—Ì¸= 0anddâ‰¥max{2 logq(Î±/âˆš
2),4C}where Î±=Âµ2/L2
andq= 1 + 2 Î±âˆ’2âˆš
Î±2+Î±âˆˆ(0,1). Then for any DFO algorithm, the output (xC, yC)after C
local gradient calls will satisfies
âˆ¥yCâˆ’yâˆ—âˆ¥2â‰¥qCÂ·âˆ¥y0âˆ’yâˆ—âˆ¥2
16. (52)
Proof. Follow the proof of Theorem 3.5 by Zhang et al. [55], in which we take Lx=Ly=Lxy=L
andÂµx=Âµy=Âµ.
Then we can prove Lemma 16 by combining Lemma 19 and 20 and noting that to reach a solution
withÎµ-accuracy needs at least â„¦(L/Âµlog(1/Îµ))local gradient calls from equation (52).
F.3 Proof of Theorem 9
Proof. In the case of nÂµ+âˆšnÎ´â‰¥â„¦(L), the problem with with functions (49) and (50) in Theorem
8 implies the lower bound on the local gradient complexity of
â„¦
n+âˆšnÎ´
Âµ
log1
Îµ
= â„¦
n+âˆšnÎ´+L
Âµ
log1
Îµ
.
In the case of Lâ‰¥â„¦(nÂµ+âˆšnÎ´), the problem with function (51) in Lemma 16 implies the lower
bound on the local gradient complexity of â„¦(L/Âµlog(1/Îµ)) = â„¦(( n+ (âˆšnÎ´+L)/Âµ) log(1 /Îµ)).
Combining these two cases, we can achieve the lower bound on the local gradient complexity of
â„¦((n+ (âˆšnÎ´+L)/Âµ) log(1 /Îµ)).
G Making the Gradient Small
In constrained case, we can also use gradient mapping to measure the sub-optimality of a solution z,
that is
FÏ„(z) =zâˆ’ PZ(zâˆ’Ï„F(z))
Ï„.
For the L-smooth convex-concave function f, we consider the constrained problem
min
xâˆˆXmax
yâˆˆYË†f(x, y) :=f(x, y) +Î»
2xâˆ’x02âˆ’Î»
2yâˆ’y02,
350 20 40 60 80 100 120
Communication Rounds1013
1011
109
107
105
103
101
101Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGS
0 5000 10000 15000 20000
Communication Complexity1014
1012
1010
108
106
104
102
100Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGS
0 20000 40000 60000 80000 100000
Gradient Calls1013
1011
109
107
105
103
101
101Gradient Mapping
EG
SMMDS
EGS
TPAPP
SVOGSFigure 5: Results for convex-concave minimax problem (12) on covtype.
0 10 20 30 40 50
Communication Rounds1011
109
107
105
103
101
||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
0 2500 5000 7500 10000 12500
Communication Complexity1010
108
106
104
102
100||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
0 20000 40000 60000
Gradient Calls1011
109
107
105
103
101
||zz*||2
EG
SMMDS
EGS
TPAPP
SVOGS
Figure 6: Results for strongly-convex-strongly-concave minimax problem (13) on covtype.
where Ë†fisÎ»-strongly-convex- Î»-strongly-concave and Zis bounded by diameter D. From the the
result of Theorem 2, we have EzKâˆ’Ë†zâˆ—2
â‰¤(1âˆ’Ï‡Î»/Î´ )Kz0âˆ’Ë†zâˆ—2for some constant
Ï‡âˆˆ(0,1), then we have
E
âˆ¥FÏ„(zK)âˆ¥
=EzKâˆ’ PZ
zKâˆ’Ï„(Ë†F(zK)âˆ’Î»(zKâˆ’z0))
Ï„
=EPZ(zK)âˆ’ PZ
zKâˆ’Ï„(Ë†F(zK)âˆ’Î»(zKâˆ’z0))
Ï„
â‰¤EhË†F(zK)âˆ’Î»(zKâˆ’z0)i
â‰¤EhË†F(zK)i
+Î»EzKâˆ’z0
=EhË†F(zK)âˆ’Ë†F(Ë†zâˆ—)i
+Î»EzKâˆ’z0
â‰¤LEzKâˆ’Ë†zâˆ—
+Î»EzKâˆ’z0
,
where we use the property of the projection that âˆ¥PZ(z1)âˆ’ PZ(z2)âˆ¥ â‰¤ âˆ¥ z1âˆ’z2âˆ¥and the gradient
mapping holds that FÏ„(Ë†zâˆ—) = 0 . Then we have
EhF(zK)2i
â‰¤2L2EhzKâˆ’Ë†zâˆ—2i
+ 2Î»2EhzKâˆ’z02i
â‰¤2L2(1âˆ’Ï‡Î»/Î´ )Kz0âˆ’Ë†zâˆ—2+ 2Î»2EhzKâˆ’z02i
â‰¤(2L2(1âˆ’Ï‡Î»/Î´ )K+ 2Î»2)D2.
LetÎ»=p
Îµ/(4D2)andK=O(Î´/Î»log(L/Îµ)), then we have EF(zK)2
â‰¤Îµ.
Hence, the complexity of communication rounds is K=O(Î´D/âˆšÎµlog(L/Îµ)). We verify that the
corresponding communication complexity is ËœO((n+âˆšnÎ´D/âˆšÎµ) log(1 /Îµ))and the local gradient
complexity is ËœO((n+ (âˆšnÎ´+L)D/âˆšÎµ) log(1 /Îµ))by following the discussion in Appendix C.5.
H More Experimental Results
We present the experimental results on dataset â€œcovtypeâ€ in Figure 5 and 6.
36NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: [Yes] See Section 1.
Guidelines:
â€¢The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: [Yes] See Section 8.
Guidelines:
â€¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
â€¢The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
â€¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
â€¢While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
37Justification: [Yes] See Section 2 and Appendix A-G.
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢All assumptions should be clearly stated or referenced in the statement of any theorems.
â€¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
â€¢Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: [Yes] See Section 7.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
â€¢Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
â€¢While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
38Answer: [Yes]
Justification: [Yes] We include the code in the supplemental materials.
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢While we encourage the release of code and data, we understand that this might not be
possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
â€¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: [Yes] See Section 7 and Appendix H.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
â€¢The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: [No] Error bars were not reported due to their potential to obscure the clarity
of convergence dynamics in the graph representation.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
â€¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
â€¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
39â€¢It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
â€¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
â€¢For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: [Yes] See Section 7 and Appendix H.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
â€¢The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: [Yes]
Guidelines:
â€¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
â€¢The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: [NA] The paper focuses on optimizing algorithmic enhancements unrelated to
potential social impacts.
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
â€¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
40â€¢The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
â€¢Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
â€¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: [Yes] The original paper for used LIBSVM dataset is cited.
Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
â€¢For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
41â€¢If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢The paper should discuss whether and how consent was obtained from people whose
asset is used.
â€¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
â€¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
â€¢We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
42