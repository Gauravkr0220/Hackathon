Training Dynamics of Transformers to Recognize
Word Co-occurrence via Gradient Flow Analysis
Hongru Yangâˆ—
The University of Texas at Austin
& Princeton University
hy6385@utexas.eduBhavya Kailkhura
Lawrence Livermore National Laboratory
kailkhura1@llnl.gov
Zhangyang Wang
The University of Texas at Austin
atlaswang@utexas.eduYingbin Liang
The Ohio State University
liang.889@osu.edu
Abstract
Understanding the training dynamics of transformers is important to explain the
impressive capabilities behind large language models. In this work, we study the
dynamics of training a shallow transformer on a task of recognizing co-occurrence
of two designated words. In the literature of studying training dynamics of trans-
formers, several simplifications are commonly adopted such as weight reparameter-
ization, attention linearization, special initialization, and lazy regime. In contrast,
we analyze the gradient flow dynamics of simultaneously training three attention
matrices and a linear MLP layer from random initialization, and provide a frame-
work of analyzing such dynamics via a coupled dynamical system. We establish
near minimum loss and characterize the attention model after training. We discover
that gradient flow serves as an inherent mechanism that naturally divide the training
process into two phases. In Phase 1, the linear MLP quickly aligns with the two tar-
get signals for correct classification, whereas the softmax attention remains almost
unchanged. In Phase 2, the attention matrices and the MLP evolve jointly to enlarge
the classification margin and reduce the loss to a near minimum value. Technically,
we prove a novel property of the gradient flow, termed automatic balancing of
gradients , which enables the loss values of different samples to decrease almost at
the same rate and further facilitates the proof of near minimum training loss. We
also conduct experiments to verify our theoretical results.
1 Introduction
Ever since the invention of self-attention [ VSP+17], transformers have become a dominat-
ing backbone architecture in many machine learning applications such as computer vision
[DBK+20,LLC+21] and natural language processing [ DCLT18 ]. Nowadays, ChatGPT and
GPT-4 [ Ope23 ] have demonstrated astonishing abilities in many areas such as language under-
standing, mathematics and coding, which have sparked artificial general intelligence [ BCE+23].
In the meantime, there has been a burgeoning development of large language models (LLMs)
[TLI+23, MH23, ADF+23] as well as multi-modal models [Tea23].
Despite the huge empirical success, theoretical understanding of why a pre-trained language model
can possess such impressive performance has been significantly lagging behind. Some previous
âˆ—Work done while doing a internship at Lawrence Livermore National Laboratory and visiting Princeton
University.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).efforts have been made in understanding the capacity and representational power of transformers
[EGKZ22 ,LAG+22,ZPGA23 ,SHT23 ,BCW+23]. However, most results of this type of works are
existential and rely on manual construction of the weights. It is unclear whether the constructed
weights are the actual solutions after training transformers. In order to understand the mechanism
behind those pre-trained language models, a line of studies have aimed to open the black box of
optimization via studying training dynamics of transformers and explaining why transformers can be
trained to perform well [ JSL22 ,LWLC22 ,TWCD23 ,TWZ+23,LLR23 ,TLZO23 ,TLTO23 ,ZFB24 ,
HCL23 ]. However, those previous works often relied on various simplifications in their analysis such
as weight reparameterization, attention linearization, special initialization, lazy regime, etc. One goal
of this paper is to take a further step to demystify the training dynamics of transformers and consider
more practical training setup, thus better capturing the actual training process.
Our study of transformersâ€™ training dynamics will focus on a basic problem of recognizing co-
occurrence of words under a binary classification setup, which is an important ability of LLMs
to perform many tasks correctly in natural language processing (NLP). For example, the classical
n-gram model [ MS99 ,Dam18 ] predicts the next word based on co-occurrence of multiple words.
Consider the following scenario: if the task for the language model is to read a paragraph describing
a children and then answer some questions, say, â€œIs Bob eating a banana?â€. In order to answer the
question correctly, the model must be able to detect the co-occurrence of the two words â€œBobâ€ and
â€œbananaâ€ in the paragraph. Motivated by this, we study the problem of detecting co-occurrence of
two target words via the model of a one-layer transformer with a self-attention module followed by a
linear multi-layer perceptrons (MLP) layer. Our goal is to characterize the dynamics of the training
process via the gradient flow analysis, thus providing a theory to explain how transformers can be
trained to perform well.
Our contribution is summarized below:
â€¢We study the gradient flow dynamics of detecting word co-occurrence. The training starts with
random initialization and then simultaneously updates four weight matrices (including key, query,
and value matrices and a linear MLP) in the transformer architecture via gradient flow. We show
that gradient flow can achieve small loss although the loss function is highly nonconvex. We
further characterize the explicit form of attention matrices after training, which captures the strong
positive correlation between the two target signals and strong negative correlation between one
target signal and the common token, both leading to large classification margin.
â€¢We characterize the training process into two phases. In Phase 1 (alignment of MLP for correct
classification), we show that the linear MLP of the transformer quickly aligns with the two target
word tokens whereas all other variables in the dynamical system stay almost unchanged from their
initialization values. All training samples are correctly classified at the end of Phase 1, but the loss
value is still large due to small classification margin. In Phase 2 (evolution of attention and MLP
for large classification margin), along with the continual evolution of MLP, correct classification
by MLP also encourages the gradients of attention matrices to learn. Specifically, the softmax
probability increases if the key and query tokens correspond to the two target words, and the
value transform of the two words becomes more positively correlated, both leading to enlarge the
classification margin. Thus, the training and test loss values both are driven down to nearly zero.
â€¢Technically, our proof techniques do not rely on several commonly used assumptions in the
literature such as weight reparameterization, attention linearization, special initialization, lazy
regime, etc. Our main idea is to treat the problem as a coupled dynamical system with sixdifferent
types of dynamic variables, for which we provide an articulated analysis on the gradient flow
dynamics. In particular, we prove a novel property of the gradient flow, termed automatic balancing
of gradients , which shows that the ratio of several important gradients will evolve closely within
the same range during training. This enables us to show that the losses of all training samples
can decrease almost at the same rate, and is also a key component in proving the near minimum
training loss as well as analyzing the changes of softmax.
1.1 Related Work
Transformer representational power. Several previous works have studied the expressiveness of
transformers. One line of work was from a universal approximation perspective and thus provided
the existential results [ YBR+19,WCM22 ,PBM21 ,ZPGA23 ,LAG+22,BCW+23]. As a separate
view, [ EGKZ22 ] showed that a single attention head can represent a sparse function over the input
2sequence with sample complexity much smaller than the context length. [ ZZYW23 ] studied the
approximation and generalization performance of transformers in in-context learning. [ SHT23 ]
proved that transformers can represent certain functions more efficiently than MLPs.
Training transformers. Various settings of training transformers have been studied recently.
[WXM21 ] studied the impact of head and prompt tuning of transformer on the downstream learning
tasks. [ JSL22 ] proved that transformers can learn spatial structures. [ LWLC22 ] studied how a
shallow transformer learns a dataset with both label-relevant and label-irrelevant tokens. [ TWCD23 ]
studied a next-token prediction problem and showed that self-attention behaves like a discriminating
scanning algorithm. [ LLR23 ] analyzed a layer-wise optimization scheme on how transformers learn
topic structures. [ TLZO23 ,TLTO23 ,VDT24 ] studied a setting where transformers can learn a
SVM solution. [ LWM+23] provided analysis of training graph transformers for node classification
tasks. [ Thr24 ] studied the implicit bias in the next-token prediction problem. For in-context linear
regression, [ VONR+23] constructed transformer weights to solve this task and showed empirically
that this is similar to what the transformer learned by gradient descent, [ ACDS24 ] proved that the
critical points of the training objective of linear transformers implement a pre-conditioned gradient
descent, [ ZFB24 ] provided the training dynamics of linear attention models, [ HCL23 ] characterized
the training dynamics of softmax transformers, and [ CSWY24 ] studied a multi-task linear regression
problem with a multi-headed softmax transformer. Further, [ LWL+24] focused on nonlinear self-
attention and nonlinear MLP over classification tasks in in-context learning. [ WLCC23 ] proved the
convergence of transformers via neural tangent kernel. [ NDL24 ] showed that two-layer transformers
can learn causal structure via gradient descent. [ CL24 ] developed algorithms for provably learning a
multi-head attention layer. [HWCL24] studied how transformers learn feature-position correlation.
This paper studies a different problem of detecting co-occurrence of words via transformers. Such a
setting has not been considered in the literature. More importantly, the previous studies of training
dynamics of transformers have adopted various assumptions/simplifications such as weight reparame-
terization, special initialization, attention linearization, lazy regime, etc. In contrast, our analysis here
based on gradient flow does not rely on those simplifications, which can be of independent interest
for studying transformers in other settings.
2 Problem Setting
Notations. For a vector vâˆˆRd, we use diag(v)to denote a diagonal matrix with vbeing the diagonal
entries. When we subtract the vector vby a scalar a, we subtract each entry of vbya, i.e.,vâˆ’aâˆˆRd
and(vâˆ’a)i=viâˆ’a. We use eâ„¦,eÎ˜,eOto hide polylogarithmic factors.
2.1 Data Model
Definition 2.1 (Data distribution) .Given a set of orthonormal vectors {Âµi}d
i=1as word embedding,
letÂµ1, Âµ2âˆˆRdbe two target signals whose co-occurrence needs to be detected by the model,
and let Âµ3âˆˆRdbe a common token vector. A data entry (X, y)âˆˆRdÃ—LÃ— {Â± 1}, where X=
[x1, x2, . . . , x L]consists of Ltokens, is generated by the distribution Das follows:
1. Uniformly randomly select an index i3âˆˆ[L]and set xi3=Âµ3.
2. Then, one of the following cases occurs:
â€¢With probability 1/2, sety= 1and uniformly randomly select two indices i1Ì¸=i2âˆˆ[L]\ {i3}
and set xi1=Âµ1, xi2=Âµ2. For iâˆˆ[L]\ {i1, i2, i3}, setxi=Uniform ({Âµi}d
i=4).
â€¢With probability 1/6, sety=âˆ’1and uniformly randomly select one index i1âˆˆ[L]\ {i3}and
setxi1=Âµ1. For iâˆˆ[L]\ {i3, i1}, we set xi=Uniform ({Âµi}d
i=4).
â€¢With probability 1/6, sety=âˆ’1and uniformly randomly select one index i2âˆˆ[L]\ {i3}and
setxi2=Âµ2. For iâˆˆ[L]\ {i3, i2}, we set xi=Uniform ({Âµi}d
i=4).
â€¢With probability 1/6, sety=âˆ’1. For all iâˆˆ[L]\ {i3}, we set xi=Uniform ({Âµi}d
i=4).
In summary, there are 4 types of data: (1) both Âµ1, Âµ2appear, (2) only Âµ1appears, (3) only Âµ2
appears, and (4) neither Âµ1norÂµ2appears. We denote the set of indices of the above 4 different types
of data by I1, I2, I3, I4âŠ†[n]. We further define R={Âµi}d
i=4. For simplicity, our data distribution
assumes Âµ1, Âµ2, Âµ3appear only once in a data entry. The occurrence probability of each type of
3data is chosen in the above way to make the distribution label-balanced. We assume there is a fixed
set of orthonormal vectors as word embedding, which is analogous to the one-hot embedding of a
set of vocabularies. Furthermore, in our daily language, there are some words appearing in almost
every sentence such as â€œaâ€ and â€œtheâ€. Thus, to model those words, we include a common token in
every data entry. Finally, notice that if we ignore the common token and random tokens, the data
distribution simplifies to a logical AND problem.
Remark 2.2. Recognizing co-occurrence of words is an important ability for language models
to perform many NLP tasks correctly. Consider the example of a language model first reading a
paragraph describing a children and then answering the question â€œIs Bob eating a banana?â€ If the
description is â€œBob is watching a television while eating a bananaâ€, then the model should answer
â€œYesâ€. If the description is â€œBob is playing computer gamesâ€, then the model should answer â€œNoâ€.
Thus, the model needs to recognize the co-occurrence of â€œBobâ€ and â€œbananaâ€.
For simplicity of our analysis, we make the following assumption on our training data set.
Assumption 2.3. The training set satisfies: (i)|I1|
n=1
2and|I2|
n=|I3|
n=|I4|
n=1
6; and (ii) for
alli1, i2âˆˆ[n], l1, l2âˆˆ[L], ifX(i1)
l1, X(i2)
l2/âˆˆ {Âµ1, Âµ2, Âµ3}, then X(i1)
l1Ì¸=X(i2)
l2, i.e., all irrelevant
words are different.
The first assumption can be approximately satisfied with high probability given the total number nof
samples is large enough. Such an assumption can be removed by applying the standard concentration
theorems. The second assumption implicitly assumes nLâ‰¤d. If the irrelevant words are uniformly
sampled from a large entire vocabulary, then each irrelevant word appears only very few times in the
training set. Thus, letting irrelevant words appear only once in the entire training set is a reasonable
way to simplify our analysis.
2.2 Transformer Architecture and Training
Consider a training set {(X(i), yi)}n
i=1withntraining samples. Each data point X(i)âˆˆRdÃ—L
contains Ltokens, i.e., X(i)= [x(i)
1, x(i)
2, . . . , x(i)
L]. We consider the transformer model with a
self-attention module followed by a linear MLP:
F(X;W, W V, WK, WQ) =LX
l=1m1X
j=1aj
wâŠ¤
jWVXÂ·SoftmaxXâŠ¤WâŠ¤
KWQxlâˆšm
(1)
where the query matrix WQâˆˆRmÃ—d, the key matrix WKâˆˆRmÃ—d, the value matrix WVâˆˆRmÃ—d,
the hidden-layer MLP weights WâˆˆRm1Ã—m(with wâŠ¤
jbeing the j-th row of W), and the output-layer
weights of the MLP aâˆˆRm1. We define the linear MLP function of the transformer to be G(Âµ) =Pm1
j=1ajwâŠ¤
jWVÂµ. We now introduce some shorthand notations K=WKX, Q =WQX, V =
WVXand let kl=WKxl. Notice that K= [k1, k2, . . . , k L]. We further extend this shorthand to
qlandvl. We also define functions k(Âµ) =WKÂµ, q(Âµ) =WQÂµ, v(Âµ) =WVÂµ. We introduce the
shorthand for the score vector sl:=XâŠ¤WâŠ¤
KWQxlâˆšmand the attention vector pl:=Softmax (sl). For the
attention vector, if Âµ, Î½âˆˆX(i), letl(i, Âµ), l(i, Î½)be the indices such that X(i)
l(i,Âµ)=Âµ, X(i)
l(i,Î½)=Î½,
and we define p(i)
qâ†Âµ,kâ†Î½:=p(i)
qâ†l(i,Âµ),kâ†l(i,Î½):=Softmax
X(i)âŠ¤WâŠ¤
KWQÂµâˆšm
l(i,Î½).
Initialization. We initialize aji.i.d.âˆ¼Uniform (Â±1)and the value of ais fixed during training.
The trainable parameters are [W, W V, WK, WQ]. We initialize [W, W V, WK, WQ]byWi,ji.i.d.âˆ¼
N(0, Ïƒ2
1)and(WV)i,j,(WK)i,j,(WQ)i,ji.i.d.âˆ¼ N (0, Ïƒ2
0).
Training. We adopt the cross-entropy loss l(x) = log(1 + exp( âˆ’x)). The gradient of the cross-
entropy loss is given by lâ€²(x) =âˆ’1
1+exp( x)and we define g(x) =1
1+exp( x). The model is trained by
gradient flow to minimize the following empirical loss:
bL(W, W V, WK, WQ) =1
nnX
i=1l(yiF(X(i);W, W V, WK, WQ)). (2)
4Similarly, we define the generalization loss L:=E(X,y)âˆ¼Dâ„“(yF(X)). We introduce the parameter
condition that we take throughout the entire analysis and proofs.
Condition 1. We make the following parameter choices in our analysis:
â€¢The embedding dimension and network width satisfy mâ‰¥eâ„¦(max {m1, L2})andm1â‰¥eâ„¦(1) .
â€¢The network weight initialization variance satisfies Ïƒ0=1
eÎ˜(âˆš
Lm); and Ïƒ1=1
eÎ˜(âˆšm1).
â€¢The number of training samples and tokens satisfy nâ‰¥eâ„¦(L2)andLâ‰¥eâ„¦(1) .
â€¢The failure probability satisfies 1/Î´â‰¤poly(m).
3 Main Results
Challenges. The essential goal is to derive the gradient flow update for each weight matrix (see
the gradient expressions for all weight matrices in Appendix B). However, directly analyzing the
dynamics of those weight matrices is extremely challenging, because: (i) keeping track of how the
column and row spaces of each weight matrix change during training is difficult; and (ii) all attention
and MLP weight matrices are affecting each other, leading to highly coupled dynamics.
Our General Idea. To overcome the above challenges, we first note that rather than tracking
W, W V, WK, WQdirectly, it is sufficient to analyzing their impact on inputs, i.e., XâŠ¤WâŠ¤
QWKXand
aâŠ¤WW VX, which are sufficient to compute F(X;W, W V, WK, WQ). Based on this observation,
we formulate two differential equations to keep track of w(t)âŠ¤
jW(t)
VÂµandÎ½âŠ¤W(t)âŠ¤
KW(t)
QÂµ(with
respect to t) for all Âµ, Î½âˆˆ {Âµi}d
i=1(See Equation (6) and Equation (7) in Appendix C). We further
include additional equations to keep track ofD
w(t)
j1, w(t)
j2E
, Î½âŠ¤W(t)âŠ¤
VW(t)
VÂµ, Î½âŠ¤W(t)âŠ¤
KW(t)
KÂµ, and
Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµto complete the system. Intuitively, the additional equations keep track of the shape
of the neurons and the word embedding after WV, WK, WQtransform. Although the dynamical
system does not directly track the softmax, the softmax probability can be calculated via the scores of
Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ. The full dynamical system is presented in Appendix C. Then the training dynamics
can be characterized by analyzing these differential equations (see a proof outline in Section 4).
In the next two theorems, we present our characterization of the training process into two phases.
Theorem 3.1 (Phase 1) .With probability at least 1âˆ’Î´over the randomness of weight initialization,
there exists a time T1=eO(1/m)such that
â€¢The linear MLP functions satisfy: G(T1)(Âµ1)â‰¥â„¦(1) ,G(T1)(Âµ2)â‰¥â„¦(1) ,G(T1)(Âµ3)â‰¤ âˆ’â„¦(1) .
â€¢All training samples are correctly classified: yiF(T1)
i>0for all iâˆˆ[n].
â€¢Fortâˆˆ[0, T1], all dynamical variablesD
w(t)
j1, w(t)
j2E
,Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ,Î½âŠ¤W(t)âŠ¤
VW(t)
VÂµ,
Î½âŠ¤W(t)âŠ¤
KW(t)
KÂµ, and Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµare close to their initialization values.
â€¢Training loss is still large: bL(T1)= Î˜(1) .
In Theorem 3.1, item 1 implies that in a short time, the linear MLP function G(T1)(Â·)positively aligns
with the two target signals Âµ1andÂµ2, but negatively aligns with the common token Âµ3. This further
guarantees item 2 of Theorem 3.1 that all training samples are classified correctly. Further, item 3 of
Theorem 3.1 indicates that the attention matrices are still close to their initialization values, and hence
have not started to learn any knowledge yet. This results in item 4 of Theorem 3.1, which shows that
the training loss is still large.
Theorem 3.2 (Phase 2) .With probability at least 1âˆ’Î´over the randomness of weight initialization,
there exists a time range (T1, T2)withT2=poly(m)such that for all tâˆˆ(T1, T2)
â€¢ÂµâŠ¤
2W(t)âŠ¤
KW(t)
QÂµ1and ÂµâŠ¤
1W(t)âŠ¤
KW(t)
QÂµ2increase, whereas ÂµâŠ¤
3W(t)âŠ¤
KW(t)
QÂµ1and
ÂµâŠ¤
3W(t)âŠ¤
KW(t)
QÂµ2decrease.
5â€¢ÂµâŠ¤
1W(t)âŠ¤
VW(t)
VÂµ2increases, whereas ÂµâŠ¤
1W(t)âŠ¤
VW(t)
VÂµ3andÂµâŠ¤
2W(t)âŠ¤
VW(t)
VÂµ3decrease.
â€¢Linear MLP functions satisfy: G(t)(Âµ1)â‰¥â„¦(1) ,G(t)(Âµ2)â‰¥â„¦(1) ,âˆ’G(t)(Âµ3)â‰¤â„¦(1) .
â€¢G(t)(Âµ1) +G(t)(Âµ2) +G(t)(Âµ3)â‰¥â„¦(1) ,G(t)(Âµ1) +G(t)(Âµ3)â‰¤ âˆ’â„¦(1) andG(t)(Âµ2) +
G(t)(Âµ3)â‰¤ âˆ’â„¦(1) .
In Theorem 3.2, item 1 indicates that, during Phase 2, gradient flow drives the self-attention module
to weigh more between the two target signals Âµ1andÂµ2, and to weigh less between one of these
signals and the common token Âµ3. Item 2 indicates that gradient flow drives the value matrix WV
to positively align the two target signals Âµ1andÂµ2, but negatively align one target signal ( Âµ1orÂµ2)
with the common token Âµ3. Further, the last two items indicate that the MLP continue to classify
correctly and further enlarge the classification margin. Hence, all items in Theorem 3.2 collectively
indicate that attention and MLP evolve jointly to enlarge the classification margin and hence drive the
loss value to decrease in Phase 2.
Theorem 3.3 (Near Minimum Training Loss and Attention) .With probability at least 1âˆ’Î´, there
exists a time Tâ‹†= Î˜( poly(m))such that
â€¢The training and generalization losses satisfy bL(Tâ‹†)â‰¤1/poly(m)andL(Tâ‹†)â‰¤1/poly(m).
â€¢The attention matrices satisfies:
W(Tâ‹†)âŠ¤
K W(Tâ‹†)
Q=W(0)âŠ¤
KW(0)
Q+P
i1,i2âˆˆ[d]C(Tâ‹†)
i1,i2Âµi1ÂµâŠ¤
i2, (3)
where C(Tâ‹†)
1,2, C(Tâ‹†)
2,1,âˆ’C(Tâ‹†)
3,1,âˆ’C(Tâ‹†)
3,2 = Î˜
Ïƒ2
0mâˆšmLÏƒ2
1mm 1+Ïƒ2
0âˆšmâˆšmÏƒ2
1mm 1
and C(Tâ‹†)
i1,i2â‰¤
eO
Ïƒ2
0m
nâˆšmLÏƒ2
1mm 1+Ïƒ2
0âˆšmâˆšmÏƒ2
1mm 1
if one of i1, i2âˆˆ[d]\[3].
Theorem 3.3 indicates that both training and test losses converge nearly to zero as long as the
embedding dimension mis sufficiently large, because both the attention and MLP matrices are
trained towards enlarging the classification margin in Phase 2. Theorem 3.3 also provides the explicit
form of the attention matrix in Equation (3), in which the second term captures the learned information
of the self-attention module. It can be seen that the large coefficients C(Tâ‹†)
1,2andC(Tâ‹†)
2,1capture strong
coupling of the two target signals Âµ1andÂµ2, and the large negative coefficients C(Tâ‹†)
3,1andC(Tâ‹†)
3,2
encourages strong negative coupling of one target signal Âµ1orÂµ2and the common token Âµ3. All these
attention terms contribute to enlarge correct classification margin. Further, the coefficients between
all other random tokens are order-level smaller and hence do not corrupt the correct classification.
Synthetic Experiment: We next verify our theory and the two-phase characterization of the training
process via synthetic experiments (see the experiment setup in Appendix A).

		
		
				


	Phase 1Phase 2

		
		
	
	
	

Phase 1Phase 2
(a) Attention score correlation (b) Training loss
Figure 1: Synthetic experiments with illustration of two training phases. The detailed experiment
setup can be found in Appendix A.
Figure 1 (a) shows how the attention score correlation ÂµâŠ¤
iW(t)âŠ¤
KW(t)
QÂµjevolves during the training.
It is clear that these scores do not change significantly in Phase 1, verifying Theorem 3.1. In Phase
2, the score correlation between two target signals Âµ1andÂµ2increases, and the score between one
target signal and the common token decreases, verifying Theorem 3.2.
6Figure 1 (b) plots how the training loss changes during the two phases of training. The blue curve
(indexed by â€˜lossâ€™) represents the overall training loss of all samples. The other curves correspond to
the training loss of four types of samples as indicated in the legend. In Phase 1, the training loss for
samples with both target signals (i.e., orange curve) decreases because the linear MLP layer aligns
with the target signals (verifying Lemma 4.1 in Section 4.1). The training loss for samples with
one target signal and the common token (i.e., green or red curves) first increases because the linear
MLP layer initially has not aligned negatively enough with the common token yet (as captured by
Lemma 4.2 in Section 4.1), and then decreases in the later stage of Phase 1 when the MLP layer aligns
negatively with the common token (as captured by Lemma 4.3 in Section 4.1). All loss functions
decrease in Phase 2 because all attention matrices and linear MLP jointly enlarge the classification
margin, verifying Theorem 3.2.
4 Proof Outline: Two-phase Gradient Flow Analysis
4.1 Phase 1: Alignment of Linear MLP for Correct Classification
In Phase 1, the linear MLP quickly aligns with the two target word tokens while all attention matrices
stay roughly unchanged from their initialization values. We show that the linear MLP functions
|G(t)(Âµ1)|,|G(t)(Âµ2)|,|G(t)(Âµ3)|become sufficiently large (larger than some constant threshold) so
that all training samples are correctly classified at the end of Phase 1.
We first analyze the dynamical system at the initialization. In particular, the following lemma shows
that at the initialization, the linear MLP layer receives a sufficiently large gradient from the two target
signals, and hence samples with the two target signals will be classified correctly as co-occurrence
soon afte the training starts.
Lemma 4.1 (Same as Lemma E.4) .With probability at least 1âˆ’Î´over the weight initialization,
âˆ€Âµâˆˆ {Âµ1, Âµ2}:âˆ‚ajw(0)
jW(0)
VÂµ
âˆ‚t= Î˜(( Ïƒ2
0+Ïƒ2
1)m).
Further, by the definition of Phase 1 (see Definition E.2 for a formal definition), the gradients of
the attention matrices in the dynamical system are much smaller than that of linear MLP given
in Lemma 4.1. This implies that during Phase 1, mainly the linear MLP is performing learning,
whereas all the attention matrices are changing slowly from their initialization. Based on this, we have
âˆ‚
âˆ‚tG(t)(Âµ1) = Î˜(( Ïƒ2
0+Ïƒ2
1)mm 1)which implies that it takes only O(1/(Ïƒ2
0+Ïƒ2
1)mm 1)iterations
forG(t)(Âµ1)to reach a certain constant magnitude.
Lemma 4.1 indicates that the samples with co-occurrence of the two target signals are classified
correctly. The following lemma shows that the initial gradient from the common token, i.e., the
gradient of G(t)(Âµ3), is much smaller than the gradient from the two target signals, which implies
that the samples with only one target signal may be classified incorrectly as co-occurrence (since the
network in this case will output a positive value). This is verified empirically by our experiments in
Figure 1 (b), where the loss function corresponding to only one target signal and the common token
first increases in Phase 1.
Lemma 4.2 (Same as Lemma E.16) .LetF= max i|F(0)
i|. With probability at least 1âˆ’Î´over the
weight initialization,âˆ‚ajw(0)
jW(0)
VÂµ3
âˆ‚t=eO
Ïƒ2
1âˆšmm 1+Ïƒ2
0âˆš
mL+Ïƒ2
1mF
.
Notice that the model output Fdepends on the weight initialization scale and can be made small.
We next show in the following lemma that the gradientâˆ‚G(t)(Âµ3)
âˆ‚tof the common token will quickly
become negative soon after the training begins, which drives the transformer model to output a
negative value when it sees those types of samples. This implies that negative samples (without
co-occurrence of two target tokens) will be classified correctly towards the end of Phase 1. This is
also verified empirically by our experiments in Figure 1 (b), where the loss function corresponding to
only one target signal and the common token descreases towards the end of Phase 1.
Lemma 4.3 (Abbreviated from Theorem E.19) .There exists a time T0.5â‰¤T1and a constant Csuch
that for all tâˆˆ[T0.5, T1]
(1 +C) max
âˆ‚G(t)(Âµ1)
âˆ‚t,âˆ‚G(t)(Âµ2)
âˆ‚t
â‰¤ âˆ’âˆ‚G(t)(Âµ3)
âˆ‚tâ‰¤(1âˆ’C)
âˆ‚G(t)(Âµ1)
âˆ‚t+âˆ‚G(t)(Âµ2)
âˆ‚t
.
7Proof Intuition of Lemma 4.3. We first note that the term
1
nPn
i=1g(0)
iyiPL
l2=1Pm1
j2=1âˆ¥w(0)
j2âˆ¥2
2(X(i)p(0,i)
l2)âŠ¤Âµ
makes the major contribution to the gradientâˆ‚G(t)(Âµ3)
âˆ‚t. Such a term is small at the initialization due
to the cancellation effect from positive and negative yiâ€™s. However, since the linear MLP Gwill
positively align the two target signals at the beginning, for the samples with positive labels, g(t)
iwill
decrease, whereas for samples with only one target signal, g(t)
iwill increase. Hence,âˆ‚ajw(t)
jW(t)
VÂµ3
âˆ‚twill become negative. This trend will continue until the gradient from Âµ3starts to match the gradients
from Âµ1, Âµ2, which is what we establish in Lemma 4.3.
Using Lemma 4.3, we can show that all training samples are correctly classified at end of Phase 1.
4.2 Phase 2: Evolution of Attention and MLP for Large Classification Margin
In Phase 2, both attention and MLP matrices evolve towards enlarging the classification margin, thus
driving the loss value small.
We now analyze what happens in Phase 2. Let T2denote the end of Phase 2. Recall that at the end of
Phase 1, we have G(t)(Âµ1), G(t)(Âµ2),âˆ’G(t)(Âµ3)â‰¥â„¦(1) . We will mainly need to show that such a
condition continues to hold in Phase 2, so that attention matrices will evolve with MLP to learn better
classifiers. To this end, we exam the following gradient flow in the dynamical system:
âˆ‚G(t)(Âµ)
âˆ‚t=1
nX
i2:ÂµâˆˆX(i2)g(t)
i2yi2LX
l2=1p(t,i2)
qâ†l2,kâ†ÂµÂ·m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
(4)
+m1
nnX
i1=1g(t)
i1yi1LX
l1=1aj1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ.
It has been proved that at the end of Phase 1, for Âµâˆˆ {Âµ1, Âµ2, Âµ3}, we haveP
j1âˆ‚w(t)âŠ¤
j1
âˆ‚tW(t)
VÂµâ‰ª
P
j1w(t)âŠ¤
j1âˆ‚W(t)
V
âˆ‚tÂµsince the magnitude ofPm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
is large. Assume this
can hold for long enough (which we can indeed prove later). Then, we only need to focus on the
first term in the sum on the right-hand side in Equation (4). On the other hand, from the dynamical
system, we can calculate
âˆ‚
âˆ‚tm1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
=2m1
nnX
i=1g(t)
iyiF(t)
i. (5)
Thus, if yiF(t)
i>0for all iâˆˆ[n], thenPm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
is always increasing.
Thus,âˆ‚G(t)(Âµ)
âˆ‚tmainly depends on the behavior of1
nP
i2:ÂµâˆˆX(i2)g(t)
i2yi2PL
l2=1p(t,i2)
qâ†l2,kâ†Âµ. Fur-
ther, this is also a key quantity we need to analyzeâˆ‚Î½âŠ¤W(t)âŠ¤
VW(t)
VÂµ
âˆ‚tandâˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ
âˆ‚t. Note
that1
nP
i2:ÂµâˆˆX(i2)g(t)
i2yi2PL
l2=1p(t,i2)
qâ†l2,kâ†Âµâ‰ˆ1
nP
i2:ÂµâˆˆX(i2)g(t)
i2yi2ifp(t,i2)
qâ†l2,kâ†Âµâ‰ˆ1/Lwhich
holds at the beginning of Phase 2. Later, we are going to prove convergence of the training loss via
the following: (1) the training loss can decrease if the softmax probability is uniform; (2) even though
the softmax probability will deviate from uniform distribution during training, we can bound such
deviation and the loss value can still decrease.
Automatic balancing of gradients. As argued above, our main focus is on analyzing the behavior of
1
nP
i2:ÂµâˆˆX(i2)g(t)
i2yi2. This consists of two parts: (i) Lemma 4.4, which shows that the two groups
of samples with only the presence of one target signal have gradientsP
iâˆˆI2g(t)
iandP
iâˆˆI3g(t)
iclose
to each other during training; and (ii) Lemma 4.5, which shows that the gradient gapsP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iandP
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’P
iâˆˆI1g(t)
iare not too small compared withP
iâˆˆ[n]g(t)
i. Both
8Lemmas 4.4 and 4.5 establish that the ratio of those important gradients are kept within certain ranges
during training. We call such a key property as automatic balancing of gradients , which is further
used for proving that the gradient flow can drive the training loss small.
Lemma 4.4 (Same as Lemma F.5) .Fortâˆˆ[T1, T2], there exists a small constant Câ‰ª1such that
P
iâˆˆI2g(t)
iâˆ’P
iâˆˆI3g(t)
i
min(P
iâˆˆI2g(t)
i,P
iâˆˆI3g(t)
i)â‰¤C.
Proof Intuition of Lemma 4.4. The intuition behind the result is as follows. IfP
iâˆˆI2g(t)
ibecomes
much bigger thanP
iâˆˆI3g(t)
iduring the training, thenP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iis much smaller than
P
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
iwhich makesâˆ‚G(t)(Âµ1)
âˆ‚t<âˆ‚G(t)(Âµ2)
âˆ‚t. It is not hard to show that random
tokens make negligible contributions to the gradient. Thus, for iâˆˆI2, we haveâˆ‚F(t)
i
âˆ‚tâ‰ˆâˆ‚G(t)(Âµ1)
âˆ‚t+
âˆ‚G(t)(Âµ3)
âˆ‚t. By the chain rule, we haveâˆ‚g(t)
i
âˆ‚t=gâ€²(yiF(t)
i)yiâˆ‚F(t)
i
âˆ‚t. Sinceâˆ‚G(t)(Âµ3)
âˆ‚t<0, ifâˆ‚G(t)(Âµ1)
âˆ‚t<
âˆ‚G(t)(Âµ2)
âˆ‚t, thenP
iâˆˆI2g(t)
iwill drop faster thanP
iâˆˆI3g(t)
i, i.e.,âˆ’âˆ‚
âˆ‚tP
iâˆˆI2g(t)
i>âˆ’âˆ‚
âˆ‚tP
iâˆˆI3g(t)
i.
In Appendix, we formally prove Lemma 4.4 by analyzing the ratioP
iâˆˆI2g(t)
i/P
iâˆˆI3g(t)
i, and show
that this ratio hangs over around 1during training.
Lemma 4.5 (Abbreviated from Lemma F.6) .Fortâˆˆ[T1, T2], the gradient satisfies that
P
iâˆˆ[n]g(t)
iP
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’P
iâˆˆI1g(t)
i=O(1),P
iâˆˆ[n]g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i=O(1).
Further, for some constant C, we have
(1 +C) maxâˆ‚G(t)(Âµ1)
âˆ‚t,âˆ‚G(t)(Âµ2)
âˆ‚t
â‰¤ âˆ’âˆ‚G(t)(Âµ3)
âˆ‚tâ‰¤(1âˆ’C)âˆ‚G(t)(Âµ1)
âˆ‚t+âˆ‚G(t)(Âµ2)
âˆ‚t
.
Proof Sketch of Lemma 4.5. The proof of Lemma 4.5 relies on analyzing how the ratio between
âˆ‚G(t)(Âµ1)
âˆ‚tandâˆ’âˆ‚G(t)(Âµ3)
âˆ‚tchanges. We show that this ratio will hang over around some range. Recall
the relationship thatâˆ‚G(t)(Âµ)
âˆ‚tâ‰ˆ1
nP
i2:ÂµâˆˆX(i2)g(t)
i2yi2Â·Pm1
j1=1Pm1
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
. It is not
hard to show that
âˆ’âˆ‚G(t)(Âµ3)
âˆ‚t
âˆ‚G(t)(Âµ1)
âˆ‚tâ‰ˆâˆ’P
iâˆˆI1g(t)
i+P
iâˆˆI2âˆªI3âˆªI4g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i.
Define R(t) :=âˆ’P
iâˆˆI1g(t)
i+P
iâˆˆI2âˆªI3âˆªI4g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i. Solving whenâˆ‚
âˆ‚tR(t)â‰¥0yields a quadratic inequal-
ity, and further analysis shows that the root is contractive and is within some specific range.
Utilizing the gradient automatic balancing properties, the following corollary characterizes how the
attention matrices in the dynamical system change in Phase 2. In particular, we can show that after
WV-transform, Âµ1andÂµ2become more positively correlated whereas Âµ1andÂµ3(also Âµ2andÂµ3)
become negatively correlated. This is a direct result following from updates of the dynamical system.
Corollary 4.6 (Abbreviated from Corollary F.13) .Fortâˆˆ[T1, T2],
âˆ‚
âˆ‚tÂµâŠ¤
2W(t)âŠ¤
VW(t)
VÂµ1>0,âˆ‚
âˆ‚tÂµâŠ¤
1W(t)âŠ¤
VW(t)
VÂµ3<0.
Since we have analyzed how G(t)(Â·)will change in stage 2, we can utilize this information to analyze
the change of softmax attention via the following relationship: by Appendix C, we can derive
âˆ‚ÂµâŠ¤
1W(t)âŠ¤
KW(t)
QÂµ2
âˆ‚t
9=1
nâˆšmnX
i=1g(t)
iyiLX
l=1ÂµâŠ¤
1W(t)âŠ¤
KK(t,i)Â·diag
G(t)(X(i))âˆ’(G(t)(X(i)))âŠ¤p(t,i)
l
p(t,i)
lx(i)âŠ¤
lÂµ2
+1
nâˆšmnX
i=1g(t)
iyiLX
l=1ÂµâŠ¤
2W(t)âŠ¤
Qq(t,i)
lp(t,i)âŠ¤
lÂ·diag
G(t)(X(i))âˆ’(G(t)(X(i)))âŠ¤p(t,i)
l
X(i)âŠ¤Âµ1.
The following lemma shows that the attention score between the two target signals Âµ1andÂµ2
increases, whereas that between one target signal Âµ1orÂµ2and the common token Âµ3decreases.
Lemma 4.7 (Abbreviated from Lemma F.16) .ForÂµ, Î½âˆˆ {Âµ1, Âµ2}, ÂµÌ¸=Î½, and for tâˆˆ[T1, T2],
âˆ‚
âˆ‚tÎ½âŠ¤W(t)âŠ¤
KW(t)
QÂµ=1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L,âˆ‚
âˆ‚tÂµâŠ¤
3W(t)âŠ¤
KW(t)
QÂµ=âˆ’1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L.
Lemma 4.7 is keeping track of the attention coefficients C(t)
i1,i2in Theorem 3.3 via gradient flow,
which proves the second item of Theorem 3.3.
5 Discussion and Future Directions
In this work, we developed a novel gradient flow based framework for analyzing the training
dynamics of a one-layer transformer to recognize co-occurring tokens. We provided a two-phase
characterization of the training process. In Phase 1, the linear MLP layer is trained to classify samples
correctly, with attention weights almost unchanged. In Phase 2, both attention matrices and the linear
MLP jointly evolve to enlarge the classification margin, thus reducing the loss to near minimum.
As future work, it will be interesting to analyze more general transformer architectures such as
multi-headed attention, multi-layer transformer, etc. Further, it is of interest to study the dynamics of
more advanced gradient descent algorithms such as gradient descent with adaptive learning rate, with
momentum, etc., and explore how the hyperparameters will affect the training dynamics. Another
direction is to study more practical language sequences where tokens are generated in a correlated
fashion. Then the next token prediction becomes an intriguing problem.
Acknowledgement
H. Yang would like to thank Jason D. Lee and Yunwei Ren for insightful discussion and suggestions.
This work was performed under the auspices of the U.S. Department of Energy by the Lawrence
Livermore National Laboratory under Contract No. DE-AC52-07NA27344 and supported by the
LLNL-LDRD Program under Project No. 22-SI-004 and 24-ERD-010. The work of Y . Liang was
supported in part by the U.S. National Science Foundation under the grants ECCS-2113860 and
DMS-2134145. The work of Z. Wang was in part supported by an NSF Scale-MoDL grant (award
number: 2133861) and the CAREER Award (award number: 2145346).
References
[ACDS24] Kwangjun Ahn, Xiang Cheng, Hadi Daneshmand, and Suvrit Sra. Transformers learn
to implement preconditioned gradient descent for in-context learning. Advances in
Neural Information Processing Systems , 36, 2024.
[ADF+23]Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre
Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2
technical report. arXiv preprint arXiv:2305.10403 , 2023.
[BCE+23]SÃ©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric
Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.
Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint
arXiv:2303.12712 , 2023.
[BCW+23]Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, and Song Mei. Transformers as
statisticians: Provable in-context learning with in-context algorithm selection. arXiv
preprint arXiv:2306.04637 , 2023.
10[CL24] Sitan Chen and Yuanzhi Li. Provably learning a multi-head attention layer. arXiv
preprint arXiv:2402.04084 , 2024.
[CSWY24] Siyu Chen, Heejune Sheen, Tianhao Wang, and Zhuoran Yang. Training dynamics of
multi-head softmax attention for in-context learning: Emergence, convergence, and
optimality. arXiv preprint arXiv:2402.19442 , 2024.
[Dam18] Friederick J Damerau. Markov models and linguistic theory , volume 95. Walter de
Gruyter GmbH & Co KG, 2018.
[DBK+20]Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua
Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition
at scale. In International Conference on Learning Representations , 2020.
[DCLT18] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-
training of deep bidirectional transformers for language understanding. arXiv preprint
arXiv:1810.04805 , 2018.
[EGKZ22] Benjamin L Edelman, Surbhi Goel, Sham Kakade, and Cyril Zhang. Inductive biases
and variable creation in self-attention mechanisms. In International Conference on
Machine Learning , pages 5793â€“5831. PMLR, 2022.
[HCL23] Yu Huang, Yuan Cheng, and Yingbin Liang. In-context convergence of transformers.
arXiv preprint arXiv:2310.05249 , 2023.
[HWCL24] Yu Huang, Zixin Wen, Yuejie Chi, and Yingbin Liang. Transformers provably
learn feature-position correlations in masked image modeling. arXiv preprint
arXiv:2403.02233 , 2024.
[JSL22] Samy Jelassi, Michael Sander, and Yuanzhi Li. Vision transformers provably learn
spatial structure. Advances in Neural Information Processing Systems , 35:37822â€“
37836, 2022.
[LAG+22]Bingbin Liu, Jordan T Ash, Surbhi Goel, Akshay Krishnamurthy, and Cyril Zhang.
Transformers learn shortcuts to automata. In The Eleventh International Conference
on Learning Representations , 2022.
[LLC+21]Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows.
InProceedings of the IEEE/CVF international conference on computer vision , pages
10012â€“10022, 2021.
[LLR23] Yuchen Li, Yuanzhi Li, and Andrej Risteski. How do transformers learn topic structure:
Towards a mechanistic understanding. arXiv preprint arXiv:2303.04245 , 2023.
[LWL+24]Hongkang Li, Meng Wang, Songtao Lu, Xiaodong Cui, and Pin-Yu Chen. Training
nonlinear transformers for efficient in-context learning: A theoretical learning and
generalization analysis. arXiv preprint arXiv:2402.15607 , 2024.
[LWLC22] Hongkang Li, Meng Wang, Sijia Liu, and Pin-Yu Chen. A theoretical understanding of
shallow vision transformers: Learning, generalization, and sample complexity. In The
Eleventh International Conference on Learning Representations , 2022.
[LWM+23]Hongkang Li, Meng Wang, Tengfei Ma, Sijia Liu, Zaixi Zhang, and Pin-Yu Chen. What
improves the generalization of graph transformer? a theoretical dive into self-attention
and positional encoding. NeurIPS 2023 Workshop: New Frontiers in Graph Learning,
2023 , 2023.
[MH23] James Manyika and Sissie Hsiao. An overview of bard: an early experiment with
generative ai. AI. Google Static Documents , 2, 2023.
[MS99] Christopher Manning and Hinrich Schutze. Foundations of statistical natural language
processing . MIT press, 1999.
11[NDL24] Eshaan Nichani, Alex Damian, and Jason D Lee. How transformers learn causal
structure with gradient descent. arXiv preprint arXiv:2402.14735 , 2024.
[Ope23] OpenAI. Gpt-4 technical report, 2023.
[PBM21] Jorge PÃ©rez, Pablo BarcelÃ³, and Javier Marinkovic. Attention is turing complete. The
Journal of Machine Learning Research , 22(1):3463â€“3497, 2021.
[SHT23] Clayton Sanford, Daniel Hsu, and Matus Telgarsky. Representational strengths and
limitations of transformers. arXiv preprint arXiv:2306.02896 , 2023.
[Tea23] Gemini Team. Gemini: a family of highly capable multimodal models. arXiv preprint
arXiv:2312.11805 , 2023.
[Thr24] Christos Thrampoulidis. Implicit bias of next-token prediction. arXiv:2402.18551 ,
2024.
[TLI+23]Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux,
TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar,
et al. Llama: Open and efficient foundation language models. arXiv preprint
arXiv:2302.13971 , 2023.
[TLTO23] Davoud Ataee Tarzanagh, Yingcong Li, Christos Thrampoulidis, and Samet Oymak.
Transformers as support vector machines. In NeurIPS 2023 Workshop on Mathematics
of Modern Machine Learning , 2023.
[TLZO23] Davoud Ataee Tarzanagh, Yingcong Li, Xuechen Zhang, and Samet Oymak. Max-
margin token selection in attention mechanism. In Thirty-seventh Conference on Neural
Information Processing Systems , 2023.
[TWCD23] Yuandong Tian, Yiping Wang, Beidi Chen, and Simon Du. Scan and snap: Understand-
ing training dynamics and token composition in 1-layer transformer. arXiv preprint
arXiv:2305.16380 , 2023.
[TWZ+23]Yuandong Tian, Yiping Wang, Zhenyu Zhang, Beidi Chen, and Simon Shaolei Du.
Joma: Demystifying multilayer transformers via joint dynamics of mlp and attention.
InThe Twelfth International Conference on Learning Representations , 2023.
[VDT24] Bhavya Vasudeva, Puneesh Deora, and Christos Thrampoulidis. Implicit bias and fast
convergence rates for self-attention. arXiv preprint arXiv:2402.05738 , 2024.
[VONR+23]Johannes V on Oswald, Eyvind Niklasson, Ettore Randazzo, JoÃ£o Sacramento, Alexan-
der Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. Transformers learn
in-context by gradient descent. In International Conference on Machine Learning ,
pages 35151â€“35174. PMLR, 2023.
[VSP+17]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N
Gomez, Åukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in
neural information processing systems , 30, 2017.
[WCM22] Colin Wei, Yining Chen, and Tengyu Ma. Statistically meaningful approximation: a
case study on approximating turing machines with transformers. Advances in Neural
Information Processing Systems , 35:12071â€“12083, 2022.
[WLCC23] Yongtao Wu, Fanghui Liu, Grigorios Chrysos, and V olkan Cevher. On the conver-
gence of encoder-only shallow transformers. In Thirty-seventh Conference on Neural
Information Processing Systems , 2023.
[WXM21] Colin Wei, Sang Michael Xie, and Tengyu Ma. Why do pretrained language models
help in downstream tasks? an analysis of head and prompt tuning. Advances in Neural
Information Processing Systems , 34:16158â€“16170, 2021.
[YBR+19]Chulhee Yun, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank Reddi, and Sanjiv
Kumar. Are transformers universal approximators of sequence-to-sequence functions?
InInternational Conference on Learning Representations , 2019.
12[ZFB24] Ruiqi Zhang, Spencer Frei, and Peter L Bartlett. Trained transformers learn linear
models in-context. Journal of Machine Learning Research , 25(49):1â€“55, 2024.
[ZPGA23] Haoyu Zhao, Abhishek Panigrahi, Rong Ge, and Sanjeev Arora. Do transformers parse
while predicting the masked word? arXiv preprint arXiv:2303.08117 , 2023.
[ZZYW23] Yufeng Zhang, Fengzhuo Zhang, Zhuoran Yang, and Zhaoran Wang. What and how
does in-context learning learn? bayesian model averaging, parameterization, and
generalization. arXiv preprint arXiv:2305.19420 , 2023.
13Contents
1 Introduction 1
1.1 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
2 Problem Setting 3
2.1 Data Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
2.2 Transformer Architecture and Training . . . . . . . . . . . . . . . . . . . . . . . . 4
3 Main Results 5
4 Proof Outline: Two-phase Gradient Flow Analysis 7
4.1 Phase 1: Alignment of Linear MLP for Correct Classification . . . . . . . . . . . . 7
4.2 Phase 2: Evolution of Attention and MLP for Large Classification Margin . . . . . 8
5 Discussion and Future Directions 10
A Setup of Synthetic Experiment 16
B Gradient Flow Update for Weight Matrices 16
C Gradient Flow Dynamical System 16
C.1 Derivation of the Dynamical System . . . . . . . . . . . . . . . . . . . . . . . . . 17
D Initialization 21
E Training Dynamics: Phase 1 23
E.1 Initial Gradients . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
E.2 Maximum Perturbation of Neuron Outputs . . . . . . . . . . . . . . . . . . . . . . 27
E.3 Perturbation Term Involving Correlation of Value-transformed Data . . . . . . . . 27
E.4 Perturbation Term Involving Correlation of Neurons . . . . . . . . . . . . . . . . . 29
E.5 Neuron Weights Align with Signal Value . . . . . . . . . . . . . . . . . . . . . . . 30
E.6 Alignment of Common Token . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
E.7 Small Score Movement in Phase 1 . . . . . . . . . . . . . . . . . . . . . . . . . . 37
E.8 All Variables are within Range in Definition of Phase 1 . . . . . . . . . . . . . . . 43
F Training Dynamics: Phase 2 44
F.1 Automatic Balancing of Gradients . . . . . . . . . . . . . . . . . . . . . . . . . . 48
F.2 How Fast the Loss Decreases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
F.3 Growth of Neuron Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
F.4 Growth of Correlation of Value-Transformed Data . . . . . . . . . . . . . . . . . . 56
F.5 Change of Random-Token Sub-Network . . . . . . . . . . . . . . . . . . . . . . . 57
F.6 Change of Score and Softmax Probability . . . . . . . . . . . . . . . . . . . . . . 59
F.7 Change of Self-Correlation of Key/Query-Transformed data . . . . . . . . . . . . 61
14F.8 Small Loss is Achieved . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
F.9 Proof of Theorem 3.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
F.10 Proof of Theorem 3.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
G Auxiliary Results 63
H Probability 64
15A Setup of Synthetic Experiment
We conduct synthetic experiment to verify our theoretical results. We create a dataset following our
data distribution in Definition 2.1 with 60 training samples: 30 samples have both Âµ1andÂµ2in it, 10
samples have only Âµ1, 10 samples have only Âµ2, and 10 samples have neither Âµ1norÂµ2. Each data
consists of 5 patches and each patch has dimension 64. The embedding dimension mis set to be 128
and the number of neurons is set to be 256. We use Kaiming initialization to initialize the transformer
weights. The transformer is trained by gradient descent with learning rate 0.01 for 30000 epochs.
B Gradient Flow Update for Weight Matrices
We provide the gradient flow update for each weight matrix as follows.
âˆ‚w(t)
j
âˆ‚t=1
nnX
i=1g(t)
iyiLX
l=1ajV(t,i)p(t,i)
l=1
nnX
i=1g(t)
iyiLX
l=1ajLX
h=1v(t,i)
hp(t,i)
l,h
âˆ‚W(t)
V
âˆ‚t=1
nnX
i=1g(t)
iyiLX
l=1m1X
j=1ajw(t)
j
X(i)p(t,i)
lâŠ¤
âˆ‚W(t)
K
âˆ‚t=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajLX
h=1w(t)âŠ¤
jv(t,i)
hLX
hâ€²=1âˆ‚p(t,i)
l,h
âˆ‚sl,hâ€²q(t,i)
lx(i)âŠ¤
hâ€²
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajLX
h=1w(t)âŠ¤
jv(t,i)
hLX
hâ€²=1p(t,i)
l,h(I(h=hâ€²)âˆ’p(t,i)
l,hâ€²)q(t,i)
lx(i)âŠ¤
hâ€²
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1aj
âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
lq(t,i)
l(X(i)p(t,i)
l)âŠ¤+q(t,i)
lw(t)âŠ¤
jV(t,i)diag(p(t,i)
l)X(i)âŠ¤
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajq(t,i)
l
âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
lp(t,i)âŠ¤
l+w(t)âŠ¤
jV(t,i)diag(p(t,i)
l)
X(i)âŠ¤
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajq(t,i)
lp(t,i)âŠ¤
ldiag
w(t)âŠ¤
jV(t,i)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
X(i)âŠ¤
âˆ‚W(t)
Q
âˆ‚t=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajLX
h=1w(t)âŠ¤
jv(t,i)
hLX
hâ€²=1p(t,i)
l,h(I(h=hâ€²)âˆ’p(t,i)
l,hâ€²)k(t,i)
hâ€²x(i)âŠ¤
l
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1aj
âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(K(t,i)p(t,i)
l) +K(t,i)diag(p(t,i)
l)V(t,i)âŠ¤w(t)
j
x(i)âŠ¤
l
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajK(t,i)
âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
lp(t,i)
l+diag(p(t,i)
l)V(t,i)âŠ¤w(t)
j
x(i)âŠ¤
l
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
p(t,i)
lx(i)âŠ¤
l
C Gradient Flow Dynamical System
We first provide our complete dynamical system. The derivation of each equation is provided in
Appendix C.1.
âˆ‚w(t)âŠ¤
j1W(t)
VÂµ
âˆ‚t
16=1
nnX
i2=1g(t)
i2yi2LX
l2=1m1X
j2=1aj2D
w(t)
j1, w(t)
j2E
X(i2)p(t,i2)
l2âŠ¤
Âµ+1
nnX
i1=1g(t)
i1yi1LX
l1=1aj1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ
(6)
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ
âˆ‚t
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
KK(t,i)Â·diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
p(t,i)
lx(i)âŠ¤
lÂµ
+1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Qq(t,i)
lp(t,i)âŠ¤
lÂ·diag
w(t)âŠ¤
jV(t,i)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
X(i)âŠ¤Î½
(7)
âˆ‚D
w(t)
j1, w(t)
j2E
âˆ‚t=1
nnX
i=1g(t)
iyiLX
l=1aj2w(t)âŠ¤
j1V(t,i)p(t,i)
l+1
nnX
i=1g(t)
iyiLX
l=1aj1w(t)âŠ¤
j2V(t,i)p(t,i)
l
âˆ‚Î½âŠ¤W(t)âŠ¤
VW(t)
VÂµ
âˆ‚t
=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Âµ+1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Î½
âˆ‚Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµ
âˆ‚t
=1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajÎ½âŠ¤W(t)âŠ¤
QK(t,i)Â·diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
l(i,Âµ)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyim1X
j=1ajÂµâŠ¤W(t)âŠ¤
QK(t,i)Â·diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Î½)
p(t,i)
l(i,Î½)
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
KÂµ
âˆ‚t
=1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Kq(t,i)
lp(t,i)
qâ†l,kâ†ÂµÂ·
w(t)âŠ¤
jv(t,i)(Âµ)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Kq(t,i)
lp(t,i)
qâ†l,kâ†Î½Â·
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
C.1 Derivation of the Dynamical System
Lemma C.1. LetÂµâˆˆ {Âµi}d
i=1. For all jâˆˆ[m], we have
âˆ‚w(t)âŠ¤
j1W(t)
VÂµ
âˆ‚t=1
nnX
i2=1g(t)
i2yi2LX
l2=1m1X
j2=1aj2D
w(t)
j1, w(t)
j2E
X(i2)p(t,i2)
l2âŠ¤
Âµ
+1
nnX
i1=1g(t)
i1yi1LX
l1=1aj1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ
=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1aj
âˆ¥w(t)
jâˆ¥2
2+âˆ¥v(t)(Âµ)âˆ¥2
2
p(t,i)
qâ†l,kâ†Âµ+Îµ,
17where
Îµ=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
p(t,i)
qâ†l,kâ†Âµ
+1
nnX
i=1g(t)
iyiLX
l1=1aj1LX
l2=1D
p(t,i)
l1,l2v(t,i)
l2, v(t)(Âµ)E
I(v(t,i)
l2Ì¸=v(t)(Âµ)).
Proof. Letl(i, Âµ)denote the index such that X(i)
l(i,Âµ)=Âµ. By the gradient flow update, we have
âˆ‚w(t)âŠ¤
j1W(t)
VÂµ
âˆ‚t=1
nnX
i2=1g(t)
i2yi2LX
l2=1m1X
j2=1aj2D
w(t)
j1, w(t)
j2E
X(i2)p(t,i2)
l2âŠ¤
Âµ
+1
nnX
i1=1g(t)
i1yi1LX
l1=1aj1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ
=1
nX
i2:ÂµâˆˆX(i2)g(t)
i2yi2LX
l2=1m1X
j2=1aj2D
w(t)
j1, w(t)
j2E
p(t,i2)
qâ†l2,kâ†Âµ
+1
nnX
i1=1g(t)
i1yi1LX
l1=1aj1LX
l2=1D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)E
=1
nX
i2:ÂµâˆˆX(i2)g(t)
i2yi2LX
l2=1ï£«
ï£­aj1âˆ¥w(t)
j1âˆ¥2
2+X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2Eï£¶
ï£¸p(t,i2)
qâ†l2,kâ†Âµ
+1
nX
i1:Âµ/âˆˆX(i1)g(t)
i1yi1LX
l1=1aj1LX
l2=1D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)E
+1
nX
i1:ÂµâˆˆX(i1)g(t)
i1yi1LX
l1=1aj1ï£«
ï£­âˆ¥v(t)(Âµ)âˆ¥2
2p(t,i1)
qâ†l1,kâ†Âµ+X
l2Ì¸=l(i1,Âµ)D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)Eï£¶
ï£¸
=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1aj1
âˆ¥w(t)
j1âˆ¥2
2+âˆ¥v(t)(Âµ)âˆ¥2
2
p(t,i)
qâ†l,kâ†Âµ
+1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
p(t,i)
qâ†l,kâ†Âµ
+1
nnX
i=1g(t)
iyiLX
l1=1aj1LX
l2=1D
p(t,i)
l1,l2v(t,i)
l2, v(t)(Âµ)E
I(v(t,i)
l2Ì¸=v(t)(Âµ)).
Lemma C.2. The following equation on the gradient flow holds:
âˆ‚D
w(t)
j1, w(t)
j2E
âˆ‚t=1
nnX
i=1g(t)
iyiLX
l=1ï£«
ï£¬ï£­X
lâ€²:X(i)
lâ€²âˆˆUaj2w(t)âŠ¤
j1V(t,i)
lâ€²p(t,i)
l,lâ€²+aj1w(t)âŠ¤
j2V(t,i)
lâ€²p(t,i)
l,lâ€²ï£¶
ï£·ï£¸
+1
nnX
i=1g(t)
iyiLX
l=1ï£«
ï£¬ï£­X
lâ€²:X(i)
lâ€²/âˆˆUaj2w(t)âŠ¤
j1V(t,i)
lâ€²p(t,i)
l,lâ€²+aj1w(t)âŠ¤
j2V(t,i)
lâ€²p(t,i)
l,lâ€²ï£¶
ï£·ï£¸.
18Proof. By gradient flow update, we have
âˆ‚D
w(t)
j1, w(t)
j2E
âˆ‚t=1
nnX
i=1g(t)
iyiLX
l=1aj2w(t)âŠ¤
j1V(t,i)p(t,i)
l+1
nnX
i=1g(t)
iyiLX
l=1aj1w(t)âŠ¤
j2V(t,i)p(t,i)
l
=1
nnX
i=1g(t)
iyiLX
l=1ï£«
ï£¬ï£­X
lâ€²:X(i)
lâ€²âˆˆUaj2w(t)âŠ¤
j1V(t,i)
lâ€²p(t,i)
l,lâ€²+aj1w(t)âŠ¤
j2V(t,i)
lâ€²p(t,i)
l,lâ€²ï£¶
ï£·ï£¸
+1
nnX
i=1g(t)
iyiLX
l=1ï£«
ï£¬ï£­X
lâ€²:X(i)
lâ€²/âˆˆUaj2w(t)âŠ¤
j1V(t,i)
lâ€²p(t,i)
l,lâ€²+aj1w(t)âŠ¤
j2V(t,i)
lâ€²p(t,i)
l,lâ€²ï£¶
ï£·ï£¸.
Lemma C.3. LetÂµ, Î½âˆˆ {Âµi}d
i=1. Then the following equation on gradient flow holds:
âˆ‚Î½W(t)âŠ¤
VW(t)
VÂµ
âˆ‚t=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Âµ
+1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Î½.
Proof. The gradient flow update can be derived as follows:
âˆ‚Î½W(t)âŠ¤
VW(t)
VÂµ
âˆ‚t=1
nnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
j
X(i)p(t,i)
lâŠ¤
Âµ
+1
nnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Vw(t)
j
X(i)p(t,i)
lâŠ¤
Î½
=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Âµ
+1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Î½.
Lemma C.4. LetÂµ, Î½âˆˆ {Âµi}d
i=1. Then the following equations on gradient flow hold.
âˆ‚Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµ
âˆ‚t
=1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajÎ½âŠ¤W(t)âŠ¤
QK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
l(i,Âµ)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyim1X
j=1ajÂµâŠ¤W(t)âŠ¤
QK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Î½)
p(t,i)
l(i,Î½),
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
KÂµ
âˆ‚t
=1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Kq(t,i)
lp(t,i)
qâ†l,kâ†Âµ
w(t)âŠ¤
jv(t,i)(Âµ)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
19+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Kq(t,i)
lp(t,i)
qâ†l,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
,
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ
âˆ‚t
=1
nâˆšmX
i:Âµ,Î½âˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2
v(t)âŠ¤(Î½)w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
qâ†Âµ,kâ†Î½
+1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajLX
l=1Î½âŠ¤W(t)âŠ¤
KK(t,i)
l
V(t,i)âŠ¤
lw(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
qâ†Âµ,kâ†lI(K(t,i)
lÌ¸=k(t)(Î½))
+1
nâˆšmX
i:Î½,ÂµâˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥q(t)(Âµ)âˆ¥2
2p(t,i)
qâ†Âµ,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Qq(t,i)
lp(t,i)
qâ†l,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
I(q(t,i)
lÌ¸=q(t)(Âµ)).
Proof. To prove the first result, we have
âˆ‚Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµ
âˆ‚t
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
QK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
p(t,i)
lx(i)âŠ¤
lÂµ
+1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
QK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
p(t,i)
lx(i)âŠ¤
lÎ½
=1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajÎ½âŠ¤W(t)âŠ¤
QK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
l(i,Âµ)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyim1X
j=1ajÂµâŠ¤W(t)âŠ¤
QK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Î½)
p(t,i)
l(i,Î½).
To prove the second result, we have
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
KÂµ
âˆ‚t
=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Kq(t,i)
lp(t,i)âŠ¤
ldiag
w(t)âŠ¤
jV(t,i)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
X(i)âŠ¤Âµ
+1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Kq(t,i)
lp(t,i)âŠ¤
ldiag
w(t)âŠ¤
jV(t,i)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
X(i)âŠ¤Î½
=1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Kq(t,i)
lp(t,i)
qâ†l,kâ†Âµ
w(t)âŠ¤
jv(t,i)(Âµ)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Kq(t,i)
lp(t,i)
qâ†l,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
.
To prove the third result, we have
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ
âˆ‚t
20=1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
KK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
p(t,i)
lx(i)âŠ¤
lÂµ
+1
nâˆšmnX
i=1g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Qq(t,i)
lp(t,i)âŠ¤
ldiag
w(t)âŠ¤
jV(t,i)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
X(i)âŠ¤Î½
=1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajÎ½âŠ¤W(t)âŠ¤
KK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
l(i,Âµ)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Qq(t,i)
lp(t,i)
qâ†l,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
=1
nâˆšmX
i:Âµ,Î½âˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2
v(t)âŠ¤(Î½)w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
qâ†Âµ,kâ†Î½
+1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajLX
l=1Î½âŠ¤W(t)âŠ¤
KK(t,i)
l
V(t,i)âŠ¤
lw(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
qâ†Âµ,kâ†lI(K(t,i)
lÌ¸=k(t)(Î½))
+1
nâˆšmX
i:Î½,ÂµâˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥q(t)(Âµ)âˆ¥2
2p(t,i)
qâ†Âµ,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Qq(t,i)
lp(t,i)
qâ†l,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
I(q(t,i)
lÌ¸=q(t)(Âµ)).
D Initialization
Lemma D.1. With probability at least 1âˆ’Î´over the randomness of the initialization of WKand
WQ, for any l1, l2âˆˆ[d], we have
D
W(0)
KÂµl1, W(0)
QÂµl2Eâ‰¤Ïƒ2
0m r
4
mlog2d
Î´+4
mlog2d
Î´!
,
D
W(0)
KÂµl1, W(0)
KÂµl2Eâ‰¤Ïƒ2
0m r
4
mlog2d
Î´+4
mlog2d
Î´!
, l 1Ì¸=l2
D
W(0)
QÂµl1, W(0)
QÂµl2Eâ‰¤Ïƒ2
0m r
4
mlog2d
Î´+4
mlog2d
Î´!
, l 1Ì¸=l2
and for any lâˆˆ[d],
âˆ¥W(0)
KÂµlâˆ¥2
2=Ïƒ2
0m 
1Â± r
4
mlog2d
Î´+4
mlog2d
Î´!!
,
âˆ¥W(0)
QÂµlâˆ¥2
2=Ïƒ2
0m 
1Â± r
4
mlog2d
Î´+4
mlog2d
Î´!!
.
Proof. Note that W(0)
KÂµl1, W(0)
QÂµl2âˆ¼ N(0, Ïƒ2
0I). The rest of proof applies Lemma H.2.
Corollary D.2. For all iâˆˆ[n],l, kâˆˆ[L], we have
p(0,i)
l,k=1
LÂ±eO1
Lm
.
21Proof. Following from Lemma G.2 and from the first-order Taylor approximation on the softmax
function from 0, we have
p(0,i)
l,k=1
LÂ±O 
Ïƒ2
0m
Lâˆšm r
4
mlog2d
Î´+4
mlog2d
Î´!!
.
The corollary then follows from Condition 1.
Lemma D.3. With probability at least 1âˆ’Î´over the randomness of the initialization of WandWV,
then for l1Ì¸=l2âˆˆ[d], we have
D
W(0)
VÂµl1, W(0)
VÂµl2Eâ‰¤Ïƒ2
0m r
4
mlog2d
Î´+4
mlog2d
Î´!
,
forj1Ì¸=j2âˆˆ[m1], we have
D
w(0)
j1, w(0)
j2Eâ‰¤Ïƒ2
1m r
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´!
,
and for all jâˆˆ[m1], lâˆˆ[d], we have
D
w(0)
j, W(0)
VÂµlEâ‰¤Ïƒ0Ïƒ1m r
4
mlog2m1d
Î´+4
mlog2m1d
Î´!
âˆ¥wjâˆ¥2
2=Ïƒ2
1m 
1Â± r
4
mlog2m1
Î´+4
mlog2m1
Î´!!
âˆ¥W(0)
VÂµlâˆ¥2
2=Ïƒ2
0m 
1Â± r
4
mlog2d
Î´+4
mlog2d
Î´!!
.
Proof. The proof is similar to that for Lemma D.1 and is omitted.
Lemma D.4. Conditioned on the success of the event in Corollary D.2, for all iâˆˆ[n], lâˆˆ[L], with
probability at least 1âˆ’Î´over the randomness in the initialization of WV,
âˆ¥W(0)
VX(i)p(0,i)
lâˆ¥2
2=Ïƒ2
0m
L 
1Â±r
4
mlog2nL
Î´Â±4
mlog2nL
Î´!
Proof. First of all, by Corollary D.2 and Assumption 2.3,
Eh
âˆ¥W(0)
VX(i)p(0,i)
lâˆ¥2
2i
=Eï£®
ï£°mX
j=1
W(0)
V
j, X(i)p(0,i)
l2ï£¹
ï£»=Ïƒ2
0mâˆ¥X(i)p(0,i)
lâˆ¥2
2=Ïƒ2
0m
L.
Finally, applying Bernsteinâ€™s inequality and taking a union bound over [n]and[L]we finish the
proof.
Corollary D.5. Conditioned on the success of Lemma D.4, with probability at least 1âˆ’Î´over the
randomness of W, for all jâˆˆ[m1], iâˆˆ[n], lâˆˆ[L], we have
w(0)âŠ¤
jV(0,i)p(0,i)
lâ‰¤Ïƒ1Ïƒ0r
m
Llogm1nL
Î´.
Proof. Conditioned on V(0,i)p(0,i)
l, we have w(0)âŠ¤
jV(0,i)p(0,i)
lâˆ¼ N(0, Ïƒ2
1âˆ¥V(0,i)p(0,i)
lâˆ¥2
2). Thus, by
Gaussian tail bound and a union bound over jâˆˆ[m1], iâˆˆ[n], lâˆˆ[L], with probability at least
1âˆ’Î´, we have
w(0)âŠ¤
jV(0,i)p(0,i)
lâ‰¤Ïƒ1Ïƒ0r
m
Llogm1nL
Î´.
22Lemma D.6. With probability at least 1âˆ’Î´over the randomness in the initialization of a, we have
|S+1|=m1ï£«
ï£­1
2Â±s
2 log(4 /Î´)
m1ï£¶
ï£¸,
|Sâˆ’1|=m1ï£«
ï£­1
2Â±s
2 log(4 /Î´)
m1ï£¶
ï£¸.
Proof. The proof follows by applying Hoeffdingâ€™s inequality.
Lemma D.7 (Initial sub-network output) .Assume that the success of the events in Lemma D.3 holds.
For all iâˆˆ[d], with probability at least 1âˆ’Î´over the randomness in the weight initialization, we
have
|G(0)(Âµi)| â‰¤eO(Ïƒ1Ïƒ0âˆšmm 1).
Proof. Consider a fixed iâˆˆ[d]. By Lemma D.3, we have âˆ¥W(0)
VÂµiâˆ¥2
2= Î˜( Ïƒ2
0m). Thus, conditioned
onW(0)
VÂµi, we havePm1
j=1w(0)
jW(0)
VÂµiâˆ¼ N (0, Ïƒ2
1Ïƒ2
0mm 1). Thus, by Gaussian concentration
bound, we have |G(0)(Âµi)| â‰¤eO(Ïƒ1Ïƒ0âˆšmm 1).
Lemma D.8 (Initial network output) .Assume that the success of the events in Lemma D.3 and
Lemma D.4 holds. For all iâˆˆ[n], with probability at least 1âˆ’Î´over the randomness in the weight
initialization, we have
|F(0)(X(i))| â‰¤2Ïƒ0Ïƒ1p
2Lm1mlog(2Ln/Î´ )â‰¤0.01.
Proof. For fixed lâˆˆL, jâˆˆ[m], iâˆˆ[n], by Corollary D.5, we have
w(0)âŠ¤
jV(0,i)p(0,i)
lâ‰¤Ïƒ1Ïƒ0r
m
Llogm1nL
Î´.
Thus, this implies that ajw(0)âŠ¤
jV(0,i)p(0,i)
lis a sub-Gaussian random variable with variance proxy
Ïƒ2
0Ïƒ2
1m
Llogm1nL
Î´. Therefore, the following inequality holds.
Pï£®
ï£°m1X
j=1ajw(0)âŠ¤
jV(0,i)p(0,i)
lâ‰¥2Ïƒ0Ïƒ1s
2m1m(logm1nL
Î´) log(2 /Î´)
Lï£¹
ï£»â‰¤Î´.
Taking a union bound over iâˆˆ[n], lâˆˆ[L], with probability at least 1âˆ’Î´, for all iâˆˆ[n], we have
|F(0)(X(i))| â‰¤2Ïƒ0Ïƒ1r
2Lm1m(logm1nL
Î´) log(2 Ln/Î´ ).
Finally, by Condition 1, we can make |F(0)(X(i))| â‰¤0.01.
E Training Dynamics: Phase 1
During Phase 1 of training, the linear layer quickly aligns with the target signals and all the remaining
quantities stay roughly the same. The analysis need to keep track of the evolution of the above
quantities with respect to the two signals Âµ1, Âµ2, the common token Âµ3and the random tokens.
Definition E.1 (Radius of keys and queries) .Define the radius of keys and queries RK, RQrespec-
tively to be
RK:= max
i,jâˆˆ[d]ÂµâŠ¤
iW(t)âŠ¤
KW(t)
KÂµjâˆ’ÂµâŠ¤
iW(0)âŠ¤
KW(0)
KÂµj,
RQ:= max
i,jâˆˆ[d]ÂµâŠ¤
iW(t)âŠ¤
QW(t)
QÂµjâˆ’ÂµâŠ¤
iW(0)âŠ¤
QW(0)
QÂµj.
23Definition E.2 (Phase 1) .Define the range of Phase 1 to be [0, T1], where T1=
min{tâ€², CT1/(Ïƒ2
1mm 1)}for some sufficiently large constant CT1andtâ€²is defined to be the maximum
time such that for all tâ‰¤tâ€², all of the following hold:
1.maxjâˆˆ[m],Âµâˆˆ{Âµi}3
i=1w(t)
jW(t)
VÂµâˆ’w(0)
jW(0)
VÂµâ‰¤Rwhere R < O (1/m1);
2.maxjâˆˆ[m],Âµ/âˆˆ{Âµi}3
i=1w(t)
jW(t)
VÂµâˆ’w(0)
jW(0)
VÂµâ‰¤O(R/n+R/âˆšm);
3.maxÂµ,Î½âˆˆ{Âµ}d
i=1ÂµâŠ¤W(t)âŠ¤
QW(t)
KÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
QW(0)
KÎ½â‰¤RSwhere RSâ‰¤O(1/(mâˆšm));
4.RK, RQâ‰¤eO(Ïƒ2
0âˆšm).
Based on this definition, we can further obtain the maximum softmax probability change as follows.
Proposition E.3. Define
RP:= max
iâˆˆ[n], Âµ,Î½âˆˆX(i)p(t,i)
qâ†Âµ,kâ†Î½âˆ’p(0,i)
qâ†Âµ,kâ†Î½.
Then
RP=O1âˆšmL+L
m
.
Proof. By Lemma G.2, we have RPâ‰¤O(RS/L+R2
SL) =O
1âˆšmL+L
m
.
Initially, the loss for the samples with one signal will increase.
E.1 Initial Gradients
Lemma E.4 (Signal updates, same as Lemma 4.1) .Att= 0, forÂµâˆˆ {Âµ1, Âµ2}, we have
âˆ‚ajw(0)
jW(0)
VÂµ
âˆ‚t= Î˜(( Ïƒ2
0+Ïƒ2
1)m).
Proof. TakeÂµ=Âµ1. First of all, by the gradient flow update in Lemma C.1, we have
âˆ‚w(t)âŠ¤
j1W(t)
VÂµ
âˆ‚t=1
nnX
i2=1g(t)
i2yi2LX
l2=1m1X
j2=1aj2D
w(t)
j1, w(t)
j2E
X(i2)p(t,i2)
l2âŠ¤
Âµ
+1
nnX
i1=1g(t)
i1yi1LX
l1=1aj1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ
=1
nX
i2:ÂµâˆˆX(i2)g(t)
i2yi2LX
l2=1m1X
j2=1aj2D
w(t)
j1, w(t)
j2E
p(t,i2)
qâ†l2,kâ†Âµ
+1
nnX
i1=1g(t)
i1yi1LX
l1=1aj1LX
l2=1D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)E
=1
nX
i2:ÂµâˆˆX(i2)g(t)
i2yi2LX
l2=1ï£«
ï£­aj1âˆ¥w(t)
j1âˆ¥2
2+X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2Eï£¶
ï£¸p(t,i2)
qâ†l2,kâ†Âµ
+1
nX
i1:Âµ/âˆˆX(i1)g(t)
i1yi1LX
l1=1aj1LX
l2=1D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)E
+1
nX
i1:ÂµâˆˆX(i1)g(t)
i1yi1LX
l1=1aj1ï£«
ï£­âˆ¥v(t)(Âµ)âˆ¥2
2p(t,i1)
qâ†l1,kâ†Âµ+X
l2Ì¸=l(i1,Âµ)D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)Eï£¶
ï£¸
24=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1aj1
âˆ¥w(t)
j1âˆ¥2
2+âˆ¥v(t)(Âµ)âˆ¥2
2
p(t,i)
qâ†l,kâ†Âµ
+1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
p(t,i)
qâ†l,kâ†Âµ
| {z }
Îµ1
+1
nnX
i=1g(t)
iyiLX
l1=1aj1LX
l2=1D
p(t,i)
l1,l2v(t,i)
l2, v(t)(Âµ)E
I(v(t,i)
l2Ì¸=v(t)(Âµ))
| {z }
Îµ2.
Now, by Lemma D.3, Corollary D.2 and Lemma D.8, we have
aj11
nX
i:Âµ1âˆˆX(i)g(0)
iyiLX
l=1aj1
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ1
=1
nX
iâˆˆI1g(0)
iLX
l=1
âˆ¥w(0)
jâˆ¥2
2+âˆ¥v(0)(Âµ1)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ1âˆ’1
nX
iâˆˆI2g(0)
iLX
l=1
âˆ¥w(0)
jâˆ¥2
2+âˆ¥v(0)(Âµ1)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ1
=1
3Â±0.01
LÂ· 
Ïƒ2
1m+Ïƒ2
0m 
1Â± r
4
mlog2d
Î´+4
mlog2d
Î´!!
1
L(1 +o(1)).
On the other hand, by Proposition E.5, we have
|Îµ1|=1
nX
i:Âµ1âˆˆX(i)g(0)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2E
p(0,i)
qâ†l,kâ†Âµ1
â‰¤Ïƒ2
1âˆšm1m r
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´!r
logm1
Î´;
|Îµ2|=1
nnX
i=1g(0)
iyiLX
l1=1aj1LX
l2=1D
p(0,i)
l1,l2v(0,i)
l2, v(0)(Âµ1)E
I(v(0,i)
l2Ì¸=v(0)(Âµ1))
â‰¤Ïƒ2
0mâˆš
L r
4
mlog2nL
Î´+4
mlog2nL
Î´!
.
Ifmâ‰¥Cm1log2m1
Î´in Condition 1 for some sufficiently large C, then|Îµ1| â‰¤0.01Ïƒ2
1m; and if
mâ‰¥Câ€²Llog2nL
Î´for some sufficiently large Câ€², then|Îµ2| â‰¤0.01Ïƒ2
0m.
Proposition E.5. Assume the events in Lemma D.3 and Corollary D.2 succeed. With probability at
least1âˆ’Î´over the randomness in the weight initialization, for all j1âˆˆ[m1], we haveX
j2:j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2Eâ‰¤Ïƒ2
1âˆšm1m r
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´!r
log4m1
Î´.
Further, for all Âµâˆˆ {Âµi}d
i=1, we have1
nX
i:ÂµâˆˆX(i)g(0)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2E
p(0,i)
qâ†l,kâ†Âµ
â‰¤|i:ÂµâˆˆX(i)|
nÏƒ2
1âˆšm1m r
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´!r
logm1
Î´,
and1
nnX
i=1g(0)
iyiLX
l1=1aj1LX
l2=1D
p(0,i)
l1,l2v(0,i)
l2, v(0)(Âµ)E
I(v(0,i)
l2Ì¸=v(0)(Âµ))
25â‰¤Ïƒ2
0mâˆš
L r
4
mlog2nLd
Î´+4
mlog2nLd
Î´!
.
Proof. First, fix i, l, and consider the randomness of a. By Lemma D.3, aj2D
w(0)
j1, w(0)
j2E
is a sub-
Gaussian random variable with variance proxy Ïƒ4
1m2q
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´2
. This implies
that with probability at least 1âˆ’Î´/2, for all j1âˆˆ[m1], we have
X
j2:j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2Eâ‰¤Ïƒ2
1âˆšm1m r
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´!r
log4m1
Î´.
Thus, by Corollary D.2, for all Âµâˆˆ {Âµi}d
i=1, we have
1
nX
i:Âµ1âˆˆX(i)g(0)
iyiLX
l=1X
j2:j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2E
p(0,i)
qâ†l,kâ†Âµ
â‰¤|i:ÂµâˆˆX(i)|
nÏƒ2
1âˆšm1m r
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´!r
logm1
Î´.
We next derive the second inequality. Consider the randomness in W(0)
V. Note that
LX
l2=1p(0,i)
l1,l2v(0,i)
l2I(v(0,i)
l2Ì¸=v(0)(Âµ))âˆ¼ N 
0, Ïƒ2
0LX
l2=1(p(0,i)
l1,l2)2I(v(0,i)
l2Ì¸=v(0)(Âµ))I!
.
Thus, by Lemma H.2 and Corollary D.2 and taking a union bound over iâˆˆ[n], l1âˆˆ[L], Âµâˆˆ
{Âµi}d
i=1, we have with probability at least 1âˆ’Î´/2,
*LX
l2=1p(0,i)
l1,l2v(0,i)
l2I(v(0,i)
l2Ì¸=v(0)(Âµ)), v(0)(Âµ)+â‰¤Ïƒ2
0m1âˆš
L r
4
mlog2nLd
Î´+4
mlog2nLd
Î´!
.
Therefore,
1
nnX
i=1g(0)
iyiLX
l1=1aj1LX
l2=1D
p(0,i)
l1,l2v(0,i)
l2, v(0)(Âµ)E
I(v(0,i)
l2Ì¸=v(0)(Âµ))
â‰¤Ïƒ2
0mâˆš
L r
4
mlog2nLd
Î´+4
mlog2nLd
Î´!
.
Lemma E.6 (Random token updates) .ForÂµâˆˆ {Âµi}d
i=4, we have
âˆ‚ajw(0)
jW(0)
VÂµ
âˆ‚t=O1
n(Ïƒ2
0+Ïƒ2
1)m+Ïƒ2
0âˆš
mL
.
Proof. Following the proof of Lemma E.4, we have
âˆ‚ajw(0)
jW(0)
VÂµ
âˆ‚t=1
nnX
i2=1g(0)
i2yi2LX
l2=1m1X
j2=1aj2D
w(0)
j1, w(0)
j2E
X(i2)p(0,i2)
l2âŠ¤
Âµ
+1
nnX
i1=1g(0)
i1yi1LX
l1=1aj1p(0,i1)âŠ¤
l1V(0,i1)âŠ¤W(0)
VÂµ
=1
nX
i:ÂµâˆˆX(i)g(0)
iyiLX
l=1aj1
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ
26+1
nX
i:ÂµâˆˆX(i)g(0)
iyiLX
l=1X
j2:j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2E
p(0,i)
qâ†l,kâ†Âµ
| {z }
Îµ1
+1
nnX
i=1g(0)
iyiLX
l1=1aj1LX
l2=1D
p(0,i)
l1,l2v(0,i)
l2, v(0)(Âµ)E
I(v(0,i)
l2Ì¸=v(0)(Âµ))
| {z }
Îµ2
By Proposition E.5 and the fact that only one X(i)satisfies ÂµâˆˆX(i), we have
1
nX
i:ÂµâˆˆX(i)g(0)
iyiLX
l=1aj1
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ= Î˜1
n(Ïƒ2
0+Ïƒ2
1)m
,
and
|Îµ1| â‰¤1
nÏƒ2
1âˆšm1m r
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´!r
log4m1
Î´,
|Îµ2| â‰¤Ïƒ2
0mâˆš
L r
4
mlog2nLd
Î´+4
mlog2nLd
Î´!
.
E.2 Maximum Perturbation of Neuron Outputs
Lemma E.7. For all tâ‰¤T1, for all iâˆˆ[n], lâˆˆ[L], we have
w(t)
jW(t)
VX(i)p(t,i)
lâˆ’w(0)
jW(0)
VX(i)p(0,i)
lâ‰¤eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L.
Proof. By Definition E.2, we have
w(t)
jV(t,i)p(t,i)
lâˆ’w(0)
jV(0,i)p(0,i)
l
â‰¤LX
lâ€²=1w(t)
jV(t,i)
lâ€²p(t,i)
l,lâ€²âˆ’w(0)
jV(0,i)
lâ€²p(0,i)
l,lâ€²
â‰¤X
lâ€²:Vlâ€²âˆˆv(Âµ1,Âµ2,Âµ3)(RPeO(Ïƒ0Ïƒ1âˆšm) +R/L) +X
lâ€²:Vlâ€²/âˆˆv(Âµ1,Âµ2,Âµ3)(RPeO(Ïƒ0Ïƒ1âˆšm) +R/(nL))
â‰¤eO(RPÏƒ0Ïƒ1âˆšm+R/L) +eO(LRPÏƒ0Ïƒ1âˆšm+R/n)
=eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L.
By our choice of parameters in Condition 1 and Definition E.2, we have eO(LRPÏƒ0Ïƒ1âˆšm)+4R/L <
Ïƒ0Ïƒ1p
m/L .
E.3 Perturbation Term Involving Correlation of Value-transformed Data
Proposition E.8. With probability at least 1âˆ’Î´, for all Âµâˆˆ {Âµi}d
i=1, we have
m1X
j=1ajÂµâŠ¤W(0)âŠ¤
Vw(0)
jâ‰¤eO(Ïƒ0Ïƒ1âˆšmm 1).
Proof. The proof is similar to Proposition E.22, and is omitted.
27Lemma E.9 (Value correlation change) .For all Âµ, Î½âˆˆ {Âµi}d
i=1, we haveâˆ‚
v(t)(Âµ), v(t)(Î½)
âˆ‚tâ‰¤
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
nO(1),
and thus,
D
v(t)(Âµ), v(t)(Î½)E
âˆ’D
v(0)(Âµ), v(0)(Î½)Eâ‰¤t
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
nO(1)
for all tâ‰¤T1. Thus, for ÂµÌ¸=Î½, we have
v(t)(Âµ), v(t)(Î½)â‰¤eO(Ïƒ2
0âˆšm)andâˆ¥v(t)(Âµ)âˆ¥2
2=
Î˜(Ïƒ2
0m)fortâ‰¤T1.
Proof. By Lemma C.3, we have
âˆ‚Î½W(t)âŠ¤
VW(t)
VÂµ
âˆ‚t=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Âµ
+1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Î½.
Further,m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
jâˆ’m1X
j=1ajÎ½âŠ¤W(0)âŠ¤
Vw(0)
jâ‰¤m1R.
Thus, by Proposition E.8, we havem1X
j=1ajw(t)âŠ¤
jW(t)
VÎ½â‰¤m1X
j=1ajË™Ïƒ(0)
i,l,jw(0)âŠ¤
jW(0)
VÎ½+m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
jâˆ’m1X
j=1ajÎ½âŠ¤W(0)âŠ¤
Vw(0)
j
â‰¤eO(Ïƒ0Ïƒ1âˆšmm 1) +m1R,
which implies1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Âµ
+1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Î½
â‰¤1
nn
i:ÂµâˆˆX(i)o+n
i:Î½âˆˆX(i)o
eO(Ïƒ0Ïƒ1âˆšmm 1) +m1R
â‰¤
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
nO(1)
where the last inequality applies Lemma E.7.
Corollary E.10. For all tâ‰¤T1, we have1
nnX
i=1g(t)
iyiLX
l1=1aj1LX
l2=1D
p(t,i)
l1,l2v(t,i)
l2, v(t)(Âµ1)E
I(v(t,i)
l2Ì¸=v(t)(Âµ1))â‰¤LÂ·eO 
Ïƒ2
0âˆšm
.
Proof. We derive the following bound:1
nnX
i=1g(t)
iyiLX
l1=1aj1LX
l2=1D
p(t,i)
l1,l2v(t,i)
l2, v(t)(Âµ)E
I(v(t,i)
l2Ì¸=v(t)(Âµ))
â‰¤LX
l1=1LX
l2=1p(t,i)
l1,l2D
v(t,i)
l2, v(t)(Âµ)EI(v(t,i)
l2Ì¸=v(t)(Âµ))
â‰¤LÂ·eO 
Ïƒ2
0âˆšm
,
where the last inequality follows from Lemma E.9 and Lemma D.3.
28E.4 Perturbation Term Involving Correlation of Neurons
Lemma E.11. For all tâ‰¤T1, we have1
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
p(t,i)
qâ†l,kâ†Âµ1â‰¤|{i:Âµ1âˆˆX(i)}|
neO(Ïƒ2
1âˆšmm 1).
Proof. We first derive:1
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
p(t,i)
qâ†l,kâ†Âµ1
â‰¤1
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2EÂ·max
i,lp(t,i)
qâ†l,kâ†Âµ1
â‰¤1
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2EÂ·max
i,lp(t,i)
qâ†l,kâ†Âµ1
| {z }
(1)
+1
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
âˆ’D
w(0)
j1, w(0)
j2EÂ·max
i,lp(t,i)
qâ†l,kâ†Âµ1
| {z }
(2).
For term (1), by Proposition E.5, we have1
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2Eâ‰¤|{i:Âµ1âˆˆX(i)}|
neO 
Ïƒ2
1âˆšmm 1L
.
For term (2), note that1
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
âˆ’D
w(0)
j1, w(0)
j2E
â‰¤|{i:Âµ1âˆˆX(i)}|
nLm1Â·O1
m
,
where the inequality is by Lemma D.3, Proposition E.12.
Finally, since p(t,i)
qâ†l,kâ†Âµ1â‰¤1
L+1
L2+RP, combining the upper bound for both terms (1)and(2),
we haveÎ±
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2Ë™Ïƒ(t)
i,l,j 2D
w(t)
j1, w(t)
j2E
p(t,i)
qâ†l,kâ†Âµ1
â‰¤Î±|{i:Âµ1âˆˆX(i)}|
nÂ·eO 
Ïƒ2
1âˆšmm 1L
.
Proposition E.12 (Neuron correlation change, Phase 1) .Fortâ‰¤T1, for all j1, j2âˆˆ[m1], we have
âˆ‚D
w(t)
j1, w(t)
j2E
âˆ‚tâ‰¤2L 
Ïƒ1Ïƒ0r
m
Llogm1nL
Î´+eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L!
,
and thus,
D
w(t)
j1, w(t)
j2E
âˆ’D
w(0)
j1, w(0)
j2Eâ‰¤t2L 
Ïƒ1Ïƒ0r
m
Llogm1nL
Î´+eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L!
.
29Proof. By the gradient flow update in Lemma C.2, we have
âˆ‚D
w(t)
j1, w(t)
j2E
âˆ‚t=1
nnX
iâ€²=1g(t)
iâ€²yiâ€²LX
lâ€²=1aj2w(t)âŠ¤
j1V(t,iâ€²)p(t,iâ€²)
lâ€²+1
nnX
iâ€²=1g(t)
iâ€²yiâ€²LX
lâ€²=1aj1w(t)âŠ¤
j2V(t,iâ€²)p(t,iâ€²)
lâ€²
=1
nnX
iâ€²=1g(t)
iâ€²yiâ€²LX
lâ€²=1aj2
w(0)âŠ¤
j1V(0,iâ€²)p(0,iâ€²)
lâ€²+ (w(t)âŠ¤
j1V(t,iâ€²)p(t,iâ€²)
lâ€²âˆ’w(0)âŠ¤
j1V(0,iâ€²)p(0,iâ€²)
lâ€²)
+1
nnX
iâ€²=1g(t)
iâ€²yiâ€²LX
lâ€²=1aj1
w(0)âŠ¤
j2V(0,iâ€²)p(0,iâ€²)
lâ€²+ (w(t)âŠ¤
j2V(t,iâ€²)p(t,iâ€²)
lâ€²âˆ’w(0)âŠ¤
j2V(0,iâ€²)p(0,iâ€²)
lâ€²)
.
Now, since by Lemma E.7 we have
w(t)
jW(t)
VX(i)p(t,i)
lâˆ’w(0)
jW(0)
VX(i)p(0,i)
lâ‰¤eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L,
by Definition E.2 and Corollary D.5, we have
1
nnX
iâ€²=1g(t)
iâ€²yiâ€²LX
lâ€²=1aj2
w(0)âŠ¤
j1V(0,iâ€²)p(0,iâ€²)
lâ€²+ (w(t)âŠ¤
j1V(t,iâ€²)p(t,iâ€²)
lâ€²âˆ’w(0)âŠ¤
j1V(0,iâ€²)p(0,iâ€²)
lâ€²)
â‰¤L 
Ïƒ1Ïƒ0r
m
Llogm1nL
Î´+eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L!
1
nnX
iâ€²=1g(t)
iâ€²yiâ€²LX
lâ€²=1aj1
w(0)âŠ¤
j2V(0,iâ€²)p(0,iâ€²)
lâ€²+ (w(t)âŠ¤
j2V(t,iâ€²)p(t,iâ€²)
lâ€²âˆ’w(0)âŠ¤
j2V(0,iâ€²)p(0,iâ€²)
lâ€²)
â‰¤L 
Ïƒ1Ïƒ0r
m
Llogm1nL
Î´+eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L!
.
Thus,
D
w(t)
j1, w(t)
j2E
âˆ’D
w(0)
j1, w(0)
j2E
â‰¤Zt
Ï„=0âˆ‚D
w(Ï„)
j1, w(Ï„)
j2E
âˆ‚Ï„â‰¤t2L 
Ïƒ1Ïƒ0r
m
Llogm1nL
Î´+eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L!
.
Corollary E.13 (Neuron Norm Change, Phase 1) .For all tâ‰¤T1and all jâˆˆ[m], we have
âˆ¥w(t)
jâˆ¥2
2âˆ’ âˆ¥w(0)
jâˆ¥2
2â‰¤t2L(Ïƒ1Ïƒ0r
m
Llogm1nL
Î´+eO(LRPÏƒ0Ïƒ1âˆšm) + 4R/L).
E.5 Neuron Weights Align with Signal Value
Theorem E.14 (Signal correlation growth, phase 1) .Fortâ‰¤T1, forÂµâˆˆ {Âµ1, Âµ2},
âˆ‚ajw(t)
jW(t)
VÂµ
âˆ‚t=1
n X
i:ÂµâˆˆX(i),
yi=1g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµâˆ’X
i:ÂµâˆˆX(i),
yi=âˆ’1g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ!
Î˜((Ïƒ2
0+Ïƒ2
1)m) +Îµ
where
|Îµ| â‰¤eO(LÏƒ2
0âˆšm+Ïƒ2
1âˆšmm 1).
Proof. We take Âµ=Âµ1and the proof is similar for Âµ=Âµ2. By Lemma C.1, we have
âˆ‚ajw(t)
jW(t)
VÂµ
âˆ‚t
30=1
nX
i:Âµ1âˆˆX(i),yi=1g(t)
iLX
l=1
âˆ¥w(t)
jâˆ¥2
2+âˆ¥v(t)(Âµ1)âˆ¥2
2
p(t,i)
qâ†l,kâ†Âµ1
âˆ’1
nX
i:Âµ1âˆˆX(i),yi=âˆ’1g(t)
iLX
l=1
âˆ¥w(t)
jâˆ¥2
2+âˆ¥v(t)(Âµ1)âˆ¥2
2
p(t,i)
qâ†l,kâ†Âµ1+Îµ
=
âˆ¥w(t)
jâˆ¥2
2+âˆ¥v(t)(Âµ1)âˆ¥2
21
n X
i:Âµ1âˆˆX(i),
yi=1g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ1âˆ’X
i:Âµ1âˆˆX(i),
yi=âˆ’1g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ1!
+Îµ
where
Îµ=1
nX
i:Âµ1âˆˆX(i)g(t)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
p(t,i)
qâ†l,kâ†Âµ1
+1
nnX
i=1g(t)
iyiLX
l1=1aj1LX
l2=1D
p(t,i)
l1,l2v(t,i)
l2, v(t)(Âµ1)E
I(v(t,i)
l2Ì¸=v(t)(Âµ1)).
We can now bound the magnitude of Îµby Corollary E.10, Lemma E.11 and Proposition E.5 and
obtain:
|Îµ| â‰¤LÂ·eO 
Ïƒ2
0âˆšm
+eO(Ïƒ2
1âˆšmm 1).
Finally, by Lemma D.3 and Corollary E.13, we have âˆ¥w(t)
jâˆ¥2
2= Î˜( Ïƒ2
1m)and by Lemma E.9, we
haveâˆ¥v(t)(Âµ1)âˆ¥2
2= Î˜( Ïƒ2
0m). The proof is completed.
Theorem E.15 (Random token growth, Phase 1) .Fortâ‰¤T1, forÂµâˆˆ R, we have
âˆ‚ajw(t)
jW(t)
VÂµ
âˆ‚t=O1
n(Ïƒ2
0+Ïƒ2
1)m
+eO(Ïƒ2
0Lâˆšm).
Proof. Fix a Âµâˆˆ R. By our Assumption 2.3, Âµappears at most once in the training data set. Now,
assume Âµis in the training set and let iâ‹†be the index of the sample containing Âµ. Applying Lemma C.1
on the random token Âµ, we have
âˆ‚ajw(t)
jW(t)
VÂµ
âˆ‚t=1
ng(t)
iâ‹†yiâ‹†LX
l=1aj
âˆ¥w(t)
jâˆ¥2
2+âˆ¥v(t)(Âµ)âˆ¥2
2
p(t,iâ‹†)
qâ†l,kâ†Âµ+Îµ,
where
Îµ=1
ng(t)
iâ‹†yiâ‹†LX
l=1X
j2Ì¸=j1aj2D
w(t)
j1, w(t)
j2E
p(t,iâ‹†)
qâ†l,kâ†Âµ
+1
nnX
i=1g(t)yiLX
l1=1aj1LX
l2=1D
p(t,i)
l1,l2v(t,i)
l2, v(t)(Âµ)E
I(v(t,i)
l2Ì¸=v(t)(Âµ)).
We can now bound the magnitude of Îµby Corollary E.10 and Lemma E.11 as follows:
|Îµ| â‰¤LÂ·eO 
Ïƒ2
0âˆšm
+1
neO(Ïƒ2
1âˆšmm 1).
Finally, by Lemma D.3 and Corollary E.13, we have
âˆ‚ajw(t)
jW(t)
VÂµ
âˆ‚t=O1
n(Ïƒ2
0+Ïƒ2
1)m
+eO(Ïƒ2
0Lâˆšm).
31E.6 Alignment of Common Token
Lemma E.16 (Initial Per Neuron Gradient of Common Token, same as Lemma 4.2) .LetF=
max iF(0)
i. We have
âˆ‚ajw(0)
jW(0)
VÂµ3
âˆ‚t=eO
Ïƒ2
1âˆšmm 1+Ïƒ2
0âˆš
mL+ (Ïƒ2
0+Ïƒ2
1)mF
.
Proof. Following from the proof of Lemma E.4, we have
âˆ‚aj1w(0)
j1W(0)
VÂµ3
âˆ‚t=1
nX
i:Âµ3âˆˆX(i)g(0)
iyiLX
l=1
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ1)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ3
+aj11
nX
i:Âµ3âˆˆX(i)g(0)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2E
p(0,i)
qâ†l,kâ†Âµ3
| {z }
Îµ1
+aj11
nnX
i=1g(0)
iyiLX
l1=1aj1LX
l2=1D
p(0,i)
l1,l2v(0,i)
l2, v(0)(Âµ3)E
I(v(0,i)
l2Ì¸=v(0)(Âµ3))
| {z }
Îµ2.
For the first term, we have1
nX
i:Âµ3âˆˆX(i)g(0)
iyiLX
l=1
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ3)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ3
=1
nX
yi=1g(0)
iLX
l=1
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ3)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ3
âˆ’1
nX
yi=âˆ’1g(0)
iLX
l=1
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ3)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ3
=1
n
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ3)âˆ¥2
2X
yi=1g(0)
iLX
l=1p(0,i)
qâ†l,kâ†Âµ3âˆ’X
yi=âˆ’1g(0)
iLX
l=1p(0,i)
qâ†l,kâ†Âµ3.
By Lemma D.8, and Corollary D.2, we have
1
nX
yi=1g(0)
iLX
l=1p(0,i)
qâ†l,kâ†Âµ3âˆ’X
yi=âˆ’1g(0)
iLX
l=1p(0,i)
qâ†l,kâ†Âµ3
â‰¤1
n X
yi=11
2+FLX
l=11
L+1
L2
âˆ’X
yi=âˆ’11
2âˆ’FLX
l=11
Lâˆ’1
L2!
â‰¤1
2+F1
L+1
LmL
2âˆ’1
2âˆ’F1
Lâˆ’1
LmL
2
â‰¤2F+O(1/m).
By Lemma D.3, we have âˆ¥w(0)
j1âˆ¥2
2= Î˜( Ïƒ2
1m)andâˆ¥v(0)(Âµ3)âˆ¥2
2= Î˜( Ïƒ2
0m), and thus,
1
nX
i:Âµ3âˆˆX(i)g(0)
iyiLX
l=1aj1
âˆ¥w(0)
j1âˆ¥2
2+âˆ¥v(0)(Âµ3)âˆ¥2
2
p(0,i)
qâ†l,kâ†Âµ3â‰¤eO(Î±(Ïƒ2
0+Ïƒ2
1)mF).
Further, by Proposition E.5, we have
|Îµ1|=1
nX
i:Âµ3âˆˆX(i)g(0)
iyiLX
l=1X
j2Ì¸=j1aj2D
w(0)
j1, w(0)
j2E
p(0,i)
qâ†l,kâ†Âµ3
32â‰¤Ïƒ2
1âˆšm1m r
4
mlog2m2
1
Î´+4
mlog2m2
1
Î´!r
logm1
Î´.
|Îµ2|=1
nnX
i=1g(0)
iyiLX
l1=1aj1LX
l2=1D
p(0,i)
l1,l2v(0,i)
l2, v(0)(Âµ3)E
I(v(0,i)
l2Ì¸=v(0)(Âµ3))
â‰¤Ïƒ2
0mâˆš
L r
4
mlog2nL
Î´+4
mlog2nL
Î´!
.
Finally, we have
âˆ‚aj1w(0)
j1W(0)
VÂµ3
âˆ‚tâ‰¤eO
Ïƒ2
1âˆšmm 1+Ïƒ2
0âˆš
mL+ (Ïƒ2
0+Ïƒ2
1)mF
.
Lemma E.17 (Per neuron gradient of common token) .Fortâ‰¤T1, we have
âˆ‚ajw(0)
jW(0)
VÂµ3
âˆ‚tâ‰¤eO(Ïƒ2
1m)
Proof. The proof is similar to that for Theorem E.14 and we omit it here.
Definition E.18 (sub-network) .Define the sub-network structure as
G(Âµ) =m1X
j=1ajwjWVÂµ.
We can compute the gradient of the sub-network as
âˆ‚G(Âµ)
âˆ‚t=m1X
j=1âˆ‚ajw(t)
jW(t)
VÂµ
âˆ‚t=m1X
j=1ajw(t)
jâˆ‚W(t)
VÂµ
âˆ‚t+ajâˆ‚w(t)
j
âˆ‚tW(t)
VÂµ
=1
nX
i2:ÂµâˆˆX(i2)g(t)
i2yi2LX
l2=1m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
p(t,i2)
qâ†l2,kâ†Âµ
+1
nnX
i1=1g(t)
i1yi1m1LX
l1=1LX
l2=1D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)E
.
Theorem E.19 (Complete version of Lemma 4.3) .There exists a T0.5â‰¤T1and a constant 0< C < 1
such that for all T0.5â‰¤tâ‰¤T1,
(1 +C) maxâˆ‚G(t)(Âµ1)
âˆ‚t,âˆ‚G(t)(Âµ2)
âˆ‚t
â‰¤ âˆ’âˆ‚G(t)(Âµ3)
âˆ‚tâ‰¤(1âˆ’C)âˆ‚G(t)(Âµ1)
âˆ‚t+âˆ‚G(t)(Âµ2)
âˆ‚t
.
Further,
âˆ‚G(t)(Âµ1)
âˆ‚t,âˆ‚G(t)(Âµ2)
âˆ‚tâ‰¥â„¦((Ïƒ2
0+Ïƒ2
1)mm 1).
Proof. First of all, we have
âˆ‚F(t)
i
âˆ‚t=LX
l1=1m1X
j=1LX
l2=1 
âˆ‚ajw(t)
jW(t)
VXl2
âˆ‚tp(t,i)
l1,l2+ajw(t)
jW(t)
VXl2âˆ‚p(t,i)
l1,l2
âˆ‚t!
.
By Lemma E.4 and Lemma E.16, we have
âˆ‚ajw(0)
jW(0)
VÂµ1
âˆ‚tâˆ’âˆ‚ajw(0)
jW(0)
VÂµ3
âˆ‚t= Î˜(( Ïƒ2
0+Ïƒ2
1)m),
33âˆ‚ajw(0)
jW(0)
VÂµ2
âˆ‚tâˆ’âˆ‚ajw(0)
jW(0)
VÂµ3
âˆ‚t= Î˜(( Ïƒ2
0+Ïƒ2
1)m).
By Theorem E.15 and Corollary E.24, we have
LX
l1=1m1X
j=1LX
l2=1 
âˆ‚ajw(t)
jW(t)
VXl2
âˆ‚tI(Xl2/âˆˆ {Âµi}3
i=1)p(t,i)
l1,l2+ajw(t)
jW(t)
VXl2âˆ‚p(t,i)
l1,l2
âˆ‚t!
=OL
n(Ïƒ2
0+Ïƒ2
1)mm 1
.
Thus, for all iâˆˆI1âˆªI2âˆªI3,âˆ‚F(0)
i
âˆ‚t>0, which impliesâˆ‚g(0)
i
âˆ‚t<0foriâˆˆI1andâˆ‚g(0)
i
âˆ‚t>0for
iâˆˆI2âˆªI3.
Next, we show that there must exist a time such that âˆ’âˆ‚G(t)(Âµ3)
âˆ‚t= max(âˆ‚G(t)(Âµ1)
âˆ‚t,âˆ‚G(t)(Âµ2)
âˆ‚t).
Without loss of generality, assumeâˆ‚G(t)(Âµ1)
âˆ‚t>âˆ‚G(t)(Âµ2)
âˆ‚t. We now analyze the condition when the
magnitude of the update of the common token is less than the magnitude of the update of the signals.
By Lemma C.1, we have
m1X
j=1âˆ‚ajw(t)
jW(t)
VÂµ1
âˆ‚tâ‰¥ âˆ’m1X
j=1âˆ‚ajw(t)
jW(t)
VÂµ3
âˆ‚t
â‡”1
n
âˆ¥W(t)âˆ¥2
F+m1âˆ¥v(t)(Âµ1)âˆ¥2
2 X
iâˆˆI1g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ1âˆ’X
iâˆˆI2g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ1!
+m1X
j=1ajÎµ(t)(Âµ1)
â‰¥1
n
âˆ¥W(t)âˆ¥2
F+m1âˆ¥v(t)(Âµ3)âˆ¥2
2 X
iâˆˆI2âˆªI3âˆªI4g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ3âˆ’X
iâˆˆI1g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ3!
+m1X
j=1ajÎµ(t)(Âµ3)
â‡”1
nX
iâˆˆI1g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ1+1
nâˆ¥W(t)âˆ¥2
F+m1âˆ¥v(t)(Âµ3)âˆ¥2
2
âˆ¥W(t)âˆ¥2
F+m1âˆ¥v(t)(Âµ1)âˆ¥2
2X
iâˆˆI1g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ3
â‰¥1
nâˆ¥W(t)âˆ¥2
F+m1âˆ¥v(t)(Âµ3)âˆ¥2
2
âˆ¥W(t)âˆ¥2
F+m1âˆ¥v(t)(Âµ1)âˆ¥2
2X
iâˆˆI2âˆªI3âˆªI4g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ3+1
nX
iâˆˆI2g(t)
iLX
l=1p(t,i)
qâ†l,kâ†Âµ1
+Pm1
j=1ajÎµ(t)(Âµ3)
âˆ¥W(t)âˆ¥2
F+m1âˆ¥v(t)(Âµ1)âˆ¥2
2âˆ’Pm1
j=1ajÎµ(t)(Âµ1)
âˆ¥W(t)âˆ¥2
F+m1âˆ¥v(t)(Âµ1)âˆ¥2
2
â‡”1
n(1 +o(1))X
iâˆˆI1g(t)
i+1
n(1 +o(1))X
iâˆˆI1g(t)
i
â‰¥1
n(1 +o(1))X
iâˆˆI2âˆªI3âˆªI4g(t)
i+1
n(1 +o(1))X
iâˆˆI2g(t)
iÂ±Orm1
m
where the last equality applies Corollary E.24. If mis sufficiently larger than m1(by some large
constant factor C), then the last term is negligible. Note that the above implies that ifâˆ‚G(t)(Âµ1)
âˆ‚tâ‰¥
âˆ‚G(t)(Âµ3)
âˆ‚tthenP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i= â„¦(1) sinceP
iâˆˆI3âˆªI4g(t)
i= â„¦(1) for all tâ‰¤T1. Now, by
Proposition E.21, if the initialization level is small enough, thenP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
iâ‰¥â„¦(1) .
Thus, ifâˆ‚G(t)(Âµ1)
âˆ‚tâ‰¥ âˆ’âˆ‚G(t)(Âµ3)
âˆ‚t, then1
nP
iâˆˆI1âˆ‚g(t)
i
âˆ‚t=âˆ’Î˜((Ïƒ2
0+Ïƒ2
1)mm 1). Therefore, there
must exist a time tâ€²= Î˜(1 /m)such thatâˆ‚G(tâ€²)(Âµ1)
âˆ‚t=âˆ’âˆ‚G(tâ€²)(Âµ3)
âˆ‚t. Further, for tâ‰¥Î˜(F/m),
we have yiF(t)
i>0for all iâˆˆI4andP
iâˆˆI4g(t)
i<min(P
iâˆˆI2g(t)
i,P
iâˆˆI3g(t)
i), where F=
max iâˆˆ[n]|F(0)
i|.
34Now, consider a time point tâ€²whenâˆ‚G(tâ€²)(Âµ1)
âˆ‚t=âˆ’âˆ‚G(tâ€²)(Âµ3)
âˆ‚t. At tâ€², we must have
min(P
iâˆˆI2g(tâ€²)
i,P
iâˆˆI3g(tâ€²)
i)âˆ’P
iâˆˆI4g(tâ€²)
i= â„¦(1) . Thus,
2X
iâˆˆI1g(tâ€²)
iâˆ’2X
iâˆˆI4g(tâ€²)
i= â„¦(1) ,
which implies
âˆ‚
âˆ‚F2X
iâˆˆI1g(tâ€²)
iâˆ’âˆ‚
âˆ‚FX
iâˆˆI4g(tâ€²)
i= â„¦(1) .
ForiâˆˆI1, we have
âˆ‚F(tâ€²)
i
âˆ‚t=âˆ‚G(tâ€²)(Âµ1)
âˆ‚t+âˆ‚G(tâ€²)(Âµ2)
âˆ‚t+âˆ‚G(tâ€²)(Âµ3)
âˆ‚t+OL
nÏƒ2
1mm 1
=âˆ‚G(tâ€²)(Âµ2)
âˆ‚t+OL
nÏƒ2
1mm 1
.
ForiâˆˆI2,
âˆ‚F(t)
i
âˆ‚t=âˆ‚G(tâ€²)(Âµ1)
âˆ‚t+âˆ‚G(tâ€²)(Âµ3)
âˆ‚t+OL
nÏƒ2
1mm 1
=OL
nÏƒ2
1mm 1
.
ForiâˆˆI3, by Proposition E.21,
âˆ‚F(t)
i
âˆ‚t=âˆ‚G(tâ€²)(Âµ2)
âˆ‚t+âˆ‚G(tâ€²)(Âµ3)
âˆ‚t+OL
nÏƒ2
1mm 1
=O 
FÏƒ2
1mm 1
,
and for iâˆˆI4,
âˆ‚F(t)
i
âˆ‚t=âˆ‚G(tâ€²)(Âµ3)
âˆ‚t+OL
nÏƒ2
1mm 1
.
Thus, by chain ruleâˆ‚g(t)
i
âˆ‚t=âˆ‚gi
âˆ‚Fiâˆ‚F(t)
i
âˆ‚t, we have
âˆ‚
âˆ‚t 
2X
iâˆˆI1g(tâ€²)
iâˆ’2X
iâˆˆI2g(tâ€²)
iâˆ’X
iâˆˆI3âˆªI4g(tâ€²)
i!
=âˆ’Î˜(Ïƒ2
1mm 1). (8)
This implies that there exists a constant Lsuch that
âˆ‚
âˆ‚t X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
i+ (1 + L) X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i!!
=âˆ’Î˜(Ïƒ2
1mm 1),
which implies that there must exist a time T0.5â‰¤O(1/m)such that for all tâ‰¥T0.5,
âˆ’âˆ‚G(t)(Âµ3)
âˆ‚tâ‰¥(1 +L)âˆ‚G(t)(Âµ1)
âˆ‚t.
Moreover, by Theorem E.26, if CT1is sufficiently large, we have T0.5< T1.
Finally, consider the time whenâˆ‚G(t)(Âµ1)
âˆ‚t+âˆ‚G(t)(Âµ2)
âˆ‚t>âˆ’âˆ‚G(t)(Âµ3)
âˆ‚t. During this time, note that we
have
âˆ‚G(t)(Âµ1)
âˆ‚t,âˆ‚G(t)(Âµ2)
âˆ‚tâ‰¥Î˜(Ïƒ2
1mm 1).
Further, ifâˆ‚G(t)(Âµ1)
âˆ‚t+âˆ‚G(t)(Âµ2)
âˆ‚t=âˆ’âˆ‚G(t)(Âµ3)
âˆ‚t, thenâˆ‚
âˆ‚tg(t)
i=âˆ’Î˜(Ïƒ2
1mm 1)for all iâˆˆI2âˆªI3âˆªI4.
Thus, there must exist a constant Usuch that
âˆ’âˆ‚G(t)(Âµ3)
âˆ‚tâ‰¤(1âˆ’U)âˆ‚G(t)(Âµ1)
âˆ‚t+âˆ‚G(t)(Âµ2)
âˆ‚t
for all tâ‰¤T1.
35Corollary E.20. There exists a small positive constant Csuch that if we define Tâ€²:= min {t:
miniâˆˆI2âˆªI3F(t)
iâ‰¥C}, then Tâ€²â‰¤O(1/m).
Proposition E.21. LetF= max iâˆˆ[n]|F(0)
i|. For tâ‰¤T1, we have
1
nX
iâˆˆI2g(t)
iâˆ’1
nX
iâˆˆI3g(t)
iâ‰¤O(F).
Proof. First of all, by Lipschitzness of g, we have
1
nX
iâˆˆI2g(t)
iâˆ’1
nX
iâˆˆI3g(t)
iâ‰¤ |G(t)(Âµ1)âˆ’G(0)(Âµ1)âˆ’(G(t)(Âµ2)âˆ’G(0)(Âµ2))|+ 2 max
iâˆˆ[n]F(0)
i+o(1).
Without loss of generality, assume G(t)(Âµ1)> G(t)(Âµ2)for all tâ‰¤T1; otherwise, we can break the
interval [0, T1]into sub-intervals by the time points when G(t)(Âµ1)âˆ’G(t)(Âµ2)changes its sign and
then apply the analysis below to each sub-interval. We first derive
âˆ‚G(t)(Âµ1)
âˆ‚tâˆ’âˆ‚G(t)(Âµ2)
âˆ‚t
=m1X
j1=1 
1
nX
i2âˆˆI1âˆªI2g(t)
i2yi2LX
l2=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
p(t,i2)
qâ†l2,kâ†Âµ1+1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ1
âˆ’1
nX
i2âˆˆI1âˆªI3g(t)
i2yi2LX
l2=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
p(t,i2)
qâ†l2,kâ†Âµ2âˆ’1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ2!
=m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E 
1
nX
iâˆˆI1g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Âµ1âˆ’1
nX
iâˆˆI1g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Âµ2!
+m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E 
1
nX
iâˆˆI2g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Âµ1âˆ’1
nX
iâˆˆI3g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Âµ2!
+m1 
1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ1âˆ’1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ2!
=m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E 
1
nX
iâˆˆI3g(t)
iâˆ’1
nX
iâˆˆI2g(t)
i+o(1)!
+m1 
1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ1âˆ’1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ2!
â‰¤m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E 
G(t)(Âµ1)âˆ’G(0)(Âµ1)âˆ’(G(t)(Âµ2)âˆ’G(0)(Âµ2))
+G(0)(Âµ1) +G(0)(Âµ2) +O
max
iâˆˆ[n]|F(0)
i|
+o(1)!
+m1 
1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ1âˆ’1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ2!
.
By Theorem E.14, we have
m1ZT
01
nnX
i1=1g(t)
i1yi1LX
l1=1aj1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ1âˆ’1
nnX
i1=1g(t)
i1yi1LX
l1=1aj1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ2dt
â‰¤TÂ·eO(LÏƒ2
0âˆšmm 1),
36ZT
0
G(0)(Âµ1) +G(0)(Âµ2) +O
max
iâˆˆ[n]|F(0)
i|
+o(1)m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
dt
â‰¤O
G(0)(Âµ1) +G(0)(Âµ2) + max
iâˆˆ[n]|F(0)
i|
TÏƒ2
1mm 1
,
and
expï£«
ï£­ZT
0m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
dtï£¶
ï£¸=O(1).
By GrÃ¶nwallâ€™s inequality, we have
G(T)(Âµ1)âˆ’G(0)(Âµ1)âˆ’(G(T)(Âµ2)âˆ’G(0)(Âµ2))
â‰¤TÂ·eO(LÏƒ2
0âˆšmm 1) +O
G(0)(Âµ1) +G(0)(Âµ2) + max
iâˆˆ[n]|F(0)
i|
TÏƒ2
1mm 1
+ZT
0
tÂ·eO(LÏƒ2
0âˆšm) +O
G(0)(Âµ1) +G(0)(Âµ2) + max
iâˆˆ[n]|F(0)
i|
tÏƒ2
1m
Â·O(1)dt
â‰¤O
G(0)(Âµ1) +G(0)(Âµ2) + max
iâˆˆ[n]|F(0)
i|
.
This implies that
1
nX
iâˆˆI2g(t)
iâˆ’1
nX
iâˆˆI3g(t)
iâ‰¤O
G(0)(Âµ1) +G(0)(Âµ2) + max
iâˆˆ[n]|F(0)
i|
.
Thus, if the initialization scale is sufficiently small,1
nP
iâˆˆI2g(t)
iand1
nP
iâˆˆI3g(t)
iare only differed
by a small constant.
E.7 Small Score Movement in Phase 1
Proposition E.22. Conditioned on the success of Lemma D.1 and Lemma D.3, with probability at
least1âˆ’Î´over the randomness of a, for all iâˆˆ[n]andÂµ, Î½âˆˆX(i), we have
m1X
j=1ajâˆ¥k(0)(Âµ)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)â‰¤O 
Ïƒ2
0mÏƒ1Ïƒ0r
mm 1logm1d
Î´r
lognd
Î´!
,
m1X
j=1ajâˆ¥q(0)(Âµ)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)â‰¤O 
Ïƒ2
0mÏƒ1Ïƒ0r
mm 1logm1d
Î´r
lognd
Î´!
and for all l, lâ€²âˆˆ[L]withK(0,i)
lÌ¸=k(0)(Î½)andq(0,i)
lÌ¸=Q(0)(Î½), we have
m1X
j=1ajÎ½âŠ¤W(0)âŠ¤
KK(0,i)
lV(0,i)âŠ¤
lâ€²w(0)
jâ‰¤eO(Ïƒ2
0âˆšmÏƒ0Ïƒ1âˆšmm 1),
m1X
j=1ajÎ½âŠ¤W(0)âŠ¤
Qq(0,i)
lV(0,i)âŠ¤
lâ€²w(0)
jâ‰¤eO(Ïƒ2
0âˆšmÏƒ0Ïƒ1âˆšmm 1).
Proof. Fixiâˆˆ[n]andÂµ, Î½âˆˆX(i). Consider the randomness of a. By Lemma D.1, Corollary D.2
and Lemma D.3, ajâˆ¥k(0)(Âµ)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)is a sub-Gaussian random variable with variance proxy
O((Ïƒ2
0mÏƒ1Ïƒ0âˆšmp
log(dm1/Î´))2). Then the following inequality holds.
m1X
j=1ajâˆ¥k(0)(Âµ)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)â‰¤O 
Ïƒ2
0mÏƒ1Ïƒ0r
mm 1logm1d
Î´r
log2
Î´!
.
37Finally, take a union bound over iâˆˆ[n], Âµ, Î½âˆˆ {Âµi}d
i=1. The analysis for the second term is similar.
Next, note that ajÎ½âŠ¤W(0)âŠ¤
KK(0,i)
lV(0,i)âŠ¤
lâ€²w(0)
jis a sub-Gaussian random variable with variance proxy
eO((Ïƒ2
0âˆšmÏƒ0Ïƒ1âˆšm)2). Thus,m1X
j=1ajÎ½âŠ¤W(0)âŠ¤
KK(0,i)
lV(0,i)âŠ¤
lâ€²w(0)
jâ‰¤eO(Ïƒ2
0âˆšmÏƒ0Ïƒ1âˆšmm 1).
Lemma E.23 (Score change) .For all tâ‰¤T1, for all Î½, Âµâˆˆ {Âµi}d
i=1, we have
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ
âˆ‚tâ‰¤1âˆšm
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
neO1
L+1âˆšm
and thus,
Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµâˆ’Î½âŠ¤W(0)âŠ¤
KW(0)
QÂµâ‰¤t1âˆšm
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
neO1
L+1âˆšm
.
Proof. First of all, by Lemma C.4, we expand the per step gradient descent update as follows:
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ
âˆ‚t
=1
nâˆšmX
i:Âµ,Î½âˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2
v(t)âŠ¤(Î½)w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
qâ†Âµ,kâ†Î½
| {z }
(1)
+1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajLX
l=1Î½âŠ¤W(t)âŠ¤
KK(t,i)
l
V(t,i)âŠ¤
lw(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
qâ†Âµ,kâ†lI(K(t,i)
lÌ¸=k(t)(Î½))
| {z }
(2)
+1
nâˆšmX
i:Î½,ÂµâˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥q(t)(Âµ)âˆ¥2
2p(t,i)
qâ†Âµ,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
| {z }
(3)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Qq(t,i)
lp(t,i)
qâ†l,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
I(q(t,i)
lÌ¸=q(t)(Âµ))
| {z }
(4)
Analysis of (1): By triangle inequality, we have
|(1)| â‰¤1
nâˆšmX
i:Âµ,Î½âˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2v(t)âŠ¤(Î½)w(t)
jp(t,i)
qâ†Âµ,kâ†Î½
| {z }
(a)
+1
nâˆšmX
i:Âµ,Î½âˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)p(t,i)
qâ†Âµ,kâ†Î½
| {z }
(b).
To analyze (a), since (a+Îµ1)(b+Îµ2) =ab+aÎµ2+bÎµ1+Îµ1Îµ2, we havem1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jv(t)(Î½)p(t,i)
qâ†Âµ,kâ†Î½âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)p(0,i)
qâ†Âµ,kâ†Î½
38â‰¤m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jv(t)(Î½)âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)p(t,i)
qâ†Âµ,kâ†Î½
+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)Â·p(t,i)
qâ†Âµ,kâ†Î½âˆ’p(0,i)
qâ†Âµ,kâ†Î½.
Further, by Lemma D.1, Lemma D.3, Definition E.1 and Definition E.2, we havem1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jv(t)(Î½)âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)
â‰¤max
Î½,jâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jv(t)(Î½)âˆ’ âˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)
â‰¤m1
RKeO(Ïƒ0Ïƒ1âˆšm) +ReO(Ïƒ2
0m) +RKR
. (9)
Combining with Proposition E.22, this impliesm1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jv(t)(Î½)p(t,i)
qâ†Âµ,kâ†Î½âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)p(0,i)
qâ†Âµ,kâ†Î½
â‰¤m1Â·max
Î½,jâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jv(t)(Î½)âˆ’ âˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)p(t,i)
qâ†Âµ,kâ†Î½
+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)Â·p(t,i)
qâ†Âµ,kâ†Î½âˆ’p(0,i)
qâ†Âµ,kâ†Î½
â‰¤m1
RKeO(Ïƒ0Ïƒ1âˆšm) +ReO(Ïƒ2
0m) +RKR2
L+RP
+eO 
RPÏƒ2
0mÏƒ1Ïƒ0âˆšmm 1
.
Thus,
|(a)|=m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jv(t)(Î½)p(t,i)
qâ†Âµ,kâ†Î½
â‰¤m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jv(t)(Î½)p(t,i)
qâ†Âµ,kâ†Î½âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)p(0,i)
qâ†Âµ,kâ†Î½
+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jv(0)(Î½)p(0,i)
qâ†Âµ,kâ†Î½
â‰¤m1
RKeO(Ïƒ0Ïƒ1âˆšm) +ReO(Ïƒ2
0m) +RKR2
L+RP
+eO 
RPÏƒ2
0mÏƒ1Ïƒ0âˆšmm 1
+eO
Ïƒ2
0mÏƒ1Ïƒ0âˆšmm 11
L
.
On the other hand, to analyze (b), we have
m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)p(t,i)
qâ†Âµ,kâ†Î½âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)p(0,i)
qâ†Âµ,kâ†Î½
â‰¤m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)Â·p(t,i)
qâ†Âµ,kâ†Î½
+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)Â·p(t,i)
qâ†Âµ,kâ†Î½âˆ’p(0,i)
qâ†Âµ,kâ†Î½. (10)
39Note that
m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)
=LX
l=1m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)
lp(t,i)
l(i,Âµ),lâˆ’LX
l=1m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)
lp(0,i)
l(i,Âµ),l
â‰¤LX
l=1m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)
lp(t,i)
l(i,Âµ),lâˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)
lp(0,i)
l(i,Âµ),l
â‰¤LX
l=1m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)
lâˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)
lp(t,i)
l(i,Âµ),l
+LX
l=1m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)
lÂ·p(t,i)
l(i,Âµ),lâˆ’p(0,i)
l(i,Âµ),l
â‰¤max
lâˆˆ[L]m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)
lâˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)
l
+LRPmax
lâˆˆ[L]m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)
l, (11)
which implies
|(b)|
=m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)p(t,i)
qâ†Âµ,kâ†Î½
â‰¤m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)p(t,i)
qâ†Âµ,kâ†Î½âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)p(0,i)
qâ†Âµ,kâ†Î½
+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)p(0,i)
qâ†Âµ,kâ†Î½
(i)
â‰¤m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)âˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)Â·p(t,i)
qâ†Âµ,kâ†Î½
+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)Â·p(t,i)
qâ†Âµ,kâ†Î½âˆ’p(0,i)
qâ†Âµ,kâ†Î½
+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)p(0,i)
qâ†Âµ,kâ†Î½
(ii)
â‰¤ 
max
lâˆˆ[L]m1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2w(t)âŠ¤
jV(t,i)
lâˆ’m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)
l
+LRPmax
lâˆˆ[L]m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)
l!
Â·p(t,i)
qâ†Âµ,kâ†Î½
40+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)Â·p(t,i)
qâ†Âµ,kâ†Î½âˆ’p(0,i)
qâ†Âµ,kâ†Î½
+m1X
j=1ajâˆ¥k(0)(Î½)âˆ¥2
2w(0)âŠ¤
jV(0,i)p(0,i)
l(i,Âµ)p(0,i)
qâ†Âµ,kâ†Î½
(iii)
â‰¤ 
m1
RKeO(Ïƒ0Ïƒ1âˆšm) +ReO(Ïƒ2
0m) +RKR
+LRPeO(Ïƒ2
0mÏƒ0Ïƒ1âˆšmm 1)!
Â·1
L+RP
+eO
Ïƒ2
0mÏƒ0Ïƒ1âˆšmm 11
L+RP
where (i)follows from Equation (10), (ii)follows from Equation (11) and (iii)follows from
Equation (9) and Proposition E.22. Combining the upper bound for both (a)and(b), we obtain
|(1)| â‰¤1âˆšm
i:Âµ, Î½âˆˆX(i)	
neO  
m1
RKeO(Ïƒ0Ïƒ1âˆšm) +ReO(Ïƒ2
0m) +RKR
+LRPeO(Ïƒ2
0mÏƒ0Ïƒ1âˆšmm 1)!
Â·1
L+RP
+Ïƒ2
0mÏƒ0Ïƒ1âˆšmm 11
L+RP!
=1âˆšm
i:Âµ, Î½âˆˆX(i)	
neO(1/L).
Analysis of (2):(2)can be analyzed similarly as (1)withâˆ¥k(0)(Î½)âˆ¥2
2replaced by Î½âŠ¤W(t)
KK(t,i)
l.
Thus, we only need to replace Ïƒ2
0mwithÏƒ2
0âˆšmand then take a sum over l. We have
|(2)| â‰¤1âˆšm
i:ÂµâˆˆX(i)	
neO  
m1
RKeO(Ïƒ0Ïƒ1âˆšm) +ReO(Ïƒ2
0âˆšm) +RKR
+LRPeO(Ïƒ2
0âˆšmÏƒ0Ïƒ1âˆšmm 1)!
Â·(1 +LRP) +Ïƒ2
0âˆšmÏƒ0Ïƒ1âˆšmm 1(1 +LRP)!
=1âˆšm
i:ÂµâˆˆX(i)	
neO(1/âˆšm).
Analysis of (3):(3)can be analyzed similarly to (1), and we obtain
|(3)| â‰¤1âˆšm
i:Âµ, Î½âˆˆX(i)	
neO(1/L).
Analysis of (4):(4)can be analyzed similarly to (2), and we obtain
|(4)| â‰¤1âˆšm
i:Î½âˆˆX(i)	
neO(1/âˆšm).
Finally, combining the bounds on (1)âˆ’(4), we have
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ
âˆ‚tâ‰¤1âˆšm
i:Âµ, Î½âˆˆX(i)	
neO(1/L) +1âˆšm
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
neO(1/âˆšm)
â‰¤1âˆšm
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
neO(1/L+ 1/âˆšm).
Corollary E.24 (Softmax change) .Fortâ‰¤T1, we have the following:
41â€¢if both X(i)
l1, X(i)
l2âˆˆ R, then
âˆ‚p(t,i)
l1,l2
âˆ‚tâ‰¤eO1
L(L2+n)âˆšm
,
â€¢otherwise,
âˆ‚p(t,i)
l1,l2
âˆ‚tâ‰¤eO1
L2âˆšm
.
Thus,
â€¢if both X(i)
l1, X(i)
l2âˆˆ R, then
p(t,i)
l1,l2âˆ’p(0,i)
l1,l2â‰¤eO1
L+1
n1
Lm21
L+1âˆšm
,
â€¢otherwise,
p(t,i)
l1,l2âˆ’p(0,i)
l1,l2â‰¤eO1
Lm21
L+1âˆšm
.
Proof. Consider fixed i, l1, l2. By Lemma G.2, we have
âˆ‚p(t,i)
l1,l2
âˆ‚tâ‰¤p(t,i)
l1,l2âˆ‚s(t,i)
l1,l2
âˆ‚t+p(t,i)
l1,l2p(t,i)âŠ¤
l1âˆ‚s(t,i)
l1
âˆ‚t.
By Lemma E.23, we have the following cases:
â€¢ if both X(i)
l1, X(i)
l2âˆˆ R, then
âˆ‚s(t,i)
l1,l2
âˆ‚tâ‰¤eO1
nm1
L+1âˆšm
;
â€¢ otherwise,
âˆ‚s(t,i)
l1,l2
âˆ‚tâ‰¤eO1
m1
L+1âˆšm
.
Next, during Phase 1, we have p(t,i)
l1,l2â‰¤1
L+1
Lm+RP. Therefore,
â€¢ ifX(i)
l1âˆˆ R, then
p(t,i)âŠ¤
l1âˆ‚s(t,i)
l1
âˆ‚tâ‰¤eO1
L+1
n1
m1
L+1âˆšm
;
â€¢ otherwise,
p(t,i)âŠ¤
l1âˆ‚s(t,i)
l1
âˆ‚tâ‰¤eO1
m1
L+1âˆšm
.
Thus,
â€¢ if both X(i)
l1, X(i)
l2âˆˆ R, then
âˆ‚p(t,i)
l1,l2
âˆ‚tâ‰¤eO1
L+1
n1
Lm1
L+1âˆšm
;
42â€¢ otherwise,âˆ‚p(t,i)
l1,l2
âˆ‚tâ‰¤eO1
Lm1
L+1âˆšm
.
This implies that
â€¢ if both X(i)
l1, X(i)
l2âˆˆ R, then
p(t,i)
l1,l2âˆ’p(0,i)
l1,l2â‰¤eO1
L+1
n1
Lm21
L+1âˆšm
;
â€¢ otherwise,
p(t,i)
l1,l2âˆ’p(0,i)
l1,l2â‰¤eO1
Lm21
L+1âˆšm
.
Lemma E.25 (K, Q self-correlation change) .Fortâ‰¤T1, forÂµ, Î½âˆˆ {Âµi}d
i=1, we have
ÂµâŠ¤W(t)âŠ¤
KW(t)
KÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
KW(0)
KÎ½â‰¤t1âˆšm
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
neO1âˆšm
,
ÂµâŠ¤W(t)âŠ¤
QW(t)
QÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
QW(0)
QÎ½â‰¤t1âˆšm
i:ÂµâˆˆX(i)	+
i:Î½âˆˆX(i)	
neO1âˆšm
.
Proof. By Lemma C.4, we only need to replace eO(Ïƒ2
0m)byeO(Ïƒ2
0âˆšm)in the proof of Lemma E.23.
Thus, we omit the proof here.
E.8 All Variables are within Range in Definition of Phase 1
Finally, we prove that at the end of Phase 1, all the variables in Definition E.2 stay in the range.
Theorem E.26. Fortâ‰¤CT1/(Ïƒ2
1mm 1)(where the constant CT1is from the definition of T1in
Definition E.2), all of the following hold:
1.maxjâˆˆ[m],Âµâˆˆ{Âµi}3
i=1w(t)
jW(t)
VÂµâˆ’w(0)
jW(0)
VÂµâ‰¤R, where R=O(1/m1);
2.maxjâˆˆ[m],Âµ/âˆˆ{Âµi}3
i=1w(t)
jW(t)
VÂµâˆ’w(0)
jW(0)
VÂµâ‰¤O(R/n+R/âˆšm);
3.maxÂµ,Î½âˆˆ{Âµi}d
i=1ÂµâŠ¤W(t)âŠ¤
QW(t)
KÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
QW(0)
KÎ½â‰¤RS, where RSâ‰¤O(1/mâˆšm);
4.maxÂµ,Î½âˆˆ{Âµi}d
i=1ÂµâŠ¤W(t)âŠ¤
QW(t)
QÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
QW(0)
QÎ½â‰¤RQ;
5.maxÂµ,Î½âˆˆ{Âµi}d
i=1ÂµâŠ¤W(t)âŠ¤
KW(t)
KÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
KW(0)
KÎ½â‰¤RK.
Thus, T1=CT1/(Ïƒ2
1mm 1).
Proof. The first two results are proved by Theorem E.14, Theorem E.15, Lemma E.17. The third
result is proved by Lemma E.23, The fourth and fifth results are proved by Lemma E.25.
Theorem E.27 (End of Phase 1) .Att=T1, we have yiF(T1)
i= Î˜(1) for all iâˆˆ[n], and
G(T1)(Âµ1) = Î˜(1) , G(T1)(Âµ2) = Î˜(1) ,âˆ’G(T1)(Âµ3) = Î˜(1) ,
âˆ€Âµâˆˆ R:G(T1)(Âµ) =eO(Ïƒ0Ïƒ1âˆšmm 1).
Further,
m1X
j1=1m1X
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2E
= Î˜( Ïƒ2
1mm 1).
43Proof. By Theorem E.26, we have yiF(T1)
i=O(1)and
G(T1)(Âµ1) =O(1), G(T1)(Âµ2) =O(1),âˆ’G(T1)(Âµ3) =O(1).
Further, by Theorem E.14 and Theorem E.19, we have yiF(T1)
iâ‰¥â„¦(1) foriâˆˆI1and
G(T1)(Âµ1)â‰¥â„¦(1), G(T1)(Âµ2)â‰¥â„¦(1).
Finally, by Theorem E.26, we have that T1=CT1/m. And note that if the constant CT1in
Definition E.2 is sufficiently large, then by Corollary E.20, we have Tâ€²â‰¤T1. Thus, we have
yiF(T1)
iâ‰¥â„¦(1) foriâˆˆI2âˆªI3âˆªI4andâˆ’G(T1)(Âµ3)â‰¥â„¦(1) .
By Lemma D.7 and Theorem E.15, we have
âˆ€Âµâˆˆ R:G(T1)(Âµ) =eO(Ïƒ0Ïƒ1âˆšmm 1).
Finally, by Lemma D.3, Proposition E.5 and Proposition E.12, we have
m1X
j1=1m1X
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2E
= Î˜( Ïƒ2
1mm 1).
Theorem E.28 (Phase 1, formal restatement of Theorem 3.1) .With probability at least 1âˆ’Î´over
the randomness of weight initialization, there exists a time T1=eO(1/m)such that
â€¢G(T1)(Âµ1)â‰¥â„¦(1), G(T1)(Âµ2)â‰¥â„¦(1), G(T1)(Âµ3)â‰¤ âˆ’â„¦(1) .
â€¢All the training samples are correctly classified: yiF(T1)
i= â„¦(1) for all iâˆˆ[n].
â€¢Fortâˆˆ[0, T1],
D
w(t)
j1, w(t)
j2E
âˆ’D
w(0)
j1, w(0)
j2Eâ‰¤eO1
m
D
v(t)(Âµ), v(t)(Î½)E
âˆ’D
v(0)(Âµ), v(0)(Î½)Eâ‰¤eO1
m
Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµâˆ’Î½âŠ¤W(0)âŠ¤
KW(0)
QÂµâ‰¤eO1
m3/21
L+1âˆšm
ÂµâŠ¤W(t)âŠ¤
KW(t)
KÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
KW(0)
KÎ½â‰¤eO1
m2
ÂµâŠ¤W(t)âŠ¤
QW(t)
QÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
QW(0)
QÎ½â‰¤eO1
m2
â€¢The training loss satisfies bL(T1)= Î˜(1) .
Proof. The first two results are proved in Theorem E.27. The third result is proved by Lemma E.9,
Proposition E.12, Lemma E.23, and Lemma E.25. The result on the training loss is a direct conse-
quence of Definition E.2.
F Training Dynamics: Phase 2
The idea of the proof is to first define conditions for Phase 2, which guarantees that the small training
loss can be achieved. Then we will show that those conditions can be satisfied starting from the end
of Phase 1 and up to at least â„¦(poly(m))time, which will serve as the end of Phase 2.
Definition F.1. We define Phase 2 of the training to be tâˆˆ[T1, T2]such that
44â€¢The change of K, Q self-correlation is small:
max
Âµ,Î½ÂµâŠ¤W(t)âŠ¤
KW(t)
KÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
KW(0)
KÎ½=eO(Ïƒ2
0âˆšm)
max
Âµ,Î½ÂµâŠ¤W(t)âŠ¤
QW(t)
QÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
QW(0)
QÎ½=eO(Ïƒ2
0âˆšm)
â€¢The change of softmax probability satisfies:
max
l1,l2âˆˆ[L], iâˆˆ[n]p(t,i)
l1,l2âˆ’p(0,i)
l1,l2< O(1/L2)
â€¢The sum of neuron correlation satisfies
m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
â‰¤O(Ïƒ2
1mm 1).
â€¢The gradient of W, W Vsatisfies
maxÂµâˆˆ{Âµi}d
i=1Pm1
j=1ajâˆ‚w(t)
j
âˆ‚tW(t)
VÂµ
Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2Eâ‰¤o(1/L)1
nX
iâˆˆ[n]g(t)
i
max iâˆˆ[n]PL
l1=1PL
l2=1G(t)(X(i)
l2)âˆ‚p(t,i)
l1,l2
âˆ‚t
Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2E â‰¤o(1)1
nX
iâˆˆ[n]g(t)
i
â€¢The gradientsP
iâˆˆIg(t)
iforIâˆˆ {I1, I2, I3, I4}satisfies
X
iâˆˆI4giâ‰¤min X
iâˆˆI2g(t)
i,X
iâˆˆI3g(t)
i!
â‰¤max X
iâˆˆI2g(t)
i,X
iâˆˆI3g(t)
i!
â‰¤X
iâˆˆI1g(t)
iâ‰¤X
iâˆˆI2âˆªI3âˆªI4g(t)
i
and
1
2â‰¤P
iâˆˆI2g(t)
iP
iâˆˆI3g(t)
iâ‰¤2.
â€¢yiF(t)
i> C for all iâˆˆ[n]for some fixed constant C.
â€¢|G(t)(Âµ)| â‰¤O(logm)forÂµâˆˆ {Âµi}3
i=1.
â€¢PL
l1=1P
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(t)(X(i)
l2)p(t,i)
qâ†l1,kâ†l2â‰¤O(1).
â€¢T2â‰¤O(poly(m)).
Corollary F.2. Fortâˆˆ[T1, T2], ifi, jâˆˆIwhere Iâˆˆ {I1, I2, I3, I4}, then
max
i,jâˆˆIg(t)
i
g(t)
jâ‰¤O(1).
Proof. TakeI=I1and the proof is similar for the remaining cases. For fixed i, jâˆˆI1, we have
g(t)
i
g(t)
j=1 + exp( yjF(t)
j)
1 + exp( yiF(t)
i)â‰¤2exp(yjF(t)
j)
exp(yiF(t)
i),
where the inequality is due to yiF(t)
iâ‰¥Cin Definition F.1. Now we consider
exp(yjF(t)
j)
exp(yiF(t)
i)
45=exp(yjPL
l1=1PL
l2=1G(t)(X(j)
l2)p(t,j)
qâ†l1,kâ†l2)
exp(yiPL
l1=1PL
l2=1G(t)(X(i)
l2)p(t,i)
qâ†l1,kâ†l2)
= expï£«
ï£­ï£«
ï£­LX
l1=1X
Âµâˆˆ{Âµk}3
k=1G(t)(Âµ)p(t,j)
qâ†l1,kâ†Âµï£¶
ï£¸âˆ’ï£«
ï£­LX
l1=1X
Âµâˆˆ{Âµk}3
k=1G(t)(Âµ)p(t,i)
qâ†l1,kâ†Âµï£¶
ï£¸ï£¶
ï£¸
| {z }
(1)
Â·expï£«
ï£¬ï£­ï£«
ï£¬ï£­LX
l1=1X
l2:X(j)
l2âˆˆ{Âµk}d
k=4G(t)(X(j)
l2)p(t,j)
qâ†l1,kâ†l2ï£¶
ï£·ï£¸âˆ’ï£«
ï£¬ï£­LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(t)(X(i)
l2)p(t,i)
qâ†l1,kâ†l2ï£¶
ï£·ï£¸ï£¶
ï£·ï£¸
| {z }
(2).
By Definition F.1, it is easy to see that |(2)| â‰¤O(1). For (1), we have
ï£«
ï£­LX
l1=1X
Âµâˆˆ{Âµk}3
k=1G(t)(Âµ)p(t,j)
qâ†l1,kâ†Âµï£¶
ï£¸âˆ’ï£«
ï£­LX
l1=1X
Âµâˆˆ{Âµk}3
k=1G(t)(Âµ)p(t,i)
qâ†l1,kâ†Âµï£¶
ï£¸
â‰¤X
Âµâˆˆ{Âµk}3
k=1G(t)(Âµ)(1Â±o(1))âˆ’X
Âµâˆˆ{Âµk}3
k=1G(t)(Âµ)(1Â±o(1))â‰¤O(1).
Thus, we have
exp(yjF(t)
j)
exp(yiF(t)
i)â‰¤O(1)
fortâˆˆ[T1, T2].
Lemma F.3. Phase 2 in Definition F .1 is well-defined.
Proof. We need to show that the definition is valid at t=T1with conditions satisfied with strict
inequality. Then since everything changes continuously, there naturally exists a T2> T1such that
Definition F.1 is well-defined.
First of all, by Lemma E.25, for Âµ, Î½âˆˆ {Âµi}d
i=1, we have
max
Âµ,Î½ÂµâŠ¤W(T1)âŠ¤
K W(T1)
KÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
KW(0)
KÎ½=eO(Ïƒ2
0âˆšm),
max
Âµ,Î½ÂµâŠ¤W(T1)âŠ¤
Q W(T1)
QÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
QW(0)
QÎ½=eO(Ïƒ2
0âˆšm).
Next, by Proposition E.12, Proposition E.5 and Lemma D.3, we have
m1X
j1=1m1X
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2E
= Î˜( Ïƒ2
1mm 1).
Recall that1
nPn
i=1g(T1)
i= Î˜(1) . On the other hand, by Corollary E.10, Lemma D.3, we have
max
Âµâˆˆ{Âµi}d
i=1m1X
j=1ajâˆ‚w(T1)
j
âˆ‚tW(T1)
VÂµ=O(Ïƒ2
0mm 1)
=â‡’maxÂµâˆˆ{Âµi}d
i=1Pm1
j=1ajâˆ‚w(T1)
j
âˆ‚tW(T1)
VÂµ
Pm1
j1=1Pm1
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2Eâ‰¤OÏƒ2
0
Ïƒ2
1
=eOm1
Lm
.
46Also, by Corollary E.24, we have
max
iâˆˆ[n]LX
l1=1LX
l2=1G(T1)(X(i)
l2)âˆ‚p(T1,i)
l1,l2
âˆ‚t=eO1âˆšm
=â‡’max iâˆˆ[n]PL
l1=1PL
l2=1G(T1)(X(i)
l2)âˆ‚p(T1,i)
l1,l2
âˆ‚t
Pm1
j1=1Pm1
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2E â‰¤eO1
m3/2
â‰¤o(1)X
iâˆˆ[n]g(T1)
i.
Further, by Corollary E.24, we have
max
l1,l2âˆˆ[L], iâˆˆ[n]p(T1,i)
l1,l2âˆ’p(0,i)
l1,l2< O(1/L2).
Now, by Proposition E.21, if Fis small enough (which can be achieved by making the initialization
scale small enough), then
1
2<P
iâˆˆI2g(T1)
iP
iâˆˆI3g(T1)
i<2.
Lastly, by Theorem E.27, we have yiF(T1)
iâ‰¥â„¦(1) . And it is straightforward to see that |G(T1)(Âµ)| â‰¤
O(logm)forÂµâˆˆ {Âµi}3
i=1.
Finally, we provePL
l1=1P
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(T1)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2â‰¤O(1). A simple corollary
from Lemma D.7 and Lemma D.8 is thatLX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(0)(X(i)
l2)p(0,i)
qâ†l1,kâ†l2â‰¤O(1).
Next, we have
LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(T1)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2âˆ’LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(0)(X(i)
l2)p(0,i)
qâ†l1,kâ†l2
â‰¤LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4(G(T1)(X(i)
l2)âˆ’G(0)(X(i)
l2))p(0,i)
qâ†l1,kâ†l2
+LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(0)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2âˆ’p(0,i)
qâ†l1,kâ†l2
+LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(T1)(X(i)
l2)âˆ’G(0)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2âˆ’p(0,i)
qâ†l1,kâ†l2
â‰¤O(1)
which proves that
LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(T1)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2â‰¤O(1).
In Phase 2, we will analyze the dynamical system in a different way since all the variables now might
change dramatically from their values at initialization.
47Lemma F.4. Fortâˆˆ[T1, T2], we have
âˆ‚
âˆ‚tm1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
=2m1
nnX
i=1g(t)
iyiF(t)
i>0
and thus,
m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
= â„¦(Ïƒ2
1mm 1).
Proof. By Lemma C.2, we obtain
âˆ‚
âˆ‚tm1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
=m1X
j1=1m1X
j2=1 
1
nnX
i=1g(t)
iyiLX
l1=1aj1w(t)âŠ¤
j1V(t,i)p(t,i)
l1+1
nnX
i=1g(t)
iyiLX
l2=1aj2w(t)âŠ¤
j2V(t,i)p(t,i)
l2!
=2m1
nnX
i=1g(t)
iyiF(t)
i.
Then, note that the final term is positive since by Definition F.1, we have yiF(t)
i>0for all iâˆˆ[n].
Finally, by Theorem E.27, we have for all tâˆˆ[T1, T2],
m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
â‰¥â„¦(Ïƒ2
1mm 1).
F.1 Automatic Balancing of Gradients
Lemma F.5 (Same as Lemma 4.4) .Fortâˆˆ[T1, T2], there exists a small constant Câ‰ª1such that
P
iâˆˆI2g(t)
iâˆ’P
iâˆˆI3g(t)
i
min(P
iâˆˆI2g(t)
i,P
iâˆˆI3g(t)
i)â‰¤C.
Proof. Without loss of generality, assumeP
iâˆˆI2g(t)
i>P
iâˆˆI3g(t)
i. Then, we have
P
iâˆˆI2g(t)
iâˆ’P
iâˆˆI3g(t)
i
min(P
iâˆˆI2g(t)
i,P
iâˆˆI3g(t)
i)=P
iâˆˆI2g(t)
iâˆ’P
iâˆˆI3g(t)
iP
iâˆˆI3g(t)
i=P
iâˆˆI2g(t)
iP
iâˆˆI3g(t)
iâˆ’1.
Now by the quotient rule, we haveâˆ‚
âˆ‚tP
iâˆˆI2g(t)
iP
iâˆˆI3g(t)
i
â‰¤0if and only if
âˆ‚
âˆ‚t X
iâˆˆI2g(t)
i! X
iâˆˆI3g(t)
i!
âˆ’ X
iâˆˆI2g(t)
i!
âˆ‚
âˆ‚t X
iâˆˆI3g(t)
i!
â‰¤0
â‡” X
iâˆˆI2gâ€²(yiF(t)
i)âˆ‚yiF(t)
i
âˆ‚t! X
iâˆˆI3g(t)
i!
âˆ’ X
iâˆˆI2g(t)
i! X
iâˆˆI3gâ€²(yiF(t)
i)âˆ‚yiF(t)
i
âˆ‚t!
â‰¤0
â‡” X
iâˆˆI2g(t)
i! X
iâˆˆI3g(t)
i! 
1
P
iâˆˆI2g(t)
iX
iâˆˆI2gâ€²(yiF(t)
i)âˆ‚yiF(t)
i
âˆ‚tâˆ’1
P
iâˆˆI3g(t)
iX
iâˆˆI3gâ€²(yiF(t)
i)âˆ‚yiF(t)
i
âˆ‚t!
â‰¤0
â‡” 
1
P
iâˆˆI2g(t)
iX
iâˆˆI2gâ€²(yiF(t)
i)âˆ‚yiF(t)
i
âˆ‚tâˆ’1
P
iâˆˆI3g(t)
iX
iâˆˆI3gâ€²(yiF(t)
i)âˆ‚yiF(t)
i
âˆ‚t!
â‰¤0
48â‡” 
1
P
iâˆˆI2g(t)
iX
iâˆˆI2âˆ’1
(1 + exp( yiF(t)
i))(1 + exp( âˆ’yiF(t)
i))âˆ‚yiF(t)
i
âˆ‚t!
âˆ’ 
1
P
iâˆˆI3g(t)
iX
iâˆˆI3âˆ’1
(1 + exp( yiF(t)
i))(1 + exp( âˆ’yiF(t)
i))âˆ‚yiF(t)
i
âˆ‚t!
â‰¤0
â‡” 
1
P
iâˆˆI3g(t)
iX
iâˆˆI31
(1 + exp( yiF(t)
i))(1 + exp( âˆ’yiF(t)
i))âˆ‚yiF(t)
i
âˆ‚t!
â‰¤ 
1
P
iâˆˆI2g(t)
iX
iâˆˆI21
(1 + exp( yiF(t)
i))(1 + exp( âˆ’yiF(t)
i))âˆ‚yiF(t)
i
âˆ‚t!
. (12)
Note that
P
iâˆˆIg(t)
i
1 + min iâˆˆIexp(âˆ’yiF(t)
i)â‰¥X
iâˆˆI1
(1 + exp( yiF(t)
i))(1 + exp( âˆ’yiF(t)
i))â‰¥P
iâˆˆIg(t)
i
1 + max iâˆˆIexp(âˆ’yiF(t)
i).
By Definition F.1, we have that for iâ€²âˆˆI2,
âˆ‚yiâ€²F(t)
iâ€²
âˆ‚t
=yiâ€²LX
l1=1m1X
j=1LX
l2=1ï£«
ï£­âˆ‚ajw(t)
jW(t)
VX(iâ€²)
l2
âˆ‚tp(t,iâ€²)
l1,l2+ajw(t)
jW(t)
VX(iâ€²)
l2âˆ‚p(t,iâ€²)
l1,l2
âˆ‚tï£¶
ï£¸
=yiâ€²LX
l2=1âˆ‚G(t)(X(iâ€²)
l2)
âˆ‚t(1 +o(1)) +LX
l1=1LX
l2=1yiâ€²G(t)(X(iâ€²)
l2)âˆ‚p(t,iâ€²)
l1,l2
âˆ‚t
=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸.
Similarly, for iâ€²âˆˆI3, we have
âˆ‚yiâ€²F(t)
iâ€²
âˆ‚t
=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI3g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸.
Now, we analyze Equation (12). Note that for tâˆˆ[T1, T2], ifP
iâˆˆI2g(t)
iis sufficiently larger
thanP
iâˆˆI3g(t)
i(i.e.,P
iâˆˆI2g(t)
i/P
iâˆˆI3g(t)
iis bigger than some threshold), thenâˆ‚G(t)(Âµ1)
âˆ‚t<
âˆ‚G(t)(Âµ2)
âˆ‚tandminiâˆˆI2âˆ‚yiF(t)
i
âˆ‚t>max iâˆˆI3âˆ‚yiF(t)
i
âˆ‚t. Thus, the ratio will decrease. Similarly,
ifP
iâˆˆI2g(t)
i/P
iâˆˆI3g(t)
iis too small, the ratio will increase. Next, we compute a bound on
P
iâˆˆI2g(t)
i/P
iâˆˆI3g(t)
iso thatâˆ‚
âˆ‚tP
iâˆˆI2g(t)
iP
iâˆˆI3g(t)
i
= 0. Substitutingâˆ‚yiF(t)
i
âˆ‚tin Equation (12), we
have 
1
P
iâˆˆI3g(t)
iX
iâˆˆI31
(1 + exp( yiF(t)
i))(1 + exp( âˆ’yiF(t)
i))!
Â·ï£«
ï£­âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2Eï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
iÂ±o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸ï£¶
ï£¸
= 
1
P
iâˆˆI2g(t)
iX
iâˆˆI21
(1 + exp( yiF(t)
i))(1 + exp( âˆ’yiF(t)
i))!
49Â·ï£«
ï£­âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2Eï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI3g(t)
iÂ±o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸ï£¶
ï£¸
â‡’1 + min iâˆˆI2exp(âˆ’yiF(t)
i)
1 + max iâˆˆI3exp(âˆ’yiF(t)
i)ï£«
ï£­âˆ’X
iâˆˆI1g(t)
i+X
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’X
iâˆˆI1g(t)
i+X
iâˆˆI2g(t)
iÂ±o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸
=ï£«
ï£­âˆ’X
iâˆˆI1g(t)
i+X
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’X
iâˆˆI1g(t)
i+X
iâˆˆI3g(t)
iÂ±o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸
â‡’P
iâˆˆI2g(t)
iP
iâˆˆI3g(t)
i= 1 + 1P
iâˆˆI3g(t)
iP
iâˆˆI31
(1+exp( yiF(t)
i))(1+exp( âˆ’yiF(t)
i))
1P
iâˆˆI2g(t)
iP
iâˆˆI21
(1+exp( yiF(t)
i))(1+exp( âˆ’yiF(t)
i))
Â·âˆ’P
iâˆˆI1g(t)
i+P
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’P
iâˆˆI1g(t)
i+P
iâˆˆI2g(t)
iÂ±o(1)P
iâˆˆ[n]g(t)
iP
iâˆˆI3g(t)
i!
.
Since
1
P
iâˆˆIg(t)
iX
iâˆˆI1
(1 + exp( yiF(t)
i))(1 + exp( âˆ’yiF(t)
i))
âˆˆ"
1
1 + max iâˆˆIexp(âˆ’yiF(t)
i),1
1 + min iâˆˆIexp(âˆ’yiF(t)
i)#
,
we have
1P
iâˆˆI3g(t)
iP
iâˆˆI31
(1+exp( yiF(t)
i))(1+exp( âˆ’yiF(t)
i))
1P
iâˆˆI2g(t)
iP
iâˆˆI21
(1+exp( yiF(t)
i))(1+exp( âˆ’yiF(t)
i))
âˆˆ"
1 + min iâˆˆI2exp(âˆ’yiF(t)
i)
1 + max iâˆˆI3exp(âˆ’yiF(t)
i),1 + max iâˆˆI2exp(âˆ’yiF(t)
i)
1 + min iâˆˆI3exp(âˆ’yiF(t)
i)#
.
By Definition F.1, we have
âˆ’P
iâˆˆI1g(t)
i+P
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’P
iâˆˆI1g(t)
i+P
iâˆˆI2g(t)
iÂ±o(1)P
iâˆˆ[n]g(t)
iP
iâˆˆI3g(t)
iâ‰¤6.
Thus,
P
iâˆˆI2g(t)
iP
iâˆˆI3g(t)
iâˆˆ1Â±6Â· "
1 + min iâˆˆI2exp(âˆ’yiF(t)
i)
1 + max iâˆˆI3exp(âˆ’yiF(t)
i),1 + max iâˆˆI2exp(âˆ’yiF(t)
i)
1 + min iâˆˆI3exp(âˆ’yiF(t)
i)#
âˆ’1!
.
Lemma F.6 (Complete version of Lemma 4.5) .Fortâˆˆ[T1, T2], we have
P
iâˆˆ[n]g(t)
iP
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’P
iâˆˆI1g(t)
i=O(1),P
iâˆˆ[n]g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i=O(1)
P
iâˆˆ[n]g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
i=O(1),âˆ‚G(t)(Âµ1)
âˆ‚t
âˆ‚G(t)(Âµ2)
âˆ‚t= Î˜(1) .
Further, there exists a constant Csuch that
(1 +C) maxâˆ‚G(t)(Âµ1)
âˆ‚t,âˆ‚G(t)(Âµ2)
âˆ‚t
â‰¤ âˆ’âˆ‚G(t)(Âµ3)
âˆ‚tâ‰¤(1âˆ’C)âˆ‚G(t)(Âµ1)
âˆ‚t+âˆ‚G(t)(Âµ2)
âˆ‚t
.
50Proof. Without loss of generality, assumeâˆ‚G(t)(Âµ1)
âˆ‚t>âˆ‚G(t)(Âµ2)
âˆ‚t. First of all, by Definition F.1, we
have
âˆ‚G(t)(Âµ1)
âˆ‚t=m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
iÂ±o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸,
âˆ‚G(t)(Âµ2)
âˆ‚t=m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI3g(t)
iÂ±o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸,
âˆ‚G(t)(Âµ3)
âˆ‚t=m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
iÂ±o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸.
This implies that
âˆ‚G(t)(Âµ1)
âˆ‚t
âˆ‚G(t)(Âµ2)
âˆ‚t=P
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iÂ±o(1)P
iâˆˆ[n]g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
iÂ±o(1)P
iâˆˆ[n]g(t)
i,
âˆ’âˆ‚G(t)(Âµ3)
âˆ‚t
âˆ‚G(t)(Âµ1)
âˆ‚t=âˆ’P
iâˆˆI1g(t)
i+P
iâˆˆI2âˆªI3âˆªI4g(t)
iÂ±o(1)P
iâˆˆ[n]g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iÂ±o(1)P
iâˆˆ[n]g(t)
i.
We next analyzeâˆ‚
âˆ‚tâˆ’âˆ‚G(t)(Âµ3)
âˆ‚t
âˆ‚G(t)(Âµ1)
âˆ‚t. We first define the ratio R(t) =P
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’P
iâˆˆI1g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i. Since
the dependence of Rontis clear and for the ease of notation, we omit this dependence below.
Rearranging this definition, we obtain
(1 +R) X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
i!
=X
iâˆˆI3âˆªI4g(t)
i. (13)
We consider the range of Râˆˆ[1,3]. By Definition F.1, we have
P
iâˆˆ[n]g(t)
iP
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’P
iâˆˆI1g(t)
i=O(1),P
iâˆˆ[n]g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i=O(1), (14)
where the second equation follows from Lemma F.5. This implies that
âˆ‚G(t)(Âµ1)
âˆ‚t
âˆ‚G(t)(Âµ2)
âˆ‚t= Î˜(1) ,P
iâˆˆ[n]g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
i=O(1),
which proves the first result and
âˆ’âˆ‚G(t)(Âµ3)
âˆ‚t
âˆ‚G(t)(Âµ1)
âˆ‚t=âˆ’P
iâˆˆI1g(t)
i+P
iâˆˆI2âˆªI3âˆªI4g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i+o(1).
Thus, to analyzeâˆ‚
âˆ‚tâˆ’âˆ‚G(t)(Âµ3)
âˆ‚t
âˆ‚G(t)(Âµ1)
âˆ‚t, we can instead analyze
âˆ‚
âˆ‚tP
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’P
iâˆˆI1g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iâ‰¥0
â‡”âˆ‚
âˆ‚t X
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’X
iâˆˆI1g(t)
i! X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
i!
âˆ’ X
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’X
iâˆˆI1g(t)
i!
âˆ‚
âˆ‚t X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
i!
â‰¥0
51â‡”X
iâˆˆI2âˆªI3âˆªI4âˆ‚g(t)
i
âˆ‚t+RX
iâˆˆI2âˆ‚g(t)
i
âˆ‚tâ‰¥(1 +R)X
iâˆˆI1âˆ‚g(t)
i
âˆ‚t. (15)
Recall that by Definition F.1, we have for i1âˆˆI1,
âˆ‚yi1F(t)
i1
âˆ‚t=m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­3X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’X
iâˆˆI2âˆªI3g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸;
fori2âˆˆI2,
âˆ‚yi2F(t)
i2
âˆ‚t=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸;
fori3âˆˆI3,
âˆ‚yi3F(t)
i3
âˆ‚t=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI3g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸;
and for i4âˆˆI4,
âˆ‚yi4F(t)
i4
âˆ‚t=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸.
The above implies that for i1âˆˆI1,
âˆ‚yi1F(t)
i1
âˆ‚tP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i=m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
n 
1 +P
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iâˆ’R+o(1)!
;
fori2âˆˆI2,
âˆ‚yi2F(t)
i2
âˆ‚tP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
n(1âˆ’R+o(1)) ;
fori3âˆˆI3,
âˆ‚yi3F(t)
i3
âˆ‚tP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
n P
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iâˆ’R+o(1)!
;
and for i4âˆˆI4,
âˆ‚yi1F(t)
i1
âˆ‚tP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
n(âˆ’R+o(1)).
Substituting the above into Equation (15) and divide both sides by
1
nPm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
, we have
(1 +R)X
i2âˆˆI2gâ€²(F(t)
i2)(Râˆ’1 +o(1)) +X
i3âˆˆI3gâ€²(F(t)
i3) 
Râˆ’P
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
i+o(1)!
+X
i4âˆˆI4gâ€²(F(t)
i4)(R+o(1))
â‰¥(1 +R)X
i1âˆˆI1gâ€²(F(t)
i1) 
1 +P
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iâˆ’R+o(1)!
. (16)
52By Lemma F.5, we obtainP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI3g(t)
iP
iâˆˆI1g(t)
iâˆ’P
iâˆˆI2g(t)
iâˆ’1â‰¤Îµ,
where we use Îµto denote the small deviation. Note that Equation (16) is a quadratic inequality in R
and can be rearranged as aR2+bR+câ‰¥0, where
a=X
i1âˆˆI1gâ€²(F(t)
i1) +X
i2âˆˆI2gâ€²(F(t)
i2),
b=X
i3âˆˆI3gâ€²(F(t)
i3) +X
i4âˆˆI4gâ€²(F(t)
i4)âˆ’X
i1âˆˆI1gâ€²(F(t)
i1),
c= (1 + o(1)) 
âˆ’X
i2âˆˆI2gâ€²(F(t)
i2)âˆ’(1Â±Îµ)X
i3âˆˆI3gâ€²(F(t)
i3)âˆ’(2Â±Îµ)X
i1âˆˆI1gâ€²(F(t)
i1)!
.
Now we analyze the equality condition in Equation (16) where we calculate the root of the equation
aR2+bR+c= 0. We have
b
a=P
i3âˆˆI3gâ€²(F(t)
i3) +P
i4âˆˆI4gâ€²(F(t)
i4)âˆ’P
i1âˆˆI1gâ€²(F(t)
i1)
P
i1âˆˆI1gâ€²(F(t)
i1) +P
i2âˆˆI2gâ€²(F(t)
i2),
c
a=(1 +o(1))
âˆ’P
i2âˆˆI2gâ€²(F(t)
i2)âˆ’(1Â±Îµ)P
i3âˆˆI3gâ€²(F(t)
i3)âˆ’(2Â±Îµ)P
i1âˆˆI1gâ€²(F(t)
i1)
P
i1âˆˆI1gâ€²(F(t)
i1) +P
i2âˆˆI2gâ€²(F(t)
i2).
Note that
X
iâˆˆIg(t)
imin
iâˆˆI1
1 + exp( yiF(t)
i)â‰¤ âˆ’X
iâˆˆIgâ€²(F(t)
i)â‰¤X
iâˆˆIg(t)
imax
iâˆˆI1
1 + exp( yiF(t)
i).
By Equation (14), we have âˆ’b
2aâ‰¥ âˆ’1/4and
b
aâ‰¤(1 +O(max
iâˆˆ[n]exp(âˆ’yiF(t)
i))) max P
i1âˆˆI1g(F(t)
i1)âˆ’P
i3âˆˆI3g(F(t)
i3)
P
i1âˆˆI1g(F(t)
i1) +P
i2âˆˆI2g(F(t)
i2),P
i4âˆˆI4g(F(t)
i4)
P
i1âˆˆI1g(F(t)
i1) +P
i2âˆˆI2g(F(t)
i2)!
â‰¤C <1,
andc
a= (1Â±O(Îµ)Â±O(max
iâˆˆ[n]exp(âˆ’yiF(t)
i)))Â·2.
Recall that we are considering the case of Râˆˆ[1,3]. Thus, we only need to consider the
root that is positive and we can calculate the root Râ‹†=âˆ’b
2a+q
b2
4a2âˆ’c
aâˆˆ(1,2)ifÎµand
max iâˆˆ[n]exp(âˆ’yiF(t)
i)are both suffiently small.
Next, since gâ€²(F(t)
i)<0, the root Râ‹†is contractive (i.e., if R(t)> Râ‹†thenR(t)is decreasing and if
R(t)< Râ‹†thenR(t)is increasing).
Finally, the result at the end of Phase 1 implies that R(T1)âˆˆ[1,3], which completes the proof.
Corollary F.7. Fortâˆˆ[T1, T2], we have
G(t)(Âµ1)
G(t)(Âµ2),G(t)(Âµ1)
âˆ’G(t)(Âµ3),G(t)(Âµ2)
âˆ’G(t)(Âµ3)= Î˜(1) .
Proof. We first proveG(t)(Âµ1)
G(t)(Âµ2)= Î˜(1) . Following from Lemma F.6, we haveâˆ‚G(t)(Âµ1)
âˆ‚t
âˆ‚G(t)(Âµ2)
âˆ‚t= Î˜(1) . By
Theorem E.27, we haveG(T1)(Âµ1)
G(T1)(Âµ2)= Î˜(1) . Thus, for tâˆˆ[T1, T2], we obtain
G(t)(Âµ1)
G(t)(Âµ2)=G(T1)(Âµ1) +Rt
T1âˆ‚G(Ï„)(Âµ1)
âˆ‚Ï„dÏ„
G(T1)(Âµ2) +Rt
T1âˆ‚G(Ï„)(Âµ2)
âˆ‚Ï„dÏ„= Î˜(1) .
53Note that Lemma F.6 and Definition F.1 imply thatâˆ‚G(t)(Âµ1)
âˆ‚t
âˆ’âˆ‚G(t)(Âµ3)
âˆ‚t= Î˜(1) . SinceG(T1)(Âµ1)
âˆ’G(T1)(Âµ3)= Î˜(1) ,
similarly, we haveG(t)(Âµ1)
âˆ’G(t)(Âµ3)= Î˜(1) . Finally,G(t)(Âµ1)
G(t)(Âµ2)= Î˜(1) andG(t)(Âµ1)
âˆ’G(t)(Âµ3)= Î˜(1) imply that
G(t)(Âµ2)
âˆ’G(t)(Âµ3)= Î˜(1) .
F.2 How Fast the Loss Decreases
Theorem F.8. Fortâˆˆ[T1, T2], we have
bL(t) =1
Î˜(Ïƒ2
1mm 1)(tâˆ’T1) + (1 /bL(T1)).
Proof. First of all, the gradient flow update for the empirical loss is given byâˆ‚bL
âˆ‚t=
Pn
i=1â„“â€²(yiF(t)
i)âˆ‚yiF(t)
i
âˆ‚t. By Definition F.1, we have for i1âˆˆI1,
âˆ‚yi1F(t)
i1
âˆ‚t=m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­3X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
iâˆ’X
iâˆˆI2âˆªI3g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸;
fori2âˆˆI2,
âˆ‚yi2F(t)
i2
âˆ‚t=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸;
fori3âˆˆI3,
âˆ‚yi3F(t)
i3
âˆ‚t=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI3g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸;
and for i4âˆˆI4,
âˆ‚yi4F(t)
i4
âˆ‚t=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E1
nï£«
ï£­X
iâˆˆI1g(t)
iâˆ’X
iâˆˆI2âˆªI3âˆªI4g(t)
i+o(1)X
iâˆˆ[n]g(t)
iï£¶
ï£¸.
By Lemma F.6, we have
âˆ‚yiF(t)
i
âˆ‚t=m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
Î˜ï£«
ï£­1
nX
iâˆˆ[n]g(t)
iï£¶
ï£¸
for all iâˆˆ[n]. Therefore,
âˆ‚bL
âˆ‚t=1
nnX
i=1â„“â€²(yiF(t)
i)âˆ‚yiF(t)
i
âˆ‚t
=1
nnX
i=1âˆ’g(t)
im1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
Î˜ï£«
ï£­1
nX
iâ€²âˆˆ[n]g(t)
iâ€²ï£¶
ï£¸
=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
Î˜ï£«
ï£¬ï£­ï£«
ï£­1
nX
iâˆˆ[n]g(t)
iï£¶
ï£¸2ï£¶
ï£·ï£¸
=âˆ’m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
Î˜
bL2
,
54where the last equality follows from the property of binary cross-entropy loss that â„“(x) = Î˜( âˆ’â„“â€²(x))
forx >0. By Definition F.1 and Lemma F.4, we have for all tâˆˆ[T1, T2],
m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
= Î˜( Ïƒ2
1mm 1).
Thus, we have
âˆ‚bL
âˆ‚t=âˆ’Î˜(Ïƒ2
1mm 1)bL2.
Now, consider the differential equationdL
dt=âˆ’C1L2. Note that this is a separable differential
equation in tand we can solve it by
1
L2dL
dt+C1= 0 â‡’d
dt 
C1tâˆ’Lâˆ’1+C2
= 0 â‡’ L(t) =1
C1t+C2.
This implies for tâˆˆ[T1, T2], we have
bL(t) =1
Î˜(Ïƒ2
1mm 1)(tâˆ’T1) + (1 /bL(T1))
Corollary F.9. The following bound holds:
m1X
j1=1m1X
j2=1D
aj1w(T2)
j1, aj2w(T2)
j2E
âˆ’m1X
j1=1m1X
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2Eâ‰¤eOm1
m
.
Proof. This is a direct consequence of Lemma F.4 and Theorem F.8.
F.3 Growth of Neuron Correlation
Lemma F.10. Fortâˆˆ[T1, T2], we have
m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
âˆ’m1X
j1=1m1X
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2E
=Om1logmlogt
Ïƒ2
1mm 1
=Om1log2m
Ïƒ2
1mm 1
and thus,
m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
= Î˜( Ïƒ2
1mm 1).
Proof. By Lemma F.4, we have
âˆ‚
âˆ‚tm1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
=2m1
nnX
i=1g(t)
iyiF(t)
i.
By Theorem F.8, we have1
nPn
i=1g(t)
i=O(bL(t)) =O
1
(Ïƒ2
1mm 1)(tâˆ’T1)+1/bL(T1)
. Further, by
Definition F.1, we have |F(t)
i| â‰¤O(logm). Thus, for tâˆˆ[T1, T2], we obtain
m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
âˆ’m1X
j1=1m1X
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2E
= 2m1Zt
T11
nnX
i=1g(Ï„)
iyiF(Ï„)
idÏ„
55â‰¤O(m1logm)Zt
T1O 
1
(Ïƒ2
1mm 1)(Ï„âˆ’T1) + 1/bL(T1)!
dÏ„
=Om1logmlogt
Ïƒ2
1mm 1
=Om1log2m
Ïƒ2
1mm 1
where the last line follows because T2â‰¤O(poly(m))in Definition F.1. Finally, by Theorem E.27
we have
m1X
j1=1m1X
j2=1D
aj1w(T1)
j1, aj2w(T1)
j2E
= Î˜( Ïƒ2
1mm 1).
F.4 Growth of Correlation of Value-Transformed Data
We now analyze the correlation term with value-transformed data.
Lemma F.11 (Growth of correlation of value-transformed data) .ForÂµ, Î½âˆˆ {Âµi}d
i=1, we have
âˆ‚
âˆ‚tÂµâŠ¤W(t)âŠ¤
VW(t)
VÎ½=G(t)(Î½)1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Âµ+G(t)(Âµ)1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Î½.
Thus, for tâˆˆ[T1, T2], we have
max
Âµ,Î½ÂµâŠ¤W(t)âŠ¤
VW(t)
VÎ½âˆ’ÂµâŠ¤W(T1)âŠ¤
V W(T1)
VÎ½â‰¤Ologmlogt
Ïƒ2
1mm 1
.
Proof. By the gradient flow update, we have
âˆ‚ÂµW(t)âŠ¤
VW(t)
VÎ½
âˆ‚t
=1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÎ½âŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Âµ+1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Vw(t)
jp(t,i)
qâ†l,kâ†Î½
=G(t)(Î½)1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Âµ+G(t)(Âµ)1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Î½.
Thus, we obtain
ÂµW(Ï„)âŠ¤
VW(Ï„)
VÎ½âˆ’ÂµW(T1)âŠ¤
V W(T1)
VÎ½
â‰¤ZÏ„
T1|G(t)(Î½)|1
nX
i:ÂµâˆˆX(i)g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Âµ+|G(t)(Âµ)|1
nX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1p(t,i)
qâ†l,kâ†Î½dt.
By Definition F.1, for tâˆˆ[T1, T2], we have |G(t)(Âµ)| â‰¤O(logm)andPL
l=1p(t,i)
qâ†l,kâ†Âµâ‰¤O(1).
Further, by the property of the cross-entropy loss, we have
1
nX
i:ÂµâˆˆX(i)g(t)
iyi=O(bL(t)).
Therefore, by Theorem F.8, we obtain
ÂµW(Ï„)âŠ¤
VW(Ï„)
VÎ½âˆ’ÂµW(T1)âŠ¤
V W(T1)
VÎ½â‰¤O(logm)ZÏ„
T1bL(t)dtâ‰¤O(logm)Â·OlogÏ„
Ïƒ2
1mm 1
.
56Corollary F.12. Fortâˆˆ[T1, T2], we have
maxÂµâˆˆ{Âµi}d
i=1Pm1
j=1ajâˆ‚w(t)
j
âˆ‚tW(t)
VÂµ
Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2Eâ‰¤o(1/L)1
nX
iâˆˆ[n]g(t)
i.
Proof. By Lemma E.9 and and Lemma F.11, for all ÂµÌ¸=Î½âˆˆ {Âµi}d
i=1, we have |ÂµâŠ¤W(t)âŠ¤
VW(t)
VÎ½| â‰¤
eO(Ïƒ2
0âˆšm+ 1/m)andâˆ¥W(t)
VÎ½âˆ¥2
2=eO(Ïƒ2
0m+ 1/m). Thus, by Lemma F.11, we have
max Âµ,Î½ÂµâŠ¤W(t)âŠ¤
VW(t)
VÎ½
Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2Eâ‰¤eOÏƒ2
0âˆšm+ 1/m
Ïƒ2
1mm 1
,
max Î½âˆ¥W(t)
VÎ½âˆ¥2
2Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2Eâ‰¤eOÏƒ2
0m+ 1/m
Ïƒ2
1mm 1
.
Recall that
m1X
j=1ajâˆ‚w(t)
j
âˆ‚tW(t)
VÂµ=m1
nnX
i1=1g(t)
i1yi1LX
l1=1p(t,i1)âŠ¤
l1V(t,i1)âŠ¤W(t)
VÂµ.
This implies that
maxÂµâˆˆ{Âµi}d
i=1Pm1
j=1ajâˆ‚w(t)
j
âˆ‚tW(t)
VÂµ
Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2Eâ‰¤eOÏƒ2
0âˆšmL+L/m +Ïƒ2
0m+ 1/m
Ïƒ2
1m
Â·1
nnX
i=1g(t)
i.
Corollary F.13 (Complete version of Corollary 4.6) .Fortâˆˆ[T1, T2], we have
âˆ‚
âˆ‚tÂµâŠ¤
2W(t)âŠ¤
VW(t)
VÂµ1>0,âˆ‚
âˆ‚tÂµâŠ¤
1W(t)âŠ¤
VW(t)
VÂµ1>0,âˆ‚
âˆ‚tÂµâŠ¤
2W(t)âŠ¤
VW(t)
VÂµ2>0
âˆ‚
âˆ‚tÂµâŠ¤
1W(t)âŠ¤
VW(t)
VÂµ3<0,âˆ‚
âˆ‚tÂµâŠ¤
2W(t)âŠ¤
VW(t)
VÂµ3<0.
Proof. This is a direct consequence of Lemma F.11, Lemma F.6 and Definition F.1.
F.5 Change of Random-Token Sub-Network
Lemma F.14. Fortâˆˆ[T1, T2]andÂµâˆˆ {Âµi}d
i=4, we have
âˆ‚G(t)(Âµ)
âˆ‚tâ‰¤O1
nbL(t)Ïƒ2
1mm 1
+eO(bL(t)m1(L(Ïƒ2
0âˆšm+ 1/m) +Ïƒ2
0m)).
Thus,
G(t)(Âµ)âˆ’G(T1)(Âµ)â‰¤eO1
n+m1(L(Ïƒ2
0âˆšm+ 1/m) +Ïƒ2
0m)
Ïƒ2
1mm 1
.
Proof. By Lemma C.1 and Definition F.1, we have
âˆ‚G(t)(Âµ)
âˆ‚t=m1X
j=1ajw(t)
jâˆ‚W(t)
VÂµ
âˆ‚t+ajâˆ‚w(t)
j
âˆ‚tW(t)
VÂµ
â‰¤1
nX
i2:ÂµâˆˆX(i2)g(t)
i2yi2LX
l2=1m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
p(t,i2)
qâ†l2,kâ†Âµ
57+1
nnX
i1=1g(t)
i1yi1m1LX
l1=1LX
l2=1D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)E.
By Definition F.1 and Corollary F.2,
1
nX
i2:ÂµâˆˆX(i2)g(t)
i2yi2LX
l2=1m1X
j1=1m1X
j2=1aj1aj2D
w(t)
j1, w(t)
j2E
p(t,i2)
qâ†l2,kâ†Âµâ‰¤O1
nbL(t)Ïƒ2
1mm 1
.
By Lemma E.9 and and Lemma F.11, we have |ÂµâŠ¤W(t)âŠ¤
VW(t)
VÎ½| â‰¤eO(Ïƒ2
0âˆšm+ 1/m)forÂµÌ¸=Î½
andâˆ¥W(t)
VÂµâˆ¥2
2=O(Ïƒ2
0m). Thus,
1
nnX
i1=1g(t)
i1yi1m1LX
l1=1LX
l2=1D
p(t,i1)
l1,l2v(t,i1)
l2, v(t)(Âµ)Eâ‰¤eO(bL(t)m1(L(Ïƒ2
0âˆšm+ 1/m) +Ïƒ2
0m)).
Thus, by Theorem F.8, for tâˆˆ[T1, T2], we have
G(t)(Âµ)âˆ’G(T1)(Âµ)=Zt
T1âˆ‚G(Ï„)(Âµ)
âˆ‚Ï„dÏ„â‰¤
OÏƒ2
1mm 1
n
+eO(m1L(Ïƒ2
0âˆšm+ 1/m))Zt
T1bL(Ï„)dÏ„
â‰¤eO1
n+m1(L(Ïƒ2
0âˆšm+ 1/m) +Ïƒ2
0m)
Ïƒ2
1mm 1
.
Corollary F.15. Fortâˆˆ[T1, T2], we have
LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(t)(X(i)
l2)p(t,i)
qâ†l1,kâ†l2â‰¤O(1).
Proof. By Lemma F.3, we have
LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(T1)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2â‰¤O(1)
By Lemma F.14, for tâˆˆ[T1, T2],G(t)(Âµ) =O(1)forÂµâˆˆ {Âµi}d
i=4. On the other hand, by the
triangle inequality, we have
LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(T1)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2âˆ’LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(t)(X(i)
l2)p(t,i)
qâ†l1,kâ†l2
â‰¤LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4(G(T1)(X(i)
l2)âˆ’G(t)(X(i)
l2))p(t,i)
qâ†l1,kâ†l2
+LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(t)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2âˆ’p(t,i)
qâ†l1,kâ†l2
+LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(T1)(X(i)
l2)âˆ’G(t)(X(i)
l2)p(T1,i)
qâ†l1,kâ†l2âˆ’p(t,i)
qâ†l1,kâ†l2
â‰¤O(1),
58where the last inequality applies Definition F.1. This implies that, for tâˆˆ[T1, T2], by Lemma F.14,
we haveLX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(t)(X(i)
l2)p(t,i)
qâ†l1,kâ†l2â‰¤O(1).
F.6 Change of Score and Softmax Probability
Lemma F.16 (Change of score, complete version of Lemma 4.7) .Fortâˆˆ[T1, T2], the attention
scores are changing in the following way:
â€¢ForÂµ, Î½âˆˆ {Âµ1, Âµ2}, ÂµÌ¸=Î½, the query-key-correlation score between the two target signals
increases, while the query-key-correlation score between one target signal and the common
token decreases, i.e.,
âˆ‚
âˆ‚tÎ½âŠ¤W(t)âŠ¤
KW(t)
QÂµ=1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L,
âˆ‚
âˆ‚tÂµâŠ¤
3W(t)âŠ¤
KW(t)
QÂµ=âˆ’1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L.
â€¢The change of score satisfies:
max
Âµ,Î½âˆˆ{Âµi}3
i=1Î½âŠ¤W(t)
KW(t)
QÂµâˆ’Î½âŠ¤W(T1)
KW(T1)
QÂµ= Î˜Ïƒ2
0mâˆšmLÏƒ2
1mm 1+Ïƒ2
0âˆšmâˆšmÏƒ2
1mm 1
.
â€¢For all Âµâˆˆ {Âµ1, Âµ2, Âµ3}, Î³âˆˆ {Âµi}d
i=4, the query-key-correlation score changes as follows:
âˆ‚
âˆ‚tÂµâŠ¤W(t)âŠ¤
KW(t)
QÎ³=1
nâˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L+eO1âˆšmbL(t)Ïƒ2
0âˆšm
,
and
ÂµâŠ¤W(t)âŠ¤
KW(t)
QÎ³âˆ’ÂµâŠ¤W(T1)âŠ¤
K W(T1)
QÎ³â‰¤eOÏƒ2
0m
nâˆšmLÏƒ2
1mm 1+Ïƒ2
0âˆšmâˆšmÏƒ2
1mm 1
,
Î³âŠ¤W(t)âŠ¤
KW(t)
QÂµâˆ’Î³âŠ¤W(T1)âŠ¤
K W(T1)
QÂµâ‰¤eOÏƒ2
0m
nâˆšmLÏƒ2
1mm 1+Ïƒ2
0âˆšmâˆšmÏƒ2
1mm 1
.
Proof. By Lemma C.4, we have
âˆ‚Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ
âˆ‚t
=1
nâˆšmX
i:Âµ,Î½âˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥k(t)(Î½)âˆ¥2
2
v(t)âŠ¤(Î½)w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
qâ†Âµ,kâ†Î½
+1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajLX
l=1Î½âŠ¤W(t)âŠ¤
KK(t,i)
l
V(t,i)âŠ¤
lw(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
qâ†Âµ,kâ†lI(K(t,i)
lÌ¸=k(t)(Î½))
+1
nâˆšmX
i:Î½,ÂµâˆˆX(i)g(t)
iyim1X
j=1ajâˆ¥q(t)(Âµ)âˆ¥2
2p(t,i)
qâ†Âµ,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyiLX
l=1m1X
j=1ajÂµâŠ¤W(t)âŠ¤
Qq(t,i)
lp(t,i)
qâ†l,kâ†Î½
w(t)âŠ¤
jv(t,i)(Î½)âˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l
I(q(t,i)
lÌ¸=q(t)(Âµ)).
Now, we take Âµ=Âµ1, Î½=Âµ2. By Theorem E.27, we have G(T1)(Âµ2)â‰¥â„¦(1) . A consequence of
Definition F.1 and Lemma F.6 is thatâˆ‚G(t)(Âµ2)
âˆ‚t>0fortâˆˆ[T1, T2]. Thus, we have G(t)(Âµ2)â‰¥â„¦(1) .
59Further by Theorem E.27, we have G(T1)(Âµ) =eO(Ïƒ0Ïƒ1âˆšmm 1)forÂµâˆˆ R and then by Lemma F.14,
we have G(t)(Âµ) =eO(Ïƒ0Ïƒ1âˆšmm 1) +eO
1
n+m1(L(Ïƒ2
0âˆšm+1/m)+Ïƒ2
0m)
Ïƒ2
1mm 1
fortâˆˆ[T1, T2]. Also,
Definition F.1 implies that G(t)(Âµ2)âˆ’Pm1
j=1w(t)
jV(t,i)p(t,i)
l(i,Âµ)â‰¥â„¦(1) . Now, this yields
âˆ‚ÂµâŠ¤
2W(t)âŠ¤
KW(t)
QÂµ1
âˆ‚t=1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L+eO1âˆšmbL(t)Ïƒ2
0âˆšm
.
On the other hand, by the analysis similar to the above, we obtain
âˆ‚ÂµâŠ¤
3W(t)âŠ¤
KW(t)
QÂµ1
âˆ‚t=âˆ’1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L+eO1âˆšmbL(t)Ïƒ2
0âˆšm
.
Next, to prove the maximum change of the score, we have
max
Âµ,Î½âˆ‚Î½âŠ¤W(t)
KW(t)
QÂµ
âˆ‚tâ‰¤1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L+eO1âˆšmbL(t)Ïƒ2
0âˆšm
.
By Theorem F.8, we have
Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµâˆ’Î½âŠ¤W(T1)âŠ¤
K W(T1)
QÂµâ‰¤Zt
T11âˆšmeÎ˜(bL(Ï„)Ïƒ2
0m)1
L+eO1âˆšmbL(Ï„)Ïƒ2
0âˆšm
dÏ„
â‰¤eOÏƒ2
0mâˆšmLÏƒ2
1mm 1+Ïƒ2
0âˆšmâˆšmÏƒ2
1mm 1
.
Finally, for Î³âˆˆ {Âµi}d
i=4, Âµâˆˆ {Âµi}d
i=1, we have
âˆ‚
âˆ‚tÂµâŠ¤W(t)âŠ¤
KW(t)
QÎ³=1
nâˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L+eO1âˆšmbL(t)Ïƒ2
0âˆšm
,
which implies that
ÂµâŠ¤W(t)âŠ¤
KW(t)
QÎ³âˆ’ÂµâŠ¤W(T1)âŠ¤
K W(T1)
QÎ³â‰¤eOÏƒ2
0m
nâˆšmLÏƒ2
1mm 1+Ïƒ2
0âˆšmâˆšmÏƒ2
1mm 1
.
Corollary F.17 (Change of softmax) .Fortâˆˆ[T1, T2], the softmax probability is changing in the
following way:
â€¢ForÂµ, Î½âˆˆ {Âµ1, Âµ2}, ÂµÌ¸=Î½, the softmax probability between the two target signals
increases, whereas the softmax probability between one target signal and the common token
decreases, i.e.,
âˆ‚
âˆ‚tp(t,i)
qâ†Âµ,kâ†Î½=1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L2,
âˆ‚
âˆ‚tp(t,i)
qâ†Âµ,kâ†Âµ3=âˆ’1âˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L2.
â€¢For all Âµâˆˆ {Âµ1, Âµ2}, Î³âˆˆ {Âµi}d
i=4, the softmax probability between one target signal and
a random token changes as follows:
âˆ‚
âˆ‚tp(t,i)
qâ†Âµ,kâ†Î³â‰¤1
nâˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L2+eO1
LâˆšmbL(t)Ïƒ2
0âˆšm
.
Furthermore, we have
max
iâˆˆ[n],l1,l2âˆˆ[L]p(t,i)
l1,l2âˆ’p(0,i)
l1,l2â‰¤O(1/L2).
60Proof. TakeÂµ=Âµ1, Î½=Âµ2. First of all, by Definition F.1 and Lemma F.16, we have
p(t,i)âŠ¤
qâ†Âµ1âˆ‚X(i)âŠ¤W(t)âŠ¤
KW(t)
QÂµ1
âˆ‚tâ‰¤1âˆšmO(bL(t)Ïƒ2
0m)1
L2+1
nâˆšmeÎ˜(bL(t)Ïƒ2
0m)1
L+eO1âˆšmbL(t)Ïƒ2
0âˆšm
.
Thus, by Lemma G.1 and Lemma F.16, for iâˆˆI1, we obtain
âˆ‚
âˆ‚tp(t,i)
qâ†Âµ1,kâ†Âµ2=1
meÎ˜(bL(t)Ïƒ2
0m)1
L2,
âˆ‚
âˆ‚tp(t,i)
qâ†Âµ1,kâ†Âµ3=âˆ’1
meÎ˜(bL(t)Ïƒ2
0m)1
L2.
On the other hand, for Î³âˆˆ {Âµi}d
i=4, we have
âˆ‚
âˆ‚tp(t,i)
qâ†Âµ,kâ†Î³â‰¤1
nmeÎ˜(bL(t)Ïƒ2
0m)1
L2+eO1
LmbL(t)Ïƒ2
0âˆšm
.
Finally, by Lemma F.16, we have
max
Âµ,Î½Î½âŠ¤W(t)
KW(t)
QÂµâˆ’Î½âŠ¤W(T1)
KW(T1)
QÂµâ‰¤eOÏƒ2
0mâˆšmLÏƒ2
1mm 1+Ïƒ2
0âˆšmâˆšmÏƒ2
1mm 1
.
Thus, by Lemma G.2, we obtain
max
i,l1,l2p(t,i)
l1,l2âˆ’p(T1,i)
l1,l2
â‰¤eO 
Ïƒ2
0m
mL2Ïƒ2
1mm 1+Ïƒ2
0âˆšm
mÏƒ2
1mm 1L+LÏƒ2
0m
mLÏƒ2
1mm 1+Ïƒ2
0âˆšm
mÏƒ2
1mm 12!
=O(1/L2).
Corollary F.18. Fortâˆˆ[T1, T2], we have
max iâˆˆ[n]PL
l1=1PL
l2=1G(t)(X(i)
l2)âˆ‚p(t,i)
l1,l2
âˆ‚t
Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2E â‰¤o(1)1
nX
iâˆˆ[n]g(t)
i.
Proof. This is a direct consequence of Definition F.1, Lemma F.10 and Corollary F.17.
F.7 Change of Self-Correlation of Key/Query-Transformed data
Lemma F.19 (Change of self-correlation) .ForÂµ, Î½âˆˆ {Âµi}d
i=1, we have
Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµâˆ’Î½âŠ¤W(T1)âŠ¤
Q W(T1)
QÂµâ‰¤eOÏƒ2
0âˆšmâˆšmÏƒ2
1mm 1
,
Î½âŠ¤W(t)âŠ¤
KW(t)
KÂµâˆ’Î½âŠ¤W(T1)âŠ¤
K W(T1)
KÂµâ‰¤eOÏƒ2
0âˆšmâˆšmÏƒ2
1mm 1
.
Proof. We prove the result for Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµand the proof for Î½âŠ¤W(t)âŠ¤
KW(t)
KÂµis similar. By
Lemma C.4, we have
âˆ‚Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµ
âˆ‚t
=1
nâˆšmX
i:ÂµâˆˆX(i)g(t)
iyim1X
j=1ajÎ½âŠ¤W(t)âŠ¤
QK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Âµ)
p(t,i)
l(i,Âµ)
+1
nâˆšmX
i:Î½âˆˆX(i)g(t)
iyim1X
j=1ajÂµâŠ¤W(t)âŠ¤
QK(t,i)diag
V(t,i)âŠ¤w(t)
jâˆ’w(t)âŠ¤
jV(t,i)p(t,i)
l(i,Î½)
p(t,i)
l(i,Î½).
61A simple result from Lemma F.16 is that |Î½âŠ¤W(t)âŠ¤
KW(t)
QÂµ| â‰¤eO(Ïƒ2
0âˆšm)fortâˆˆ[T1, T2]and
Âµ, Î½âˆˆ {Âµi}d
i=1. Therefore, by Definition F.1,
âˆ‚Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµ
âˆ‚tâ‰¤eO1âˆšmbL(t)Ïƒ2
0âˆšmlogm
,
which implies
Î½âŠ¤W(t)âŠ¤
QW(t)
QÂµâˆ’Î½âŠ¤W(T1)âŠ¤
Q W(T1)
QÂµâ‰¤Zt
T1eO1âˆšmbL(t)Ïƒ2
0âˆšmlogm
dÏ„â‰¤eOÏƒ2
0âˆšmâˆšmÏƒ2
1mm 1
,
where the inequality follows from Theorem F.8 and Definition F.1.
F.8 Small Loss is Achieved
Theorem F.20. Define Tâ‹†= min t{t:bL(t)= Î˜(1 /poly(m))}. Then, Tâ‹†âˆˆ[T1, T2].
Proof. The following results altogether show that Phase 2 can last for at least Î˜(poly(m))time:
â€¢ Lemma F.19 proves that the change of K, Q self-correlation as follows:
max
Âµ,Î½ÂµâŠ¤W(t)âŠ¤
KW(t)
KÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
KW(0)
KÎ½=eO(Ïƒ2
0âˆšm),
max
Âµ,Î½ÂµâŠ¤W(t)âŠ¤
QW(t)
QÎ½âˆ’ÂµâŠ¤W(0)âŠ¤
QW(0)
QÎ½=eO(Ïƒ2
0âˆšm).
â€¢ Corollary F.9 proves that
m1X
j1=1m1X
j2=1D
aj1w(t)
j1, aj2w(t)
j2E
â‰¤O(Ïƒ2
1mm 1).
â€¢ Corollary F.12 proves that
maxÂµâˆˆ{Âµi}d
i=1Pm1
j=1ajâˆ‚w(t)
j
âˆ‚tW(t)
VÂµ
Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2Eâ‰¤o(1/L)1
nX
iâˆˆ[n]g(t)
i.
â€¢ Corollary F.15 proves that
LX
l1=1X
l2:X(i)
l2âˆˆ{Âµk}d
k=4G(t)(X(i)
l2)p(t,i)
qâ†l1,kâ†l2â‰¤O(1).
â€¢ Corollary F.17 proves that
max
iâˆˆ[n],l1,l2âˆˆ[L]p(t,i)
l1,l2âˆ’p(0,i)
l1,l2â‰¤O(1/L2).
â€¢ Corollary F.18 proves that
max iâˆˆ[n]PL
l1=1PL
l2=1G(t)(X(i)
l2)âˆ‚p(t,i)
l1,l2
âˆ‚t
Pm1
j1=1Pm1
j2=1D
aj1w(t)
j1, aj2w(t)
j2E â‰¤o(1)1
nX
iâˆˆ[n]g(t)
i.
â€¢ Lemma F.5 implies that
1
2â‰¤P
iâˆˆI2g(t)
iP
iâˆˆI3g(t)
iâ‰¤2.
62â€¢ Lemma F.6 implies that the gradientsP
iâˆˆIg(t)
iforIâˆˆ {I1, I2, I3, I4}satisfies
X
iâˆˆI4giâ‰¤min X
iâˆˆI2g(t)
i,X
iâˆˆI3g(t)
i!
â‰¤max X
iâˆˆI2g(t)
i,X
iâˆˆI3g(t)
i!
â‰¤X
iâˆˆI1g(t)
iâ‰¤X
iâˆˆI2âˆªI3âˆªI4g(t)
i.
â€¢ Lemma F.6 and Corollary F.17 proves that yiF(t)
iâ‰¥yiF(T1)
iâ‰¥C.
The above shows that all the requirements needed to satisfy the definition of Phase 2 (Definition F.1)
can hold for at least â„¦(poly(m))time. Thus, T2âˆ’T1â‰¥â„¦(poly(m)). Further, by Theorem F.8, we
have that bL(t)â‰¤O(1/poly(m))implies t= Î˜( poly(m)).
F.9 Proof of Theorem 3.2
Proof. This is proved in Corollary F.13 and Lemma F.16.
F.10 Proof of Theorem 3.3
Proof. This is proved as a direct consequence of Lemma F.6 and Theorem F.20.
For the generalization loss, since the training loss satisfies bL(Tâ‹†)â‰¤1/poly(m), for each class Iâˆˆ
{I1, I2, I3, I4}there exists a sample Xâ‹†
Isuch that â„“(Xâ‹†
I)â‰¤1/poly(m). Note that by Definition F.1
the random tokens only contributes to O(1)inF(Tâ‹†)(X). Thus, given a fixed new sample Xâˆ¼ D,
we have |F(Tâ‹†)(X)âˆ’F(Tâ‹†)(Xâ‹†
I)| â‰¤O(1)which implies â„“(yF(Tâ‹†)(X))â‰¤1/poly(m). Since this
holds for all Xâˆ¼ D, we have L(Tâ‹†)â‰¤1/poly(m).
G Auxiliary Results
The gradient of p(x)i=Softmax (x)iforxâˆˆRn:
âˆ‚p(x)i
âˆ‚xj=âˆ‚
âˆ‚xjexp(xi)Pn
k=1exp(xk)=ï£±
ï£²
ï£³âˆ’exp(xi)P
kexp(xk)exp(xj)P
kexp(xk)=âˆ’p(x)ip(x)j iÌ¸=j
exp(xi)P
kexp(xk)âˆ’
exp(xi)P
kexp(xk)2
=p(x)i(1âˆ’p(x)i)i=j
=p(x)i(I(i=j)âˆ’p(x)j)
â‡’J(p(x)) = diag(p(x))âˆ’p(x)p(x)âŠ¤. (17)
Lemma G.1 (Gradient of softmax) .Lets(t)âˆˆRlbe differentiable in tandp(s) = Softmax (s).
Denote pi(s) =Softmax (s)i. Then
âˆ‚p(s(t))
âˆ‚t=âˆ‚p(s)
âˆ‚sâˆ‚s(t)
âˆ‚t= (diag(p(s))âˆ’p(s)p(s)âŠ¤)âˆ‚s(t)
âˆ‚t.
Proof. By the chain rule and the gradient of softmax in Equation (17), we obtain
âˆ‚p(s(t))
âˆ‚t=âˆ‚p(s)
âˆ‚sâˆ‚s(t)
âˆ‚t=J(p(s))âˆ‚s(t)
âˆ‚t= (diag(p(s))âˆ’p(s)p(s)âŠ¤)âˆ‚s(t)
âˆ‚t.
Lemma G.2 (Perturbation of softmax) .LetsâˆˆRlandp(s) = Softmax (s). Denote pi(s) =
Softmax (s)i. Consider a small perturbation ÎµâˆˆRltos. Then
p(s+Îµ)âˆ’p(s) = ( diag(p(s))âˆ’p(s)p(s)âŠ¤)Îµ+Î¾,
where âˆ¥Î¾âˆ¥âˆ=O(âˆ¥Îµâˆ¥2
2).
Proof. By Taylorâ€™s expansion theorem on softmax and the gradient of softmax in Equation (17), we
have
p(s+Îµ)âˆ’p(s) =J(p(s))Îµ+Î¾= (diag(p(s))âˆ’p(s)p(s)âŠ¤)Îµ+Î¾,
where âˆ¥Î¾âˆ¥âˆ=O(âˆ¥Îµâˆ¥2
2).
63H Probability
Lemma H.1 (Bernsteinâ€™s inequality for bounded random variables) .Assume Z1, . . . , Z nareni.i.d.
random variables with E[Zi] = 0 and|Zi| â‰¤Mfor all iâˆˆ[n]almost surely. Let Z=Pn
i=1Zi.
Then, for all t >0,
P[Z > t ]â‰¤exp 
âˆ’t2/2Pn
j=1E[Z2
j] +Mt/3!
â‰¤exp 
âˆ’min(
t2
2Pn
j=1E[Z2
j],t
2M)!
,
which implies with probability at least 1âˆ’Î´,
Zâ‰¤vuut2nX
j=1E[Z2
j] log1
Î´+ 2Mlog1
Î´.
Lemma H.2. Forw1, w2âˆˆRmwithw1, w2i.i.d.âˆ¼ N (0, Im/m), we have
P"
âˆ¥w1âˆ¥2
2âˆ’1â‰¥r
4
mlog2
Î´+4
mlog2
Î´#
â‰¤Î´,
P"
|âŸ¨w1, w2âŸ©| â‰¥r
4
mlog2
Î´+4
mlog2
Î´#
â‰¤Î´.
Proof. We first have
E
âˆ¥w1âˆ¥2
2
=E"mX
i=1w2
1,i#
= 1.
Note that w2
1,iis a sub-Gamma random variable with parameters (4
m2,4
m). Thus, by Bernsteinâ€™s
inequality,
P"
âˆ¥w1âˆ¥2
2âˆ’E
âˆ¥w1âˆ¥2
2â‰¥r
4
mlog2
Î´+4
mlog2
Î´#
â‰¤Î´.
Next,
E[âŸ¨w1, w2âŸ©] =E"mX
i=1w1,iw2,i#
= 0
By Bernsteinâ€™s inequality, we obtain
P"
|âŸ¨w1, w2âŸ©| â‰¥r
4
mlog2
Î´+4
mlog2
Î´#
â‰¤Î´.
64NeurIPS Paper Checklist
The checklist is designed to encourage best practices for responsible machine learning research,
addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
the checklist: The papers not including the checklist will be desk rejected. The checklist should
follow the references and precede the (optional) supplemental material. The checklist does NOT
count towards the page limit.
Please read the checklist guidelines carefully for information on how to answer these questions. For
each question in the checklist:
â€¢ You should answer [Yes] , [No] , or [NA] .
â€¢[NA] means either that the question is Not Applicable for that particular paper or the
relevant information is Not Available.
â€¢ Please provide a short (1â€“2 sentence) justification right after your answer (even for NA).
The checklist answers are an integral part of your paper submission. They are visible to the
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
(after eventual revisions) with the final version of your paper, and its final version will be published
with the paper.
The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a
proper justification is given (e.g., "error bars are not reported because it would be too computationally
expensive" or "we were unable to find the license for the dataset we used"). In general, answering
"[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we
acknowledge that the true answer is often more nuanced, so please just use your best judgment and
write a justification to elaborate. All supporting evidence can appear either in the main paper or the
supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification
please point to the section(s) where related material for the question can be found.
IMPORTANT, please:
â€¢Delete this instruction block, but keep the section heading â€œNeurIPS paper checklist" ,
â€¢Keep the checklist subsection headings, questions/answers and guidelines below.
â€¢Do not modify the questions and only use the provided macros for your answers .
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justification: [NA]
Guidelines:
â€¢The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
â€¢It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: [NA]
65Guidelines:
â€¢The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
â€¢The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
â€¢The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
â€¢If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
â€¢While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢All assumptions should be clearly stated or referenced in the statement of any theorems.
â€¢The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
â€¢Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
66â€¢If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
â€¢Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
â€¢While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
â€¢While we encourage the release of code and data, we understand that this might not be
possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
â€¢The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
â€¢At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
67â€¢Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
â€¢The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA]
Justification: The experiments are done with synthetic data of small scale and the behavior
of the experiment results are pretty consistent.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
â€¢The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
â€¢The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
â€¢It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
â€¢It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
â€¢For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
68â€¢The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didnâ€™t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: [NA]
Guidelines:
â€¢The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
â€¢The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
â€¢If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
â€¢The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
69â€¢Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
â€¢Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
â€¢If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
â€¢For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
â€¢If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢The paper should discuss whether and how consent was obtained from people whose
asset is used.
â€¢At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: [NA]
70Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
â€¢According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: [NA]
Guidelines:
â€¢The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
â€¢Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
â€¢We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
71